{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KPrfYY_pxOyb"
      },
      "source": [
        "<img\n",
        "src=\"https://www.imt-atlantique.fr/sites/default/files/Images/Ecole/charte-graphique/IMT_Atlantique_logo_RVB_Baseline_400x272.jpg\"\n",
        "WIDTH=235 HEIGHT=180>\n",
        "\n",
        "<div align='center' >\n",
        "\n",
        "<font size=\"8\"> Final Project of Class Deep Learning</font>\n",
        "\n",
        "<font size=\"5\"> Students Name: Zuoyu Zhang and Xingyuan Kang</font>\n",
        "</div>\n",
        "\n",
        "The topic of our deep learning project is Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. In this jupyter notebook we reproduce the cycle GAN network based on the example mnist-svhn-transfer provided in the class and the platform Pytorch and implement the transformation of unpaired images from mnist to SVHN dataset. Then, to further verify the generalizability of the network, we used the new datasets fashion mnist dataset and fashion product small dataset to train the network and obtained good results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug_eCFYzyt1m"
      },
      "source": [
        "**Part1 Data pre-processing and importing**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the description and information of the GPU and CUDA devices we used in the training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgXjDK14zDmC",
        "outputId": "935a27d9-39b5-46c8-e9f0-933ff72d4661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Dec  3 15:26:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section we import the libraries needed to data process and rangement follow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "coYDySmX6aD2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from pathlib import Path\n",
        "from torchvision import datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the class methode to generate our owm Dataset from the input data. The input data shall be the pictures is the type of png or jpg "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yqmyMAjJiyTc"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        \"\"\"\n",
        "        Initialize the path and the parameters for image format and image conversion settings\n",
        "        \"\"\"\n",
        "        #This method is used to convert the input image to a tensor type with size 32*32 and normalized with mean and variance of 0.5 \n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.Resize((32,32)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "            ])\n",
        "        #Set the path of the folder storing the input data\n",
        "        images_path = Path(root)\n",
        "        #Here our data is always in thpe of jpg\n",
        "        images_list = list(images_path.glob('*.jpg')) # list(images_path.glob('*.png'))\n",
        "        images_list_str = [ str(x) for x in images_list ]\n",
        "        self.images = images_list_str\n",
        "        \n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        Read and process input data and return\n",
        "        \"\"\"\n",
        "        image_path = self.images[item]\n",
        "        #Read the every image \n",
        "        image = cv2.imread(image_path) \n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #transform to the RGB\n",
        "        #At this point the image is in the order H,W,C, so the following needs to be transformed into: C, H, W\n",
        "        #Normalize [0, 1] to be consistent with the data read by PIL\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)/255 \n",
        "        #Here we don't use labels when training so we directly set all the labels 1\n",
        "        label = 1 \n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the length of the Dataset\n",
        "        \"\"\"\n",
        "        return len(self.images)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the function to get the dataloader of fashion mnist data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3DF5vgn-iyTi"
      },
      "outputs": [],
      "source": [
        "def get_loader_fashion(image_size, batch_size, num_workers):\n",
        "    \"\"\"Builds and returns Dataloader for Fashion MNIST dataset.\"\"\"\n",
        "    #convert the input image to a tensor type with size 32*32 and normalized with mean and variance of 0.5 \n",
        "    transform = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5), (0.5))])\n",
        "    \n",
        "    #download the dataset of fashion mnist\n",
        "    Fashionmnist = datasets.FashionMNIST(root='./Fashionmnist', download=True, transform=transform)\n",
        "\n",
        "    #build the dataloader of fashion mnist\n",
        "    Fashionmnist_loader = torch.utils.data.DataLoader(dataset=Fashionmnist,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          drop_last=True,                           \n",
        "                          num_workers=num_workers)\n",
        "    return Fashionmnist_loader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the function to return the dataloader for MNIST and SVHN dataset.\n",
        "\n",
        "Here the mnist dataset with 10 classes is the dataset of the hand written numbers and have 60000 data in total conyaining 50000 training samples and 10000 test samples. the images are in type of grey image with size of (28,28,1). While the SVHN dataset, also known as the Street View House Number dataset, is extracted from Google Street View images of house numbers in a similar style to MNIST (the cropped numbers of the images are small), but contains a much larger order of magnitude of tagging data (over 600,000 digital images) and has 10 categories, with numbers 1 to 9 corresponding to tags 1 to 9, and \"0\" for tag 10. \"The format of the dataset is the original image with character-level bounding boxes, and the image size is (32,32,3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ba5dC_ROB3o_"
      },
      "outputs": [],
      "source": [
        "def get_loader(image_size, batch_size, num_workers):\n",
        "    \"\"\"Builds and returns Dataloader for MNIST and SVHN dataset.\"\"\"\n",
        "    ##convert the input image to a tensor type with size 32*32 and normalized with mean and variance of 0.5 for SVHN\n",
        "    transform = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    ##convert the input image to a tensor type with size 32*32 and normalized with mean and variance of 0.5 for mnist\n",
        "    transform1 = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "    #Download the data\n",
        "    svhn = datasets.SVHN(root='./svhn', download=True, transform=transform)\n",
        "    mnist = datasets.MNIST(root='./mnist', download=True, transform=transform1)\n",
        "\n",
        "    #Build the two dataloader then return\n",
        "    svhn_loader = torch.utils.data.DataLoader(dataset=svhn,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=num_workers)\n",
        "\n",
        "    mnist_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=num_workers)\n",
        "    return svhn_loader, mnist_loader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Part2 Build the Cycle-GAN Network**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The stuctures of Cycle-GAN is showed in the following image. The model contains two mapping functions G : X -> Y and F : Y -> X, and associated adversarial\n",
        "discriminators DY and DX. DY encourages G to translate X into outputs indistinguishable from domain Y , and vice versa\n",
        "for DX and F. To further regularize the mappings, we introduce two cycle consistency losses that capture the intuition that if\n",
        "we translate from one domain to the other and back again we should arrive at where we started: (b) forward cycle-consistency\n",
        "loss: x -> G(x) -> F(G(x)) is approximately equal to x, and (c) backward cycle-consistency loss: y -> F(y) -> G(F(y)) is approximately equal to y\n",
        "\n",
        "<div align='center' >\n",
        "<img\n",
        "src=\"https://production-media.paperswithcode.com/methods/Screen_Shot_2020-07-05_at_3.54.24_PM_aoT8JRU.png\"\n",
        "WIDTH=400 HEIGHT=180>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This block is to import the necessary libraries to build the network and train the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ww9Ufmt7dFk-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V_f8bOtHdHUO"
      },
      "outputs": [],
      "source": [
        "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom deconvolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1rKfUCwSdIXX"
      },
      "outputs": [],
      "source": [
        "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom convolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_3SZr9P5eTCf"
      },
      "outputs": [],
      "source": [
        "class G12(nn.Module):\n",
        "    \"\"\"Generator for transfering from mnist to svhn\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G12, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(1, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        \n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        \n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 3, 4, bn=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      \n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    \n",
        "        \n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    \n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    \n",
        "        \n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  \n",
        "        out = F.tanh(self.deconv2(out))            \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VhcaXSsOeXuQ"
      },
      "outputs": [],
      "source": [
        "class G21(nn.Module):\n",
        "    \"\"\"Generator for transfering from svhn to mnist\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G21, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(3, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        \n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        \n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 1, 4, bn=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n",
        "        \n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    # ( \" )\n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    # ( \" )\n",
        "        \n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out))              # (?, 1, 32, 32)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fta1wjhgebQw"
      },
      "outputs": [],
      "source": [
        "class D1(nn.Module):\n",
        "    \"\"\"Discriminator for mnist.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D1, self).__init__()\n",
        "        self.conv1 = conv(1, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-38bCORpDvwa"
      },
      "outputs": [],
      "source": [
        "class D2(nn.Module):\n",
        "    \"\"\"Discriminator for svhn.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D2, self).__init__()\n",
        "        self.conv1 = conv(3, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Define the training process**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the parametres of the training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixUYLO0EiyTm"
      },
      "outputs": [],
      "source": [
        "#Model hyper-parameters using for creating dataloder\n",
        "image_size=32 \n",
        "num_workers=2\n",
        "batch_size=64\n",
        "#Initiate the hyper-parameters for modeling and training\n",
        "use_reconst_loss = True\n",
        "use_labels = False\n",
        "#The number of classes\n",
        "num_classes = 10\n",
        "#The coefficients used for computing running averages of gradient and its square when using adam\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999 \n",
        "#The basic length of the hidden layers \n",
        "g_conv_dim = 64\n",
        "d_conv_dim = 64\n",
        "train_iters = 80000\n",
        "lr = 0.0005\n",
        "#the step to print the log information\n",
        "log_step = 10\n",
        "#the step to store the trained samples\n",
        "sample_step = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ublxhEX3jdGW"
      },
      "outputs": [],
      "source": [
        "def merge_images(batch_size, sources, targets, k=10):\n",
        "    \"\"\"This is the function to merge the source image with the generated fake image\"\"\"\n",
        "    _, _, h, w = sources.shape\n",
        "    row = int(np.sqrt(batch_size))\n",
        "    merged = np.zeros([3, row*h, row*w*2])\n",
        "    for idx, (s, t) in enumerate(zip(sources, targets)):\n",
        "        i = idx // row\n",
        "        j = idx % row\n",
        "        merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
        "        merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
        "    return merged.transpose(1, 2, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9vGtA2dSjwkn"
      },
      "outputs": [],
      "source": [
        "def to_var(x):\n",
        "    \"\"\"Converts numpy to torch.variable.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "         x = x.cuda()\n",
        "    return Variable(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TLy0NH7kkB85"
      },
      "outputs": [],
      "source": [
        "def to_data(x):\n",
        "    \"\"\"Converts variable to numpy.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cpu()\n",
        "    return x.data.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZAe99dDYl6zx"
      },
      "outputs": [],
      "source": [
        "def reset_grad(g_optimizer, d_optimizer):\n",
        "    \"\"\"Zeros the gradient buffers.\"\"\"\n",
        "    g_optimizer.zero_grad()\n",
        "    d_optimizer.zero_grad()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "According to the previous model introduction, here we need to define two losses during the training process, adversarial loss and cycle consistency loss. Normally we define the loss in the formulation of:\n",
        "\n",
        "The cycle consistency loss\n",
        "\n",
        "<div align='center' >\n",
        "<img\n",
        "src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRnj6GTGirDyseejD2grtaGEWUijpBfHyto0Q&usqp=CAU\"\n",
        "WIDTH=600 HEIGHT=100>\n",
        "\n",
        "The adversarial loss\n",
        "\n",
        "<img\n",
        "src=\"https://lh4.googleusercontent.com/WLI1b-odvUJRUXXw0dQZ77zJb2zv9TQUrfxBLfR7z9n5TNDjNB1azEkxRuHFpQMd75YePY7MCCxI2gC_kjRmYfEg_ud4mkhzC3bhXRtI-2IouKj5IRta2LuCd9j01AXRZ0DXClS1-YkHqvbenO1SsCY\"\n",
        "WIDTH=600 HEIGHT=100>\n",
        "\n",
        "Then the total loss\n",
        "\n",
        "<img\n",
        "src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRxvJMV0t1LDm3_atEHBr4-kbatMi9RiiqLMQp1vvteLnCOH7QbVFEMQR7Lixj7FNz81w&usqp=CAU\"\n",
        "WIDTH=600 HEIGHT=100>\n",
        "</div>\n",
        "\n",
        "But here when we implement the process of training for the cycle-GAN network, we apply the technique from recent works to stabilize our model training procedure. For LGAN, we replace the negative log likelihood objective by a least-squares loss. This loss is more stable during training and generates higher quality results. In particular, for a GAN loss LGAN(G;D;X;Y), we train the G to minimize Ex~pdata(x)[(D(G(x)) - 1)^2] and train the D to minimize Ey~pdata(y)[(D(y) - 1)^2] + Ex~pdata(x)[D(G(x))^2].\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Qb_zTNktkaDI"
      },
      "outputs": [],
      "source": [
        "def train(svhn_loader, mnist_loader, train_iters=train_iters, use_labels=use_labels, \n",
        "     use_reconst_loss=use_reconst_loss, num_classes=num_classes, g_conv_dim=g_conv_dim, \n",
        "     d_conv_dim=d_conv_dim, lr=lr, beta1=beta1, beta2=beta2, log_step=log_step, \n",
        "     sample_step=sample_step, sample_path=None, model_path=None):\n",
        "     \"\"\"This is the function for training and we use the adam optimizer and CrossEntropyLoss methode\"\"\"\n",
        "    #============ data process ============#\n",
        "\n",
        "    svhn_iter = iter(svhn_loader)\n",
        "    mnist_iter = iter(mnist_loader)\n",
        "    iter_per_epoch = min(len(svhn_iter), len(mnist_iter))\n",
        "\n",
        "    #fixed mnist and svhn for sampling\n",
        "    fixed_svhn = to_var(svhn_iter.next()[0])\n",
        "    fixed_mnist = to_var(mnist_iter.next()[0])\n",
        "\n",
        "    #============ model creation ============\n",
        "    #Define the models\n",
        "    g12 = G12(conv_dim=g_conv_dim)\n",
        "    g21 = G21(conv_dim=g_conv_dim)\n",
        "    d1 = D1(conv_dim=d_conv_dim, use_labels=True)\n",
        "    d2 = D2(conv_dim=d_conv_dim, use_labels=True)\n",
        "    g_params = list(g12.parameters()) + list(g21.parameters())\n",
        "    d_params = list(d1.parameters()) + list(d2.parameters())\n",
        "    #Define the optimizer of adam\n",
        "    g_optimizer = optim.Adam(g_params, lr, [beta1, beta2])\n",
        "    d_optimizer = optim.Adam(d_params, lr, [beta1, beta2])\n",
        "    if torch.cuda.is_available():\n",
        "            g12.cuda()\n",
        "            g21.cuda()\n",
        "            d1.cuda()\n",
        "            d2.cuda()\n",
        "    #Define the loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    #============ train process ============#\n",
        "    #The lists to store the results of loss\n",
        "    d_real_loss_list = []\n",
        "    d_mnist_loss_list = [] \n",
        "    d_svhn_loss_list = []\n",
        "    d_fake_loss_list =[] \n",
        "    g_loss_list = []\n",
        "    for step in range(train_iters+1):\n",
        "      # reset data_iter for each epoch\n",
        "      \n",
        "      if (step+1) % iter_per_epoch == 0:\n",
        "          mnist_iter = iter(mnist_loader)\n",
        "          svhn_iter = iter(svhn_loader)\n",
        "      \n",
        "      # load svhn and mnist dataset\n",
        "      svhn, s_labels = svhn_iter.next() \n",
        "      svhn, s_labels = to_var(svhn), to_var(s_labels).long().squeeze()\n",
        "      mnist, m_labels = mnist_iter.next() \n",
        "      mnist, m_labels = to_var(mnist), to_var(m_labels)\n",
        "\n",
        "      if use_labels:\n",
        "          mnist_fake_labels = to_var(\n",
        "              torch.Tensor([num_classes]*svhn.size(0)).long())\n",
        "          svhn_fake_labels = to_var(\n",
        "              torch.Tensor([num_classes]*mnist.size(0)).long())\n",
        "      \n",
        "      #============ train D ============#\n",
        "      \n",
        "      # train with real images\n",
        "      reset_grad(g_optimizer, d_optimizer)\n",
        "      out = d1(mnist)\n",
        "      if use_labels:\n",
        "          d1_loss = criterion(out, m_labels)\n",
        "      else:\n",
        "          d1_loss = torch.mean((out-1)**2)\n",
        "      \n",
        "      out = d2(svhn)\n",
        "      if use_labels:\n",
        "          d2_loss = criterion(out, s_labels)\n",
        "      else:\n",
        "          d2_loss = torch.mean((out-1)**2)\n",
        "      \n",
        "      d_mnist_loss = d1_loss\n",
        "      d_svhn_loss = d2_loss\n",
        "      d_real_loss = d1_loss + d2_loss\n",
        "      d_real_loss.backward()\n",
        "      d_optimizer.step()\n",
        "      \n",
        "      # train with fake images\n",
        "      reset_grad(g_optimizer, d_optimizer)\n",
        "      fake_svhn = g12(mnist)\n",
        "      out = d2(fake_svhn)\n",
        "      if use_labels:\n",
        "          d2_loss = criterion(out, svhn_fake_labels)\n",
        "      else:\n",
        "          d2_loss = torch.mean(out**2)\n",
        "      \n",
        "      fake_mnist = g21(svhn)\n",
        "      out = d1(fake_mnist)\n",
        "      if use_labels:\n",
        "          d1_loss = criterion(out, mnist_fake_labels)\n",
        "      else:\n",
        "          d1_loss = torch.mean(out**2)\n",
        "      \n",
        "      d_fake_loss = d1_loss + d2_loss\n",
        "      d_fake_loss.backward()\n",
        "      d_optimizer.step()\n",
        "      \n",
        "      #============ train G ============#\n",
        "      \n",
        "      # train mnist-svhn-mnist cycle\n",
        "      reset_grad(g_optimizer, d_optimizer)\n",
        "      fake_svhn = g12(mnist)\n",
        "      out = d2(fake_svhn)\n",
        "      reconst_mnist = g21(fake_svhn)\n",
        "      if use_labels:\n",
        "          g_loss = criterion(out, m_labels) \n",
        "      else:\n",
        "          g_loss = torch.mean((out-1)**2) \n",
        "\n",
        "      if use_reconst_loss:\n",
        "          g_loss += torch.mean((mnist - reconst_mnist)**2)\n",
        "\n",
        "      g_loss.backward()\n",
        "      g_optimizer.step()\n",
        "\n",
        "      # train svhn-mnist-svhn cycle\n",
        "      reset_grad(g_optimizer, d_optimizer)\n",
        "      fake_mnist = g21(svhn)\n",
        "      out = d1(fake_mnist)\n",
        "      reconst_svhn = g12(fake_mnist)\n",
        "      if use_labels:\n",
        "          g_loss = criterion(out, s_labels) \n",
        "      else:\n",
        "          g_loss = torch.mean((out-1)**2) \n",
        "\n",
        "      if use_reconst_loss:\n",
        "          g_loss += torch.mean((svhn - reconst_svhn)**2)\n",
        "\n",
        "      g_loss.backward()\n",
        "      g_optimizer.step()\n",
        "      \n",
        "      # print the log info\n",
        "      if (step+1) % log_step == 0:\n",
        "          print('Step [%d/%d], d_real_loss: %.4f, d_mnist_loss: %.4f, d_svhn_loss: %.4f, '\n",
        "                'd_fake_loss: %.4f, g_loss: %.4f' \n",
        "                %(step+1, train_iters, d_real_loss.item(), d_mnist_loss.item(), \n",
        "                  d_svhn_loss.item(), d_fake_loss.item(), g_loss.item()))\n",
        "      d_real_loss_list.append(d_real_loss.item())\n",
        "      d_mnist_loss_list.append(d_mnist_loss.item()) \n",
        "      d_svhn_loss_list.append(d_svhn_loss.item())\n",
        "      d_fake_loss_list.append(d_fake_loss.item()) \n",
        "      g_loss_list.append(g_loss.item())\n",
        "\n",
        "      # save the sampled images\n",
        "      if (step+1) % sample_step == 0:\n",
        "          fake_svhn = g12(fixed_mnist)\n",
        "          fake_mnist = g21(fixed_svhn)\n",
        "          \n",
        "          mnist, fake_mnist = to_data(fixed_mnist), to_data(fake_mnist)\n",
        "          svhn , fake_svhn = to_data(fixed_svhn), to_data(fake_svhn)\n",
        "          \n",
        "          merged = merge_images(batch_size, mnist, fake_svhn)\n",
        "          path = os.path.join(sample_path, 'sample-%d-m-s.png' %(step+1))\n",
        "          imageio.imwrite(path, merged)\n",
        "          print ('saved %s' %path)\n",
        "          \n",
        "          merged = merge_images(batch_size, svhn, fake_mnist)\n",
        "          path = os.path.join(sample_path, 'sample-%d-s-m.png' %(step+1))\n",
        "          imageio.imwrite(path, merged)\n",
        "          print ('saved %s' %path)\n",
        "          \n",
        "      \n",
        "      if (step+1) % 5000 == 0:\n",
        "          # save the model parameters for each epoch\n",
        "          g12_path = os.path.join(model_path, 'g12-%d.pkl' %(step+1))\n",
        "          g21_path = os.path.join(model_path, 'g21-%d.pkl' %(step+1))\n",
        "          d1_path = os.path.join(model_path, 'd1-%d.pkl' %(step+1))\n",
        "          d2_path = os.path.join(model_path, 'd2-%d.pkl' %(step+1))\n",
        "          torch.save(g12.state_dict(), g12_path)\n",
        "          torch.save(g21.state_dict(), g21_path)\n",
        "          torch.save(d1.state_dict(), d1_path)\n",
        "          torch.save(d2.state_dict(), d2_path)\n",
        "    return d_real_loss_list, d_mnist_loss_list, d_svhn_loss_list, d_fake_loss_list, g_loss_list"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Part3 The process of training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7zLfvQo4fKZm"
      },
      "outputs": [],
      "source": [
        "#Here are the path roots of our dataset\n",
        "sample_path1 = './samples_mnist_svhn'\n",
        "model_path1 = './models_mnist_svhn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6gKgGIdHp6_Y"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(model_path1):\n",
        "    os.makedirs(model_path1)\n",
        "if not os.path.exists(sample_path1):\n",
        "    os.makedirs(sample_path1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481,
          "referenced_widgets": [
            "ce998c5b1f544057999c9e174e072370",
            "98445261432247aa864f6648fc733347",
            "b6177b05518643d18070ad9c9d68fd7b",
            "0ce286599d59446e9f9c1740a6110438",
            "80776282337c46f2b39bd402c00aa263",
            "b91f267d7ec745dca0ef9e1cbaee758e",
            "76d5f8651f5d4ad98c63f63278c95a1f",
            "3b41aad9d49146a283b344281e029dd2",
            "c70115c6582743a5bbc3b38db8a76635",
            "e1079999e90e4f2893b2ef5a9f92ec0a",
            "d76c3a8ebb9940129dcf0666fd9d6ff6",
            "561ab4b73e9b4574926af119007ec1ea",
            "c0d940c26774469bbb5597af870b6daf",
            "0bbb1a696d0e459d85407e797ec98aa7",
            "2a510f199a19429ba186a423ac239a30",
            "6887d0c8b4a3493f8d3d8c40f93c937e",
            "64009ebb36d4444aa5fa9138f57795f8",
            "c9f5d8edcd7145df98170e4f286216a6",
            "11b9cf716cae496eb6681064630c53f1",
            "cec282bc878a4dd7a47146b35d149aa0",
            "6e7e5767dbcc4d4681efeb993e53ba47",
            "35ba1f69f6eb446f8cdafbc5b72128ce",
            "a2b22237dd6e4726ad1ea71bd3295bb4",
            "3b50d03b930f4a6dbe052b13cc25abe4",
            "701c97f1148b4a28bed01b9bec9e8966",
            "64ffbde9cd2e4be3a98e488feb0efaa9",
            "5928acdae82347faa204c867d77fd548",
            "bcef9c0e4e82437f81e65473741b3edc",
            "0d572a2d14b849958bf9769201883d7c",
            "ad20095203f84e3485d69d721bcd142e",
            "d51f2f07bfcb44ddadf77b1de7ab0fbe",
            "1d0c8a0b43474db8a8cf6021cde89fba",
            "2e7dfc1e331c48c8a886009e91f05983",
            "85fae1f3fe11472da459818c8ff50bd9",
            "8b15e290882b44859365a0ffddb3aad4",
            "85fb547ba22f4424a9a68638c41946d7",
            "4c50c572641945ac8768b3eedb3fd839",
            "5cdf44cd04a34b81bdd0c7bb3349c9ee",
            "f007362cae584e94bac74f91c3879715",
            "2e255a7b46c04e289700625b111af01e",
            "dedb58dd62df4493841ad00a51d7b347",
            "1718ae104c0f424192e82c8610317c9c",
            "197ab77e841b4fbe8078b4b4fb1da1ab",
            "96c9a0500aa0471396e5b55bbf6c0dc3",
            "2b457e1e39164137a20fc1b5dc9364c4",
            "3dddbbdbd1b44508b844e14a07c543e3",
            "34e17eb71c184391a6715d07bdfd7046",
            "3b0091c989024cf6a05ee7fd5a44f3c7",
            "d2503080e5cf4189b24bf66aac683246",
            "070056be423c4e92a42d991386ca2b75",
            "81d37efa74104fe1ba1bdeb48ef75bc1",
            "b8b789f24ad54956a0e638f3a15a5314",
            "9be12fa3615846f08cc5823f08462996",
            "84fe62b6b9bc4a1b838277e0c8991e60",
            "3ce57a293edc4fb98358c3d332d79a42"
          ]
        },
        "id": "vmT-IJXNbSF3",
        "outputId": "323eb5ce-5549-4223-b8ec-30c0b0cbbdfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./svhn/train_32x32.mat\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce998c5b1f544057999c9e174e072370",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/182040794 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "561ab4b73e9b4574926af119007ec1ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2b22237dd6e4726ad1ea71bd3295bb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85fae1f3fe11472da459818c8ff50bd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b457e1e39164137a20fc1b5dc9364c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Generate the data loader of svhn and mnist\n",
        "svhn_loader, mnist_loader = get_loader(image_size, batch_size, num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae6DCbZRiyT5",
        "outputId": "984c7aef-88d5-4f6d-d594-f8db327aabce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [10/80000], d_real_loss: 0.6107, d_mnist_loss: 0.4325, d_svhn_loss: 0.1782, d_fake_loss: 1.3833, g_loss: 1.5433\n",
            "Step [20/80000], d_real_loss: 0.9078, d_mnist_loss: 0.5265, d_svhn_loss: 0.3813, d_fake_loss: 0.9132, g_loss: 1.1800\n",
            "Step [30/80000], d_real_loss: 0.3207, d_mnist_loss: 0.1422, d_svhn_loss: 0.1785, d_fake_loss: 0.8721, g_loss: 1.9088\n",
            "Step [40/80000], d_real_loss: 0.7834, d_mnist_loss: 0.4670, d_svhn_loss: 0.3164, d_fake_loss: 0.8393, g_loss: 1.3487\n",
            "Step [50/80000], d_real_loss: 0.8655, d_mnist_loss: 0.5275, d_svhn_loss: 0.3380, d_fake_loss: 0.6063, g_loss: 1.1088\n",
            "Step [60/80000], d_real_loss: 0.4722, d_mnist_loss: 0.2773, d_svhn_loss: 0.1949, d_fake_loss: 0.6258, g_loss: 2.1489\n",
            "Step [70/80000], d_real_loss: 0.3345, d_mnist_loss: 0.1906, d_svhn_loss: 0.1439, d_fake_loss: 0.3623, g_loss: 1.6545\n",
            "Step [80/80000], d_real_loss: 0.4057, d_mnist_loss: 0.2887, d_svhn_loss: 0.1170, d_fake_loss: 0.5072, g_loss: 1.6388\n",
            "Step [90/80000], d_real_loss: 0.3694, d_mnist_loss: 0.0719, d_svhn_loss: 0.2975, d_fake_loss: 0.3182, g_loss: 1.7665\n",
            "Step [100/80000], d_real_loss: 0.4041, d_mnist_loss: 0.1520, d_svhn_loss: 0.2521, d_fake_loss: 0.4121, g_loss: 2.2604\n",
            "Step [110/80000], d_real_loss: 0.6695, d_mnist_loss: 0.2689, d_svhn_loss: 0.4007, d_fake_loss: 0.6239, g_loss: 1.5158\n",
            "Step [120/80000], d_real_loss: 1.1697, d_mnist_loss: 0.1990, d_svhn_loss: 0.9707, d_fake_loss: 0.3928, g_loss: 2.6324\n",
            "Step [130/80000], d_real_loss: 1.3615, d_mnist_loss: 0.1967, d_svhn_loss: 1.1648, d_fake_loss: 0.2238, g_loss: 1.5029\n",
            "Step [140/80000], d_real_loss: 0.4690, d_mnist_loss: 0.3200, d_svhn_loss: 0.1489, d_fake_loss: 0.3436, g_loss: 1.6076\n",
            "Step [150/80000], d_real_loss: 0.4414, d_mnist_loss: 0.2204, d_svhn_loss: 0.2210, d_fake_loss: 0.1579, g_loss: 1.2145\n",
            "Step [160/80000], d_real_loss: 0.6600, d_mnist_loss: 0.1387, d_svhn_loss: 0.5213, d_fake_loss: 0.4178, g_loss: 1.8687\n",
            "Step [170/80000], d_real_loss: 0.4445, d_mnist_loss: 0.1106, d_svhn_loss: 0.3339, d_fake_loss: 0.5080, g_loss: 2.2481\n",
            "Step [180/80000], d_real_loss: 0.3068, d_mnist_loss: 0.2157, d_svhn_loss: 0.0910, d_fake_loss: 0.5205, g_loss: 2.1846\n",
            "Step [190/80000], d_real_loss: 0.4703, d_mnist_loss: 0.2665, d_svhn_loss: 0.2038, d_fake_loss: 0.3812, g_loss: 1.2651\n",
            "Step [200/80000], d_real_loss: 0.4108, d_mnist_loss: 0.3040, d_svhn_loss: 0.1068, d_fake_loss: 0.3039, g_loss: 1.2808\n",
            "Step [210/80000], d_real_loss: 0.5412, d_mnist_loss: 0.2147, d_svhn_loss: 0.3265, d_fake_loss: 0.5399, g_loss: 1.5627\n",
            "Step [220/80000], d_real_loss: 0.2218, d_mnist_loss: 0.0892, d_svhn_loss: 0.1326, d_fake_loss: 0.4415, g_loss: 1.7915\n",
            "Step [230/80000], d_real_loss: 0.2498, d_mnist_loss: 0.1363, d_svhn_loss: 0.1135, d_fake_loss: 0.3173, g_loss: 1.6661\n",
            "Step [240/80000], d_real_loss: 0.5301, d_mnist_loss: 0.0771, d_svhn_loss: 0.4530, d_fake_loss: 0.1823, g_loss: 1.6625\n",
            "Step [250/80000], d_real_loss: 0.2126, d_mnist_loss: 0.1171, d_svhn_loss: 0.0955, d_fake_loss: 0.1795, g_loss: 1.3088\n",
            "Step [260/80000], d_real_loss: 0.4114, d_mnist_loss: 0.3324, d_svhn_loss: 0.0790, d_fake_loss: 0.5665, g_loss: 1.6460\n",
            "Step [270/80000], d_real_loss: 0.5653, d_mnist_loss: 0.0804, d_svhn_loss: 0.4848, d_fake_loss: 0.2460, g_loss: 1.9017\n",
            "Step [280/80000], d_real_loss: 0.2444, d_mnist_loss: 0.1001, d_svhn_loss: 0.1443, d_fake_loss: 0.3520, g_loss: 1.3609\n",
            "Step [290/80000], d_real_loss: 0.5565, d_mnist_loss: 0.1769, d_svhn_loss: 0.3796, d_fake_loss: 0.5268, g_loss: 1.8291\n",
            "Step [300/80000], d_real_loss: 0.5427, d_mnist_loss: 0.0854, d_svhn_loss: 0.4574, d_fake_loss: 0.1484, g_loss: 1.1050\n",
            "Step [310/80000], d_real_loss: 0.7843, d_mnist_loss: 0.7448, d_svhn_loss: 0.0395, d_fake_loss: 0.8505, g_loss: 2.0317\n",
            "Step [320/80000], d_real_loss: 0.2636, d_mnist_loss: 0.2145, d_svhn_loss: 0.0491, d_fake_loss: 0.2491, g_loss: 1.2884\n",
            "Step [330/80000], d_real_loss: 0.1150, d_mnist_loss: 0.0706, d_svhn_loss: 0.0444, d_fake_loss: 0.1717, g_loss: 1.6020\n",
            "Step [340/80000], d_real_loss: 0.2808, d_mnist_loss: 0.0968, d_svhn_loss: 0.1839, d_fake_loss: 0.1137, g_loss: 1.2488\n",
            "Step [350/80000], d_real_loss: 0.1540, d_mnist_loss: 0.0892, d_svhn_loss: 0.0648, d_fake_loss: 0.1628, g_loss: 1.5728\n",
            "Step [360/80000], d_real_loss: 0.4075, d_mnist_loss: 0.2016, d_svhn_loss: 0.2059, d_fake_loss: 0.5157, g_loss: 2.1602\n",
            "Step [370/80000], d_real_loss: 0.3013, d_mnist_loss: 0.0863, d_svhn_loss: 0.2150, d_fake_loss: 0.3057, g_loss: 1.8604\n",
            "Step [380/80000], d_real_loss: 0.2020, d_mnist_loss: 0.0466, d_svhn_loss: 0.1554, d_fake_loss: 0.6645, g_loss: 1.2812\n",
            "Step [390/80000], d_real_loss: 0.1958, d_mnist_loss: 0.0481, d_svhn_loss: 0.1477, d_fake_loss: 0.1190, g_loss: 1.4702\n",
            "Step [400/80000], d_real_loss: 0.1154, d_mnist_loss: 0.0456, d_svhn_loss: 0.0698, d_fake_loss: 0.1486, g_loss: 1.7817\n",
            "Step [410/80000], d_real_loss: 0.1168, d_mnist_loss: 0.0372, d_svhn_loss: 0.0796, d_fake_loss: 0.2221, g_loss: 1.3679\n",
            "Step [420/80000], d_real_loss: 0.2773, d_mnist_loss: 0.2010, d_svhn_loss: 0.0763, d_fake_loss: 0.2448, g_loss: 1.2813\n",
            "Step [430/80000], d_real_loss: 0.4870, d_mnist_loss: 0.0974, d_svhn_loss: 0.3897, d_fake_loss: 0.1153, g_loss: 1.1072\n",
            "Step [440/80000], d_real_loss: 0.3378, d_mnist_loss: 0.0742, d_svhn_loss: 0.2636, d_fake_loss: 0.5167, g_loss: 1.5630\n",
            "Step [450/80000], d_real_loss: 0.2803, d_mnist_loss: 0.0263, d_svhn_loss: 0.2540, d_fake_loss: 0.1292, g_loss: 1.6341\n",
            "Step [460/80000], d_real_loss: 0.1196, d_mnist_loss: 0.0485, d_svhn_loss: 0.0711, d_fake_loss: 0.1587, g_loss: 0.7532\n",
            "Step [470/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0468, d_svhn_loss: 0.0481, d_fake_loss: 0.1844, g_loss: 1.1395\n",
            "Step [480/80000], d_real_loss: 0.1462, d_mnist_loss: 0.0402, d_svhn_loss: 0.1059, d_fake_loss: 0.4185, g_loss: 1.2243\n",
            "Step [490/80000], d_real_loss: 0.3481, d_mnist_loss: 0.2952, d_svhn_loss: 0.0528, d_fake_loss: 0.3088, g_loss: 1.5266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/80000], d_real_loss: 0.0827, d_mnist_loss: 0.0472, d_svhn_loss: 0.0355, d_fake_loss: 0.1632, g_loss: 1.8412\n",
            "saved ./samples_mnist_svhn/sample-500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-500-s-m.png\n",
            "Step [510/80000], d_real_loss: 0.1368, d_mnist_loss: 0.0604, d_svhn_loss: 0.0764, d_fake_loss: 0.2231, g_loss: 1.3570\n",
            "Step [520/80000], d_real_loss: 0.3834, d_mnist_loss: 0.1081, d_svhn_loss: 0.2752, d_fake_loss: 0.1018, g_loss: 1.3921\n",
            "Step [530/80000], d_real_loss: 0.2031, d_mnist_loss: 0.0548, d_svhn_loss: 0.1483, d_fake_loss: 0.2280, g_loss: 1.5923\n",
            "Step [540/80000], d_real_loss: 0.2098, d_mnist_loss: 0.0443, d_svhn_loss: 0.1655, d_fake_loss: 0.1076, g_loss: 1.1144\n",
            "Step [550/80000], d_real_loss: 0.1309, d_mnist_loss: 0.0494, d_svhn_loss: 0.0815, d_fake_loss: 0.1346, g_loss: 1.4497\n",
            "Step [560/80000], d_real_loss: 0.6485, d_mnist_loss: 0.0691, d_svhn_loss: 0.5794, d_fake_loss: 0.1751, g_loss: 1.2780\n",
            "Step [570/80000], d_real_loss: 0.2286, d_mnist_loss: 0.0424, d_svhn_loss: 0.1863, d_fake_loss: 0.1033, g_loss: 1.1539\n",
            "Step [580/80000], d_real_loss: 0.2748, d_mnist_loss: 0.0951, d_svhn_loss: 0.1796, d_fake_loss: 0.2451, g_loss: 2.1574\n",
            "Step [590/80000], d_real_loss: 0.2883, d_mnist_loss: 0.0490, d_svhn_loss: 0.2393, d_fake_loss: 0.4480, g_loss: 1.3938\n",
            "Step [600/80000], d_real_loss: 0.1436, d_mnist_loss: 0.0348, d_svhn_loss: 0.1088, d_fake_loss: 0.2855, g_loss: 1.3698\n",
            "Step [610/80000], d_real_loss: 0.7722, d_mnist_loss: 0.0721, d_svhn_loss: 0.7001, d_fake_loss: 0.0994, g_loss: 1.5883\n",
            "Step [620/80000], d_real_loss: 0.2572, d_mnist_loss: 0.0254, d_svhn_loss: 0.2318, d_fake_loss: 0.2023, g_loss: 2.1137\n",
            "Step [630/80000], d_real_loss: 0.3767, d_mnist_loss: 0.0733, d_svhn_loss: 0.3034, d_fake_loss: 0.1612, g_loss: 1.4545\n",
            "Step [640/80000], d_real_loss: 0.1401, d_mnist_loss: 0.0495, d_svhn_loss: 0.0906, d_fake_loss: 0.2977, g_loss: 1.2650\n",
            "Step [650/80000], d_real_loss: 0.1144, d_mnist_loss: 0.0315, d_svhn_loss: 0.0829, d_fake_loss: 0.1022, g_loss: 1.1514\n",
            "Step [660/80000], d_real_loss: 0.3333, d_mnist_loss: 0.2216, d_svhn_loss: 0.1118, d_fake_loss: 0.3842, g_loss: 1.9661\n",
            "Step [670/80000], d_real_loss: 0.2813, d_mnist_loss: 0.2061, d_svhn_loss: 0.0752, d_fake_loss: 0.1118, g_loss: 1.1566\n",
            "Step [680/80000], d_real_loss: 0.1486, d_mnist_loss: 0.0317, d_svhn_loss: 0.1169, d_fake_loss: 0.1312, g_loss: 1.3150\n",
            "Step [690/80000], d_real_loss: 0.5199, d_mnist_loss: 0.0433, d_svhn_loss: 0.4766, d_fake_loss: 0.3800, g_loss: 1.9398\n",
            "Step [700/80000], d_real_loss: 0.1962, d_mnist_loss: 0.1363, d_svhn_loss: 0.0599, d_fake_loss: 0.1350, g_loss: 1.6020\n",
            "Step [710/80000], d_real_loss: 0.2407, d_mnist_loss: 0.0416, d_svhn_loss: 0.1990, d_fake_loss: 0.2740, g_loss: 1.3613\n",
            "Step [720/80000], d_real_loss: 0.1366, d_mnist_loss: 0.0341, d_svhn_loss: 0.1025, d_fake_loss: 0.8753, g_loss: 2.3575\n",
            "Step [730/80000], d_real_loss: 0.3305, d_mnist_loss: 0.0386, d_svhn_loss: 0.2919, d_fake_loss: 0.2514, g_loss: 0.4090\n",
            "Step [740/80000], d_real_loss: 0.1829, d_mnist_loss: 0.0659, d_svhn_loss: 0.1170, d_fake_loss: 0.0850, g_loss: 1.0070\n",
            "Step [750/80000], d_real_loss: 0.5688, d_mnist_loss: 0.4044, d_svhn_loss: 0.1644, d_fake_loss: 0.4339, g_loss: 1.4597\n",
            "Step [760/80000], d_real_loss: 0.1405, d_mnist_loss: 0.0451, d_svhn_loss: 0.0953, d_fake_loss: 0.2292, g_loss: 1.0613\n",
            "Step [770/80000], d_real_loss: 0.1635, d_mnist_loss: 0.1136, d_svhn_loss: 0.0499, d_fake_loss: 0.1987, g_loss: 1.1476\n",
            "Step [780/80000], d_real_loss: 0.1185, d_mnist_loss: 0.0482, d_svhn_loss: 0.0702, d_fake_loss: 0.1739, g_loss: 0.9385\n",
            "Step [790/80000], d_real_loss: 0.2846, d_mnist_loss: 0.0292, d_svhn_loss: 0.2555, d_fake_loss: 0.1122, g_loss: 1.4709\n",
            "Step [800/80000], d_real_loss: 0.0964, d_mnist_loss: 0.0314, d_svhn_loss: 0.0650, d_fake_loss: 0.2297, g_loss: 0.6236\n",
            "Step [810/80000], d_real_loss: 0.1921, d_mnist_loss: 0.0563, d_svhn_loss: 0.1357, d_fake_loss: 0.1873, g_loss: 0.9233\n",
            "Step [820/80000], d_real_loss: 0.1367, d_mnist_loss: 0.0229, d_svhn_loss: 0.1139, d_fake_loss: 0.5259, g_loss: 1.5442\n",
            "Step [830/80000], d_real_loss: 0.6444, d_mnist_loss: 0.2349, d_svhn_loss: 0.4095, d_fake_loss: 0.5794, g_loss: 0.9213\n",
            "Step [840/80000], d_real_loss: 0.4073, d_mnist_loss: 0.1185, d_svhn_loss: 0.2888, d_fake_loss: 0.4897, g_loss: 0.7987\n",
            "Step [850/80000], d_real_loss: 0.1142, d_mnist_loss: 0.0546, d_svhn_loss: 0.0597, d_fake_loss: 0.0747, g_loss: 0.9547\n",
            "Step [860/80000], d_real_loss: 0.2994, d_mnist_loss: 0.1339, d_svhn_loss: 0.1655, d_fake_loss: 0.2227, g_loss: 1.3010\n",
            "Step [870/80000], d_real_loss: 0.1401, d_mnist_loss: 0.0304, d_svhn_loss: 0.1096, d_fake_loss: 0.2052, g_loss: 0.9028\n",
            "Step [880/80000], d_real_loss: 0.2051, d_mnist_loss: 0.0341, d_svhn_loss: 0.1710, d_fake_loss: 0.2565, g_loss: 1.6270\n",
            "Step [890/80000], d_real_loss: 0.2682, d_mnist_loss: 0.0407, d_svhn_loss: 0.2276, d_fake_loss: 0.2171, g_loss: 1.2047\n",
            "Step [900/80000], d_real_loss: 0.5909, d_mnist_loss: 0.1695, d_svhn_loss: 0.4214, d_fake_loss: 0.5130, g_loss: 1.5407\n",
            "Step [910/80000], d_real_loss: 0.1298, d_mnist_loss: 0.0766, d_svhn_loss: 0.0532, d_fake_loss: 0.0890, g_loss: 0.9091\n",
            "Step [920/80000], d_real_loss: 0.6800, d_mnist_loss: 0.0976, d_svhn_loss: 0.5823, d_fake_loss: 0.1212, g_loss: 1.1320\n",
            "Step [930/80000], d_real_loss: 0.1360, d_mnist_loss: 0.0285, d_svhn_loss: 0.1075, d_fake_loss: 0.1442, g_loss: 1.8926\n",
            "Step [940/80000], d_real_loss: 0.3105, d_mnist_loss: 0.0615, d_svhn_loss: 0.2490, d_fake_loss: 0.1572, g_loss: 1.6214\n",
            "Step [950/80000], d_real_loss: 0.1582, d_mnist_loss: 0.0413, d_svhn_loss: 0.1169, d_fake_loss: 0.1088, g_loss: 1.4217\n",
            "Step [960/80000], d_real_loss: 0.1548, d_mnist_loss: 0.0293, d_svhn_loss: 0.1255, d_fake_loss: 0.3923, g_loss: 1.3335\n",
            "Step [970/80000], d_real_loss: 0.2025, d_mnist_loss: 0.0271, d_svhn_loss: 0.1754, d_fake_loss: 0.1562, g_loss: 0.9654\n",
            "Step [980/80000], d_real_loss: 0.4120, d_mnist_loss: 0.2020, d_svhn_loss: 0.2099, d_fake_loss: 0.1747, g_loss: 1.5619\n",
            "Step [990/80000], d_real_loss: 0.3344, d_mnist_loss: 0.1129, d_svhn_loss: 0.2216, d_fake_loss: 0.2815, g_loss: 1.7600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [1000/80000], d_real_loss: 0.2225, d_mnist_loss: 0.1425, d_svhn_loss: 0.0800, d_fake_loss: 0.6741, g_loss: 1.3643\n",
            "saved ./samples_mnist_svhn/sample-1000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-1000-s-m.png\n",
            "Step [1010/80000], d_real_loss: 0.1018, d_mnist_loss: 0.0440, d_svhn_loss: 0.0577, d_fake_loss: 0.2870, g_loss: 1.1657\n",
            "Step [1020/80000], d_real_loss: 0.1534, d_mnist_loss: 0.0906, d_svhn_loss: 0.0628, d_fake_loss: 0.4561, g_loss: 1.3866\n",
            "Step [1030/80000], d_real_loss: 0.0982, d_mnist_loss: 0.0324, d_svhn_loss: 0.0659, d_fake_loss: 0.1347, g_loss: 1.7476\n",
            "Step [1040/80000], d_real_loss: 0.4029, d_mnist_loss: 0.0888, d_svhn_loss: 0.3141, d_fake_loss: 0.0963, g_loss: 1.7550\n",
            "Step [1050/80000], d_real_loss: 0.1219, d_mnist_loss: 0.0438, d_svhn_loss: 0.0780, d_fake_loss: 0.1632, g_loss: 1.8376\n",
            "Step [1060/80000], d_real_loss: 0.2816, d_mnist_loss: 0.0707, d_svhn_loss: 0.2109, d_fake_loss: 0.2825, g_loss: 1.2477\n",
            "Step [1070/80000], d_real_loss: 0.1290, d_mnist_loss: 0.0978, d_svhn_loss: 0.0312, d_fake_loss: 0.5925, g_loss: 1.6181\n",
            "Step [1080/80000], d_real_loss: 0.1958, d_mnist_loss: 0.1263, d_svhn_loss: 0.0695, d_fake_loss: 0.2537, g_loss: 1.7985\n",
            "Step [1090/80000], d_real_loss: 0.3927, d_mnist_loss: 0.1592, d_svhn_loss: 0.2335, d_fake_loss: 0.1914, g_loss: 1.3819\n",
            "Step [1100/80000], d_real_loss: 0.4730, d_mnist_loss: 0.0434, d_svhn_loss: 0.4296, d_fake_loss: 0.3005, g_loss: 0.8839\n",
            "Step [1110/80000], d_real_loss: 0.4482, d_mnist_loss: 0.2979, d_svhn_loss: 0.1503, d_fake_loss: 0.4731, g_loss: 1.0184\n",
            "Step [1120/80000], d_real_loss: 0.3025, d_mnist_loss: 0.1844, d_svhn_loss: 0.1181, d_fake_loss: 0.4201, g_loss: 1.6209\n",
            "Step [1130/80000], d_real_loss: 0.1090, d_mnist_loss: 0.0456, d_svhn_loss: 0.0635, d_fake_loss: 0.3045, g_loss: 1.8044\n",
            "Step [1140/80000], d_real_loss: 0.2081, d_mnist_loss: 0.0240, d_svhn_loss: 0.1841, d_fake_loss: 0.1079, g_loss: 1.3869\n",
            "Step [1150/80000], d_real_loss: 0.2221, d_mnist_loss: 0.0320, d_svhn_loss: 0.1901, d_fake_loss: 0.5628, g_loss: 0.9200\n",
            "Step [1160/80000], d_real_loss: 0.2988, d_mnist_loss: 0.0254, d_svhn_loss: 0.2734, d_fake_loss: 0.2320, g_loss: 1.3912\n",
            "Step [1170/80000], d_real_loss: 0.1771, d_mnist_loss: 0.0397, d_svhn_loss: 0.1374, d_fake_loss: 0.4099, g_loss: 1.4097\n",
            "Step [1180/80000], d_real_loss: 0.1851, d_mnist_loss: 0.0844, d_svhn_loss: 0.1006, d_fake_loss: 0.6010, g_loss: 2.0529\n",
            "Step [1190/80000], d_real_loss: 0.3058, d_mnist_loss: 0.0846, d_svhn_loss: 0.2212, d_fake_loss: 0.4513, g_loss: 0.6984\n",
            "Step [1200/80000], d_real_loss: 0.2552, d_mnist_loss: 0.0717, d_svhn_loss: 0.1835, d_fake_loss: 0.2166, g_loss: 0.9253\n",
            "Step [1210/80000], d_real_loss: 0.7751, d_mnist_loss: 0.0604, d_svhn_loss: 0.7147, d_fake_loss: 0.1243, g_loss: 1.0902\n",
            "Step [1220/80000], d_real_loss: 0.4263, d_mnist_loss: 0.0333, d_svhn_loss: 0.3930, d_fake_loss: 0.0980, g_loss: 0.8692\n",
            "Step [1230/80000], d_real_loss: 0.1227, d_mnist_loss: 0.0482, d_svhn_loss: 0.0745, d_fake_loss: 0.3168, g_loss: 1.0763\n",
            "Step [1240/80000], d_real_loss: 0.1823, d_mnist_loss: 0.0587, d_svhn_loss: 0.1237, d_fake_loss: 0.3336, g_loss: 0.8618\n",
            "Step [1250/80000], d_real_loss: 0.8348, d_mnist_loss: 0.7508, d_svhn_loss: 0.0840, d_fake_loss: 0.6148, g_loss: 1.5671\n",
            "Step [1260/80000], d_real_loss: 0.2829, d_mnist_loss: 0.0638, d_svhn_loss: 0.2191, d_fake_loss: 0.1812, g_loss: 1.4434\n",
            "Step [1270/80000], d_real_loss: 0.2488, d_mnist_loss: 0.0937, d_svhn_loss: 0.1551, d_fake_loss: 0.2662, g_loss: 0.8666\n",
            "Step [1280/80000], d_real_loss: 0.2177, d_mnist_loss: 0.0259, d_svhn_loss: 0.1918, d_fake_loss: 0.0903, g_loss: 1.3679\n",
            "Step [1290/80000], d_real_loss: 0.1194, d_mnist_loss: 0.0382, d_svhn_loss: 0.0812, d_fake_loss: 0.1741, g_loss: 1.4304\n",
            "Step [1300/80000], d_real_loss: 0.1708, d_mnist_loss: 0.0441, d_svhn_loss: 0.1267, d_fake_loss: 0.2166, g_loss: 1.6370\n",
            "Step [1310/80000], d_real_loss: 0.4192, d_mnist_loss: 0.2828, d_svhn_loss: 0.1364, d_fake_loss: 0.4400, g_loss: 1.8724\n",
            "Step [1320/80000], d_real_loss: 0.1310, d_mnist_loss: 0.0567, d_svhn_loss: 0.0743, d_fake_loss: 0.7501, g_loss: 1.8242\n",
            "Step [1330/80000], d_real_loss: 0.4315, d_mnist_loss: 0.0409, d_svhn_loss: 0.3907, d_fake_loss: 0.5251, g_loss: 2.0838\n",
            "Step [1340/80000], d_real_loss: 0.1131, d_mnist_loss: 0.0261, d_svhn_loss: 0.0870, d_fake_loss: 0.0671, g_loss: 1.3377\n",
            "Step [1350/80000], d_real_loss: 0.1950, d_mnist_loss: 0.0937, d_svhn_loss: 0.1013, d_fake_loss: 0.3989, g_loss: 1.6376\n",
            "Step [1360/80000], d_real_loss: 0.0887, d_mnist_loss: 0.0347, d_svhn_loss: 0.0539, d_fake_loss: 0.1111, g_loss: 0.9689\n",
            "Step [1370/80000], d_real_loss: 0.1430, d_mnist_loss: 0.0907, d_svhn_loss: 0.0522, d_fake_loss: 0.0665, g_loss: 1.0165\n",
            "Step [1380/80000], d_real_loss: 0.2851, d_mnist_loss: 0.0604, d_svhn_loss: 0.2246, d_fake_loss: 0.0966, g_loss: 1.4502\n",
            "Step [1390/80000], d_real_loss: 0.1813, d_mnist_loss: 0.0228, d_svhn_loss: 0.1585, d_fake_loss: 0.1152, g_loss: 1.4396\n",
            "Step [1400/80000], d_real_loss: 0.7803, d_mnist_loss: 0.2324, d_svhn_loss: 0.5479, d_fake_loss: 0.2497, g_loss: 1.4937\n",
            "Step [1410/80000], d_real_loss: 0.3753, d_mnist_loss: 0.2231, d_svhn_loss: 0.1522, d_fake_loss: 0.2235, g_loss: 0.4776\n",
            "Step [1420/80000], d_real_loss: 0.2911, d_mnist_loss: 0.0210, d_svhn_loss: 0.2701, d_fake_loss: 0.1654, g_loss: 1.6506\n",
            "Step [1430/80000], d_real_loss: 0.3995, d_mnist_loss: 0.1065, d_svhn_loss: 0.2930, d_fake_loss: 0.1663, g_loss: 0.8672\n",
            "Step [1440/80000], d_real_loss: 0.1941, d_mnist_loss: 0.0441, d_svhn_loss: 0.1500, d_fake_loss: 0.1054, g_loss: 1.0729\n",
            "Step [1450/80000], d_real_loss: 0.2255, d_mnist_loss: 0.0815, d_svhn_loss: 0.1441, d_fake_loss: 0.1933, g_loss: 1.2136\n",
            "Step [1460/80000], d_real_loss: 0.0994, d_mnist_loss: 0.0305, d_svhn_loss: 0.0689, d_fake_loss: 0.2149, g_loss: 1.6580\n",
            "Step [1470/80000], d_real_loss: 0.2131, d_mnist_loss: 0.1010, d_svhn_loss: 0.1121, d_fake_loss: 0.1466, g_loss: 0.6518\n",
            "Step [1480/80000], d_real_loss: 0.2015, d_mnist_loss: 0.0431, d_svhn_loss: 0.1584, d_fake_loss: 0.0916, g_loss: 1.4345\n",
            "Step [1490/80000], d_real_loss: 0.3561, d_mnist_loss: 0.1445, d_svhn_loss: 0.2116, d_fake_loss: 0.1561, g_loss: 1.4526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [1500/80000], d_real_loss: 0.2598, d_mnist_loss: 0.0401, d_svhn_loss: 0.2197, d_fake_loss: 0.1411, g_loss: 1.2404\n",
            "saved ./samples_mnist_svhn/sample-1500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-1500-s-m.png\n",
            "Step [1510/80000], d_real_loss: 0.1434, d_mnist_loss: 0.0418, d_svhn_loss: 0.1015, d_fake_loss: 0.1157, g_loss: 1.8158\n",
            "Step [1520/80000], d_real_loss: 0.1147, d_mnist_loss: 0.0253, d_svhn_loss: 0.0894, d_fake_loss: 0.1495, g_loss: 1.6272\n",
            "Step [1530/80000], d_real_loss: 0.3295, d_mnist_loss: 0.2211, d_svhn_loss: 0.1084, d_fake_loss: 0.1151, g_loss: 1.0849\n",
            "Step [1540/80000], d_real_loss: 0.1286, d_mnist_loss: 0.0531, d_svhn_loss: 0.0755, d_fake_loss: 0.1008, g_loss: 1.3721\n",
            "Step [1550/80000], d_real_loss: 0.2072, d_mnist_loss: 0.0891, d_svhn_loss: 0.1181, d_fake_loss: 0.1577, g_loss: 1.6285\n",
            "Step [1560/80000], d_real_loss: 0.0937, d_mnist_loss: 0.0223, d_svhn_loss: 0.0714, d_fake_loss: 0.2252, g_loss: 1.0762\n",
            "Step [1570/80000], d_real_loss: 0.3527, d_mnist_loss: 0.0147, d_svhn_loss: 0.3379, d_fake_loss: 0.3590, g_loss: 1.1929\n",
            "Step [1580/80000], d_real_loss: 0.2337, d_mnist_loss: 0.0613, d_svhn_loss: 0.1724, d_fake_loss: 0.1220, g_loss: 1.2542\n",
            "Step [1590/80000], d_real_loss: 0.1052, d_mnist_loss: 0.0393, d_svhn_loss: 0.0659, d_fake_loss: 0.0829, g_loss: 1.1309\n",
            "Step [1600/80000], d_real_loss: 0.3378, d_mnist_loss: 0.1679, d_svhn_loss: 0.1699, d_fake_loss: 0.3005, g_loss: 1.3676\n",
            "Step [1610/80000], d_real_loss: 0.2018, d_mnist_loss: 0.0296, d_svhn_loss: 0.1722, d_fake_loss: 0.2008, g_loss: 1.5220\n",
            "Step [1620/80000], d_real_loss: 0.1616, d_mnist_loss: 0.0459, d_svhn_loss: 0.1157, d_fake_loss: 0.1597, g_loss: 1.7734\n",
            "Step [1630/80000], d_real_loss: 0.0839, d_mnist_loss: 0.0204, d_svhn_loss: 0.0635, d_fake_loss: 0.1342, g_loss: 1.6290\n",
            "Step [1640/80000], d_real_loss: 0.2790, d_mnist_loss: 0.0192, d_svhn_loss: 0.2599, d_fake_loss: 0.1940, g_loss: 1.2799\n",
            "Step [1650/80000], d_real_loss: 0.3516, d_mnist_loss: 0.1043, d_svhn_loss: 0.2473, d_fake_loss: 0.2483, g_loss: 1.5096\n",
            "Step [1660/80000], d_real_loss: 0.1615, d_mnist_loss: 0.0745, d_svhn_loss: 0.0870, d_fake_loss: 0.0844, g_loss: 1.0614\n",
            "Step [1670/80000], d_real_loss: 0.1804, d_mnist_loss: 0.1050, d_svhn_loss: 0.0754, d_fake_loss: 0.1868, g_loss: 1.3851\n",
            "Step [1680/80000], d_real_loss: 0.2452, d_mnist_loss: 0.0456, d_svhn_loss: 0.1996, d_fake_loss: 0.1292, g_loss: 1.4658\n",
            "Step [1690/80000], d_real_loss: 0.1423, d_mnist_loss: 0.0673, d_svhn_loss: 0.0750, d_fake_loss: 0.3735, g_loss: 1.9321\n",
            "Step [1700/80000], d_real_loss: 0.2187, d_mnist_loss: 0.1046, d_svhn_loss: 0.1141, d_fake_loss: 0.1126, g_loss: 1.3628\n",
            "Step [1710/80000], d_real_loss: 0.1683, d_mnist_loss: 0.0862, d_svhn_loss: 0.0821, d_fake_loss: 0.2947, g_loss: 0.9898\n",
            "Step [1720/80000], d_real_loss: 0.8170, d_mnist_loss: 0.2716, d_svhn_loss: 0.5454, d_fake_loss: 0.6197, g_loss: 1.4113\n",
            "Step [1730/80000], d_real_loss: 0.2050, d_mnist_loss: 0.0365, d_svhn_loss: 0.1685, d_fake_loss: 0.0797, g_loss: 1.4992\n",
            "Step [1740/80000], d_real_loss: 0.2226, d_mnist_loss: 0.0197, d_svhn_loss: 0.2029, d_fake_loss: 0.2730, g_loss: 1.1850\n",
            "Step [1750/80000], d_real_loss: 0.2624, d_mnist_loss: 0.0221, d_svhn_loss: 0.2403, d_fake_loss: 0.3494, g_loss: 1.5254\n",
            "Step [1760/80000], d_real_loss: 0.2848, d_mnist_loss: 0.0746, d_svhn_loss: 0.2102, d_fake_loss: 0.1860, g_loss: 0.7765\n",
            "Step [1770/80000], d_real_loss: 0.1185, d_mnist_loss: 0.0166, d_svhn_loss: 0.1018, d_fake_loss: 0.1971, g_loss: 1.7566\n",
            "Step [1780/80000], d_real_loss: 0.2098, d_mnist_loss: 0.0885, d_svhn_loss: 0.1213, d_fake_loss: 0.1082, g_loss: 1.1915\n",
            "Step [1790/80000], d_real_loss: 0.1590, d_mnist_loss: 0.0193, d_svhn_loss: 0.1397, d_fake_loss: 0.2280, g_loss: 0.8603\n",
            "Step [1800/80000], d_real_loss: 0.1460, d_mnist_loss: 0.0281, d_svhn_loss: 0.1180, d_fake_loss: 0.0964, g_loss: 0.9880\n",
            "Step [1810/80000], d_real_loss: 0.2347, d_mnist_loss: 0.0723, d_svhn_loss: 0.1625, d_fake_loss: 0.2469, g_loss: 0.9830\n",
            "Step [1820/80000], d_real_loss: 0.4770, d_mnist_loss: 0.3965, d_svhn_loss: 0.0805, d_fake_loss: 0.1297, g_loss: 1.1949\n",
            "Step [1830/80000], d_real_loss: 0.1195, d_mnist_loss: 0.0278, d_svhn_loss: 0.0916, d_fake_loss: 0.1721, g_loss: 1.5353\n",
            "Step [1840/80000], d_real_loss: 0.2494, d_mnist_loss: 0.0702, d_svhn_loss: 0.1791, d_fake_loss: 0.4496, g_loss: 1.6510\n",
            "Step [1850/80000], d_real_loss: 0.2024, d_mnist_loss: 0.0362, d_svhn_loss: 0.1662, d_fake_loss: 0.2655, g_loss: 1.1044\n",
            "Step [1860/80000], d_real_loss: 0.2076, d_mnist_loss: 0.0188, d_svhn_loss: 0.1887, d_fake_loss: 0.5104, g_loss: 2.1023\n",
            "Step [1870/80000], d_real_loss: 0.3069, d_mnist_loss: 0.1952, d_svhn_loss: 0.1117, d_fake_loss: 0.2154, g_loss: 1.0914\n",
            "Step [1880/80000], d_real_loss: 0.1064, d_mnist_loss: 0.0383, d_svhn_loss: 0.0681, d_fake_loss: 0.0883, g_loss: 0.9209\n",
            "Step [1890/80000], d_real_loss: 0.3142, d_mnist_loss: 0.0212, d_svhn_loss: 0.2930, d_fake_loss: 0.2224, g_loss: 1.4796\n",
            "Step [1900/80000], d_real_loss: 0.1580, d_mnist_loss: 0.0592, d_svhn_loss: 0.0989, d_fake_loss: 0.0795, g_loss: 1.1185\n",
            "Step [1910/80000], d_real_loss: 0.2598, d_mnist_loss: 0.1910, d_svhn_loss: 0.0688, d_fake_loss: 0.1317, g_loss: 1.1943\n",
            "Step [1920/80000], d_real_loss: 0.1839, d_mnist_loss: 0.0220, d_svhn_loss: 0.1619, d_fake_loss: 0.4838, g_loss: 1.6653\n",
            "Step [1930/80000], d_real_loss: 0.1378, d_mnist_loss: 0.0626, d_svhn_loss: 0.0752, d_fake_loss: 0.0720, g_loss: 1.2856\n",
            "Step [1940/80000], d_real_loss: 0.1388, d_mnist_loss: 0.0392, d_svhn_loss: 0.0996, d_fake_loss: 0.0845, g_loss: 1.0980\n",
            "Step [1950/80000], d_real_loss: 0.3249, d_mnist_loss: 0.1006, d_svhn_loss: 0.2243, d_fake_loss: 0.2961, g_loss: 1.6780\n",
            "Step [1960/80000], d_real_loss: 0.3780, d_mnist_loss: 0.1253, d_svhn_loss: 0.2527, d_fake_loss: 0.3158, g_loss: 1.3587\n",
            "Step [1970/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0239, d_svhn_loss: 0.0671, d_fake_loss: 0.2596, g_loss: 2.0018\n",
            "Step [1980/80000], d_real_loss: 0.1777, d_mnist_loss: 0.0408, d_svhn_loss: 0.1369, d_fake_loss: 0.1370, g_loss: 1.2029\n",
            "Step [1990/80000], d_real_loss: 0.2646, d_mnist_loss: 0.0775, d_svhn_loss: 0.1870, d_fake_loss: 0.3688, g_loss: 1.6538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [2000/80000], d_real_loss: 0.3977, d_mnist_loss: 0.0368, d_svhn_loss: 0.3609, d_fake_loss: 0.3171, g_loss: 1.1252\n",
            "saved ./samples_mnist_svhn/sample-2000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-2000-s-m.png\n",
            "Step [2010/80000], d_real_loss: 0.1707, d_mnist_loss: 0.0135, d_svhn_loss: 0.1571, d_fake_loss: 0.1906, g_loss: 1.4144\n",
            "Step [2020/80000], d_real_loss: 0.1521, d_mnist_loss: 0.0200, d_svhn_loss: 0.1321, d_fake_loss: 0.1685, g_loss: 1.2358\n",
            "Step [2030/80000], d_real_loss: 0.2235, d_mnist_loss: 0.0130, d_svhn_loss: 0.2105, d_fake_loss: 0.2278, g_loss: 1.2878\n",
            "Step [2040/80000], d_real_loss: 0.2599, d_mnist_loss: 0.0458, d_svhn_loss: 0.2141, d_fake_loss: 0.1525, g_loss: 0.9486\n",
            "Step [2050/80000], d_real_loss: 0.6715, d_mnist_loss: 0.0109, d_svhn_loss: 0.6606, d_fake_loss: 0.0823, g_loss: 1.1206\n",
            "Step [2060/80000], d_real_loss: 0.2826, d_mnist_loss: 0.2021, d_svhn_loss: 0.0805, d_fake_loss: 0.2955, g_loss: 0.7094\n",
            "Step [2070/80000], d_real_loss: 0.2648, d_mnist_loss: 0.0142, d_svhn_loss: 0.2506, d_fake_loss: 0.0900, g_loss: 1.5950\n",
            "Step [2080/80000], d_real_loss: 0.1948, d_mnist_loss: 0.1064, d_svhn_loss: 0.0884, d_fake_loss: 0.0973, g_loss: 1.4240\n",
            "Step [2090/80000], d_real_loss: 0.2027, d_mnist_loss: 0.0144, d_svhn_loss: 0.1883, d_fake_loss: 0.1070, g_loss: 1.4233\n",
            "Step [2100/80000], d_real_loss: 0.1422, d_mnist_loss: 0.0444, d_svhn_loss: 0.0978, d_fake_loss: 0.2828, g_loss: 1.1663\n",
            "Step [2110/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0172, d_svhn_loss: 0.0653, d_fake_loss: 0.1184, g_loss: 1.0944\n",
            "Step [2120/80000], d_real_loss: 0.2387, d_mnist_loss: 0.0557, d_svhn_loss: 0.1830, d_fake_loss: 0.1277, g_loss: 1.3236\n",
            "Step [2130/80000], d_real_loss: 0.0775, d_mnist_loss: 0.0209, d_svhn_loss: 0.0566, d_fake_loss: 0.2288, g_loss: 0.8316\n",
            "Step [2140/80000], d_real_loss: 0.0824, d_mnist_loss: 0.0166, d_svhn_loss: 0.0658, d_fake_loss: 0.0820, g_loss: 0.8902\n",
            "Step [2150/80000], d_real_loss: 0.1907, d_mnist_loss: 0.0544, d_svhn_loss: 0.1363, d_fake_loss: 0.1584, g_loss: 2.2427\n",
            "Step [2160/80000], d_real_loss: 0.1409, d_mnist_loss: 0.0534, d_svhn_loss: 0.0875, d_fake_loss: 0.2494, g_loss: 1.8127\n",
            "Step [2170/80000], d_real_loss: 0.2513, d_mnist_loss: 0.1580, d_svhn_loss: 0.0933, d_fake_loss: 0.2688, g_loss: 1.7817\n",
            "Step [2180/80000], d_real_loss: 0.2271, d_mnist_loss: 0.0560, d_svhn_loss: 0.1711, d_fake_loss: 0.1236, g_loss: 1.4457\n",
            "Step [2190/80000], d_real_loss: 0.2581, d_mnist_loss: 0.0408, d_svhn_loss: 0.2174, d_fake_loss: 0.2618, g_loss: 1.6998\n",
            "Step [2200/80000], d_real_loss: 0.1737, d_mnist_loss: 0.0601, d_svhn_loss: 0.1136, d_fake_loss: 0.2212, g_loss: 1.3009\n",
            "Step [2210/80000], d_real_loss: 0.3844, d_mnist_loss: 0.0200, d_svhn_loss: 0.3644, d_fake_loss: 0.3323, g_loss: 0.7464\n",
            "Step [2220/80000], d_real_loss: 0.0698, d_mnist_loss: 0.0207, d_svhn_loss: 0.0491, d_fake_loss: 0.1366, g_loss: 1.7985\n",
            "Step [2230/80000], d_real_loss: 0.0990, d_mnist_loss: 0.0180, d_svhn_loss: 0.0810, d_fake_loss: 0.1619, g_loss: 1.2680\n",
            "Step [2240/80000], d_real_loss: 0.2098, d_mnist_loss: 0.0294, d_svhn_loss: 0.1804, d_fake_loss: 0.1656, g_loss: 1.8289\n",
            "Step [2250/80000], d_real_loss: 0.0850, d_mnist_loss: 0.0288, d_svhn_loss: 0.0562, d_fake_loss: 0.2515, g_loss: 0.7705\n",
            "Step [2260/80000], d_real_loss: 0.1018, d_mnist_loss: 0.0277, d_svhn_loss: 0.0741, d_fake_loss: 0.1644, g_loss: 1.7391\n",
            "Step [2270/80000], d_real_loss: 0.1895, d_mnist_loss: 0.0340, d_svhn_loss: 0.1555, d_fake_loss: 0.1159, g_loss: 1.4606\n",
            "Step [2280/80000], d_real_loss: 0.1556, d_mnist_loss: 0.0625, d_svhn_loss: 0.0931, d_fake_loss: 0.2649, g_loss: 1.0355\n",
            "Step [2290/80000], d_real_loss: 0.2027, d_mnist_loss: 0.0710, d_svhn_loss: 0.1317, d_fake_loss: 0.3868, g_loss: 2.1967\n",
            "Step [2300/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0213, d_svhn_loss: 0.0598, d_fake_loss: 0.1691, g_loss: 0.9272\n",
            "Step [2310/80000], d_real_loss: 0.0776, d_mnist_loss: 0.0205, d_svhn_loss: 0.0571, d_fake_loss: 0.1350, g_loss: 0.8015\n",
            "Step [2320/80000], d_real_loss: 0.1518, d_mnist_loss: 0.0917, d_svhn_loss: 0.0601, d_fake_loss: 0.3690, g_loss: 2.2565\n",
            "Step [2330/80000], d_real_loss: 0.3176, d_mnist_loss: 0.0305, d_svhn_loss: 0.2871, d_fake_loss: 0.2196, g_loss: 1.2039\n",
            "Step [2340/80000], d_real_loss: 0.1857, d_mnist_loss: 0.0469, d_svhn_loss: 0.1387, d_fake_loss: 0.2399, g_loss: 1.4556\n",
            "Step [2350/80000], d_real_loss: 0.2590, d_mnist_loss: 0.0119, d_svhn_loss: 0.2470, d_fake_loss: 0.2543, g_loss: 1.8647\n",
            "Step [2360/80000], d_real_loss: 0.1549, d_mnist_loss: 0.0190, d_svhn_loss: 0.1359, d_fake_loss: 0.1286, g_loss: 1.7238\n",
            "Step [2370/80000], d_real_loss: 0.1626, d_mnist_loss: 0.0154, d_svhn_loss: 0.1472, d_fake_loss: 0.1321, g_loss: 1.7344\n",
            "Step [2380/80000], d_real_loss: 0.1026, d_mnist_loss: 0.0269, d_svhn_loss: 0.0757, d_fake_loss: 0.1570, g_loss: 0.6990\n",
            "Step [2390/80000], d_real_loss: 0.1598, d_mnist_loss: 0.0279, d_svhn_loss: 0.1320, d_fake_loss: 0.1566, g_loss: 1.6871\n",
            "Step [2400/80000], d_real_loss: 0.2065, d_mnist_loss: 0.0165, d_svhn_loss: 0.1900, d_fake_loss: 0.1216, g_loss: 1.6778\n",
            "Step [2410/80000], d_real_loss: 0.1278, d_mnist_loss: 0.0258, d_svhn_loss: 0.1020, d_fake_loss: 0.1603, g_loss: 1.1047\n",
            "Step [2420/80000], d_real_loss: 0.1915, d_mnist_loss: 0.1092, d_svhn_loss: 0.0823, d_fake_loss: 0.1124, g_loss: 1.0378\n",
            "Step [2430/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0150, d_svhn_loss: 0.0460, d_fake_loss: 0.2647, g_loss: 1.0336\n",
            "Step [2440/80000], d_real_loss: 0.4905, d_mnist_loss: 0.2241, d_svhn_loss: 0.2663, d_fake_loss: 0.1230, g_loss: 1.1949\n",
            "Step [2450/80000], d_real_loss: 0.1147, d_mnist_loss: 0.0433, d_svhn_loss: 0.0714, d_fake_loss: 0.1005, g_loss: 0.8006\n",
            "Step [2460/80000], d_real_loss: 0.1877, d_mnist_loss: 0.1091, d_svhn_loss: 0.0786, d_fake_loss: 0.1917, g_loss: 1.3229\n",
            "Step [2470/80000], d_real_loss: 0.1815, d_mnist_loss: 0.0199, d_svhn_loss: 0.1616, d_fake_loss: 0.0704, g_loss: 1.2089\n",
            "Step [2480/80000], d_real_loss: 0.1183, d_mnist_loss: 0.0452, d_svhn_loss: 0.0731, d_fake_loss: 0.0896, g_loss: 0.8495\n",
            "Step [2490/80000], d_real_loss: 0.1285, d_mnist_loss: 0.0428, d_svhn_loss: 0.0857, d_fake_loss: 0.2636, g_loss: 1.1944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [2500/80000], d_real_loss: 0.1382, d_mnist_loss: 0.0228, d_svhn_loss: 0.1154, d_fake_loss: 0.2596, g_loss: 1.0532\n",
            "saved ./samples_mnist_svhn/sample-2500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-2500-s-m.png\n",
            "Step [2510/80000], d_real_loss: 0.3713, d_mnist_loss: 0.1386, d_svhn_loss: 0.2327, d_fake_loss: 0.2399, g_loss: 1.5259\n",
            "Step [2520/80000], d_real_loss: 0.1609, d_mnist_loss: 0.0242, d_svhn_loss: 0.1366, d_fake_loss: 0.1843, g_loss: 0.5519\n",
            "Step [2530/80000], d_real_loss: 0.2475, d_mnist_loss: 0.0782, d_svhn_loss: 0.1693, d_fake_loss: 0.1987, g_loss: 0.5790\n",
            "Step [2540/80000], d_real_loss: 0.1047, d_mnist_loss: 0.0197, d_svhn_loss: 0.0849, d_fake_loss: 0.0906, g_loss: 1.1144\n",
            "Step [2550/80000], d_real_loss: 0.0939, d_mnist_loss: 0.0176, d_svhn_loss: 0.0763, d_fake_loss: 0.1519, g_loss: 1.2313\n",
            "Step [2560/80000], d_real_loss: 0.2170, d_mnist_loss: 0.1275, d_svhn_loss: 0.0895, d_fake_loss: 0.3489, g_loss: 1.4052\n",
            "Step [2570/80000], d_real_loss: 0.2022, d_mnist_loss: 0.0200, d_svhn_loss: 0.1822, d_fake_loss: 0.1371, g_loss: 1.0926\n",
            "Step [2580/80000], d_real_loss: 0.1974, d_mnist_loss: 0.0924, d_svhn_loss: 0.1050, d_fake_loss: 0.1844, g_loss: 0.9765\n",
            "Step [2590/80000], d_real_loss: 0.1493, d_mnist_loss: 0.0757, d_svhn_loss: 0.0736, d_fake_loss: 0.1754, g_loss: 1.4350\n",
            "Step [2600/80000], d_real_loss: 0.2703, d_mnist_loss: 0.0483, d_svhn_loss: 0.2220, d_fake_loss: 0.0925, g_loss: 1.3803\n",
            "Step [2610/80000], d_real_loss: 0.3310, d_mnist_loss: 0.1602, d_svhn_loss: 0.1708, d_fake_loss: 0.3190, g_loss: 2.2568\n",
            "Step [2620/80000], d_real_loss: 0.2558, d_mnist_loss: 0.0567, d_svhn_loss: 0.1991, d_fake_loss: 0.2036, g_loss: 1.4340\n",
            "Step [2630/80000], d_real_loss: 0.1711, d_mnist_loss: 0.0193, d_svhn_loss: 0.1518, d_fake_loss: 0.2437, g_loss: 1.5021\n",
            "Step [2640/80000], d_real_loss: 0.1651, d_mnist_loss: 0.0797, d_svhn_loss: 0.0853, d_fake_loss: 0.3016, g_loss: 1.6313\n",
            "Step [2650/80000], d_real_loss: 0.1974, d_mnist_loss: 0.1211, d_svhn_loss: 0.0763, d_fake_loss: 0.2370, g_loss: 1.7658\n",
            "Step [2660/80000], d_real_loss: 0.0856, d_mnist_loss: 0.0204, d_svhn_loss: 0.0652, d_fake_loss: 0.1203, g_loss: 1.5737\n",
            "Step [2670/80000], d_real_loss: 0.1899, d_mnist_loss: 0.0195, d_svhn_loss: 0.1704, d_fake_loss: 0.0753, g_loss: 1.0277\n",
            "Step [2680/80000], d_real_loss: 0.5093, d_mnist_loss: 0.0606, d_svhn_loss: 0.4487, d_fake_loss: 0.0790, g_loss: 1.0857\n",
            "Step [2690/80000], d_real_loss: 0.1573, d_mnist_loss: 0.0573, d_svhn_loss: 0.1000, d_fake_loss: 0.2660, g_loss: 1.3421\n",
            "Step [2700/80000], d_real_loss: 0.1483, d_mnist_loss: 0.0226, d_svhn_loss: 0.1258, d_fake_loss: 0.1542, g_loss: 1.3651\n",
            "Step [2710/80000], d_real_loss: 0.3723, d_mnist_loss: 0.1866, d_svhn_loss: 0.1857, d_fake_loss: 0.2607, g_loss: 2.0710\n",
            "Step [2720/80000], d_real_loss: 0.0890, d_mnist_loss: 0.0181, d_svhn_loss: 0.0709, d_fake_loss: 0.0853, g_loss: 1.4702\n",
            "Step [2730/80000], d_real_loss: 0.2244, d_mnist_loss: 0.1239, d_svhn_loss: 0.1005, d_fake_loss: 0.1456, g_loss: 1.5303\n",
            "Step [2740/80000], d_real_loss: 0.1101, d_mnist_loss: 0.0335, d_svhn_loss: 0.0767, d_fake_loss: 0.0792, g_loss: 1.0256\n",
            "Step [2750/80000], d_real_loss: 0.0949, d_mnist_loss: 0.0146, d_svhn_loss: 0.0803, d_fake_loss: 0.0671, g_loss: 1.5762\n",
            "Step [2760/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0132, d_svhn_loss: 0.0568, d_fake_loss: 0.1526, g_loss: 0.9630\n",
            "Step [2770/80000], d_real_loss: 0.1240, d_mnist_loss: 0.0150, d_svhn_loss: 0.1090, d_fake_loss: 0.0826, g_loss: 1.0956\n",
            "Step [2780/80000], d_real_loss: 0.2193, d_mnist_loss: 0.0175, d_svhn_loss: 0.2018, d_fake_loss: 0.2069, g_loss: 1.7188\n",
            "Step [2790/80000], d_real_loss: 0.1906, d_mnist_loss: 0.1449, d_svhn_loss: 0.0457, d_fake_loss: 0.0841, g_loss: 1.6349\n",
            "Step [2800/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0140, d_svhn_loss: 0.0413, d_fake_loss: 0.1444, g_loss: 0.9167\n",
            "Step [2810/80000], d_real_loss: 0.1726, d_mnist_loss: 0.0170, d_svhn_loss: 0.1556, d_fake_loss: 0.0957, g_loss: 1.3998\n",
            "Step [2820/80000], d_real_loss: 0.1430, d_mnist_loss: 0.0469, d_svhn_loss: 0.0961, d_fake_loss: 0.1046, g_loss: 1.9030\n",
            "Step [2830/80000], d_real_loss: 0.3986, d_mnist_loss: 0.1057, d_svhn_loss: 0.2929, d_fake_loss: 0.2832, g_loss: 2.1706\n",
            "Step [2840/80000], d_real_loss: 0.1299, d_mnist_loss: 0.0187, d_svhn_loss: 0.1112, d_fake_loss: 0.1933, g_loss: 1.2314\n",
            "Step [2850/80000], d_real_loss: 0.1787, d_mnist_loss: 0.0773, d_svhn_loss: 0.1014, d_fake_loss: 0.1593, g_loss: 1.4100\n",
            "Step [2860/80000], d_real_loss: 0.1628, d_mnist_loss: 0.0230, d_svhn_loss: 0.1398, d_fake_loss: 0.1390, g_loss: 1.4035\n",
            "Step [2870/80000], d_real_loss: 0.2418, d_mnist_loss: 0.1251, d_svhn_loss: 0.1167, d_fake_loss: 0.1545, g_loss: 1.6203\n",
            "Step [2880/80000], d_real_loss: 0.2487, d_mnist_loss: 0.0177, d_svhn_loss: 0.2310, d_fake_loss: 0.2597, g_loss: 0.7018\n",
            "Step [2890/80000], d_real_loss: 0.2056, d_mnist_loss: 0.0365, d_svhn_loss: 0.1691, d_fake_loss: 0.0701, g_loss: 0.9859\n",
            "Step [2900/80000], d_real_loss: 0.1876, d_mnist_loss: 0.0673, d_svhn_loss: 0.1203, d_fake_loss: 0.1482, g_loss: 1.0391\n",
            "Step [2910/80000], d_real_loss: 0.1372, d_mnist_loss: 0.0136, d_svhn_loss: 0.1236, d_fake_loss: 0.2933, g_loss: 0.4994\n",
            "Step [2920/80000], d_real_loss: 0.4013, d_mnist_loss: 0.3393, d_svhn_loss: 0.0620, d_fake_loss: 0.2697, g_loss: 1.7539\n",
            "Step [2930/80000], d_real_loss: 0.2152, d_mnist_loss: 0.0214, d_svhn_loss: 0.1938, d_fake_loss: 0.1657, g_loss: 1.3494\n",
            "Step [2940/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0196, d_svhn_loss: 0.0375, d_fake_loss: 0.0484, g_loss: 1.0708\n",
            "Step [2950/80000], d_real_loss: 0.1287, d_mnist_loss: 0.0200, d_svhn_loss: 0.1086, d_fake_loss: 0.2925, g_loss: 2.4700\n",
            "Step [2960/80000], d_real_loss: 0.1367, d_mnist_loss: 0.0305, d_svhn_loss: 0.1062, d_fake_loss: 0.1992, g_loss: 1.7773\n",
            "Step [2970/80000], d_real_loss: 0.1362, d_mnist_loss: 0.0401, d_svhn_loss: 0.0961, d_fake_loss: 0.0908, g_loss: 1.2861\n",
            "Step [2980/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0346, d_svhn_loss: 0.0570, d_fake_loss: 0.1582, g_loss: 1.6613\n",
            "Step [2990/80000], d_real_loss: 0.1491, d_mnist_loss: 0.0189, d_svhn_loss: 0.1302, d_fake_loss: 0.3577, g_loss: 1.0682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [3000/80000], d_real_loss: 0.1239, d_mnist_loss: 0.0399, d_svhn_loss: 0.0840, d_fake_loss: 0.0709, g_loss: 1.0047\n",
            "saved ./samples_mnist_svhn/sample-3000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-3000-s-m.png\n",
            "Step [3010/80000], d_real_loss: 0.2208, d_mnist_loss: 0.1259, d_svhn_loss: 0.0950, d_fake_loss: 0.0865, g_loss: 0.9780\n",
            "Step [3020/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0082, d_svhn_loss: 0.0728, d_fake_loss: 0.0751, g_loss: 1.1581\n",
            "Step [3030/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0214, d_svhn_loss: 0.0510, d_fake_loss: 0.2586, g_loss: 0.5826\n",
            "Step [3040/80000], d_real_loss: 0.3089, d_mnist_loss: 0.0480, d_svhn_loss: 0.2609, d_fake_loss: 0.2231, g_loss: 1.1232\n",
            "Step [3050/80000], d_real_loss: 0.2329, d_mnist_loss: 0.1608, d_svhn_loss: 0.0721, d_fake_loss: 0.4256, g_loss: 1.8071\n",
            "Step [3060/80000], d_real_loss: 0.1331, d_mnist_loss: 0.0135, d_svhn_loss: 0.1196, d_fake_loss: 0.1147, g_loss: 0.7483\n",
            "Step [3070/80000], d_real_loss: 0.1349, d_mnist_loss: 0.0643, d_svhn_loss: 0.0707, d_fake_loss: 0.1457, g_loss: 1.1900\n",
            "Step [3080/80000], d_real_loss: 0.1269, d_mnist_loss: 0.0121, d_svhn_loss: 0.1148, d_fake_loss: 0.0866, g_loss: 1.0573\n",
            "Step [3090/80000], d_real_loss: 0.2480, d_mnist_loss: 0.0162, d_svhn_loss: 0.2318, d_fake_loss: 0.1424, g_loss: 1.0040\n",
            "Step [3100/80000], d_real_loss: 0.1357, d_mnist_loss: 0.0439, d_svhn_loss: 0.0918, d_fake_loss: 0.0545, g_loss: 1.4366\n",
            "Step [3110/80000], d_real_loss: 0.2098, d_mnist_loss: 0.0125, d_svhn_loss: 0.1972, d_fake_loss: 0.0617, g_loss: 1.3445\n",
            "Step [3120/80000], d_real_loss: 0.1513, d_mnist_loss: 0.0403, d_svhn_loss: 0.1110, d_fake_loss: 0.0655, g_loss: 1.1857\n",
            "Step [3130/80000], d_real_loss: 0.1640, d_mnist_loss: 0.0613, d_svhn_loss: 0.1027, d_fake_loss: 0.2563, g_loss: 2.1574\n",
            "Step [3140/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0163, d_svhn_loss: 0.0437, d_fake_loss: 0.1379, g_loss: 0.7977\n",
            "Step [3150/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0225, d_svhn_loss: 0.0446, d_fake_loss: 0.1027, g_loss: 0.8549\n",
            "Step [3160/80000], d_real_loss: 0.1046, d_mnist_loss: 0.0366, d_svhn_loss: 0.0681, d_fake_loss: 0.1079, g_loss: 1.4657\n",
            "Step [3170/80000], d_real_loss: 0.1120, d_mnist_loss: 0.0320, d_svhn_loss: 0.0800, d_fake_loss: 0.1022, g_loss: 0.8408\n",
            "Step [3180/80000], d_real_loss: 0.2552, d_mnist_loss: 0.1629, d_svhn_loss: 0.0923, d_fake_loss: 0.1317, g_loss: 1.2335\n",
            "Step [3190/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0100, d_svhn_loss: 0.0553, d_fake_loss: 0.1309, g_loss: 1.0383\n",
            "Step [3200/80000], d_real_loss: 0.2644, d_mnist_loss: 0.0291, d_svhn_loss: 0.2353, d_fake_loss: 0.1712, g_loss: 0.6125\n",
            "Step [3210/80000], d_real_loss: 0.1188, d_mnist_loss: 0.0396, d_svhn_loss: 0.0792, d_fake_loss: 0.6818, g_loss: 0.6142\n",
            "Step [3220/80000], d_real_loss: 0.1199, d_mnist_loss: 0.0120, d_svhn_loss: 0.1079, d_fake_loss: 0.2230, g_loss: 1.2036\n",
            "Step [3230/80000], d_real_loss: 0.1043, d_mnist_loss: 0.0402, d_svhn_loss: 0.0641, d_fake_loss: 0.2753, g_loss: 1.1813\n",
            "Step [3240/80000], d_real_loss: 0.2491, d_mnist_loss: 0.0221, d_svhn_loss: 0.2270, d_fake_loss: 0.1723, g_loss: 1.0045\n",
            "Step [3250/80000], d_real_loss: 0.2106, d_mnist_loss: 0.0660, d_svhn_loss: 0.1446, d_fake_loss: 0.0571, g_loss: 1.1064\n",
            "Step [3260/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0152, d_svhn_loss: 0.0468, d_fake_loss: 0.4581, g_loss: 1.4150\n",
            "Step [3270/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0068, d_svhn_loss: 0.0418, d_fake_loss: 0.1067, g_loss: 0.9402\n",
            "Step [3280/80000], d_real_loss: 0.4095, d_mnist_loss: 0.3272, d_svhn_loss: 0.0823, d_fake_loss: 0.3251, g_loss: 2.1434\n",
            "Step [3290/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0168, d_svhn_loss: 0.0518, d_fake_loss: 0.0602, g_loss: 0.9940\n",
            "Step [3300/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0088, d_svhn_loss: 0.0683, d_fake_loss: 0.1552, g_loss: 1.1759\n",
            "Step [3310/80000], d_real_loss: 0.3450, d_mnist_loss: 0.2503, d_svhn_loss: 0.0947, d_fake_loss: 0.7317, g_loss: 1.4317\n",
            "Step [3320/80000], d_real_loss: 0.2429, d_mnist_loss: 0.1087, d_svhn_loss: 0.1341, d_fake_loss: 0.2977, g_loss: 1.8066\n",
            "Step [3330/80000], d_real_loss: 0.1685, d_mnist_loss: 0.1008, d_svhn_loss: 0.0678, d_fake_loss: 0.0865, g_loss: 0.6483\n",
            "Step [3340/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0200, d_svhn_loss: 0.0433, d_fake_loss: 0.0956, g_loss: 1.4838\n",
            "Step [3350/80000], d_real_loss: 0.1256, d_mnist_loss: 0.0586, d_svhn_loss: 0.0670, d_fake_loss: 0.1251, g_loss: 1.2020\n",
            "Step [3360/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0206, d_svhn_loss: 0.0584, d_fake_loss: 0.1703, g_loss: 1.5750\n",
            "Step [3370/80000], d_real_loss: 0.1756, d_mnist_loss: 0.0610, d_svhn_loss: 0.1146, d_fake_loss: 0.1359, g_loss: 1.1786\n",
            "Step [3380/80000], d_real_loss: 0.1133, d_mnist_loss: 0.0509, d_svhn_loss: 0.0625, d_fake_loss: 0.0619, g_loss: 1.2988\n",
            "Step [3390/80000], d_real_loss: 0.2853, d_mnist_loss: 0.0116, d_svhn_loss: 0.2737, d_fake_loss: 0.1150, g_loss: 1.7890\n",
            "Step [3400/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0315, d_svhn_loss: 0.0442, d_fake_loss: 0.0837, g_loss: 0.8412\n",
            "Step [3410/80000], d_real_loss: 0.1322, d_mnist_loss: 0.0521, d_svhn_loss: 0.0801, d_fake_loss: 0.1222, g_loss: 0.8261\n",
            "Step [3420/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0193, d_svhn_loss: 0.0611, d_fake_loss: 0.0700, g_loss: 0.9870\n",
            "Step [3430/80000], d_real_loss: 0.1834, d_mnist_loss: 0.0427, d_svhn_loss: 0.1407, d_fake_loss: 0.1856, g_loss: 1.4338\n",
            "Step [3440/80000], d_real_loss: 0.2477, d_mnist_loss: 0.0400, d_svhn_loss: 0.2076, d_fake_loss: 0.4164, g_loss: 1.8701\n",
            "Step [3450/80000], d_real_loss: 0.1012, d_mnist_loss: 0.0345, d_svhn_loss: 0.0667, d_fake_loss: 0.0698, g_loss: 1.4919\n",
            "Step [3460/80000], d_real_loss: 0.1835, d_mnist_loss: 0.1214, d_svhn_loss: 0.0621, d_fake_loss: 0.0697, g_loss: 1.4425\n",
            "Step [3470/80000], d_real_loss: 0.1051, d_mnist_loss: 0.0463, d_svhn_loss: 0.0589, d_fake_loss: 0.2382, g_loss: 0.9794\n",
            "Step [3480/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0151, d_svhn_loss: 0.0470, d_fake_loss: 0.0727, g_loss: 1.0131\n",
            "Step [3490/80000], d_real_loss: 1.1749, d_mnist_loss: 1.0518, d_svhn_loss: 0.1231, d_fake_loss: 0.5146, g_loss: 3.0308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [3500/80000], d_real_loss: 0.2020, d_mnist_loss: 0.0461, d_svhn_loss: 0.1559, d_fake_loss: 0.2752, g_loss: 1.2672\n",
            "saved ./samples_mnist_svhn/sample-3500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-3500-s-m.png\n",
            "Step [3510/80000], d_real_loss: 0.2667, d_mnist_loss: 0.0228, d_svhn_loss: 0.2439, d_fake_loss: 0.2141, g_loss: 1.0235\n",
            "Step [3520/80000], d_real_loss: 0.3282, d_mnist_loss: 0.1906, d_svhn_loss: 0.1375, d_fake_loss: 0.0788, g_loss: 1.1236\n",
            "Step [3530/80000], d_real_loss: 0.3592, d_mnist_loss: 0.0151, d_svhn_loss: 0.3441, d_fake_loss: 0.0723, g_loss: 1.2893\n",
            "Step [3540/80000], d_real_loss: 0.3124, d_mnist_loss: 0.0672, d_svhn_loss: 0.2452, d_fake_loss: 0.1054, g_loss: 1.3694\n",
            "Step [3550/80000], d_real_loss: 0.1520, d_mnist_loss: 0.0717, d_svhn_loss: 0.0802, d_fake_loss: 0.0673, g_loss: 1.1116\n",
            "Step [3560/80000], d_real_loss: 0.1504, d_mnist_loss: 0.0361, d_svhn_loss: 0.1144, d_fake_loss: 0.2372, g_loss: 1.3851\n",
            "Step [3570/80000], d_real_loss: 0.5404, d_mnist_loss: 0.0284, d_svhn_loss: 0.5120, d_fake_loss: 0.2946, g_loss: 1.8396\n",
            "Step [3580/80000], d_real_loss: 0.1989, d_mnist_loss: 0.1265, d_svhn_loss: 0.0724, d_fake_loss: 0.3014, g_loss: 1.4654\n",
            "Step [3590/80000], d_real_loss: 0.1073, d_mnist_loss: 0.0260, d_svhn_loss: 0.0812, d_fake_loss: 0.0691, g_loss: 1.1768\n",
            "Step [3600/80000], d_real_loss: 0.1270, d_mnist_loss: 0.0824, d_svhn_loss: 0.0447, d_fake_loss: 0.0857, g_loss: 0.8801\n",
            "Step [3610/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0147, d_svhn_loss: 0.0770, d_fake_loss: 0.3127, g_loss: 0.7440\n",
            "Step [3620/80000], d_real_loss: 0.1816, d_mnist_loss: 0.0536, d_svhn_loss: 0.1280, d_fake_loss: 0.1087, g_loss: 1.2236\n",
            "Step [3630/80000], d_real_loss: 0.1610, d_mnist_loss: 0.0306, d_svhn_loss: 0.1304, d_fake_loss: 0.1631, g_loss: 0.7773\n",
            "Step [3640/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0272, d_svhn_loss: 0.0566, d_fake_loss: 0.0856, g_loss: 1.4139\n",
            "Step [3650/80000], d_real_loss: 0.1010, d_mnist_loss: 0.0458, d_svhn_loss: 0.0552, d_fake_loss: 0.0785, g_loss: 1.1738\n",
            "Step [3660/80000], d_real_loss: 0.2429, d_mnist_loss: 0.0338, d_svhn_loss: 0.2091, d_fake_loss: 0.1418, g_loss: 1.2408\n",
            "Step [3670/80000], d_real_loss: 0.2379, d_mnist_loss: 0.0946, d_svhn_loss: 0.1433, d_fake_loss: 0.1777, g_loss: 1.2488\n",
            "Step [3680/80000], d_real_loss: 0.1596, d_mnist_loss: 0.0377, d_svhn_loss: 0.1220, d_fake_loss: 0.2474, g_loss: 1.4857\n",
            "Step [3690/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0155, d_svhn_loss: 0.0685, d_fake_loss: 0.1599, g_loss: 1.5445\n",
            "Step [3700/80000], d_real_loss: 0.1234, d_mnist_loss: 0.0126, d_svhn_loss: 0.1108, d_fake_loss: 0.1629, g_loss: 1.1795\n",
            "Step [3710/80000], d_real_loss: 0.0982, d_mnist_loss: 0.0194, d_svhn_loss: 0.0789, d_fake_loss: 0.0789, g_loss: 1.3151\n",
            "Step [3720/80000], d_real_loss: 0.1376, d_mnist_loss: 0.0708, d_svhn_loss: 0.0667, d_fake_loss: 0.0615, g_loss: 1.2258\n",
            "Step [3730/80000], d_real_loss: 0.1573, d_mnist_loss: 0.0126, d_svhn_loss: 0.1446, d_fake_loss: 0.0899, g_loss: 1.1903\n",
            "Step [3740/80000], d_real_loss: 0.2005, d_mnist_loss: 0.0467, d_svhn_loss: 0.1539, d_fake_loss: 0.2331, g_loss: 1.3381\n",
            "Step [3750/80000], d_real_loss: 0.1514, d_mnist_loss: 0.0127, d_svhn_loss: 0.1387, d_fake_loss: 0.2467, g_loss: 1.3288\n",
            "Step [3760/80000], d_real_loss: 0.1499, d_mnist_loss: 0.0258, d_svhn_loss: 0.1241, d_fake_loss: 0.1250, g_loss: 1.3599\n",
            "Step [3770/80000], d_real_loss: 0.1082, d_mnist_loss: 0.0066, d_svhn_loss: 0.1016, d_fake_loss: 0.1297, g_loss: 0.8746\n",
            "Step [3780/80000], d_real_loss: 0.1401, d_mnist_loss: 0.0617, d_svhn_loss: 0.0783, d_fake_loss: 0.0567, g_loss: 1.4768\n",
            "Step [3790/80000], d_real_loss: 0.1930, d_mnist_loss: 0.0136, d_svhn_loss: 0.1794, d_fake_loss: 0.0793, g_loss: 1.3518\n",
            "Step [3800/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0084, d_svhn_loss: 0.0851, d_fake_loss: 0.0557, g_loss: 1.2644\n",
            "Step [3810/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0075, d_svhn_loss: 0.0624, d_fake_loss: 0.1376, g_loss: 1.0529\n",
            "Step [3820/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0093, d_svhn_loss: 0.0622, d_fake_loss: 0.3153, g_loss: 0.8406\n",
            "Step [3830/80000], d_real_loss: 0.1605, d_mnist_loss: 0.0642, d_svhn_loss: 0.0964, d_fake_loss: 0.0745, g_loss: 1.4711\n",
            "Step [3840/80000], d_real_loss: 0.1157, d_mnist_loss: 0.0122, d_svhn_loss: 0.1036, d_fake_loss: 0.0468, g_loss: 1.1681\n",
            "Step [3850/80000], d_real_loss: 0.0972, d_mnist_loss: 0.0119, d_svhn_loss: 0.0853, d_fake_loss: 0.3432, g_loss: 1.5270\n",
            "Step [3860/80000], d_real_loss: 0.1158, d_mnist_loss: 0.0163, d_svhn_loss: 0.0995, d_fake_loss: 0.0671, g_loss: 0.8589\n",
            "Step [3870/80000], d_real_loss: 0.2226, d_mnist_loss: 0.0624, d_svhn_loss: 0.1603, d_fake_loss: 0.0733, g_loss: 1.3188\n",
            "Step [3880/80000], d_real_loss: 0.2677, d_mnist_loss: 0.0106, d_svhn_loss: 0.2571, d_fake_loss: 0.0808, g_loss: 1.1800\n",
            "Step [3890/80000], d_real_loss: 0.1094, d_mnist_loss: 0.0459, d_svhn_loss: 0.0634, d_fake_loss: 0.1752, g_loss: 1.3540\n",
            "Step [3900/80000], d_real_loss: 0.1504, d_mnist_loss: 0.0140, d_svhn_loss: 0.1364, d_fake_loss: 0.0846, g_loss: 1.5830\n",
            "Step [3910/80000], d_real_loss: 0.2240, d_mnist_loss: 0.1158, d_svhn_loss: 0.1081, d_fake_loss: 0.1470, g_loss: 1.2822\n",
            "Step [3920/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0131, d_svhn_loss: 0.0498, d_fake_loss: 0.0467, g_loss: 1.0578\n",
            "Step [3930/80000], d_real_loss: 0.1263, d_mnist_loss: 0.0577, d_svhn_loss: 0.0686, d_fake_loss: 0.1462, g_loss: 1.4492\n",
            "Step [3940/80000], d_real_loss: 0.1416, d_mnist_loss: 0.0794, d_svhn_loss: 0.0622, d_fake_loss: 0.1413, g_loss: 1.5760\n",
            "Step [3950/80000], d_real_loss: 0.1463, d_mnist_loss: 0.0154, d_svhn_loss: 0.1309, d_fake_loss: 0.3519, g_loss: 0.9341\n",
            "Step [3960/80000], d_real_loss: 0.1448, d_mnist_loss: 0.0624, d_svhn_loss: 0.0824, d_fake_loss: 0.0573, g_loss: 1.1393\n",
            "Step [3970/80000], d_real_loss: 0.2131, d_mnist_loss: 0.0146, d_svhn_loss: 0.1984, d_fake_loss: 0.1834, g_loss: 1.6069\n",
            "Step [3980/80000], d_real_loss: 0.1949, d_mnist_loss: 0.0306, d_svhn_loss: 0.1643, d_fake_loss: 0.0932, g_loss: 1.0473\n",
            "Step [3990/80000], d_real_loss: 0.1592, d_mnist_loss: 0.0239, d_svhn_loss: 0.1354, d_fake_loss: 0.1373, g_loss: 1.0596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [4000/80000], d_real_loss: 0.1846, d_mnist_loss: 0.1351, d_svhn_loss: 0.0495, d_fake_loss: 0.1796, g_loss: 1.8381\n",
            "saved ./samples_mnist_svhn/sample-4000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-4000-s-m.png\n",
            "Step [4010/80000], d_real_loss: 0.1015, d_mnist_loss: 0.0387, d_svhn_loss: 0.0627, d_fake_loss: 0.0964, g_loss: 1.1235\n",
            "Step [4020/80000], d_real_loss: 0.1314, d_mnist_loss: 0.0271, d_svhn_loss: 0.1042, d_fake_loss: 0.0970, g_loss: 0.8828\n",
            "Step [4030/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0146, d_svhn_loss: 0.0514, d_fake_loss: 0.1404, g_loss: 1.3573\n",
            "Step [4040/80000], d_real_loss: 0.1087, d_mnist_loss: 0.0124, d_svhn_loss: 0.0964, d_fake_loss: 0.1424, g_loss: 1.0248\n",
            "Step [4050/80000], d_real_loss: 0.2432, d_mnist_loss: 0.0087, d_svhn_loss: 0.2345, d_fake_loss: 0.6432, g_loss: 1.0047\n",
            "Step [4060/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0078, d_svhn_loss: 0.0433, d_fake_loss: 0.1294, g_loss: 1.6059\n",
            "Step [4070/80000], d_real_loss: 0.1349, d_mnist_loss: 0.0556, d_svhn_loss: 0.0793, d_fake_loss: 0.1264, g_loss: 0.6263\n",
            "Step [4080/80000], d_real_loss: 0.0834, d_mnist_loss: 0.0181, d_svhn_loss: 0.0653, d_fake_loss: 0.1486, g_loss: 0.9472\n",
            "Step [4090/80000], d_real_loss: 0.0886, d_mnist_loss: 0.0077, d_svhn_loss: 0.0809, d_fake_loss: 0.1687, g_loss: 1.4047\n",
            "Step [4100/80000], d_real_loss: 0.1725, d_mnist_loss: 0.0798, d_svhn_loss: 0.0927, d_fake_loss: 0.0998, g_loss: 1.0756\n",
            "Step [4110/80000], d_real_loss: 0.0999, d_mnist_loss: 0.0233, d_svhn_loss: 0.0766, d_fake_loss: 0.0699, g_loss: 1.2645\n",
            "Step [4120/80000], d_real_loss: 0.1925, d_mnist_loss: 0.1048, d_svhn_loss: 0.0878, d_fake_loss: 0.0553, g_loss: 0.9921\n",
            "Step [4130/80000], d_real_loss: 0.1132, d_mnist_loss: 0.0152, d_svhn_loss: 0.0980, d_fake_loss: 0.0901, g_loss: 0.7996\n",
            "Step [4140/80000], d_real_loss: 0.1973, d_mnist_loss: 0.0312, d_svhn_loss: 0.1660, d_fake_loss: 0.1394, g_loss: 0.8634\n",
            "Step [4150/80000], d_real_loss: 0.2670, d_mnist_loss: 0.1031, d_svhn_loss: 0.1639, d_fake_loss: 0.0780, g_loss: 1.5824\n",
            "Step [4160/80000], d_real_loss: 0.0854, d_mnist_loss: 0.0230, d_svhn_loss: 0.0624, d_fake_loss: 0.1192, g_loss: 1.4055\n",
            "Step [4170/80000], d_real_loss: 0.0938, d_mnist_loss: 0.0165, d_svhn_loss: 0.0774, d_fake_loss: 0.1465, g_loss: 1.8018\n",
            "Step [4180/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0125, d_svhn_loss: 0.0713, d_fake_loss: 0.0908, g_loss: 1.0745\n",
            "Step [4190/80000], d_real_loss: 0.1068, d_mnist_loss: 0.0224, d_svhn_loss: 0.0844, d_fake_loss: 0.0397, g_loss: 1.2346\n",
            "Step [4200/80000], d_real_loss: 0.1610, d_mnist_loss: 0.0213, d_svhn_loss: 0.1397, d_fake_loss: 0.2313, g_loss: 1.1528\n",
            "Step [4210/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0321, d_svhn_loss: 0.0530, d_fake_loss: 0.0725, g_loss: 1.3536\n",
            "Step [4220/80000], d_real_loss: 0.1329, d_mnist_loss: 0.0134, d_svhn_loss: 0.1195, d_fake_loss: 0.2405, g_loss: 1.3394\n",
            "Step [4230/80000], d_real_loss: 0.3699, d_mnist_loss: 0.0392, d_svhn_loss: 0.3307, d_fake_loss: 0.0858, g_loss: 1.7765\n",
            "Step [4240/80000], d_real_loss: 0.4209, d_mnist_loss: 0.3735, d_svhn_loss: 0.0474, d_fake_loss: 0.1140, g_loss: 1.1543\n",
            "Step [4250/80000], d_real_loss: 0.1681, d_mnist_loss: 0.0736, d_svhn_loss: 0.0945, d_fake_loss: 0.1734, g_loss: 1.7017\n",
            "Step [4260/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0350, d_svhn_loss: 0.0363, d_fake_loss: 0.0758, g_loss: 1.7093\n",
            "Step [4270/80000], d_real_loss: 0.1217, d_mnist_loss: 0.0321, d_svhn_loss: 0.0897, d_fake_loss: 0.2031, g_loss: 1.0759\n",
            "Step [4280/80000], d_real_loss: 0.1165, d_mnist_loss: 0.0239, d_svhn_loss: 0.0927, d_fake_loss: 0.0850, g_loss: 1.4656\n",
            "Step [4290/80000], d_real_loss: 0.0865, d_mnist_loss: 0.0082, d_svhn_loss: 0.0783, d_fake_loss: 0.2454, g_loss: 0.9071\n",
            "Step [4300/80000], d_real_loss: 0.1084, d_mnist_loss: 0.0234, d_svhn_loss: 0.0850, d_fake_loss: 0.0769, g_loss: 1.0366\n",
            "Step [4310/80000], d_real_loss: 0.1126, d_mnist_loss: 0.0387, d_svhn_loss: 0.0739, d_fake_loss: 0.1266, g_loss: 1.2122\n",
            "Step [4320/80000], d_real_loss: 0.3023, d_mnist_loss: 0.0093, d_svhn_loss: 0.2931, d_fake_loss: 0.1240, g_loss: 0.7711\n",
            "Step [4330/80000], d_real_loss: 0.0780, d_mnist_loss: 0.0073, d_svhn_loss: 0.0708, d_fake_loss: 0.0884, g_loss: 1.3091\n",
            "Step [4340/80000], d_real_loss: 0.0906, d_mnist_loss: 0.0485, d_svhn_loss: 0.0421, d_fake_loss: 0.0616, g_loss: 1.1412\n",
            "Step [4350/80000], d_real_loss: 0.1299, d_mnist_loss: 0.0177, d_svhn_loss: 0.1123, d_fake_loss: 0.3579, g_loss: 1.9859\n",
            "Step [4360/80000], d_real_loss: 0.1280, d_mnist_loss: 0.0430, d_svhn_loss: 0.0850, d_fake_loss: 0.1099, g_loss: 1.2301\n",
            "Step [4370/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0116, d_svhn_loss: 0.0626, d_fake_loss: 0.1364, g_loss: 0.7689\n",
            "Step [4380/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0154, d_svhn_loss: 0.0632, d_fake_loss: 0.2671, g_loss: 0.9673\n",
            "Step [4390/80000], d_real_loss: 0.2106, d_mnist_loss: 0.0283, d_svhn_loss: 0.1823, d_fake_loss: 0.0680, g_loss: 0.9604\n",
            "Step [4400/80000], d_real_loss: 0.0937, d_mnist_loss: 0.0580, d_svhn_loss: 0.0357, d_fake_loss: 0.0638, g_loss: 1.1524\n",
            "Step [4410/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0083, d_svhn_loss: 0.0521, d_fake_loss: 0.2264, g_loss: 1.2423\n",
            "Step [4420/80000], d_real_loss: 0.0866, d_mnist_loss: 0.0193, d_svhn_loss: 0.0673, d_fake_loss: 0.0497, g_loss: 1.3565\n",
            "Step [4430/80000], d_real_loss: 0.1825, d_mnist_loss: 0.0078, d_svhn_loss: 0.1748, d_fake_loss: 0.0850, g_loss: 1.4693\n",
            "Step [4440/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0165, d_svhn_loss: 0.0554, d_fake_loss: 0.0350, g_loss: 1.0936\n",
            "Step [4450/80000], d_real_loss: 0.1181, d_mnist_loss: 0.0371, d_svhn_loss: 0.0810, d_fake_loss: 0.1320, g_loss: 1.1962\n",
            "Step [4460/80000], d_real_loss: 0.0945, d_mnist_loss: 0.0474, d_svhn_loss: 0.0471, d_fake_loss: 0.0795, g_loss: 1.1522\n",
            "Step [4470/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0199, d_svhn_loss: 0.0645, d_fake_loss: 0.1342, g_loss: 0.9037\n",
            "Step [4480/80000], d_real_loss: 0.1431, d_mnist_loss: 0.0324, d_svhn_loss: 0.1107, d_fake_loss: 0.2372, g_loss: 1.1454\n",
            "Step [4490/80000], d_real_loss: 0.0952, d_mnist_loss: 0.0181, d_svhn_loss: 0.0771, d_fake_loss: 0.3234, g_loss: 1.4414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [4500/80000], d_real_loss: 0.0909, d_mnist_loss: 0.0154, d_svhn_loss: 0.0755, d_fake_loss: 0.1151, g_loss: 1.0130\n",
            "saved ./samples_mnist_svhn/sample-4500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-4500-s-m.png\n",
            "Step [4510/80000], d_real_loss: 0.1701, d_mnist_loss: 0.0981, d_svhn_loss: 0.0720, d_fake_loss: 0.0466, g_loss: 1.3976\n",
            "Step [4520/80000], d_real_loss: 0.1423, d_mnist_loss: 0.0073, d_svhn_loss: 0.1350, d_fake_loss: 0.2057, g_loss: 1.1053\n",
            "Step [4530/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0090, d_svhn_loss: 0.0487, d_fake_loss: 0.1043, g_loss: 0.8976\n",
            "Step [4540/80000], d_real_loss: 0.1302, d_mnist_loss: 0.0255, d_svhn_loss: 0.1047, d_fake_loss: 0.1194, g_loss: 0.9116\n",
            "Step [4550/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0188, d_svhn_loss: 0.0504, d_fake_loss: 0.0918, g_loss: 1.0453\n",
            "Step [4560/80000], d_real_loss: 0.1216, d_mnist_loss: 0.0089, d_svhn_loss: 0.1127, d_fake_loss: 0.0791, g_loss: 1.8769\n",
            "Step [4570/80000], d_real_loss: 0.0965, d_mnist_loss: 0.0527, d_svhn_loss: 0.0438, d_fake_loss: 0.2844, g_loss: 1.1107\n",
            "Step [4580/80000], d_real_loss: 0.1950, d_mnist_loss: 0.0098, d_svhn_loss: 0.1852, d_fake_loss: 0.1578, g_loss: 1.3432\n",
            "Step [4590/80000], d_real_loss: 0.1305, d_mnist_loss: 0.0446, d_svhn_loss: 0.0860, d_fake_loss: 0.2903, g_loss: 1.0473\n",
            "Step [4600/80000], d_real_loss: 0.1012, d_mnist_loss: 0.0177, d_svhn_loss: 0.0835, d_fake_loss: 0.0637, g_loss: 1.0858\n",
            "Step [4610/80000], d_real_loss: 0.0807, d_mnist_loss: 0.0230, d_svhn_loss: 0.0577, d_fake_loss: 0.1770, g_loss: 1.0989\n",
            "Step [4620/80000], d_real_loss: 0.1629, d_mnist_loss: 0.0404, d_svhn_loss: 0.1225, d_fake_loss: 0.0638, g_loss: 1.2184\n",
            "Step [4630/80000], d_real_loss: 0.0751, d_mnist_loss: 0.0089, d_svhn_loss: 0.0661, d_fake_loss: 0.1086, g_loss: 1.5212\n",
            "Step [4640/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0139, d_svhn_loss: 0.0373, d_fake_loss: 0.0881, g_loss: 1.4262\n",
            "Step [4650/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0063, d_svhn_loss: 0.0748, d_fake_loss: 0.0434, g_loss: 0.9858\n",
            "Step [4660/80000], d_real_loss: 0.2308, d_mnist_loss: 0.0082, d_svhn_loss: 0.2225, d_fake_loss: 0.3951, g_loss: 1.0544\n",
            "Step [4670/80000], d_real_loss: 0.1419, d_mnist_loss: 0.0196, d_svhn_loss: 0.1222, d_fake_loss: 0.2972, g_loss: 0.5129\n",
            "Step [4680/80000], d_real_loss: 0.2073, d_mnist_loss: 0.1058, d_svhn_loss: 0.1016, d_fake_loss: 0.1104, g_loss: 1.1341\n",
            "Step [4690/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0101, d_svhn_loss: 0.0632, d_fake_loss: 0.1400, g_loss: 1.3294\n",
            "Step [4700/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0125, d_svhn_loss: 0.0464, d_fake_loss: 0.0667, g_loss: 1.4330\n",
            "Step [4710/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0144, d_svhn_loss: 0.0565, d_fake_loss: 0.0512, g_loss: 1.1174\n",
            "Step [4720/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0149, d_svhn_loss: 0.0561, d_fake_loss: 0.0455, g_loss: 1.0355\n",
            "Step [4730/80000], d_real_loss: 0.2622, d_mnist_loss: 0.0612, d_svhn_loss: 0.2010, d_fake_loss: 0.1912, g_loss: 1.9339\n",
            "Step [4740/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0286, d_svhn_loss: 0.0499, d_fake_loss: 0.0605, g_loss: 1.3432\n",
            "Step [4750/80000], d_real_loss: 0.1070, d_mnist_loss: 0.0713, d_svhn_loss: 0.0358, d_fake_loss: 0.0888, g_loss: 1.2451\n",
            "Step [4760/80000], d_real_loss: 0.1401, d_mnist_loss: 0.0168, d_svhn_loss: 0.1234, d_fake_loss: 0.1908, g_loss: 0.9875\n",
            "Step [4770/80000], d_real_loss: 0.1127, d_mnist_loss: 0.0216, d_svhn_loss: 0.0910, d_fake_loss: 0.0753, g_loss: 1.1670\n",
            "Step [4780/80000], d_real_loss: 0.1811, d_mnist_loss: 0.0457, d_svhn_loss: 0.1354, d_fake_loss: 0.1931, g_loss: 1.4532\n",
            "Step [4790/80000], d_real_loss: 0.1030, d_mnist_loss: 0.0545, d_svhn_loss: 0.0485, d_fake_loss: 0.1325, g_loss: 1.3197\n",
            "Step [4800/80000], d_real_loss: 0.0966, d_mnist_loss: 0.0157, d_svhn_loss: 0.0809, d_fake_loss: 0.1683, g_loss: 1.0946\n",
            "Step [4810/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0055, d_svhn_loss: 0.0636, d_fake_loss: 0.0528, g_loss: 1.0651\n",
            "Step [4820/80000], d_real_loss: 0.1008, d_mnist_loss: 0.0085, d_svhn_loss: 0.0923, d_fake_loss: 0.0561, g_loss: 1.2356\n",
            "Step [4830/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0071, d_svhn_loss: 0.0707, d_fake_loss: 0.0617, g_loss: 1.1424\n",
            "Step [4840/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0183, d_svhn_loss: 0.0473, d_fake_loss: 0.0998, g_loss: 1.4985\n",
            "Step [4850/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0133, d_svhn_loss: 0.0679, d_fake_loss: 0.1327, g_loss: 1.3285\n",
            "Step [4860/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0145, d_svhn_loss: 0.0359, d_fake_loss: 0.0882, g_loss: 1.1338\n",
            "Step [4870/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0103, d_svhn_loss: 0.0305, d_fake_loss: 0.2549, g_loss: 1.1715\n",
            "Step [4880/80000], d_real_loss: 0.0832, d_mnist_loss: 0.0414, d_svhn_loss: 0.0418, d_fake_loss: 0.0798, g_loss: 0.7238\n",
            "Step [4890/80000], d_real_loss: 0.1694, d_mnist_loss: 0.1061, d_svhn_loss: 0.0633, d_fake_loss: 0.0825, g_loss: 1.6907\n",
            "Step [4900/80000], d_real_loss: 0.3740, d_mnist_loss: 0.0922, d_svhn_loss: 0.2818, d_fake_loss: 0.1642, g_loss: 1.4040\n",
            "Step [4910/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0114, d_svhn_loss: 0.0562, d_fake_loss: 0.1753, g_loss: 0.8911\n",
            "Step [4920/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0148, d_svhn_loss: 0.0683, d_fake_loss: 0.0578, g_loss: 1.1225\n",
            "Step [4930/80000], d_real_loss: 0.0902, d_mnist_loss: 0.0133, d_svhn_loss: 0.0769, d_fake_loss: 0.0418, g_loss: 1.2284\n",
            "Step [4940/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0271, d_svhn_loss: 0.0365, d_fake_loss: 0.0467, g_loss: 1.2153\n",
            "Step [4950/80000], d_real_loss: 0.2469, d_mnist_loss: 0.2005, d_svhn_loss: 0.0464, d_fake_loss: 0.0424, g_loss: 1.1393\n",
            "Step [4960/80000], d_real_loss: 0.0930, d_mnist_loss: 0.0202, d_svhn_loss: 0.0728, d_fake_loss: 0.1517, g_loss: 1.8276\n",
            "Step [4970/80000], d_real_loss: 0.1478, d_mnist_loss: 0.0377, d_svhn_loss: 0.1102, d_fake_loss: 0.0781, g_loss: 1.2564\n",
            "Step [4980/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0153, d_svhn_loss: 0.0313, d_fake_loss: 0.0822, g_loss: 1.1342\n",
            "Step [4990/80000], d_real_loss: 0.1543, d_mnist_loss: 0.0322, d_svhn_loss: 0.1221, d_fake_loss: 0.1284, g_loss: 1.2298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [5000/80000], d_real_loss: 0.4193, d_mnist_loss: 0.1820, d_svhn_loss: 0.2373, d_fake_loss: 0.1877, g_loss: 1.5895\n",
            "saved ./samples_mnist_svhn/sample-5000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-5000-s-m.png\n",
            "Step [5010/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0166, d_svhn_loss: 0.0585, d_fake_loss: 0.1668, g_loss: 1.5003\n",
            "Step [5020/80000], d_real_loss: 0.1745, d_mnist_loss: 0.0256, d_svhn_loss: 0.1489, d_fake_loss: 0.0801, g_loss: 1.1368\n",
            "Step [5030/80000], d_real_loss: 0.1445, d_mnist_loss: 0.0469, d_svhn_loss: 0.0975, d_fake_loss: 0.2315, g_loss: 1.7280\n",
            "Step [5040/80000], d_real_loss: 0.1727, d_mnist_loss: 0.0702, d_svhn_loss: 0.1025, d_fake_loss: 0.1068, g_loss: 1.4019\n",
            "Step [5050/80000], d_real_loss: 0.1514, d_mnist_loss: 0.0513, d_svhn_loss: 0.1001, d_fake_loss: 0.0707, g_loss: 1.3092\n",
            "Step [5060/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0128, d_svhn_loss: 0.0613, d_fake_loss: 0.4605, g_loss: 0.9795\n",
            "Step [5070/80000], d_real_loss: 0.0921, d_mnist_loss: 0.0103, d_svhn_loss: 0.0818, d_fake_loss: 0.1190, g_loss: 0.9401\n",
            "Step [5080/80000], d_real_loss: 0.1926, d_mnist_loss: 0.0083, d_svhn_loss: 0.1843, d_fake_loss: 0.1180, g_loss: 1.5580\n",
            "Step [5090/80000], d_real_loss: 0.1426, d_mnist_loss: 0.0077, d_svhn_loss: 0.1349, d_fake_loss: 0.1287, g_loss: 1.3205\n",
            "Step [5100/80000], d_real_loss: 0.1798, d_mnist_loss: 0.0526, d_svhn_loss: 0.1272, d_fake_loss: 0.1688, g_loss: 1.1901\n",
            "Step [5110/80000], d_real_loss: 0.3037, d_mnist_loss: 0.0465, d_svhn_loss: 0.2572, d_fake_loss: 0.1109, g_loss: 1.2335\n",
            "Step [5120/80000], d_real_loss: 0.0884, d_mnist_loss: 0.0219, d_svhn_loss: 0.0665, d_fake_loss: 0.2398, g_loss: 1.3169\n",
            "Step [5130/80000], d_real_loss: 0.1435, d_mnist_loss: 0.0099, d_svhn_loss: 0.1335, d_fake_loss: 0.1985, g_loss: 1.3042\n",
            "Step [5140/80000], d_real_loss: 0.1081, d_mnist_loss: 0.0674, d_svhn_loss: 0.0406, d_fake_loss: 0.1245, g_loss: 1.3910\n",
            "Step [5150/80000], d_real_loss: 0.1426, d_mnist_loss: 0.0235, d_svhn_loss: 0.1191, d_fake_loss: 0.0652, g_loss: 0.8460\n",
            "Step [5160/80000], d_real_loss: 0.6210, d_mnist_loss: 0.0091, d_svhn_loss: 0.6119, d_fake_loss: 0.0741, g_loss: 1.1716\n",
            "Step [5170/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0286, d_svhn_loss: 0.0509, d_fake_loss: 0.0579, g_loss: 0.9025\n",
            "Step [5180/80000], d_real_loss: 0.1199, d_mnist_loss: 0.0424, d_svhn_loss: 0.0775, d_fake_loss: 0.1180, g_loss: 1.0627\n",
            "Step [5190/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0082, d_svhn_loss: 0.0556, d_fake_loss: 0.2080, g_loss: 1.1819\n",
            "Step [5200/80000], d_real_loss: 0.2338, d_mnist_loss: 0.0074, d_svhn_loss: 0.2264, d_fake_loss: 0.1027, g_loss: 1.2232\n",
            "Step [5210/80000], d_real_loss: 0.1423, d_mnist_loss: 0.0822, d_svhn_loss: 0.0602, d_fake_loss: 0.1526, g_loss: 1.3433\n",
            "Step [5220/80000], d_real_loss: 0.0974, d_mnist_loss: 0.0277, d_svhn_loss: 0.0697, d_fake_loss: 0.0666, g_loss: 1.0092\n",
            "Step [5230/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0109, d_svhn_loss: 0.0540, d_fake_loss: 0.0502, g_loss: 1.1949\n",
            "Step [5240/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0081, d_svhn_loss: 0.0359, d_fake_loss: 0.1014, g_loss: 1.5267\n",
            "Step [5250/80000], d_real_loss: 0.1269, d_mnist_loss: 0.0715, d_svhn_loss: 0.0554, d_fake_loss: 0.1171, g_loss: 1.0464\n",
            "Step [5260/80000], d_real_loss: 0.1052, d_mnist_loss: 0.0067, d_svhn_loss: 0.0985, d_fake_loss: 0.1038, g_loss: 1.2938\n",
            "Step [5270/80000], d_real_loss: 0.1680, d_mnist_loss: 0.0924, d_svhn_loss: 0.0756, d_fake_loss: 0.1840, g_loss: 1.5199\n",
            "Step [5280/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0089, d_svhn_loss: 0.0639, d_fake_loss: 0.0701, g_loss: 1.2026\n",
            "Step [5290/80000], d_real_loss: 0.1331, d_mnist_loss: 0.0352, d_svhn_loss: 0.0979, d_fake_loss: 0.1216, g_loss: 1.0708\n",
            "Step [5300/80000], d_real_loss: 0.0665, d_mnist_loss: 0.0075, d_svhn_loss: 0.0590, d_fake_loss: 0.0766, g_loss: 0.9107\n",
            "Step [5310/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0421, d_svhn_loss: 0.0472, d_fake_loss: 0.1207, g_loss: 1.7709\n",
            "Step [5320/80000], d_real_loss: 0.1533, d_mnist_loss: 0.0089, d_svhn_loss: 0.1444, d_fake_loss: 0.2755, g_loss: 1.5818\n",
            "Step [5330/80000], d_real_loss: 0.1718, d_mnist_loss: 0.0104, d_svhn_loss: 0.1614, d_fake_loss: 0.0739, g_loss: 1.2464\n",
            "Step [5340/80000], d_real_loss: 0.1088, d_mnist_loss: 0.0077, d_svhn_loss: 0.1011, d_fake_loss: 0.1183, g_loss: 1.1514\n",
            "Step [5350/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0093, d_svhn_loss: 0.0685, d_fake_loss: 0.1100, g_loss: 1.4743\n",
            "Step [5360/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0626, d_svhn_loss: 0.0452, d_fake_loss: 0.4287, g_loss: 1.8720\n",
            "Step [5370/80000], d_real_loss: 0.1455, d_mnist_loss: 0.0576, d_svhn_loss: 0.0879, d_fake_loss: 0.1125, g_loss: 1.5744\n",
            "Step [5380/80000], d_real_loss: 0.1453, d_mnist_loss: 0.0229, d_svhn_loss: 0.1224, d_fake_loss: 0.4093, g_loss: 1.0993\n",
            "Step [5390/80000], d_real_loss: 0.2980, d_mnist_loss: 0.1556, d_svhn_loss: 0.1424, d_fake_loss: 0.0958, g_loss: 0.9784\n",
            "Step [5400/80000], d_real_loss: 0.1526, d_mnist_loss: 0.0654, d_svhn_loss: 0.0873, d_fake_loss: 0.0991, g_loss: 1.1209\n",
            "Step [5410/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0115, d_svhn_loss: 0.0421, d_fake_loss: 0.0883, g_loss: 0.8368\n",
            "Step [5420/80000], d_real_loss: 0.2115, d_mnist_loss: 0.0085, d_svhn_loss: 0.2030, d_fake_loss: 0.0903, g_loss: 1.4377\n",
            "Step [5430/80000], d_real_loss: 0.1058, d_mnist_loss: 0.0612, d_svhn_loss: 0.0446, d_fake_loss: 0.0894, g_loss: 0.8614\n",
            "Step [5440/80000], d_real_loss: 0.1093, d_mnist_loss: 0.0085, d_svhn_loss: 0.1008, d_fake_loss: 0.1355, g_loss: 1.2416\n",
            "Step [5450/80000], d_real_loss: 0.1205, d_mnist_loss: 0.0698, d_svhn_loss: 0.0507, d_fake_loss: 0.0533, g_loss: 1.0918\n",
            "Step [5460/80000], d_real_loss: 0.1363, d_mnist_loss: 0.0315, d_svhn_loss: 0.1048, d_fake_loss: 0.0745, g_loss: 1.1050\n",
            "Step [5470/80000], d_real_loss: 0.0814, d_mnist_loss: 0.0309, d_svhn_loss: 0.0505, d_fake_loss: 0.0653, g_loss: 1.1201\n",
            "Step [5480/80000], d_real_loss: 0.1910, d_mnist_loss: 0.0908, d_svhn_loss: 0.1002, d_fake_loss: 0.2199, g_loss: 1.4347\n",
            "Step [5490/80000], d_real_loss: 0.2338, d_mnist_loss: 0.0059, d_svhn_loss: 0.2279, d_fake_loss: 0.2193, g_loss: 1.1319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [5500/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0167, d_svhn_loss: 0.0432, d_fake_loss: 0.0762, g_loss: 1.3338\n",
            "saved ./samples_mnist_svhn/sample-5500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-5500-s-m.png\n",
            "Step [5510/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0121, d_svhn_loss: 0.0581, d_fake_loss: 0.0416, g_loss: 1.1682\n",
            "Step [5520/80000], d_real_loss: 0.1479, d_mnist_loss: 0.0171, d_svhn_loss: 0.1309, d_fake_loss: 0.0393, g_loss: 1.2881\n",
            "Step [5530/80000], d_real_loss: 0.1244, d_mnist_loss: 0.0319, d_svhn_loss: 0.0925, d_fake_loss: 0.1030, g_loss: 1.7355\n",
            "Step [5540/80000], d_real_loss: 0.1554, d_mnist_loss: 0.1119, d_svhn_loss: 0.0436, d_fake_loss: 0.0717, g_loss: 1.0647\n",
            "Step [5550/80000], d_real_loss: 0.2045, d_mnist_loss: 0.1398, d_svhn_loss: 0.0647, d_fake_loss: 0.1361, g_loss: 1.3970\n",
            "Step [5560/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0110, d_svhn_loss: 0.0337, d_fake_loss: 0.1065, g_loss: 1.3797\n",
            "Step [5570/80000], d_real_loss: 0.0967, d_mnist_loss: 0.0355, d_svhn_loss: 0.0612, d_fake_loss: 0.0584, g_loss: 1.6073\n",
            "Step [5580/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0090, d_svhn_loss: 0.0697, d_fake_loss: 0.0564, g_loss: 1.3531\n",
            "Step [5590/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0230, d_svhn_loss: 0.0541, d_fake_loss: 0.2551, g_loss: 1.7980\n",
            "Step [5600/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0133, d_svhn_loss: 0.0410, d_fake_loss: 0.0631, g_loss: 1.3998\n",
            "Step [5610/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0092, d_svhn_loss: 0.0528, d_fake_loss: 0.0832, g_loss: 0.8777\n",
            "Step [5620/80000], d_real_loss: 0.1580, d_mnist_loss: 0.0078, d_svhn_loss: 0.1502, d_fake_loss: 0.1530, g_loss: 1.1756\n",
            "Step [5630/80000], d_real_loss: 0.0967, d_mnist_loss: 0.0219, d_svhn_loss: 0.0748, d_fake_loss: 0.0733, g_loss: 1.2847\n",
            "Step [5640/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0097, d_svhn_loss: 0.0739, d_fake_loss: 0.0410, g_loss: 1.1381\n",
            "Step [5650/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0131, d_svhn_loss: 0.0466, d_fake_loss: 0.0824, g_loss: 1.1360\n",
            "Step [5660/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0090, d_svhn_loss: 0.0693, d_fake_loss: 0.2062, g_loss: 1.3679\n",
            "Step [5670/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0095, d_svhn_loss: 0.0408, d_fake_loss: 0.2638, g_loss: 0.8857\n",
            "Step [5680/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0047, d_svhn_loss: 0.0482, d_fake_loss: 0.0709, g_loss: 1.1712\n",
            "Step [5690/80000], d_real_loss: 0.1413, d_mnist_loss: 0.0186, d_svhn_loss: 0.1227, d_fake_loss: 0.0599, g_loss: 1.3539\n",
            "Step [5700/80000], d_real_loss: 0.2041, d_mnist_loss: 0.0067, d_svhn_loss: 0.1974, d_fake_loss: 0.0875, g_loss: 1.3368\n",
            "Step [5710/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0097, d_svhn_loss: 0.0464, d_fake_loss: 0.1921, g_loss: 0.7059\n",
            "Step [5720/80000], d_real_loss: 0.0864, d_mnist_loss: 0.0177, d_svhn_loss: 0.0687, d_fake_loss: 0.0498, g_loss: 1.2704\n",
            "Step [5730/80000], d_real_loss: 0.1484, d_mnist_loss: 0.0372, d_svhn_loss: 0.1112, d_fake_loss: 0.1656, g_loss: 1.2869\n",
            "Step [5740/80000], d_real_loss: 0.0687, d_mnist_loss: 0.0064, d_svhn_loss: 0.0624, d_fake_loss: 0.1557, g_loss: 0.8228\n",
            "Step [5750/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0046, d_svhn_loss: 0.0608, d_fake_loss: 0.0676, g_loss: 1.2669\n",
            "Step [5760/80000], d_real_loss: 0.0947, d_mnist_loss: 0.0094, d_svhn_loss: 0.0853, d_fake_loss: 0.2276, g_loss: 0.9813\n",
            "Step [5770/80000], d_real_loss: 0.1335, d_mnist_loss: 0.0750, d_svhn_loss: 0.0585, d_fake_loss: 0.0897, g_loss: 1.3922\n",
            "Step [5780/80000], d_real_loss: 0.3109, d_mnist_loss: 0.0089, d_svhn_loss: 0.3020, d_fake_loss: 0.0957, g_loss: 0.9970\n",
            "Step [5790/80000], d_real_loss: 0.1007, d_mnist_loss: 0.0520, d_svhn_loss: 0.0486, d_fake_loss: 0.0985, g_loss: 1.0399\n",
            "Step [5800/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0089, d_svhn_loss: 0.0343, d_fake_loss: 0.1673, g_loss: 1.4910\n",
            "Step [5810/80000], d_real_loss: 0.0946, d_mnist_loss: 0.0102, d_svhn_loss: 0.0844, d_fake_loss: 0.0749, g_loss: 1.3181\n",
            "Step [5820/80000], d_real_loss: 0.5087, d_mnist_loss: 0.0993, d_svhn_loss: 0.4094, d_fake_loss: 0.0637, g_loss: 1.5420\n",
            "Step [5830/80000], d_real_loss: 0.1850, d_mnist_loss: 0.0126, d_svhn_loss: 0.1724, d_fake_loss: 0.0992, g_loss: 0.9210\n",
            "Step [5840/80000], d_real_loss: 0.0997, d_mnist_loss: 0.0234, d_svhn_loss: 0.0763, d_fake_loss: 0.0596, g_loss: 1.1013\n",
            "Step [5850/80000], d_real_loss: 0.1944, d_mnist_loss: 0.0119, d_svhn_loss: 0.1825, d_fake_loss: 0.2599, g_loss: 1.1812\n",
            "Step [5860/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0138, d_svhn_loss: 0.0393, d_fake_loss: 0.0389, g_loss: 1.2347\n",
            "Step [5870/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0085, d_svhn_loss: 0.0656, d_fake_loss: 0.0924, g_loss: 1.0304\n",
            "Step [5880/80000], d_real_loss: 0.2050, d_mnist_loss: 0.0165, d_svhn_loss: 0.1884, d_fake_loss: 0.1278, g_loss: 1.1750\n",
            "Step [5890/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0065, d_svhn_loss: 0.0550, d_fake_loss: 0.0558, g_loss: 1.2563\n",
            "Step [5900/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0120, d_svhn_loss: 0.0373, d_fake_loss: 0.0989, g_loss: 1.0613\n",
            "Step [5910/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0097, d_svhn_loss: 0.0589, d_fake_loss: 0.0504, g_loss: 1.2109\n",
            "Step [5920/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0174, d_svhn_loss: 0.0537, d_fake_loss: 0.0642, g_loss: 1.1139\n",
            "Step [5930/80000], d_real_loss: 0.2758, d_mnist_loss: 0.0882, d_svhn_loss: 0.1876, d_fake_loss: 0.1384, g_loss: 1.0785\n",
            "Step [5940/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0175, d_svhn_loss: 0.0491, d_fake_loss: 0.0632, g_loss: 1.0897\n",
            "Step [5950/80000], d_real_loss: 0.2131, d_mnist_loss: 0.0249, d_svhn_loss: 0.1883, d_fake_loss: 0.2099, g_loss: 1.1707\n",
            "Step [5960/80000], d_real_loss: 0.1248, d_mnist_loss: 0.0656, d_svhn_loss: 0.0592, d_fake_loss: 0.0804, g_loss: 1.2067\n",
            "Step [5970/80000], d_real_loss: 0.1075, d_mnist_loss: 0.0061, d_svhn_loss: 0.1014, d_fake_loss: 0.0661, g_loss: 0.9279\n",
            "Step [5980/80000], d_real_loss: 0.1146, d_mnist_loss: 0.0466, d_svhn_loss: 0.0680, d_fake_loss: 0.1126, g_loss: 0.9743\n",
            "Step [5990/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0071, d_svhn_loss: 0.0525, d_fake_loss: 0.1658, g_loss: 1.1962\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [6000/80000], d_real_loss: 0.1065, d_mnist_loss: 0.0583, d_svhn_loss: 0.0482, d_fake_loss: 0.1452, g_loss: 1.5545\n",
            "saved ./samples_mnist_svhn/sample-6000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-6000-s-m.png\n",
            "Step [6010/80000], d_real_loss: 0.1439, d_mnist_loss: 0.0088, d_svhn_loss: 0.1352, d_fake_loss: 0.1922, g_loss: 1.0592\n",
            "Step [6020/80000], d_real_loss: 0.0888, d_mnist_loss: 0.0122, d_svhn_loss: 0.0765, d_fake_loss: 0.0796, g_loss: 1.3710\n",
            "Step [6030/80000], d_real_loss: 0.0654, d_mnist_loss: 0.0086, d_svhn_loss: 0.0568, d_fake_loss: 0.1382, g_loss: 0.8041\n",
            "Step [6040/80000], d_real_loss: 0.3767, d_mnist_loss: 0.3168, d_svhn_loss: 0.0599, d_fake_loss: 0.1396, g_loss: 1.2259\n",
            "Step [6050/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0084, d_svhn_loss: 0.0405, d_fake_loss: 0.0616, g_loss: 1.3946\n",
            "Step [6060/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0254, d_svhn_loss: 0.0482, d_fake_loss: 0.0530, g_loss: 1.2087\n",
            "Step [6070/80000], d_real_loss: 0.2358, d_mnist_loss: 0.0821, d_svhn_loss: 0.1537, d_fake_loss: 0.0593, g_loss: 1.5053\n",
            "Step [6080/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0447, d_svhn_loss: 0.0457, d_fake_loss: 0.1513, g_loss: 1.0671\n",
            "Step [6090/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0162, d_svhn_loss: 0.0415, d_fake_loss: 0.1020, g_loss: 1.3382\n",
            "Step [6100/80000], d_real_loss: 0.0827, d_mnist_loss: 0.0064, d_svhn_loss: 0.0764, d_fake_loss: 0.1783, g_loss: 0.8956\n",
            "Step [6110/80000], d_real_loss: 0.0682, d_mnist_loss: 0.0054, d_svhn_loss: 0.0627, d_fake_loss: 0.1390, g_loss: 1.0943\n",
            "Step [6120/80000], d_real_loss: 0.1371, d_mnist_loss: 0.0183, d_svhn_loss: 0.1188, d_fake_loss: 0.0648, g_loss: 1.1004\n",
            "Step [6130/80000], d_real_loss: 0.3682, d_mnist_loss: 0.1569, d_svhn_loss: 0.2113, d_fake_loss: 0.1829, g_loss: 1.2892\n",
            "Step [6140/80000], d_real_loss: 0.1225, d_mnist_loss: 0.0106, d_svhn_loss: 0.1120, d_fake_loss: 0.0756, g_loss: 1.2544\n",
            "Step [6150/80000], d_real_loss: 0.1484, d_mnist_loss: 0.0067, d_svhn_loss: 0.1418, d_fake_loss: 0.0764, g_loss: 1.2106\n",
            "Step [6160/80000], d_real_loss: 0.1042, d_mnist_loss: 0.0045, d_svhn_loss: 0.0997, d_fake_loss: 0.1429, g_loss: 1.3942\n",
            "Step [6170/80000], d_real_loss: 0.1435, d_mnist_loss: 0.0208, d_svhn_loss: 0.1227, d_fake_loss: 0.0619, g_loss: 1.2636\n",
            "Step [6180/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0267, d_svhn_loss: 0.0498, d_fake_loss: 0.1637, g_loss: 1.3365\n",
            "Step [6190/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0130, d_svhn_loss: 0.0345, d_fake_loss: 0.0907, g_loss: 0.9867\n",
            "Step [6200/80000], d_real_loss: 0.2876, d_mnist_loss: 0.0920, d_svhn_loss: 0.1956, d_fake_loss: 0.0615, g_loss: 0.8206\n",
            "Step [6210/80000], d_real_loss: 0.1199, d_mnist_loss: 0.0051, d_svhn_loss: 0.1147, d_fake_loss: 0.0992, g_loss: 1.1210\n",
            "Step [6220/80000], d_real_loss: 0.2096, d_mnist_loss: 0.0191, d_svhn_loss: 0.1905, d_fake_loss: 0.0412, g_loss: 1.2056\n",
            "Step [6230/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0120, d_svhn_loss: 0.0721, d_fake_loss: 0.1287, g_loss: 1.2598\n",
            "Step [6240/80000], d_real_loss: 0.0894, d_mnist_loss: 0.0060, d_svhn_loss: 0.0834, d_fake_loss: 0.2507, g_loss: 1.4644\n",
            "Step [6250/80000], d_real_loss: 0.1347, d_mnist_loss: 0.0235, d_svhn_loss: 0.1112, d_fake_loss: 0.2208, g_loss: 1.1763\n",
            "Step [6260/80000], d_real_loss: 0.1030, d_mnist_loss: 0.0102, d_svhn_loss: 0.0928, d_fake_loss: 0.0966, g_loss: 1.1412\n",
            "Step [6270/80000], d_real_loss: 0.1175, d_mnist_loss: 0.0109, d_svhn_loss: 0.1066, d_fake_loss: 0.0575, g_loss: 1.2637\n",
            "Step [6280/80000], d_real_loss: 0.0712, d_mnist_loss: 0.0264, d_svhn_loss: 0.0447, d_fake_loss: 0.0932, g_loss: 1.1169\n",
            "Step [6290/80000], d_real_loss: 0.0707, d_mnist_loss: 0.0073, d_svhn_loss: 0.0634, d_fake_loss: 0.3336, g_loss: 1.7478\n",
            "Step [6300/80000], d_real_loss: 0.1429, d_mnist_loss: 0.0401, d_svhn_loss: 0.1028, d_fake_loss: 0.0519, g_loss: 1.0368\n",
            "Step [6310/80000], d_real_loss: 0.0972, d_mnist_loss: 0.0109, d_svhn_loss: 0.0863, d_fake_loss: 0.0812, g_loss: 0.8635\n",
            "Step [6320/80000], d_real_loss: 0.1199, d_mnist_loss: 0.0063, d_svhn_loss: 0.1136, d_fake_loss: 0.0452, g_loss: 1.2783\n",
            "Step [6330/80000], d_real_loss: 0.4464, d_mnist_loss: 0.0109, d_svhn_loss: 0.4355, d_fake_loss: 0.2186, g_loss: 1.1188\n",
            "Step [6340/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0056, d_svhn_loss: 0.0755, d_fake_loss: 0.0466, g_loss: 1.2340\n",
            "Step [6350/80000], d_real_loss: 0.1530, d_mnist_loss: 0.0720, d_svhn_loss: 0.0809, d_fake_loss: 0.1007, g_loss: 1.1971\n",
            "Step [6360/80000], d_real_loss: 0.0955, d_mnist_loss: 0.0112, d_svhn_loss: 0.0843, d_fake_loss: 0.1300, g_loss: 0.9395\n",
            "Step [6370/80000], d_real_loss: 0.1994, d_mnist_loss: 0.1028, d_svhn_loss: 0.0966, d_fake_loss: 0.1039, g_loss: 1.5519\n",
            "Step [6380/80000], d_real_loss: 0.1107, d_mnist_loss: 0.0697, d_svhn_loss: 0.0409, d_fake_loss: 0.1081, g_loss: 1.3007\n",
            "Step [6390/80000], d_real_loss: 0.1082, d_mnist_loss: 0.0224, d_svhn_loss: 0.0859, d_fake_loss: 0.0807, g_loss: 1.3311\n",
            "Step [6400/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0227, d_svhn_loss: 0.0490, d_fake_loss: 0.1109, g_loss: 1.6560\n",
            "Step [6410/80000], d_real_loss: 0.1236, d_mnist_loss: 0.0653, d_svhn_loss: 0.0584, d_fake_loss: 0.0785, g_loss: 1.2570\n",
            "Step [6420/80000], d_real_loss: 0.1357, d_mnist_loss: 0.0062, d_svhn_loss: 0.1295, d_fake_loss: 0.1265, g_loss: 1.6428\n",
            "Step [6430/80000], d_real_loss: 0.1160, d_mnist_loss: 0.0380, d_svhn_loss: 0.0780, d_fake_loss: 0.1090, g_loss: 1.4311\n",
            "Step [6440/80000], d_real_loss: 0.1161, d_mnist_loss: 0.0753, d_svhn_loss: 0.0408, d_fake_loss: 0.0676, g_loss: 1.3487\n",
            "Step [6450/80000], d_real_loss: 0.1347, d_mnist_loss: 0.0722, d_svhn_loss: 0.0624, d_fake_loss: 0.3224, g_loss: 1.2874\n",
            "Step [6460/80000], d_real_loss: 0.1330, d_mnist_loss: 0.0146, d_svhn_loss: 0.1183, d_fake_loss: 0.0940, g_loss: 1.0178\n",
            "Step [6470/80000], d_real_loss: 0.1673, d_mnist_loss: 0.0211, d_svhn_loss: 0.1462, d_fake_loss: 0.2123, g_loss: 1.1430\n",
            "Step [6480/80000], d_real_loss: 0.1769, d_mnist_loss: 0.0059, d_svhn_loss: 0.1710, d_fake_loss: 0.2716, g_loss: 1.2469\n",
            "Step [6490/80000], d_real_loss: 0.1380, d_mnist_loss: 0.0108, d_svhn_loss: 0.1272, d_fake_loss: 0.0803, g_loss: 1.1260\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [6500/80000], d_real_loss: 0.3218, d_mnist_loss: 0.0078, d_svhn_loss: 0.3140, d_fake_loss: 0.1244, g_loss: 1.2865\n",
            "saved ./samples_mnist_svhn/sample-6500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-6500-s-m.png\n",
            "Step [6510/80000], d_real_loss: 0.1146, d_mnist_loss: 0.0122, d_svhn_loss: 0.1025, d_fake_loss: 0.0714, g_loss: 1.1837\n",
            "Step [6520/80000], d_real_loss: 0.2003, d_mnist_loss: 0.0058, d_svhn_loss: 0.1945, d_fake_loss: 0.2232, g_loss: 1.2939\n",
            "Step [6530/80000], d_real_loss: 0.1793, d_mnist_loss: 0.0069, d_svhn_loss: 0.1724, d_fake_loss: 0.1854, g_loss: 1.3610\n",
            "Step [6540/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0061, d_svhn_loss: 0.0624, d_fake_loss: 0.0731, g_loss: 1.4788\n",
            "Step [6550/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0194, d_svhn_loss: 0.0347, d_fake_loss: 0.0938, g_loss: 1.5719\n",
            "Step [6560/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0281, d_svhn_loss: 0.0464, d_fake_loss: 0.1277, g_loss: 1.2038\n",
            "Step [6570/80000], d_real_loss: 0.7735, d_mnist_loss: 0.0507, d_svhn_loss: 0.7228, d_fake_loss: 0.7636, g_loss: 1.4221\n",
            "Step [6580/80000], d_real_loss: 0.1895, d_mnist_loss: 0.0231, d_svhn_loss: 0.1664, d_fake_loss: 0.2017, g_loss: 1.3264\n",
            "Step [6590/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0070, d_svhn_loss: 0.0337, d_fake_loss: 0.0709, g_loss: 1.0652\n",
            "Step [6600/80000], d_real_loss: 0.1123, d_mnist_loss: 0.0626, d_svhn_loss: 0.0497, d_fake_loss: 0.1220, g_loss: 1.6500\n",
            "Step [6610/80000], d_real_loss: 0.0818, d_mnist_loss: 0.0211, d_svhn_loss: 0.0608, d_fake_loss: 0.0804, g_loss: 1.2408\n",
            "Step [6620/80000], d_real_loss: 0.2030, d_mnist_loss: 0.1180, d_svhn_loss: 0.0849, d_fake_loss: 0.2444, g_loss: 1.2893\n",
            "Step [6630/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0061, d_svhn_loss: 0.0462, d_fake_loss: 0.2710, g_loss: 1.1987\n",
            "Step [6640/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0100, d_svhn_loss: 0.0492, d_fake_loss: 0.0533, g_loss: 1.0479\n",
            "Step [6650/80000], d_real_loss: 0.1304, d_mnist_loss: 0.0493, d_svhn_loss: 0.0812, d_fake_loss: 0.0778, g_loss: 1.6832\n",
            "Step [6660/80000], d_real_loss: 0.0869, d_mnist_loss: 0.0047, d_svhn_loss: 0.0823, d_fake_loss: 0.1877, g_loss: 1.3376\n",
            "Step [6670/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0072, d_svhn_loss: 0.0407, d_fake_loss: 0.0553, g_loss: 1.1371\n",
            "Step [6680/80000], d_real_loss: 0.1477, d_mnist_loss: 0.0079, d_svhn_loss: 0.1398, d_fake_loss: 0.0547, g_loss: 1.2243\n",
            "Step [6690/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0175, d_svhn_loss: 0.0539, d_fake_loss: 0.0782, g_loss: 1.4219\n",
            "Step [6700/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0079, d_svhn_loss: 0.0583, d_fake_loss: 0.0830, g_loss: 1.1682\n",
            "Step [6710/80000], d_real_loss: 0.1798, d_mnist_loss: 0.1059, d_svhn_loss: 0.0739, d_fake_loss: 0.0857, g_loss: 1.2173\n",
            "Step [6720/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0555, d_svhn_loss: 0.0337, d_fake_loss: 0.0403, g_loss: 0.9439\n",
            "Step [6730/80000], d_real_loss: 0.1417, d_mnist_loss: 0.0065, d_svhn_loss: 0.1352, d_fake_loss: 0.0557, g_loss: 1.3699\n",
            "Step [6740/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0223, d_svhn_loss: 0.0476, d_fake_loss: 0.0659, g_loss: 0.9319\n",
            "Step [6750/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0226, d_svhn_loss: 0.0459, d_fake_loss: 0.0394, g_loss: 1.2373\n",
            "Step [6760/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0210, d_svhn_loss: 0.0430, d_fake_loss: 0.3290, g_loss: 0.8837\n",
            "Step [6770/80000], d_real_loss: 0.0876, d_mnist_loss: 0.0060, d_svhn_loss: 0.0816, d_fake_loss: 0.0935, g_loss: 1.2735\n",
            "Step [6780/80000], d_real_loss: 0.1979, d_mnist_loss: 0.0159, d_svhn_loss: 0.1820, d_fake_loss: 0.3723, g_loss: 1.0865\n",
            "Step [6790/80000], d_real_loss: 0.3429, d_mnist_loss: 0.0034, d_svhn_loss: 0.3395, d_fake_loss: 0.1664, g_loss: 0.8520\n",
            "Step [6800/80000], d_real_loss: 0.2257, d_mnist_loss: 0.0475, d_svhn_loss: 0.1782, d_fake_loss: 0.2639, g_loss: 1.3106\n",
            "Step [6810/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0149, d_svhn_loss: 0.0583, d_fake_loss: 0.0820, g_loss: 1.0092\n",
            "Step [6820/80000], d_real_loss: 0.1345, d_mnist_loss: 0.0142, d_svhn_loss: 0.1203, d_fake_loss: 0.3685, g_loss: 1.2664\n",
            "Step [6830/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0100, d_svhn_loss: 0.0705, d_fake_loss: 0.0645, g_loss: 0.9751\n",
            "Step [6840/80000], d_real_loss: 0.1791, d_mnist_loss: 0.0184, d_svhn_loss: 0.1607, d_fake_loss: 0.2407, g_loss: 1.4841\n",
            "Step [6850/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0061, d_svhn_loss: 0.1017, d_fake_loss: 0.0823, g_loss: 1.0166\n",
            "Step [6860/80000], d_real_loss: 0.0986, d_mnist_loss: 0.0542, d_svhn_loss: 0.0445, d_fake_loss: 0.1303, g_loss: 1.3799\n",
            "Step [6870/80000], d_real_loss: 0.1001, d_mnist_loss: 0.0038, d_svhn_loss: 0.0964, d_fake_loss: 0.0498, g_loss: 1.2407\n",
            "Step [6880/80000], d_real_loss: 0.1499, d_mnist_loss: 0.0076, d_svhn_loss: 0.1423, d_fake_loss: 0.1116, g_loss: 0.8883\n",
            "Step [6890/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0093, d_svhn_loss: 0.0380, d_fake_loss: 0.0422, g_loss: 1.3891\n",
            "Step [6900/80000], d_real_loss: 0.1483, d_mnist_loss: 0.0231, d_svhn_loss: 0.1252, d_fake_loss: 0.2122, g_loss: 1.0205\n",
            "Step [6910/80000], d_real_loss: 0.0869, d_mnist_loss: 0.0157, d_svhn_loss: 0.0712, d_fake_loss: 0.0302, g_loss: 1.2301\n",
            "Step [6920/80000], d_real_loss: 0.1200, d_mnist_loss: 0.0133, d_svhn_loss: 0.1067, d_fake_loss: 0.1059, g_loss: 1.5684\n",
            "Step [6930/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0240, d_svhn_loss: 0.0603, d_fake_loss: 0.1206, g_loss: 1.2676\n",
            "Step [6940/80000], d_real_loss: 0.1650, d_mnist_loss: 0.0065, d_svhn_loss: 0.1585, d_fake_loss: 0.2140, g_loss: 1.3297\n",
            "Step [6950/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0087, d_svhn_loss: 0.0506, d_fake_loss: 0.0474, g_loss: 1.1717\n",
            "Step [6960/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0035, d_svhn_loss: 0.0804, d_fake_loss: 0.1606, g_loss: 1.6526\n",
            "Step [6970/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0044, d_svhn_loss: 0.0427, d_fake_loss: 0.0862, g_loss: 1.4182\n",
            "Step [6980/80000], d_real_loss: 0.2326, d_mnist_loss: 0.0063, d_svhn_loss: 0.2262, d_fake_loss: 0.0639, g_loss: 1.0200\n",
            "Step [6990/80000], d_real_loss: 0.1370, d_mnist_loss: 0.0691, d_svhn_loss: 0.0679, d_fake_loss: 0.0443, g_loss: 1.1402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [7000/80000], d_real_loss: 0.1167, d_mnist_loss: 0.0038, d_svhn_loss: 0.1130, d_fake_loss: 0.0557, g_loss: 1.1739\n",
            "saved ./samples_mnist_svhn/sample-7000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-7000-s-m.png\n",
            "Step [7010/80000], d_real_loss: 0.0895, d_mnist_loss: 0.0053, d_svhn_loss: 0.0842, d_fake_loss: 0.0865, g_loss: 1.3884\n",
            "Step [7020/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0038, d_svhn_loss: 0.0802, d_fake_loss: 0.0509, g_loss: 1.0981\n",
            "Step [7030/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0221, d_svhn_loss: 0.0564, d_fake_loss: 0.0695, g_loss: 1.4380\n",
            "Step [7040/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0104, d_svhn_loss: 0.0394, d_fake_loss: 0.1307, g_loss: 1.2742\n",
            "Step [7050/80000], d_real_loss: 0.1710, d_mnist_loss: 0.0528, d_svhn_loss: 0.1182, d_fake_loss: 0.2398, g_loss: 1.3780\n",
            "Step [7060/80000], d_real_loss: 0.3969, d_mnist_loss: 0.3654, d_svhn_loss: 0.0315, d_fake_loss: 0.8424, g_loss: 2.7137\n",
            "Step [7070/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0160, d_svhn_loss: 0.0391, d_fake_loss: 0.0858, g_loss: 0.9059\n",
            "Step [7080/80000], d_real_loss: 0.0757, d_mnist_loss: 0.0239, d_svhn_loss: 0.0517, d_fake_loss: 0.0629, g_loss: 1.2254\n",
            "Step [7090/80000], d_real_loss: 0.1293, d_mnist_loss: 0.0332, d_svhn_loss: 0.0961, d_fake_loss: 0.0835, g_loss: 1.2083\n",
            "Step [7100/80000], d_real_loss: 0.2051, d_mnist_loss: 0.0341, d_svhn_loss: 0.1710, d_fake_loss: 0.0571, g_loss: 1.2069\n",
            "Step [7110/80000], d_real_loss: 0.1641, d_mnist_loss: 0.0339, d_svhn_loss: 0.1302, d_fake_loss: 0.0994, g_loss: 1.0150\n",
            "Step [7120/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0362, d_svhn_loss: 0.0383, d_fake_loss: 0.0623, g_loss: 1.3967\n",
            "Step [7130/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0051, d_svhn_loss: 0.0503, d_fake_loss: 0.2565, g_loss: 1.8946\n",
            "Step [7140/80000], d_real_loss: 0.1871, d_mnist_loss: 0.0104, d_svhn_loss: 0.1767, d_fake_loss: 0.0952, g_loss: 1.0397\n",
            "Step [7150/80000], d_real_loss: 0.2771, d_mnist_loss: 0.0071, d_svhn_loss: 0.2700, d_fake_loss: 0.0863, g_loss: 1.2913\n",
            "Step [7160/80000], d_real_loss: 0.0823, d_mnist_loss: 0.0099, d_svhn_loss: 0.0724, d_fake_loss: 0.0690, g_loss: 1.3056\n",
            "Step [7170/80000], d_real_loss: 0.1973, d_mnist_loss: 0.0493, d_svhn_loss: 0.1479, d_fake_loss: 0.1062, g_loss: 1.2955\n",
            "Step [7180/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0056, d_svhn_loss: 0.0241, d_fake_loss: 0.0533, g_loss: 1.0963\n",
            "Step [7190/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0079, d_svhn_loss: 0.0312, d_fake_loss: 0.0675, g_loss: 1.3183\n",
            "Step [7200/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0155, d_svhn_loss: 0.0587, d_fake_loss: 0.1420, g_loss: 1.2119\n",
            "Step [7210/80000], d_real_loss: 0.1263, d_mnist_loss: 0.0044, d_svhn_loss: 0.1219, d_fake_loss: 0.1265, g_loss: 0.9906\n",
            "Step [7220/80000], d_real_loss: 0.0891, d_mnist_loss: 0.0070, d_svhn_loss: 0.0820, d_fake_loss: 0.1078, g_loss: 1.3855\n",
            "Step [7230/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0051, d_svhn_loss: 0.0634, d_fake_loss: 0.0456, g_loss: 1.0617\n",
            "Step [7240/80000], d_real_loss: 0.0897, d_mnist_loss: 0.0375, d_svhn_loss: 0.0522, d_fake_loss: 0.0772, g_loss: 1.4271\n",
            "Step [7250/80000], d_real_loss: 0.1466, d_mnist_loss: 0.0158, d_svhn_loss: 0.1309, d_fake_loss: 0.0495, g_loss: 0.9356\n",
            "Step [7260/80000], d_real_loss: 0.1531, d_mnist_loss: 0.0263, d_svhn_loss: 0.1268, d_fake_loss: 0.1962, g_loss: 1.0172\n",
            "Step [7270/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0113, d_svhn_loss: 0.0467, d_fake_loss: 0.0890, g_loss: 1.2943\n",
            "Step [7280/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0054, d_svhn_loss: 0.0560, d_fake_loss: 0.0655, g_loss: 1.3377\n",
            "Step [7290/80000], d_real_loss: 0.1173, d_mnist_loss: 0.0231, d_svhn_loss: 0.0942, d_fake_loss: 0.1425, g_loss: 1.6564\n",
            "Step [7300/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0113, d_svhn_loss: 0.0720, d_fake_loss: 0.1379, g_loss: 1.2028\n",
            "Step [7310/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0110, d_svhn_loss: 0.0467, d_fake_loss: 0.0649, g_loss: 0.9990\n",
            "Step [7320/80000], d_real_loss: 0.2022, d_mnist_loss: 0.1353, d_svhn_loss: 0.0670, d_fake_loss: 0.0511, g_loss: 1.2772\n",
            "Step [7330/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0057, d_svhn_loss: 0.0489, d_fake_loss: 0.1653, g_loss: 1.1321\n",
            "Step [7340/80000], d_real_loss: 0.0899, d_mnist_loss: 0.0116, d_svhn_loss: 0.0782, d_fake_loss: 0.0632, g_loss: 1.6025\n",
            "Step [7350/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0068, d_svhn_loss: 0.0271, d_fake_loss: 0.0548, g_loss: 0.9965\n",
            "Step [7360/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0117, d_svhn_loss: 0.0612, d_fake_loss: 0.1602, g_loss: 1.3456\n",
            "Step [7370/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0074, d_svhn_loss: 0.0700, d_fake_loss: 0.0518, g_loss: 1.3399\n",
            "Step [7380/80000], d_real_loss: 0.1218, d_mnist_loss: 0.0125, d_svhn_loss: 0.1093, d_fake_loss: 0.0902, g_loss: 0.9229\n",
            "Step [7390/80000], d_real_loss: 0.1635, d_mnist_loss: 0.0478, d_svhn_loss: 0.1157, d_fake_loss: 0.1429, g_loss: 1.2650\n",
            "Step [7400/80000], d_real_loss: 0.1082, d_mnist_loss: 0.0318, d_svhn_loss: 0.0764, d_fake_loss: 0.0640, g_loss: 1.0604\n",
            "Step [7410/80000], d_real_loss: 0.1743, d_mnist_loss: 0.0633, d_svhn_loss: 0.1110, d_fake_loss: 0.0737, g_loss: 1.3781\n",
            "Step [7420/80000], d_real_loss: 0.2190, d_mnist_loss: 0.0129, d_svhn_loss: 0.2061, d_fake_loss: 0.1309, g_loss: 1.2334\n",
            "Step [7430/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0426, d_svhn_loss: 0.0565, d_fake_loss: 0.0756, g_loss: 1.3329\n",
            "Step [7440/80000], d_real_loss: 0.1709, d_mnist_loss: 0.0332, d_svhn_loss: 0.1377, d_fake_loss: 0.2692, g_loss: 1.6330\n",
            "Step [7450/80000], d_real_loss: 0.1187, d_mnist_loss: 0.0077, d_svhn_loss: 0.1110, d_fake_loss: 0.0729, g_loss: 0.9870\n",
            "Step [7460/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0211, d_svhn_loss: 0.0599, d_fake_loss: 0.1312, g_loss: 1.4719\n",
            "Step [7470/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0394, d_svhn_loss: 0.0556, d_fake_loss: 0.0927, g_loss: 0.9898\n",
            "Step [7480/80000], d_real_loss: 0.1485, d_mnist_loss: 0.0458, d_svhn_loss: 0.1027, d_fake_loss: 0.0456, g_loss: 1.0994\n",
            "Step [7490/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0130, d_svhn_loss: 0.0566, d_fake_loss: 0.0988, g_loss: 1.1561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [7500/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0274, d_svhn_loss: 0.0526, d_fake_loss: 0.0920, g_loss: 1.3722\n",
            "saved ./samples_mnist_svhn/sample-7500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-7500-s-m.png\n",
            "Step [7510/80000], d_real_loss: 0.1003, d_mnist_loss: 0.0487, d_svhn_loss: 0.0517, d_fake_loss: 0.1640, g_loss: 1.2601\n",
            "Step [7520/80000], d_real_loss: 0.0962, d_mnist_loss: 0.0031, d_svhn_loss: 0.0931, d_fake_loss: 0.0323, g_loss: 1.1810\n",
            "Step [7530/80000], d_real_loss: 0.1012, d_mnist_loss: 0.0170, d_svhn_loss: 0.0841, d_fake_loss: 0.0449, g_loss: 1.1524\n",
            "Step [7540/80000], d_real_loss: 0.0896, d_mnist_loss: 0.0211, d_svhn_loss: 0.0685, d_fake_loss: 0.1015, g_loss: 1.4400\n",
            "Step [7550/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0048, d_svhn_loss: 0.0637, d_fake_loss: 0.1797, g_loss: 1.2201\n",
            "Step [7560/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0118, d_svhn_loss: 0.0456, d_fake_loss: 0.0435, g_loss: 1.1777\n",
            "Step [7570/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0038, d_svhn_loss: 0.0518, d_fake_loss: 0.0638, g_loss: 1.1465\n",
            "Step [7580/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0053, d_svhn_loss: 0.0857, d_fake_loss: 0.1250, g_loss: 0.7590\n",
            "Step [7590/80000], d_real_loss: 0.1336, d_mnist_loss: 0.0236, d_svhn_loss: 0.1100, d_fake_loss: 0.0487, g_loss: 1.1154\n",
            "Step [7600/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0044, d_svhn_loss: 0.0590, d_fake_loss: 0.0328, g_loss: 1.0834\n",
            "Step [7610/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0029, d_svhn_loss: 0.0276, d_fake_loss: 0.1525, g_loss: 0.8619\n",
            "Step [7620/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0050, d_svhn_loss: 0.0579, d_fake_loss: 0.0554, g_loss: 1.0112\n",
            "Step [7630/80000], d_real_loss: 0.1276, d_mnist_loss: 0.0263, d_svhn_loss: 0.1014, d_fake_loss: 0.1490, g_loss: 1.2401\n",
            "Step [7640/80000], d_real_loss: 0.2394, d_mnist_loss: 0.2023, d_svhn_loss: 0.0371, d_fake_loss: 0.0430, g_loss: 1.3907\n",
            "Step [7650/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0141, d_svhn_loss: 0.0473, d_fake_loss: 0.0549, g_loss: 0.9749\n",
            "Step [7660/80000], d_real_loss: 0.1627, d_mnist_loss: 0.0206, d_svhn_loss: 0.1421, d_fake_loss: 0.0898, g_loss: 1.0743\n",
            "Step [7670/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0082, d_svhn_loss: 0.0509, d_fake_loss: 0.1802, g_loss: 1.3361\n",
            "Step [7680/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0056, d_svhn_loss: 0.0437, d_fake_loss: 0.1643, g_loss: 1.0054\n",
            "Step [7690/80000], d_real_loss: 0.0995, d_mnist_loss: 0.0058, d_svhn_loss: 0.0937, d_fake_loss: 0.0911, g_loss: 1.3279\n",
            "Step [7700/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0262, d_svhn_loss: 0.0469, d_fake_loss: 0.0714, g_loss: 1.0386\n",
            "Step [7710/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0156, d_svhn_loss: 0.0484, d_fake_loss: 0.0523, g_loss: 1.1066\n",
            "Step [7720/80000], d_real_loss: 0.1068, d_mnist_loss: 0.0142, d_svhn_loss: 0.0926, d_fake_loss: 0.1102, g_loss: 1.3627\n",
            "Step [7730/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0441, d_svhn_loss: 0.0452, d_fake_loss: 0.0495, g_loss: 1.1302\n",
            "Step [7740/80000], d_real_loss: 0.3184, d_mnist_loss: 0.0263, d_svhn_loss: 0.2921, d_fake_loss: 0.0676, g_loss: 1.3899\n",
            "Step [7750/80000], d_real_loss: 0.1065, d_mnist_loss: 0.0340, d_svhn_loss: 0.0725, d_fake_loss: 0.0789, g_loss: 1.6871\n",
            "Step [7760/80000], d_real_loss: 0.1812, d_mnist_loss: 0.0139, d_svhn_loss: 0.1673, d_fake_loss: 0.1161, g_loss: 1.1988\n",
            "Step [7770/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0093, d_svhn_loss: 0.0644, d_fake_loss: 0.1162, g_loss: 1.2454\n",
            "Step [7780/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0162, d_svhn_loss: 0.0289, d_fake_loss: 0.0806, g_loss: 1.2801\n",
            "Step [7790/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0049, d_svhn_loss: 0.0427, d_fake_loss: 0.0298, g_loss: 1.1434\n",
            "Step [7800/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0050, d_svhn_loss: 0.0450, d_fake_loss: 0.0959, g_loss: 1.3539\n",
            "Step [7810/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0247, d_svhn_loss: 0.0413, d_fake_loss: 0.0519, g_loss: 1.3264\n",
            "Step [7820/80000], d_real_loss: 0.1213, d_mnist_loss: 0.0613, d_svhn_loss: 0.0600, d_fake_loss: 0.0657, g_loss: 0.8427\n",
            "Step [7830/80000], d_real_loss: 0.2443, d_mnist_loss: 0.0322, d_svhn_loss: 0.2121, d_fake_loss: 0.0959, g_loss: 1.0293\n",
            "Step [7840/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0075, d_svhn_loss: 0.0376, d_fake_loss: 0.0618, g_loss: 1.3012\n",
            "Step [7850/80000], d_real_loss: 0.0872, d_mnist_loss: 0.0101, d_svhn_loss: 0.0771, d_fake_loss: 0.1187, g_loss: 0.9526\n",
            "Step [7860/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0042, d_svhn_loss: 0.0546, d_fake_loss: 0.0720, g_loss: 1.3194\n",
            "Step [7870/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0058, d_svhn_loss: 0.0470, d_fake_loss: 0.0738, g_loss: 1.4681\n",
            "Step [7880/80000], d_real_loss: 0.1912, d_mnist_loss: 0.0594, d_svhn_loss: 0.1318, d_fake_loss: 0.0906, g_loss: 1.5898\n",
            "Step [7890/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0330, d_svhn_loss: 0.0460, d_fake_loss: 0.1427, g_loss: 0.9825\n",
            "Step [7900/80000], d_real_loss: 0.1027, d_mnist_loss: 0.0397, d_svhn_loss: 0.0630, d_fake_loss: 0.0953, g_loss: 1.1504\n",
            "Step [7910/80000], d_real_loss: 0.1797, d_mnist_loss: 0.0150, d_svhn_loss: 0.1648, d_fake_loss: 0.0529, g_loss: 1.0170\n",
            "Step [7920/80000], d_real_loss: 0.1557, d_mnist_loss: 0.0293, d_svhn_loss: 0.1264, d_fake_loss: 0.1763, g_loss: 1.1036\n",
            "Step [7930/80000], d_real_loss: 0.0920, d_mnist_loss: 0.0217, d_svhn_loss: 0.0703, d_fake_loss: 0.1419, g_loss: 1.1962\n",
            "Step [7940/80000], d_real_loss: 0.1533, d_mnist_loss: 0.0378, d_svhn_loss: 0.1155, d_fake_loss: 0.0570, g_loss: 1.0829\n",
            "Step [7950/80000], d_real_loss: 0.1407, d_mnist_loss: 0.0587, d_svhn_loss: 0.0820, d_fake_loss: 0.0510, g_loss: 1.1099\n",
            "Step [7960/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0045, d_svhn_loss: 0.0694, d_fake_loss: 0.0567, g_loss: 1.0818\n",
            "Step [7970/80000], d_real_loss: 0.2059, d_mnist_loss: 0.0451, d_svhn_loss: 0.1608, d_fake_loss: 0.0359, g_loss: 1.0902\n",
            "Step [7980/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0041, d_svhn_loss: 0.0417, d_fake_loss: 0.0291, g_loss: 1.2685\n",
            "Step [7990/80000], d_real_loss: 0.0835, d_mnist_loss: 0.0248, d_svhn_loss: 0.0587, d_fake_loss: 0.0534, g_loss: 1.0732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [8000/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0065, d_svhn_loss: 0.0328, d_fake_loss: 0.0872, g_loss: 1.2455\n",
            "saved ./samples_mnist_svhn/sample-8000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-8000-s-m.png\n",
            "Step [8010/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0369, d_svhn_loss: 0.0427, d_fake_loss: 0.1111, g_loss: 1.6295\n",
            "Step [8020/80000], d_real_loss: 0.1162, d_mnist_loss: 0.0670, d_svhn_loss: 0.0492, d_fake_loss: 0.1684, g_loss: 1.3439\n",
            "Step [8030/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0056, d_svhn_loss: 0.0482, d_fake_loss: 0.0634, g_loss: 1.1989\n",
            "Step [8040/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0036, d_svhn_loss: 0.0478, d_fake_loss: 0.0698, g_loss: 1.2077\n",
            "Step [8050/80000], d_real_loss: 0.1998, d_mnist_loss: 0.0304, d_svhn_loss: 0.1693, d_fake_loss: 0.0575, g_loss: 1.3895\n",
            "Step [8060/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0183, d_svhn_loss: 0.0346, d_fake_loss: 0.1332, g_loss: 0.9473\n",
            "Step [8070/80000], d_real_loss: 0.7794, d_mnist_loss: 0.0108, d_svhn_loss: 0.7686, d_fake_loss: 0.2699, g_loss: 1.1364\n",
            "Step [8080/80000], d_real_loss: 0.1618, d_mnist_loss: 0.0156, d_svhn_loss: 0.1462, d_fake_loss: 0.0848, g_loss: 1.4213\n",
            "Step [8090/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0093, d_svhn_loss: 0.0596, d_fake_loss: 0.0569, g_loss: 1.2260\n",
            "Step [8100/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0127, d_svhn_loss: 0.0446, d_fake_loss: 0.0275, g_loss: 1.4575\n",
            "Step [8110/80000], d_real_loss: 0.1395, d_mnist_loss: 0.0723, d_svhn_loss: 0.0672, d_fake_loss: 0.1021, g_loss: 1.4018\n",
            "Step [8120/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0052, d_svhn_loss: 0.0864, d_fake_loss: 0.0806, g_loss: 0.9672\n",
            "Step [8130/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0029, d_svhn_loss: 0.0427, d_fake_loss: 0.0690, g_loss: 1.0617\n",
            "Step [8140/80000], d_real_loss: 0.1666, d_mnist_loss: 0.0038, d_svhn_loss: 0.1628, d_fake_loss: 0.1374, g_loss: 1.3635\n",
            "Step [8150/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0304, d_svhn_loss: 0.0461, d_fake_loss: 0.1984, g_loss: 1.4208\n",
            "Step [8160/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0037, d_svhn_loss: 0.0652, d_fake_loss: 0.0373, g_loss: 1.1979\n",
            "Step [8170/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0041, d_svhn_loss: 0.0438, d_fake_loss: 0.0368, g_loss: 1.2419\n",
            "Step [8180/80000], d_real_loss: 0.1952, d_mnist_loss: 0.0047, d_svhn_loss: 0.1905, d_fake_loss: 0.0418, g_loss: 1.3313\n",
            "Step [8190/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0049, d_svhn_loss: 0.0396, d_fake_loss: 0.0627, g_loss: 1.1681\n",
            "Step [8200/80000], d_real_loss: 0.2069, d_mnist_loss: 0.0321, d_svhn_loss: 0.1748, d_fake_loss: 0.0432, g_loss: 1.5631\n",
            "Step [8210/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0064, d_svhn_loss: 0.0453, d_fake_loss: 0.2929, g_loss: 1.1242\n",
            "Step [8220/80000], d_real_loss: 0.1139, d_mnist_loss: 0.0156, d_svhn_loss: 0.0982, d_fake_loss: 0.1366, g_loss: 1.1714\n",
            "Step [8230/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0045, d_svhn_loss: 0.0498, d_fake_loss: 0.0936, g_loss: 0.8945\n",
            "Step [8240/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0061, d_svhn_loss: 0.0637, d_fake_loss: 0.0463, g_loss: 1.2877\n",
            "Step [8250/80000], d_real_loss: 0.1121, d_mnist_loss: 0.0092, d_svhn_loss: 0.1029, d_fake_loss: 0.0262, g_loss: 1.2024\n",
            "Step [8260/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0025, d_svhn_loss: 0.0531, d_fake_loss: 0.0405, g_loss: 1.0340\n",
            "Step [8270/80000], d_real_loss: 0.2076, d_mnist_loss: 0.0202, d_svhn_loss: 0.1873, d_fake_loss: 0.0791, g_loss: 1.3843\n",
            "Step [8280/80000], d_real_loss: 0.2502, d_mnist_loss: 0.0456, d_svhn_loss: 0.2046, d_fake_loss: 0.0939, g_loss: 1.3115\n",
            "Step [8290/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0042, d_svhn_loss: 0.0598, d_fake_loss: 0.0415, g_loss: 1.1682\n",
            "Step [8300/80000], d_real_loss: 0.1482, d_mnist_loss: 0.0718, d_svhn_loss: 0.0764, d_fake_loss: 0.0791, g_loss: 1.2405\n",
            "Step [8310/80000], d_real_loss: 0.2095, d_mnist_loss: 0.0867, d_svhn_loss: 0.1228, d_fake_loss: 0.1812, g_loss: 2.1722\n",
            "Step [8320/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0246, d_svhn_loss: 0.0346, d_fake_loss: 0.0727, g_loss: 1.0340\n",
            "Step [8330/80000], d_real_loss: 0.0920, d_mnist_loss: 0.0058, d_svhn_loss: 0.0862, d_fake_loss: 0.0736, g_loss: 1.5065\n",
            "Step [8340/80000], d_real_loss: 0.1145, d_mnist_loss: 0.0464, d_svhn_loss: 0.0681, d_fake_loss: 0.1453, g_loss: 1.4465\n",
            "Step [8350/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0110, d_svhn_loss: 0.0621, d_fake_loss: 0.2635, g_loss: 1.3310\n",
            "Step [8360/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0061, d_svhn_loss: 0.0465, d_fake_loss: 0.0336, g_loss: 1.0942\n",
            "Step [8370/80000], d_real_loss: 0.2905, d_mnist_loss: 0.0032, d_svhn_loss: 0.2873, d_fake_loss: 0.1404, g_loss: 1.0789\n",
            "Step [8380/80000], d_real_loss: 0.0953, d_mnist_loss: 0.0359, d_svhn_loss: 0.0594, d_fake_loss: 0.0851, g_loss: 1.4284\n",
            "Step [8390/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0103, d_svhn_loss: 0.0743, d_fake_loss: 0.2018, g_loss: 1.2238\n",
            "Step [8400/80000], d_real_loss: 0.1846, d_mnist_loss: 0.0110, d_svhn_loss: 0.1736, d_fake_loss: 0.0603, g_loss: 1.0428\n",
            "Step [8410/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0047, d_svhn_loss: 0.0452, d_fake_loss: 0.0593, g_loss: 1.2187\n",
            "Step [8420/80000], d_real_loss: 0.1028, d_mnist_loss: 0.0224, d_svhn_loss: 0.0804, d_fake_loss: 0.0429, g_loss: 0.8962\n",
            "Step [8430/80000], d_real_loss: 0.2028, d_mnist_loss: 0.0185, d_svhn_loss: 0.1844, d_fake_loss: 0.0739, g_loss: 1.0802\n",
            "Step [8440/80000], d_real_loss: 0.1924, d_mnist_loss: 0.0903, d_svhn_loss: 0.1021, d_fake_loss: 0.1110, g_loss: 1.1913\n",
            "Step [8450/80000], d_real_loss: 0.1933, d_mnist_loss: 0.1336, d_svhn_loss: 0.0596, d_fake_loss: 0.1055, g_loss: 1.3257\n",
            "Step [8460/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0081, d_svhn_loss: 0.0682, d_fake_loss: 0.0769, g_loss: 1.0470\n",
            "Step [8470/80000], d_real_loss: 0.1717, d_mnist_loss: 0.0057, d_svhn_loss: 0.1660, d_fake_loss: 0.0657, g_loss: 1.1007\n",
            "Step [8480/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0038, d_svhn_loss: 0.0475, d_fake_loss: 0.0665, g_loss: 1.3691\n",
            "Step [8490/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0105, d_svhn_loss: 0.0501, d_fake_loss: 0.0610, g_loss: 1.2663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [8500/80000], d_real_loss: 0.0757, d_mnist_loss: 0.0358, d_svhn_loss: 0.0399, d_fake_loss: 0.1538, g_loss: 1.5776\n",
            "saved ./samples_mnist_svhn/sample-8500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-8500-s-m.png\n",
            "Step [8510/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0231, d_svhn_loss: 0.0439, d_fake_loss: 0.0798, g_loss: 0.9825\n",
            "Step [8520/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0064, d_svhn_loss: 0.0561, d_fake_loss: 0.0850, g_loss: 1.1156\n",
            "Step [8530/80000], d_real_loss: 0.1157, d_mnist_loss: 0.0042, d_svhn_loss: 0.1115, d_fake_loss: 0.0519, g_loss: 1.2758\n",
            "Step [8540/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0115, d_svhn_loss: 0.0557, d_fake_loss: 0.0383, g_loss: 1.0811\n",
            "Step [8550/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0031, d_svhn_loss: 0.0537, d_fake_loss: 0.0271, g_loss: 1.1869\n",
            "Step [8560/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0182, d_svhn_loss: 0.0332, d_fake_loss: 0.0749, g_loss: 0.9950\n",
            "Step [8570/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0041, d_svhn_loss: 0.0358, d_fake_loss: 0.0487, g_loss: 0.9812\n",
            "Step [8580/80000], d_real_loss: 0.1729, d_mnist_loss: 0.1260, d_svhn_loss: 0.0469, d_fake_loss: 0.3708, g_loss: 1.9167\n",
            "Step [8590/80000], d_real_loss: 0.0751, d_mnist_loss: 0.0205, d_svhn_loss: 0.0546, d_fake_loss: 0.0708, g_loss: 1.1072\n",
            "Step [8600/80000], d_real_loss: 0.0862, d_mnist_loss: 0.0036, d_svhn_loss: 0.0826, d_fake_loss: 0.0517, g_loss: 1.0772\n",
            "Step [8610/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0038, d_svhn_loss: 0.0378, d_fake_loss: 0.0568, g_loss: 1.2793\n",
            "Step [8620/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0059, d_svhn_loss: 0.0589, d_fake_loss: 0.0713, g_loss: 1.1344\n",
            "Step [8630/80000], d_real_loss: 0.2691, d_mnist_loss: 0.0651, d_svhn_loss: 0.2040, d_fake_loss: 0.3213, g_loss: 1.3658\n",
            "Step [8640/80000], d_real_loss: 0.1419, d_mnist_loss: 0.0377, d_svhn_loss: 0.1043, d_fake_loss: 0.0670, g_loss: 1.1140\n",
            "Step [8650/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0161, d_svhn_loss: 0.0455, d_fake_loss: 0.0817, g_loss: 1.4284\n",
            "Step [8660/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0038, d_svhn_loss: 0.0573, d_fake_loss: 0.1678, g_loss: 1.5088\n",
            "Step [8670/80000], d_real_loss: 0.1493, d_mnist_loss: 0.0220, d_svhn_loss: 0.1273, d_fake_loss: 0.0407, g_loss: 1.1368\n",
            "Step [8680/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0135, d_svhn_loss: 0.0506, d_fake_loss: 0.0713, g_loss: 1.0444\n",
            "Step [8690/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0189, d_svhn_loss: 0.0371, d_fake_loss: 0.0980, g_loss: 1.3422\n",
            "Step [8700/80000], d_real_loss: 0.1250, d_mnist_loss: 0.0595, d_svhn_loss: 0.0656, d_fake_loss: 0.2069, g_loss: 0.8514\n",
            "Step [8710/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0035, d_svhn_loss: 0.0524, d_fake_loss: 0.0954, g_loss: 1.0444\n",
            "Step [8720/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0091, d_svhn_loss: 0.0391, d_fake_loss: 0.1154, g_loss: 0.7964\n",
            "Step [8730/80000], d_real_loss: 0.1228, d_mnist_loss: 0.0193, d_svhn_loss: 0.1036, d_fake_loss: 0.2883, g_loss: 0.9871\n",
            "Step [8740/80000], d_real_loss: 0.2821, d_mnist_loss: 0.2237, d_svhn_loss: 0.0584, d_fake_loss: 0.4187, g_loss: 2.1934\n",
            "Step [8750/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0125, d_svhn_loss: 0.0302, d_fake_loss: 0.0397, g_loss: 1.1181\n",
            "Step [8760/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0124, d_svhn_loss: 0.0825, d_fake_loss: 0.0520, g_loss: 1.1812\n",
            "Step [8770/80000], d_real_loss: 0.1539, d_mnist_loss: 0.0402, d_svhn_loss: 0.1137, d_fake_loss: 0.3226, g_loss: 1.4960\n",
            "Step [8780/80000], d_real_loss: 0.1614, d_mnist_loss: 0.0185, d_svhn_loss: 0.1429, d_fake_loss: 0.0452, g_loss: 1.1872\n",
            "Step [8790/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0301, d_svhn_loss: 0.0505, d_fake_loss: 0.0730, g_loss: 1.2530\n",
            "Step [8800/80000], d_real_loss: 0.1079, d_mnist_loss: 0.0216, d_svhn_loss: 0.0863, d_fake_loss: 0.0737, g_loss: 0.9001\n",
            "Step [8810/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0297, d_svhn_loss: 0.0295, d_fake_loss: 0.0459, g_loss: 1.3304\n",
            "Step [8820/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0246, d_svhn_loss: 0.0343, d_fake_loss: 0.1039, g_loss: 1.2530\n",
            "Step [8830/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0195, d_svhn_loss: 0.0445, d_fake_loss: 0.0718, g_loss: 1.1643\n",
            "Step [8840/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0071, d_svhn_loss: 0.0321, d_fake_loss: 0.0547, g_loss: 1.1504\n",
            "Step [8850/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0053, d_svhn_loss: 0.0752, d_fake_loss: 0.1095, g_loss: 1.0934\n",
            "Step [8860/80000], d_real_loss: 0.0946, d_mnist_loss: 0.0071, d_svhn_loss: 0.0875, d_fake_loss: 0.1982, g_loss: 1.0683\n",
            "Step [8870/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0110, d_svhn_loss: 0.0392, d_fake_loss: 0.1104, g_loss: 1.2651\n",
            "Step [8880/80000], d_real_loss: 0.0705, d_mnist_loss: 0.0081, d_svhn_loss: 0.0624, d_fake_loss: 0.1279, g_loss: 1.0699\n",
            "Step [8890/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0074, d_svhn_loss: 0.0324, d_fake_loss: 0.0864, g_loss: 1.0767\n",
            "Step [8900/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0204, d_svhn_loss: 0.0462, d_fake_loss: 0.0308, g_loss: 0.9268\n",
            "Step [8910/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0321, d_svhn_loss: 0.0462, d_fake_loss: 0.0378, g_loss: 1.0010\n",
            "Step [8920/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0275, d_svhn_loss: 0.0564, d_fake_loss: 0.0434, g_loss: 1.1849\n",
            "Step [8930/80000], d_real_loss: 0.0863, d_mnist_loss: 0.0257, d_svhn_loss: 0.0606, d_fake_loss: 0.0688, g_loss: 1.1409\n",
            "Step [8940/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0166, d_svhn_loss: 0.0556, d_fake_loss: 0.1464, g_loss: 1.3740\n",
            "Step [8950/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0045, d_svhn_loss: 0.0353, d_fake_loss: 0.0644, g_loss: 0.9909\n",
            "Step [8960/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0033, d_svhn_loss: 0.0638, d_fake_loss: 0.0735, g_loss: 1.3656\n",
            "Step [8970/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0124, d_svhn_loss: 0.0316, d_fake_loss: 0.0391, g_loss: 1.0622\n",
            "Step [8980/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0210, d_svhn_loss: 0.0386, d_fake_loss: 0.0637, g_loss: 1.3929\n",
            "Step [8990/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0038, d_svhn_loss: 0.0585, d_fake_loss: 0.0492, g_loss: 1.3463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [9000/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0049, d_svhn_loss: 0.0339, d_fake_loss: 0.0301, g_loss: 1.1604\n",
            "saved ./samples_mnist_svhn/sample-9000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-9000-s-m.png\n",
            "Step [9010/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0049, d_svhn_loss: 0.0598, d_fake_loss: 0.0797, g_loss: 1.1825\n",
            "Step [9020/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0042, d_svhn_loss: 0.0498, d_fake_loss: 0.0338, g_loss: 1.3009\n",
            "Step [9030/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0173, d_svhn_loss: 0.0468, d_fake_loss: 0.0723, g_loss: 1.2288\n",
            "Step [9040/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0035, d_svhn_loss: 0.0271, d_fake_loss: 0.0284, g_loss: 1.0530\n",
            "Step [9050/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0054, d_svhn_loss: 0.0594, d_fake_loss: 0.0817, g_loss: 1.0936\n",
            "Step [9060/80000], d_real_loss: 0.1181, d_mnist_loss: 0.0185, d_svhn_loss: 0.0996, d_fake_loss: 0.0718, g_loss: 1.1028\n",
            "Step [9070/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0031, d_svhn_loss: 0.0561, d_fake_loss: 0.0626, g_loss: 1.0827\n",
            "Step [9080/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0030, d_svhn_loss: 0.0535, d_fake_loss: 0.0716, g_loss: 1.2220\n",
            "Step [9090/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0052, d_svhn_loss: 0.0529, d_fake_loss: 0.0645, g_loss: 1.1806\n",
            "Step [9100/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0069, d_svhn_loss: 0.0532, d_fake_loss: 0.0516, g_loss: 1.0104\n",
            "Step [9110/80000], d_real_loss: 0.1279, d_mnist_loss: 0.0612, d_svhn_loss: 0.0667, d_fake_loss: 0.0688, g_loss: 1.2928\n",
            "Step [9120/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0052, d_svhn_loss: 0.0484, d_fake_loss: 0.1015, g_loss: 1.0636\n",
            "Step [9130/80000], d_real_loss: 0.1049, d_mnist_loss: 0.0420, d_svhn_loss: 0.0629, d_fake_loss: 0.1939, g_loss: 0.7885\n",
            "Step [9140/80000], d_real_loss: 0.1538, d_mnist_loss: 0.0078, d_svhn_loss: 0.1460, d_fake_loss: 0.0462, g_loss: 1.0784\n",
            "Step [9150/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0452, d_svhn_loss: 0.0279, d_fake_loss: 0.0446, g_loss: 0.9941\n",
            "Step [9160/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0085, d_svhn_loss: 0.0274, d_fake_loss: 0.0912, g_loss: 1.0186\n",
            "Step [9170/80000], d_real_loss: 0.0695, d_mnist_loss: 0.0329, d_svhn_loss: 0.0366, d_fake_loss: 0.0958, g_loss: 1.3734\n",
            "Step [9180/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0092, d_svhn_loss: 0.0554, d_fake_loss: 0.0356, g_loss: 0.9838\n",
            "Step [9190/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0051, d_svhn_loss: 0.0379, d_fake_loss: 0.0365, g_loss: 1.2259\n",
            "Step [9200/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0161, d_svhn_loss: 0.0428, d_fake_loss: 0.0866, g_loss: 0.9375\n",
            "Step [9210/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0161, d_svhn_loss: 0.0428, d_fake_loss: 0.1410, g_loss: 1.2907\n",
            "Step [9220/80000], d_real_loss: 0.0962, d_mnist_loss: 0.0182, d_svhn_loss: 0.0780, d_fake_loss: 0.0491, g_loss: 1.1648\n",
            "Step [9230/80000], d_real_loss: 0.1010, d_mnist_loss: 0.0067, d_svhn_loss: 0.0942, d_fake_loss: 0.1657, g_loss: 1.0278\n",
            "Step [9240/80000], d_real_loss: 0.1201, d_mnist_loss: 0.0843, d_svhn_loss: 0.0358, d_fake_loss: 0.0551, g_loss: 1.2390\n",
            "Step [9250/80000], d_real_loss: 0.2207, d_mnist_loss: 0.0131, d_svhn_loss: 0.2076, d_fake_loss: 0.1181, g_loss: 1.3590\n",
            "Step [9260/80000], d_real_loss: 0.0807, d_mnist_loss: 0.0056, d_svhn_loss: 0.0751, d_fake_loss: 0.0506, g_loss: 1.1732\n",
            "Step [9270/80000], d_real_loss: 0.1206, d_mnist_loss: 0.0541, d_svhn_loss: 0.0665, d_fake_loss: 0.0619, g_loss: 1.5755\n",
            "Step [9280/80000], d_real_loss: 0.1352, d_mnist_loss: 0.0543, d_svhn_loss: 0.0809, d_fake_loss: 0.1888, g_loss: 1.6779\n",
            "Step [9290/80000], d_real_loss: 0.2517, d_mnist_loss: 0.1915, d_svhn_loss: 0.0602, d_fake_loss: 0.1708, g_loss: 1.3470\n",
            "Step [9300/80000], d_real_loss: 0.1521, d_mnist_loss: 0.0913, d_svhn_loss: 0.0608, d_fake_loss: 0.2067, g_loss: 1.4447\n",
            "Step [9310/80000], d_real_loss: 0.0939, d_mnist_loss: 0.0120, d_svhn_loss: 0.0819, d_fake_loss: 0.0690, g_loss: 1.3425\n",
            "Step [9320/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0107, d_svhn_loss: 0.0515, d_fake_loss: 0.0664, g_loss: 1.2293\n",
            "Step [9330/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0322, d_svhn_loss: 0.0464, d_fake_loss: 0.0872, g_loss: 1.1720\n",
            "Step [9340/80000], d_real_loss: 0.1301, d_mnist_loss: 0.0630, d_svhn_loss: 0.0671, d_fake_loss: 0.0443, g_loss: 1.1087\n",
            "Step [9350/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0070, d_svhn_loss: 0.0798, d_fake_loss: 0.0451, g_loss: 1.0146\n",
            "Step [9360/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0072, d_svhn_loss: 0.0539, d_fake_loss: 0.0647, g_loss: 1.2634\n",
            "Step [9370/80000], d_real_loss: 0.1062, d_mnist_loss: 0.0054, d_svhn_loss: 0.1008, d_fake_loss: 0.1980, g_loss: 0.9813\n",
            "Step [9380/80000], d_real_loss: 0.1529, d_mnist_loss: 0.0591, d_svhn_loss: 0.0938, d_fake_loss: 0.0938, g_loss: 1.1763\n",
            "Step [9390/80000], d_real_loss: 0.1923, d_mnist_loss: 0.0086, d_svhn_loss: 0.1837, d_fake_loss: 0.0897, g_loss: 0.9973\n",
            "Step [9400/80000], d_real_loss: 0.1209, d_mnist_loss: 0.0274, d_svhn_loss: 0.0935, d_fake_loss: 0.0551, g_loss: 1.2450\n",
            "Step [9410/80000], d_real_loss: 0.0779, d_mnist_loss: 0.0212, d_svhn_loss: 0.0567, d_fake_loss: 0.4469, g_loss: 1.1685\n",
            "Step [9420/80000], d_real_loss: 0.1160, d_mnist_loss: 0.0044, d_svhn_loss: 0.1115, d_fake_loss: 0.0642, g_loss: 1.3915\n",
            "Step [9430/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0040, d_svhn_loss: 0.0401, d_fake_loss: 0.1168, g_loss: 1.3760\n",
            "Step [9440/80000], d_real_loss: 0.1191, d_mnist_loss: 0.0048, d_svhn_loss: 0.1144, d_fake_loss: 0.0566, g_loss: 0.9581\n",
            "Step [9450/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0126, d_svhn_loss: 0.0255, d_fake_loss: 0.0381, g_loss: 1.1670\n",
            "Step [9460/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0062, d_svhn_loss: 0.0661, d_fake_loss: 0.0697, g_loss: 1.1052\n",
            "Step [9470/80000], d_real_loss: 0.2364, d_mnist_loss: 0.0134, d_svhn_loss: 0.2230, d_fake_loss: 0.0991, g_loss: 1.0147\n",
            "Step [9480/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0058, d_svhn_loss: 0.0451, d_fake_loss: 0.0720, g_loss: 1.1231\n",
            "Step [9490/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0238, d_svhn_loss: 0.0360, d_fake_loss: 0.2666, g_loss: 1.1914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [9500/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0083, d_svhn_loss: 0.0482, d_fake_loss: 0.2740, g_loss: 1.5565\n",
            "saved ./samples_mnist_svhn/sample-9500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-9500-s-m.png\n",
            "Step [9510/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0065, d_svhn_loss: 0.0436, d_fake_loss: 0.0836, g_loss: 1.4071\n",
            "Step [9520/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0137, d_svhn_loss: 0.0310, d_fake_loss: 0.0468, g_loss: 1.3531\n",
            "Step [9530/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0049, d_svhn_loss: 0.0536, d_fake_loss: 0.0489, g_loss: 1.1458\n",
            "Step [9540/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0175, d_svhn_loss: 0.0472, d_fake_loss: 0.0613, g_loss: 1.1857\n",
            "Step [9550/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0031, d_svhn_loss: 0.0371, d_fake_loss: 0.0424, g_loss: 0.9332\n",
            "Step [9560/80000], d_real_loss: 0.1333, d_mnist_loss: 0.0045, d_svhn_loss: 0.1288, d_fake_loss: 0.1435, g_loss: 0.8649\n",
            "Step [9570/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0031, d_svhn_loss: 0.0380, d_fake_loss: 0.0527, g_loss: 1.1196\n",
            "Step [9580/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0036, d_svhn_loss: 0.0366, d_fake_loss: 0.0442, g_loss: 1.2208\n",
            "Step [9590/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0092, d_svhn_loss: 0.0477, d_fake_loss: 0.0447, g_loss: 1.1085\n",
            "Step [9600/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0038, d_svhn_loss: 0.0461, d_fake_loss: 0.0821, g_loss: 1.3037\n",
            "Step [9610/80000], d_real_loss: 0.1901, d_mnist_loss: 0.0254, d_svhn_loss: 0.1646, d_fake_loss: 0.1795, g_loss: 1.0138\n",
            "Step [9620/80000], d_real_loss: 0.1537, d_mnist_loss: 0.0306, d_svhn_loss: 0.1231, d_fake_loss: 0.0464, g_loss: 1.4296\n",
            "Step [9630/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0044, d_svhn_loss: 0.0416, d_fake_loss: 0.0520, g_loss: 1.1847\n",
            "Step [9640/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0039, d_svhn_loss: 0.0436, d_fake_loss: 0.0526, g_loss: 0.9940\n",
            "Step [9650/80000], d_real_loss: 0.0952, d_mnist_loss: 0.0297, d_svhn_loss: 0.0656, d_fake_loss: 0.0781, g_loss: 1.0986\n",
            "Step [9660/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0032, d_svhn_loss: 0.0656, d_fake_loss: 0.0986, g_loss: 1.3155\n",
            "Step [9670/80000], d_real_loss: 0.1991, d_mnist_loss: 0.0811, d_svhn_loss: 0.1179, d_fake_loss: 0.0712, g_loss: 1.3599\n",
            "Step [9680/80000], d_real_loss: 0.1194, d_mnist_loss: 0.0100, d_svhn_loss: 0.1094, d_fake_loss: 0.1195, g_loss: 1.6553\n",
            "Step [9690/80000], d_real_loss: 0.1789, d_mnist_loss: 0.0058, d_svhn_loss: 0.1731, d_fake_loss: 0.1538, g_loss: 1.0175\n",
            "Step [9700/80000], d_real_loss: 0.5212, d_mnist_loss: 0.0252, d_svhn_loss: 0.4960, d_fake_loss: 0.0777, g_loss: 1.1398\n",
            "Step [9710/80000], d_real_loss: 0.1792, d_mnist_loss: 0.0046, d_svhn_loss: 0.1746, d_fake_loss: 0.2383, g_loss: 0.7734\n",
            "Step [9720/80000], d_real_loss: 0.2054, d_mnist_loss: 0.0188, d_svhn_loss: 0.1866, d_fake_loss: 0.2496, g_loss: 1.1244\n",
            "Step [9730/80000], d_real_loss: 0.0830, d_mnist_loss: 0.0251, d_svhn_loss: 0.0579, d_fake_loss: 0.1071, g_loss: 1.2324\n",
            "Step [9740/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0096, d_svhn_loss: 0.0601, d_fake_loss: 0.0394, g_loss: 1.0379\n",
            "Step [9750/80000], d_real_loss: 0.0922, d_mnist_loss: 0.0334, d_svhn_loss: 0.0588, d_fake_loss: 0.0377, g_loss: 1.1410\n",
            "Step [9760/80000], d_real_loss: 0.2174, d_mnist_loss: 0.0073, d_svhn_loss: 0.2101, d_fake_loss: 0.3134, g_loss: 1.1485\n",
            "Step [9770/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0165, d_svhn_loss: 0.0414, d_fake_loss: 0.2133, g_loss: 1.6360\n",
            "Step [9780/80000], d_real_loss: 0.1419, d_mnist_loss: 0.0463, d_svhn_loss: 0.0956, d_fake_loss: 0.3163, g_loss: 1.2170\n",
            "Step [9790/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0060, d_svhn_loss: 0.0455, d_fake_loss: 0.1354, g_loss: 1.0760\n",
            "Step [9800/80000], d_real_loss: 0.0682, d_mnist_loss: 0.0078, d_svhn_loss: 0.0603, d_fake_loss: 0.0611, g_loss: 1.3176\n",
            "Step [9810/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0108, d_svhn_loss: 0.0608, d_fake_loss: 0.0758, g_loss: 1.2086\n",
            "Step [9820/80000], d_real_loss: 0.1854, d_mnist_loss: 0.0042, d_svhn_loss: 0.1812, d_fake_loss: 0.0384, g_loss: 1.2355\n",
            "Step [9830/80000], d_real_loss: 0.0922, d_mnist_loss: 0.0229, d_svhn_loss: 0.0693, d_fake_loss: 0.0496, g_loss: 1.3282\n",
            "Step [9840/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0337, d_svhn_loss: 0.0415, d_fake_loss: 0.0748, g_loss: 0.9267\n",
            "Step [9850/80000], d_real_loss: 0.1126, d_mnist_loss: 0.0150, d_svhn_loss: 0.0976, d_fake_loss: 0.1812, g_loss: 1.1155\n",
            "Step [9860/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0166, d_svhn_loss: 0.0366, d_fake_loss: 0.0621, g_loss: 1.2844\n",
            "Step [9870/80000], d_real_loss: 0.1072, d_mnist_loss: 0.0081, d_svhn_loss: 0.0991, d_fake_loss: 0.0531, g_loss: 1.2959\n",
            "Step [9880/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0052, d_svhn_loss: 0.0434, d_fake_loss: 0.1644, g_loss: 1.3195\n",
            "Step [9890/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0081, d_svhn_loss: 0.0578, d_fake_loss: 0.0450, g_loss: 0.8989\n",
            "Step [9900/80000], d_real_loss: 0.1401, d_mnist_loss: 0.0751, d_svhn_loss: 0.0650, d_fake_loss: 0.1568, g_loss: 1.5076\n",
            "Step [9910/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0344, d_svhn_loss: 0.0394, d_fake_loss: 0.2533, g_loss: 1.4090\n",
            "Step [9920/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0092, d_svhn_loss: 0.0353, d_fake_loss: 0.0794, g_loss: 0.9086\n",
            "Step [9930/80000], d_real_loss: 0.0793, d_mnist_loss: 0.0098, d_svhn_loss: 0.0695, d_fake_loss: 0.0668, g_loss: 1.2230\n",
            "Step [9940/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0072, d_svhn_loss: 0.0344, d_fake_loss: 0.0501, g_loss: 1.1016\n",
            "Step [9950/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0028, d_svhn_loss: 0.0553, d_fake_loss: 0.1070, g_loss: 1.1467\n",
            "Step [9960/80000], d_real_loss: 0.1555, d_mnist_loss: 0.0903, d_svhn_loss: 0.0652, d_fake_loss: 0.0697, g_loss: 0.8739\n",
            "Step [9970/80000], d_real_loss: 0.1557, d_mnist_loss: 0.0845, d_svhn_loss: 0.0712, d_fake_loss: 0.0508, g_loss: 0.9936\n",
            "Step [9980/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0103, d_svhn_loss: 0.0470, d_fake_loss: 0.0635, g_loss: 1.0404\n",
            "Step [9990/80000], d_real_loss: 0.0888, d_mnist_loss: 0.0067, d_svhn_loss: 0.0821, d_fake_loss: 0.1130, g_loss: 1.0826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [10000/80000], d_real_loss: 0.1130, d_mnist_loss: 0.0636, d_svhn_loss: 0.0494, d_fake_loss: 0.2273, g_loss: 1.1731\n",
            "saved ./samples_mnist_svhn/sample-10000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-10000-s-m.png\n",
            "Step [10010/80000], d_real_loss: 0.0734, d_mnist_loss: 0.0070, d_svhn_loss: 0.0664, d_fake_loss: 0.2865, g_loss: 1.0890\n",
            "Step [10020/80000], d_real_loss: 0.2040, d_mnist_loss: 0.0135, d_svhn_loss: 0.1906, d_fake_loss: 0.3524, g_loss: 1.6731\n",
            "Step [10030/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0161, d_svhn_loss: 0.0514, d_fake_loss: 0.0325, g_loss: 1.2103\n",
            "Step [10040/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0053, d_svhn_loss: 0.0669, d_fake_loss: 0.0538, g_loss: 1.0787\n",
            "Step [10050/80000], d_real_loss: 0.2794, d_mnist_loss: 0.0166, d_svhn_loss: 0.2628, d_fake_loss: 0.0957, g_loss: 1.3855\n",
            "Step [10060/80000], d_real_loss: 0.1506, d_mnist_loss: 0.0950, d_svhn_loss: 0.0556, d_fake_loss: 0.0350, g_loss: 1.3669\n",
            "Step [10070/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0106, d_svhn_loss: 0.0325, d_fake_loss: 0.1604, g_loss: 1.2046\n",
            "Step [10080/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0051, d_svhn_loss: 0.0628, d_fake_loss: 0.1599, g_loss: 1.2596\n",
            "Step [10090/80000], d_real_loss: 0.0695, d_mnist_loss: 0.0035, d_svhn_loss: 0.0660, d_fake_loss: 0.0438, g_loss: 1.0715\n",
            "Step [10100/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0223, d_svhn_loss: 0.0466, d_fake_loss: 0.0774, g_loss: 0.9896\n",
            "Step [10110/80000], d_real_loss: 0.1228, d_mnist_loss: 0.0206, d_svhn_loss: 0.1022, d_fake_loss: 0.1364, g_loss: 0.8540\n",
            "Step [10120/80000], d_real_loss: 0.0781, d_mnist_loss: 0.0047, d_svhn_loss: 0.0734, d_fake_loss: 0.0621, g_loss: 1.2995\n",
            "Step [10130/80000], d_real_loss: 0.1737, d_mnist_loss: 0.0422, d_svhn_loss: 0.1315, d_fake_loss: 0.2706, g_loss: 1.2655\n",
            "Step [10140/80000], d_real_loss: 0.0965, d_mnist_loss: 0.0375, d_svhn_loss: 0.0590, d_fake_loss: 0.0712, g_loss: 0.9564\n",
            "Step [10150/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0066, d_svhn_loss: 0.0658, d_fake_loss: 0.0407, g_loss: 1.1042\n",
            "Step [10160/80000], d_real_loss: 0.0936, d_mnist_loss: 0.0023, d_svhn_loss: 0.0913, d_fake_loss: 0.0384, g_loss: 1.1605\n",
            "Step [10170/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0024, d_svhn_loss: 0.0610, d_fake_loss: 0.0375, g_loss: 1.0423\n",
            "Step [10180/80000], d_real_loss: 0.1373, d_mnist_loss: 0.0173, d_svhn_loss: 0.1200, d_fake_loss: 0.0813, g_loss: 1.0010\n",
            "Step [10190/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0028, d_svhn_loss: 0.0865, d_fake_loss: 0.0865, g_loss: 1.0047\n",
            "Step [10200/80000], d_real_loss: 0.1211, d_mnist_loss: 0.0110, d_svhn_loss: 0.1101, d_fake_loss: 0.1102, g_loss: 1.0480\n",
            "Step [10210/80000], d_real_loss: 0.1024, d_mnist_loss: 0.0178, d_svhn_loss: 0.0846, d_fake_loss: 0.0413, g_loss: 1.1056\n",
            "Step [10220/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0094, d_svhn_loss: 0.0344, d_fake_loss: 0.0817, g_loss: 1.1685\n",
            "Step [10230/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0040, d_svhn_loss: 0.0475, d_fake_loss: 0.0644, g_loss: 1.2060\n",
            "Step [10240/80000], d_real_loss: 0.1149, d_mnist_loss: 0.0243, d_svhn_loss: 0.0906, d_fake_loss: 0.0517, g_loss: 1.2072\n",
            "Step [10250/80000], d_real_loss: 0.0866, d_mnist_loss: 0.0483, d_svhn_loss: 0.0383, d_fake_loss: 0.0676, g_loss: 1.0441\n",
            "Step [10260/80000], d_real_loss: 0.1376, d_mnist_loss: 0.0039, d_svhn_loss: 0.1337, d_fake_loss: 0.0587, g_loss: 1.2409\n",
            "Step [10270/80000], d_real_loss: 0.1123, d_mnist_loss: 0.0242, d_svhn_loss: 0.0881, d_fake_loss: 0.1519, g_loss: 0.9955\n",
            "Step [10280/80000], d_real_loss: 0.1537, d_mnist_loss: 0.0228, d_svhn_loss: 0.1309, d_fake_loss: 0.0471, g_loss: 1.0855\n",
            "Step [10290/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0305, d_svhn_loss: 0.0300, d_fake_loss: 0.0982, g_loss: 1.4804\n",
            "Step [10300/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0092, d_svhn_loss: 0.0502, d_fake_loss: 0.0594, g_loss: 1.2999\n",
            "Step [10310/80000], d_real_loss: 0.1613, d_mnist_loss: 0.0334, d_svhn_loss: 0.1279, d_fake_loss: 0.0443, g_loss: 1.0673\n",
            "Step [10320/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0039, d_svhn_loss: 0.0612, d_fake_loss: 0.0409, g_loss: 1.1888\n",
            "Step [10330/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0133, d_svhn_loss: 0.0857, d_fake_loss: 0.0522, g_loss: 1.1824\n",
            "Step [10340/80000], d_real_loss: 0.1070, d_mnist_loss: 0.0091, d_svhn_loss: 0.0979, d_fake_loss: 0.1607, g_loss: 1.0849\n",
            "Step [10350/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0267, d_svhn_loss: 0.0546, d_fake_loss: 0.0849, g_loss: 1.1771\n",
            "Step [10360/80000], d_real_loss: 0.0886, d_mnist_loss: 0.0023, d_svhn_loss: 0.0863, d_fake_loss: 0.0432, g_loss: 1.1204\n",
            "Step [10370/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0018, d_svhn_loss: 0.0525, d_fake_loss: 0.0873, g_loss: 1.1189\n",
            "Step [10380/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0088, d_svhn_loss: 0.0657, d_fake_loss: 0.2770, g_loss: 1.0584\n",
            "Step [10390/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0050, d_svhn_loss: 0.0436, d_fake_loss: 0.0678, g_loss: 1.1459\n",
            "Step [10400/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0062, d_svhn_loss: 0.0249, d_fake_loss: 0.0452, g_loss: 1.3549\n",
            "Step [10410/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0037, d_svhn_loss: 0.0510, d_fake_loss: 0.1983, g_loss: 1.1715\n",
            "Step [10420/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0307, d_svhn_loss: 0.0390, d_fake_loss: 0.0593, g_loss: 1.2289\n",
            "Step [10430/80000], d_real_loss: 0.3288, d_mnist_loss: 0.0041, d_svhn_loss: 0.3246, d_fake_loss: 0.0346, g_loss: 1.2520\n",
            "Step [10440/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0176, d_svhn_loss: 0.0473, d_fake_loss: 0.0671, g_loss: 1.0309\n",
            "Step [10450/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0098, d_svhn_loss: 0.0290, d_fake_loss: 0.1516, g_loss: 1.1193\n",
            "Step [10460/80000], d_real_loss: 0.2582, d_mnist_loss: 0.0795, d_svhn_loss: 0.1786, d_fake_loss: 0.1785, g_loss: 1.1437\n",
            "Step [10470/80000], d_real_loss: 0.0958, d_mnist_loss: 0.0229, d_svhn_loss: 0.0729, d_fake_loss: 0.1232, g_loss: 1.1654\n",
            "Step [10480/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0101, d_svhn_loss: 0.0341, d_fake_loss: 0.0482, g_loss: 0.8494\n",
            "Step [10490/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0046, d_svhn_loss: 0.0526, d_fake_loss: 0.0977, g_loss: 1.9319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [10500/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0272, d_svhn_loss: 0.0261, d_fake_loss: 0.0445, g_loss: 1.1495\n",
            "saved ./samples_mnist_svhn/sample-10500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-10500-s-m.png\n",
            "Step [10510/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0101, d_svhn_loss: 0.0411, d_fake_loss: 0.1453, g_loss: 0.8704\n",
            "Step [10520/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0405, d_svhn_loss: 0.0439, d_fake_loss: 0.0707, g_loss: 1.1093\n",
            "Step [10530/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0051, d_svhn_loss: 0.0439, d_fake_loss: 0.0487, g_loss: 1.0977\n",
            "Step [10540/80000], d_real_loss: 0.1538, d_mnist_loss: 0.0228, d_svhn_loss: 0.1310, d_fake_loss: 0.1414, g_loss: 1.8185\n",
            "Step [10550/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0175, d_svhn_loss: 0.0362, d_fake_loss: 0.1258, g_loss: 1.1035\n",
            "Step [10560/80000], d_real_loss: 0.2991, d_mnist_loss: 0.0324, d_svhn_loss: 0.2667, d_fake_loss: 0.1724, g_loss: 1.0544\n",
            "Step [10570/80000], d_real_loss: 0.1474, d_mnist_loss: 0.0091, d_svhn_loss: 0.1383, d_fake_loss: 0.0629, g_loss: 1.4081\n",
            "Step [10580/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0066, d_svhn_loss: 0.0612, d_fake_loss: 0.0936, g_loss: 1.1371\n",
            "Step [10590/80000], d_real_loss: 0.0927, d_mnist_loss: 0.0062, d_svhn_loss: 0.0864, d_fake_loss: 0.1635, g_loss: 1.4599\n",
            "Step [10600/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0263, d_svhn_loss: 0.0355, d_fake_loss: 0.1201, g_loss: 1.2153\n",
            "Step [10610/80000], d_real_loss: 0.1764, d_mnist_loss: 0.0517, d_svhn_loss: 0.1247, d_fake_loss: 0.2062, g_loss: 0.9214\n",
            "Step [10620/80000], d_real_loss: 0.0755, d_mnist_loss: 0.0170, d_svhn_loss: 0.0585, d_fake_loss: 0.1237, g_loss: 1.3390\n",
            "Step [10630/80000], d_real_loss: 0.0962, d_mnist_loss: 0.0079, d_svhn_loss: 0.0884, d_fake_loss: 0.0678, g_loss: 1.2649\n",
            "Step [10640/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0048, d_svhn_loss: 0.0392, d_fake_loss: 0.1299, g_loss: 1.3598\n",
            "Step [10650/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0117, d_svhn_loss: 0.0386, d_fake_loss: 0.0885, g_loss: 1.2832\n",
            "Step [10660/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0328, d_svhn_loss: 0.0355, d_fake_loss: 0.0863, g_loss: 1.1190\n",
            "Step [10670/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0059, d_svhn_loss: 0.0554, d_fake_loss: 0.0551, g_loss: 1.1598\n",
            "Step [10680/80000], d_real_loss: 0.0952, d_mnist_loss: 0.0065, d_svhn_loss: 0.0886, d_fake_loss: 0.0326, g_loss: 1.1826\n",
            "Step [10690/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0056, d_svhn_loss: 0.0364, d_fake_loss: 0.0371, g_loss: 1.1128\n",
            "Step [10700/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0123, d_svhn_loss: 0.0340, d_fake_loss: 0.0924, g_loss: 1.1110\n",
            "Step [10710/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0094, d_svhn_loss: 0.0499, d_fake_loss: 0.0762, g_loss: 1.3159\n",
            "Step [10720/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0057, d_svhn_loss: 0.0544, d_fake_loss: 0.0384, g_loss: 1.1863\n",
            "Step [10730/80000], d_real_loss: 0.2456, d_mnist_loss: 0.0123, d_svhn_loss: 0.2333, d_fake_loss: 0.0490, g_loss: 1.3685\n",
            "Step [10740/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0163, d_svhn_loss: 0.0477, d_fake_loss: 0.3417, g_loss: 0.8174\n",
            "Step [10750/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0036, d_svhn_loss: 0.0603, d_fake_loss: 0.0505, g_loss: 1.0801\n",
            "Step [10760/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0128, d_svhn_loss: 0.0677, d_fake_loss: 0.1200, g_loss: 1.3105\n",
            "Step [10770/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0281, d_svhn_loss: 0.0524, d_fake_loss: 0.0800, g_loss: 1.3256\n",
            "Step [10780/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0120, d_svhn_loss: 0.0306, d_fake_loss: 0.0900, g_loss: 1.2183\n",
            "Step [10790/80000], d_real_loss: 0.0936, d_mnist_loss: 0.0217, d_svhn_loss: 0.0719, d_fake_loss: 0.0656, g_loss: 1.4369\n",
            "Step [10800/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0059, d_svhn_loss: 0.0539, d_fake_loss: 0.0471, g_loss: 0.9925\n",
            "Step [10810/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0124, d_svhn_loss: 0.0689, d_fake_loss: 0.0334, g_loss: 1.1920\n",
            "Step [10820/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0041, d_svhn_loss: 0.0341, d_fake_loss: 0.1717, g_loss: 1.3356\n",
            "Step [10830/80000], d_real_loss: 0.3954, d_mnist_loss: 0.0703, d_svhn_loss: 0.3251, d_fake_loss: 0.1185, g_loss: 1.4555\n",
            "Step [10840/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0068, d_svhn_loss: 0.0538, d_fake_loss: 0.0417, g_loss: 1.0690\n",
            "Step [10850/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0099, d_svhn_loss: 0.0701, d_fake_loss: 0.3102, g_loss: 1.2280\n",
            "Step [10860/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0422, d_svhn_loss: 0.0488, d_fake_loss: 0.0463, g_loss: 1.1192\n",
            "Step [10870/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0084, d_svhn_loss: 0.1088, d_fake_loss: 0.0649, g_loss: 1.0919\n",
            "Step [10880/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0080, d_svhn_loss: 0.0309, d_fake_loss: 0.0694, g_loss: 1.1856\n",
            "Step [10890/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0091, d_svhn_loss: 0.0445, d_fake_loss: 0.1122, g_loss: 0.9097\n",
            "Step [10900/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0110, d_svhn_loss: 0.0438, d_fake_loss: 0.0841, g_loss: 1.2876\n",
            "Step [10910/80000], d_real_loss: 0.0726, d_mnist_loss: 0.0042, d_svhn_loss: 0.0684, d_fake_loss: 0.0584, g_loss: 1.2441\n",
            "Step [10920/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0045, d_svhn_loss: 0.0322, d_fake_loss: 0.0554, g_loss: 1.2775\n",
            "Step [10930/80000], d_real_loss: 0.1180, d_mnist_loss: 0.0040, d_svhn_loss: 0.1139, d_fake_loss: 0.0442, g_loss: 1.2346\n",
            "Step [10940/80000], d_real_loss: 0.1176, d_mnist_loss: 0.0028, d_svhn_loss: 0.1148, d_fake_loss: 0.0819, g_loss: 1.6097\n",
            "Step [10950/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0076, d_svhn_loss: 0.0553, d_fake_loss: 0.0663, g_loss: 1.0521\n",
            "Step [10960/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0208, d_svhn_loss: 0.0325, d_fake_loss: 0.1226, g_loss: 1.4045\n",
            "Step [10970/80000], d_real_loss: 0.1041, d_mnist_loss: 0.0054, d_svhn_loss: 0.0987, d_fake_loss: 0.0458, g_loss: 1.1273\n",
            "Step [10980/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0033, d_svhn_loss: 0.0512, d_fake_loss: 0.1161, g_loss: 1.4087\n",
            "Step [10990/80000], d_real_loss: 0.1716, d_mnist_loss: 0.1002, d_svhn_loss: 0.0714, d_fake_loss: 0.0479, g_loss: 1.2959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [11000/80000], d_real_loss: 0.1237, d_mnist_loss: 0.0178, d_svhn_loss: 0.1059, d_fake_loss: 0.1268, g_loss: 1.3959\n",
            "saved ./samples_mnist_svhn/sample-11000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-11000-s-m.png\n",
            "Step [11010/80000], d_real_loss: 0.0975, d_mnist_loss: 0.0564, d_svhn_loss: 0.0411, d_fake_loss: 0.2659, g_loss: 1.4542\n",
            "Step [11020/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0068, d_svhn_loss: 0.0505, d_fake_loss: 0.1778, g_loss: 1.1548\n",
            "Step [11030/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0079, d_svhn_loss: 0.0558, d_fake_loss: 0.0785, g_loss: 1.0932\n",
            "Step [11040/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0064, d_svhn_loss: 0.0514, d_fake_loss: 0.0593, g_loss: 1.0323\n",
            "Step [11050/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0062, d_svhn_loss: 0.0769, d_fake_loss: 0.1854, g_loss: 1.1866\n",
            "Step [11060/80000], d_real_loss: 0.0735, d_mnist_loss: 0.0031, d_svhn_loss: 0.0704, d_fake_loss: 0.0484, g_loss: 1.1862\n",
            "Step [11070/80000], d_real_loss: 0.1212, d_mnist_loss: 0.0176, d_svhn_loss: 0.1036, d_fake_loss: 0.0520, g_loss: 1.3232\n",
            "Step [11080/80000], d_real_loss: 0.1105, d_mnist_loss: 0.0051, d_svhn_loss: 0.1054, d_fake_loss: 0.0503, g_loss: 1.3307\n",
            "Step [11090/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0139, d_svhn_loss: 0.0344, d_fake_loss: 0.0793, g_loss: 1.2400\n",
            "Step [11100/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0058, d_svhn_loss: 0.0483, d_fake_loss: 0.2319, g_loss: 0.9859\n",
            "Step [11110/80000], d_real_loss: 0.1669, d_mnist_loss: 0.0050, d_svhn_loss: 0.1620, d_fake_loss: 0.0504, g_loss: 1.1029\n",
            "Step [11120/80000], d_real_loss: 0.0792, d_mnist_loss: 0.0172, d_svhn_loss: 0.0619, d_fake_loss: 0.1053, g_loss: 1.3348\n",
            "Step [11130/80000], d_real_loss: 0.1177, d_mnist_loss: 0.0086, d_svhn_loss: 0.1092, d_fake_loss: 0.1885, g_loss: 1.4151\n",
            "Step [11140/80000], d_real_loss: 0.0907, d_mnist_loss: 0.0275, d_svhn_loss: 0.0631, d_fake_loss: 0.0581, g_loss: 1.1272\n",
            "Step [11150/80000], d_real_loss: 0.1206, d_mnist_loss: 0.0649, d_svhn_loss: 0.0557, d_fake_loss: 0.0684, g_loss: 0.9292\n",
            "Step [11160/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0045, d_svhn_loss: 0.0705, d_fake_loss: 0.1826, g_loss: 1.0748\n",
            "Step [11170/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0041, d_svhn_loss: 0.0257, d_fake_loss: 0.1773, g_loss: 1.0499\n",
            "Step [11180/80000], d_real_loss: 0.1531, d_mnist_loss: 0.0203, d_svhn_loss: 0.1328, d_fake_loss: 0.0700, g_loss: 1.0501\n",
            "Step [11190/80000], d_real_loss: 0.1232, d_mnist_loss: 0.0065, d_svhn_loss: 0.1167, d_fake_loss: 0.2509, g_loss: 1.1275\n",
            "Step [11200/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0037, d_svhn_loss: 0.0593, d_fake_loss: 0.0394, g_loss: 1.1870\n",
            "Step [11210/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0045, d_svhn_loss: 0.0380, d_fake_loss: 0.0735, g_loss: 1.2590\n",
            "Step [11220/80000], d_real_loss: 0.1046, d_mnist_loss: 0.0515, d_svhn_loss: 0.0531, d_fake_loss: 0.0338, g_loss: 1.2893\n",
            "Step [11230/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0356, d_svhn_loss: 0.0337, d_fake_loss: 0.0318, g_loss: 1.1082\n",
            "Step [11240/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0044, d_svhn_loss: 0.0393, d_fake_loss: 0.0387, g_loss: 1.1431\n",
            "Step [11250/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0273, d_svhn_loss: 0.0416, d_fake_loss: 0.3378, g_loss: 1.0559\n",
            "Step [11260/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0053, d_svhn_loss: 0.0556, d_fake_loss: 0.0646, g_loss: 1.2050\n",
            "Step [11270/80000], d_real_loss: 0.3286, d_mnist_loss: 0.0351, d_svhn_loss: 0.2936, d_fake_loss: 0.2153, g_loss: 1.2371\n",
            "Step [11280/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0035, d_svhn_loss: 0.0505, d_fake_loss: 0.0428, g_loss: 1.1502\n",
            "Step [11290/80000], d_real_loss: 0.1614, d_mnist_loss: 0.0055, d_svhn_loss: 0.1559, d_fake_loss: 0.1131, g_loss: 1.1235\n",
            "Step [11300/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0176, d_svhn_loss: 0.0725, d_fake_loss: 0.0563, g_loss: 1.1511\n",
            "Step [11310/80000], d_real_loss: 0.6197, d_mnist_loss: 0.5786, d_svhn_loss: 0.0411, d_fake_loss: 0.5969, g_loss: 1.7314\n",
            "Step [11320/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0062, d_svhn_loss: 0.0561, d_fake_loss: 0.0834, g_loss: 1.2660\n",
            "Step [11330/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0065, d_svhn_loss: 0.0382, d_fake_loss: 0.0483, g_loss: 1.1735\n",
            "Step [11340/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0068, d_svhn_loss: 0.0564, d_fake_loss: 0.1022, g_loss: 0.9952\n",
            "Step [11350/80000], d_real_loss: 0.1035, d_mnist_loss: 0.0037, d_svhn_loss: 0.0997, d_fake_loss: 0.0363, g_loss: 1.2180\n",
            "Step [11360/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0270, d_svhn_loss: 0.0328, d_fake_loss: 0.0559, g_loss: 1.2466\n",
            "Step [11370/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0077, d_svhn_loss: 0.0385, d_fake_loss: 0.0373, g_loss: 1.2174\n",
            "Step [11380/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0104, d_svhn_loss: 0.0612, d_fake_loss: 0.1453, g_loss: 1.0789\n",
            "Step [11390/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0035, d_svhn_loss: 0.0430, d_fake_loss: 0.1052, g_loss: 0.9224\n",
            "Step [11400/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0102, d_svhn_loss: 0.0543, d_fake_loss: 0.0288, g_loss: 1.1439\n",
            "Step [11410/80000], d_real_loss: 0.1034, d_mnist_loss: 0.0024, d_svhn_loss: 0.1010, d_fake_loss: 0.0550, g_loss: 1.1062\n",
            "Step [11420/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0123, d_svhn_loss: 0.0375, d_fake_loss: 0.1156, g_loss: 1.3376\n",
            "Step [11430/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0054, d_svhn_loss: 0.0790, d_fake_loss: 0.1422, g_loss: 1.2237\n",
            "Step [11440/80000], d_real_loss: 0.0865, d_mnist_loss: 0.0107, d_svhn_loss: 0.0758, d_fake_loss: 0.0540, g_loss: 0.9056\n",
            "Step [11450/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0050, d_svhn_loss: 0.0415, d_fake_loss: 0.0568, g_loss: 1.1769\n",
            "Step [11460/80000], d_real_loss: 0.1692, d_mnist_loss: 0.0058, d_svhn_loss: 0.1633, d_fake_loss: 0.1755, g_loss: 1.3906\n",
            "Step [11470/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0115, d_svhn_loss: 0.0468, d_fake_loss: 0.0433, g_loss: 1.1780\n",
            "Step [11480/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0039, d_svhn_loss: 0.0225, d_fake_loss: 0.0409, g_loss: 1.3268\n",
            "Step [11490/80000], d_real_loss: 0.1814, d_mnist_loss: 0.0034, d_svhn_loss: 0.1780, d_fake_loss: 0.0479, g_loss: 1.2682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [11500/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0039, d_svhn_loss: 0.0340, d_fake_loss: 0.0364, g_loss: 1.1738\n",
            "saved ./samples_mnist_svhn/sample-11500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-11500-s-m.png\n",
            "Step [11510/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0095, d_svhn_loss: 0.0330, d_fake_loss: 0.0333, g_loss: 1.2974\n",
            "Step [11520/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0067, d_svhn_loss: 0.0657, d_fake_loss: 0.0380, g_loss: 1.1030\n",
            "Step [11530/80000], d_real_loss: 0.1361, d_mnist_loss: 0.0057, d_svhn_loss: 0.1304, d_fake_loss: 0.4318, g_loss: 1.2408\n",
            "Step [11540/80000], d_real_loss: 0.1043, d_mnist_loss: 0.0702, d_svhn_loss: 0.0340, d_fake_loss: 0.0953, g_loss: 1.1795\n",
            "Step [11550/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0127, d_svhn_loss: 0.0336, d_fake_loss: 0.0306, g_loss: 1.2846\n",
            "Step [11560/80000], d_real_loss: 0.1103, d_mnist_loss: 0.0032, d_svhn_loss: 0.1071, d_fake_loss: 0.0429, g_loss: 1.1709\n",
            "Step [11570/80000], d_real_loss: 0.0755, d_mnist_loss: 0.0038, d_svhn_loss: 0.0717, d_fake_loss: 0.0597, g_loss: 1.2442\n",
            "Step [11580/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0030, d_svhn_loss: 0.0336, d_fake_loss: 0.0378, g_loss: 1.2715\n",
            "Step [11590/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0049, d_svhn_loss: 0.0491, d_fake_loss: 0.0788, g_loss: 1.2615\n",
            "Step [11600/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0066, d_svhn_loss: 0.0273, d_fake_loss: 0.0548, g_loss: 1.1395\n",
            "Step [11610/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0026, d_svhn_loss: 0.0371, d_fake_loss: 0.0593, g_loss: 1.3092\n",
            "Step [11620/80000], d_real_loss: 0.0794, d_mnist_loss: 0.0349, d_svhn_loss: 0.0446, d_fake_loss: 0.0619, g_loss: 1.2463\n",
            "Step [11630/80000], d_real_loss: 0.1837, d_mnist_loss: 0.1104, d_svhn_loss: 0.0733, d_fake_loss: 0.1363, g_loss: 1.1286\n",
            "Step [11640/80000], d_real_loss: 0.2899, d_mnist_loss: 0.2345, d_svhn_loss: 0.0554, d_fake_loss: 0.0481, g_loss: 1.2908\n",
            "Step [11650/80000], d_real_loss: 0.1536, d_mnist_loss: 0.0307, d_svhn_loss: 0.1229, d_fake_loss: 0.0577, g_loss: 1.1812\n",
            "Step [11660/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0033, d_svhn_loss: 0.0651, d_fake_loss: 0.0344, g_loss: 1.2471\n",
            "Step [11670/80000], d_real_loss: 0.2641, d_mnist_loss: 0.0036, d_svhn_loss: 0.2605, d_fake_loss: 0.1501, g_loss: 1.1710\n",
            "Step [11680/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0105, d_svhn_loss: 0.0538, d_fake_loss: 0.0814, g_loss: 1.3586\n",
            "Step [11690/80000], d_real_loss: 0.1040, d_mnist_loss: 0.0094, d_svhn_loss: 0.0946, d_fake_loss: 0.0494, g_loss: 1.1664\n",
            "Step [11700/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0049, d_svhn_loss: 0.0375, d_fake_loss: 0.0564, g_loss: 1.0526\n",
            "Step [11710/80000], d_real_loss: 0.1341, d_mnist_loss: 0.0032, d_svhn_loss: 0.1309, d_fake_loss: 0.0543, g_loss: 0.9572\n",
            "Step [11720/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0036, d_svhn_loss: 0.0563, d_fake_loss: 0.0314, g_loss: 1.1811\n",
            "Step [11730/80000], d_real_loss: 0.1259, d_mnist_loss: 0.0541, d_svhn_loss: 0.0717, d_fake_loss: 0.0594, g_loss: 1.2120\n",
            "Step [11740/80000], d_real_loss: 0.1685, d_mnist_loss: 0.1472, d_svhn_loss: 0.0212, d_fake_loss: 0.2467, g_loss: 0.6943\n",
            "Step [11750/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0121, d_svhn_loss: 0.0415, d_fake_loss: 0.0531, g_loss: 1.0797\n",
            "Step [11760/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0036, d_svhn_loss: 0.0499, d_fake_loss: 0.0469, g_loss: 1.3544\n",
            "Step [11770/80000], d_real_loss: 0.0658, d_mnist_loss: 0.0282, d_svhn_loss: 0.0377, d_fake_loss: 0.0518, g_loss: 0.8832\n",
            "Step [11780/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0159, d_svhn_loss: 0.0685, d_fake_loss: 0.1754, g_loss: 1.3369\n",
            "Step [11790/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0180, d_svhn_loss: 0.0622, d_fake_loss: 0.1020, g_loss: 1.1485\n",
            "Step [11800/80000], d_real_loss: 0.2288, d_mnist_loss: 0.0034, d_svhn_loss: 0.2254, d_fake_loss: 0.0654, g_loss: 1.2838\n",
            "Step [11810/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0043, d_svhn_loss: 0.0554, d_fake_loss: 0.2720, g_loss: 1.2602\n",
            "Step [11820/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0033, d_svhn_loss: 0.0504, d_fake_loss: 0.0420, g_loss: 1.1660\n",
            "Step [11830/80000], d_real_loss: 0.0801, d_mnist_loss: 0.0091, d_svhn_loss: 0.0710, d_fake_loss: 0.0474, g_loss: 1.2632\n",
            "Step [11840/80000], d_real_loss: 0.0855, d_mnist_loss: 0.0039, d_svhn_loss: 0.0816, d_fake_loss: 0.0841, g_loss: 1.2259\n",
            "Step [11850/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0033, d_svhn_loss: 0.0638, d_fake_loss: 0.0291, g_loss: 1.1119\n",
            "Step [11860/80000], d_real_loss: 0.0863, d_mnist_loss: 0.0028, d_svhn_loss: 0.0835, d_fake_loss: 0.0370, g_loss: 1.0719\n",
            "Step [11870/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0043, d_svhn_loss: 0.0331, d_fake_loss: 0.0408, g_loss: 1.1483\n",
            "Step [11880/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0204, d_svhn_loss: 0.0337, d_fake_loss: 0.0701, g_loss: 0.8824\n",
            "Step [11890/80000], d_real_loss: 0.0949, d_mnist_loss: 0.0074, d_svhn_loss: 0.0875, d_fake_loss: 0.0642, g_loss: 1.0907\n",
            "Step [11900/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0259, d_svhn_loss: 0.0574, d_fake_loss: 0.0455, g_loss: 1.2188\n",
            "Step [11910/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0037, d_svhn_loss: 0.0272, d_fake_loss: 0.0388, g_loss: 1.2302\n",
            "Step [11920/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0037, d_svhn_loss: 0.0295, d_fake_loss: 0.0611, g_loss: 1.2012\n",
            "Step [11930/80000], d_real_loss: 0.1002, d_mnist_loss: 0.0492, d_svhn_loss: 0.0509, d_fake_loss: 0.2347, g_loss: 1.2537\n",
            "Step [11940/80000], d_real_loss: 0.0920, d_mnist_loss: 0.0239, d_svhn_loss: 0.0681, d_fake_loss: 0.0756, g_loss: 0.9884\n",
            "Step [11950/80000], d_real_loss: 0.1164, d_mnist_loss: 0.0040, d_svhn_loss: 0.1123, d_fake_loss: 0.0493, g_loss: 1.1373\n",
            "Step [11960/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0144, d_svhn_loss: 0.0603, d_fake_loss: 0.0601, g_loss: 1.1769\n",
            "Step [11970/80000], d_real_loss: 0.1132, d_mnist_loss: 0.0147, d_svhn_loss: 0.0985, d_fake_loss: 0.0565, g_loss: 1.0099\n",
            "Step [11980/80000], d_real_loss: 0.1687, d_mnist_loss: 0.0715, d_svhn_loss: 0.0972, d_fake_loss: 0.0585, g_loss: 1.0881\n",
            "Step [11990/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0057, d_svhn_loss: 0.0581, d_fake_loss: 0.0484, g_loss: 1.1550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [12000/80000], d_real_loss: 0.1750, d_mnist_loss: 0.0038, d_svhn_loss: 0.1712, d_fake_loss: 0.1173, g_loss: 1.3425\n",
            "saved ./samples_mnist_svhn/sample-12000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-12000-s-m.png\n",
            "Step [12010/80000], d_real_loss: 0.1256, d_mnist_loss: 0.0091, d_svhn_loss: 0.1165, d_fake_loss: 0.0353, g_loss: 1.0356\n",
            "Step [12020/80000], d_real_loss: 0.0798, d_mnist_loss: 0.0394, d_svhn_loss: 0.0405, d_fake_loss: 0.3757, g_loss: 0.8874\n",
            "Step [12030/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0071, d_svhn_loss: 0.0416, d_fake_loss: 0.0668, g_loss: 1.2897\n",
            "Step [12040/80000], d_real_loss: 0.7407, d_mnist_loss: 0.6588, d_svhn_loss: 0.0819, d_fake_loss: 0.4053, g_loss: 2.0168\n",
            "Step [12050/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0181, d_svhn_loss: 0.0517, d_fake_loss: 0.0335, g_loss: 1.0981\n",
            "Step [12060/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0156, d_svhn_loss: 0.0550, d_fake_loss: 0.0571, g_loss: 1.0746\n",
            "Step [12070/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0041, d_svhn_loss: 0.0365, d_fake_loss: 0.0413, g_loss: 1.0223\n",
            "Step [12080/80000], d_real_loss: 0.1629, d_mnist_loss: 0.0085, d_svhn_loss: 0.1544, d_fake_loss: 0.0549, g_loss: 1.0693\n",
            "Step [12090/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0213, d_svhn_loss: 0.0388, d_fake_loss: 0.0463, g_loss: 1.1158\n",
            "Step [12100/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0056, d_svhn_loss: 0.0422, d_fake_loss: 0.0534, g_loss: 1.3223\n",
            "Step [12110/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0100, d_svhn_loss: 0.0271, d_fake_loss: 0.0309, g_loss: 1.3436\n",
            "Step [12120/80000], d_real_loss: 0.1550, d_mnist_loss: 0.0046, d_svhn_loss: 0.1504, d_fake_loss: 0.0647, g_loss: 1.3195\n",
            "Step [12130/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0025, d_svhn_loss: 0.0439, d_fake_loss: 0.0474, g_loss: 1.3622\n",
            "Step [12140/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0138, d_svhn_loss: 0.0452, d_fake_loss: 0.0757, g_loss: 1.0844\n",
            "Step [12150/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0144, d_svhn_loss: 0.0486, d_fake_loss: 0.0458, g_loss: 1.0669\n",
            "Step [12160/80000], d_real_loss: 0.3411, d_mnist_loss: 0.0174, d_svhn_loss: 0.3238, d_fake_loss: 0.2652, g_loss: 1.2102\n",
            "Step [12170/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0036, d_svhn_loss: 0.0687, d_fake_loss: 0.0292, g_loss: 1.3325\n",
            "Step [12180/80000], d_real_loss: 0.2162, d_mnist_loss: 0.0067, d_svhn_loss: 0.2095, d_fake_loss: 0.0680, g_loss: 1.1994\n",
            "Step [12190/80000], d_real_loss: 0.1271, d_mnist_loss: 0.0341, d_svhn_loss: 0.0930, d_fake_loss: 0.1337, g_loss: 1.1401\n",
            "Step [12200/80000], d_real_loss: 0.2115, d_mnist_loss: 0.0112, d_svhn_loss: 0.2003, d_fake_loss: 0.0773, g_loss: 1.2305\n",
            "Step [12210/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0040, d_svhn_loss: 0.0316, d_fake_loss: 0.0382, g_loss: 1.1426\n",
            "Step [12220/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0061, d_svhn_loss: 0.0781, d_fake_loss: 0.0537, g_loss: 1.2891\n",
            "Step [12230/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0124, d_svhn_loss: 0.0440, d_fake_loss: 0.0304, g_loss: 1.0131\n",
            "Step [12240/80000], d_real_loss: 0.1116, d_mnist_loss: 0.0275, d_svhn_loss: 0.0841, d_fake_loss: 0.0916, g_loss: 1.1314\n",
            "Step [12250/80000], d_real_loss: 0.1467, d_mnist_loss: 0.0171, d_svhn_loss: 0.1295, d_fake_loss: 0.0350, g_loss: 1.3167\n",
            "Step [12260/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0030, d_svhn_loss: 0.0504, d_fake_loss: 0.1053, g_loss: 0.9644\n",
            "Step [12270/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0018, d_svhn_loss: 0.0458, d_fake_loss: 0.0841, g_loss: 1.0038\n",
            "Step [12280/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0027, d_svhn_loss: 0.0347, d_fake_loss: 0.0485, g_loss: 1.0677\n",
            "Step [12290/80000], d_real_loss: 0.2184, d_mnist_loss: 0.0035, d_svhn_loss: 0.2149, d_fake_loss: 0.0477, g_loss: 1.1234\n",
            "Step [12300/80000], d_real_loss: 0.1351, d_mnist_loss: 0.0077, d_svhn_loss: 0.1275, d_fake_loss: 0.0380, g_loss: 1.1636\n",
            "Step [12310/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0064, d_svhn_loss: 0.0326, d_fake_loss: 0.1329, g_loss: 0.9560\n",
            "Step [12320/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0096, d_svhn_loss: 0.0797, d_fake_loss: 0.0608, g_loss: 1.2649\n",
            "Step [12330/80000], d_real_loss: 0.0978, d_mnist_loss: 0.0102, d_svhn_loss: 0.0875, d_fake_loss: 0.1452, g_loss: 1.1380\n",
            "Step [12340/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0056, d_svhn_loss: 0.0557, d_fake_loss: 0.1819, g_loss: 1.1344\n",
            "Step [12350/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0023, d_svhn_loss: 0.0762, d_fake_loss: 0.0433, g_loss: 1.2157\n",
            "Step [12360/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0033, d_svhn_loss: 0.0449, d_fake_loss: 0.0317, g_loss: 1.2384\n",
            "Step [12370/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0066, d_svhn_loss: 0.0370, d_fake_loss: 0.0973, g_loss: 1.2132\n",
            "Step [12380/80000], d_real_loss: 0.1635, d_mnist_loss: 0.0197, d_svhn_loss: 0.1438, d_fake_loss: 0.6493, g_loss: 1.9380\n",
            "Step [12390/80000], d_real_loss: 0.1564, d_mnist_loss: 0.0050, d_svhn_loss: 0.1514, d_fake_loss: 0.0951, g_loss: 0.8200\n",
            "Step [12400/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0040, d_svhn_loss: 0.0435, d_fake_loss: 0.0515, g_loss: 1.2087\n",
            "Step [12410/80000], d_real_loss: 0.0889, d_mnist_loss: 0.0324, d_svhn_loss: 0.0565, d_fake_loss: 0.0396, g_loss: 1.1455\n",
            "Step [12420/80000], d_real_loss: 0.0895, d_mnist_loss: 0.0050, d_svhn_loss: 0.0846, d_fake_loss: 0.0523, g_loss: 1.4430\n",
            "Step [12430/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0042, d_svhn_loss: 0.0410, d_fake_loss: 0.0536, g_loss: 1.4432\n",
            "Step [12440/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0123, d_svhn_loss: 0.0442, d_fake_loss: 0.0354, g_loss: 1.1421\n",
            "Step [12450/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0033, d_svhn_loss: 0.0328, d_fake_loss: 0.0361, g_loss: 0.9650\n",
            "Step [12460/80000], d_real_loss: 0.0705, d_mnist_loss: 0.0061, d_svhn_loss: 0.0644, d_fake_loss: 0.0275, g_loss: 1.2554\n",
            "Step [12470/80000], d_real_loss: 0.2000, d_mnist_loss: 0.0038, d_svhn_loss: 0.1962, d_fake_loss: 0.1125, g_loss: 1.1934\n",
            "Step [12480/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0122, d_svhn_loss: 0.0330, d_fake_loss: 0.0567, g_loss: 1.2158\n",
            "Step [12490/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0156, d_svhn_loss: 0.0409, d_fake_loss: 0.0786, g_loss: 1.3876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [12500/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0069, d_svhn_loss: 0.0389, d_fake_loss: 0.0560, g_loss: 1.5025\n",
            "saved ./samples_mnist_svhn/sample-12500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-12500-s-m.png\n",
            "Step [12510/80000], d_real_loss: 0.1024, d_mnist_loss: 0.0059, d_svhn_loss: 0.0965, d_fake_loss: 0.2017, g_loss: 1.4617\n",
            "Step [12520/80000], d_real_loss: 0.1077, d_mnist_loss: 0.0038, d_svhn_loss: 0.1039, d_fake_loss: 0.1211, g_loss: 1.1802\n",
            "Step [12530/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0142, d_svhn_loss: 0.0224, d_fake_loss: 0.0483, g_loss: 1.2812\n",
            "Step [12540/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0047, d_svhn_loss: 0.0340, d_fake_loss: 0.0735, g_loss: 0.9715\n",
            "Step [12550/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0059, d_svhn_loss: 0.0539, d_fake_loss: 0.0676, g_loss: 1.1906\n",
            "Step [12560/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0077, d_svhn_loss: 0.0451, d_fake_loss: 0.0468, g_loss: 0.9958\n",
            "Step [12570/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0165, d_svhn_loss: 0.0247, d_fake_loss: 0.0422, g_loss: 1.0376\n",
            "Step [12580/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0024, d_svhn_loss: 0.0479, d_fake_loss: 0.0364, g_loss: 1.1158\n",
            "Step [12590/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0049, d_svhn_loss: 0.0579, d_fake_loss: 0.0438, g_loss: 1.3893\n",
            "Step [12600/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0286, d_svhn_loss: 0.0342, d_fake_loss: 0.0853, g_loss: 1.1453\n",
            "Step [12610/80000], d_real_loss: 0.2565, d_mnist_loss: 0.0058, d_svhn_loss: 0.2507, d_fake_loss: 0.0945, g_loss: 1.2369\n",
            "Step [12620/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0245, d_svhn_loss: 0.0392, d_fake_loss: 0.0669, g_loss: 0.9895\n",
            "Step [12630/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0047, d_svhn_loss: 0.0323, d_fake_loss: 0.0292, g_loss: 1.0074\n",
            "Step [12640/80000], d_real_loss: 0.1965, d_mnist_loss: 0.0041, d_svhn_loss: 0.1924, d_fake_loss: 0.0302, g_loss: 1.1137\n",
            "Step [12650/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0064, d_svhn_loss: 0.0391, d_fake_loss: 0.0394, g_loss: 1.2514\n",
            "Step [12660/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0048, d_svhn_loss: 0.0420, d_fake_loss: 0.0583, g_loss: 0.9986\n",
            "Step [12670/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0076, d_svhn_loss: 0.0541, d_fake_loss: 0.0733, g_loss: 1.0262\n",
            "Step [12680/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0032, d_svhn_loss: 0.0584, d_fake_loss: 0.0618, g_loss: 1.3394\n",
            "Step [12690/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0045, d_svhn_loss: 0.0500, d_fake_loss: 0.0819, g_loss: 1.1828\n",
            "Step [12700/80000], d_real_loss: 0.1701, d_mnist_loss: 0.0559, d_svhn_loss: 0.1142, d_fake_loss: 0.0753, g_loss: 1.2267\n",
            "Step [12710/80000], d_real_loss: 0.0754, d_mnist_loss: 0.0044, d_svhn_loss: 0.0709, d_fake_loss: 0.0370, g_loss: 1.3701\n",
            "Step [12720/80000], d_real_loss: 0.1208, d_mnist_loss: 0.0320, d_svhn_loss: 0.0888, d_fake_loss: 0.0565, g_loss: 1.0607\n",
            "Step [12730/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0161, d_svhn_loss: 0.0263, d_fake_loss: 0.0382, g_loss: 1.4686\n",
            "Step [12740/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0042, d_svhn_loss: 0.0284, d_fake_loss: 0.0564, g_loss: 1.1835\n",
            "Step [12750/80000], d_real_loss: 0.1230, d_mnist_loss: 0.0041, d_svhn_loss: 0.1189, d_fake_loss: 0.0670, g_loss: 1.2382\n",
            "Step [12760/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0200, d_svhn_loss: 0.0403, d_fake_loss: 0.0491, g_loss: 1.2287\n",
            "Step [12770/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0034, d_svhn_loss: 0.0481, d_fake_loss: 0.1053, g_loss: 1.1754\n",
            "Step [12780/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0029, d_svhn_loss: 0.0296, d_fake_loss: 0.0487, g_loss: 1.0768\n",
            "Step [12790/80000], d_real_loss: 0.0707, d_mnist_loss: 0.0235, d_svhn_loss: 0.0473, d_fake_loss: 0.0468, g_loss: 1.3411\n",
            "Step [12800/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0066, d_svhn_loss: 0.0547, d_fake_loss: 0.0355, g_loss: 1.3201\n",
            "Step [12810/80000], d_real_loss: 0.1647, d_mnist_loss: 0.0112, d_svhn_loss: 0.1536, d_fake_loss: 0.1108, g_loss: 1.1764\n",
            "Step [12820/80000], d_real_loss: 0.0906, d_mnist_loss: 0.0459, d_svhn_loss: 0.0447, d_fake_loss: 0.0411, g_loss: 1.2341\n",
            "Step [12830/80000], d_real_loss: 0.1130, d_mnist_loss: 0.0183, d_svhn_loss: 0.0947, d_fake_loss: 0.1089, g_loss: 1.1890\n",
            "Step [12840/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0028, d_svhn_loss: 0.0691, d_fake_loss: 0.0594, g_loss: 1.2354\n",
            "Step [12850/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0139, d_svhn_loss: 0.1033, d_fake_loss: 0.0376, g_loss: 1.1631\n",
            "Step [12860/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0026, d_svhn_loss: 0.0501, d_fake_loss: 0.0372, g_loss: 1.0691\n",
            "Step [12870/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0040, d_svhn_loss: 0.0240, d_fake_loss: 0.0814, g_loss: 1.4606\n",
            "Step [12880/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0043, d_svhn_loss: 0.0484, d_fake_loss: 0.1221, g_loss: 0.9777\n",
            "Step [12890/80000], d_real_loss: 0.1428, d_mnist_loss: 0.0043, d_svhn_loss: 0.1385, d_fake_loss: 0.0334, g_loss: 1.1296\n",
            "Step [12900/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0044, d_svhn_loss: 0.0371, d_fake_loss: 0.0557, g_loss: 1.1739\n",
            "Step [12910/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0078, d_svhn_loss: 0.0601, d_fake_loss: 0.0456, g_loss: 1.1998\n",
            "Step [12920/80000], d_real_loss: 0.0919, d_mnist_loss: 0.0092, d_svhn_loss: 0.0827, d_fake_loss: 0.0767, g_loss: 0.9951\n",
            "Step [12930/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0136, d_svhn_loss: 0.0403, d_fake_loss: 0.1117, g_loss: 1.0744\n",
            "Step [12940/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0036, d_svhn_loss: 0.0392, d_fake_loss: 0.0405, g_loss: 1.1243\n",
            "Step [12950/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0165, d_svhn_loss: 0.0588, d_fake_loss: 0.1722, g_loss: 0.8805\n",
            "Step [12960/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0205, d_svhn_loss: 0.0739, d_fake_loss: 0.1061, g_loss: 0.9502\n",
            "Step [12970/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0172, d_svhn_loss: 0.0385, d_fake_loss: 0.1140, g_loss: 1.1681\n",
            "Step [12980/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0082, d_svhn_loss: 0.0339, d_fake_loss: 0.1144, g_loss: 1.3910\n",
            "Step [12990/80000], d_real_loss: 0.0830, d_mnist_loss: 0.0144, d_svhn_loss: 0.0686, d_fake_loss: 0.0458, g_loss: 1.1918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [13000/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0137, d_svhn_loss: 0.0288, d_fake_loss: 0.0431, g_loss: 1.0068\n",
            "saved ./samples_mnist_svhn/sample-13000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-13000-s-m.png\n",
            "Step [13010/80000], d_real_loss: 0.0965, d_mnist_loss: 0.0027, d_svhn_loss: 0.0938, d_fake_loss: 0.0428, g_loss: 1.2487\n",
            "Step [13020/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0023, d_svhn_loss: 0.0552, d_fake_loss: 0.0609, g_loss: 1.3010\n",
            "Step [13030/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0116, d_svhn_loss: 0.0355, d_fake_loss: 0.0363, g_loss: 1.1682\n",
            "Step [13040/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0210, d_svhn_loss: 0.0331, d_fake_loss: 0.0732, g_loss: 1.1089\n",
            "Step [13050/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0318, d_svhn_loss: 0.0520, d_fake_loss: 0.1194, g_loss: 1.3145\n",
            "Step [13060/80000], d_real_loss: 0.1725, d_mnist_loss: 0.0057, d_svhn_loss: 0.1668, d_fake_loss: 0.1784, g_loss: 1.5544\n",
            "Step [13070/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0031, d_svhn_loss: 0.0261, d_fake_loss: 0.1137, g_loss: 1.0053\n",
            "Step [13080/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0022, d_svhn_loss: 0.0481, d_fake_loss: 0.0554, g_loss: 1.0559\n",
            "Step [13090/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0038, d_svhn_loss: 0.0349, d_fake_loss: 0.0473, g_loss: 1.1334\n",
            "Step [13100/80000], d_real_loss: 0.2624, d_mnist_loss: 0.0023, d_svhn_loss: 0.2601, d_fake_loss: 0.0616, g_loss: 1.2149\n",
            "Step [13110/80000], d_real_loss: 0.1726, d_mnist_loss: 0.1351, d_svhn_loss: 0.0374, d_fake_loss: 0.1422, g_loss: 1.1213\n",
            "Step [13120/80000], d_real_loss: 0.1098, d_mnist_loss: 0.0089, d_svhn_loss: 0.1010, d_fake_loss: 0.1658, g_loss: 1.2198\n",
            "Step [13130/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0038, d_svhn_loss: 0.0228, d_fake_loss: 0.0381, g_loss: 1.1202\n",
            "Step [13140/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0133, d_svhn_loss: 0.0430, d_fake_loss: 0.0863, g_loss: 1.3214\n",
            "Step [13150/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0065, d_svhn_loss: 0.0348, d_fake_loss: 0.0524, g_loss: 1.2271\n",
            "Step [13160/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0032, d_svhn_loss: 0.0533, d_fake_loss: 0.1289, g_loss: 1.2578\n",
            "Step [13170/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0240, d_svhn_loss: 0.0447, d_fake_loss: 0.2192, g_loss: 1.2666\n",
            "Step [13180/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0184, d_svhn_loss: 0.0342, d_fake_loss: 0.0351, g_loss: 1.1292\n",
            "Step [13190/80000], d_real_loss: 0.0735, d_mnist_loss: 0.0022, d_svhn_loss: 0.0713, d_fake_loss: 0.0408, g_loss: 1.2419\n",
            "Step [13200/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0062, d_svhn_loss: 0.0477, d_fake_loss: 0.0382, g_loss: 1.2397\n",
            "Step [13210/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0077, d_svhn_loss: 0.0312, d_fake_loss: 0.0536, g_loss: 1.2051\n",
            "Step [13220/80000], d_real_loss: 0.0905, d_mnist_loss: 0.0073, d_svhn_loss: 0.0832, d_fake_loss: 0.0499, g_loss: 0.9387\n",
            "Step [13230/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0033, d_svhn_loss: 0.0327, d_fake_loss: 0.0464, g_loss: 1.3188\n",
            "Step [13240/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0136, d_svhn_loss: 0.0338, d_fake_loss: 0.0363, g_loss: 1.2427\n",
            "Step [13250/80000], d_real_loss: 0.1643, d_mnist_loss: 0.0634, d_svhn_loss: 0.1009, d_fake_loss: 0.0502, g_loss: 1.1403\n",
            "Step [13260/80000], d_real_loss: 0.0796, d_mnist_loss: 0.0347, d_svhn_loss: 0.0449, d_fake_loss: 0.2439, g_loss: 1.7713\n",
            "Step [13270/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0029, d_svhn_loss: 0.0433, d_fake_loss: 0.0443, g_loss: 0.9379\n",
            "Step [13280/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0043, d_svhn_loss: 0.0287, d_fake_loss: 0.0389, g_loss: 1.1288\n",
            "Step [13290/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0023, d_svhn_loss: 0.0729, d_fake_loss: 0.0641, g_loss: 1.1640\n",
            "Step [13300/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0470, d_svhn_loss: 0.0286, d_fake_loss: 0.0516, g_loss: 1.0758\n",
            "Step [13310/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0236, d_svhn_loss: 0.0240, d_fake_loss: 0.0727, g_loss: 1.1832\n",
            "Step [13320/80000], d_real_loss: 0.1416, d_mnist_loss: 0.0051, d_svhn_loss: 0.1365, d_fake_loss: 0.1941, g_loss: 1.0676\n",
            "Step [13330/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0042, d_svhn_loss: 0.0619, d_fake_loss: 0.0513, g_loss: 1.2279\n",
            "Step [13340/80000], d_real_loss: 0.0792, d_mnist_loss: 0.0260, d_svhn_loss: 0.0532, d_fake_loss: 0.0655, g_loss: 1.1014\n",
            "Step [13350/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0220, d_svhn_loss: 0.0375, d_fake_loss: 0.0520, g_loss: 1.3011\n",
            "Step [13360/80000], d_real_loss: 0.1226, d_mnist_loss: 0.0050, d_svhn_loss: 0.1176, d_fake_loss: 0.0494, g_loss: 1.2270\n",
            "Step [13370/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0104, d_svhn_loss: 0.0427, d_fake_loss: 0.0390, g_loss: 1.0673\n",
            "Step [13380/80000], d_real_loss: 0.1485, d_mnist_loss: 0.0137, d_svhn_loss: 0.1348, d_fake_loss: 0.1439, g_loss: 1.2455\n",
            "Step [13390/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0034, d_svhn_loss: 0.0728, d_fake_loss: 0.0318, g_loss: 1.1452\n",
            "Step [13400/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0057, d_svhn_loss: 0.0490, d_fake_loss: 0.0873, g_loss: 1.1641\n",
            "Step [13410/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0089, d_svhn_loss: 0.0582, d_fake_loss: 0.1236, g_loss: 1.2213\n",
            "Step [13420/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0069, d_svhn_loss: 0.0530, d_fake_loss: 0.0644, g_loss: 1.0500\n",
            "Step [13430/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0055, d_svhn_loss: 0.0508, d_fake_loss: 0.1104, g_loss: 1.0418\n",
            "Step [13440/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0039, d_svhn_loss: 0.0310, d_fake_loss: 0.0887, g_loss: 1.1717\n",
            "Step [13450/80000], d_real_loss: 0.0757, d_mnist_loss: 0.0359, d_svhn_loss: 0.0398, d_fake_loss: 0.0774, g_loss: 1.2153\n",
            "Step [13460/80000], d_real_loss: 0.1047, d_mnist_loss: 0.0034, d_svhn_loss: 0.1013, d_fake_loss: 0.2522, g_loss: 1.3913\n",
            "Step [13470/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0144, d_svhn_loss: 0.0460, d_fake_loss: 0.0927, g_loss: 1.5407\n",
            "Step [13480/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0050, d_svhn_loss: 0.0338, d_fake_loss: 0.0769, g_loss: 1.4094\n",
            "Step [13490/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0091, d_svhn_loss: 0.1081, d_fake_loss: 0.1436, g_loss: 1.0564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [13500/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0086, d_svhn_loss: 0.0307, d_fake_loss: 0.0309, g_loss: 1.0301\n",
            "saved ./samples_mnist_svhn/sample-13500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-13500-s-m.png\n",
            "Step [13510/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0088, d_svhn_loss: 0.0355, d_fake_loss: 0.1648, g_loss: 1.2144\n",
            "Step [13520/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0027, d_svhn_loss: 0.0423, d_fake_loss: 0.0332, g_loss: 1.0334\n",
            "Step [13530/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0281, d_svhn_loss: 0.0371, d_fake_loss: 0.0309, g_loss: 1.0559\n",
            "Step [13540/80000], d_real_loss: 0.0890, d_mnist_loss: 0.0634, d_svhn_loss: 0.0256, d_fake_loss: 0.0496, g_loss: 1.1361\n",
            "Step [13550/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0070, d_svhn_loss: 0.0550, d_fake_loss: 0.0541, g_loss: 1.2524\n",
            "Step [13560/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0206, d_svhn_loss: 0.0349, d_fake_loss: 0.0701, g_loss: 1.2845\n",
            "Step [13570/80000], d_real_loss: 0.0826, d_mnist_loss: 0.0188, d_svhn_loss: 0.0638, d_fake_loss: 0.0495, g_loss: 0.9949\n",
            "Step [13580/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0152, d_svhn_loss: 0.0319, d_fake_loss: 0.0488, g_loss: 1.1277\n",
            "Step [13590/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0044, d_svhn_loss: 0.0366, d_fake_loss: 0.0522, g_loss: 1.1821\n",
            "Step [13600/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0017, d_svhn_loss: 0.0548, d_fake_loss: 0.0517, g_loss: 1.1331\n",
            "Step [13610/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0179, d_svhn_loss: 0.0297, d_fake_loss: 0.0310, g_loss: 1.4111\n",
            "Step [13620/80000], d_real_loss: 0.0938, d_mnist_loss: 0.0054, d_svhn_loss: 0.0884, d_fake_loss: 0.0461, g_loss: 1.2286\n",
            "Step [13630/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0118, d_svhn_loss: 0.0208, d_fake_loss: 0.0968, g_loss: 1.3397\n",
            "Step [13640/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0059, d_svhn_loss: 0.0338, d_fake_loss: 0.0944, g_loss: 1.3423\n",
            "Step [13650/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0072, d_svhn_loss: 0.0360, d_fake_loss: 0.0491, g_loss: 1.1109\n",
            "Step [13660/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0095, d_svhn_loss: 0.0380, d_fake_loss: 0.0335, g_loss: 1.1028\n",
            "Step [13670/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0205, d_svhn_loss: 0.0632, d_fake_loss: 0.0769, g_loss: 1.0961\n",
            "Step [13680/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0048, d_svhn_loss: 0.0685, d_fake_loss: 0.4012, g_loss: 1.2502\n",
            "Step [13690/80000], d_real_loss: 0.1300, d_mnist_loss: 0.0059, d_svhn_loss: 0.1241, d_fake_loss: 0.0500, g_loss: 1.1578\n",
            "Step [13700/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0148, d_svhn_loss: 0.0537, d_fake_loss: 0.0957, g_loss: 1.2836\n",
            "Step [13710/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0252, d_svhn_loss: 0.0461, d_fake_loss: 0.0643, g_loss: 1.3506\n",
            "Step [13720/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0038, d_svhn_loss: 0.0271, d_fake_loss: 0.0321, g_loss: 1.2329\n",
            "Step [13730/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0203, d_svhn_loss: 0.0432, d_fake_loss: 0.0740, g_loss: 1.1870\n",
            "Step [13740/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0092, d_svhn_loss: 0.0305, d_fake_loss: 0.1942, g_loss: 1.2996\n",
            "Step [13750/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0263, d_svhn_loss: 0.0629, d_fake_loss: 0.0738, g_loss: 1.0558\n",
            "Step [13760/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0074, d_svhn_loss: 0.0295, d_fake_loss: 0.0432, g_loss: 1.2183\n",
            "Step [13770/80000], d_real_loss: 0.0828, d_mnist_loss: 0.0369, d_svhn_loss: 0.0459, d_fake_loss: 0.0842, g_loss: 0.8666\n",
            "Step [13780/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0089, d_svhn_loss: 0.0340, d_fake_loss: 0.1043, g_loss: 0.9626\n",
            "Step [13790/80000], d_real_loss: 0.1351, d_mnist_loss: 0.0041, d_svhn_loss: 0.1310, d_fake_loss: 0.0307, g_loss: 1.2553\n",
            "Step [13800/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0198, d_svhn_loss: 0.0389, d_fake_loss: 0.0612, g_loss: 1.1849\n",
            "Step [13810/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0190, d_svhn_loss: 0.0324, d_fake_loss: 0.0391, g_loss: 1.0994\n",
            "Step [13820/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0159, d_svhn_loss: 0.0321, d_fake_loss: 0.1751, g_loss: 1.0537\n",
            "Step [13830/80000], d_real_loss: 0.0943, d_mnist_loss: 0.0404, d_svhn_loss: 0.0540, d_fake_loss: 0.0989, g_loss: 1.2088\n",
            "Step [13840/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0078, d_svhn_loss: 0.0373, d_fake_loss: 0.0280, g_loss: 1.3183\n",
            "Step [13850/80000], d_real_loss: 0.1495, d_mnist_loss: 0.0267, d_svhn_loss: 0.1228, d_fake_loss: 0.0461, g_loss: 1.1747\n",
            "Step [13860/80000], d_real_loss: 0.1127, d_mnist_loss: 0.0074, d_svhn_loss: 0.1053, d_fake_loss: 0.0555, g_loss: 1.1778\n",
            "Step [13870/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0032, d_svhn_loss: 0.0572, d_fake_loss: 0.1249, g_loss: 1.0340\n",
            "Step [13880/80000], d_real_loss: 0.0817, d_mnist_loss: 0.0066, d_svhn_loss: 0.0751, d_fake_loss: 0.0474, g_loss: 1.3557\n",
            "Step [13890/80000], d_real_loss: 0.4867, d_mnist_loss: 0.4478, d_svhn_loss: 0.0389, d_fake_loss: 0.5106, g_loss: 1.6528\n",
            "Step [13900/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0077, d_svhn_loss: 0.0450, d_fake_loss: 0.1190, g_loss: 1.0790\n",
            "Step [13910/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0056, d_svhn_loss: 0.0250, d_fake_loss: 0.0384, g_loss: 1.0684\n",
            "Step [13920/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0051, d_svhn_loss: 0.0800, d_fake_loss: 0.0949, g_loss: 1.4473\n",
            "Step [13930/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0210, d_svhn_loss: 0.0475, d_fake_loss: 0.0414, g_loss: 1.0871\n",
            "Step [13940/80000], d_real_loss: 0.1665, d_mnist_loss: 0.0058, d_svhn_loss: 0.1608, d_fake_loss: 0.0701, g_loss: 1.1014\n",
            "Step [13950/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0025, d_svhn_loss: 0.0691, d_fake_loss: 0.1109, g_loss: 1.0343\n",
            "Step [13960/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0025, d_svhn_loss: 0.0664, d_fake_loss: 0.1416, g_loss: 1.1250\n",
            "Step [13970/80000], d_real_loss: 0.1676, d_mnist_loss: 0.1047, d_svhn_loss: 0.0629, d_fake_loss: 0.0599, g_loss: 1.0971\n",
            "Step [13980/80000], d_real_loss: 0.1056, d_mnist_loss: 0.0129, d_svhn_loss: 0.0927, d_fake_loss: 0.1824, g_loss: 1.0495\n",
            "Step [13990/80000], d_real_loss: 0.0644, d_mnist_loss: 0.0202, d_svhn_loss: 0.0442, d_fake_loss: 0.0408, g_loss: 1.0030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [14000/80000], d_real_loss: 0.1362, d_mnist_loss: 0.0049, d_svhn_loss: 0.1313, d_fake_loss: 0.1618, g_loss: 1.3896\n",
            "saved ./samples_mnist_svhn/sample-14000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-14000-s-m.png\n",
            "Step [14010/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0035, d_svhn_loss: 0.0378, d_fake_loss: 0.0854, g_loss: 1.1875\n",
            "Step [14020/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0140, d_svhn_loss: 0.0511, d_fake_loss: 0.0623, g_loss: 1.1428\n",
            "Step [14030/80000], d_real_loss: 0.1033, d_mnist_loss: 0.0048, d_svhn_loss: 0.0985, d_fake_loss: 0.2228, g_loss: 1.2443\n",
            "Step [14040/80000], d_real_loss: 0.0807, d_mnist_loss: 0.0033, d_svhn_loss: 0.0774, d_fake_loss: 0.0968, g_loss: 1.0490\n",
            "Step [14050/80000], d_real_loss: 0.1890, d_mnist_loss: 0.0128, d_svhn_loss: 0.1762, d_fake_loss: 0.0668, g_loss: 1.1660\n",
            "Step [14060/80000], d_real_loss: 0.1741, d_mnist_loss: 0.0185, d_svhn_loss: 0.1556, d_fake_loss: 0.0486, g_loss: 1.1767\n",
            "Step [14070/80000], d_real_loss: 0.2949, d_mnist_loss: 0.0238, d_svhn_loss: 0.2710, d_fake_loss: 0.1016, g_loss: 1.2019\n",
            "Step [14080/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0162, d_svhn_loss: 0.0547, d_fake_loss: 0.0581, g_loss: 1.3201\n",
            "Step [14090/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0112, d_svhn_loss: 0.0157, d_fake_loss: 0.0267, g_loss: 1.0646\n",
            "Step [14100/80000], d_real_loss: 0.0861, d_mnist_loss: 0.0034, d_svhn_loss: 0.0827, d_fake_loss: 0.0784, g_loss: 1.0925\n",
            "Step [14110/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0032, d_svhn_loss: 0.0412, d_fake_loss: 0.0241, g_loss: 1.1531\n",
            "Step [14120/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0069, d_svhn_loss: 0.0282, d_fake_loss: 0.0475, g_loss: 1.1597\n",
            "Step [14130/80000], d_real_loss: 0.2153, d_mnist_loss: 0.0036, d_svhn_loss: 0.2118, d_fake_loss: 0.0604, g_loss: 1.2781\n",
            "Step [14140/80000], d_real_loss: 0.0626, d_mnist_loss: 0.0038, d_svhn_loss: 0.0588, d_fake_loss: 0.1610, g_loss: 1.1138\n",
            "Step [14150/80000], d_real_loss: 0.0857, d_mnist_loss: 0.0213, d_svhn_loss: 0.0643, d_fake_loss: 0.0414, g_loss: 1.0921\n",
            "Step [14160/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0146, d_svhn_loss: 0.0644, d_fake_loss: 0.0761, g_loss: 1.2200\n",
            "Step [14170/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0131, d_svhn_loss: 0.0369, d_fake_loss: 0.0459, g_loss: 1.0449\n",
            "Step [14180/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0049, d_svhn_loss: 0.0536, d_fake_loss: 0.0791, g_loss: 1.0016\n",
            "Step [14190/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0053, d_svhn_loss: 0.0223, d_fake_loss: 0.0469, g_loss: 1.0908\n",
            "Step [14200/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0297, d_svhn_loss: 0.0396, d_fake_loss: 0.0480, g_loss: 1.2625\n",
            "Step [14210/80000], d_real_loss: 0.1443, d_mnist_loss: 0.0020, d_svhn_loss: 0.1423, d_fake_loss: 0.1167, g_loss: 1.2077\n",
            "Step [14220/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0066, d_svhn_loss: 0.0360, d_fake_loss: 0.0389, g_loss: 1.2880\n",
            "Step [14230/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0052, d_svhn_loss: 0.0430, d_fake_loss: 0.0231, g_loss: 1.1354\n",
            "Step [14240/80000], d_real_loss: 0.1226, d_mnist_loss: 0.0391, d_svhn_loss: 0.0835, d_fake_loss: 0.0331, g_loss: 1.4204\n",
            "Step [14250/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0045, d_svhn_loss: 0.0658, d_fake_loss: 0.0579, g_loss: 1.1448\n",
            "Step [14260/80000], d_real_loss: 0.0755, d_mnist_loss: 0.0152, d_svhn_loss: 0.0603, d_fake_loss: 0.0558, g_loss: 1.0086\n",
            "Step [14270/80000], d_real_loss: 0.1292, d_mnist_loss: 0.0034, d_svhn_loss: 0.1258, d_fake_loss: 0.0908, g_loss: 1.4304\n",
            "Step [14280/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0113, d_svhn_loss: 0.0460, d_fake_loss: 0.2106, g_loss: 1.1058\n",
            "Step [14290/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0055, d_svhn_loss: 0.0373, d_fake_loss: 0.0768, g_loss: 1.1086\n",
            "Step [14300/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0027, d_svhn_loss: 0.0395, d_fake_loss: 0.1434, g_loss: 1.2148\n",
            "Step [14310/80000], d_real_loss: 0.1475, d_mnist_loss: 0.0495, d_svhn_loss: 0.0979, d_fake_loss: 0.0906, g_loss: 1.1043\n",
            "Step [14320/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0156, d_svhn_loss: 0.0693, d_fake_loss: 0.1048, g_loss: 1.2583\n",
            "Step [14330/80000], d_real_loss: 0.0964, d_mnist_loss: 0.0294, d_svhn_loss: 0.0670, d_fake_loss: 0.0437, g_loss: 1.0291\n",
            "Step [14340/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0335, d_svhn_loss: 0.0358, d_fake_loss: 0.1157, g_loss: 1.1304\n",
            "Step [14350/80000], d_real_loss: 0.2839, d_mnist_loss: 0.0047, d_svhn_loss: 0.2792, d_fake_loss: 0.0914, g_loss: 1.1263\n",
            "Step [14360/80000], d_real_loss: 0.0945, d_mnist_loss: 0.0114, d_svhn_loss: 0.0831, d_fake_loss: 0.1272, g_loss: 1.3637\n",
            "Step [14370/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0112, d_svhn_loss: 0.0574, d_fake_loss: 0.1246, g_loss: 1.0326\n",
            "Step [14380/80000], d_real_loss: 0.1071, d_mnist_loss: 0.0207, d_svhn_loss: 0.0863, d_fake_loss: 0.0604, g_loss: 1.1100\n",
            "Step [14390/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0198, d_svhn_loss: 0.0313, d_fake_loss: 0.0469, g_loss: 1.3151\n",
            "Step [14400/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0149, d_svhn_loss: 0.0360, d_fake_loss: 0.0745, g_loss: 1.1309\n",
            "Step [14410/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0074, d_svhn_loss: 0.0348, d_fake_loss: 0.0347, g_loss: 1.2758\n",
            "Step [14420/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0331, d_svhn_loss: 0.0312, d_fake_loss: 0.1809, g_loss: 1.2440\n",
            "Step [14430/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0034, d_svhn_loss: 0.0488, d_fake_loss: 0.0677, g_loss: 1.1441\n",
            "Step [14440/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0024, d_svhn_loss: 0.0413, d_fake_loss: 0.0519, g_loss: 1.2269\n",
            "Step [14450/80000], d_real_loss: 0.0704, d_mnist_loss: 0.0119, d_svhn_loss: 0.0585, d_fake_loss: 0.0383, g_loss: 1.0175\n",
            "Step [14460/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0079, d_svhn_loss: 0.0725, d_fake_loss: 0.2079, g_loss: 1.0452\n",
            "Step [14470/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0051, d_svhn_loss: 0.0422, d_fake_loss: 0.0373, g_loss: 1.1773\n",
            "Step [14480/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0044, d_svhn_loss: 0.0341, d_fake_loss: 0.0511, g_loss: 1.1510\n",
            "Step [14490/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0101, d_svhn_loss: 0.0377, d_fake_loss: 0.0439, g_loss: 1.2177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [14500/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0216, d_svhn_loss: 0.0389, d_fake_loss: 0.0360, g_loss: 1.1590\n",
            "saved ./samples_mnist_svhn/sample-14500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-14500-s-m.png\n",
            "Step [14510/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0143, d_svhn_loss: 0.0407, d_fake_loss: 0.0798, g_loss: 1.1909\n",
            "Step [14520/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0038, d_svhn_loss: 0.0370, d_fake_loss: 0.0309, g_loss: 1.0938\n",
            "Step [14530/80000], d_real_loss: 0.0957, d_mnist_loss: 0.0048, d_svhn_loss: 0.0909, d_fake_loss: 0.0575, g_loss: 1.1356\n",
            "Step [14540/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0069, d_svhn_loss: 0.0327, d_fake_loss: 0.0280, g_loss: 1.1102\n",
            "Step [14550/80000], d_real_loss: 0.0954, d_mnist_loss: 0.0239, d_svhn_loss: 0.0715, d_fake_loss: 0.0389, g_loss: 1.3862\n",
            "Step [14560/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0130, d_svhn_loss: 0.0327, d_fake_loss: 0.0794, g_loss: 1.1664\n",
            "Step [14570/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0147, d_svhn_loss: 0.0388, d_fake_loss: 0.0341, g_loss: 1.3144\n",
            "Step [14580/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0030, d_svhn_loss: 0.0507, d_fake_loss: 0.0575, g_loss: 1.0564\n",
            "Step [14590/80000], d_real_loss: 0.1577, d_mnist_loss: 0.0077, d_svhn_loss: 0.1501, d_fake_loss: 0.1404, g_loss: 1.2173\n",
            "Step [14600/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0030, d_svhn_loss: 0.0804, d_fake_loss: 0.0272, g_loss: 1.1600\n",
            "Step [14610/80000], d_real_loss: 0.1631, d_mnist_loss: 0.0200, d_svhn_loss: 0.1431, d_fake_loss: 0.0374, g_loss: 1.2918\n",
            "Step [14620/80000], d_real_loss: 0.1072, d_mnist_loss: 0.0834, d_svhn_loss: 0.0238, d_fake_loss: 0.0501, g_loss: 1.1973\n",
            "Step [14630/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0045, d_svhn_loss: 0.0695, d_fake_loss: 0.1408, g_loss: 1.0297\n",
            "Step [14640/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0066, d_svhn_loss: 0.0696, d_fake_loss: 0.0342, g_loss: 1.0584\n",
            "Step [14650/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0033, d_svhn_loss: 0.0523, d_fake_loss: 0.0377, g_loss: 1.2111\n",
            "Step [14660/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0041, d_svhn_loss: 0.0292, d_fake_loss: 0.0255, g_loss: 1.0957\n",
            "Step [14670/80000], d_real_loss: 0.1188, d_mnist_loss: 0.0051, d_svhn_loss: 0.1137, d_fake_loss: 0.0418, g_loss: 1.0893\n",
            "Step [14680/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0048, d_svhn_loss: 0.0763, d_fake_loss: 0.1273, g_loss: 1.1349\n",
            "Step [14690/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0051, d_svhn_loss: 0.0410, d_fake_loss: 0.0496, g_loss: 1.1857\n",
            "Step [14700/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0051, d_svhn_loss: 0.0538, d_fake_loss: 0.0359, g_loss: 1.0311\n",
            "Step [14710/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0089, d_svhn_loss: 0.0717, d_fake_loss: 0.0403, g_loss: 1.1707\n",
            "Step [14720/80000], d_real_loss: 0.1133, d_mnist_loss: 0.0066, d_svhn_loss: 0.1067, d_fake_loss: 0.0604, g_loss: 1.1706\n",
            "Step [14730/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0027, d_svhn_loss: 0.0672, d_fake_loss: 0.0831, g_loss: 1.1993\n",
            "Step [14740/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0067, d_svhn_loss: 0.0486, d_fake_loss: 0.0427, g_loss: 1.3089\n",
            "Step [14750/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0154, d_svhn_loss: 0.0274, d_fake_loss: 0.0476, g_loss: 1.1603\n",
            "Step [14760/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0034, d_svhn_loss: 0.0385, d_fake_loss: 0.0370, g_loss: 1.0883\n",
            "Step [14770/80000], d_real_loss: 0.1169, d_mnist_loss: 0.0151, d_svhn_loss: 0.1018, d_fake_loss: 0.1283, g_loss: 0.9648\n",
            "Step [14780/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0070, d_svhn_loss: 0.0469, d_fake_loss: 0.0465, g_loss: 1.1750\n",
            "Step [14790/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0020, d_svhn_loss: 0.0501, d_fake_loss: 0.1056, g_loss: 1.1731\n",
            "Step [14800/80000], d_real_loss: 0.1790, d_mnist_loss: 0.0017, d_svhn_loss: 0.1774, d_fake_loss: 0.0681, g_loss: 1.1233\n",
            "Step [14810/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0037, d_svhn_loss: 0.0329, d_fake_loss: 0.0431, g_loss: 1.2241\n",
            "Step [14820/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0015, d_svhn_loss: 0.0299, d_fake_loss: 0.0661, g_loss: 1.1811\n",
            "Step [14830/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0012, d_svhn_loss: 0.0411, d_fake_loss: 0.0275, g_loss: 1.2277\n",
            "Step [14840/80000], d_real_loss: 0.1378, d_mnist_loss: 0.0080, d_svhn_loss: 0.1298, d_fake_loss: 0.1597, g_loss: 1.0186\n",
            "Step [14850/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0076, d_svhn_loss: 0.0359, d_fake_loss: 0.1745, g_loss: 1.0613\n",
            "Step [14860/80000], d_real_loss: 0.0732, d_mnist_loss: 0.0399, d_svhn_loss: 0.0333, d_fake_loss: 0.2356, g_loss: 1.9070\n",
            "Step [14870/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0025, d_svhn_loss: 0.0821, d_fake_loss: 0.0552, g_loss: 1.0287\n",
            "Step [14880/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0026, d_svhn_loss: 0.0414, d_fake_loss: 0.0509, g_loss: 0.9865\n",
            "Step [14890/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0019, d_svhn_loss: 0.0734, d_fake_loss: 0.1063, g_loss: 1.5051\n",
            "Step [14900/80000], d_real_loss: 0.1348, d_mnist_loss: 0.0217, d_svhn_loss: 0.1130, d_fake_loss: 0.0422, g_loss: 0.9553\n",
            "Step [14910/80000], d_real_loss: 0.0854, d_mnist_loss: 0.0309, d_svhn_loss: 0.0545, d_fake_loss: 0.1400, g_loss: 1.3602\n",
            "Step [14920/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0154, d_svhn_loss: 0.0334, d_fake_loss: 0.0749, g_loss: 1.2342\n",
            "Step [14930/80000], d_real_loss: 0.0865, d_mnist_loss: 0.0031, d_svhn_loss: 0.0834, d_fake_loss: 0.0437, g_loss: 1.0331\n",
            "Step [14940/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0059, d_svhn_loss: 0.0413, d_fake_loss: 0.0283, g_loss: 1.2623\n",
            "Step [14950/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0030, d_svhn_loss: 0.0382, d_fake_loss: 0.0634, g_loss: 1.0707\n",
            "Step [14960/80000], d_real_loss: 0.3303, d_mnist_loss: 0.0085, d_svhn_loss: 0.3217, d_fake_loss: 0.1812, g_loss: 0.9841\n",
            "Step [14970/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0026, d_svhn_loss: 0.0285, d_fake_loss: 0.0729, g_loss: 1.3063\n",
            "Step [14980/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0031, d_svhn_loss: 0.0536, d_fake_loss: 0.0280, g_loss: 1.1736\n",
            "Step [14990/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0027, d_svhn_loss: 0.0348, d_fake_loss: 0.0471, g_loss: 1.0315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [15000/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0098, d_svhn_loss: 0.0467, d_fake_loss: 0.0499, g_loss: 1.2364\n",
            "saved ./samples_mnist_svhn/sample-15000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-15000-s-m.png\n",
            "Step [15010/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0177, d_svhn_loss: 0.0443, d_fake_loss: 0.1106, g_loss: 1.1748\n",
            "Step [15020/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0036, d_svhn_loss: 0.0272, d_fake_loss: 0.0471, g_loss: 1.1839\n",
            "Step [15030/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0075, d_svhn_loss: 0.0372, d_fake_loss: 0.1614, g_loss: 1.1967\n",
            "Step [15040/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0034, d_svhn_loss: 0.0270, d_fake_loss: 0.0316, g_loss: 1.1559\n",
            "Step [15050/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0050, d_svhn_loss: 0.0234, d_fake_loss: 0.0594, g_loss: 1.0427\n",
            "Step [15060/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0150, d_svhn_loss: 0.0290, d_fake_loss: 0.0443, g_loss: 1.2769\n",
            "Step [15070/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0019, d_svhn_loss: 0.0488, d_fake_loss: 0.1943, g_loss: 1.1258\n",
            "Step [15080/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0155, d_svhn_loss: 0.0622, d_fake_loss: 0.0648, g_loss: 1.0408\n",
            "Step [15090/80000], d_real_loss: 0.0807, d_mnist_loss: 0.0211, d_svhn_loss: 0.0596, d_fake_loss: 0.1177, g_loss: 1.2618\n",
            "Step [15100/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0123, d_svhn_loss: 0.0465, d_fake_loss: 0.0400, g_loss: 1.1988\n",
            "Step [15110/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0091, d_svhn_loss: 0.0248, d_fake_loss: 0.0562, g_loss: 1.4655\n",
            "Step [15120/80000], d_real_loss: 0.1096, d_mnist_loss: 0.0180, d_svhn_loss: 0.0916, d_fake_loss: 0.0742, g_loss: 1.3306\n",
            "Step [15130/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0531, d_svhn_loss: 0.0311, d_fake_loss: 0.0656, g_loss: 1.2909\n",
            "Step [15140/80000], d_real_loss: 0.0870, d_mnist_loss: 0.0036, d_svhn_loss: 0.0833, d_fake_loss: 0.0276, g_loss: 1.1516\n",
            "Step [15150/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0018, d_svhn_loss: 0.0625, d_fake_loss: 0.0342, g_loss: 1.4195\n",
            "Step [15160/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0015, d_svhn_loss: 0.0555, d_fake_loss: 0.0328, g_loss: 1.2316\n",
            "Step [15170/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0019, d_svhn_loss: 0.0376, d_fake_loss: 0.0749, g_loss: 1.3184\n",
            "Step [15180/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0126, d_svhn_loss: 0.0329, d_fake_loss: 0.0386, g_loss: 1.1952\n",
            "Step [15190/80000], d_real_loss: 0.1204, d_mnist_loss: 0.0544, d_svhn_loss: 0.0660, d_fake_loss: 0.0874, g_loss: 1.0474\n",
            "Step [15200/80000], d_real_loss: 0.0385, d_mnist_loss: 0.0055, d_svhn_loss: 0.0330, d_fake_loss: 0.0361, g_loss: 1.2013\n",
            "Step [15210/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0025, d_svhn_loss: 0.0583, d_fake_loss: 0.0269, g_loss: 1.1607\n",
            "Step [15220/80000], d_real_loss: 0.1161, d_mnist_loss: 0.0199, d_svhn_loss: 0.0962, d_fake_loss: 0.1494, g_loss: 1.0808\n",
            "Step [15230/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0019, d_svhn_loss: 0.0330, d_fake_loss: 0.0277, g_loss: 1.1687\n",
            "Step [15240/80000], d_real_loss: 0.0937, d_mnist_loss: 0.0579, d_svhn_loss: 0.0358, d_fake_loss: 0.0310, g_loss: 1.5280\n",
            "Step [15250/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0268, d_svhn_loss: 0.0268, d_fake_loss: 0.1251, g_loss: 1.0801\n",
            "Step [15260/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0096, d_svhn_loss: 0.0370, d_fake_loss: 0.0372, g_loss: 1.0908\n",
            "Step [15270/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0035, d_svhn_loss: 0.0476, d_fake_loss: 0.0325, g_loss: 1.1455\n",
            "Step [15280/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0146, d_svhn_loss: 0.0385, d_fake_loss: 0.0769, g_loss: 0.9881\n",
            "Step [15290/80000], d_real_loss: 0.1156, d_mnist_loss: 0.0153, d_svhn_loss: 0.1003, d_fake_loss: 0.0438, g_loss: 1.1432\n",
            "Step [15300/80000], d_real_loss: 0.1238, d_mnist_loss: 0.0239, d_svhn_loss: 0.0998, d_fake_loss: 0.1056, g_loss: 1.1132\n",
            "Step [15310/80000], d_real_loss: 0.1187, d_mnist_loss: 0.0150, d_svhn_loss: 0.1037, d_fake_loss: 0.1566, g_loss: 1.3157\n",
            "Step [15320/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0262, d_svhn_loss: 0.0411, d_fake_loss: 0.1452, g_loss: 1.4140\n",
            "Step [15330/80000], d_real_loss: 0.0728, d_mnist_loss: 0.0070, d_svhn_loss: 0.0657, d_fake_loss: 0.0630, g_loss: 1.2765\n",
            "Step [15340/80000], d_real_loss: 0.1253, d_mnist_loss: 0.0329, d_svhn_loss: 0.0924, d_fake_loss: 0.0723, g_loss: 1.2367\n",
            "Step [15350/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0118, d_svhn_loss: 0.0423, d_fake_loss: 0.0468, g_loss: 1.1287\n",
            "Step [15360/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0062, d_svhn_loss: 0.0556, d_fake_loss: 0.0685, g_loss: 1.0490\n",
            "Step [15370/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0026, d_svhn_loss: 0.0345, d_fake_loss: 0.0426, g_loss: 1.2352\n",
            "Step [15380/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0024, d_svhn_loss: 0.0492, d_fake_loss: 0.0622, g_loss: 1.2899\n",
            "Step [15390/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0369, d_svhn_loss: 0.0301, d_fake_loss: 0.0388, g_loss: 1.3363\n",
            "Step [15400/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0061, d_svhn_loss: 0.0207, d_fake_loss: 0.1502, g_loss: 1.1422\n",
            "Step [15410/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0109, d_svhn_loss: 0.0263, d_fake_loss: 0.1280, g_loss: 1.0443\n",
            "Step [15420/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0046, d_svhn_loss: 0.0373, d_fake_loss: 0.0815, g_loss: 1.1130\n",
            "Step [15430/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0062, d_svhn_loss: 0.0404, d_fake_loss: 0.1062, g_loss: 1.4317\n",
            "Step [15440/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0018, d_svhn_loss: 0.0514, d_fake_loss: 0.1218, g_loss: 1.1395\n",
            "Step [15450/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0139, d_svhn_loss: 0.0617, d_fake_loss: 0.0354, g_loss: 1.2297\n",
            "Step [15460/80000], d_real_loss: 0.1071, d_mnist_loss: 0.0025, d_svhn_loss: 0.1046, d_fake_loss: 0.1302, g_loss: 1.2618\n",
            "Step [15470/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0020, d_svhn_loss: 0.0578, d_fake_loss: 0.0384, g_loss: 1.3030\n",
            "Step [15480/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0072, d_svhn_loss: 0.0301, d_fake_loss: 0.0393, g_loss: 1.2204\n",
            "Step [15490/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0163, d_svhn_loss: 0.0265, d_fake_loss: 0.0974, g_loss: 1.0903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [15500/80000], d_real_loss: 0.0927, d_mnist_loss: 0.0173, d_svhn_loss: 0.0755, d_fake_loss: 0.1901, g_loss: 1.0241\n",
            "saved ./samples_mnist_svhn/sample-15500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-15500-s-m.png\n",
            "Step [15510/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0026, d_svhn_loss: 0.0498, d_fake_loss: 0.0554, g_loss: 1.0299\n",
            "Step [15520/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0030, d_svhn_loss: 0.0325, d_fake_loss: 0.0666, g_loss: 1.3345\n",
            "Step [15530/80000], d_real_loss: 0.2138, d_mnist_loss: 0.0079, d_svhn_loss: 0.2059, d_fake_loss: 0.0961, g_loss: 1.3635\n",
            "Step [15540/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0118, d_svhn_loss: 0.0304, d_fake_loss: 0.0957, g_loss: 1.2339\n",
            "Step [15550/80000], d_real_loss: 0.0951, d_mnist_loss: 0.0065, d_svhn_loss: 0.0887, d_fake_loss: 0.0641, g_loss: 1.3605\n",
            "Step [15560/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0064, d_svhn_loss: 0.0452, d_fake_loss: 0.0343, g_loss: 1.1800\n",
            "Step [15570/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0070, d_svhn_loss: 0.0265, d_fake_loss: 0.0472, g_loss: 1.2120\n",
            "Step [15580/80000], d_real_loss: 0.1014, d_mnist_loss: 0.0084, d_svhn_loss: 0.0930, d_fake_loss: 0.1842, g_loss: 0.9395\n",
            "Step [15590/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0072, d_svhn_loss: 0.0420, d_fake_loss: 0.1266, g_loss: 1.0401\n",
            "Step [15600/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0028, d_svhn_loss: 0.0314, d_fake_loss: 0.0382, g_loss: 1.2261\n",
            "Step [15610/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0025, d_svhn_loss: 0.0343, d_fake_loss: 0.1019, g_loss: 1.2274\n",
            "Step [15620/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0228, d_svhn_loss: 0.0640, d_fake_loss: 0.1114, g_loss: 1.3865\n",
            "Step [15630/80000], d_real_loss: 0.0914, d_mnist_loss: 0.0019, d_svhn_loss: 0.0895, d_fake_loss: 0.0393, g_loss: 1.0502\n",
            "Step [15640/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0034, d_svhn_loss: 0.0478, d_fake_loss: 0.0290, g_loss: 1.1805\n",
            "Step [15650/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0035, d_svhn_loss: 0.0390, d_fake_loss: 0.0574, g_loss: 1.2663\n",
            "Step [15660/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0032, d_svhn_loss: 0.0538, d_fake_loss: 0.1748, g_loss: 1.2182\n",
            "Step [15670/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0021, d_svhn_loss: 0.0434, d_fake_loss: 0.0428, g_loss: 1.1820\n",
            "Step [15680/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0033, d_svhn_loss: 0.0243, d_fake_loss: 0.0556, g_loss: 1.1203\n",
            "Step [15690/80000], d_real_loss: 0.2179, d_mnist_loss: 0.0054, d_svhn_loss: 0.2125, d_fake_loss: 0.0819, g_loss: 1.2000\n",
            "Step [15700/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0022, d_svhn_loss: 0.0446, d_fake_loss: 0.1082, g_loss: 1.2644\n",
            "Step [15710/80000], d_real_loss: 0.0926, d_mnist_loss: 0.0023, d_svhn_loss: 0.0903, d_fake_loss: 0.0361, g_loss: 1.1763\n",
            "Step [15720/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0101, d_svhn_loss: 0.0449, d_fake_loss: 0.0626, g_loss: 1.3209\n",
            "Step [15730/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0196, d_svhn_loss: 0.0339, d_fake_loss: 0.0457, g_loss: 1.2233\n",
            "Step [15740/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0061, d_svhn_loss: 0.0319, d_fake_loss: 0.1462, g_loss: 1.3915\n",
            "Step [15750/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0034, d_svhn_loss: 0.0343, d_fake_loss: 0.0421, g_loss: 1.0119\n",
            "Step [15760/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0039, d_svhn_loss: 0.0461, d_fake_loss: 0.0357, g_loss: 1.2205\n",
            "Step [15770/80000], d_real_loss: 0.0832, d_mnist_loss: 0.0026, d_svhn_loss: 0.0806, d_fake_loss: 0.0775, g_loss: 0.9723\n",
            "Step [15780/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0102, d_svhn_loss: 0.0271, d_fake_loss: 0.0324, g_loss: 1.1393\n",
            "Step [15790/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0132, d_svhn_loss: 0.0585, d_fake_loss: 0.0659, g_loss: 1.2555\n",
            "Step [15800/80000], d_real_loss: 0.1046, d_mnist_loss: 0.0150, d_svhn_loss: 0.0896, d_fake_loss: 0.0625, g_loss: 1.1241\n",
            "Step [15810/80000], d_real_loss: 0.1470, d_mnist_loss: 0.0086, d_svhn_loss: 0.1383, d_fake_loss: 0.0516, g_loss: 1.0374\n",
            "Step [15820/80000], d_real_loss: 0.1464, d_mnist_loss: 0.0045, d_svhn_loss: 0.1419, d_fake_loss: 0.0781, g_loss: 1.3442\n",
            "Step [15830/80000], d_real_loss: 0.1762, d_mnist_loss: 0.0072, d_svhn_loss: 0.1690, d_fake_loss: 0.0473, g_loss: 1.1399\n",
            "Step [15840/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0176, d_svhn_loss: 0.0368, d_fake_loss: 0.0649, g_loss: 1.2772\n",
            "Step [15850/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0169, d_svhn_loss: 0.0406, d_fake_loss: 0.0318, g_loss: 1.1068\n",
            "Step [15860/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0069, d_svhn_loss: 0.0350, d_fake_loss: 0.0341, g_loss: 1.3442\n",
            "Step [15870/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0098, d_svhn_loss: 0.0454, d_fake_loss: 0.0333, g_loss: 1.1216\n",
            "Step [15880/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0121, d_svhn_loss: 0.0267, d_fake_loss: 0.0447, g_loss: 1.3151\n",
            "Step [15890/80000], d_real_loss: 0.0821, d_mnist_loss: 0.0064, d_svhn_loss: 0.0757, d_fake_loss: 0.0701, g_loss: 1.0909\n",
            "Step [15900/80000], d_real_loss: 0.1450, d_mnist_loss: 0.0365, d_svhn_loss: 0.1085, d_fake_loss: 0.1888, g_loss: 1.6757\n",
            "Step [15910/80000], d_real_loss: 0.1025, d_mnist_loss: 0.0026, d_svhn_loss: 0.0999, d_fake_loss: 0.0434, g_loss: 0.9945\n",
            "Step [15920/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0124, d_svhn_loss: 0.0246, d_fake_loss: 0.0610, g_loss: 1.1003\n",
            "Step [15930/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0050, d_svhn_loss: 0.0413, d_fake_loss: 0.0296, g_loss: 1.1668\n",
            "Step [15940/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0031, d_svhn_loss: 0.0484, d_fake_loss: 0.0332, g_loss: 1.1471\n",
            "Step [15950/80000], d_real_loss: 0.1611, d_mnist_loss: 0.0089, d_svhn_loss: 0.1522, d_fake_loss: 0.0620, g_loss: 1.2687\n",
            "Step [15960/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0142, d_svhn_loss: 0.0400, d_fake_loss: 0.0678, g_loss: 1.0715\n",
            "Step [15970/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0129, d_svhn_loss: 0.0385, d_fake_loss: 0.0457, g_loss: 1.2195\n",
            "Step [15980/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0018, d_svhn_loss: 0.0747, d_fake_loss: 0.0459, g_loss: 1.1343\n",
            "Step [15990/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0021, d_svhn_loss: 0.0544, d_fake_loss: 0.0841, g_loss: 1.2186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [16000/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0017, d_svhn_loss: 0.0403, d_fake_loss: 0.1303, g_loss: 1.0484\n",
            "saved ./samples_mnist_svhn/sample-16000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-16000-s-m.png\n",
            "Step [16010/80000], d_real_loss: 0.4563, d_mnist_loss: 0.3509, d_svhn_loss: 0.1053, d_fake_loss: 0.1634, g_loss: 2.0926\n",
            "Step [16020/80000], d_real_loss: 0.0891, d_mnist_loss: 0.0170, d_svhn_loss: 0.0721, d_fake_loss: 0.1181, g_loss: 1.1268\n",
            "Step [16030/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0212, d_svhn_loss: 0.0500, d_fake_loss: 0.0502, g_loss: 1.2485\n",
            "Step [16040/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0225, d_svhn_loss: 0.0421, d_fake_loss: 0.1031, g_loss: 1.1305\n",
            "Step [16050/80000], d_real_loss: 0.1150, d_mnist_loss: 0.0180, d_svhn_loss: 0.0970, d_fake_loss: 0.0721, g_loss: 1.1282\n",
            "Step [16060/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0034, d_svhn_loss: 0.0326, d_fake_loss: 0.0267, g_loss: 1.2179\n",
            "Step [16070/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0018, d_svhn_loss: 0.0389, d_fake_loss: 0.0531, g_loss: 1.2352\n",
            "Step [16080/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0029, d_svhn_loss: 0.0414, d_fake_loss: 0.0458, g_loss: 1.3383\n",
            "Step [16090/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0031, d_svhn_loss: 0.0496, d_fake_loss: 0.0612, g_loss: 1.3090\n",
            "Step [16100/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0049, d_svhn_loss: 0.0434, d_fake_loss: 0.0484, g_loss: 1.0499\n",
            "Step [16110/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0084, d_svhn_loss: 0.0395, d_fake_loss: 0.0449, g_loss: 1.1692\n",
            "Step [16120/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0171, d_svhn_loss: 0.0399, d_fake_loss: 0.1710, g_loss: 0.9865\n",
            "Step [16130/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0153, d_svhn_loss: 0.0298, d_fake_loss: 0.0920, g_loss: 1.0305\n",
            "Step [16140/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0185, d_svhn_loss: 0.0894, d_fake_loss: 0.0303, g_loss: 1.1827\n",
            "Step [16150/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0033, d_svhn_loss: 0.0456, d_fake_loss: 0.1010, g_loss: 1.1745\n",
            "Step [16160/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0058, d_svhn_loss: 0.0333, d_fake_loss: 0.0260, g_loss: 1.1905\n",
            "Step [16170/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0227, d_svhn_loss: 0.0315, d_fake_loss: 0.0466, g_loss: 1.1676\n",
            "Step [16180/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0024, d_svhn_loss: 0.0303, d_fake_loss: 0.0870, g_loss: 1.1259\n",
            "Step [16190/80000], d_real_loss: 0.1567, d_mnist_loss: 0.0087, d_svhn_loss: 0.1480, d_fake_loss: 0.0792, g_loss: 1.0880\n",
            "Step [16200/80000], d_real_loss: 0.0979, d_mnist_loss: 0.0416, d_svhn_loss: 0.0563, d_fake_loss: 0.0522, g_loss: 1.0445\n",
            "Step [16210/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0043, d_svhn_loss: 0.0651, d_fake_loss: 0.0639, g_loss: 1.1210\n",
            "Step [16220/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0023, d_svhn_loss: 0.0681, d_fake_loss: 0.0627, g_loss: 1.2219\n",
            "Step [16230/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0059, d_svhn_loss: 0.0261, d_fake_loss: 0.0402, g_loss: 1.1862\n",
            "Step [16240/80000], d_real_loss: 0.1331, d_mnist_loss: 0.0070, d_svhn_loss: 0.1261, d_fake_loss: 0.2148, g_loss: 1.1563\n",
            "Step [16250/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0021, d_svhn_loss: 0.0502, d_fake_loss: 0.1575, g_loss: 1.2701\n",
            "Step [16260/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0121, d_svhn_loss: 0.0704, d_fake_loss: 0.0454, g_loss: 1.1754\n",
            "Step [16270/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0057, d_svhn_loss: 0.0418, d_fake_loss: 0.1476, g_loss: 1.1012\n",
            "Step [16280/80000], d_real_loss: 0.1120, d_mnist_loss: 0.0014, d_svhn_loss: 0.1106, d_fake_loss: 0.1188, g_loss: 1.1542\n",
            "Step [16290/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0153, d_svhn_loss: 0.0624, d_fake_loss: 0.0722, g_loss: 1.2282\n",
            "Step [16300/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0144, d_svhn_loss: 0.0427, d_fake_loss: 0.0450, g_loss: 1.1926\n",
            "Step [16310/80000], d_real_loss: 0.1962, d_mnist_loss: 0.0029, d_svhn_loss: 0.1933, d_fake_loss: 0.2047, g_loss: 1.0661\n",
            "Step [16320/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0019, d_svhn_loss: 0.0800, d_fake_loss: 0.0485, g_loss: 1.4597\n",
            "Step [16330/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0082, d_svhn_loss: 0.0363, d_fake_loss: 0.0516, g_loss: 1.2838\n",
            "Step [16340/80000], d_real_loss: 0.1028, d_mnist_loss: 0.0091, d_svhn_loss: 0.0937, d_fake_loss: 0.0513, g_loss: 1.3876\n",
            "Step [16350/80000], d_real_loss: 0.0855, d_mnist_loss: 0.0018, d_svhn_loss: 0.0837, d_fake_loss: 0.0317, g_loss: 1.1857\n",
            "Step [16360/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0044, d_svhn_loss: 0.0534, d_fake_loss: 0.0562, g_loss: 1.2816\n",
            "Step [16370/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0095, d_svhn_loss: 0.0705, d_fake_loss: 0.0484, g_loss: 1.1764\n",
            "Step [16380/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0245, d_svhn_loss: 0.0511, d_fake_loss: 0.0382, g_loss: 1.2070\n",
            "Step [16390/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0071, d_svhn_loss: 0.0301, d_fake_loss: 0.2587, g_loss: 1.0722\n",
            "Step [16400/80000], d_real_loss: 0.1025, d_mnist_loss: 0.0052, d_svhn_loss: 0.0974, d_fake_loss: 0.0360, g_loss: 1.2212\n",
            "Step [16410/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0128, d_svhn_loss: 0.0412, d_fake_loss: 0.0364, g_loss: 1.2738\n",
            "Step [16420/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0024, d_svhn_loss: 0.0314, d_fake_loss: 0.0890, g_loss: 1.2785\n",
            "Step [16430/80000], d_real_loss: 0.1481, d_mnist_loss: 0.0222, d_svhn_loss: 0.1258, d_fake_loss: 0.0774, g_loss: 1.1575\n",
            "Step [16440/80000], d_real_loss: 0.1207, d_mnist_loss: 0.0023, d_svhn_loss: 0.1184, d_fake_loss: 0.0457, g_loss: 1.1178\n",
            "Step [16450/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0051, d_svhn_loss: 0.0323, d_fake_loss: 0.0517, g_loss: 1.1747\n",
            "Step [16460/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0020, d_svhn_loss: 0.0361, d_fake_loss: 0.0319, g_loss: 1.1182\n",
            "Step [16470/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0032, d_svhn_loss: 0.0233, d_fake_loss: 0.0332, g_loss: 1.1715\n",
            "Step [16480/80000], d_real_loss: 0.1185, d_mnist_loss: 0.0216, d_svhn_loss: 0.0969, d_fake_loss: 0.0587, g_loss: 1.5193\n",
            "Step [16490/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0026, d_svhn_loss: 0.0530, d_fake_loss: 0.0265, g_loss: 1.2033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [16500/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0187, d_svhn_loss: 0.0276, d_fake_loss: 0.0214, g_loss: 1.0991\n",
            "saved ./samples_mnist_svhn/sample-16500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-16500-s-m.png\n",
            "Step [16510/80000], d_real_loss: 0.0818, d_mnist_loss: 0.0018, d_svhn_loss: 0.0800, d_fake_loss: 0.0680, g_loss: 1.1755\n",
            "Step [16520/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0126, d_svhn_loss: 0.0662, d_fake_loss: 0.1190, g_loss: 1.2931\n",
            "Step [16530/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0024, d_svhn_loss: 0.0331, d_fake_loss: 0.1020, g_loss: 1.2204\n",
            "Step [16540/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0045, d_svhn_loss: 0.0295, d_fake_loss: 0.0505, g_loss: 1.2798\n",
            "Step [16550/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0021, d_svhn_loss: 0.0401, d_fake_loss: 0.0445, g_loss: 1.1998\n",
            "Step [16560/80000], d_real_loss: 0.1263, d_mnist_loss: 0.0173, d_svhn_loss: 0.1090, d_fake_loss: 0.0965, g_loss: 1.0154\n",
            "Step [16570/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0063, d_svhn_loss: 0.0586, d_fake_loss: 0.1544, g_loss: 1.4717\n",
            "Step [16580/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0037, d_svhn_loss: 0.0434, d_fake_loss: 0.0435, g_loss: 1.1834\n",
            "Step [16590/80000], d_real_loss: 0.1642, d_mnist_loss: 0.0612, d_svhn_loss: 0.1030, d_fake_loss: 0.1141, g_loss: 1.6296\n",
            "Step [16600/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0055, d_svhn_loss: 0.0596, d_fake_loss: 0.0287, g_loss: 1.1613\n",
            "Step [16610/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0023, d_svhn_loss: 0.0920, d_fake_loss: 0.0466, g_loss: 1.0625\n",
            "Step [16620/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0308, d_svhn_loss: 0.0292, d_fake_loss: 0.0669, g_loss: 1.6195\n",
            "Step [16630/80000], d_real_loss: 0.1019, d_mnist_loss: 0.0519, d_svhn_loss: 0.0500, d_fake_loss: 0.0672, g_loss: 1.0678\n",
            "Step [16640/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0027, d_svhn_loss: 0.0605, d_fake_loss: 0.0413, g_loss: 1.1506\n",
            "Step [16650/80000], d_real_loss: 0.0808, d_mnist_loss: 0.0155, d_svhn_loss: 0.0652, d_fake_loss: 0.0433, g_loss: 1.3048\n",
            "Step [16660/80000], d_real_loss: 0.0932, d_mnist_loss: 0.0039, d_svhn_loss: 0.0893, d_fake_loss: 0.0350, g_loss: 1.1775\n",
            "Step [16670/80000], d_real_loss: 0.2797, d_mnist_loss: 0.0018, d_svhn_loss: 0.2779, d_fake_loss: 0.0381, g_loss: 1.2937\n",
            "Step [16680/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0020, d_svhn_loss: 0.0363, d_fake_loss: 0.1594, g_loss: 1.0917\n",
            "Step [16690/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0054, d_svhn_loss: 0.0419, d_fake_loss: 0.0909, g_loss: 1.1378\n",
            "Step [16700/80000], d_real_loss: 0.0682, d_mnist_loss: 0.0054, d_svhn_loss: 0.0628, d_fake_loss: 0.0369, g_loss: 1.1455\n",
            "Step [16710/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0072, d_svhn_loss: 0.0477, d_fake_loss: 0.0423, g_loss: 1.0385\n",
            "Step [16720/80000], d_real_loss: 0.1137, d_mnist_loss: 0.0039, d_svhn_loss: 0.1098, d_fake_loss: 0.1804, g_loss: 1.1087\n",
            "Step [16730/80000], d_real_loss: 0.1173, d_mnist_loss: 0.0032, d_svhn_loss: 0.1141, d_fake_loss: 0.0860, g_loss: 1.1184\n",
            "Step [16740/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0020, d_svhn_loss: 0.0381, d_fake_loss: 0.0402, g_loss: 1.1630\n",
            "Step [16750/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0039, d_svhn_loss: 0.0237, d_fake_loss: 0.0460, g_loss: 1.1562\n",
            "Step [16760/80000], d_real_loss: 0.0816, d_mnist_loss: 0.0065, d_svhn_loss: 0.0751, d_fake_loss: 0.0426, g_loss: 1.0911\n",
            "Step [16770/80000], d_real_loss: 0.1610, d_mnist_loss: 0.0284, d_svhn_loss: 0.1326, d_fake_loss: 0.0664, g_loss: 0.9652\n",
            "Step [16780/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0025, d_svhn_loss: 0.0309, d_fake_loss: 0.0462, g_loss: 1.1191\n",
            "Step [16790/80000], d_real_loss: 0.1003, d_mnist_loss: 0.0020, d_svhn_loss: 0.0984, d_fake_loss: 0.0374, g_loss: 1.2777\n",
            "Step [16800/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0021, d_svhn_loss: 0.0412, d_fake_loss: 0.0351, g_loss: 1.2106\n",
            "Step [16810/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0020, d_svhn_loss: 0.0609, d_fake_loss: 0.0784, g_loss: 1.2041\n",
            "Step [16820/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0097, d_svhn_loss: 0.0441, d_fake_loss: 0.0279, g_loss: 1.1503\n",
            "Step [16830/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0017, d_svhn_loss: 0.0418, d_fake_loss: 0.0307, g_loss: 1.1447\n",
            "Step [16840/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0089, d_svhn_loss: 0.0435, d_fake_loss: 0.0275, g_loss: 1.1453\n",
            "Step [16850/80000], d_real_loss: 0.0769, d_mnist_loss: 0.0071, d_svhn_loss: 0.0698, d_fake_loss: 0.0615, g_loss: 1.0991\n",
            "Step [16860/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0217, d_svhn_loss: 0.0429, d_fake_loss: 0.1770, g_loss: 0.9539\n",
            "Step [16870/80000], d_real_loss: 0.3292, d_mnist_loss: 0.2889, d_svhn_loss: 0.0403, d_fake_loss: 0.3932, g_loss: 1.5913\n",
            "Step [16880/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0112, d_svhn_loss: 0.0297, d_fake_loss: 0.0660, g_loss: 1.2356\n",
            "Step [16890/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0266, d_svhn_loss: 0.0516, d_fake_loss: 0.0376, g_loss: 1.1784\n",
            "Step [16900/80000], d_real_loss: 0.1721, d_mnist_loss: 0.0847, d_svhn_loss: 0.0874, d_fake_loss: 0.1296, g_loss: 0.9740\n",
            "Step [16910/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0066, d_svhn_loss: 0.0308, d_fake_loss: 0.0261, g_loss: 1.1261\n",
            "Step [16920/80000], d_real_loss: 0.1106, d_mnist_loss: 0.0695, d_svhn_loss: 0.0411, d_fake_loss: 0.0448, g_loss: 1.2867\n",
            "Step [16930/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0233, d_svhn_loss: 0.0240, d_fake_loss: 0.0363, g_loss: 1.0077\n",
            "Step [16940/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0036, d_svhn_loss: 0.0268, d_fake_loss: 0.0310, g_loss: 1.0833\n",
            "Step [16950/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0021, d_svhn_loss: 0.0272, d_fake_loss: 0.0526, g_loss: 1.0280\n",
            "Step [16960/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0029, d_svhn_loss: 0.0572, d_fake_loss: 0.0403, g_loss: 1.1975\n",
            "Step [16970/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0083, d_svhn_loss: 0.0357, d_fake_loss: 0.0529, g_loss: 1.2374\n",
            "Step [16980/80000], d_real_loss: 0.1060, d_mnist_loss: 0.0169, d_svhn_loss: 0.0891, d_fake_loss: 0.0270, g_loss: 1.1816\n",
            "Step [16990/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0026, d_svhn_loss: 0.0501, d_fake_loss: 0.1274, g_loss: 1.2949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [17000/80000], d_real_loss: 0.1320, d_mnist_loss: 0.0055, d_svhn_loss: 0.1265, d_fake_loss: 0.0768, g_loss: 1.2164\n",
            "saved ./samples_mnist_svhn/sample-17000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-17000-s-m.png\n",
            "Step [17010/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0019, d_svhn_loss: 0.0275, d_fake_loss: 0.0421, g_loss: 1.1891\n",
            "Step [17020/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0032, d_svhn_loss: 0.0604, d_fake_loss: 0.0545, g_loss: 1.2481\n",
            "Step [17030/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0097, d_svhn_loss: 0.0315, d_fake_loss: 0.0379, g_loss: 1.4157\n",
            "Step [17040/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0027, d_svhn_loss: 0.0257, d_fake_loss: 0.0275, g_loss: 1.1491\n",
            "Step [17050/80000], d_real_loss: 0.0966, d_mnist_loss: 0.0038, d_svhn_loss: 0.0928, d_fake_loss: 0.0482, g_loss: 1.0453\n",
            "Step [17060/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0112, d_svhn_loss: 0.0293, d_fake_loss: 0.0434, g_loss: 1.3071\n",
            "Step [17070/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0095, d_svhn_loss: 0.0222, d_fake_loss: 0.0505, g_loss: 1.1992\n",
            "Step [17080/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0152, d_svhn_loss: 0.0341, d_fake_loss: 0.0311, g_loss: 1.1927\n",
            "Step [17090/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0069, d_svhn_loss: 0.0650, d_fake_loss: 0.0395, g_loss: 1.1166\n",
            "Step [17100/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0057, d_svhn_loss: 0.0407, d_fake_loss: 0.0993, g_loss: 1.3769\n",
            "Step [17110/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0049, d_svhn_loss: 0.0687, d_fake_loss: 0.0623, g_loss: 1.0845\n",
            "Step [17120/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0030, d_svhn_loss: 0.0618, d_fake_loss: 0.0492, g_loss: 1.0927\n",
            "Step [17130/80000], d_real_loss: 0.1447, d_mnist_loss: 0.0158, d_svhn_loss: 0.1289, d_fake_loss: 0.0825, g_loss: 1.0014\n",
            "Step [17140/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0055, d_svhn_loss: 0.0592, d_fake_loss: 0.0290, g_loss: 1.0837\n",
            "Step [17150/80000], d_real_loss: 0.1068, d_mnist_loss: 0.0078, d_svhn_loss: 0.0990, d_fake_loss: 0.0990, g_loss: 1.1347\n",
            "Step [17160/80000], d_real_loss: 0.0709, d_mnist_loss: 0.0102, d_svhn_loss: 0.0607, d_fake_loss: 0.1253, g_loss: 1.0751\n",
            "Step [17170/80000], d_real_loss: 0.0779, d_mnist_loss: 0.0315, d_svhn_loss: 0.0465, d_fake_loss: 0.0253, g_loss: 1.0044\n",
            "Step [17180/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0169, d_svhn_loss: 0.0355, d_fake_loss: 0.0468, g_loss: 1.1270\n",
            "Step [17190/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0020, d_svhn_loss: 0.0376, d_fake_loss: 0.0281, g_loss: 1.0910\n",
            "Step [17200/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0073, d_svhn_loss: 0.0404, d_fake_loss: 0.0495, g_loss: 1.0507\n",
            "Step [17210/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0015, d_svhn_loss: 0.0398, d_fake_loss: 0.0345, g_loss: 1.2647\n",
            "Step [17220/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0031, d_svhn_loss: 0.0417, d_fake_loss: 0.0767, g_loss: 1.4178\n",
            "Step [17230/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0019, d_svhn_loss: 0.0463, d_fake_loss: 0.0841, g_loss: 1.3244\n",
            "Step [17240/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0020, d_svhn_loss: 0.0460, d_fake_loss: 0.0281, g_loss: 1.1669\n",
            "Step [17250/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0082, d_svhn_loss: 0.0349, d_fake_loss: 0.0524, g_loss: 1.3028\n",
            "Step [17260/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0103, d_svhn_loss: 0.0267, d_fake_loss: 0.0548, g_loss: 1.1628\n",
            "Step [17270/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0093, d_svhn_loss: 0.0399, d_fake_loss: 0.0302, g_loss: 1.1750\n",
            "Step [17280/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0125, d_svhn_loss: 0.0308, d_fake_loss: 0.0229, g_loss: 1.1381\n",
            "Step [17290/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0192, d_svhn_loss: 0.0289, d_fake_loss: 0.0655, g_loss: 1.3204\n",
            "Step [17300/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0022, d_svhn_loss: 0.0652, d_fake_loss: 0.0555, g_loss: 1.1030\n",
            "Step [17310/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0069, d_svhn_loss: 0.0317, d_fake_loss: 0.0475, g_loss: 1.1793\n",
            "Step [17320/80000], d_real_loss: 0.1400, d_mnist_loss: 0.0291, d_svhn_loss: 0.1109, d_fake_loss: 0.0677, g_loss: 1.3184\n",
            "Step [17330/80000], d_real_loss: 0.1821, d_mnist_loss: 0.0215, d_svhn_loss: 0.1606, d_fake_loss: 0.1190, g_loss: 1.1398\n",
            "Step [17340/80000], d_real_loss: 0.0863, d_mnist_loss: 0.0090, d_svhn_loss: 0.0774, d_fake_loss: 0.0604, g_loss: 1.0812\n",
            "Step [17350/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0362, d_svhn_loss: 0.0268, d_fake_loss: 0.0442, g_loss: 1.0342\n",
            "Step [17360/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0033, d_svhn_loss: 0.0285, d_fake_loss: 0.0864, g_loss: 1.1729\n",
            "Step [17370/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0054, d_svhn_loss: 0.0312, d_fake_loss: 0.0644, g_loss: 1.4096\n",
            "Step [17380/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0024, d_svhn_loss: 0.0580, d_fake_loss: 0.1156, g_loss: 1.0596\n",
            "Step [17390/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0059, d_svhn_loss: 0.0456, d_fake_loss: 0.0897, g_loss: 1.0943\n",
            "Step [17400/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0117, d_svhn_loss: 0.0388, d_fake_loss: 0.1080, g_loss: 1.2280\n",
            "Step [17410/80000], d_real_loss: 0.1985, d_mnist_loss: 0.0033, d_svhn_loss: 0.1952, d_fake_loss: 0.3067, g_loss: 1.1310\n",
            "Step [17420/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0095, d_svhn_loss: 0.0593, d_fake_loss: 0.0792, g_loss: 1.1054\n",
            "Step [17430/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0275, d_svhn_loss: 0.0436, d_fake_loss: 0.0925, g_loss: 1.5981\n",
            "Step [17440/80000], d_real_loss: 0.1053, d_mnist_loss: 0.0039, d_svhn_loss: 0.1014, d_fake_loss: 0.1818, g_loss: 1.1191\n",
            "Step [17450/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0017, d_svhn_loss: 0.0322, d_fake_loss: 0.0331, g_loss: 1.2110\n",
            "Step [17460/80000], d_real_loss: 0.1920, d_mnist_loss: 0.0032, d_svhn_loss: 0.1888, d_fake_loss: 0.2149, g_loss: 1.1420\n",
            "Step [17470/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0165, d_svhn_loss: 0.0440, d_fake_loss: 0.0749, g_loss: 1.0518\n",
            "Step [17480/80000], d_real_loss: 0.2628, d_mnist_loss: 0.0047, d_svhn_loss: 0.2580, d_fake_loss: 0.0874, g_loss: 1.2144\n",
            "Step [17490/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0016, d_svhn_loss: 0.0533, d_fake_loss: 0.0250, g_loss: 1.1761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [17500/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0024, d_svhn_loss: 0.0465, d_fake_loss: 0.0253, g_loss: 1.1661\n",
            "saved ./samples_mnist_svhn/sample-17500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-17500-s-m.png\n",
            "Step [17510/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0044, d_svhn_loss: 0.0408, d_fake_loss: 0.0361, g_loss: 1.0922\n",
            "Step [17520/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0085, d_svhn_loss: 0.0304, d_fake_loss: 0.1687, g_loss: 1.3451\n",
            "Step [17530/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0252, d_svhn_loss: 0.0278, d_fake_loss: 0.0590, g_loss: 1.0565\n",
            "Step [17540/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0029, d_svhn_loss: 0.0331, d_fake_loss: 0.0493, g_loss: 1.3204\n",
            "Step [17550/80000], d_real_loss: 0.1020, d_mnist_loss: 0.0114, d_svhn_loss: 0.0906, d_fake_loss: 0.0723, g_loss: 1.0634\n",
            "Step [17560/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0291, d_svhn_loss: 0.0373, d_fake_loss: 0.0293, g_loss: 1.2625\n",
            "Step [17570/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0058, d_svhn_loss: 0.0257, d_fake_loss: 0.0313, g_loss: 1.2968\n",
            "Step [17580/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0030, d_svhn_loss: 0.0414, d_fake_loss: 0.0379, g_loss: 1.1975\n",
            "Step [17590/80000], d_real_loss: 0.0963, d_mnist_loss: 0.0092, d_svhn_loss: 0.0871, d_fake_loss: 0.1104, g_loss: 1.2247\n",
            "Step [17600/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0079, d_svhn_loss: 0.0436, d_fake_loss: 0.0401, g_loss: 1.1041\n",
            "Step [17610/80000], d_real_loss: 0.1338, d_mnist_loss: 0.0046, d_svhn_loss: 0.1292, d_fake_loss: 0.0967, g_loss: 0.9542\n",
            "Step [17620/80000], d_real_loss: 0.0705, d_mnist_loss: 0.0200, d_svhn_loss: 0.0504, d_fake_loss: 0.1059, g_loss: 1.1090\n",
            "Step [17630/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0107, d_svhn_loss: 0.0300, d_fake_loss: 0.0266, g_loss: 1.2302\n",
            "Step [17640/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0408, d_svhn_loss: 0.0340, d_fake_loss: 0.0361, g_loss: 1.2961\n",
            "Step [17650/80000], d_real_loss: 0.0715, d_mnist_loss: 0.0056, d_svhn_loss: 0.0659, d_fake_loss: 0.0742, g_loss: 1.0874\n",
            "Step [17660/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0249, d_svhn_loss: 0.0253, d_fake_loss: 0.0481, g_loss: 1.2730\n",
            "Step [17670/80000], d_real_loss: 0.1628, d_mnist_loss: 0.0206, d_svhn_loss: 0.1422, d_fake_loss: 0.0962, g_loss: 1.1994\n",
            "Step [17680/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0034, d_svhn_loss: 0.0308, d_fake_loss: 0.0287, g_loss: 1.0873\n",
            "Step [17690/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0076, d_svhn_loss: 0.0645, d_fake_loss: 0.0384, g_loss: 1.2345\n",
            "Step [17700/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0019, d_svhn_loss: 0.0231, d_fake_loss: 0.0336, g_loss: 1.1796\n",
            "Step [17710/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0017, d_svhn_loss: 0.0376, d_fake_loss: 0.0336, g_loss: 1.2707\n",
            "Step [17720/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0023, d_svhn_loss: 0.0670, d_fake_loss: 0.0451, g_loss: 1.0487\n",
            "Step [17730/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0044, d_svhn_loss: 0.0318, d_fake_loss: 0.0982, g_loss: 1.2499\n",
            "Step [17740/80000], d_real_loss: 0.1633, d_mnist_loss: 0.0031, d_svhn_loss: 0.1603, d_fake_loss: 0.0377, g_loss: 1.1861\n",
            "Step [17750/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0072, d_svhn_loss: 0.0661, d_fake_loss: 0.0676, g_loss: 1.1763\n",
            "Step [17760/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0020, d_svhn_loss: 0.0375, d_fake_loss: 0.0717, g_loss: 1.0570\n",
            "Step [17770/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0020, d_svhn_loss: 0.0412, d_fake_loss: 0.0494, g_loss: 1.1173\n",
            "Step [17780/80000], d_real_loss: 0.0797, d_mnist_loss: 0.0143, d_svhn_loss: 0.0654, d_fake_loss: 0.0587, g_loss: 1.0420\n",
            "Step [17790/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0028, d_svhn_loss: 0.0705, d_fake_loss: 0.0376, g_loss: 1.1170\n",
            "Step [17800/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0022, d_svhn_loss: 0.0317, d_fake_loss: 0.0935, g_loss: 1.1896\n",
            "Step [17810/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0055, d_svhn_loss: 0.0217, d_fake_loss: 0.0384, g_loss: 1.1631\n",
            "Step [17820/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0036, d_svhn_loss: 0.0729, d_fake_loss: 0.0793, g_loss: 1.0954\n",
            "Step [17830/80000], d_real_loss: 0.0862, d_mnist_loss: 0.0226, d_svhn_loss: 0.0637, d_fake_loss: 0.0385, g_loss: 1.1097\n",
            "Step [17840/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0153, d_svhn_loss: 0.0392, d_fake_loss: 0.1007, g_loss: 1.4376\n",
            "Step [17850/80000], d_real_loss: 0.1154, d_mnist_loss: 0.0268, d_svhn_loss: 0.0886, d_fake_loss: 0.0366, g_loss: 1.1457\n",
            "Step [17860/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0019, d_svhn_loss: 0.0434, d_fake_loss: 0.0244, g_loss: 1.2211\n",
            "Step [17870/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0070, d_svhn_loss: 0.0248, d_fake_loss: 0.0439, g_loss: 1.1587\n",
            "Step [17880/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0040, d_svhn_loss: 0.0363, d_fake_loss: 0.0525, g_loss: 0.9724\n",
            "Step [17890/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0036, d_svhn_loss: 0.0304, d_fake_loss: 0.0675, g_loss: 0.9996\n",
            "Step [17900/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0041, d_svhn_loss: 0.0561, d_fake_loss: 0.0241, g_loss: 1.0803\n",
            "Step [17910/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0224, d_svhn_loss: 0.0525, d_fake_loss: 0.0343, g_loss: 1.0167\n",
            "Step [17920/80000], d_real_loss: 0.0898, d_mnist_loss: 0.0021, d_svhn_loss: 0.0878, d_fake_loss: 0.1322, g_loss: 1.3550\n",
            "Step [17930/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0031, d_svhn_loss: 0.0336, d_fake_loss: 0.0406, g_loss: 1.2686\n",
            "Step [17940/80000], d_real_loss: 0.1235, d_mnist_loss: 0.0709, d_svhn_loss: 0.0526, d_fake_loss: 0.0581, g_loss: 1.1632\n",
            "Step [17950/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0100, d_svhn_loss: 0.0352, d_fake_loss: 0.2490, g_loss: 1.9181\n",
            "Step [17960/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0270, d_svhn_loss: 0.0241, d_fake_loss: 0.0901, g_loss: 1.2446\n",
            "Step [17970/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0069, d_svhn_loss: 0.0718, d_fake_loss: 0.0391, g_loss: 1.0503\n",
            "Step [17980/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0095, d_svhn_loss: 0.0518, d_fake_loss: 0.0991, g_loss: 1.2078\n",
            "Step [17990/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0099, d_svhn_loss: 0.0273, d_fake_loss: 0.0528, g_loss: 1.2699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [18000/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0117, d_svhn_loss: 0.0419, d_fake_loss: 0.0384, g_loss: 1.0726\n",
            "saved ./samples_mnist_svhn/sample-18000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-18000-s-m.png\n",
            "Step [18010/80000], d_real_loss: 0.1017, d_mnist_loss: 0.0105, d_svhn_loss: 0.0912, d_fake_loss: 0.0476, g_loss: 1.1803\n",
            "Step [18020/80000], d_real_loss: 0.1434, d_mnist_loss: 0.0044, d_svhn_loss: 0.1390, d_fake_loss: 0.0972, g_loss: 1.1488\n",
            "Step [18030/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0110, d_svhn_loss: 0.0224, d_fake_loss: 0.0412, g_loss: 1.1782\n",
            "Step [18040/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0028, d_svhn_loss: 0.0387, d_fake_loss: 0.0390, g_loss: 1.2062\n",
            "Step [18050/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0053, d_svhn_loss: 0.0450, d_fake_loss: 0.0498, g_loss: 1.2071\n",
            "Step [18060/80000], d_real_loss: 0.1314, d_mnist_loss: 0.0114, d_svhn_loss: 0.1199, d_fake_loss: 0.1044, g_loss: 1.0398\n",
            "Step [18070/80000], d_real_loss: 0.0870, d_mnist_loss: 0.0059, d_svhn_loss: 0.0811, d_fake_loss: 0.1930, g_loss: 1.1994\n",
            "Step [18080/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0287, d_svhn_loss: 0.0559, d_fake_loss: 0.0663, g_loss: 1.0685\n",
            "Step [18090/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0020, d_svhn_loss: 0.0341, d_fake_loss: 0.0283, g_loss: 1.3011\n",
            "Step [18100/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0032, d_svhn_loss: 0.0319, d_fake_loss: 0.0422, g_loss: 1.1772\n",
            "Step [18110/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0048, d_svhn_loss: 0.0191, d_fake_loss: 0.0478, g_loss: 1.1604\n",
            "Step [18120/80000], d_real_loss: 0.1515, d_mnist_loss: 0.0020, d_svhn_loss: 0.1496, d_fake_loss: 0.1415, g_loss: 1.2367\n",
            "Step [18130/80000], d_real_loss: 0.0781, d_mnist_loss: 0.0021, d_svhn_loss: 0.0760, d_fake_loss: 0.1105, g_loss: 1.1101\n",
            "Step [18140/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0053, d_svhn_loss: 0.0511, d_fake_loss: 0.0211, g_loss: 1.1886\n",
            "Step [18150/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0125, d_svhn_loss: 0.0277, d_fake_loss: 0.0396, g_loss: 1.2235\n",
            "Step [18160/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0067, d_svhn_loss: 0.0261, d_fake_loss: 0.0428, g_loss: 1.1699\n",
            "Step [18170/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0025, d_svhn_loss: 0.0421, d_fake_loss: 0.0557, g_loss: 1.1469\n",
            "Step [18180/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0213, d_svhn_loss: 0.0291, d_fake_loss: 0.0331, g_loss: 1.1933\n",
            "Step [18190/80000], d_real_loss: 0.1148, d_mnist_loss: 0.0125, d_svhn_loss: 0.1023, d_fake_loss: 0.1203, g_loss: 1.1498\n",
            "Step [18200/80000], d_real_loss: 0.1642, d_mnist_loss: 0.0097, d_svhn_loss: 0.1544, d_fake_loss: 0.0768, g_loss: 1.0597\n",
            "Step [18210/80000], d_real_loss: 0.1034, d_mnist_loss: 0.0080, d_svhn_loss: 0.0954, d_fake_loss: 0.0595, g_loss: 1.2501\n",
            "Step [18220/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0034, d_svhn_loss: 0.0263, d_fake_loss: 0.0639, g_loss: 1.1580\n",
            "Step [18230/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0016, d_svhn_loss: 0.0402, d_fake_loss: 0.1668, g_loss: 1.1354\n",
            "Step [18240/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0014, d_svhn_loss: 0.0443, d_fake_loss: 0.0531, g_loss: 1.2349\n",
            "Step [18250/80000], d_real_loss: 0.1060, d_mnist_loss: 0.0083, d_svhn_loss: 0.0977, d_fake_loss: 0.1085, g_loss: 1.1145\n",
            "Step [18260/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0024, d_svhn_loss: 0.0373, d_fake_loss: 0.0262, g_loss: 1.1899\n",
            "Step [18270/80000], d_real_loss: 0.0948, d_mnist_loss: 0.0653, d_svhn_loss: 0.0295, d_fake_loss: 0.0624, g_loss: 1.6788\n",
            "Step [18280/80000], d_real_loss: 0.2013, d_mnist_loss: 0.0090, d_svhn_loss: 0.1922, d_fake_loss: 0.1138, g_loss: 1.2966\n",
            "Step [18290/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0041, d_svhn_loss: 0.0217, d_fake_loss: 0.0890, g_loss: 1.2097\n",
            "Step [18300/80000], d_real_loss: 0.1454, d_mnist_loss: 0.0096, d_svhn_loss: 0.1358, d_fake_loss: 0.0325, g_loss: 1.2072\n",
            "Step [18310/80000], d_real_loss: 0.0823, d_mnist_loss: 0.0061, d_svhn_loss: 0.0762, d_fake_loss: 0.1028, g_loss: 1.2157\n",
            "Step [18320/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0171, d_svhn_loss: 0.0398, d_fake_loss: 0.0976, g_loss: 1.3066\n",
            "Step [18330/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0031, d_svhn_loss: 0.0817, d_fake_loss: 0.2584, g_loss: 1.1555\n",
            "Step [18340/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0071, d_svhn_loss: 0.0298, d_fake_loss: 0.0582, g_loss: 1.1641\n",
            "Step [18350/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0019, d_svhn_loss: 0.0335, d_fake_loss: 0.0869, g_loss: 1.2014\n",
            "Step [18360/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0035, d_svhn_loss: 0.0434, d_fake_loss: 0.0404, g_loss: 1.1253\n",
            "Step [18370/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0024, d_svhn_loss: 0.0551, d_fake_loss: 0.1043, g_loss: 1.2039\n",
            "Step [18380/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0036, d_svhn_loss: 0.0498, d_fake_loss: 0.0928, g_loss: 1.2631\n",
            "Step [18390/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0044, d_svhn_loss: 0.0370, d_fake_loss: 0.0310, g_loss: 1.1008\n",
            "Step [18400/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0036, d_svhn_loss: 0.0280, d_fake_loss: 0.0620, g_loss: 1.0262\n",
            "Step [18410/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0029, d_svhn_loss: 0.0962, d_fake_loss: 0.0815, g_loss: 1.0471\n",
            "Step [18420/80000], d_real_loss: 0.1142, d_mnist_loss: 0.0146, d_svhn_loss: 0.0996, d_fake_loss: 0.0691, g_loss: 1.1452\n",
            "Step [18430/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0037, d_svhn_loss: 0.0680, d_fake_loss: 0.0894, g_loss: 1.1654\n",
            "Step [18440/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0027, d_svhn_loss: 0.0262, d_fake_loss: 0.0437, g_loss: 1.2390\n",
            "Step [18450/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0093, d_svhn_loss: 0.0442, d_fake_loss: 0.0244, g_loss: 1.2531\n",
            "Step [18460/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0034, d_svhn_loss: 0.0293, d_fake_loss: 0.0767, g_loss: 1.1872\n",
            "Step [18470/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0019, d_svhn_loss: 0.0259, d_fake_loss: 0.0380, g_loss: 1.3804\n",
            "Step [18480/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0018, d_svhn_loss: 0.0571, d_fake_loss: 0.0325, g_loss: 1.1578\n",
            "Step [18490/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0019, d_svhn_loss: 0.0295, d_fake_loss: 0.0513, g_loss: 1.1737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [18500/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0020, d_svhn_loss: 0.0346, d_fake_loss: 0.0543, g_loss: 1.1305\n",
            "saved ./samples_mnist_svhn/sample-18500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-18500-s-m.png\n",
            "Step [18510/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0022, d_svhn_loss: 0.0300, d_fake_loss: 0.0313, g_loss: 1.1325\n",
            "Step [18520/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0019, d_svhn_loss: 0.0440, d_fake_loss: 0.0314, g_loss: 1.1017\n",
            "Step [18530/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0033, d_svhn_loss: 0.0777, d_fake_loss: 0.0617, g_loss: 1.3294\n",
            "Step [18540/80000], d_real_loss: 0.1236, d_mnist_loss: 0.0022, d_svhn_loss: 0.1214, d_fake_loss: 0.0440, g_loss: 1.2011\n",
            "Step [18550/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0107, d_svhn_loss: 0.0561, d_fake_loss: 0.0968, g_loss: 1.2777\n",
            "Step [18560/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0022, d_svhn_loss: 0.0456, d_fake_loss: 0.0274, g_loss: 1.1590\n",
            "Step [18570/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0030, d_svhn_loss: 0.0365, d_fake_loss: 0.0349, g_loss: 1.1854\n",
            "Step [18580/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0045, d_svhn_loss: 0.0250, d_fake_loss: 0.1257, g_loss: 1.3531\n",
            "Step [18590/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0031, d_svhn_loss: 0.0338, d_fake_loss: 0.0521, g_loss: 1.1289\n",
            "Step [18600/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0052, d_svhn_loss: 0.0358, d_fake_loss: 0.1447, g_loss: 1.2854\n",
            "Step [18610/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0013, d_svhn_loss: 0.0484, d_fake_loss: 0.0320, g_loss: 1.2690\n",
            "Step [18620/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0013, d_svhn_loss: 0.0326, d_fake_loss: 0.1794, g_loss: 1.0632\n",
            "Step [18630/80000], d_real_loss: 0.1264, d_mnist_loss: 0.0014, d_svhn_loss: 0.1249, d_fake_loss: 0.0440, g_loss: 1.1999\n",
            "Step [18640/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0060, d_svhn_loss: 0.0765, d_fake_loss: 0.0650, g_loss: 0.9514\n",
            "Step [18650/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0043, d_svhn_loss: 0.0478, d_fake_loss: 0.0279, g_loss: 1.0715\n",
            "Step [18660/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0208, d_svhn_loss: 0.0326, d_fake_loss: 0.0281, g_loss: 1.1049\n",
            "Step [18670/80000], d_real_loss: 0.1063, d_mnist_loss: 0.0020, d_svhn_loss: 0.1043, d_fake_loss: 0.0373, g_loss: 1.1363\n",
            "Step [18680/80000], d_real_loss: 0.1086, d_mnist_loss: 0.0041, d_svhn_loss: 0.1045, d_fake_loss: 0.0654, g_loss: 1.0847\n",
            "Step [18690/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0030, d_svhn_loss: 0.0517, d_fake_loss: 0.0493, g_loss: 1.1791\n",
            "Step [18700/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0036, d_svhn_loss: 0.0456, d_fake_loss: 0.0471, g_loss: 1.2184\n",
            "Step [18710/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0150, d_svhn_loss: 0.0342, d_fake_loss: 0.0772, g_loss: 1.2708\n",
            "Step [18720/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0016, d_svhn_loss: 0.0430, d_fake_loss: 0.0767, g_loss: 1.2283\n",
            "Step [18730/80000], d_real_loss: 0.1109, d_mnist_loss: 0.0022, d_svhn_loss: 0.1087, d_fake_loss: 0.0275, g_loss: 1.2072\n",
            "Step [18740/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0082, d_svhn_loss: 0.0619, d_fake_loss: 0.0733, g_loss: 1.2040\n",
            "Step [18750/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0203, d_svhn_loss: 0.0409, d_fake_loss: 0.0209, g_loss: 1.4295\n",
            "Step [18760/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0090, d_svhn_loss: 0.0243, d_fake_loss: 0.1400, g_loss: 1.1071\n",
            "Step [18770/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0023, d_svhn_loss: 0.0669, d_fake_loss: 0.2826, g_loss: 1.4043\n",
            "Step [18780/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0411, d_svhn_loss: 0.0242, d_fake_loss: 0.0303, g_loss: 1.2398\n",
            "Step [18790/80000], d_real_loss: 0.1455, d_mnist_loss: 0.0785, d_svhn_loss: 0.0670, d_fake_loss: 0.4141, g_loss: 2.1422\n",
            "Step [18800/80000], d_real_loss: 0.1066, d_mnist_loss: 0.0402, d_svhn_loss: 0.0663, d_fake_loss: 0.1726, g_loss: 1.1049\n",
            "Step [18810/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0085, d_svhn_loss: 0.0298, d_fake_loss: 0.0441, g_loss: 1.2054\n",
            "Step [18820/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0054, d_svhn_loss: 0.0372, d_fake_loss: 0.0492, g_loss: 1.1179\n",
            "Step [18830/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0059, d_svhn_loss: 0.0244, d_fake_loss: 0.0323, g_loss: 1.0796\n",
            "Step [18840/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0068, d_svhn_loss: 0.0277, d_fake_loss: 0.0304, g_loss: 1.2109\n",
            "Step [18850/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0137, d_svhn_loss: 0.0447, d_fake_loss: 0.1440, g_loss: 1.0504\n",
            "Step [18860/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0087, d_svhn_loss: 0.0670, d_fake_loss: 0.1247, g_loss: 1.2676\n",
            "Step [18870/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0064, d_svhn_loss: 0.0555, d_fake_loss: 0.0425, g_loss: 1.1386\n",
            "Step [18880/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0051, d_svhn_loss: 0.0253, d_fake_loss: 0.0542, g_loss: 1.1983\n",
            "Step [18890/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0191, d_svhn_loss: 0.0250, d_fake_loss: 0.1134, g_loss: 1.2312\n",
            "Step [18900/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0173, d_svhn_loss: 0.0345, d_fake_loss: 0.1761, g_loss: 1.0926\n",
            "Step [18910/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0168, d_svhn_loss: 0.0584, d_fake_loss: 0.0412, g_loss: 1.1983\n",
            "Step [18920/80000], d_real_loss: 0.1466, d_mnist_loss: 0.0042, d_svhn_loss: 0.1424, d_fake_loss: 0.1434, g_loss: 1.1207\n",
            "Step [18930/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0035, d_svhn_loss: 0.0584, d_fake_loss: 0.0282, g_loss: 1.1856\n",
            "Step [18940/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0100, d_svhn_loss: 0.0683, d_fake_loss: 0.0407, g_loss: 1.1022\n",
            "Step [18950/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0010, d_svhn_loss: 0.0367, d_fake_loss: 0.0530, g_loss: 1.1587\n",
            "Step [18960/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0027, d_svhn_loss: 0.0337, d_fake_loss: 0.0339, g_loss: 1.0792\n",
            "Step [18970/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0036, d_svhn_loss: 0.0329, d_fake_loss: 0.0946, g_loss: 1.1285\n",
            "Step [18980/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0230, d_svhn_loss: 0.0329, d_fake_loss: 0.0443, g_loss: 1.1168\n",
            "Step [18990/80000], d_real_loss: 0.1269, d_mnist_loss: 0.0039, d_svhn_loss: 0.1229, d_fake_loss: 0.1307, g_loss: 1.1315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [19000/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0026, d_svhn_loss: 0.0359, d_fake_loss: 0.0792, g_loss: 1.1869\n",
            "saved ./samples_mnist_svhn/sample-19000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-19000-s-m.png\n",
            "Step [19010/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0031, d_svhn_loss: 0.0518, d_fake_loss: 0.0275, g_loss: 1.1711\n",
            "Step [19020/80000], d_real_loss: 0.1606, d_mnist_loss: 0.0027, d_svhn_loss: 0.1579, d_fake_loss: 0.1039, g_loss: 1.1176\n",
            "Step [19030/80000], d_real_loss: 0.2080, d_mnist_loss: 0.0012, d_svhn_loss: 0.2068, d_fake_loss: 0.0654, g_loss: 1.0620\n",
            "Step [19040/80000], d_real_loss: 0.1688, d_mnist_loss: 0.0014, d_svhn_loss: 0.1673, d_fake_loss: 0.0915, g_loss: 1.1500\n",
            "Step [19050/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0127, d_svhn_loss: 0.0325, d_fake_loss: 0.0857, g_loss: 1.1686\n",
            "Step [19060/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0014, d_svhn_loss: 0.0526, d_fake_loss: 0.0430, g_loss: 1.1940\n",
            "Step [19070/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0021, d_svhn_loss: 0.0715, d_fake_loss: 0.0353, g_loss: 1.1689\n",
            "Step [19080/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0042, d_svhn_loss: 0.0567, d_fake_loss: 0.0545, g_loss: 1.2370\n",
            "Step [19090/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0037, d_svhn_loss: 0.0330, d_fake_loss: 0.0300, g_loss: 1.1461\n",
            "Step [19100/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0025, d_svhn_loss: 0.0399, d_fake_loss: 0.0491, g_loss: 1.0574\n",
            "Step [19110/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0059, d_svhn_loss: 0.0288, d_fake_loss: 0.0360, g_loss: 1.0971\n",
            "Step [19120/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0106, d_svhn_loss: 0.0254, d_fake_loss: 0.0186, g_loss: 1.1855\n",
            "Step [19130/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0028, d_svhn_loss: 0.0529, d_fake_loss: 0.0686, g_loss: 1.1601\n",
            "Step [19140/80000], d_real_loss: 0.1801, d_mnist_loss: 0.0122, d_svhn_loss: 0.1679, d_fake_loss: 0.0568, g_loss: 1.1578\n",
            "Step [19150/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0024, d_svhn_loss: 0.0705, d_fake_loss: 0.0297, g_loss: 1.1440\n",
            "Step [19160/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0019, d_svhn_loss: 0.0598, d_fake_loss: 0.0556, g_loss: 1.3023\n",
            "Step [19170/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0048, d_svhn_loss: 0.0512, d_fake_loss: 0.0565, g_loss: 1.1342\n",
            "Step [19180/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0521, d_svhn_loss: 0.0317, d_fake_loss: 0.0381, g_loss: 1.2086\n",
            "Step [19190/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0019, d_svhn_loss: 0.0659, d_fake_loss: 0.0375, g_loss: 1.1892\n",
            "Step [19200/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0104, d_svhn_loss: 0.0532, d_fake_loss: 0.0658, g_loss: 1.0941\n",
            "Step [19210/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0140, d_svhn_loss: 0.0554, d_fake_loss: 0.1112, g_loss: 1.1089\n",
            "Step [19220/80000], d_real_loss: 0.0906, d_mnist_loss: 0.0222, d_svhn_loss: 0.0684, d_fake_loss: 0.0691, g_loss: 1.1426\n",
            "Step [19230/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0030, d_svhn_loss: 0.0693, d_fake_loss: 0.0329, g_loss: 1.1036\n",
            "Step [19240/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0173, d_svhn_loss: 0.0540, d_fake_loss: 0.0746, g_loss: 1.1924\n",
            "Step [19250/80000], d_real_loss: 0.1552, d_mnist_loss: 0.0038, d_svhn_loss: 0.1514, d_fake_loss: 0.0575, g_loss: 1.1655\n",
            "Step [19260/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0015, d_svhn_loss: 0.0497, d_fake_loss: 0.0252, g_loss: 1.1434\n",
            "Step [19270/80000], d_real_loss: 0.0927, d_mnist_loss: 0.0026, d_svhn_loss: 0.0902, d_fake_loss: 0.0261, g_loss: 1.1281\n",
            "Step [19280/80000], d_real_loss: 0.0897, d_mnist_loss: 0.0034, d_svhn_loss: 0.0863, d_fake_loss: 0.0421, g_loss: 1.2497\n",
            "Step [19290/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0064, d_svhn_loss: 0.0416, d_fake_loss: 0.0316, g_loss: 1.1191\n",
            "Step [19300/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0015, d_svhn_loss: 0.0609, d_fake_loss: 0.1254, g_loss: 1.2423\n",
            "Step [19310/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0109, d_svhn_loss: 0.0254, d_fake_loss: 0.0361, g_loss: 1.0854\n",
            "Step [19320/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0164, d_svhn_loss: 0.0655, d_fake_loss: 0.0906, g_loss: 0.9804\n",
            "Step [19330/80000], d_real_loss: 0.1004, d_mnist_loss: 0.0132, d_svhn_loss: 0.0872, d_fake_loss: 0.0397, g_loss: 1.3271\n",
            "Step [19340/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0086, d_svhn_loss: 0.0419, d_fake_loss: 0.0910, g_loss: 1.1198\n",
            "Step [19350/80000], d_real_loss: 0.1194, d_mnist_loss: 0.0437, d_svhn_loss: 0.0757, d_fake_loss: 0.0646, g_loss: 1.3958\n",
            "Step [19360/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0036, d_svhn_loss: 0.0271, d_fake_loss: 0.0373, g_loss: 1.0568\n",
            "Step [19370/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0016, d_svhn_loss: 0.0405, d_fake_loss: 0.0205, g_loss: 1.2035\n",
            "Step [19380/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0067, d_svhn_loss: 0.0312, d_fake_loss: 0.0579, g_loss: 1.2088\n",
            "Step [19390/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0062, d_svhn_loss: 0.0292, d_fake_loss: 0.1605, g_loss: 0.8249\n",
            "Step [19400/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0523, d_svhn_loss: 0.0315, d_fake_loss: 0.0475, g_loss: 1.0981\n",
            "Step [19410/80000], d_real_loss: 0.0854, d_mnist_loss: 0.0063, d_svhn_loss: 0.0790, d_fake_loss: 0.1498, g_loss: 1.0953\n",
            "Step [19420/80000], d_real_loss: 0.1047, d_mnist_loss: 0.0223, d_svhn_loss: 0.0824, d_fake_loss: 0.0493, g_loss: 1.1635\n",
            "Step [19430/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0250, d_svhn_loss: 0.0353, d_fake_loss: 0.0834, g_loss: 1.2352\n",
            "Step [19440/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0145, d_svhn_loss: 0.0466, d_fake_loss: 0.1025, g_loss: 1.0824\n",
            "Step [19450/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0046, d_svhn_loss: 0.0361, d_fake_loss: 0.0570, g_loss: 1.1150\n",
            "Step [19460/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0046, d_svhn_loss: 0.0566, d_fake_loss: 0.0637, g_loss: 1.1284\n",
            "Step [19470/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0024, d_svhn_loss: 0.0468, d_fake_loss: 0.0447, g_loss: 1.3651\n",
            "Step [19480/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0021, d_svhn_loss: 0.0456, d_fake_loss: 0.0653, g_loss: 1.3605\n",
            "Step [19490/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0030, d_svhn_loss: 0.0266, d_fake_loss: 0.0341, g_loss: 1.1749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [19500/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0140, d_svhn_loss: 0.0375, d_fake_loss: 0.0446, g_loss: 1.0998\n",
            "saved ./samples_mnist_svhn/sample-19500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-19500-s-m.png\n",
            "Step [19510/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0025, d_svhn_loss: 0.0287, d_fake_loss: 0.0704, g_loss: 1.1007\n",
            "Step [19520/80000], d_real_loss: 0.0869, d_mnist_loss: 0.0069, d_svhn_loss: 0.0800, d_fake_loss: 0.0829, g_loss: 1.1497\n",
            "Step [19530/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0075, d_svhn_loss: 0.0286, d_fake_loss: 0.0736, g_loss: 1.3361\n",
            "Step [19540/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0016, d_svhn_loss: 0.0686, d_fake_loss: 0.0605, g_loss: 1.0823\n",
            "Step [19550/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0235, d_svhn_loss: 0.0336, d_fake_loss: 0.0565, g_loss: 1.1934\n",
            "Step [19560/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0017, d_svhn_loss: 0.0445, d_fake_loss: 0.0322, g_loss: 1.1828\n",
            "Step [19570/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0160, d_svhn_loss: 0.0292, d_fake_loss: 0.0733, g_loss: 1.1246\n",
            "Step [19580/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0021, d_svhn_loss: 0.0354, d_fake_loss: 0.0659, g_loss: 1.2039\n",
            "Step [19590/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0197, d_svhn_loss: 0.0312, d_fake_loss: 0.0467, g_loss: 1.0212\n",
            "Step [19600/80000], d_real_loss: 0.1577, d_mnist_loss: 0.0026, d_svhn_loss: 0.1550, d_fake_loss: 0.0190, g_loss: 1.1519\n",
            "Step [19610/80000], d_real_loss: 0.1694, d_mnist_loss: 0.0180, d_svhn_loss: 0.1514, d_fake_loss: 0.0769, g_loss: 1.2153\n",
            "Step [19620/80000], d_real_loss: 0.0732, d_mnist_loss: 0.0137, d_svhn_loss: 0.0595, d_fake_loss: 0.0475, g_loss: 1.1179\n",
            "Step [19630/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0127, d_svhn_loss: 0.0238, d_fake_loss: 0.0830, g_loss: 1.3551\n",
            "Step [19640/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0135, d_svhn_loss: 0.0303, d_fake_loss: 0.0277, g_loss: 1.1897\n",
            "Step [19650/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0026, d_svhn_loss: 0.0257, d_fake_loss: 0.0213, g_loss: 1.2378\n",
            "Step [19660/80000], d_real_loss: 0.1155, d_mnist_loss: 0.0113, d_svhn_loss: 0.1042, d_fake_loss: 0.0733, g_loss: 1.1118\n",
            "Step [19670/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0046, d_svhn_loss: 0.0488, d_fake_loss: 0.0657, g_loss: 1.0951\n",
            "Step [19680/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0014, d_svhn_loss: 0.0255, d_fake_loss: 0.0694, g_loss: 1.1742\n",
            "Step [19690/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0108, d_svhn_loss: 0.0347, d_fake_loss: 0.2579, g_loss: 0.9846\n",
            "Step [19700/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0086, d_svhn_loss: 0.0280, d_fake_loss: 0.0573, g_loss: 1.1115\n",
            "Step [19710/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0064, d_svhn_loss: 0.0247, d_fake_loss: 0.0360, g_loss: 1.0653\n",
            "Step [19720/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0103, d_svhn_loss: 0.0393, d_fake_loss: 0.0631, g_loss: 1.5185\n",
            "Step [19730/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0032, d_svhn_loss: 0.0585, d_fake_loss: 0.1121, g_loss: 1.1088\n",
            "Step [19740/80000], d_real_loss: 0.1304, d_mnist_loss: 0.0141, d_svhn_loss: 0.1163, d_fake_loss: 0.0255, g_loss: 1.1474\n",
            "Step [19750/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0240, d_svhn_loss: 0.0285, d_fake_loss: 0.0993, g_loss: 1.4010\n",
            "Step [19760/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0158, d_svhn_loss: 0.0620, d_fake_loss: 0.0398, g_loss: 1.1537\n",
            "Step [19770/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0136, d_svhn_loss: 0.0384, d_fake_loss: 0.0347, g_loss: 1.0106\n",
            "Step [19780/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0041, d_svhn_loss: 0.0348, d_fake_loss: 0.0205, g_loss: 1.0970\n",
            "Step [19790/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0061, d_svhn_loss: 0.0309, d_fake_loss: 0.0375, g_loss: 1.1133\n",
            "Step [19800/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0216, d_svhn_loss: 0.0597, d_fake_loss: 0.0446, g_loss: 1.1732\n",
            "Step [19810/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0411, d_svhn_loss: 0.0401, d_fake_loss: 0.0497, g_loss: 1.0385\n",
            "Step [19820/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0046, d_svhn_loss: 0.0291, d_fake_loss: 0.1031, g_loss: 1.1015\n",
            "Step [19830/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0060, d_svhn_loss: 0.0367, d_fake_loss: 0.0293, g_loss: 1.1845\n",
            "Step [19840/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0089, d_svhn_loss: 0.0428, d_fake_loss: 0.1011, g_loss: 1.0413\n",
            "Step [19850/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0014, d_svhn_loss: 0.0565, d_fake_loss: 0.0289, g_loss: 1.1744\n",
            "Step [19860/80000], d_real_loss: 0.3075, d_mnist_loss: 0.0020, d_svhn_loss: 0.3055, d_fake_loss: 0.1766, g_loss: 1.2061\n",
            "Step [19870/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0016, d_svhn_loss: 0.0589, d_fake_loss: 0.0399, g_loss: 1.2059\n",
            "Step [19880/80000], d_real_loss: 0.1025, d_mnist_loss: 0.0192, d_svhn_loss: 0.0833, d_fake_loss: 0.0213, g_loss: 1.1238\n",
            "Step [19890/80000], d_real_loss: 0.1017, d_mnist_loss: 0.0029, d_svhn_loss: 0.0987, d_fake_loss: 0.0373, g_loss: 1.2162\n",
            "Step [19900/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0017, d_svhn_loss: 0.0601, d_fake_loss: 0.0281, g_loss: 1.1745\n",
            "Step [19910/80000], d_real_loss: 0.1445, d_mnist_loss: 0.0204, d_svhn_loss: 0.1241, d_fake_loss: 0.0713, g_loss: 1.2134\n",
            "Step [19920/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0200, d_svhn_loss: 0.0327, d_fake_loss: 0.0621, g_loss: 1.2875\n",
            "Step [19930/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0097, d_svhn_loss: 0.0289, d_fake_loss: 0.0455, g_loss: 1.1039\n",
            "Step [19940/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0054, d_svhn_loss: 0.0820, d_fake_loss: 0.0919, g_loss: 1.2029\n",
            "Step [19950/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0016, d_svhn_loss: 0.0537, d_fake_loss: 0.1028, g_loss: 1.3128\n",
            "Step [19960/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0015, d_svhn_loss: 0.0877, d_fake_loss: 0.0429, g_loss: 1.2882\n",
            "Step [19970/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0038, d_svhn_loss: 0.0511, d_fake_loss: 0.0714, g_loss: 1.1942\n",
            "Step [19980/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0012, d_svhn_loss: 0.0331, d_fake_loss: 0.0267, g_loss: 1.0763\n",
            "Step [19990/80000], d_real_loss: 0.0925, d_mnist_loss: 0.0095, d_svhn_loss: 0.0830, d_fake_loss: 0.0206, g_loss: 1.2190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [20000/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0104, d_svhn_loss: 0.0370, d_fake_loss: 0.0487, g_loss: 1.3083\n",
            "saved ./samples_mnist_svhn/sample-20000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-20000-s-m.png\n",
            "Step [20010/80000], d_real_loss: 0.0747, d_mnist_loss: 0.0024, d_svhn_loss: 0.0723, d_fake_loss: 0.0353, g_loss: 1.2311\n",
            "Step [20020/80000], d_real_loss: 0.3761, d_mnist_loss: 0.0029, d_svhn_loss: 0.3732, d_fake_loss: 0.1218, g_loss: 1.1900\n",
            "Step [20030/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0016, d_svhn_loss: 0.0826, d_fake_loss: 0.0550, g_loss: 1.1715\n",
            "Step [20040/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0014, d_svhn_loss: 0.0412, d_fake_loss: 0.0354, g_loss: 1.1566\n",
            "Step [20050/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0024, d_svhn_loss: 0.0436, d_fake_loss: 0.1920, g_loss: 1.4257\n",
            "Step [20060/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0019, d_svhn_loss: 0.0502, d_fake_loss: 0.1135, g_loss: 1.1894\n",
            "Step [20070/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0177, d_svhn_loss: 0.0265, d_fake_loss: 0.0666, g_loss: 1.1195\n",
            "Step [20080/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0073, d_svhn_loss: 0.0771, d_fake_loss: 0.1478, g_loss: 1.1367\n",
            "Step [20090/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0027, d_svhn_loss: 0.0385, d_fake_loss: 0.0902, g_loss: 1.1001\n",
            "Step [20100/80000], d_real_loss: 0.0816, d_mnist_loss: 0.0141, d_svhn_loss: 0.0675, d_fake_loss: 0.0452, g_loss: 1.0662\n",
            "Step [20110/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0023, d_svhn_loss: 0.0383, d_fake_loss: 0.0301, g_loss: 1.2632\n",
            "Step [20120/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0118, d_svhn_loss: 0.0353, d_fake_loss: 0.0190, g_loss: 1.2523\n",
            "Step [20130/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0054, d_svhn_loss: 0.0382, d_fake_loss: 0.0233, g_loss: 1.1321\n",
            "Step [20140/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0041, d_svhn_loss: 0.0345, d_fake_loss: 0.0393, g_loss: 1.1976\n",
            "Step [20150/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0024, d_svhn_loss: 0.0812, d_fake_loss: 0.0415, g_loss: 1.2058\n",
            "Step [20160/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0090, d_svhn_loss: 0.0366, d_fake_loss: 0.0325, g_loss: 1.3530\n",
            "Step [20170/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0183, d_svhn_loss: 0.0301, d_fake_loss: 0.0325, g_loss: 1.1643\n",
            "Step [20180/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0026, d_svhn_loss: 0.0333, d_fake_loss: 0.0302, g_loss: 1.3002\n",
            "Step [20190/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0051, d_svhn_loss: 0.0360, d_fake_loss: 0.0590, g_loss: 1.2726\n",
            "Step [20200/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0021, d_svhn_loss: 0.0532, d_fake_loss: 0.1982, g_loss: 1.1362\n",
            "Step [20210/80000], d_real_loss: 0.1149, d_mnist_loss: 0.0359, d_svhn_loss: 0.0790, d_fake_loss: 0.2047, g_loss: 0.9043\n",
            "Step [20220/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0077, d_svhn_loss: 0.0306, d_fake_loss: 0.2022, g_loss: 1.0834\n",
            "Step [20230/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0136, d_svhn_loss: 0.0483, d_fake_loss: 0.0795, g_loss: 0.9441\n",
            "Step [20240/80000], d_real_loss: 0.0885, d_mnist_loss: 0.0026, d_svhn_loss: 0.0859, d_fake_loss: 0.0770, g_loss: 1.0644\n",
            "Step [20250/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0065, d_svhn_loss: 0.0464, d_fake_loss: 0.0329, g_loss: 1.1643\n",
            "Step [20260/80000], d_real_loss: 0.1406, d_mnist_loss: 0.0036, d_svhn_loss: 0.1370, d_fake_loss: 0.1495, g_loss: 1.3931\n",
            "Step [20270/80000], d_real_loss: 0.1055, d_mnist_loss: 0.0125, d_svhn_loss: 0.0930, d_fake_loss: 0.0634, g_loss: 1.1464\n",
            "Step [20280/80000], d_real_loss: 0.2874, d_mnist_loss: 0.0414, d_svhn_loss: 0.2460, d_fake_loss: 0.1684, g_loss: 1.1289\n",
            "Step [20290/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0019, d_svhn_loss: 0.0638, d_fake_loss: 0.1195, g_loss: 1.1129\n",
            "Step [20300/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0028, d_svhn_loss: 0.0458, d_fake_loss: 0.0854, g_loss: 1.1413\n",
            "Step [20310/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0019, d_svhn_loss: 0.0236, d_fake_loss: 0.0277, g_loss: 1.2144\n",
            "Step [20320/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0046, d_svhn_loss: 0.0614, d_fake_loss: 0.0465, g_loss: 1.1060\n",
            "Step [20330/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0021, d_svhn_loss: 0.0665, d_fake_loss: 0.0245, g_loss: 1.2674\n",
            "Step [20340/80000], d_real_loss: 0.1085, d_mnist_loss: 0.0045, d_svhn_loss: 0.1040, d_fake_loss: 0.0386, g_loss: 1.2159\n",
            "Step [20350/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0101, d_svhn_loss: 0.0616, d_fake_loss: 0.1038, g_loss: 1.0777\n",
            "Step [20360/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0015, d_svhn_loss: 0.0251, d_fake_loss: 0.0359, g_loss: 1.0810\n",
            "Step [20370/80000], d_real_loss: 0.2015, d_mnist_loss: 0.0016, d_svhn_loss: 0.1999, d_fake_loss: 0.0860, g_loss: 1.1791\n",
            "Step [20380/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0039, d_svhn_loss: 0.0588, d_fake_loss: 0.0410, g_loss: 1.1370\n",
            "Step [20390/80000], d_real_loss: 0.0921, d_mnist_loss: 0.0128, d_svhn_loss: 0.0792, d_fake_loss: 0.0330, g_loss: 1.2722\n",
            "Step [20400/80000], d_real_loss: 0.0909, d_mnist_loss: 0.0024, d_svhn_loss: 0.0884, d_fake_loss: 0.0745, g_loss: 1.2911\n",
            "Step [20410/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0172, d_svhn_loss: 0.0525, d_fake_loss: 0.1282, g_loss: 1.0498\n",
            "Step [20420/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0078, d_svhn_loss: 0.0511, d_fake_loss: 0.0210, g_loss: 1.0495\n",
            "Step [20430/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0160, d_svhn_loss: 0.0360, d_fake_loss: 0.0268, g_loss: 1.0709\n",
            "Step [20440/80000], d_real_loss: 0.0949, d_mnist_loss: 0.0365, d_svhn_loss: 0.0583, d_fake_loss: 0.0333, g_loss: 1.0237\n",
            "Step [20450/80000], d_real_loss: 0.0749, d_mnist_loss: 0.0347, d_svhn_loss: 0.0402, d_fake_loss: 0.0471, g_loss: 1.3684\n",
            "Step [20460/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0133, d_svhn_loss: 0.0296, d_fake_loss: 0.0234, g_loss: 1.2027\n",
            "Step [20470/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0211, d_svhn_loss: 0.0438, d_fake_loss: 0.1276, g_loss: 1.1408\n",
            "Step [20480/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0063, d_svhn_loss: 0.0430, d_fake_loss: 0.0520, g_loss: 1.2296\n",
            "Step [20490/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0026, d_svhn_loss: 0.0351, d_fake_loss: 0.0443, g_loss: 1.1251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [20500/80000], d_real_loss: 0.1009, d_mnist_loss: 0.0138, d_svhn_loss: 0.0871, d_fake_loss: 0.0571, g_loss: 1.3230\n",
            "saved ./samples_mnist_svhn/sample-20500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-20500-s-m.png\n",
            "Step [20510/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0072, d_svhn_loss: 0.0738, d_fake_loss: 0.0358, g_loss: 1.2395\n",
            "Step [20520/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0029, d_svhn_loss: 0.0332, d_fake_loss: 0.1140, g_loss: 1.4123\n",
            "Step [20530/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0087, d_svhn_loss: 0.0687, d_fake_loss: 0.0326, g_loss: 1.1778\n",
            "Step [20540/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0027, d_svhn_loss: 0.0848, d_fake_loss: 0.0346, g_loss: 1.2071\n",
            "Step [20550/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0032, d_svhn_loss: 0.0300, d_fake_loss: 0.0264, g_loss: 1.0789\n",
            "Step [20560/80000], d_real_loss: 0.1104, d_mnist_loss: 0.0012, d_svhn_loss: 0.1092, d_fake_loss: 0.0331, g_loss: 1.1237\n",
            "Step [20570/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0096, d_svhn_loss: 0.0368, d_fake_loss: 0.0319, g_loss: 1.2248\n",
            "Step [20580/80000], d_real_loss: 0.0658, d_mnist_loss: 0.0202, d_svhn_loss: 0.0456, d_fake_loss: 0.0505, g_loss: 1.2424\n",
            "Step [20590/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0049, d_svhn_loss: 0.0225, d_fake_loss: 0.0746, g_loss: 1.1345\n",
            "Step [20600/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0046, d_svhn_loss: 0.0504, d_fake_loss: 0.0591, g_loss: 1.4200\n",
            "Step [20610/80000], d_real_loss: 0.1076, d_mnist_loss: 0.0055, d_svhn_loss: 0.1021, d_fake_loss: 0.0381, g_loss: 1.2870\n",
            "Step [20620/80000], d_real_loss: 0.0793, d_mnist_loss: 0.0013, d_svhn_loss: 0.0780, d_fake_loss: 0.0218, g_loss: 1.1167\n",
            "Step [20630/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0030, d_svhn_loss: 0.0496, d_fake_loss: 0.0419, g_loss: 1.4030\n",
            "Step [20640/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0049, d_svhn_loss: 0.0422, d_fake_loss: 0.0836, g_loss: 1.1868\n",
            "Step [20650/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0013, d_svhn_loss: 0.0186, d_fake_loss: 0.0347, g_loss: 1.2486\n",
            "Step [20660/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0143, d_svhn_loss: 0.0338, d_fake_loss: 0.0410, g_loss: 1.2645\n",
            "Step [20670/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0028, d_svhn_loss: 0.0619, d_fake_loss: 0.1113, g_loss: 1.1443\n",
            "Step [20680/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0019, d_svhn_loss: 0.0335, d_fake_loss: 0.0317, g_loss: 1.1447\n",
            "Step [20690/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0087, d_svhn_loss: 0.0273, d_fake_loss: 0.0251, g_loss: 1.4347\n",
            "Step [20700/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0030, d_svhn_loss: 0.0259, d_fake_loss: 0.0234, g_loss: 1.2403\n",
            "Step [20710/80000], d_real_loss: 0.1438, d_mnist_loss: 0.0210, d_svhn_loss: 0.1228, d_fake_loss: 0.0968, g_loss: 1.1657\n",
            "Step [20720/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0118, d_svhn_loss: 0.0442, d_fake_loss: 0.0697, g_loss: 1.1952\n",
            "Step [20730/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0068, d_svhn_loss: 0.0523, d_fake_loss: 0.0500, g_loss: 1.3033\n",
            "Step [20740/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0082, d_svhn_loss: 0.0525, d_fake_loss: 0.1104, g_loss: 1.4347\n",
            "Step [20750/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0041, d_svhn_loss: 0.0491, d_fake_loss: 0.1000, g_loss: 1.1082\n",
            "Step [20760/80000], d_real_loss: 0.0911, d_mnist_loss: 0.0024, d_svhn_loss: 0.0887, d_fake_loss: 0.0617, g_loss: 1.0706\n",
            "Step [20770/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0103, d_svhn_loss: 0.0286, d_fake_loss: 0.0456, g_loss: 1.0821\n",
            "Step [20780/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0022, d_svhn_loss: 0.0519, d_fake_loss: 0.0298, g_loss: 1.1328\n",
            "Step [20790/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0037, d_svhn_loss: 0.0384, d_fake_loss: 0.0357, g_loss: 1.0734\n",
            "Step [20800/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0111, d_svhn_loss: 0.0638, d_fake_loss: 0.0306, g_loss: 1.0579\n",
            "Step [20810/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0040, d_svhn_loss: 0.0267, d_fake_loss: 0.0350, g_loss: 1.3210\n",
            "Step [20820/80000], d_real_loss: 0.1872, d_mnist_loss: 0.0035, d_svhn_loss: 0.1837, d_fake_loss: 0.0369, g_loss: 1.1063\n",
            "Step [20830/80000], d_real_loss: 0.1228, d_mnist_loss: 0.0027, d_svhn_loss: 0.1201, d_fake_loss: 0.1667, g_loss: 1.1095\n",
            "Step [20840/80000], d_real_loss: 0.1670, d_mnist_loss: 0.0183, d_svhn_loss: 0.1487, d_fake_loss: 0.0755, g_loss: 1.0720\n",
            "Step [20850/80000], d_real_loss: 0.1024, d_mnist_loss: 0.0040, d_svhn_loss: 0.0984, d_fake_loss: 0.0961, g_loss: 1.0616\n",
            "Step [20860/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0059, d_svhn_loss: 0.0522, d_fake_loss: 0.1163, g_loss: 1.0609\n",
            "Step [20870/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0074, d_svhn_loss: 0.0308, d_fake_loss: 0.0717, g_loss: 1.0761\n",
            "Step [20880/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0167, d_svhn_loss: 0.0367, d_fake_loss: 0.0618, g_loss: 1.2097\n",
            "Step [20890/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0072, d_svhn_loss: 0.0310, d_fake_loss: 0.0264, g_loss: 1.0174\n",
            "Step [20900/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0049, d_svhn_loss: 0.0410, d_fake_loss: 0.0245, g_loss: 1.1032\n",
            "Step [20910/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0059, d_svhn_loss: 0.0346, d_fake_loss: 0.0532, g_loss: 1.1564\n",
            "Step [20920/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0032, d_svhn_loss: 0.0495, d_fake_loss: 0.0792, g_loss: 1.0975\n",
            "Step [20930/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0023, d_svhn_loss: 0.0538, d_fake_loss: 0.0412, g_loss: 1.1422\n",
            "Step [20940/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0106, d_svhn_loss: 0.0380, d_fake_loss: 0.1427, g_loss: 1.0846\n",
            "Step [20950/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0086, d_svhn_loss: 0.0386, d_fake_loss: 0.1028, g_loss: 1.0755\n",
            "Step [20960/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0104, d_svhn_loss: 0.0485, d_fake_loss: 0.0531, g_loss: 1.2039\n",
            "Step [20970/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0043, d_svhn_loss: 0.0222, d_fake_loss: 0.0556, g_loss: 1.0467\n",
            "Step [20980/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0208, d_svhn_loss: 0.0407, d_fake_loss: 0.0579, g_loss: 1.1600\n",
            "Step [20990/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0141, d_svhn_loss: 0.0362, d_fake_loss: 0.0366, g_loss: 1.0997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [21000/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0015, d_svhn_loss: 0.0282, d_fake_loss: 0.0343, g_loss: 1.1470\n",
            "saved ./samples_mnist_svhn/sample-21000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-21000-s-m.png\n",
            "Step [21010/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0012, d_svhn_loss: 0.0474, d_fake_loss: 0.0386, g_loss: 1.1169\n",
            "Step [21020/80000], d_real_loss: 0.1541, d_mnist_loss: 0.0225, d_svhn_loss: 0.1316, d_fake_loss: 0.0330, g_loss: 1.1439\n",
            "Step [21030/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0044, d_svhn_loss: 0.0315, d_fake_loss: 0.1283, g_loss: 1.2309\n",
            "Step [21040/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0019, d_svhn_loss: 0.0309, d_fake_loss: 0.0512, g_loss: 1.1893\n",
            "Step [21050/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0101, d_svhn_loss: 0.0389, d_fake_loss: 0.0284, g_loss: 1.0730\n",
            "Step [21060/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0064, d_svhn_loss: 0.0307, d_fake_loss: 0.0677, g_loss: 1.2445\n",
            "Step [21070/80000], d_real_loss: 0.1292, d_mnist_loss: 0.0080, d_svhn_loss: 0.1211, d_fake_loss: 0.0473, g_loss: 1.2196\n",
            "Step [21080/80000], d_real_loss: 0.1618, d_mnist_loss: 0.0106, d_svhn_loss: 0.1512, d_fake_loss: 0.1621, g_loss: 1.1203\n",
            "Step [21090/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0110, d_svhn_loss: 0.0440, d_fake_loss: 0.1285, g_loss: 1.2133\n",
            "Step [21100/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0083, d_svhn_loss: 0.0289, d_fake_loss: 0.0564, g_loss: 1.0767\n",
            "Step [21110/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0045, d_svhn_loss: 0.0578, d_fake_loss: 0.0548, g_loss: 1.1531\n",
            "Step [21120/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0067, d_svhn_loss: 0.0561, d_fake_loss: 0.0277, g_loss: 1.1560\n",
            "Step [21130/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0035, d_svhn_loss: 0.0743, d_fake_loss: 0.0654, g_loss: 1.0593\n",
            "Step [21140/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0014, d_svhn_loss: 0.0375, d_fake_loss: 0.0259, g_loss: 1.1431\n",
            "Step [21150/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0051, d_svhn_loss: 0.0498, d_fake_loss: 0.0405, g_loss: 1.1061\n",
            "Step [21160/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0043, d_svhn_loss: 0.0394, d_fake_loss: 0.0255, g_loss: 1.2216\n",
            "Step [21170/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0032, d_svhn_loss: 0.0262, d_fake_loss: 0.1090, g_loss: 1.1342\n",
            "Step [21180/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0033, d_svhn_loss: 0.0586, d_fake_loss: 0.0975, g_loss: 1.2074\n",
            "Step [21190/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0060, d_svhn_loss: 0.0434, d_fake_loss: 0.0401, g_loss: 1.1811\n",
            "Step [21200/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0022, d_svhn_loss: 0.0488, d_fake_loss: 0.0852, g_loss: 1.1589\n",
            "Step [21210/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0029, d_svhn_loss: 0.0388, d_fake_loss: 0.0373, g_loss: 1.1686\n",
            "Step [21220/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0214, d_svhn_loss: 0.0339, d_fake_loss: 0.0948, g_loss: 1.2011\n",
            "Step [21230/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0141, d_svhn_loss: 0.0376, d_fake_loss: 0.0671, g_loss: 1.2104\n",
            "Step [21240/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0033, d_svhn_loss: 0.0344, d_fake_loss: 0.0563, g_loss: 1.1336\n",
            "Step [21250/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0033, d_svhn_loss: 0.0301, d_fake_loss: 0.0273, g_loss: 1.1330\n",
            "Step [21260/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0013, d_svhn_loss: 0.0213, d_fake_loss: 0.1399, g_loss: 1.1235\n",
            "Step [21270/80000], d_real_loss: 0.0878, d_mnist_loss: 0.0018, d_svhn_loss: 0.0859, d_fake_loss: 0.0444, g_loss: 1.1947\n",
            "Step [21280/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0183, d_svhn_loss: 0.0389, d_fake_loss: 0.0393, g_loss: 1.2494\n",
            "Step [21290/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0020, d_svhn_loss: 0.0229, d_fake_loss: 0.0357, g_loss: 1.1202\n",
            "Step [21300/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0031, d_svhn_loss: 0.0293, d_fake_loss: 0.0609, g_loss: 1.2808\n",
            "Step [21310/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0065, d_svhn_loss: 0.0272, d_fake_loss: 0.0434, g_loss: 1.0903\n",
            "Step [21320/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0073, d_svhn_loss: 0.0245, d_fake_loss: 0.0399, g_loss: 1.2994\n",
            "Step [21330/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0024, d_svhn_loss: 0.0606, d_fake_loss: 0.0910, g_loss: 1.1004\n",
            "Step [21340/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0057, d_svhn_loss: 0.0370, d_fake_loss: 0.1875, g_loss: 1.2229\n",
            "Step [21350/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0060, d_svhn_loss: 0.0385, d_fake_loss: 0.0301, g_loss: 1.0745\n",
            "Step [21360/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0015, d_svhn_loss: 0.0355, d_fake_loss: 0.0248, g_loss: 1.1761\n",
            "Step [21370/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0026, d_svhn_loss: 0.0421, d_fake_loss: 0.0694, g_loss: 1.1457\n",
            "Step [21380/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0026, d_svhn_loss: 0.0309, d_fake_loss: 0.0452, g_loss: 1.1719\n",
            "Step [21390/80000], d_real_loss: 0.0834, d_mnist_loss: 0.0056, d_svhn_loss: 0.0778, d_fake_loss: 0.0332, g_loss: 1.1662\n",
            "Step [21400/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0054, d_svhn_loss: 0.0396, d_fake_loss: 0.1030, g_loss: 1.1246\n",
            "Step [21410/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0197, d_svhn_loss: 0.0296, d_fake_loss: 0.0805, g_loss: 1.2642\n",
            "Step [21420/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0033, d_svhn_loss: 0.0427, d_fake_loss: 0.0525, g_loss: 1.1255\n",
            "Step [21430/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0039, d_svhn_loss: 0.0186, d_fake_loss: 0.0395, g_loss: 1.0558\n",
            "Step [21440/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0154, d_svhn_loss: 0.0377, d_fake_loss: 0.0453, g_loss: 1.2737\n",
            "Step [21450/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0158, d_svhn_loss: 0.0392, d_fake_loss: 0.0361, g_loss: 1.0725\n",
            "Step [21460/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0142, d_svhn_loss: 0.0295, d_fake_loss: 0.0377, g_loss: 1.2450\n",
            "Step [21470/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0093, d_svhn_loss: 0.0280, d_fake_loss: 0.1446, g_loss: 1.4917\n",
            "Step [21480/80000], d_real_loss: 0.0766, d_mnist_loss: 0.0049, d_svhn_loss: 0.0717, d_fake_loss: 0.0323, g_loss: 1.1405\n",
            "Step [21490/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0046, d_svhn_loss: 0.0408, d_fake_loss: 0.0348, g_loss: 1.1433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [21500/80000], d_real_loss: 0.1220, d_mnist_loss: 0.0140, d_svhn_loss: 0.1080, d_fake_loss: 0.0344, g_loss: 1.1985\n",
            "saved ./samples_mnist_svhn/sample-21500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-21500-s-m.png\n",
            "Step [21510/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0031, d_svhn_loss: 0.0328, d_fake_loss: 0.2463, g_loss: 1.1228\n",
            "Step [21520/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0117, d_svhn_loss: 0.0189, d_fake_loss: 0.1009, g_loss: 1.1688\n",
            "Step [21530/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0204, d_svhn_loss: 0.0447, d_fake_loss: 0.0597, g_loss: 1.0272\n",
            "Step [21540/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0036, d_svhn_loss: 0.0192, d_fake_loss: 0.0347, g_loss: 1.1526\n",
            "Step [21550/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0176, d_svhn_loss: 0.0373, d_fake_loss: 0.0264, g_loss: 1.2250\n",
            "Step [21560/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0020, d_svhn_loss: 0.0268, d_fake_loss: 0.0527, g_loss: 1.2131\n",
            "Step [21570/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0115, d_svhn_loss: 0.0251, d_fake_loss: 0.0253, g_loss: 1.0714\n",
            "Step [21580/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0048, d_svhn_loss: 0.0262, d_fake_loss: 0.0151, g_loss: 1.1565\n",
            "Step [21590/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0069, d_svhn_loss: 0.0381, d_fake_loss: 0.0453, g_loss: 1.3859\n",
            "Step [21600/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0018, d_svhn_loss: 0.0371, d_fake_loss: 0.1274, g_loss: 1.1296\n",
            "Step [21610/80000], d_real_loss: 0.0909, d_mnist_loss: 0.0059, d_svhn_loss: 0.0851, d_fake_loss: 0.1520, g_loss: 1.0679\n",
            "Step [21620/80000], d_real_loss: 0.0988, d_mnist_loss: 0.0026, d_svhn_loss: 0.0962, d_fake_loss: 0.1372, g_loss: 1.1260\n",
            "Step [21630/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0035, d_svhn_loss: 0.0301, d_fake_loss: 0.0942, g_loss: 1.1336\n",
            "Step [21640/80000], d_real_loss: 0.1088, d_mnist_loss: 0.0087, d_svhn_loss: 0.1002, d_fake_loss: 0.1156, g_loss: 1.1645\n",
            "Step [21650/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0028, d_svhn_loss: 0.0371, d_fake_loss: 0.0714, g_loss: 1.1467\n",
            "Step [21660/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0060, d_svhn_loss: 0.0412, d_fake_loss: 0.0348, g_loss: 1.1305\n",
            "Step [21670/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0063, d_svhn_loss: 0.0361, d_fake_loss: 0.0378, g_loss: 1.1592\n",
            "Step [21680/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0060, d_svhn_loss: 0.0235, d_fake_loss: 0.0224, g_loss: 1.1520\n",
            "Step [21690/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0098, d_svhn_loss: 0.0174, d_fake_loss: 0.0585, g_loss: 1.1853\n",
            "Step [21700/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0024, d_svhn_loss: 0.0197, d_fake_loss: 0.0283, g_loss: 1.1521\n",
            "Step [21710/80000], d_real_loss: 0.2345, d_mnist_loss: 0.0025, d_svhn_loss: 0.2320, d_fake_loss: 0.0579, g_loss: 1.0654\n",
            "Step [21720/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0038, d_svhn_loss: 0.0252, d_fake_loss: 0.0188, g_loss: 1.1448\n",
            "Step [21730/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0053, d_svhn_loss: 0.0289, d_fake_loss: 0.0679, g_loss: 1.1894\n",
            "Step [21740/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0093, d_svhn_loss: 0.0377, d_fake_loss: 0.1370, g_loss: 1.0982\n",
            "Step [21750/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0015, d_svhn_loss: 0.0279, d_fake_loss: 0.0241, g_loss: 1.0538\n",
            "Step [21760/80000], d_real_loss: 0.1332, d_mnist_loss: 0.0042, d_svhn_loss: 0.1290, d_fake_loss: 0.0648, g_loss: 1.2090\n",
            "Step [21770/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0043, d_svhn_loss: 0.0287, d_fake_loss: 0.0545, g_loss: 1.1463\n",
            "Step [21780/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0018, d_svhn_loss: 0.0372, d_fake_loss: 0.0555, g_loss: 1.2490\n",
            "Step [21790/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0071, d_svhn_loss: 0.0328, d_fake_loss: 0.0398, g_loss: 1.1525\n",
            "Step [21800/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0100, d_svhn_loss: 0.0387, d_fake_loss: 0.0376, g_loss: 1.0891\n",
            "Step [21810/80000], d_real_loss: 0.0999, d_mnist_loss: 0.0088, d_svhn_loss: 0.0911, d_fake_loss: 0.0312, g_loss: 1.0596\n",
            "Step [21820/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0112, d_svhn_loss: 0.0289, d_fake_loss: 0.0567, g_loss: 1.2552\n",
            "Step [21830/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0043, d_svhn_loss: 0.0315, d_fake_loss: 0.2263, g_loss: 1.1263\n",
            "Step [21840/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0078, d_svhn_loss: 0.0326, d_fake_loss: 0.0595, g_loss: 1.3034\n",
            "Step [21850/80000], d_real_loss: 0.1314, d_mnist_loss: 0.0026, d_svhn_loss: 0.1288, d_fake_loss: 0.0699, g_loss: 1.2241\n",
            "Step [21860/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0097, d_svhn_loss: 0.0290, d_fake_loss: 0.0343, g_loss: 1.0611\n",
            "Step [21870/80000], d_real_loss: 0.2718, d_mnist_loss: 0.0033, d_svhn_loss: 0.2684, d_fake_loss: 0.0714, g_loss: 1.2225\n",
            "Step [21880/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0043, d_svhn_loss: 0.0350, d_fake_loss: 0.0403, g_loss: 1.1478\n",
            "Step [21890/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0021, d_svhn_loss: 0.0247, d_fake_loss: 0.1106, g_loss: 1.0721\n",
            "Step [21900/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0074, d_svhn_loss: 0.0258, d_fake_loss: 0.0282, g_loss: 1.1600\n",
            "Step [21910/80000], d_real_loss: 0.0698, d_mnist_loss: 0.0015, d_svhn_loss: 0.0682, d_fake_loss: 0.0487, g_loss: 1.0914\n",
            "Step [21920/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0350, d_svhn_loss: 0.0183, d_fake_loss: 0.0327, g_loss: 1.0450\n",
            "Step [21930/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0025, d_svhn_loss: 0.0503, d_fake_loss: 0.0469, g_loss: 1.2435\n",
            "Step [21940/80000], d_real_loss: 0.1071, d_mnist_loss: 0.0227, d_svhn_loss: 0.0844, d_fake_loss: 0.0901, g_loss: 1.0669\n",
            "Step [21950/80000], d_real_loss: 0.1287, d_mnist_loss: 0.0171, d_svhn_loss: 0.1116, d_fake_loss: 0.0332, g_loss: 1.1682\n",
            "Step [21960/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0013, d_svhn_loss: 0.0357, d_fake_loss: 0.0472, g_loss: 1.0829\n",
            "Step [21970/80000], d_real_loss: 0.1679, d_mnist_loss: 0.0082, d_svhn_loss: 0.1597, d_fake_loss: 0.2157, g_loss: 1.1542\n",
            "Step [21980/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0046, d_svhn_loss: 0.0258, d_fake_loss: 0.0226, g_loss: 1.1678\n",
            "Step [21990/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0054, d_svhn_loss: 0.0415, d_fake_loss: 0.0255, g_loss: 1.0547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [22000/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0097, d_svhn_loss: 0.0626, d_fake_loss: 0.0231, g_loss: 1.0509\n",
            "saved ./samples_mnist_svhn/sample-22000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-22000-s-m.png\n",
            "Step [22010/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0020, d_svhn_loss: 0.0448, d_fake_loss: 0.0291, g_loss: 1.1215\n",
            "Step [22020/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0021, d_svhn_loss: 0.0441, d_fake_loss: 0.0441, g_loss: 1.1504\n",
            "Step [22030/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0044, d_svhn_loss: 0.0339, d_fake_loss: 0.1510, g_loss: 1.1760\n",
            "Step [22040/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0178, d_svhn_loss: 0.0291, d_fake_loss: 0.1535, g_loss: 1.0845\n",
            "Step [22050/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0194, d_svhn_loss: 0.0258, d_fake_loss: 0.0595, g_loss: 1.2096\n",
            "Step [22060/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0059, d_svhn_loss: 0.0292, d_fake_loss: 0.0522, g_loss: 1.2587\n",
            "Step [22070/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0074, d_svhn_loss: 0.0478, d_fake_loss: 0.0293, g_loss: 1.1424\n",
            "Step [22080/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0056, d_svhn_loss: 0.0430, d_fake_loss: 0.0560, g_loss: 1.1119\n",
            "Step [22090/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0011, d_svhn_loss: 0.0353, d_fake_loss: 0.0230, g_loss: 1.1247\n",
            "Step [22100/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0171, d_svhn_loss: 0.0600, d_fake_loss: 0.0466, g_loss: 1.0816\n",
            "Step [22110/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0071, d_svhn_loss: 0.0472, d_fake_loss: 0.0792, g_loss: 1.0664\n",
            "Step [22120/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0070, d_svhn_loss: 0.0199, d_fake_loss: 0.0573, g_loss: 1.0770\n",
            "Step [22130/80000], d_real_loss: 0.1354, d_mnist_loss: 0.0196, d_svhn_loss: 0.1158, d_fake_loss: 0.0948, g_loss: 1.1861\n",
            "Step [22140/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0101, d_svhn_loss: 0.0496, d_fake_loss: 0.0474, g_loss: 1.0438\n",
            "Step [22150/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0049, d_svhn_loss: 0.0309, d_fake_loss: 0.0472, g_loss: 0.9555\n",
            "Step [22160/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0140, d_svhn_loss: 0.0381, d_fake_loss: 0.0580, g_loss: 1.1426\n",
            "Step [22170/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0016, d_svhn_loss: 0.0561, d_fake_loss: 0.0586, g_loss: 1.1210\n",
            "Step [22180/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0023, d_svhn_loss: 0.0332, d_fake_loss: 0.0582, g_loss: 1.0012\n",
            "Step [22190/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0034, d_svhn_loss: 0.0547, d_fake_loss: 0.0253, g_loss: 1.2189\n",
            "Step [22200/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0026, d_svhn_loss: 0.0394, d_fake_loss: 0.0323, g_loss: 1.1154\n",
            "Step [22210/80000], d_real_loss: 0.1159, d_mnist_loss: 0.0017, d_svhn_loss: 0.1142, d_fake_loss: 0.0722, g_loss: 1.2022\n",
            "Step [22220/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0011, d_svhn_loss: 0.0337, d_fake_loss: 0.0545, g_loss: 1.1120\n",
            "Step [22230/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0027, d_svhn_loss: 0.0221, d_fake_loss: 0.0576, g_loss: 1.0971\n",
            "Step [22240/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0013, d_svhn_loss: 0.0478, d_fake_loss: 0.0252, g_loss: 1.1049\n",
            "Step [22250/80000], d_real_loss: 0.1450, d_mnist_loss: 0.0170, d_svhn_loss: 0.1279, d_fake_loss: 0.0354, g_loss: 1.1636\n",
            "Step [22260/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0184, d_svhn_loss: 0.0227, d_fake_loss: 0.2124, g_loss: 0.9310\n",
            "Step [22270/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0027, d_svhn_loss: 0.0634, d_fake_loss: 0.1097, g_loss: 1.2392\n",
            "Step [22280/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0018, d_svhn_loss: 0.0290, d_fake_loss: 0.0321, g_loss: 1.0094\n",
            "Step [22290/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0038, d_svhn_loss: 0.0332, d_fake_loss: 0.0377, g_loss: 1.2599\n",
            "Step [22300/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0022, d_svhn_loss: 0.0753, d_fake_loss: 0.0206, g_loss: 1.2285\n",
            "Step [22310/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0222, d_svhn_loss: 0.0535, d_fake_loss: 0.0842, g_loss: 1.3724\n",
            "Step [22320/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0044, d_svhn_loss: 0.0366, d_fake_loss: 0.0243, g_loss: 1.0813\n",
            "Step [22330/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0017, d_svhn_loss: 0.0209, d_fake_loss: 0.0245, g_loss: 1.1077\n",
            "Step [22340/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0011, d_svhn_loss: 0.0583, d_fake_loss: 0.0740, g_loss: 1.3939\n",
            "Step [22350/80000], d_real_loss: 0.1742, d_mnist_loss: 0.0016, d_svhn_loss: 0.1725, d_fake_loss: 0.1318, g_loss: 1.0427\n",
            "Step [22360/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0079, d_svhn_loss: 0.0426, d_fake_loss: 0.0518, g_loss: 1.1421\n",
            "Step [22370/80000], d_real_loss: 0.0902, d_mnist_loss: 0.0099, d_svhn_loss: 0.0803, d_fake_loss: 0.1318, g_loss: 1.1650\n",
            "Step [22380/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0033, d_svhn_loss: 0.0686, d_fake_loss: 0.0963, g_loss: 1.0654\n",
            "Step [22390/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0170, d_svhn_loss: 0.0552, d_fake_loss: 0.0540, g_loss: 1.0670\n",
            "Step [22400/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0256, d_svhn_loss: 0.0483, d_fake_loss: 0.0281, g_loss: 0.9534\n",
            "Step [22410/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0033, d_svhn_loss: 0.0526, d_fake_loss: 0.1376, g_loss: 1.1318\n",
            "Step [22420/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0022, d_svhn_loss: 0.0672, d_fake_loss: 0.0307, g_loss: 1.1413\n",
            "Step [22430/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0085, d_svhn_loss: 0.0330, d_fake_loss: 0.0300, g_loss: 1.0208\n",
            "Step [22440/80000], d_real_loss: 0.1351, d_mnist_loss: 0.0035, d_svhn_loss: 0.1316, d_fake_loss: 0.0546, g_loss: 1.1296\n",
            "Step [22450/80000], d_real_loss: 0.0917, d_mnist_loss: 0.0137, d_svhn_loss: 0.0780, d_fake_loss: 0.0706, g_loss: 0.9589\n",
            "Step [22460/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0019, d_svhn_loss: 0.0398, d_fake_loss: 0.1183, g_loss: 1.0908\n",
            "Step [22470/80000], d_real_loss: 0.1397, d_mnist_loss: 0.0141, d_svhn_loss: 0.1256, d_fake_loss: 0.0445, g_loss: 1.1312\n",
            "Step [22480/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0142, d_svhn_loss: 0.0294, d_fake_loss: 0.0252, g_loss: 1.1174\n",
            "Step [22490/80000], d_real_loss: 0.1053, d_mnist_loss: 0.0212, d_svhn_loss: 0.0842, d_fake_loss: 0.0653, g_loss: 1.3777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [22500/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0071, d_svhn_loss: 0.0259, d_fake_loss: 0.0369, g_loss: 1.1702\n",
            "saved ./samples_mnist_svhn/sample-22500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-22500-s-m.png\n",
            "Step [22510/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0019, d_svhn_loss: 0.0235, d_fake_loss: 0.0211, g_loss: 1.1455\n",
            "Step [22520/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0102, d_svhn_loss: 0.0409, d_fake_loss: 0.0339, g_loss: 1.0379\n",
            "Step [22530/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0030, d_svhn_loss: 0.0378, d_fake_loss: 0.0500, g_loss: 1.2025\n",
            "Step [22540/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0026, d_svhn_loss: 0.0455, d_fake_loss: 0.0285, g_loss: 1.0804\n",
            "Step [22550/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0057, d_svhn_loss: 0.0372, d_fake_loss: 0.0867, g_loss: 1.2353\n",
            "Step [22560/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0040, d_svhn_loss: 0.0252, d_fake_loss: 0.1448, g_loss: 1.1524\n",
            "Step [22570/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0309, d_svhn_loss: 0.0422, d_fake_loss: 0.0846, g_loss: 1.2858\n",
            "Step [22580/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0255, d_svhn_loss: 0.0299, d_fake_loss: 0.0610, g_loss: 1.1370\n",
            "Step [22590/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0076, d_svhn_loss: 0.0355, d_fake_loss: 0.0296, g_loss: 1.2196\n",
            "Step [22600/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0050, d_svhn_loss: 0.0278, d_fake_loss: 0.0629, g_loss: 1.0566\n",
            "Step [22610/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0017, d_svhn_loss: 0.0500, d_fake_loss: 0.0280, g_loss: 1.1360\n",
            "Step [22620/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0051, d_svhn_loss: 0.0157, d_fake_loss: 0.0261, g_loss: 1.2876\n",
            "Step [22630/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0014, d_svhn_loss: 0.0326, d_fake_loss: 0.0545, g_loss: 1.2232\n",
            "Step [22640/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0017, d_svhn_loss: 0.0270, d_fake_loss: 0.0279, g_loss: 1.2645\n",
            "Step [22650/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0053, d_svhn_loss: 0.0170, d_fake_loss: 0.0377, g_loss: 0.9731\n",
            "Step [22660/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0019, d_svhn_loss: 0.0419, d_fake_loss: 0.0278, g_loss: 1.0999\n",
            "Step [22670/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0035, d_svhn_loss: 0.0348, d_fake_loss: 0.0335, g_loss: 1.0533\n",
            "Step [22680/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0042, d_svhn_loss: 0.0507, d_fake_loss: 0.0450, g_loss: 1.1709\n",
            "Step [22690/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0018, d_svhn_loss: 0.0430, d_fake_loss: 0.1060, g_loss: 1.2968\n",
            "Step [22700/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0069, d_svhn_loss: 0.0374, d_fake_loss: 0.0732, g_loss: 1.2224\n",
            "Step [22710/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0016, d_svhn_loss: 0.0316, d_fake_loss: 0.0540, g_loss: 1.0814\n",
            "Step [22720/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0010, d_svhn_loss: 0.0507, d_fake_loss: 0.0477, g_loss: 1.3300\n",
            "Step [22730/80000], d_real_loss: 0.1066, d_mnist_loss: 0.0160, d_svhn_loss: 0.0906, d_fake_loss: 0.0413, g_loss: 1.1284\n",
            "Step [22740/80000], d_real_loss: 0.1724, d_mnist_loss: 0.0106, d_svhn_loss: 0.1618, d_fake_loss: 0.1128, g_loss: 1.0603\n",
            "Step [22750/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0049, d_svhn_loss: 0.0358, d_fake_loss: 0.0274, g_loss: 1.1700\n",
            "Step [22760/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0025, d_svhn_loss: 0.0399, d_fake_loss: 0.0406, g_loss: 1.1200\n",
            "Step [22770/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0037, d_svhn_loss: 0.0627, d_fake_loss: 0.0394, g_loss: 1.1955\n",
            "Step [22780/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0078, d_svhn_loss: 0.0325, d_fake_loss: 0.0467, g_loss: 1.0947\n",
            "Step [22790/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0041, d_svhn_loss: 0.0444, d_fake_loss: 0.0364, g_loss: 1.2083\n",
            "Step [22800/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0048, d_svhn_loss: 0.0459, d_fake_loss: 0.1026, g_loss: 1.2628\n",
            "Step [22810/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0048, d_svhn_loss: 0.0439, d_fake_loss: 0.1090, g_loss: 1.2202\n",
            "Step [22820/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0043, d_svhn_loss: 0.0315, d_fake_loss: 0.1287, g_loss: 1.1712\n",
            "Step [22830/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0169, d_svhn_loss: 0.0418, d_fake_loss: 0.0345, g_loss: 1.0945\n",
            "Step [22840/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0100, d_svhn_loss: 0.0138, d_fake_loss: 0.0303, g_loss: 1.2199\n",
            "Step [22850/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0060, d_svhn_loss: 0.0547, d_fake_loss: 0.0468, g_loss: 1.1166\n",
            "Step [22860/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0033, d_svhn_loss: 0.0339, d_fake_loss: 0.0338, g_loss: 1.2060\n",
            "Step [22870/80000], d_real_loss: 0.0835, d_mnist_loss: 0.0130, d_svhn_loss: 0.0705, d_fake_loss: 0.0567, g_loss: 1.2012\n",
            "Step [22880/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0050, d_svhn_loss: 0.0350, d_fake_loss: 0.0501, g_loss: 1.2037\n",
            "Step [22890/80000], d_real_loss: 0.0905, d_mnist_loss: 0.0100, d_svhn_loss: 0.0806, d_fake_loss: 0.0257, g_loss: 1.2377\n",
            "Step [22900/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0012, d_svhn_loss: 0.0440, d_fake_loss: 0.0322, g_loss: 1.1357\n",
            "Step [22910/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0489, d_svhn_loss: 0.0315, d_fake_loss: 0.0474, g_loss: 0.9921\n",
            "Step [22920/80000], d_real_loss: 0.3018, d_mnist_loss: 0.0073, d_svhn_loss: 0.2945, d_fake_loss: 0.0927, g_loss: 1.0967\n",
            "Step [22930/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0029, d_svhn_loss: 0.0384, d_fake_loss: 0.0307, g_loss: 1.1355\n",
            "Step [22940/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0016, d_svhn_loss: 0.0427, d_fake_loss: 0.0282, g_loss: 1.0985\n",
            "Step [22950/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0296, d_svhn_loss: 0.0475, d_fake_loss: 0.0503, g_loss: 1.2408\n",
            "Step [22960/80000], d_real_loss: 0.1224, d_mnist_loss: 0.0039, d_svhn_loss: 0.1184, d_fake_loss: 0.0567, g_loss: 1.1568\n",
            "Step [22970/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0097, d_svhn_loss: 0.0205, d_fake_loss: 0.0397, g_loss: 1.1769\n",
            "Step [22980/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0015, d_svhn_loss: 0.0475, d_fake_loss: 0.0545, g_loss: 1.1331\n",
            "Step [22990/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0018, d_svhn_loss: 0.0274, d_fake_loss: 0.0554, g_loss: 1.0946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [23000/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0036, d_svhn_loss: 0.0544, d_fake_loss: 0.0340, g_loss: 1.1650\n",
            "saved ./samples_mnist_svhn/sample-23000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-23000-s-m.png\n",
            "Step [23010/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0056, d_svhn_loss: 0.0420, d_fake_loss: 0.0323, g_loss: 1.2163\n",
            "Step [23020/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0012, d_svhn_loss: 0.0402, d_fake_loss: 0.0471, g_loss: 1.0660\n",
            "Step [23030/80000], d_real_loss: 0.1338, d_mnist_loss: 0.0096, d_svhn_loss: 0.1242, d_fake_loss: 0.0582, g_loss: 1.1314\n",
            "Step [23040/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0013, d_svhn_loss: 0.0387, d_fake_loss: 0.0746, g_loss: 1.2983\n",
            "Step [23050/80000], d_real_loss: 0.1864, d_mnist_loss: 0.0043, d_svhn_loss: 0.1821, d_fake_loss: 0.0846, g_loss: 1.0588\n",
            "Step [23060/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0022, d_svhn_loss: 0.0284, d_fake_loss: 0.1374, g_loss: 1.1000\n",
            "Step [23070/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0082, d_svhn_loss: 0.0378, d_fake_loss: 0.0744, g_loss: 1.0176\n",
            "Step [23080/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0027, d_svhn_loss: 0.0514, d_fake_loss: 0.0677, g_loss: 1.1407\n",
            "Step [23090/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0074, d_svhn_loss: 0.0428, d_fake_loss: 0.1361, g_loss: 1.0570\n",
            "Step [23100/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0016, d_svhn_loss: 0.0296, d_fake_loss: 0.0356, g_loss: 1.0853\n",
            "Step [23110/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0014, d_svhn_loss: 0.0191, d_fake_loss: 0.0641, g_loss: 1.1217\n",
            "Step [23120/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0028, d_svhn_loss: 0.0438, d_fake_loss: 0.0482, g_loss: 1.0617\n",
            "Step [23130/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0048, d_svhn_loss: 0.0576, d_fake_loss: 0.2300, g_loss: 1.4284\n",
            "Step [23140/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0022, d_svhn_loss: 0.0421, d_fake_loss: 0.1460, g_loss: 1.2405\n",
            "Step [23150/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0047, d_svhn_loss: 0.0250, d_fake_loss: 0.0242, g_loss: 1.0481\n",
            "Step [23160/80000], d_real_loss: 0.0193, d_mnist_loss: 0.0023, d_svhn_loss: 0.0170, d_fake_loss: 0.0193, g_loss: 1.0802\n",
            "Step [23170/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0260, d_svhn_loss: 0.0225, d_fake_loss: 0.0171, g_loss: 1.2220\n",
            "Step [23180/80000], d_real_loss: 0.0832, d_mnist_loss: 0.0103, d_svhn_loss: 0.0729, d_fake_loss: 0.0390, g_loss: 1.1888\n",
            "Step [23190/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0489, d_svhn_loss: 0.0379, d_fake_loss: 0.0242, g_loss: 1.2265\n",
            "Step [23200/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0018, d_svhn_loss: 0.0452, d_fake_loss: 0.0337, g_loss: 1.2280\n",
            "Step [23210/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0021, d_svhn_loss: 0.0485, d_fake_loss: 0.0652, g_loss: 1.3050\n",
            "Step [23220/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0017, d_svhn_loss: 0.0313, d_fake_loss: 0.0642, g_loss: 1.2828\n",
            "Step [23230/80000], d_real_loss: 0.0644, d_mnist_loss: 0.0043, d_svhn_loss: 0.0601, d_fake_loss: 0.0305, g_loss: 1.0807\n",
            "Step [23240/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0056, d_svhn_loss: 0.0312, d_fake_loss: 0.0300, g_loss: 1.1731\n",
            "Step [23250/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0061, d_svhn_loss: 0.0241, d_fake_loss: 0.0538, g_loss: 1.1585\n",
            "Step [23260/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0014, d_svhn_loss: 0.0267, d_fake_loss: 0.0326, g_loss: 1.1550\n",
            "Step [23270/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0131, d_svhn_loss: 0.0358, d_fake_loss: 0.0359, g_loss: 1.1018\n",
            "Step [23280/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0283, d_svhn_loss: 0.0334, d_fake_loss: 0.0854, g_loss: 1.2196\n",
            "Step [23290/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0304, d_svhn_loss: 0.0299, d_fake_loss: 0.0327, g_loss: 1.0639\n",
            "Step [23300/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0329, d_svhn_loss: 0.0328, d_fake_loss: 0.0466, g_loss: 1.0771\n",
            "Step [23310/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0041, d_svhn_loss: 0.0332, d_fake_loss: 0.0586, g_loss: 1.1971\n",
            "Step [23320/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0151, d_svhn_loss: 0.0274, d_fake_loss: 0.0363, g_loss: 1.1928\n",
            "Step [23330/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0043, d_svhn_loss: 0.0414, d_fake_loss: 0.0622, g_loss: 1.2042\n",
            "Step [23340/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0053, d_svhn_loss: 0.0670, d_fake_loss: 0.0742, g_loss: 1.0351\n",
            "Step [23350/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0017, d_svhn_loss: 0.0276, d_fake_loss: 0.0280, g_loss: 1.1796\n",
            "Step [23360/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0027, d_svhn_loss: 0.0444, d_fake_loss: 0.0306, g_loss: 1.1485\n",
            "Step [23370/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0027, d_svhn_loss: 0.0493, d_fake_loss: 0.0481, g_loss: 1.1485\n",
            "Step [23380/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0016, d_svhn_loss: 0.0340, d_fake_loss: 0.0233, g_loss: 1.1224\n",
            "Step [23390/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0176, d_svhn_loss: 0.0337, d_fake_loss: 0.0553, g_loss: 1.2893\n",
            "Step [23400/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0161, d_svhn_loss: 0.0427, d_fake_loss: 0.0491, g_loss: 1.2986\n",
            "Step [23410/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0059, d_svhn_loss: 0.0283, d_fake_loss: 0.0178, g_loss: 1.1177\n",
            "Step [23420/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0049, d_svhn_loss: 0.0738, d_fake_loss: 0.0528, g_loss: 1.1177\n",
            "Step [23430/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0017, d_svhn_loss: 0.0527, d_fake_loss: 0.0474, g_loss: 1.1197\n",
            "Step [23440/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0016, d_svhn_loss: 0.0353, d_fake_loss: 0.0524, g_loss: 1.1332\n",
            "Step [23450/80000], d_real_loss: 0.1791, d_mnist_loss: 0.0017, d_svhn_loss: 0.1774, d_fake_loss: 0.1123, g_loss: 1.1755\n",
            "Step [23460/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0038, d_svhn_loss: 0.0344, d_fake_loss: 0.0257, g_loss: 1.2980\n",
            "Step [23470/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0083, d_svhn_loss: 0.0476, d_fake_loss: 0.0697, g_loss: 1.0162\n",
            "Step [23480/80000], d_real_loss: 0.1544, d_mnist_loss: 0.0032, d_svhn_loss: 0.1512, d_fake_loss: 0.0585, g_loss: 1.2052\n",
            "Step [23490/80000], d_real_loss: 0.1025, d_mnist_loss: 0.0043, d_svhn_loss: 0.0982, d_fake_loss: 0.0482, g_loss: 1.0480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [23500/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0156, d_svhn_loss: 0.0141, d_fake_loss: 0.0457, g_loss: 1.2025\n",
            "saved ./samples_mnist_svhn/sample-23500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-23500-s-m.png\n",
            "Step [23510/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0099, d_svhn_loss: 0.0203, d_fake_loss: 0.0461, g_loss: 1.1709\n",
            "Step [23520/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0345, d_svhn_loss: 0.0227, d_fake_loss: 0.0271, g_loss: 1.1522\n",
            "Step [23530/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0012, d_svhn_loss: 0.0539, d_fake_loss: 0.1051, g_loss: 1.1381\n",
            "Step [23540/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0021, d_svhn_loss: 0.0465, d_fake_loss: 0.0228, g_loss: 1.4579\n",
            "Step [23550/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0020, d_svhn_loss: 0.0628, d_fake_loss: 0.0630, g_loss: 1.0336\n",
            "Step [23560/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0088, d_svhn_loss: 0.0287, d_fake_loss: 0.0750, g_loss: 1.1465\n",
            "Step [23570/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0168, d_svhn_loss: 0.0392, d_fake_loss: 0.1012, g_loss: 0.9425\n",
            "Step [23580/80000], d_real_loss: 0.0939, d_mnist_loss: 0.0033, d_svhn_loss: 0.0907, d_fake_loss: 0.0468, g_loss: 1.0539\n",
            "Step [23590/80000], d_real_loss: 0.1105, d_mnist_loss: 0.0033, d_svhn_loss: 0.1071, d_fake_loss: 0.0359, g_loss: 1.2563\n",
            "Step [23600/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0092, d_svhn_loss: 0.0462, d_fake_loss: 0.0539, g_loss: 1.4192\n",
            "Step [23610/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0051, d_svhn_loss: 0.0430, d_fake_loss: 0.0837, g_loss: 1.0868\n",
            "Step [23620/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0022, d_svhn_loss: 0.0329, d_fake_loss: 0.0435, g_loss: 1.0682\n",
            "Step [23630/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0074, d_svhn_loss: 0.0260, d_fake_loss: 0.0177, g_loss: 1.1213\n",
            "Step [23640/80000], d_real_loss: 0.1565, d_mnist_loss: 0.0020, d_svhn_loss: 0.1544, d_fake_loss: 0.0387, g_loss: 1.1313\n",
            "Step [23650/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0026, d_svhn_loss: 0.0254, d_fake_loss: 0.0182, g_loss: 1.2067\n",
            "Step [23660/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0016, d_svhn_loss: 0.0200, d_fake_loss: 0.0405, g_loss: 1.1532\n",
            "Step [23670/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0014, d_svhn_loss: 0.0183, d_fake_loss: 0.0296, g_loss: 1.1463\n",
            "Step [23680/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0054, d_svhn_loss: 0.0531, d_fake_loss: 0.0418, g_loss: 1.2053\n",
            "Step [23690/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0012, d_svhn_loss: 0.0414, d_fake_loss: 0.0346, g_loss: 1.0900\n",
            "Step [23700/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0047, d_svhn_loss: 0.0267, d_fake_loss: 0.0279, g_loss: 1.0917\n",
            "Step [23710/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0022, d_svhn_loss: 0.0529, d_fake_loss: 0.0738, g_loss: 1.1517\n",
            "Step [23720/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0013, d_svhn_loss: 0.0269, d_fake_loss: 0.0764, g_loss: 1.1440\n",
            "Step [23730/80000], d_real_loss: 0.1206, d_mnist_loss: 0.0063, d_svhn_loss: 0.1143, d_fake_loss: 0.0571, g_loss: 1.1268\n",
            "Step [23740/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0190, d_svhn_loss: 0.0351, d_fake_loss: 0.0638, g_loss: 1.3185\n",
            "Step [23750/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0026, d_svhn_loss: 0.0436, d_fake_loss: 0.1017, g_loss: 1.1157\n",
            "Step [23760/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0029, d_svhn_loss: 0.0448, d_fake_loss: 0.0387, g_loss: 1.3415\n",
            "Step [23770/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0105, d_svhn_loss: 0.0408, d_fake_loss: 0.0567, g_loss: 1.3895\n",
            "Step [23780/80000], d_real_loss: 0.1102, d_mnist_loss: 0.0602, d_svhn_loss: 0.0500, d_fake_loss: 0.2393, g_loss: 2.4326\n",
            "Step [23790/80000], d_real_loss: 0.1213, d_mnist_loss: 0.0738, d_svhn_loss: 0.0476, d_fake_loss: 0.2454, g_loss: 1.5168\n",
            "Step [23800/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0051, d_svhn_loss: 0.0792, d_fake_loss: 0.2878, g_loss: 1.0438\n",
            "Step [23810/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0054, d_svhn_loss: 0.0543, d_fake_loss: 0.0388, g_loss: 1.1926\n",
            "Step [23820/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0038, d_svhn_loss: 0.0640, d_fake_loss: 0.0614, g_loss: 1.1690\n",
            "Step [23830/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0095, d_svhn_loss: 0.0257, d_fake_loss: 0.0675, g_loss: 1.2182\n",
            "Step [23840/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0025, d_svhn_loss: 0.0656, d_fake_loss: 0.1088, g_loss: 1.2204\n",
            "Step [23850/80000], d_real_loss: 0.0922, d_mnist_loss: 0.0238, d_svhn_loss: 0.0685, d_fake_loss: 0.0537, g_loss: 1.1869\n",
            "Step [23860/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0029, d_svhn_loss: 0.0250, d_fake_loss: 0.0364, g_loss: 1.1895\n",
            "Step [23870/80000], d_real_loss: 0.0914, d_mnist_loss: 0.0042, d_svhn_loss: 0.0871, d_fake_loss: 0.0325, g_loss: 1.2428\n",
            "Step [23880/80000], d_real_loss: 0.1319, d_mnist_loss: 0.0045, d_svhn_loss: 0.1274, d_fake_loss: 0.0623, g_loss: 1.2346\n",
            "Step [23890/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0017, d_svhn_loss: 0.0289, d_fake_loss: 0.0305, g_loss: 1.0955\n",
            "Step [23900/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0162, d_svhn_loss: 0.0365, d_fake_loss: 0.0452, g_loss: 1.1911\n",
            "Step [23910/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0020, d_svhn_loss: 0.0433, d_fake_loss: 0.0395, g_loss: 1.1127\n",
            "Step [23920/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0023, d_svhn_loss: 0.0845, d_fake_loss: 0.0326, g_loss: 1.1386\n",
            "Step [23930/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0144, d_svhn_loss: 0.0547, d_fake_loss: 0.0230, g_loss: 1.1072\n",
            "Step [23940/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0017, d_svhn_loss: 0.0244, d_fake_loss: 0.0585, g_loss: 1.2053\n",
            "Step [23950/80000], d_real_loss: 0.0827, d_mnist_loss: 0.0150, d_svhn_loss: 0.0677, d_fake_loss: 0.0307, g_loss: 1.0403\n",
            "Step [23960/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0018, d_svhn_loss: 0.0331, d_fake_loss: 0.0411, g_loss: 1.4784\n",
            "Step [23970/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0025, d_svhn_loss: 0.0397, d_fake_loss: 0.0224, g_loss: 1.1910\n",
            "Step [23980/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0052, d_svhn_loss: 0.0410, d_fake_loss: 0.0843, g_loss: 1.0543\n",
            "Step [23990/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0016, d_svhn_loss: 0.0272, d_fake_loss: 0.0213, g_loss: 1.1209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [24000/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0029, d_svhn_loss: 0.0236, d_fake_loss: 0.0347, g_loss: 1.1722\n",
            "saved ./samples_mnist_svhn/sample-24000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-24000-s-m.png\n",
            "Step [24010/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0044, d_svhn_loss: 0.0315, d_fake_loss: 0.0349, g_loss: 1.1658\n",
            "Step [24020/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0197, d_svhn_loss: 0.0316, d_fake_loss: 0.0832, g_loss: 1.1825\n",
            "Step [24030/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0086, d_svhn_loss: 0.0171, d_fake_loss: 0.0275, g_loss: 1.1836\n",
            "Step [24040/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0022, d_svhn_loss: 0.0298, d_fake_loss: 0.0210, g_loss: 1.1178\n",
            "Step [24050/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0053, d_svhn_loss: 0.0286, d_fake_loss: 0.0300, g_loss: 1.1216\n",
            "Step [24060/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0010, d_svhn_loss: 0.0303, d_fake_loss: 0.0516, g_loss: 1.1171\n",
            "Step [24070/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0016, d_svhn_loss: 0.0378, d_fake_loss: 0.0206, g_loss: 1.1211\n",
            "Step [24080/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0020, d_svhn_loss: 0.0339, d_fake_loss: 0.0446, g_loss: 1.1259\n",
            "Step [24090/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0016, d_svhn_loss: 0.0654, d_fake_loss: 0.0586, g_loss: 1.0206\n",
            "Step [24100/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0097, d_svhn_loss: 0.0510, d_fake_loss: 0.0389, g_loss: 1.0845\n",
            "Step [24110/80000], d_real_loss: 0.1504, d_mnist_loss: 0.0057, d_svhn_loss: 0.1447, d_fake_loss: 0.0296, g_loss: 1.1172\n",
            "Step [24120/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0011, d_svhn_loss: 0.0606, d_fake_loss: 0.1045, g_loss: 1.1163\n",
            "Step [24130/80000], d_real_loss: 0.1431, d_mnist_loss: 0.0069, d_svhn_loss: 0.1362, d_fake_loss: 0.0380, g_loss: 1.1010\n",
            "Step [24140/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0185, d_svhn_loss: 0.0485, d_fake_loss: 0.0411, g_loss: 1.0392\n",
            "Step [24150/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0028, d_svhn_loss: 0.0533, d_fake_loss: 0.0419, g_loss: 1.1303\n",
            "Step [24160/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0023, d_svhn_loss: 0.0288, d_fake_loss: 0.0299, g_loss: 1.1274\n",
            "Step [24170/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0333, d_svhn_loss: 0.0345, d_fake_loss: 0.0293, g_loss: 1.1818\n",
            "Step [24180/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0020, d_svhn_loss: 0.0285, d_fake_loss: 0.1252, g_loss: 1.2831\n",
            "Step [24190/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0318, d_svhn_loss: 0.0260, d_fake_loss: 0.1604, g_loss: 1.1430\n",
            "Step [24200/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0250, d_svhn_loss: 0.0312, d_fake_loss: 0.0555, g_loss: 1.2526\n",
            "Step [24210/80000], d_real_loss: 0.1097, d_mnist_loss: 0.0531, d_svhn_loss: 0.0566, d_fake_loss: 0.0464, g_loss: 1.2925\n",
            "Step [24220/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0034, d_svhn_loss: 0.0696, d_fake_loss: 0.0748, g_loss: 1.2066\n",
            "Step [24230/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0103, d_svhn_loss: 0.0289, d_fake_loss: 0.0470, g_loss: 1.1372\n",
            "Step [24240/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0073, d_svhn_loss: 0.0241, d_fake_loss: 0.0430, g_loss: 1.0705\n",
            "Step [24250/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0359, d_svhn_loss: 0.0183, d_fake_loss: 0.0346, g_loss: 1.3483\n",
            "Step [24260/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0024, d_svhn_loss: 0.0348, d_fake_loss: 0.0332, g_loss: 1.1472\n",
            "Step [24270/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0021, d_svhn_loss: 0.0823, d_fake_loss: 0.0424, g_loss: 1.0949\n",
            "Step [24280/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0015, d_svhn_loss: 0.0746, d_fake_loss: 0.0949, g_loss: 1.3959\n",
            "Step [24290/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0019, d_svhn_loss: 0.0499, d_fake_loss: 0.0572, g_loss: 1.3250\n",
            "Step [24300/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0178, d_svhn_loss: 0.0372, d_fake_loss: 0.0720, g_loss: 1.2133\n",
            "Step [24310/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0207, d_svhn_loss: 0.0347, d_fake_loss: 0.0386, g_loss: 1.2192\n",
            "Step [24320/80000], d_real_loss: 0.0987, d_mnist_loss: 0.0154, d_svhn_loss: 0.0833, d_fake_loss: 0.0949, g_loss: 1.0865\n",
            "Step [24330/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0147, d_svhn_loss: 0.0446, d_fake_loss: 0.0906, g_loss: 1.0741\n",
            "Step [24340/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0188, d_svhn_loss: 0.0371, d_fake_loss: 0.0624, g_loss: 1.0979\n",
            "Step [24350/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0026, d_svhn_loss: 0.0326, d_fake_loss: 0.0748, g_loss: 1.1772\n",
            "Step [24360/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0129, d_svhn_loss: 0.0570, d_fake_loss: 0.0300, g_loss: 1.0995\n",
            "Step [24370/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0054, d_svhn_loss: 0.0401, d_fake_loss: 0.0385, g_loss: 1.0738\n",
            "Step [24380/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0017, d_svhn_loss: 0.0368, d_fake_loss: 0.0628, g_loss: 1.1213\n",
            "Step [24390/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0030, d_svhn_loss: 0.0289, d_fake_loss: 0.0288, g_loss: 1.2165\n",
            "Step [24400/80000], d_real_loss: 0.1815, d_mnist_loss: 0.0139, d_svhn_loss: 0.1676, d_fake_loss: 0.0268, g_loss: 1.2383\n",
            "Step [24410/80000], d_real_loss: 0.1871, d_mnist_loss: 0.0014, d_svhn_loss: 0.1857, d_fake_loss: 0.0890, g_loss: 1.0821\n",
            "Step [24420/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0048, d_svhn_loss: 0.0485, d_fake_loss: 0.0366, g_loss: 1.1019\n",
            "Step [24430/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0091, d_svhn_loss: 0.0538, d_fake_loss: 0.0510, g_loss: 1.1096\n",
            "Step [24440/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0016, d_svhn_loss: 0.0438, d_fake_loss: 0.1051, g_loss: 1.2343\n",
            "Step [24450/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0022, d_svhn_loss: 0.0415, d_fake_loss: 0.0807, g_loss: 1.2119\n",
            "Step [24460/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0073, d_svhn_loss: 0.0574, d_fake_loss: 0.2632, g_loss: 1.4489\n",
            "Step [24470/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0138, d_svhn_loss: 0.0440, d_fake_loss: 0.0527, g_loss: 1.2201\n",
            "Step [24480/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0034, d_svhn_loss: 0.0261, d_fake_loss: 0.0367, g_loss: 1.1882\n",
            "Step [24490/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0052, d_svhn_loss: 0.0619, d_fake_loss: 0.0279, g_loss: 1.1868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [24500/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0017, d_svhn_loss: 0.0181, d_fake_loss: 0.0786, g_loss: 1.1567\n",
            "saved ./samples_mnist_svhn/sample-24500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-24500-s-m.png\n",
            "Step [24510/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0022, d_svhn_loss: 0.0353, d_fake_loss: 0.0323, g_loss: 1.1140\n",
            "Step [24520/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0025, d_svhn_loss: 0.0388, d_fake_loss: 0.0579, g_loss: 1.1210\n",
            "Step [24530/80000], d_real_loss: 0.0759, d_mnist_loss: 0.0204, d_svhn_loss: 0.0555, d_fake_loss: 0.0514, g_loss: 1.1572\n",
            "Step [24540/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0015, d_svhn_loss: 0.0324, d_fake_loss: 0.0683, g_loss: 1.1065\n",
            "Step [24550/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0048, d_svhn_loss: 0.0831, d_fake_loss: 0.1124, g_loss: 1.1789\n",
            "Step [24560/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0061, d_svhn_loss: 0.0292, d_fake_loss: 0.0230, g_loss: 1.1682\n",
            "Step [24570/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0012, d_svhn_loss: 0.0469, d_fake_loss: 0.0412, g_loss: 1.3011\n",
            "Step [24580/80000], d_real_loss: 0.1415, d_mnist_loss: 0.0063, d_svhn_loss: 0.1352, d_fake_loss: 0.0289, g_loss: 1.1141\n",
            "Step [24590/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0027, d_svhn_loss: 0.0543, d_fake_loss: 0.0297, g_loss: 1.1782\n",
            "Step [24600/80000], d_real_loss: 0.1150, d_mnist_loss: 0.0330, d_svhn_loss: 0.0821, d_fake_loss: 0.0357, g_loss: 0.9589\n",
            "Step [24610/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0017, d_svhn_loss: 0.0309, d_fake_loss: 0.0650, g_loss: 1.1508\n",
            "Step [24620/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0014, d_svhn_loss: 0.0709, d_fake_loss: 0.0470, g_loss: 1.1241\n",
            "Step [24630/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0012, d_svhn_loss: 0.0559, d_fake_loss: 0.0246, g_loss: 1.1431\n",
            "Step [24640/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0017, d_svhn_loss: 0.0479, d_fake_loss: 0.0629, g_loss: 1.1319\n",
            "Step [24650/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0051, d_svhn_loss: 0.0727, d_fake_loss: 0.0279, g_loss: 1.1146\n",
            "Step [24660/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0032, d_svhn_loss: 0.0312, d_fake_loss: 0.0341, g_loss: 1.1477\n",
            "Step [24670/80000], d_real_loss: 0.1275, d_mnist_loss: 0.0021, d_svhn_loss: 0.1254, d_fake_loss: 0.0412, g_loss: 1.1348\n",
            "Step [24680/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0084, d_svhn_loss: 0.0296, d_fake_loss: 0.0257, g_loss: 1.1424\n",
            "Step [24690/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0170, d_svhn_loss: 0.0239, d_fake_loss: 0.0456, g_loss: 1.1035\n",
            "Step [24700/80000], d_real_loss: 0.0797, d_mnist_loss: 0.0015, d_svhn_loss: 0.0782, d_fake_loss: 0.0462, g_loss: 1.1450\n",
            "Step [24710/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0051, d_svhn_loss: 0.0215, d_fake_loss: 0.0344, g_loss: 1.0430\n",
            "Step [24720/80000], d_real_loss: 0.0949, d_mnist_loss: 0.0162, d_svhn_loss: 0.0787, d_fake_loss: 0.0884, g_loss: 1.0740\n",
            "Step [24730/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0125, d_svhn_loss: 0.0261, d_fake_loss: 0.0695, g_loss: 1.1602\n",
            "Step [24740/80000], d_real_loss: 0.0830, d_mnist_loss: 0.0020, d_svhn_loss: 0.0810, d_fake_loss: 0.0427, g_loss: 1.1116\n",
            "Step [24750/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0018, d_svhn_loss: 0.0675, d_fake_loss: 0.1776, g_loss: 1.1792\n",
            "Step [24760/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0010, d_svhn_loss: 0.0299, d_fake_loss: 0.0430, g_loss: 1.1049\n",
            "Step [24770/80000], d_real_loss: 0.0931, d_mnist_loss: 0.0013, d_svhn_loss: 0.0918, d_fake_loss: 0.0300, g_loss: 1.0941\n",
            "Step [24780/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0248, d_svhn_loss: 0.0331, d_fake_loss: 0.0188, g_loss: 1.2471\n",
            "Step [24790/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0246, d_svhn_loss: 0.0240, d_fake_loss: 0.0493, g_loss: 1.0626\n",
            "Step [24800/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0018, d_svhn_loss: 0.0530, d_fake_loss: 0.0455, g_loss: 1.1042\n",
            "Step [24810/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0014, d_svhn_loss: 0.0477, d_fake_loss: 0.0293, g_loss: 1.2273\n",
            "Step [24820/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0013, d_svhn_loss: 0.0197, d_fake_loss: 0.0691, g_loss: 1.1844\n",
            "Step [24830/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0028, d_svhn_loss: 0.0526, d_fake_loss: 0.0540, g_loss: 1.1104\n",
            "Step [24840/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0047, d_svhn_loss: 0.0450, d_fake_loss: 0.0310, g_loss: 1.0950\n",
            "Step [24850/80000], d_real_loss: 0.1165, d_mnist_loss: 0.0236, d_svhn_loss: 0.0929, d_fake_loss: 0.0636, g_loss: 1.0950\n",
            "Step [24860/80000], d_real_loss: 0.0826, d_mnist_loss: 0.0012, d_svhn_loss: 0.0813, d_fake_loss: 0.0732, g_loss: 1.1864\n",
            "Step [24870/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0015, d_svhn_loss: 0.0743, d_fake_loss: 0.0607, g_loss: 1.1447\n",
            "Step [24880/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0020, d_svhn_loss: 0.0318, d_fake_loss: 0.1308, g_loss: 1.1844\n",
            "Step [24890/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0012, d_svhn_loss: 0.0631, d_fake_loss: 0.0208, g_loss: 1.0838\n",
            "Step [24900/80000], d_real_loss: 0.1624, d_mnist_loss: 0.0141, d_svhn_loss: 0.1483, d_fake_loss: 0.0241, g_loss: 1.2556\n",
            "Step [24910/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0063, d_svhn_loss: 0.0292, d_fake_loss: 0.0325, g_loss: 1.0689\n",
            "Step [24920/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0089, d_svhn_loss: 0.0500, d_fake_loss: 0.0245, g_loss: 1.1588\n",
            "Step [24930/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0102, d_svhn_loss: 0.0314, d_fake_loss: 0.1074, g_loss: 1.0317\n",
            "Step [24940/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0107, d_svhn_loss: 0.0310, d_fake_loss: 0.0670, g_loss: 1.0448\n",
            "Step [24950/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0019, d_svhn_loss: 0.0582, d_fake_loss: 0.0270, g_loss: 1.1335\n",
            "Step [24960/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0024, d_svhn_loss: 0.0357, d_fake_loss: 0.0728, g_loss: 1.1636\n",
            "Step [24970/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0016, d_svhn_loss: 0.0282, d_fake_loss: 0.0370, g_loss: 1.1046\n",
            "Step [24980/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0013, d_svhn_loss: 0.0263, d_fake_loss: 0.0272, g_loss: 1.1852\n",
            "Step [24990/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0256, d_svhn_loss: 0.0259, d_fake_loss: 0.0289, g_loss: 0.9757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [25000/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0254, d_svhn_loss: 0.0419, d_fake_loss: 0.0941, g_loss: 1.2450\n",
            "saved ./samples_mnist_svhn/sample-25000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-25000-s-m.png\n",
            "Step [25010/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0277, d_svhn_loss: 0.0205, d_fake_loss: 0.0450, g_loss: 1.1526\n",
            "Step [25020/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0064, d_svhn_loss: 0.0312, d_fake_loss: 0.0853, g_loss: 1.4578\n",
            "Step [25030/80000], d_real_loss: 0.0816, d_mnist_loss: 0.0168, d_svhn_loss: 0.0648, d_fake_loss: 0.0565, g_loss: 1.0952\n",
            "Step [25040/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0063, d_svhn_loss: 0.0780, d_fake_loss: 0.1330, g_loss: 1.1250\n",
            "Step [25050/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0037, d_svhn_loss: 0.0290, d_fake_loss: 0.0309, g_loss: 1.1933\n",
            "Step [25060/80000], d_real_loss: 0.0821, d_mnist_loss: 0.0068, d_svhn_loss: 0.0753, d_fake_loss: 0.0364, g_loss: 1.0628\n",
            "Step [25070/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0029, d_svhn_loss: 0.0388, d_fake_loss: 0.0572, g_loss: 1.1210\n",
            "Step [25080/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0011, d_svhn_loss: 0.0220, d_fake_loss: 0.1073, g_loss: 1.1593\n",
            "Step [25090/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0029, d_svhn_loss: 0.0278, d_fake_loss: 0.0737, g_loss: 1.1919\n",
            "Step [25100/80000], d_real_loss: 0.0963, d_mnist_loss: 0.0029, d_svhn_loss: 0.0934, d_fake_loss: 0.0337, g_loss: 1.1445\n",
            "Step [25110/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0178, d_svhn_loss: 0.0539, d_fake_loss: 0.0427, g_loss: 1.2018\n",
            "Step [25120/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0021, d_svhn_loss: 0.0675, d_fake_loss: 0.0770, g_loss: 1.1338\n",
            "Step [25130/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0025, d_svhn_loss: 0.0287, d_fake_loss: 0.2016, g_loss: 1.0684\n",
            "Step [25140/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0016, d_svhn_loss: 0.0256, d_fake_loss: 0.0353, g_loss: 1.1308\n",
            "Step [25150/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0031, d_svhn_loss: 0.0543, d_fake_loss: 0.0513, g_loss: 1.1483\n",
            "Step [25160/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0087, d_svhn_loss: 0.0328, d_fake_loss: 0.0189, g_loss: 1.2020\n",
            "Step [25170/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0069, d_svhn_loss: 0.0440, d_fake_loss: 0.0367, g_loss: 1.0976\n",
            "Step [25180/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0018, d_svhn_loss: 0.0378, d_fake_loss: 0.0585, g_loss: 1.2227\n",
            "Step [25190/80000], d_real_loss: 0.0969, d_mnist_loss: 0.0089, d_svhn_loss: 0.0881, d_fake_loss: 0.2198, g_loss: 1.1841\n",
            "Step [25200/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0021, d_svhn_loss: 0.0302, d_fake_loss: 0.1114, g_loss: 1.2279\n",
            "Step [25210/80000], d_real_loss: 0.0966, d_mnist_loss: 0.0569, d_svhn_loss: 0.0398, d_fake_loss: 0.0612, g_loss: 1.1723\n",
            "Step [25220/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0019, d_svhn_loss: 0.0422, d_fake_loss: 0.0944, g_loss: 1.1342\n",
            "Step [25230/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0013, d_svhn_loss: 0.0352, d_fake_loss: 0.0282, g_loss: 1.1908\n",
            "Step [25240/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0014, d_svhn_loss: 0.0368, d_fake_loss: 0.0425, g_loss: 1.1426\n",
            "Step [25250/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0039, d_svhn_loss: 0.0255, d_fake_loss: 0.0233, g_loss: 1.1269\n",
            "Step [25260/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0022, d_svhn_loss: 0.0288, d_fake_loss: 0.0457, g_loss: 1.3182\n",
            "Step [25270/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0010, d_svhn_loss: 0.0393, d_fake_loss: 0.0350, g_loss: 1.1097\n",
            "Step [25280/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0012, d_svhn_loss: 0.0338, d_fake_loss: 0.0408, g_loss: 1.1734\n",
            "Step [25290/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0016, d_svhn_loss: 0.0255, d_fake_loss: 0.0269, g_loss: 1.0803\n",
            "Step [25300/80000], d_real_loss: 0.1290, d_mnist_loss: 0.0038, d_svhn_loss: 0.1252, d_fake_loss: 0.0590, g_loss: 1.1727\n",
            "Step [25310/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0055, d_svhn_loss: 0.0531, d_fake_loss: 0.0330, g_loss: 1.0581\n",
            "Step [25320/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0015, d_svhn_loss: 0.0285, d_fake_loss: 0.0424, g_loss: 1.1238\n",
            "Step [25330/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0140, d_svhn_loss: 0.0616, d_fake_loss: 0.2269, g_loss: 1.1630\n",
            "Step [25340/80000], d_real_loss: 0.1256, d_mnist_loss: 0.0038, d_svhn_loss: 0.1218, d_fake_loss: 0.0999, g_loss: 1.1225\n",
            "Step [25350/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0392, d_svhn_loss: 0.0254, d_fake_loss: 0.0376, g_loss: 1.1049\n",
            "Step [25360/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0023, d_svhn_loss: 0.0231, d_fake_loss: 0.0280, g_loss: 1.2292\n",
            "Step [25370/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0014, d_svhn_loss: 0.0315, d_fake_loss: 0.0397, g_loss: 1.1905\n",
            "Step [25380/80000], d_real_loss: 0.0799, d_mnist_loss: 0.0142, d_svhn_loss: 0.0657, d_fake_loss: 0.0326, g_loss: 1.1534\n",
            "Step [25390/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0080, d_svhn_loss: 0.0351, d_fake_loss: 0.0309, g_loss: 1.1673\n",
            "Step [25400/80000], d_real_loss: 0.1150, d_mnist_loss: 0.0050, d_svhn_loss: 0.1100, d_fake_loss: 0.0759, g_loss: 1.0830\n",
            "Step [25410/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0034, d_svhn_loss: 0.0323, d_fake_loss: 0.0353, g_loss: 1.1134\n",
            "Step [25420/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0030, d_svhn_loss: 0.0267, d_fake_loss: 0.0440, g_loss: 1.1098\n",
            "Step [25430/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0121, d_svhn_loss: 0.0277, d_fake_loss: 0.0226, g_loss: 1.1974\n",
            "Step [25440/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0033, d_svhn_loss: 0.0707, d_fake_loss: 0.0892, g_loss: 1.1249\n",
            "Step [25450/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0023, d_svhn_loss: 0.0253, d_fake_loss: 0.0650, g_loss: 1.1183\n",
            "Step [25460/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0123, d_svhn_loss: 0.0169, d_fake_loss: 0.0660, g_loss: 1.0757\n",
            "Step [25470/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0016, d_svhn_loss: 0.0224, d_fake_loss: 0.0668, g_loss: 1.1343\n",
            "Step [25480/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0246, d_svhn_loss: 0.0451, d_fake_loss: 0.0372, g_loss: 1.2021\n",
            "Step [25490/80000], d_real_loss: 0.0759, d_mnist_loss: 0.0010, d_svhn_loss: 0.0749, d_fake_loss: 0.0419, g_loss: 1.2036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [25500/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0054, d_svhn_loss: 0.0317, d_fake_loss: 0.0752, g_loss: 1.1306\n",
            "saved ./samples_mnist_svhn/sample-25500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-25500-s-m.png\n",
            "Step [25510/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0095, d_svhn_loss: 0.0202, d_fake_loss: 0.0329, g_loss: 1.2172\n",
            "Step [25520/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0043, d_svhn_loss: 0.0529, d_fake_loss: 0.0403, g_loss: 1.3193\n",
            "Step [25530/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0013, d_svhn_loss: 0.0333, d_fake_loss: 0.1166, g_loss: 1.1437\n",
            "Step [25540/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0023, d_svhn_loss: 0.0483, d_fake_loss: 0.0409, g_loss: 1.1560\n",
            "Step [25550/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0069, d_svhn_loss: 0.0281, d_fake_loss: 0.0260, g_loss: 1.2295\n",
            "Step [25560/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0019, d_svhn_loss: 0.0699, d_fake_loss: 0.0373, g_loss: 1.1639\n",
            "Step [25570/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0022, d_svhn_loss: 0.0253, d_fake_loss: 0.0537, g_loss: 1.0970\n",
            "Step [25580/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0109, d_svhn_loss: 0.0284, d_fake_loss: 0.0426, g_loss: 1.1568\n",
            "Step [25590/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0180, d_svhn_loss: 0.0327, d_fake_loss: 0.0353, g_loss: 1.0469\n",
            "Step [25600/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0063, d_svhn_loss: 0.0282, d_fake_loss: 0.0342, g_loss: 1.1319\n",
            "Step [25610/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0041, d_svhn_loss: 0.0576, d_fake_loss: 0.0432, g_loss: 1.0573\n",
            "Step [25620/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0037, d_svhn_loss: 0.0331, d_fake_loss: 0.0509, g_loss: 1.1070\n",
            "Step [25630/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0053, d_svhn_loss: 0.0354, d_fake_loss: 0.0752, g_loss: 1.1395\n",
            "Step [25640/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0139, d_svhn_loss: 0.0687, d_fake_loss: 0.0238, g_loss: 1.2114\n",
            "Step [25650/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0152, d_svhn_loss: 0.0345, d_fake_loss: 0.0522, g_loss: 1.1600\n",
            "Step [25660/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0053, d_svhn_loss: 0.0301, d_fake_loss: 0.0361, g_loss: 1.2549\n",
            "Step [25670/80000], d_real_loss: 0.1582, d_mnist_loss: 0.0067, d_svhn_loss: 0.1514, d_fake_loss: 0.0665, g_loss: 1.1519\n",
            "Step [25680/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0016, d_svhn_loss: 0.0383, d_fake_loss: 0.0562, g_loss: 1.0856\n",
            "Step [25690/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0016, d_svhn_loss: 0.0668, d_fake_loss: 0.0293, g_loss: 1.1958\n",
            "Step [25700/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0033, d_svhn_loss: 0.0283, d_fake_loss: 0.0939, g_loss: 1.1251\n",
            "Step [25710/80000], d_real_loss: 0.0885, d_mnist_loss: 0.0074, d_svhn_loss: 0.0812, d_fake_loss: 0.0851, g_loss: 1.2761\n",
            "Step [25720/80000], d_real_loss: 0.0707, d_mnist_loss: 0.0072, d_svhn_loss: 0.0635, d_fake_loss: 0.0316, g_loss: 1.2357\n",
            "Step [25730/80000], d_real_loss: 0.2088, d_mnist_loss: 0.0013, d_svhn_loss: 0.2075, d_fake_loss: 0.0526, g_loss: 1.1705\n",
            "Step [25740/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0137, d_svhn_loss: 0.0223, d_fake_loss: 0.0369, g_loss: 1.1372\n",
            "Step [25750/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0044, d_svhn_loss: 0.0345, d_fake_loss: 0.0935, g_loss: 1.1533\n",
            "Step [25760/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0075, d_svhn_loss: 0.0342, d_fake_loss: 0.0422, g_loss: 1.2271\n",
            "Step [25770/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0038, d_svhn_loss: 0.0322, d_fake_loss: 0.0229, g_loss: 1.1495\n",
            "Step [25780/80000], d_real_loss: 0.0859, d_mnist_loss: 0.0234, d_svhn_loss: 0.0625, d_fake_loss: 0.0886, g_loss: 1.1425\n",
            "Step [25790/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0070, d_svhn_loss: 0.0233, d_fake_loss: 0.0292, g_loss: 1.0952\n",
            "Step [25800/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0135, d_svhn_loss: 0.0526, d_fake_loss: 0.0675, g_loss: 1.1956\n",
            "Step [25810/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0025, d_svhn_loss: 0.0226, d_fake_loss: 0.0268, g_loss: 1.1565\n",
            "Step [25820/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0109, d_svhn_loss: 0.0674, d_fake_loss: 0.1251, g_loss: 1.1532\n",
            "Step [25830/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0074, d_svhn_loss: 0.0664, d_fake_loss: 0.0500, g_loss: 1.1806\n",
            "Step [25840/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0033, d_svhn_loss: 0.0236, d_fake_loss: 0.0752, g_loss: 1.1099\n",
            "Step [25850/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0030, d_svhn_loss: 0.0676, d_fake_loss: 0.0308, g_loss: 1.1232\n",
            "Step [25860/80000], d_real_loss: 0.2164, d_mnist_loss: 0.0022, d_svhn_loss: 0.2143, d_fake_loss: 0.1038, g_loss: 1.0792\n",
            "Step [25870/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0025, d_svhn_loss: 0.0665, d_fake_loss: 0.0298, g_loss: 1.1851\n",
            "Step [25880/80000], d_real_loss: 0.1613, d_mnist_loss: 0.0014, d_svhn_loss: 0.1599, d_fake_loss: 0.1648, g_loss: 1.1808\n",
            "Step [25890/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0016, d_svhn_loss: 0.0283, d_fake_loss: 0.1256, g_loss: 1.1671\n",
            "Step [25900/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0036, d_svhn_loss: 0.0505, d_fake_loss: 0.0375, g_loss: 1.1484\n",
            "Step [25910/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0133, d_svhn_loss: 0.0332, d_fake_loss: 0.0223, g_loss: 1.0720\n",
            "Step [25920/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0043, d_svhn_loss: 0.0417, d_fake_loss: 0.0349, g_loss: 1.1232\n",
            "Step [25930/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0016, d_svhn_loss: 0.0285, d_fake_loss: 0.0338, g_loss: 1.1293\n",
            "Step [25940/80000], d_real_loss: 0.0919, d_mnist_loss: 0.0063, d_svhn_loss: 0.0856, d_fake_loss: 0.0297, g_loss: 1.1466\n",
            "Step [25950/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0012, d_svhn_loss: 0.0231, d_fake_loss: 0.0429, g_loss: 1.1358\n",
            "Step [25960/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0104, d_svhn_loss: 0.0167, d_fake_loss: 0.0261, g_loss: 1.1161\n",
            "Step [25970/80000], d_real_loss: 0.1363, d_mnist_loss: 0.0078, d_svhn_loss: 0.1285, d_fake_loss: 0.0924, g_loss: 1.2679\n",
            "Step [25980/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0147, d_svhn_loss: 0.0356, d_fake_loss: 0.0292, g_loss: 1.1238\n",
            "Step [25990/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0032, d_svhn_loss: 0.0469, d_fake_loss: 0.0245, g_loss: 1.1967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [26000/80000], d_real_loss: 0.0871, d_mnist_loss: 0.0043, d_svhn_loss: 0.0828, d_fake_loss: 0.0685, g_loss: 1.1541\n",
            "saved ./samples_mnist_svhn/sample-26000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-26000-s-m.png\n",
            "Step [26010/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0016, d_svhn_loss: 0.0574, d_fake_loss: 0.1647, g_loss: 1.0402\n",
            "Step [26020/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0017, d_svhn_loss: 0.0234, d_fake_loss: 0.0503, g_loss: 1.1013\n",
            "Step [26030/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0051, d_svhn_loss: 0.0397, d_fake_loss: 0.0334, g_loss: 1.0995\n",
            "Step [26040/80000], d_real_loss: 0.0798, d_mnist_loss: 0.0512, d_svhn_loss: 0.0286, d_fake_loss: 0.0496, g_loss: 1.1078\n",
            "Step [26050/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0049, d_svhn_loss: 0.0376, d_fake_loss: 0.0241, g_loss: 1.2359\n",
            "Step [26060/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0101, d_svhn_loss: 0.0344, d_fake_loss: 0.0547, g_loss: 1.1652\n",
            "Step [26070/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0017, d_svhn_loss: 0.0287, d_fake_loss: 0.0369, g_loss: 1.1398\n",
            "Step [26080/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0154, d_svhn_loss: 0.0230, d_fake_loss: 0.0306, g_loss: 1.1442\n",
            "Step [26090/80000], d_real_loss: 0.0962, d_mnist_loss: 0.0014, d_svhn_loss: 0.0948, d_fake_loss: 0.1328, g_loss: 1.1518\n",
            "Step [26100/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0148, d_svhn_loss: 0.0930, d_fake_loss: 0.0225, g_loss: 1.2487\n",
            "Step [26110/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0044, d_svhn_loss: 0.0240, d_fake_loss: 0.0247, g_loss: 1.1740\n",
            "Step [26120/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0032, d_svhn_loss: 0.0267, d_fake_loss: 0.0397, g_loss: 1.1601\n",
            "Step [26130/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0009, d_svhn_loss: 0.0512, d_fake_loss: 0.0966, g_loss: 1.1088\n",
            "Step [26140/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0034, d_svhn_loss: 0.0393, d_fake_loss: 0.0383, g_loss: 1.0936\n",
            "Step [26150/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0013, d_svhn_loss: 0.0596, d_fake_loss: 0.0539, g_loss: 1.3069\n",
            "Step [26160/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0113, d_svhn_loss: 0.0291, d_fake_loss: 0.0477, g_loss: 1.0376\n",
            "Step [26170/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0013, d_svhn_loss: 0.0705, d_fake_loss: 0.0456, g_loss: 1.2557\n",
            "Step [26180/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0022, d_svhn_loss: 0.0294, d_fake_loss: 0.0571, g_loss: 1.1794\n",
            "Step [26190/80000], d_real_loss: 0.0872, d_mnist_loss: 0.0127, d_svhn_loss: 0.0745, d_fake_loss: 0.0474, g_loss: 1.1701\n",
            "Step [26200/80000], d_real_loss: 0.0732, d_mnist_loss: 0.0010, d_svhn_loss: 0.0723, d_fake_loss: 0.0714, g_loss: 1.1151\n",
            "Step [26210/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0006, d_svhn_loss: 0.0453, d_fake_loss: 0.0352, g_loss: 1.0828\n",
            "Step [26220/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0018, d_svhn_loss: 0.0316, d_fake_loss: 0.0339, g_loss: 1.0990\n",
            "Step [26230/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0029, d_svhn_loss: 0.0688, d_fake_loss: 0.0294, g_loss: 1.0939\n",
            "Step [26240/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0109, d_svhn_loss: 0.0722, d_fake_loss: 0.0713, g_loss: 1.1233\n",
            "Step [26250/80000], d_real_loss: 0.1348, d_mnist_loss: 0.0016, d_svhn_loss: 0.1332, d_fake_loss: 0.0666, g_loss: 1.1485\n",
            "Step [26260/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0009, d_svhn_loss: 0.0520, d_fake_loss: 0.0257, g_loss: 1.1157\n",
            "Step [26270/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0021, d_svhn_loss: 0.0314, d_fake_loss: 0.0346, g_loss: 1.1369\n",
            "Step [26280/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0019, d_svhn_loss: 0.0470, d_fake_loss: 0.0246, g_loss: 1.1527\n",
            "Step [26290/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0015, d_svhn_loss: 0.0246, d_fake_loss: 0.1124, g_loss: 1.1727\n",
            "Step [26300/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0018, d_svhn_loss: 0.0619, d_fake_loss: 0.0475, g_loss: 1.1567\n",
            "Step [26310/80000], d_real_loss: 0.0781, d_mnist_loss: 0.0008, d_svhn_loss: 0.0773, d_fake_loss: 0.0432, g_loss: 1.1566\n",
            "Step [26320/80000], d_real_loss: 0.1039, d_mnist_loss: 0.0339, d_svhn_loss: 0.0701, d_fake_loss: 0.0715, g_loss: 1.4218\n",
            "Step [26330/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0021, d_svhn_loss: 0.0232, d_fake_loss: 0.0572, g_loss: 1.1027\n",
            "Step [26340/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0103, d_svhn_loss: 0.0214, d_fake_loss: 0.0488, g_loss: 1.1511\n",
            "Step [26350/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0014, d_svhn_loss: 0.0500, d_fake_loss: 0.0619, g_loss: 1.1514\n",
            "Step [26360/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0020, d_svhn_loss: 0.0218, d_fake_loss: 0.0272, g_loss: 1.1563\n",
            "Step [26370/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0024, d_svhn_loss: 0.0174, d_fake_loss: 0.0316, g_loss: 1.1218\n",
            "Step [26380/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0033, d_svhn_loss: 0.0189, d_fake_loss: 0.0735, g_loss: 1.4235\n",
            "Step [26390/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0029, d_svhn_loss: 0.0298, d_fake_loss: 0.0433, g_loss: 1.1061\n",
            "Step [26400/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0041, d_svhn_loss: 0.0211, d_fake_loss: 0.0435, g_loss: 0.9049\n",
            "Step [26410/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0056, d_svhn_loss: 0.0697, d_fake_loss: 0.1696, g_loss: 1.2060\n",
            "Step [26420/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0022, d_svhn_loss: 0.0721, d_fake_loss: 0.0373, g_loss: 1.0762\n",
            "Step [26430/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0032, d_svhn_loss: 0.0204, d_fake_loss: 0.0234, g_loss: 1.1951\n",
            "Step [26440/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0040, d_svhn_loss: 0.0199, d_fake_loss: 0.0728, g_loss: 1.1153\n",
            "Step [26450/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0086, d_svhn_loss: 0.0216, d_fake_loss: 0.0829, g_loss: 1.1304\n",
            "Step [26460/80000], d_real_loss: 0.1055, d_mnist_loss: 0.0022, d_svhn_loss: 0.1032, d_fake_loss: 0.0859, g_loss: 1.0852\n",
            "Step [26470/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0016, d_svhn_loss: 0.0178, d_fake_loss: 0.0355, g_loss: 1.2102\n",
            "Step [26480/80000], d_real_loss: 0.0945, d_mnist_loss: 0.0016, d_svhn_loss: 0.0929, d_fake_loss: 0.1344, g_loss: 1.1057\n",
            "Step [26490/80000], d_real_loss: 0.1302, d_mnist_loss: 0.0317, d_svhn_loss: 0.0985, d_fake_loss: 0.0367, g_loss: 0.9731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [26500/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0018, d_svhn_loss: 0.0374, d_fake_loss: 0.0228, g_loss: 1.1497\n",
            "saved ./samples_mnist_svhn/sample-26500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-26500-s-m.png\n",
            "Step [26510/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0105, d_svhn_loss: 0.0276, d_fake_loss: 0.0306, g_loss: 1.0926\n",
            "Step [26520/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0018, d_svhn_loss: 0.0358, d_fake_loss: 0.0323, g_loss: 1.0873\n",
            "Step [26530/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0101, d_svhn_loss: 0.0329, d_fake_loss: 0.0889, g_loss: 1.1743\n",
            "Step [26540/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0019, d_svhn_loss: 0.0278, d_fake_loss: 0.0236, g_loss: 1.1095\n",
            "Step [26550/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0078, d_svhn_loss: 0.0289, d_fake_loss: 0.0301, g_loss: 1.0636\n",
            "Step [26560/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0028, d_svhn_loss: 0.0367, d_fake_loss: 0.0272, g_loss: 1.1734\n",
            "Step [26570/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0019, d_svhn_loss: 0.0223, d_fake_loss: 0.1246, g_loss: 1.0917\n",
            "Step [26580/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0092, d_svhn_loss: 0.0369, d_fake_loss: 0.0708, g_loss: 1.2264\n",
            "Step [26590/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0022, d_svhn_loss: 0.0336, d_fake_loss: 0.0247, g_loss: 1.0770\n",
            "Step [26600/80000], d_real_loss: 0.0644, d_mnist_loss: 0.0011, d_svhn_loss: 0.0633, d_fake_loss: 0.0448, g_loss: 1.1366\n",
            "Step [26610/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0043, d_svhn_loss: 0.0243, d_fake_loss: 0.0216, g_loss: 1.1645\n",
            "Step [26620/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0124, d_svhn_loss: 0.0701, d_fake_loss: 0.0799, g_loss: 1.1247\n",
            "Step [26630/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0069, d_svhn_loss: 0.0463, d_fake_loss: 0.0801, g_loss: 1.1349\n",
            "Step [26640/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0125, d_svhn_loss: 0.0200, d_fake_loss: 0.0246, g_loss: 1.1499\n",
            "Step [26650/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0014, d_svhn_loss: 0.0226, d_fake_loss: 0.0423, g_loss: 1.1426\n",
            "Step [26660/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0132, d_svhn_loss: 0.0329, d_fake_loss: 0.0489, g_loss: 1.1615\n",
            "Step [26670/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0027, d_svhn_loss: 0.0434, d_fake_loss: 0.0270, g_loss: 1.1440\n",
            "Step [26680/80000], d_real_loss: 0.0847, d_mnist_loss: 0.0032, d_svhn_loss: 0.0814, d_fake_loss: 0.0491, g_loss: 1.0799\n",
            "Step [26690/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0023, d_svhn_loss: 0.0328, d_fake_loss: 0.0499, g_loss: 1.2021\n",
            "Step [26700/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0063, d_svhn_loss: 0.0272, d_fake_loss: 0.0334, g_loss: 1.1230\n",
            "Step [26710/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0022, d_svhn_loss: 0.0429, d_fake_loss: 0.0321, g_loss: 1.1308\n",
            "Step [26720/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0010, d_svhn_loss: 0.0292, d_fake_loss: 0.0868, g_loss: 1.1373\n",
            "Step [26730/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0027, d_svhn_loss: 0.0252, d_fake_loss: 0.0484, g_loss: 1.1785\n",
            "Step [26740/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0022, d_svhn_loss: 0.0526, d_fake_loss: 0.2463, g_loss: 1.0362\n",
            "Step [26750/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0018, d_svhn_loss: 0.0253, d_fake_loss: 0.0497, g_loss: 1.1513\n",
            "Step [26760/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0017, d_svhn_loss: 0.0314, d_fake_loss: 0.0382, g_loss: 1.1269\n",
            "Step [26770/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0072, d_svhn_loss: 0.0336, d_fake_loss: 0.0393, g_loss: 1.1386\n",
            "Step [26780/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0017, d_svhn_loss: 0.0642, d_fake_loss: 0.0335, g_loss: 1.0619\n",
            "Step [26790/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0023, d_svhn_loss: 0.0578, d_fake_loss: 0.0341, g_loss: 1.0937\n",
            "Step [26800/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0049, d_svhn_loss: 0.0269, d_fake_loss: 0.0423, g_loss: 1.2011\n",
            "Step [26810/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0008, d_svhn_loss: 0.0379, d_fake_loss: 0.1530, g_loss: 1.1002\n",
            "Step [26820/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0053, d_svhn_loss: 0.1025, d_fake_loss: 0.0553, g_loss: 1.1426\n",
            "Step [26830/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0108, d_svhn_loss: 0.0324, d_fake_loss: 0.0350, g_loss: 1.0576\n",
            "Step [26840/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0018, d_svhn_loss: 0.0423, d_fake_loss: 0.1936, g_loss: 1.1820\n",
            "Step [26850/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0063, d_svhn_loss: 0.0370, d_fake_loss: 0.0460, g_loss: 1.1311\n",
            "Step [26860/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0105, d_svhn_loss: 0.0253, d_fake_loss: 0.0226, g_loss: 1.1173\n",
            "Step [26870/80000], d_real_loss: 0.1441, d_mnist_loss: 0.0531, d_svhn_loss: 0.0909, d_fake_loss: 0.0969, g_loss: 1.0490\n",
            "Step [26880/80000], d_real_loss: 0.1108, d_mnist_loss: 0.0126, d_svhn_loss: 0.0982, d_fake_loss: 0.0351, g_loss: 1.0469\n",
            "Step [26890/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0122, d_svhn_loss: 0.0442, d_fake_loss: 0.0617, g_loss: 1.2008\n",
            "Step [26900/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0079, d_svhn_loss: 0.0264, d_fake_loss: 0.0475, g_loss: 1.3418\n",
            "Step [26910/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0057, d_svhn_loss: 0.0233, d_fake_loss: 0.1213, g_loss: 0.9884\n",
            "Step [26920/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0057, d_svhn_loss: 0.0312, d_fake_loss: 0.0420, g_loss: 1.1184\n",
            "Step [26930/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0075, d_svhn_loss: 0.0313, d_fake_loss: 0.0445, g_loss: 1.1521\n",
            "Step [26940/80000], d_real_loss: 0.1053, d_mnist_loss: 0.0029, d_svhn_loss: 0.1024, d_fake_loss: 0.0609, g_loss: 1.1506\n",
            "Step [26950/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0026, d_svhn_loss: 0.0291, d_fake_loss: 0.0443, g_loss: 1.2046\n",
            "Step [26960/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0059, d_svhn_loss: 0.0340, d_fake_loss: 0.0524, g_loss: 1.1435\n",
            "Step [26970/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0029, d_svhn_loss: 0.0588, d_fake_loss: 0.0609, g_loss: 1.2031\n",
            "Step [26980/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0036, d_svhn_loss: 0.0264, d_fake_loss: 0.0444, g_loss: 1.1402\n",
            "Step [26990/80000], d_real_loss: 0.1670, d_mnist_loss: 0.0078, d_svhn_loss: 0.1591, d_fake_loss: 0.0649, g_loss: 1.1438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [27000/80000], d_real_loss: 0.1234, d_mnist_loss: 0.0046, d_svhn_loss: 0.1188, d_fake_loss: 0.0951, g_loss: 1.1910\n",
            "saved ./samples_mnist_svhn/sample-27000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-27000-s-m.png\n",
            "Step [27010/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0017, d_svhn_loss: 0.0263, d_fake_loss: 0.0618, g_loss: 1.1421\n",
            "Step [27020/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0041, d_svhn_loss: 0.0327, d_fake_loss: 0.0623, g_loss: 1.1841\n",
            "Step [27030/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0149, d_svhn_loss: 0.0288, d_fake_loss: 0.0615, g_loss: 1.0813\n",
            "Step [27040/80000], d_real_loss: 0.2421, d_mnist_loss: 0.0121, d_svhn_loss: 0.2300, d_fake_loss: 0.0618, g_loss: 1.1851\n",
            "Step [27050/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0034, d_svhn_loss: 0.0535, d_fake_loss: 0.0509, g_loss: 1.1407\n",
            "Step [27060/80000], d_real_loss: 0.1037, d_mnist_loss: 0.0016, d_svhn_loss: 0.1021, d_fake_loss: 0.0432, g_loss: 1.2152\n",
            "Step [27070/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0009, d_svhn_loss: 0.0472, d_fake_loss: 0.0608, g_loss: 1.2171\n",
            "Step [27080/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0115, d_svhn_loss: 0.0272, d_fake_loss: 0.0401, g_loss: 1.1464\n",
            "Step [27090/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0020, d_svhn_loss: 0.0311, d_fake_loss: 0.0276, g_loss: 1.1556\n",
            "Step [27100/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0065, d_svhn_loss: 0.0745, d_fake_loss: 0.1469, g_loss: 1.0849\n",
            "Step [27110/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0014, d_svhn_loss: 0.0432, d_fake_loss: 0.0561, g_loss: 1.1640\n",
            "Step [27120/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0071, d_svhn_loss: 0.0323, d_fake_loss: 0.0435, g_loss: 1.1250\n",
            "Step [27130/80000], d_real_loss: 0.2912, d_mnist_loss: 0.0304, d_svhn_loss: 0.2608, d_fake_loss: 0.0257, g_loss: 1.0161\n",
            "Step [27140/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0017, d_svhn_loss: 0.0222, d_fake_loss: 0.0282, g_loss: 1.1214\n",
            "Step [27150/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0031, d_svhn_loss: 0.0325, d_fake_loss: 0.0434, g_loss: 1.2758\n",
            "Step [27160/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0018, d_svhn_loss: 0.0275, d_fake_loss: 0.0342, g_loss: 1.1267\n",
            "Step [27170/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0015, d_svhn_loss: 0.0201, d_fake_loss: 0.0426, g_loss: 1.1057\n",
            "Step [27180/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0020, d_svhn_loss: 0.0322, d_fake_loss: 0.0396, g_loss: 1.1755\n",
            "Step [27190/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0069, d_svhn_loss: 0.0275, d_fake_loss: 0.0243, g_loss: 1.1598\n",
            "Step [27200/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0058, d_svhn_loss: 0.0425, d_fake_loss: 0.0295, g_loss: 1.1242\n",
            "Step [27210/80000], d_real_loss: 0.1495, d_mnist_loss: 0.0117, d_svhn_loss: 0.1378, d_fake_loss: 0.0582, g_loss: 1.1250\n",
            "Step [27220/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0014, d_svhn_loss: 0.0245, d_fake_loss: 0.0147, g_loss: 1.1337\n",
            "Step [27230/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0058, d_svhn_loss: 0.0431, d_fake_loss: 0.0317, g_loss: 1.2280\n",
            "Step [27240/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0014, d_svhn_loss: 0.0249, d_fake_loss: 0.0327, g_loss: 1.1703\n",
            "Step [27250/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0028, d_svhn_loss: 0.0346, d_fake_loss: 0.0586, g_loss: 1.2569\n",
            "Step [27260/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0301, d_svhn_loss: 0.0283, d_fake_loss: 0.0204, g_loss: 1.1767\n",
            "Step [27270/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0014, d_svhn_loss: 0.0433, d_fake_loss: 0.0196, g_loss: 1.1044\n",
            "Step [27280/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0012, d_svhn_loss: 0.0430, d_fake_loss: 0.0275, g_loss: 1.2295\n",
            "Step [27290/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0037, d_svhn_loss: 0.0469, d_fake_loss: 0.0583, g_loss: 1.1307\n",
            "Step [27300/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0145, d_svhn_loss: 0.0312, d_fake_loss: 0.1810, g_loss: 1.1482\n",
            "Step [27310/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0064, d_svhn_loss: 0.0582, d_fake_loss: 0.1402, g_loss: 1.2137\n",
            "Step [27320/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0086, d_svhn_loss: 0.0325, d_fake_loss: 0.0276, g_loss: 1.0546\n",
            "Step [27330/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0111, d_svhn_loss: 0.0313, d_fake_loss: 0.0325, g_loss: 1.0575\n",
            "Step [27340/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0010, d_svhn_loss: 0.0584, d_fake_loss: 0.0397, g_loss: 1.1534\n",
            "Step [27350/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0016, d_svhn_loss: 0.0220, d_fake_loss: 0.0288, g_loss: 1.2453\n",
            "Step [27360/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0021, d_svhn_loss: 0.0226, d_fake_loss: 0.0264, g_loss: 1.0897\n",
            "Step [27370/80000], d_real_loss: 0.0976, d_mnist_loss: 0.0186, d_svhn_loss: 0.0790, d_fake_loss: 0.0745, g_loss: 1.0338\n",
            "Step [27380/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0023, d_svhn_loss: 0.0428, d_fake_loss: 0.0392, g_loss: 1.1008\n",
            "Step [27390/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0033, d_svhn_loss: 0.0302, d_fake_loss: 0.0657, g_loss: 1.1137\n",
            "Step [27400/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0041, d_svhn_loss: 0.0374, d_fake_loss: 0.0752, g_loss: 1.2962\n",
            "Step [27410/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0046, d_svhn_loss: 0.0425, d_fake_loss: 0.0542, g_loss: 1.2744\n",
            "Step [27420/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0012, d_svhn_loss: 0.0358, d_fake_loss: 0.0180, g_loss: 1.1264\n",
            "Step [27430/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0053, d_svhn_loss: 0.0264, d_fake_loss: 0.0365, g_loss: 1.1784\n",
            "Step [27440/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0047, d_svhn_loss: 0.0290, d_fake_loss: 0.0263, g_loss: 1.1744\n",
            "Step [27450/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0029, d_svhn_loss: 0.0366, d_fake_loss: 0.1122, g_loss: 1.1334\n",
            "Step [27460/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0104, d_svhn_loss: 0.0247, d_fake_loss: 0.0344, g_loss: 1.1627\n",
            "Step [27470/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0056, d_svhn_loss: 0.0474, d_fake_loss: 0.0320, g_loss: 1.2784\n",
            "Step [27480/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0042, d_svhn_loss: 0.0606, d_fake_loss: 0.0384, g_loss: 1.2233\n",
            "Step [27490/80000], d_real_loss: 0.1557, d_mnist_loss: 0.0116, d_svhn_loss: 0.1441, d_fake_loss: 0.0400, g_loss: 1.2067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [27500/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0099, d_svhn_loss: 0.0322, d_fake_loss: 0.1438, g_loss: 1.8422\n",
            "saved ./samples_mnist_svhn/sample-27500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-27500-s-m.png\n",
            "Step [27510/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0161, d_svhn_loss: 0.0288, d_fake_loss: 0.0562, g_loss: 1.1856\n",
            "Step [27520/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0141, d_svhn_loss: 0.0227, d_fake_loss: 0.0484, g_loss: 1.1387\n",
            "Step [27530/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0208, d_svhn_loss: 0.0365, d_fake_loss: 0.0501, g_loss: 1.1116\n",
            "Step [27540/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0027, d_svhn_loss: 0.0394, d_fake_loss: 0.0310, g_loss: 1.2563\n",
            "Step [27550/80000], d_real_loss: 0.1361, d_mnist_loss: 0.0016, d_svhn_loss: 0.1345, d_fake_loss: 0.0286, g_loss: 1.0406\n",
            "Step [27560/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0068, d_svhn_loss: 0.0468, d_fake_loss: 0.0347, g_loss: 1.1909\n",
            "Step [27570/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0138, d_svhn_loss: 0.0359, d_fake_loss: 0.0846, g_loss: 1.1990\n",
            "Step [27580/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0231, d_svhn_loss: 0.0687, d_fake_loss: 0.0233, g_loss: 1.0236\n",
            "Step [27590/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0032, d_svhn_loss: 0.0326, d_fake_loss: 0.0407, g_loss: 1.1447\n",
            "Step [27600/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0174, d_svhn_loss: 0.0630, d_fake_loss: 0.0813, g_loss: 1.0910\n",
            "Step [27610/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0041, d_svhn_loss: 0.0399, d_fake_loss: 0.0463, g_loss: 1.0738\n",
            "Step [27620/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0016, d_svhn_loss: 0.0667, d_fake_loss: 0.0979, g_loss: 1.1333\n",
            "Step [27630/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0046, d_svhn_loss: 0.0531, d_fake_loss: 0.0462, g_loss: 1.1362\n",
            "Step [27640/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0039, d_svhn_loss: 0.0349, d_fake_loss: 0.0816, g_loss: 1.1934\n",
            "Step [27650/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0014, d_svhn_loss: 0.0178, d_fake_loss: 0.0495, g_loss: 1.0830\n",
            "Step [27660/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0006, d_svhn_loss: 0.0327, d_fake_loss: 0.0521, g_loss: 1.1513\n",
            "Step [27670/80000], d_real_loss: 0.0861, d_mnist_loss: 0.0021, d_svhn_loss: 0.0840, d_fake_loss: 0.0175, g_loss: 1.1363\n",
            "Step [27680/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0022, d_svhn_loss: 0.0293, d_fake_loss: 0.0378, g_loss: 1.1277\n",
            "Step [27690/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0016, d_svhn_loss: 0.0501, d_fake_loss: 0.3303, g_loss: 1.1233\n",
            "Step [27700/80000], d_real_loss: 0.0897, d_mnist_loss: 0.0018, d_svhn_loss: 0.0880, d_fake_loss: 0.0265, g_loss: 1.1990\n",
            "Step [27710/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0016, d_svhn_loss: 0.0361, d_fake_loss: 0.0294, g_loss: 1.1850\n",
            "Step [27720/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0007, d_svhn_loss: 0.0286, d_fake_loss: 0.1202, g_loss: 1.1254\n",
            "Step [27730/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0021, d_svhn_loss: 0.0324, d_fake_loss: 0.0381, g_loss: 1.0747\n",
            "Step [27740/80000], d_real_loss: 0.0874, d_mnist_loss: 0.0010, d_svhn_loss: 0.0864, d_fake_loss: 0.0504, g_loss: 1.1277\n",
            "Step [27750/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0017, d_svhn_loss: 0.0287, d_fake_loss: 0.0801, g_loss: 1.1436\n",
            "Step [27760/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0008, d_svhn_loss: 0.0327, d_fake_loss: 0.0363, g_loss: 1.0988\n",
            "Step [27770/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0024, d_svhn_loss: 0.0359, d_fake_loss: 0.0237, g_loss: 1.1132\n",
            "Step [27780/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0214, d_svhn_loss: 0.0319, d_fake_loss: 0.0267, g_loss: 1.0183\n",
            "Step [27790/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0022, d_svhn_loss: 0.0188, d_fake_loss: 0.0485, g_loss: 1.1441\n",
            "Step [27800/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0047, d_svhn_loss: 0.0265, d_fake_loss: 0.0221, g_loss: 1.1457\n",
            "Step [27810/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0051, d_svhn_loss: 0.0231, d_fake_loss: 0.0296, g_loss: 1.2163\n",
            "Step [27820/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0019, d_svhn_loss: 0.0310, d_fake_loss: 0.1079, g_loss: 1.1425\n",
            "Step [27830/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0052, d_svhn_loss: 0.0468, d_fake_loss: 0.0814, g_loss: 1.1411\n",
            "Step [27840/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0021, d_svhn_loss: 0.0342, d_fake_loss: 0.0439, g_loss: 1.0466\n",
            "Step [27850/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0008, d_svhn_loss: 0.0639, d_fake_loss: 0.0370, g_loss: 1.1496\n",
            "Step [27860/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0107, d_svhn_loss: 0.0223, d_fake_loss: 0.0435, g_loss: 1.2367\n",
            "Step [27870/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0026, d_svhn_loss: 0.0739, d_fake_loss: 0.0402, g_loss: 1.1150\n",
            "Step [27880/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0009, d_svhn_loss: 0.0209, d_fake_loss: 0.0619, g_loss: 1.1035\n",
            "Step [27890/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0051, d_svhn_loss: 0.0597, d_fake_loss: 0.0666, g_loss: 1.0795\n",
            "Step [27900/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0051, d_svhn_loss: 0.0335, d_fake_loss: 0.0535, g_loss: 1.3392\n",
            "Step [27910/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0083, d_svhn_loss: 0.0214, d_fake_loss: 0.0321, g_loss: 1.2243\n",
            "Step [27920/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0038, d_svhn_loss: 0.0601, d_fake_loss: 0.0972, g_loss: 1.1579\n",
            "Step [27930/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0012, d_svhn_loss: 0.0264, d_fake_loss: 0.0348, g_loss: 1.1377\n",
            "Step [27940/80000], d_real_loss: 0.3120, d_mnist_loss: 0.0015, d_svhn_loss: 0.3105, d_fake_loss: 0.0611, g_loss: 1.1358\n",
            "Step [27950/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0032, d_svhn_loss: 0.0307, d_fake_loss: 0.0298, g_loss: 1.1199\n",
            "Step [27960/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0074, d_svhn_loss: 0.0245, d_fake_loss: 0.0601, g_loss: 1.1685\n",
            "Step [27970/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0016, d_svhn_loss: 0.0302, d_fake_loss: 0.0817, g_loss: 1.1362\n",
            "Step [27980/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0046, d_svhn_loss: 0.0511, d_fake_loss: 0.0589, g_loss: 1.6495\n",
            "Step [27990/80000], d_real_loss: 0.0896, d_mnist_loss: 0.0345, d_svhn_loss: 0.0551, d_fake_loss: 0.1504, g_loss: 1.3460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [28000/80000], d_real_loss: 0.0985, d_mnist_loss: 0.0067, d_svhn_loss: 0.0919, d_fake_loss: 0.0563, g_loss: 1.2096\n",
            "saved ./samples_mnist_svhn/sample-28000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-28000-s-m.png\n",
            "Step [28010/80000], d_real_loss: 0.1062, d_mnist_loss: 0.0051, d_svhn_loss: 0.1011, d_fake_loss: 0.1240, g_loss: 1.0878\n",
            "Step [28020/80000], d_real_loss: 0.0759, d_mnist_loss: 0.0015, d_svhn_loss: 0.0744, d_fake_loss: 0.1501, g_loss: 1.0859\n",
            "Step [28030/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0013, d_svhn_loss: 0.0252, d_fake_loss: 0.0239, g_loss: 1.0803\n",
            "Step [28040/80000], d_real_loss: 0.2186, d_mnist_loss: 0.0251, d_svhn_loss: 0.1934, d_fake_loss: 0.0899, g_loss: 1.2129\n",
            "Step [28050/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0032, d_svhn_loss: 0.0217, d_fake_loss: 0.0376, g_loss: 1.0961\n",
            "Step [28060/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0094, d_svhn_loss: 0.0163, d_fake_loss: 0.0308, g_loss: 1.1061\n",
            "Step [28070/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0012, d_svhn_loss: 0.0254, d_fake_loss: 0.0241, g_loss: 1.0922\n",
            "Step [28080/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0010, d_svhn_loss: 0.0303, d_fake_loss: 0.0367, g_loss: 1.0881\n",
            "Step [28090/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0013, d_svhn_loss: 0.0400, d_fake_loss: 0.0487, g_loss: 1.2133\n",
            "Step [28100/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0063, d_svhn_loss: 0.0310, d_fake_loss: 0.0351, g_loss: 1.1346\n",
            "Step [28110/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0100, d_svhn_loss: 0.0321, d_fake_loss: 0.0402, g_loss: 1.1653\n",
            "Step [28120/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0027, d_svhn_loss: 0.0242, d_fake_loss: 0.0473, g_loss: 1.1113\n",
            "Step [28130/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0010, d_svhn_loss: 0.0743, d_fake_loss: 0.0267, g_loss: 1.1633\n",
            "Step [28140/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0105, d_svhn_loss: 0.0520, d_fake_loss: 0.0253, g_loss: 1.2061\n",
            "Step [28150/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0012, d_svhn_loss: 0.0206, d_fake_loss: 0.0308, g_loss: 1.1191\n",
            "Step [28160/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0011, d_svhn_loss: 0.0277, d_fake_loss: 0.0261, g_loss: 1.1610\n",
            "Step [28170/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0012, d_svhn_loss: 0.0345, d_fake_loss: 0.0381, g_loss: 1.1471\n",
            "Step [28180/80000], d_real_loss: 0.1325, d_mnist_loss: 0.0082, d_svhn_loss: 0.1243, d_fake_loss: 0.0323, g_loss: 1.1113\n",
            "Step [28190/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0006, d_svhn_loss: 0.0276, d_fake_loss: 0.0510, g_loss: 1.1419\n",
            "Step [28200/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0022, d_svhn_loss: 0.0444, d_fake_loss: 0.0305, g_loss: 1.1049\n",
            "Step [28210/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0133, d_svhn_loss: 0.0761, d_fake_loss: 0.1051, g_loss: 1.0446\n",
            "Step [28220/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0009, d_svhn_loss: 0.0314, d_fake_loss: 0.0352, g_loss: 1.1320\n",
            "Step [28230/80000], d_real_loss: 0.1739, d_mnist_loss: 0.0219, d_svhn_loss: 0.1520, d_fake_loss: 0.1033, g_loss: 1.2246\n",
            "Step [28240/80000], d_real_loss: 0.0976, d_mnist_loss: 0.0010, d_svhn_loss: 0.0966, d_fake_loss: 0.0702, g_loss: 1.0724\n",
            "Step [28250/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0009, d_svhn_loss: 0.0320, d_fake_loss: 0.0514, g_loss: 1.1836\n",
            "Step [28260/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0016, d_svhn_loss: 0.0255, d_fake_loss: 0.0181, g_loss: 1.1842\n",
            "Step [28270/80000], d_real_loss: 0.1194, d_mnist_loss: 0.0197, d_svhn_loss: 0.0997, d_fake_loss: 0.1451, g_loss: 1.0056\n",
            "Step [28280/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0039, d_svhn_loss: 0.0343, d_fake_loss: 0.0225, g_loss: 1.1343\n",
            "Step [28290/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0019, d_svhn_loss: 0.0492, d_fake_loss: 0.0530, g_loss: 1.1189\n",
            "Step [28300/80000], d_real_loss: 0.0983, d_mnist_loss: 0.0021, d_svhn_loss: 0.0962, d_fake_loss: 0.0843, g_loss: 1.1737\n",
            "Step [28310/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0135, d_svhn_loss: 0.0435, d_fake_loss: 0.0425, g_loss: 1.2712\n",
            "Step [28320/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0039, d_svhn_loss: 0.0211, d_fake_loss: 0.0729, g_loss: 1.0799\n",
            "Step [28330/80000], d_real_loss: 0.0881, d_mnist_loss: 0.0043, d_svhn_loss: 0.0838, d_fake_loss: 0.0703, g_loss: 1.5434\n",
            "Step [28340/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0021, d_svhn_loss: 0.0486, d_fake_loss: 0.0297, g_loss: 1.3044\n",
            "Step [28350/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0015, d_svhn_loss: 0.0378, d_fake_loss: 0.0208, g_loss: 1.1641\n",
            "Step [28360/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0020, d_svhn_loss: 0.0501, d_fake_loss: 0.0557, g_loss: 1.1382\n",
            "Step [28370/80000], d_real_loss: 0.2207, d_mnist_loss: 0.0094, d_svhn_loss: 0.2113, d_fake_loss: 0.0515, g_loss: 1.1096\n",
            "Step [28380/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0201, d_svhn_loss: 0.0570, d_fake_loss: 0.0376, g_loss: 1.0394\n",
            "Step [28390/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0048, d_svhn_loss: 0.0414, d_fake_loss: 0.1070, g_loss: 1.1507\n",
            "Step [28400/80000], d_real_loss: 0.0927, d_mnist_loss: 0.0013, d_svhn_loss: 0.0914, d_fake_loss: 0.1506, g_loss: 1.1145\n",
            "Step [28410/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0020, d_svhn_loss: 0.0201, d_fake_loss: 0.0293, g_loss: 1.1741\n",
            "Step [28420/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0063, d_svhn_loss: 0.0364, d_fake_loss: 0.2880, g_loss: 1.0832\n",
            "Step [28430/80000], d_real_loss: 0.1949, d_mnist_loss: 0.0039, d_svhn_loss: 0.1909, d_fake_loss: 0.1046, g_loss: 1.1289\n",
            "Step [28440/80000], d_real_loss: 0.0889, d_mnist_loss: 0.0171, d_svhn_loss: 0.0718, d_fake_loss: 0.0339, g_loss: 1.1871\n",
            "Step [28450/80000], d_real_loss: 0.0705, d_mnist_loss: 0.0217, d_svhn_loss: 0.0489, d_fake_loss: 0.0558, g_loss: 1.1002\n",
            "Step [28460/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0028, d_svhn_loss: 0.0344, d_fake_loss: 0.1060, g_loss: 1.1286\n",
            "Step [28470/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0093, d_svhn_loss: 0.0474, d_fake_loss: 0.0291, g_loss: 1.1403\n",
            "Step [28480/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0028, d_svhn_loss: 0.0303, d_fake_loss: 0.0624, g_loss: 1.0967\n",
            "Step [28490/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0036, d_svhn_loss: 0.0220, d_fake_loss: 0.0322, g_loss: 1.1501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [28500/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0008, d_svhn_loss: 0.0561, d_fake_loss: 0.0274, g_loss: 1.1150\n",
            "saved ./samples_mnist_svhn/sample-28500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-28500-s-m.png\n",
            "Step [28510/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0039, d_svhn_loss: 0.0364, d_fake_loss: 0.0600, g_loss: 1.2641\n",
            "Step [28520/80000], d_real_loss: 0.1967, d_mnist_loss: 0.0172, d_svhn_loss: 0.1796, d_fake_loss: 0.0706, g_loss: 1.2550\n",
            "Step [28530/80000], d_real_loss: 0.0994, d_mnist_loss: 0.0659, d_svhn_loss: 0.0334, d_fake_loss: 0.0254, g_loss: 1.2454\n",
            "Step [28540/80000], d_real_loss: 0.1834, d_mnist_loss: 0.0022, d_svhn_loss: 0.1811, d_fake_loss: 0.0408, g_loss: 1.0280\n",
            "Step [28550/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0158, d_svhn_loss: 0.0347, d_fake_loss: 0.0390, g_loss: 1.1854\n",
            "Step [28560/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0057, d_svhn_loss: 0.0264, d_fake_loss: 0.0612, g_loss: 1.0151\n",
            "Step [28570/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0121, d_svhn_loss: 0.0406, d_fake_loss: 0.0860, g_loss: 1.2295\n",
            "Step [28580/80000], d_real_loss: 0.1286, d_mnist_loss: 0.0020, d_svhn_loss: 0.1266, d_fake_loss: 0.0372, g_loss: 1.0629\n",
            "Step [28590/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0093, d_svhn_loss: 0.0451, d_fake_loss: 0.0728, g_loss: 1.0881\n",
            "Step [28600/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0009, d_svhn_loss: 0.0594, d_fake_loss: 0.0198, g_loss: 1.0913\n",
            "Step [28610/80000], d_real_loss: 0.1263, d_mnist_loss: 0.0039, d_svhn_loss: 0.1225, d_fake_loss: 0.0600, g_loss: 1.0691\n",
            "Step [28620/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0018, d_svhn_loss: 0.0408, d_fake_loss: 0.0235, g_loss: 1.1404\n",
            "Step [28630/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0019, d_svhn_loss: 0.0342, d_fake_loss: 0.0173, g_loss: 1.0804\n",
            "Step [28640/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0024, d_svhn_loss: 0.0388, d_fake_loss: 0.0259, g_loss: 1.1453\n",
            "Step [28650/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0056, d_svhn_loss: 0.0507, d_fake_loss: 0.0379, g_loss: 1.1762\n",
            "Step [28660/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0022, d_svhn_loss: 0.0332, d_fake_loss: 0.0271, g_loss: 1.1346\n",
            "Step [28670/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0009, d_svhn_loss: 0.0185, d_fake_loss: 0.0722, g_loss: 1.1256\n",
            "Step [28680/80000], d_real_loss: 0.1017, d_mnist_loss: 0.0034, d_svhn_loss: 0.0982, d_fake_loss: 0.0415, g_loss: 1.1530\n",
            "Step [28690/80000], d_real_loss: 0.0992, d_mnist_loss: 0.0024, d_svhn_loss: 0.0968, d_fake_loss: 0.0330, g_loss: 1.1409\n",
            "Step [28700/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0073, d_svhn_loss: 0.0569, d_fake_loss: 0.1015, g_loss: 1.1392\n",
            "Step [28710/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0060, d_svhn_loss: 0.0241, d_fake_loss: 0.0431, g_loss: 1.2034\n",
            "Step [28720/80000], d_real_loss: 0.1441, d_mnist_loss: 0.0024, d_svhn_loss: 0.1418, d_fake_loss: 0.0368, g_loss: 1.1517\n",
            "Step [28730/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0101, d_svhn_loss: 0.0495, d_fake_loss: 0.0330, g_loss: 1.2787\n",
            "Step [28740/80000], d_real_loss: 0.0996, d_mnist_loss: 0.0040, d_svhn_loss: 0.0956, d_fake_loss: 0.0304, g_loss: 1.1116\n",
            "Step [28750/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0059, d_svhn_loss: 0.0293, d_fake_loss: 0.0784, g_loss: 1.1311\n",
            "Step [28760/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0030, d_svhn_loss: 0.0290, d_fake_loss: 0.0783, g_loss: 1.0389\n",
            "Step [28770/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0010, d_svhn_loss: 0.0227, d_fake_loss: 0.0250, g_loss: 1.0727\n",
            "Step [28780/80000], d_real_loss: 0.1211, d_mnist_loss: 0.0013, d_svhn_loss: 0.1198, d_fake_loss: 0.0428, g_loss: 1.1277\n",
            "Step [28790/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0016, d_svhn_loss: 0.0236, d_fake_loss: 0.0291, g_loss: 1.1019\n",
            "Step [28800/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0009, d_svhn_loss: 0.0398, d_fake_loss: 0.0173, g_loss: 1.1556\n",
            "Step [28810/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0020, d_svhn_loss: 0.0404, d_fake_loss: 0.0364, g_loss: 1.0850\n",
            "Step [28820/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0211, d_svhn_loss: 0.0296, d_fake_loss: 0.0260, g_loss: 1.1730\n",
            "Step [28830/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0020, d_svhn_loss: 0.0234, d_fake_loss: 0.0521, g_loss: 1.0748\n",
            "Step [28840/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0051, d_svhn_loss: 0.0323, d_fake_loss: 0.0369, g_loss: 1.1207\n",
            "Step [28850/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0016, d_svhn_loss: 0.0322, d_fake_loss: 0.0343, g_loss: 1.1182\n",
            "Step [28860/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0210, d_svhn_loss: 0.0413, d_fake_loss: 0.0523, g_loss: 1.5046\n",
            "Step [28870/80000], d_real_loss: 0.2451, d_mnist_loss: 0.2033, d_svhn_loss: 0.0417, d_fake_loss: 0.2413, g_loss: 1.2189\n",
            "Step [28880/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0212, d_svhn_loss: 0.0617, d_fake_loss: 0.0368, g_loss: 1.2033\n",
            "Step [28890/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0210, d_svhn_loss: 0.0219, d_fake_loss: 0.0350, g_loss: 1.0664\n",
            "Step [28900/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0038, d_svhn_loss: 0.0249, d_fake_loss: 0.0283, g_loss: 1.1493\n",
            "Step [28910/80000], d_real_loss: 0.1684, d_mnist_loss: 0.0128, d_svhn_loss: 0.1556, d_fake_loss: 0.0536, g_loss: 1.0690\n",
            "Step [28920/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0106, d_svhn_loss: 0.0328, d_fake_loss: 0.0485, g_loss: 1.2037\n",
            "Step [28930/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0019, d_svhn_loss: 0.0513, d_fake_loss: 0.0572, g_loss: 1.1077\n",
            "Step [28940/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0130, d_svhn_loss: 0.0333, d_fake_loss: 0.0344, g_loss: 1.2118\n",
            "Step [28950/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0032, d_svhn_loss: 0.0219, d_fake_loss: 0.0308, g_loss: 1.1278\n",
            "Step [28960/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0014, d_svhn_loss: 0.0369, d_fake_loss: 0.3855, g_loss: 1.1342\n",
            "Step [28970/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0100, d_svhn_loss: 0.0312, d_fake_loss: 0.1048, g_loss: 1.1649\n",
            "Step [28980/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0127, d_svhn_loss: 0.0237, d_fake_loss: 0.0160, g_loss: 1.1205\n",
            "Step [28990/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0025, d_svhn_loss: 0.0256, d_fake_loss: 0.0174, g_loss: 1.1835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [29000/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0124, d_svhn_loss: 0.0443, d_fake_loss: 0.0180, g_loss: 1.2118\n",
            "saved ./samples_mnist_svhn/sample-29000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-29000-s-m.png\n",
            "Step [29010/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0035, d_svhn_loss: 0.0316, d_fake_loss: 0.0497, g_loss: 1.1450\n",
            "Step [29020/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0012, d_svhn_loss: 0.0565, d_fake_loss: 0.0394, g_loss: 1.0709\n",
            "Step [29030/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0176, d_svhn_loss: 0.0208, d_fake_loss: 0.0616, g_loss: 1.1428\n",
            "Step [29040/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0071, d_svhn_loss: 0.0396, d_fake_loss: 0.0589, g_loss: 1.1241\n",
            "Step [29050/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0020, d_svhn_loss: 0.0442, d_fake_loss: 0.0218, g_loss: 1.1319\n",
            "Step [29060/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0007, d_svhn_loss: 0.0645, d_fake_loss: 0.0239, g_loss: 1.2460\n",
            "Step [29070/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0019, d_svhn_loss: 0.0265, d_fake_loss: 0.0257, g_loss: 1.1105\n",
            "Step [29080/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0020, d_svhn_loss: 0.0539, d_fake_loss: 0.1502, g_loss: 1.1722\n",
            "Step [29090/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0018, d_svhn_loss: 0.0182, d_fake_loss: 0.0341, g_loss: 1.1333\n",
            "Step [29100/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0051, d_svhn_loss: 0.0323, d_fake_loss: 0.0326, g_loss: 1.1181\n",
            "Step [29110/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0243, d_svhn_loss: 0.0340, d_fake_loss: 0.0287, g_loss: 1.1388\n",
            "Step [29120/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0019, d_svhn_loss: 0.0352, d_fake_loss: 0.0257, g_loss: 1.1871\n",
            "Step [29130/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0017, d_svhn_loss: 0.0240, d_fake_loss: 0.0222, g_loss: 1.0979\n",
            "Step [29140/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0111, d_svhn_loss: 0.0250, d_fake_loss: 0.1514, g_loss: 1.0865\n",
            "Step [29150/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0101, d_svhn_loss: 0.0420, d_fake_loss: 0.1011, g_loss: 1.1453\n",
            "Step [29160/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0041, d_svhn_loss: 0.0310, d_fake_loss: 0.0983, g_loss: 1.2066\n",
            "Step [29170/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0019, d_svhn_loss: 0.0224, d_fake_loss: 0.0244, g_loss: 1.1678\n",
            "Step [29180/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0016, d_svhn_loss: 0.0588, d_fake_loss: 0.0198, g_loss: 1.0848\n",
            "Step [29190/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0020, d_svhn_loss: 0.0742, d_fake_loss: 0.0906, g_loss: 1.1188\n",
            "Step [29200/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0054, d_svhn_loss: 0.0279, d_fake_loss: 0.0317, g_loss: 1.0953\n",
            "Step [29210/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0010, d_svhn_loss: 0.0197, d_fake_loss: 0.3597, g_loss: 1.0969\n",
            "Step [29220/80000], d_real_loss: 0.1346, d_mnist_loss: 0.0008, d_svhn_loss: 0.1338, d_fake_loss: 0.0348, g_loss: 1.0909\n",
            "Step [29230/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0009, d_svhn_loss: 0.0369, d_fake_loss: 0.0288, g_loss: 1.1250\n",
            "Step [29240/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0016, d_svhn_loss: 0.0224, d_fake_loss: 0.0505, g_loss: 1.2460\n",
            "Step [29250/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0024, d_svhn_loss: 0.0264, d_fake_loss: 0.1202, g_loss: 1.1469\n",
            "Step [29260/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0033, d_svhn_loss: 0.0618, d_fake_loss: 0.0305, g_loss: 1.0907\n",
            "Step [29270/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0014, d_svhn_loss: 0.0414, d_fake_loss: 0.0299, g_loss: 1.1174\n",
            "Step [29280/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0012, d_svhn_loss: 0.0308, d_fake_loss: 0.0623, g_loss: 1.0524\n",
            "Step [29290/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0018, d_svhn_loss: 0.0265, d_fake_loss: 0.0302, g_loss: 1.1118\n",
            "Step [29300/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0034, d_svhn_loss: 0.0503, d_fake_loss: 0.0510, g_loss: 1.0685\n",
            "Step [29310/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0396, d_svhn_loss: 0.0196, d_fake_loss: 0.0396, g_loss: 1.2935\n",
            "Step [29320/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0022, d_svhn_loss: 0.0313, d_fake_loss: 0.0582, g_loss: 1.1191\n",
            "Step [29330/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0126, d_svhn_loss: 0.0382, d_fake_loss: 0.0268, g_loss: 1.1803\n",
            "Step [29340/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0018, d_svhn_loss: 0.0338, d_fake_loss: 0.0231, g_loss: 1.0682\n",
            "Step [29350/80000], d_real_loss: 0.0854, d_mnist_loss: 0.0086, d_svhn_loss: 0.0769, d_fake_loss: 0.0454, g_loss: 1.0971\n",
            "Step [29360/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0025, d_svhn_loss: 0.0210, d_fake_loss: 0.0404, g_loss: 1.2425\n",
            "Step [29370/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0020, d_svhn_loss: 0.0560, d_fake_loss: 0.0727, g_loss: 1.1746\n",
            "Step [29380/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0049, d_svhn_loss: 0.0378, d_fake_loss: 0.0665, g_loss: 1.0488\n",
            "Step [29390/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0016, d_svhn_loss: 0.0343, d_fake_loss: 0.0728, g_loss: 1.0998\n",
            "Step [29400/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0054, d_svhn_loss: 0.0358, d_fake_loss: 0.0322, g_loss: 1.0983\n",
            "Step [29410/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0084, d_svhn_loss: 0.0463, d_fake_loss: 0.0643, g_loss: 1.0719\n",
            "Step [29420/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0015, d_svhn_loss: 0.0190, d_fake_loss: 0.0296, g_loss: 1.1819\n",
            "Step [29430/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0016, d_svhn_loss: 0.0355, d_fake_loss: 0.0290, g_loss: 1.1063\n",
            "Step [29440/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0036, d_svhn_loss: 0.0682, d_fake_loss: 0.0254, g_loss: 1.0944\n",
            "Step [29450/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0016, d_svhn_loss: 0.0548, d_fake_loss: 0.0439, g_loss: 1.1389\n",
            "Step [29460/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0389, d_svhn_loss: 0.0395, d_fake_loss: 0.0939, g_loss: 1.3272\n",
            "Step [29470/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0014, d_svhn_loss: 0.0279, d_fake_loss: 0.0322, g_loss: 1.0712\n",
            "Step [29480/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0173, d_svhn_loss: 0.0361, d_fake_loss: 0.1732, g_loss: 1.2090\n",
            "Step [29490/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0026, d_svhn_loss: 0.0279, d_fake_loss: 0.0240, g_loss: 1.1132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [29500/80000], d_real_loss: 0.0932, d_mnist_loss: 0.0033, d_svhn_loss: 0.0899, d_fake_loss: 0.0911, g_loss: 1.0840\n",
            "saved ./samples_mnist_svhn/sample-29500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-29500-s-m.png\n",
            "Step [29510/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0009, d_svhn_loss: 0.0366, d_fake_loss: 0.0612, g_loss: 1.1031\n",
            "Step [29520/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0024, d_svhn_loss: 0.0540, d_fake_loss: 0.0387, g_loss: 1.1371\n",
            "Step [29530/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0097, d_svhn_loss: 0.0318, d_fake_loss: 0.0245, g_loss: 1.2165\n",
            "Step [29540/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0043, d_svhn_loss: 0.0416, d_fake_loss: 0.0253, g_loss: 1.1354\n",
            "Step [29550/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0070, d_svhn_loss: 0.0482, d_fake_loss: 0.0337, g_loss: 1.1436\n",
            "Step [29560/80000], d_real_loss: 0.1425, d_mnist_loss: 0.0011, d_svhn_loss: 0.1414, d_fake_loss: 0.0407, g_loss: 1.1250\n",
            "Step [29570/80000], d_real_loss: 0.0749, d_mnist_loss: 0.0095, d_svhn_loss: 0.0654, d_fake_loss: 0.0564, g_loss: 1.0868\n",
            "Step [29580/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0068, d_svhn_loss: 0.0355, d_fake_loss: 0.1173, g_loss: 1.1289\n",
            "Step [29590/80000], d_real_loss: 0.1008, d_mnist_loss: 0.0038, d_svhn_loss: 0.0970, d_fake_loss: 0.1195, g_loss: 1.2671\n",
            "Step [29600/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0028, d_svhn_loss: 0.0216, d_fake_loss: 0.0413, g_loss: 0.9462\n",
            "Step [29610/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0062, d_svhn_loss: 0.0561, d_fake_loss: 0.0549, g_loss: 1.1148\n",
            "Step [29620/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0056, d_svhn_loss: 0.0388, d_fake_loss: 0.0594, g_loss: 1.0967\n",
            "Step [29630/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0061, d_svhn_loss: 0.0385, d_fake_loss: 0.0558, g_loss: 1.0105\n",
            "Step [29640/80000], d_real_loss: 0.1261, d_mnist_loss: 0.0015, d_svhn_loss: 0.1246, d_fake_loss: 0.0306, g_loss: 1.1610\n",
            "Step [29650/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0033, d_svhn_loss: 0.0403, d_fake_loss: 0.1596, g_loss: 1.1069\n",
            "Step [29660/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0059, d_svhn_loss: 0.0229, d_fake_loss: 0.0278, g_loss: 1.2073\n",
            "Step [29670/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0010, d_svhn_loss: 0.0562, d_fake_loss: 0.1465, g_loss: 1.1704\n",
            "Step [29680/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0013, d_svhn_loss: 0.0409, d_fake_loss: 0.1115, g_loss: 1.0978\n",
            "Step [29690/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0026, d_svhn_loss: 0.0586, d_fake_loss: 0.0292, g_loss: 1.1649\n",
            "Step [29700/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0014, d_svhn_loss: 0.0670, d_fake_loss: 0.0305, g_loss: 1.1146\n",
            "Step [29710/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0128, d_svhn_loss: 0.0414, d_fake_loss: 0.0271, g_loss: 1.2788\n",
            "Step [29720/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0025, d_svhn_loss: 0.0243, d_fake_loss: 0.0418, g_loss: 1.1118\n",
            "Step [29730/80000], d_real_loss: 0.2036, d_mnist_loss: 0.0010, d_svhn_loss: 0.2026, d_fake_loss: 0.0509, g_loss: 1.1527\n",
            "Step [29740/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0033, d_svhn_loss: 0.0655, d_fake_loss: 0.0424, g_loss: 1.1618\n",
            "Step [29750/80000], d_real_loss: 0.1624, d_mnist_loss: 0.0013, d_svhn_loss: 0.1612, d_fake_loss: 0.1576, g_loss: 1.1697\n",
            "Step [29760/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0036, d_svhn_loss: 0.0282, d_fake_loss: 0.0429, g_loss: 1.2344\n",
            "Step [29770/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0018, d_svhn_loss: 0.0498, d_fake_loss: 0.0585, g_loss: 1.1237\n",
            "Step [29780/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0012, d_svhn_loss: 0.0307, d_fake_loss: 0.0364, g_loss: 1.1640\n",
            "Step [29790/80000], d_real_loss: 0.0707, d_mnist_loss: 0.0012, d_svhn_loss: 0.0695, d_fake_loss: 0.0889, g_loss: 1.2304\n",
            "Step [29800/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0013, d_svhn_loss: 0.0286, d_fake_loss: 0.0290, g_loss: 1.1725\n",
            "Step [29810/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0369, d_svhn_loss: 0.0358, d_fake_loss: 0.0479, g_loss: 1.1536\n",
            "Step [29820/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0108, d_svhn_loss: 0.0223, d_fake_loss: 0.0402, g_loss: 1.0599\n",
            "Step [29830/80000], d_real_loss: 0.1288, d_mnist_loss: 0.0040, d_svhn_loss: 0.1248, d_fake_loss: 0.0542, g_loss: 1.1046\n",
            "Step [29840/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0019, d_svhn_loss: 0.0242, d_fake_loss: 0.0368, g_loss: 1.0962\n",
            "Step [29850/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0068, d_svhn_loss: 0.0369, d_fake_loss: 0.0561, g_loss: 1.1892\n",
            "Step [29860/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0028, d_svhn_loss: 0.0262, d_fake_loss: 0.0343, g_loss: 1.2196\n",
            "Step [29870/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0094, d_svhn_loss: 0.0540, d_fake_loss: 0.1194, g_loss: 1.0499\n",
            "Step [29880/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0015, d_svhn_loss: 0.0309, d_fake_loss: 0.1088, g_loss: 1.2991\n",
            "Step [29890/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0093, d_svhn_loss: 0.0381, d_fake_loss: 0.0179, g_loss: 1.0576\n",
            "Step [29900/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0103, d_svhn_loss: 0.0313, d_fake_loss: 0.0548, g_loss: 1.5538\n",
            "Step [29910/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0012, d_svhn_loss: 0.0231, d_fake_loss: 0.0619, g_loss: 1.2803\n",
            "Step [29920/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0010, d_svhn_loss: 0.0779, d_fake_loss: 0.0832, g_loss: 1.1670\n",
            "Step [29930/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0021, d_svhn_loss: 0.0322, d_fake_loss: 0.0231, g_loss: 1.2094\n",
            "Step [29940/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0038, d_svhn_loss: 0.0242, d_fake_loss: 0.1923, g_loss: 1.3230\n",
            "Step [29950/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0181, d_svhn_loss: 0.0317, d_fake_loss: 0.0761, g_loss: 1.0828\n",
            "Step [29960/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0026, d_svhn_loss: 0.0442, d_fake_loss: 0.0274, g_loss: 1.1840\n",
            "Step [29970/80000], d_real_loss: 0.0929, d_mnist_loss: 0.0156, d_svhn_loss: 0.0773, d_fake_loss: 0.0442, g_loss: 1.1189\n",
            "Step [29980/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0022, d_svhn_loss: 0.0922, d_fake_loss: 0.0291, g_loss: 1.1613\n",
            "Step [29990/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0013, d_svhn_loss: 0.0314, d_fake_loss: 0.0347, g_loss: 1.1022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [30000/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0143, d_svhn_loss: 0.0264, d_fake_loss: 0.0775, g_loss: 1.2382\n",
            "saved ./samples_mnist_svhn/sample-30000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-30000-s-m.png\n",
            "Step [30010/80000], d_real_loss: 0.0757, d_mnist_loss: 0.0258, d_svhn_loss: 0.0499, d_fake_loss: 0.0809, g_loss: 1.1539\n",
            "Step [30020/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0337, d_svhn_loss: 0.0564, d_fake_loss: 0.0297, g_loss: 1.0540\n",
            "Step [30030/80000], d_real_loss: 0.1100, d_mnist_loss: 0.0094, d_svhn_loss: 0.1006, d_fake_loss: 0.0373, g_loss: 1.0655\n",
            "Step [30040/80000], d_real_loss: 0.1007, d_mnist_loss: 0.0010, d_svhn_loss: 0.0997, d_fake_loss: 0.0244, g_loss: 1.1049\n",
            "Step [30050/80000], d_real_loss: 0.0834, d_mnist_loss: 0.0015, d_svhn_loss: 0.0819, d_fake_loss: 0.0604, g_loss: 1.1187\n",
            "Step [30060/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0044, d_svhn_loss: 0.0233, d_fake_loss: 0.0351, g_loss: 1.2936\n",
            "Step [30070/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0015, d_svhn_loss: 0.0350, d_fake_loss: 0.0354, g_loss: 1.1607\n",
            "Step [30080/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0009, d_svhn_loss: 0.0199, d_fake_loss: 0.0502, g_loss: 1.0947\n",
            "Step [30090/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0413, d_svhn_loss: 0.0261, d_fake_loss: 0.1054, g_loss: 1.2311\n",
            "Step [30100/80000], d_real_loss: 0.1033, d_mnist_loss: 0.0047, d_svhn_loss: 0.0986, d_fake_loss: 0.0261, g_loss: 1.1003\n",
            "Step [30110/80000], d_real_loss: 0.1064, d_mnist_loss: 0.0072, d_svhn_loss: 0.0991, d_fake_loss: 0.0405, g_loss: 1.1460\n",
            "Step [30120/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0048, d_svhn_loss: 0.0323, d_fake_loss: 0.0747, g_loss: 1.1646\n",
            "Step [30130/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0024, d_svhn_loss: 0.0362, d_fake_loss: 0.0180, g_loss: 1.0469\n",
            "Step [30140/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0007, d_svhn_loss: 0.0339, d_fake_loss: 0.0255, g_loss: 1.0855\n",
            "Step [30150/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0016, d_svhn_loss: 0.0248, d_fake_loss: 0.0179, g_loss: 1.1229\n",
            "Step [30160/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0032, d_svhn_loss: 0.0229, d_fake_loss: 0.0471, g_loss: 1.1545\n",
            "Step [30170/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0030, d_svhn_loss: 0.0610, d_fake_loss: 0.0274, g_loss: 1.1473\n",
            "Step [30180/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0014, d_svhn_loss: 0.0785, d_fake_loss: 0.0511, g_loss: 1.1220\n",
            "Step [30190/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0048, d_svhn_loss: 0.0598, d_fake_loss: 0.0357, g_loss: 1.1514\n",
            "Step [30200/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0121, d_svhn_loss: 0.0365, d_fake_loss: 0.0292, g_loss: 1.0888\n",
            "Step [30210/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0007, d_svhn_loss: 0.0538, d_fake_loss: 0.0510, g_loss: 1.1416\n",
            "Step [30220/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0051, d_svhn_loss: 0.0184, d_fake_loss: 0.0867, g_loss: 1.1308\n",
            "Step [30230/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0021, d_svhn_loss: 0.0229, d_fake_loss: 0.0327, g_loss: 1.1134\n",
            "Step [30240/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0018, d_svhn_loss: 0.0483, d_fake_loss: 0.0460, g_loss: 1.2042\n",
            "Step [30250/80000], d_real_loss: 0.1001, d_mnist_loss: 0.0019, d_svhn_loss: 0.0982, d_fake_loss: 0.1316, g_loss: 1.1490\n",
            "Step [30260/80000], d_real_loss: 0.0930, d_mnist_loss: 0.0018, d_svhn_loss: 0.0911, d_fake_loss: 0.0898, g_loss: 1.2274\n",
            "Step [30270/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0062, d_svhn_loss: 0.0282, d_fake_loss: 0.0241, g_loss: 1.1918\n",
            "Step [30280/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0010, d_svhn_loss: 0.0513, d_fake_loss: 0.0330, g_loss: 1.1522\n",
            "Step [30290/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0099, d_svhn_loss: 0.0203, d_fake_loss: 0.0374, g_loss: 1.1693\n",
            "Step [30300/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0030, d_svhn_loss: 0.0245, d_fake_loss: 0.0456, g_loss: 1.1972\n",
            "Step [30310/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0061, d_svhn_loss: 0.0209, d_fake_loss: 0.0357, g_loss: 1.0811\n",
            "Step [30320/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0010, d_svhn_loss: 0.0624, d_fake_loss: 0.0636, g_loss: 1.1664\n",
            "Step [30330/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0067, d_svhn_loss: 0.0332, d_fake_loss: 0.0417, g_loss: 1.0818\n",
            "Step [30340/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0029, d_svhn_loss: 0.0541, d_fake_loss: 0.0341, g_loss: 1.1242\n",
            "Step [30350/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0009, d_svhn_loss: 0.0656, d_fake_loss: 0.0290, g_loss: 1.1611\n",
            "Step [30360/80000], d_real_loss: 0.0796, d_mnist_loss: 0.0036, d_svhn_loss: 0.0760, d_fake_loss: 0.0267, g_loss: 1.0970\n",
            "Step [30370/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0039, d_svhn_loss: 0.0206, d_fake_loss: 0.0655, g_loss: 1.0813\n",
            "Step [30380/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0007, d_svhn_loss: 0.0316, d_fake_loss: 0.0420, g_loss: 1.1027\n",
            "Step [30390/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0007, d_svhn_loss: 0.0302, d_fake_loss: 0.0328, g_loss: 1.0922\n",
            "Step [30400/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0036, d_svhn_loss: 0.0202, d_fake_loss: 0.0257, g_loss: 1.1441\n",
            "Step [30410/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0066, d_svhn_loss: 0.0495, d_fake_loss: 0.0215, g_loss: 1.1962\n",
            "Step [30420/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0006, d_svhn_loss: 0.0221, d_fake_loss: 0.1357, g_loss: 1.0851\n",
            "Step [30430/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0028, d_svhn_loss: 0.0217, d_fake_loss: 0.0328, g_loss: 1.1450\n",
            "Step [30440/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0120, d_svhn_loss: 0.0230, d_fake_loss: 0.0625, g_loss: 0.9003\n",
            "Step [30450/80000], d_real_loss: 0.0905, d_mnist_loss: 0.0202, d_svhn_loss: 0.0703, d_fake_loss: 0.0726, g_loss: 1.1611\n",
            "Step [30460/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0091, d_svhn_loss: 0.0568, d_fake_loss: 0.0323, g_loss: 1.0474\n",
            "Step [30470/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0041, d_svhn_loss: 0.0551, d_fake_loss: 0.1727, g_loss: 1.2635\n",
            "Step [30480/80000], d_real_loss: 0.0934, d_mnist_loss: 0.0071, d_svhn_loss: 0.0862, d_fake_loss: 0.0434, g_loss: 1.2343\n",
            "Step [30490/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0240, d_svhn_loss: 0.0424, d_fake_loss: 0.0478, g_loss: 1.1736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [30500/80000], d_real_loss: 0.1184, d_mnist_loss: 0.0097, d_svhn_loss: 0.1087, d_fake_loss: 0.0847, g_loss: 1.6298\n",
            "saved ./samples_mnist_svhn/sample-30500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-30500-s-m.png\n",
            "Step [30510/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0027, d_svhn_loss: 0.0470, d_fake_loss: 0.0649, g_loss: 1.1684\n",
            "Step [30520/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0023, d_svhn_loss: 0.0319, d_fake_loss: 0.0274, g_loss: 1.2328\n",
            "Step [30530/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0035, d_svhn_loss: 0.0278, d_fake_loss: 0.0390, g_loss: 1.0867\n",
            "Step [30540/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0067, d_svhn_loss: 0.0359, d_fake_loss: 0.0458, g_loss: 1.3124\n",
            "Step [30550/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0037, d_svhn_loss: 0.0246, d_fake_loss: 0.0614, g_loss: 1.2508\n",
            "Step [30560/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0016, d_svhn_loss: 0.0359, d_fake_loss: 0.0317, g_loss: 1.0703\n",
            "Step [30570/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0043, d_svhn_loss: 0.0278, d_fake_loss: 0.0225, g_loss: 1.2078\n",
            "Step [30580/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0052, d_svhn_loss: 0.0343, d_fake_loss: 0.0578, g_loss: 1.1164\n",
            "Step [30590/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0023, d_svhn_loss: 0.0237, d_fake_loss: 0.1007, g_loss: 1.1874\n",
            "Step [30600/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0040, d_svhn_loss: 0.0392, d_fake_loss: 0.0405, g_loss: 1.1215\n",
            "Step [30610/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0046, d_svhn_loss: 0.0407, d_fake_loss: 0.1415, g_loss: 1.2074\n",
            "Step [30620/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0036, d_svhn_loss: 0.0365, d_fake_loss: 0.0390, g_loss: 1.2336\n",
            "Step [30630/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0028, d_svhn_loss: 0.0226, d_fake_loss: 0.0248, g_loss: 1.2282\n",
            "Step [30640/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0026, d_svhn_loss: 0.0369, d_fake_loss: 0.0220, g_loss: 1.1962\n",
            "Step [30650/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0048, d_svhn_loss: 0.0184, d_fake_loss: 0.0619, g_loss: 1.1306\n",
            "Step [30660/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0013, d_svhn_loss: 0.0197, d_fake_loss: 0.0188, g_loss: 1.1810\n",
            "Step [30670/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0028, d_svhn_loss: 0.0414, d_fake_loss: 0.0480, g_loss: 1.1064\n",
            "Step [30680/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0014, d_svhn_loss: 0.0321, d_fake_loss: 0.0487, g_loss: 1.2202\n",
            "Step [30690/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0101, d_svhn_loss: 0.0388, d_fake_loss: 0.0516, g_loss: 1.0984\n",
            "Step [30700/80000], d_real_loss: 0.0824, d_mnist_loss: 0.0127, d_svhn_loss: 0.0697, d_fake_loss: 0.0372, g_loss: 1.1877\n",
            "Step [30710/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0024, d_svhn_loss: 0.0320, d_fake_loss: 0.1810, g_loss: 1.1490\n",
            "Step [30720/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0029, d_svhn_loss: 0.0244, d_fake_loss: 0.0197, g_loss: 1.1323\n",
            "Step [30730/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0017, d_svhn_loss: 0.0270, d_fake_loss: 0.0213, g_loss: 1.1539\n",
            "Step [30740/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0199, d_svhn_loss: 0.0459, d_fake_loss: 0.0347, g_loss: 1.0499\n",
            "Step [30750/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0022, d_svhn_loss: 0.0626, d_fake_loss: 0.0558, g_loss: 1.0737\n",
            "Step [30760/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0012, d_svhn_loss: 0.0759, d_fake_loss: 0.0240, g_loss: 1.1863\n",
            "Step [30770/80000], d_real_loss: 0.1217, d_mnist_loss: 0.0034, d_svhn_loss: 0.1183, d_fake_loss: 0.0463, g_loss: 1.1009\n",
            "Step [30780/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0017, d_svhn_loss: 0.0312, d_fake_loss: 0.0400, g_loss: 1.1026\n",
            "Step [30790/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0013, d_svhn_loss: 0.0250, d_fake_loss: 0.0460, g_loss: 1.2331\n",
            "Step [30800/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0019, d_svhn_loss: 0.0465, d_fake_loss: 0.0274, g_loss: 1.1633\n",
            "Step [30810/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0159, d_svhn_loss: 0.0435, d_fake_loss: 0.0535, g_loss: 1.0639\n",
            "Step [30820/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0030, d_svhn_loss: 0.0519, d_fake_loss: 0.0474, g_loss: 1.0937\n",
            "Step [30830/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0009, d_svhn_loss: 0.0506, d_fake_loss: 0.0330, g_loss: 1.1317\n",
            "Step [30840/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0027, d_svhn_loss: 0.0301, d_fake_loss: 0.0420, g_loss: 1.0844\n",
            "Step [30850/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0087, d_svhn_loss: 0.0295, d_fake_loss: 0.0311, g_loss: 1.1612\n",
            "Step [30860/80000], d_real_loss: 0.0862, d_mnist_loss: 0.0040, d_svhn_loss: 0.0822, d_fake_loss: 0.0371, g_loss: 1.0907\n",
            "Step [30870/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0010, d_svhn_loss: 0.0837, d_fake_loss: 0.0194, g_loss: 1.1730\n",
            "Step [30880/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0010, d_svhn_loss: 0.0235, d_fake_loss: 0.0507, g_loss: 1.1695\n",
            "Step [30890/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0042, d_svhn_loss: 0.0761, d_fake_loss: 0.0814, g_loss: 1.1721\n",
            "Step [30900/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0027, d_svhn_loss: 0.0230, d_fake_loss: 0.0624, g_loss: 1.1936\n",
            "Step [30910/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0028, d_svhn_loss: 0.0774, d_fake_loss: 0.0328, g_loss: 1.1962\n",
            "Step [30920/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0008, d_svhn_loss: 0.0289, d_fake_loss: 0.0322, g_loss: 1.1130\n",
            "Step [30930/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0018, d_svhn_loss: 0.0460, d_fake_loss: 0.0557, g_loss: 1.1488\n",
            "Step [30940/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0025, d_svhn_loss: 0.0455, d_fake_loss: 0.0388, g_loss: 1.1850\n",
            "Step [30950/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0020, d_svhn_loss: 0.0397, d_fake_loss: 0.0219, g_loss: 1.1219\n",
            "Step [30960/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0096, d_svhn_loss: 0.0319, d_fake_loss: 0.0170, g_loss: 1.1154\n",
            "Step [30970/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0012, d_svhn_loss: 0.0476, d_fake_loss: 0.0624, g_loss: 1.0876\n",
            "Step [30980/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0054, d_svhn_loss: 0.0368, d_fake_loss: 0.0917, g_loss: 1.1092\n",
            "Step [30990/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0017, d_svhn_loss: 0.0279, d_fake_loss: 0.0255, g_loss: 1.1947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [31000/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0010, d_svhn_loss: 0.0480, d_fake_loss: 0.0359, g_loss: 1.1472\n",
            "saved ./samples_mnist_svhn/sample-31000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-31000-s-m.png\n",
            "Step [31010/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0012, d_svhn_loss: 0.0235, d_fake_loss: 0.0932, g_loss: 1.0676\n",
            "Step [31020/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0078, d_svhn_loss: 0.0288, d_fake_loss: 0.0659, g_loss: 1.1509\n",
            "Step [31030/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0031, d_svhn_loss: 0.0259, d_fake_loss: 0.0212, g_loss: 1.1198\n",
            "Step [31040/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0012, d_svhn_loss: 0.0265, d_fake_loss: 0.0242, g_loss: 1.1225\n",
            "Step [31050/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0009, d_svhn_loss: 0.0206, d_fake_loss: 0.0450, g_loss: 1.1786\n",
            "Step [31060/80000], d_real_loss: 0.1407, d_mnist_loss: 0.0153, d_svhn_loss: 0.1254, d_fake_loss: 0.0340, g_loss: 1.0176\n",
            "Step [31070/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0012, d_svhn_loss: 0.0346, d_fake_loss: 0.0367, g_loss: 1.1053\n",
            "Step [31080/80000], d_real_loss: 0.0976, d_mnist_loss: 0.0127, d_svhn_loss: 0.0849, d_fake_loss: 0.1713, g_loss: 1.0655\n",
            "Step [31090/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0085, d_svhn_loss: 0.0511, d_fake_loss: 0.0873, g_loss: 1.4379\n",
            "Step [31100/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0142, d_svhn_loss: 0.0384, d_fake_loss: 0.0221, g_loss: 1.1721\n",
            "Step [31110/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0034, d_svhn_loss: 0.0267, d_fake_loss: 0.0382, g_loss: 1.1242\n",
            "Step [31120/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0185, d_svhn_loss: 0.0218, d_fake_loss: 0.0310, g_loss: 1.0457\n",
            "Step [31130/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0068, d_svhn_loss: 0.0192, d_fake_loss: 0.0374, g_loss: 1.1891\n",
            "Step [31140/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0074, d_svhn_loss: 0.0316, d_fake_loss: 0.0629, g_loss: 1.1111\n",
            "Step [31150/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0026, d_svhn_loss: 0.0521, d_fake_loss: 0.0679, g_loss: 1.1082\n",
            "Step [31160/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0140, d_svhn_loss: 0.0471, d_fake_loss: 0.0383, g_loss: 1.2057\n",
            "Step [31170/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0082, d_svhn_loss: 0.0246, d_fake_loss: 0.0337, g_loss: 1.1736\n",
            "Step [31180/80000], d_real_loss: 0.1543, d_mnist_loss: 0.0027, d_svhn_loss: 0.1515, d_fake_loss: 0.0451, g_loss: 1.1495\n",
            "Step [31190/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0141, d_svhn_loss: 0.0302, d_fake_loss: 0.0346, g_loss: 1.2023\n",
            "Step [31200/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0163, d_svhn_loss: 0.0362, d_fake_loss: 0.0194, g_loss: 1.1349\n",
            "Step [31210/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0164, d_svhn_loss: 0.0251, d_fake_loss: 0.0351, g_loss: 1.0310\n",
            "Step [31220/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0020, d_svhn_loss: 0.0300, d_fake_loss: 0.0189, g_loss: 1.0949\n",
            "Step [31230/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0017, d_svhn_loss: 0.0294, d_fake_loss: 0.0191, g_loss: 1.1167\n",
            "Step [31240/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0036, d_svhn_loss: 0.0287, d_fake_loss: 0.0318, g_loss: 1.0676\n",
            "Step [31250/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0009, d_svhn_loss: 0.0314, d_fake_loss: 0.0704, g_loss: 1.1637\n",
            "Step [31260/80000], d_real_loss: 0.0789, d_mnist_loss: 0.0054, d_svhn_loss: 0.0735, d_fake_loss: 0.0253, g_loss: 1.0224\n",
            "Step [31270/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0013, d_svhn_loss: 0.0265, d_fake_loss: 0.0410, g_loss: 1.2996\n",
            "Step [31280/80000], d_real_loss: 0.1181, d_mnist_loss: 0.0031, d_svhn_loss: 0.1149, d_fake_loss: 0.0275, g_loss: 1.1840\n",
            "Step [31290/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0206, d_svhn_loss: 0.0228, d_fake_loss: 0.0262, g_loss: 1.0708\n",
            "Step [31300/80000], d_real_loss: 0.1029, d_mnist_loss: 0.0023, d_svhn_loss: 0.1005, d_fake_loss: 0.0335, g_loss: 1.1602\n",
            "Step [31310/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0013, d_svhn_loss: 0.0268, d_fake_loss: 0.0393, g_loss: 1.0688\n",
            "Step [31320/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0018, d_svhn_loss: 0.0262, d_fake_loss: 0.0287, g_loss: 1.1687\n",
            "Step [31330/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0056, d_svhn_loss: 0.0205, d_fake_loss: 0.2077, g_loss: 1.0481\n",
            "Step [31340/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0021, d_svhn_loss: 0.0741, d_fake_loss: 0.0709, g_loss: 1.1367\n",
            "Step [31350/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0014, d_svhn_loss: 0.0598, d_fake_loss: 0.1405, g_loss: 1.2387\n",
            "Step [31360/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0029, d_svhn_loss: 0.0602, d_fake_loss: 0.0766, g_loss: 1.1259\n",
            "Step [31370/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0009, d_svhn_loss: 0.0244, d_fake_loss: 0.0331, g_loss: 1.1333\n",
            "Step [31380/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0054, d_svhn_loss: 0.0419, d_fake_loss: 0.0520, g_loss: 1.0765\n",
            "Step [31390/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0017, d_svhn_loss: 0.0444, d_fake_loss: 0.2169, g_loss: 1.1791\n",
            "Step [31400/80000], d_real_loss: 0.0827, d_mnist_loss: 0.0009, d_svhn_loss: 0.0818, d_fake_loss: 0.0979, g_loss: 1.1058\n",
            "Step [31410/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0044, d_svhn_loss: 0.0412, d_fake_loss: 0.0313, g_loss: 1.1285\n",
            "Step [31420/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0012, d_svhn_loss: 0.0344, d_fake_loss: 0.0253, g_loss: 1.1328\n",
            "Step [31430/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0008, d_svhn_loss: 0.0312, d_fake_loss: 0.1112, g_loss: 1.1360\n",
            "Step [31440/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0043, d_svhn_loss: 0.0489, d_fake_loss: 0.0944, g_loss: 1.0869\n",
            "Step [31450/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0012, d_svhn_loss: 0.0675, d_fake_loss: 0.0968, g_loss: 1.1190\n",
            "Step [31460/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0047, d_svhn_loss: 0.0263, d_fake_loss: 0.0967, g_loss: 1.1444\n",
            "Step [31470/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0119, d_svhn_loss: 0.0360, d_fake_loss: 0.0190, g_loss: 1.1311\n",
            "Step [31480/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0010, d_svhn_loss: 0.0558, d_fake_loss: 0.0259, g_loss: 1.1201\n",
            "Step [31490/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0010, d_svhn_loss: 0.0382, d_fake_loss: 0.0398, g_loss: 1.1774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [31500/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0027, d_svhn_loss: 0.0689, d_fake_loss: 0.0455, g_loss: 1.1901\n",
            "saved ./samples_mnist_svhn/sample-31500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-31500-s-m.png\n",
            "Step [31510/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0024, d_svhn_loss: 0.0293, d_fake_loss: 0.0261, g_loss: 1.1000\n",
            "Step [31520/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0009, d_svhn_loss: 0.0304, d_fake_loss: 0.0381, g_loss: 1.0867\n",
            "Step [31530/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0147, d_svhn_loss: 0.0295, d_fake_loss: 0.1091, g_loss: 1.2131\n",
            "Step [31540/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0164, d_svhn_loss: 0.0495, d_fake_loss: 0.0248, g_loss: 1.1579\n",
            "Step [31550/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0013, d_svhn_loss: 0.0185, d_fake_loss: 0.0828, g_loss: 1.1468\n",
            "Step [31560/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0018, d_svhn_loss: 0.0343, d_fake_loss: 0.0680, g_loss: 1.0930\n",
            "Step [31570/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0049, d_svhn_loss: 0.0214, d_fake_loss: 0.1278, g_loss: 1.1413\n",
            "Step [31580/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0008, d_svhn_loss: 0.0288, d_fake_loss: 0.0226, g_loss: 1.1140\n",
            "Step [31590/80000], d_real_loss: 0.0775, d_mnist_loss: 0.0039, d_svhn_loss: 0.0736, d_fake_loss: 0.0378, g_loss: 1.0883\n",
            "Step [31600/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0013, d_svhn_loss: 0.0383, d_fake_loss: 0.0368, g_loss: 1.1233\n",
            "Step [31610/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0007, d_svhn_loss: 0.0487, d_fake_loss: 0.1302, g_loss: 1.1385\n",
            "Step [31620/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0033, d_svhn_loss: 0.0425, d_fake_loss: 0.0361, g_loss: 1.1419\n",
            "Step [31630/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0015, d_svhn_loss: 0.0651, d_fake_loss: 0.0416, g_loss: 1.1611\n",
            "Step [31640/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0018, d_svhn_loss: 0.0245, d_fake_loss: 0.0244, g_loss: 1.1477\n",
            "Step [31650/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0019, d_svhn_loss: 0.0562, d_fake_loss: 0.0384, g_loss: 1.1089\n",
            "Step [31660/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0024, d_svhn_loss: 0.0810, d_fake_loss: 0.0355, g_loss: 1.1666\n",
            "Step [31670/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0082, d_svhn_loss: 0.0508, d_fake_loss: 0.1640, g_loss: 1.1688\n",
            "Step [31680/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0063, d_svhn_loss: 0.0396, d_fake_loss: 0.0278, g_loss: 1.0995\n",
            "Step [31690/80000], d_real_loss: 0.2105, d_mnist_loss: 0.0049, d_svhn_loss: 0.2056, d_fake_loss: 0.0287, g_loss: 1.1576\n",
            "Step [31700/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0026, d_svhn_loss: 0.0561, d_fake_loss: 0.0285, g_loss: 1.0937\n",
            "Step [31710/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0071, d_svhn_loss: 0.0304, d_fake_loss: 0.0395, g_loss: 1.0885\n",
            "Step [31720/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0059, d_svhn_loss: 0.0276, d_fake_loss: 0.0409, g_loss: 1.1713\n",
            "Step [31730/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0012, d_svhn_loss: 0.0262, d_fake_loss: 0.0825, g_loss: 1.0981\n",
            "Step [31740/80000], d_real_loss: 0.1364, d_mnist_loss: 0.0027, d_svhn_loss: 0.1337, d_fake_loss: 0.0763, g_loss: 1.1353\n",
            "Step [31750/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0030, d_svhn_loss: 0.0551, d_fake_loss: 0.0719, g_loss: 1.1611\n",
            "Step [31760/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0161, d_svhn_loss: 0.0253, d_fake_loss: 0.0161, g_loss: 1.0897\n",
            "Step [31770/80000], d_real_loss: 0.0922, d_mnist_loss: 0.0008, d_svhn_loss: 0.0914, d_fake_loss: 0.0469, g_loss: 1.1531\n",
            "Step [31780/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0055, d_svhn_loss: 0.0288, d_fake_loss: 0.0261, g_loss: 1.2357\n",
            "Step [31790/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0008, d_svhn_loss: 0.0409, d_fake_loss: 0.0459, g_loss: 1.1350\n",
            "Step [31800/80000], d_real_loss: 0.1491, d_mnist_loss: 0.0271, d_svhn_loss: 0.1219, d_fake_loss: 0.0521, g_loss: 1.0295\n",
            "Step [31810/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0122, d_svhn_loss: 0.0242, d_fake_loss: 0.0468, g_loss: 1.0778\n",
            "Step [31820/80000], d_real_loss: 0.1156, d_mnist_loss: 0.0026, d_svhn_loss: 0.1130, d_fake_loss: 0.0738, g_loss: 1.1004\n",
            "Step [31830/80000], d_real_loss: 0.1001, d_mnist_loss: 0.0011, d_svhn_loss: 0.0990, d_fake_loss: 0.0477, g_loss: 1.1051\n",
            "Step [31840/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0030, d_svhn_loss: 0.0218, d_fake_loss: 0.0194, g_loss: 1.1482\n",
            "Step [31850/80000], d_real_loss: 0.0715, d_mnist_loss: 0.0202, d_svhn_loss: 0.0512, d_fake_loss: 0.0805, g_loss: 1.1793\n",
            "Step [31860/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0025, d_svhn_loss: 0.0205, d_fake_loss: 0.0536, g_loss: 1.1168\n",
            "Step [31870/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0019, d_svhn_loss: 0.0393, d_fake_loss: 0.0418, g_loss: 1.1143\n",
            "Step [31880/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0009, d_svhn_loss: 0.0326, d_fake_loss: 0.0332, g_loss: 1.1077\n",
            "Step [31890/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0011, d_svhn_loss: 0.0760, d_fake_loss: 0.1395, g_loss: 1.0785\n",
            "Step [31900/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0010, d_svhn_loss: 0.0384, d_fake_loss: 0.0309, g_loss: 1.1125\n",
            "Step [31910/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0011, d_svhn_loss: 0.0564, d_fake_loss: 0.0397, g_loss: 1.1255\n",
            "Step [31920/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0021, d_svhn_loss: 0.0278, d_fake_loss: 0.0390, g_loss: 1.1139\n",
            "Step [31930/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0011, d_svhn_loss: 0.0339, d_fake_loss: 0.0332, g_loss: 1.0585\n",
            "Step [31940/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0012, d_svhn_loss: 0.0306, d_fake_loss: 0.0357, g_loss: 1.1391\n",
            "Step [31950/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0007, d_svhn_loss: 0.0281, d_fake_loss: 0.0503, g_loss: 1.1471\n",
            "Step [31960/80000], d_real_loss: 0.1010, d_mnist_loss: 0.0025, d_svhn_loss: 0.0985, d_fake_loss: 0.0432, g_loss: 1.1121\n",
            "Step [31970/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0041, d_svhn_loss: 0.0256, d_fake_loss: 0.0370, g_loss: 1.1234\n",
            "Step [31980/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0014, d_svhn_loss: 0.0327, d_fake_loss: 0.0490, g_loss: 1.1107\n",
            "Step [31990/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0056, d_svhn_loss: 0.0784, d_fake_loss: 0.0465, g_loss: 1.1798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [32000/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0006, d_svhn_loss: 0.0681, d_fake_loss: 0.0395, g_loss: 1.1174\n",
            "saved ./samples_mnist_svhn/sample-32000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-32000-s-m.png\n",
            "Step [32010/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0010, d_svhn_loss: 0.0320, d_fake_loss: 0.0801, g_loss: 1.1685\n",
            "Step [32020/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0011, d_svhn_loss: 0.0322, d_fake_loss: 0.0165, g_loss: 1.1459\n",
            "Step [32030/80000], d_real_loss: 0.1984, d_mnist_loss: 0.1288, d_svhn_loss: 0.0696, d_fake_loss: 0.0929, g_loss: 1.3526\n",
            "Step [32040/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0060, d_svhn_loss: 0.0304, d_fake_loss: 0.0323, g_loss: 1.1755\n",
            "Step [32050/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0049, d_svhn_loss: 0.0284, d_fake_loss: 0.0267, g_loss: 1.1284\n",
            "Step [32060/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0020, d_svhn_loss: 0.0599, d_fake_loss: 0.0425, g_loss: 1.1418\n",
            "Step [32070/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0104, d_svhn_loss: 0.0392, d_fake_loss: 0.0444, g_loss: 1.1628\n",
            "Step [32080/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0017, d_svhn_loss: 0.0408, d_fake_loss: 0.0396, g_loss: 1.2168\n",
            "Step [32090/80000], d_real_loss: 0.1090, d_mnist_loss: 0.0074, d_svhn_loss: 0.1016, d_fake_loss: 0.0309, g_loss: 1.1502\n",
            "Step [32100/80000], d_real_loss: 0.0865, d_mnist_loss: 0.0018, d_svhn_loss: 0.0847, d_fake_loss: 0.0944, g_loss: 1.1471\n",
            "Step [32110/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0037, d_svhn_loss: 0.0521, d_fake_loss: 0.0335, g_loss: 1.0473\n",
            "Step [32120/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0014, d_svhn_loss: 0.0454, d_fake_loss: 0.0317, g_loss: 1.1096\n",
            "Step [32130/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0062, d_svhn_loss: 0.0338, d_fake_loss: 0.0259, g_loss: 1.0801\n",
            "Step [32140/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0007, d_svhn_loss: 0.0296, d_fake_loss: 0.0371, g_loss: 1.2166\n",
            "Step [32150/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0009, d_svhn_loss: 0.0533, d_fake_loss: 0.0661, g_loss: 1.1252\n",
            "Step [32160/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0013, d_svhn_loss: 0.0256, d_fake_loss: 0.0289, g_loss: 1.2445\n",
            "Step [32170/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0021, d_svhn_loss: 0.0176, d_fake_loss: 0.0335, g_loss: 1.1200\n",
            "Step [32180/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0009, d_svhn_loss: 0.0339, d_fake_loss: 0.0357, g_loss: 1.2191\n",
            "Step [32190/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0057, d_svhn_loss: 0.0253, d_fake_loss: 0.0298, g_loss: 1.2002\n",
            "Step [32200/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0023, d_svhn_loss: 0.0598, d_fake_loss: 0.0394, g_loss: 1.0921\n",
            "Step [32210/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0011, d_svhn_loss: 0.0417, d_fake_loss: 0.0357, g_loss: 1.1547\n",
            "Step [32220/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0020, d_svhn_loss: 0.0730, d_fake_loss: 0.0392, g_loss: 1.1572\n",
            "Step [32230/80000], d_real_loss: 0.1012, d_mnist_loss: 0.0023, d_svhn_loss: 0.0989, d_fake_loss: 0.1213, g_loss: 1.1643\n",
            "Step [32240/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0117, d_svhn_loss: 0.0156, d_fake_loss: 0.0616, g_loss: 1.0628\n",
            "Step [32250/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0031, d_svhn_loss: 0.0294, d_fake_loss: 0.0587, g_loss: 1.0887\n",
            "Step [32260/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0068, d_svhn_loss: 0.0301, d_fake_loss: 0.0264, g_loss: 1.0657\n",
            "Step [32270/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0015, d_svhn_loss: 0.0394, d_fake_loss: 0.0273, g_loss: 1.0821\n",
            "Step [32280/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0006, d_svhn_loss: 0.0217, d_fake_loss: 0.0373, g_loss: 1.1286\n",
            "Step [32290/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0141, d_svhn_loss: 0.0447, d_fake_loss: 0.0558, g_loss: 1.0670\n",
            "Step [32300/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0008, d_svhn_loss: 0.0843, d_fake_loss: 0.0243, g_loss: 1.1016\n",
            "Step [32310/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0129, d_svhn_loss: 0.0197, d_fake_loss: 0.0573, g_loss: 1.0402\n",
            "Step [32320/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0007, d_svhn_loss: 0.0360, d_fake_loss: 0.0375, g_loss: 1.0940\n",
            "Step [32330/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0093, d_svhn_loss: 0.0239, d_fake_loss: 0.0518, g_loss: 1.0803\n",
            "Step [32340/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0009, d_svhn_loss: 0.0539, d_fake_loss: 0.0576, g_loss: 1.1490\n",
            "Step [32350/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0029, d_svhn_loss: 0.0223, d_fake_loss: 0.0262, g_loss: 1.1462\n",
            "Step [32360/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0042, d_svhn_loss: 0.0512, d_fake_loss: 0.0336, g_loss: 1.0880\n",
            "Step [32370/80000], d_real_loss: 0.1242, d_mnist_loss: 0.0016, d_svhn_loss: 0.1226, d_fake_loss: 0.0432, g_loss: 1.1350\n",
            "Step [32380/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0047, d_svhn_loss: 0.0303, d_fake_loss: 0.0688, g_loss: 1.1138\n",
            "Step [32390/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0041, d_svhn_loss: 0.0288, d_fake_loss: 0.0440, g_loss: 1.1226\n",
            "Step [32400/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0023, d_svhn_loss: 0.0580, d_fake_loss: 0.0484, g_loss: 1.0934\n",
            "Step [32410/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0011, d_svhn_loss: 0.0469, d_fake_loss: 0.0467, g_loss: 1.3569\n",
            "Step [32420/80000], d_real_loss: 0.1017, d_mnist_loss: 0.0029, d_svhn_loss: 0.0989, d_fake_loss: 0.1534, g_loss: 1.0788\n",
            "Step [32430/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0023, d_svhn_loss: 0.0406, d_fake_loss: 0.0450, g_loss: 1.0597\n",
            "Step [32440/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0169, d_svhn_loss: 0.0460, d_fake_loss: 0.0509, g_loss: 1.1872\n",
            "Step [32450/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0019, d_svhn_loss: 0.0434, d_fake_loss: 0.1059, g_loss: 1.1123\n",
            "Step [32460/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0031, d_svhn_loss: 0.0328, d_fake_loss: 0.0228, g_loss: 1.0915\n",
            "Step [32470/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0203, d_svhn_loss: 0.0343, d_fake_loss: 0.0835, g_loss: 0.9452\n",
            "Step [32480/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0163, d_svhn_loss: 0.0458, d_fake_loss: 0.0650, g_loss: 1.0378\n",
            "Step [32490/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0009, d_svhn_loss: 0.0587, d_fake_loss: 0.0726, g_loss: 1.1293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [32500/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0014, d_svhn_loss: 0.0231, d_fake_loss: 0.0255, g_loss: 1.0836\n",
            "saved ./samples_mnist_svhn/sample-32500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-32500-s-m.png\n",
            "Step [32510/80000], d_real_loss: 0.1198, d_mnist_loss: 0.0013, d_svhn_loss: 0.1186, d_fake_loss: 0.0338, g_loss: 1.1085\n",
            "Step [32520/80000], d_real_loss: 0.1045, d_mnist_loss: 0.0027, d_svhn_loss: 0.1018, d_fake_loss: 0.1666, g_loss: 1.1500\n",
            "Step [32530/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0077, d_svhn_loss: 0.0675, d_fake_loss: 0.0970, g_loss: 1.1986\n",
            "Step [32540/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0025, d_svhn_loss: 0.0511, d_fake_loss: 0.0413, g_loss: 1.0850\n",
            "Step [32550/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0016, d_svhn_loss: 0.0243, d_fake_loss: 0.0224, g_loss: 1.1732\n",
            "Step [32560/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0013, d_svhn_loss: 0.0233, d_fake_loss: 0.0231, g_loss: 1.1585\n",
            "Step [32570/80000], d_real_loss: 0.0955, d_mnist_loss: 0.0372, d_svhn_loss: 0.0584, d_fake_loss: 0.0225, g_loss: 1.0738\n",
            "Step [32580/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0077, d_svhn_loss: 0.0474, d_fake_loss: 0.0237, g_loss: 1.0499\n",
            "Step [32590/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0052, d_svhn_loss: 0.0234, d_fake_loss: 0.0236, g_loss: 1.0884\n",
            "Step [32600/80000], d_real_loss: 0.1633, d_mnist_loss: 0.0052, d_svhn_loss: 0.1581, d_fake_loss: 0.0193, g_loss: 1.0766\n",
            "Step [32610/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0022, d_svhn_loss: 0.0357, d_fake_loss: 0.0353, g_loss: 1.1150\n",
            "Step [32620/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0012, d_svhn_loss: 0.0219, d_fake_loss: 0.0276, g_loss: 1.0817\n",
            "Step [32630/80000], d_real_loss: 0.0865, d_mnist_loss: 0.0048, d_svhn_loss: 0.0816, d_fake_loss: 0.0216, g_loss: 1.1092\n",
            "Step [32640/80000], d_real_loss: 0.1574, d_mnist_loss: 0.0014, d_svhn_loss: 0.1560, d_fake_loss: 0.1515, g_loss: 1.1189\n",
            "Step [32650/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0008, d_svhn_loss: 0.0362, d_fake_loss: 0.1124, g_loss: 1.2212\n",
            "Step [32660/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0038, d_svhn_loss: 0.0434, d_fake_loss: 0.0636, g_loss: 1.1296\n",
            "Step [32670/80000], d_real_loss: 0.1066, d_mnist_loss: 0.0006, d_svhn_loss: 0.1060, d_fake_loss: 0.0363, g_loss: 1.1196\n",
            "Step [32680/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0007, d_svhn_loss: 0.0268, d_fake_loss: 0.0228, g_loss: 1.0955\n",
            "Step [32690/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0101, d_svhn_loss: 0.0159, d_fake_loss: 0.0406, g_loss: 1.1840\n",
            "Step [32700/80000], d_real_loss: 0.1161, d_mnist_loss: 0.0014, d_svhn_loss: 0.1147, d_fake_loss: 0.1028, g_loss: 1.0732\n",
            "Step [32710/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0076, d_svhn_loss: 0.0600, d_fake_loss: 0.0299, g_loss: 1.2020\n",
            "Step [32720/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0008, d_svhn_loss: 0.0586, d_fake_loss: 0.0197, g_loss: 1.1258\n",
            "Step [32730/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0171, d_svhn_loss: 0.0343, d_fake_loss: 0.0352, g_loss: 1.0741\n",
            "Step [32740/80000], d_real_loss: 0.1246, d_mnist_loss: 0.0015, d_svhn_loss: 0.1230, d_fake_loss: 0.0760, g_loss: 1.1654\n",
            "Step [32750/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0013, d_svhn_loss: 0.0791, d_fake_loss: 0.0271, g_loss: 1.1330\n",
            "Step [32760/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0054, d_svhn_loss: 0.0189, d_fake_loss: 0.0680, g_loss: 1.0704\n",
            "Step [32770/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0034, d_svhn_loss: 0.0391, d_fake_loss: 0.0263, g_loss: 1.1107\n",
            "Step [32780/80000], d_real_loss: 0.0986, d_mnist_loss: 0.0010, d_svhn_loss: 0.0976, d_fake_loss: 0.1428, g_loss: 1.1021\n",
            "Step [32790/80000], d_real_loss: 0.0965, d_mnist_loss: 0.0197, d_svhn_loss: 0.0768, d_fake_loss: 0.0300, g_loss: 1.3404\n",
            "Step [32800/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0066, d_svhn_loss: 0.0310, d_fake_loss: 0.0500, g_loss: 1.1170\n",
            "Step [32810/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0016, d_svhn_loss: 0.0695, d_fake_loss: 0.1273, g_loss: 1.2401\n",
            "Step [32820/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0118, d_svhn_loss: 0.0270, d_fake_loss: 0.0399, g_loss: 1.1707\n",
            "Step [32830/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0022, d_svhn_loss: 0.0471, d_fake_loss: 0.0346, g_loss: 1.0606\n",
            "Step [32840/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0030, d_svhn_loss: 0.0489, d_fake_loss: 0.0329, g_loss: 1.0340\n",
            "Step [32850/80000], d_real_loss: 0.1136, d_mnist_loss: 0.0294, d_svhn_loss: 0.0841, d_fake_loss: 0.0590, g_loss: 1.2103\n",
            "Step [32860/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0044, d_svhn_loss: 0.0314, d_fake_loss: 0.0242, g_loss: 1.1862\n",
            "Step [32870/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0052, d_svhn_loss: 0.0337, d_fake_loss: 0.0670, g_loss: 1.0529\n",
            "Step [32880/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0015, d_svhn_loss: 0.0337, d_fake_loss: 0.0336, g_loss: 1.1233\n",
            "Step [32890/80000], d_real_loss: 0.1203, d_mnist_loss: 0.0007, d_svhn_loss: 0.1195, d_fake_loss: 0.0672, g_loss: 1.1162\n",
            "Step [32900/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0027, d_svhn_loss: 0.0227, d_fake_loss: 0.0230, g_loss: 1.1704\n",
            "Step [32910/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0010, d_svhn_loss: 0.0296, d_fake_loss: 0.0472, g_loss: 1.1350\n",
            "Step [32920/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0019, d_svhn_loss: 0.0241, d_fake_loss: 0.0291, g_loss: 1.1622\n",
            "Step [32930/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0005, d_svhn_loss: 0.0389, d_fake_loss: 0.0218, g_loss: 1.1302\n",
            "Step [32940/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0014, d_svhn_loss: 0.0275, d_fake_loss: 0.0761, g_loss: 1.1342\n",
            "Step [32950/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0131, d_svhn_loss: 0.0241, d_fake_loss: 0.0736, g_loss: 1.1179\n",
            "Step [32960/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0012, d_svhn_loss: 0.0242, d_fake_loss: 0.0743, g_loss: 1.1279\n",
            "Step [32970/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0023, d_svhn_loss: 0.0256, d_fake_loss: 0.0685, g_loss: 1.1283\n",
            "Step [32980/80000], d_real_loss: 0.2179, d_mnist_loss: 0.0332, d_svhn_loss: 0.1847, d_fake_loss: 0.1614, g_loss: 1.4351\n",
            "Step [32990/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0021, d_svhn_loss: 0.0282, d_fake_loss: 0.0359, g_loss: 1.1148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [33000/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0009, d_svhn_loss: 0.0389, d_fake_loss: 0.0382, g_loss: 1.2289\n",
            "saved ./samples_mnist_svhn/sample-33000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-33000-s-m.png\n",
            "Step [33010/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0008, d_svhn_loss: 0.0530, d_fake_loss: 0.0315, g_loss: 1.1030\n",
            "Step [33020/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0014, d_svhn_loss: 0.0337, d_fake_loss: 0.1013, g_loss: 1.0876\n",
            "Step [33030/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0041, d_svhn_loss: 0.0635, d_fake_loss: 0.0432, g_loss: 1.1512\n",
            "Step [33040/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0021, d_svhn_loss: 0.0353, d_fake_loss: 0.0393, g_loss: 1.0757\n",
            "Step [33050/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0016, d_svhn_loss: 0.0608, d_fake_loss: 0.0214, g_loss: 1.0996\n",
            "Step [33060/80000], d_real_loss: 0.0781, d_mnist_loss: 0.0006, d_svhn_loss: 0.0775, d_fake_loss: 0.0618, g_loss: 1.0912\n",
            "Step [33070/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0031, d_svhn_loss: 0.0298, d_fake_loss: 0.0890, g_loss: 1.1508\n",
            "Step [33080/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0005, d_svhn_loss: 0.0325, d_fake_loss: 0.2072, g_loss: 1.1713\n",
            "Step [33090/80000], d_real_loss: 0.2001, d_mnist_loss: 0.1601, d_svhn_loss: 0.0400, d_fake_loss: 0.1043, g_loss: 1.1566\n",
            "Step [33100/80000], d_real_loss: 0.1169, d_mnist_loss: 0.0207, d_svhn_loss: 0.0962, d_fake_loss: 0.0252, g_loss: 1.0538\n",
            "Step [33110/80000], d_real_loss: 0.1372, d_mnist_loss: 0.0108, d_svhn_loss: 0.1264, d_fake_loss: 0.0347, g_loss: 1.0905\n",
            "Step [33120/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0116, d_svhn_loss: 0.0365, d_fake_loss: 0.0903, g_loss: 1.2225\n",
            "Step [33130/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0028, d_svhn_loss: 0.0544, d_fake_loss: 0.0419, g_loss: 1.1114\n",
            "Step [33140/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0028, d_svhn_loss: 0.0345, d_fake_loss: 0.0425, g_loss: 1.3516\n",
            "Step [33150/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0079, d_svhn_loss: 0.0278, d_fake_loss: 0.0425, g_loss: 1.1439\n",
            "Step [33160/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0015, d_svhn_loss: 0.0380, d_fake_loss: 0.0590, g_loss: 1.2097\n",
            "Step [33170/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0026, d_svhn_loss: 0.0429, d_fake_loss: 0.0990, g_loss: 1.1401\n",
            "Step [33180/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0101, d_svhn_loss: 0.0427, d_fake_loss: 0.1549, g_loss: 1.0705\n",
            "Step [33190/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0022, d_svhn_loss: 0.0396, d_fake_loss: 0.0828, g_loss: 1.3195\n",
            "Step [33200/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0020, d_svhn_loss: 0.0605, d_fake_loss: 0.0719, g_loss: 1.1336\n",
            "Step [33210/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0017, d_svhn_loss: 0.0335, d_fake_loss: 0.0340, g_loss: 1.1889\n",
            "Step [33220/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0048, d_svhn_loss: 0.0206, d_fake_loss: 0.0227, g_loss: 1.1558\n",
            "Step [33230/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0009, d_svhn_loss: 0.0575, d_fake_loss: 0.0746, g_loss: 1.2091\n",
            "Step [33240/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0020, d_svhn_loss: 0.0325, d_fake_loss: 0.0535, g_loss: 1.1353\n",
            "Step [33250/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0165, d_svhn_loss: 0.0469, d_fake_loss: 0.0686, g_loss: 1.0833\n",
            "Step [33260/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0041, d_svhn_loss: 0.0411, d_fake_loss: 0.0328, g_loss: 1.3468\n",
            "Step [33270/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0042, d_svhn_loss: 0.0403, d_fake_loss: 0.0311, g_loss: 1.1208\n",
            "Step [33280/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0013, d_svhn_loss: 0.0528, d_fake_loss: 0.0222, g_loss: 1.2263\n",
            "Step [33290/80000], d_real_loss: 0.0385, d_mnist_loss: 0.0019, d_svhn_loss: 0.0366, d_fake_loss: 0.0508, g_loss: 1.1294\n",
            "Step [33300/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0037, d_svhn_loss: 0.0562, d_fake_loss: 0.1035, g_loss: 1.1422\n",
            "Step [33310/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0041, d_svhn_loss: 0.0360, d_fake_loss: 0.0228, g_loss: 1.2120\n",
            "Step [33320/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0012, d_svhn_loss: 0.0193, d_fake_loss: 0.0285, g_loss: 1.1553\n",
            "Step [33330/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0015, d_svhn_loss: 0.0699, d_fake_loss: 0.0442, g_loss: 1.1694\n",
            "Step [33340/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0026, d_svhn_loss: 0.0438, d_fake_loss: 0.0512, g_loss: 1.1400\n",
            "Step [33350/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0037, d_svhn_loss: 0.0515, d_fake_loss: 0.0595, g_loss: 1.2175\n",
            "Step [33360/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0044, d_svhn_loss: 0.0171, d_fake_loss: 0.0393, g_loss: 1.1315\n",
            "Step [33370/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0010, d_svhn_loss: 0.0305, d_fake_loss: 0.0236, g_loss: 1.2136\n",
            "Step [33380/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0043, d_svhn_loss: 0.0264, d_fake_loss: 0.0408, g_loss: 1.0671\n",
            "Step [33390/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0020, d_svhn_loss: 0.0226, d_fake_loss: 0.0950, g_loss: 1.1286\n",
            "Step [33400/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0025, d_svhn_loss: 0.0457, d_fake_loss: 0.1684, g_loss: 1.2039\n",
            "Step [33410/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0027, d_svhn_loss: 0.0313, d_fake_loss: 0.0256, g_loss: 1.1844\n",
            "Step [33420/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0047, d_svhn_loss: 0.0269, d_fake_loss: 0.0288, g_loss: 1.0703\n",
            "Step [33430/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0020, d_svhn_loss: 0.0360, d_fake_loss: 0.0249, g_loss: 1.2648\n",
            "Step [33440/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0057, d_svhn_loss: 0.0281, d_fake_loss: 0.0423, g_loss: 1.2497\n",
            "Step [33450/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0018, d_svhn_loss: 0.0292, d_fake_loss: 0.0547, g_loss: 1.0765\n",
            "Step [33460/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0009, d_svhn_loss: 0.0320, d_fake_loss: 0.0854, g_loss: 1.1673\n",
            "Step [33470/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0013, d_svhn_loss: 0.0358, d_fake_loss: 0.0302, g_loss: 1.3411\n",
            "Step [33480/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0016, d_svhn_loss: 0.0364, d_fake_loss: 0.0283, g_loss: 1.1373\n",
            "Step [33490/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0019, d_svhn_loss: 0.0494, d_fake_loss: 0.0321, g_loss: 1.1379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [33500/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0020, d_svhn_loss: 0.0271, d_fake_loss: 0.0341, g_loss: 1.1547\n",
            "saved ./samples_mnist_svhn/sample-33500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-33500-s-m.png\n",
            "Step [33510/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0072, d_svhn_loss: 0.0343, d_fake_loss: 0.0437, g_loss: 1.1632\n",
            "Step [33520/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0022, d_svhn_loss: 0.0205, d_fake_loss: 0.0253, g_loss: 1.1171\n",
            "Step [33530/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0085, d_svhn_loss: 0.0431, d_fake_loss: 0.0267, g_loss: 1.3909\n",
            "Step [33540/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0020, d_svhn_loss: 0.0263, d_fake_loss: 0.0274, g_loss: 1.1420\n",
            "Step [33550/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0082, d_svhn_loss: 0.0261, d_fake_loss: 0.0337, g_loss: 1.4601\n",
            "Step [33560/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0025, d_svhn_loss: 0.0268, d_fake_loss: 0.0336, g_loss: 1.0995\n",
            "Step [33570/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0223, d_svhn_loss: 0.0287, d_fake_loss: 0.0396, g_loss: 1.1880\n",
            "Step [33580/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0009, d_svhn_loss: 0.0582, d_fake_loss: 0.1179, g_loss: 1.1426\n",
            "Step [33590/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0037, d_svhn_loss: 0.0305, d_fake_loss: 0.0293, g_loss: 1.1841\n",
            "Step [33600/80000], d_real_loss: 0.1661, d_mnist_loss: 0.0143, d_svhn_loss: 0.1518, d_fake_loss: 0.0706, g_loss: 1.2243\n",
            "Step [33610/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0034, d_svhn_loss: 0.0687, d_fake_loss: 0.0480, g_loss: 1.1448\n",
            "Step [33620/80000], d_real_loss: 0.0159, d_mnist_loss: 0.0010, d_svhn_loss: 0.0149, d_fake_loss: 0.0680, g_loss: 1.1038\n",
            "Step [33630/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0046, d_svhn_loss: 0.0372, d_fake_loss: 0.0455, g_loss: 0.9267\n",
            "Step [33640/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0152, d_svhn_loss: 0.0304, d_fake_loss: 0.0594, g_loss: 1.3003\n",
            "Step [33650/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0050, d_svhn_loss: 0.0403, d_fake_loss: 0.0381, g_loss: 1.1403\n",
            "Step [33660/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0375, d_svhn_loss: 0.0194, d_fake_loss: 0.0289, g_loss: 0.9135\n",
            "Step [33670/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0033, d_svhn_loss: 0.0751, d_fake_loss: 0.0472, g_loss: 1.1067\n",
            "Step [33680/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0023, d_svhn_loss: 0.0358, d_fake_loss: 0.0293, g_loss: 1.1150\n",
            "Step [33690/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0018, d_svhn_loss: 0.0313, d_fake_loss: 0.0628, g_loss: 1.1327\n",
            "Step [33700/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0059, d_svhn_loss: 0.0520, d_fake_loss: 0.0264, g_loss: 1.0914\n",
            "Step [33710/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0025, d_svhn_loss: 0.0308, d_fake_loss: 0.0531, g_loss: 1.1482\n",
            "Step [33720/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0021, d_svhn_loss: 0.0372, d_fake_loss: 0.0367, g_loss: 1.1450\n",
            "Step [33730/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0018, d_svhn_loss: 0.0245, d_fake_loss: 0.0358, g_loss: 1.1167\n",
            "Step [33740/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0024, d_svhn_loss: 0.0329, d_fake_loss: 0.0157, g_loss: 1.1013\n",
            "Step [33750/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0011, d_svhn_loss: 0.0205, d_fake_loss: 0.0157, g_loss: 1.1253\n",
            "Step [33760/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0024, d_svhn_loss: 0.0261, d_fake_loss: 0.0264, g_loss: 1.0864\n",
            "Step [33770/80000], d_real_loss: 0.2217, d_mnist_loss: 0.0032, d_svhn_loss: 0.2185, d_fake_loss: 0.2324, g_loss: 1.0989\n",
            "Step [33780/80000], d_real_loss: 0.1628, d_mnist_loss: 0.0071, d_svhn_loss: 0.1556, d_fake_loss: 0.1148, g_loss: 1.0599\n",
            "Step [33790/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0028, d_svhn_loss: 0.0293, d_fake_loss: 0.1042, g_loss: 1.1081\n",
            "Step [33800/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0039, d_svhn_loss: 0.0240, d_fake_loss: 0.0328, g_loss: 1.1392\n",
            "Step [33810/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0009, d_svhn_loss: 0.0269, d_fake_loss: 0.0273, g_loss: 1.1093\n",
            "Step [33820/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0016, d_svhn_loss: 0.0349, d_fake_loss: 0.0333, g_loss: 1.1391\n",
            "Step [33830/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0015, d_svhn_loss: 0.0260, d_fake_loss: 0.0627, g_loss: 1.1223\n",
            "Step [33840/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0010, d_svhn_loss: 0.0742, d_fake_loss: 0.0257, g_loss: 1.0967\n",
            "Step [33850/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0054, d_svhn_loss: 0.0323, d_fake_loss: 0.0189, g_loss: 1.1266\n",
            "Step [33860/80000], d_real_loss: 0.1122, d_mnist_loss: 0.0015, d_svhn_loss: 0.1108, d_fake_loss: 0.0764, g_loss: 1.1075\n",
            "Step [33870/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0026, d_svhn_loss: 0.0703, d_fake_loss: 0.2090, g_loss: 1.1133\n",
            "Step [33880/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0015, d_svhn_loss: 0.0256, d_fake_loss: 0.0180, g_loss: 1.0904\n",
            "Step [33890/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0026, d_svhn_loss: 0.0300, d_fake_loss: 0.0349, g_loss: 1.1091\n",
            "Step [33900/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0044, d_svhn_loss: 0.0447, d_fake_loss: 0.0269, g_loss: 1.1161\n",
            "Step [33910/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0064, d_svhn_loss: 0.0661, d_fake_loss: 0.1318, g_loss: 1.0679\n",
            "Step [33920/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0015, d_svhn_loss: 0.0213, d_fake_loss: 0.0228, g_loss: 1.1091\n",
            "Step [33930/80000], d_real_loss: 0.2205, d_mnist_loss: 0.0009, d_svhn_loss: 0.2197, d_fake_loss: 0.1521, g_loss: 1.1373\n",
            "Step [33940/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0039, d_svhn_loss: 0.0358, d_fake_loss: 0.0359, g_loss: 1.1409\n",
            "Step [33950/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0036, d_svhn_loss: 0.0345, d_fake_loss: 0.0401, g_loss: 1.1486\n",
            "Step [33960/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0031, d_svhn_loss: 0.0201, d_fake_loss: 0.0719, g_loss: 1.1438\n",
            "Step [33970/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0022, d_svhn_loss: 0.0562, d_fake_loss: 0.0413, g_loss: 1.1387\n",
            "Step [33980/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0013, d_svhn_loss: 0.0337, d_fake_loss: 0.0574, g_loss: 1.1556\n",
            "Step [33990/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0059, d_svhn_loss: 0.0343, d_fake_loss: 0.0212, g_loss: 1.0642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [34000/80000], d_real_loss: 0.0754, d_mnist_loss: 0.0108, d_svhn_loss: 0.0646, d_fake_loss: 0.0584, g_loss: 1.1636\n",
            "saved ./samples_mnist_svhn/sample-34000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-34000-s-m.png\n",
            "Step [34010/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0021, d_svhn_loss: 0.0479, d_fake_loss: 0.0298, g_loss: 1.1354\n",
            "Step [34020/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0009, d_svhn_loss: 0.0427, d_fake_loss: 0.0323, g_loss: 1.1454\n",
            "Step [34030/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0040, d_svhn_loss: 0.0239, d_fake_loss: 0.0811, g_loss: 1.1378\n",
            "Step [34040/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0009, d_svhn_loss: 0.0397, d_fake_loss: 0.0316, g_loss: 1.1201\n",
            "Step [34050/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0013, d_svhn_loss: 0.0223, d_fake_loss: 0.0430, g_loss: 1.1087\n",
            "Step [34060/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0009, d_svhn_loss: 0.0324, d_fake_loss: 0.0149, g_loss: 1.1144\n",
            "Step [34070/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0019, d_svhn_loss: 0.0202, d_fake_loss: 0.0292, g_loss: 1.1189\n",
            "Step [34080/80000], d_real_loss: 0.1284, d_mnist_loss: 0.0088, d_svhn_loss: 0.1196, d_fake_loss: 0.1103, g_loss: 1.0986\n",
            "Step [34090/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0018, d_svhn_loss: 0.0321, d_fake_loss: 0.0298, g_loss: 1.1067\n",
            "Step [34100/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0014, d_svhn_loss: 0.0221, d_fake_loss: 0.0214, g_loss: 1.1514\n",
            "Step [34110/80000], d_real_loss: 0.0864, d_mnist_loss: 0.0015, d_svhn_loss: 0.0850, d_fake_loss: 0.0619, g_loss: 1.1980\n",
            "Step [34120/80000], d_real_loss: 0.0747, d_mnist_loss: 0.0009, d_svhn_loss: 0.0738, d_fake_loss: 0.0649, g_loss: 1.1014\n",
            "Step [34130/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0007, d_svhn_loss: 0.0686, d_fake_loss: 0.0631, g_loss: 1.1149\n",
            "Step [34140/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0006, d_svhn_loss: 0.0259, d_fake_loss: 0.0582, g_loss: 1.1118\n",
            "Step [34150/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0020, d_svhn_loss: 0.0259, d_fake_loss: 0.1503, g_loss: 1.0888\n",
            "Step [34160/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0014, d_svhn_loss: 0.0260, d_fake_loss: 0.0290, g_loss: 1.1159\n",
            "Step [34170/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0059, d_svhn_loss: 0.0393, d_fake_loss: 0.1046, g_loss: 1.1812\n",
            "Step [34180/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0040, d_svhn_loss: 0.0481, d_fake_loss: 0.0494, g_loss: 1.1733\n",
            "Step [34190/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0009, d_svhn_loss: 0.0424, d_fake_loss: 0.0719, g_loss: 1.1426\n",
            "Step [34200/80000], d_real_loss: 0.0776, d_mnist_loss: 0.0029, d_svhn_loss: 0.0748, d_fake_loss: 0.0686, g_loss: 1.1167\n",
            "Step [34210/80000], d_real_loss: 0.1146, d_mnist_loss: 0.0056, d_svhn_loss: 0.1090, d_fake_loss: 0.0466, g_loss: 1.1231\n",
            "Step [34220/80000], d_real_loss: 0.0174, d_mnist_loss: 0.0008, d_svhn_loss: 0.0166, d_fake_loss: 0.0231, g_loss: 1.1060\n",
            "Step [34230/80000], d_real_loss: 0.0945, d_mnist_loss: 0.0020, d_svhn_loss: 0.0926, d_fake_loss: 0.0304, g_loss: 1.1345\n",
            "Step [34240/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0016, d_svhn_loss: 0.0155, d_fake_loss: 0.0158, g_loss: 1.1574\n",
            "Step [34250/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0075, d_svhn_loss: 0.0616, d_fake_loss: 0.0721, g_loss: 1.1354\n",
            "Step [34260/80000], d_real_loss: 0.0988, d_mnist_loss: 0.0022, d_svhn_loss: 0.0965, d_fake_loss: 0.1161, g_loss: 1.2303\n",
            "Step [34270/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0030, d_svhn_loss: 0.0250, d_fake_loss: 0.0364, g_loss: 1.1529\n",
            "Step [34280/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0007, d_svhn_loss: 0.0282, d_fake_loss: 0.0197, g_loss: 1.1071\n",
            "Step [34290/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0069, d_svhn_loss: 0.0270, d_fake_loss: 0.1073, g_loss: 1.1108\n",
            "Step [34300/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0038, d_svhn_loss: 0.0407, d_fake_loss: 0.0130, g_loss: 1.0921\n",
            "Step [34310/80000], d_real_loss: 0.1709, d_mnist_loss: 0.0018, d_svhn_loss: 0.1692, d_fake_loss: 0.0331, g_loss: 1.1245\n",
            "Step [34320/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0009, d_svhn_loss: 0.0429, d_fake_loss: 0.0331, g_loss: 1.1737\n",
            "Step [34330/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0007, d_svhn_loss: 0.0429, d_fake_loss: 0.0223, g_loss: 1.0995\n",
            "Step [34340/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0045, d_svhn_loss: 0.0366, d_fake_loss: 0.0363, g_loss: 1.0924\n",
            "Step [34350/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0022, d_svhn_loss: 0.0675, d_fake_loss: 0.0257, g_loss: 1.2978\n",
            "Step [34360/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0009, d_svhn_loss: 0.0185, d_fake_loss: 0.0462, g_loss: 1.1071\n",
            "Step [34370/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0019, d_svhn_loss: 0.0238, d_fake_loss: 0.0313, g_loss: 1.2333\n",
            "Step [34380/80000], d_real_loss: 0.0946, d_mnist_loss: 0.0058, d_svhn_loss: 0.0888, d_fake_loss: 0.1041, g_loss: 1.2193\n",
            "Step [34390/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0015, d_svhn_loss: 0.0733, d_fake_loss: 0.0369, g_loss: 1.2396\n",
            "Step [34400/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0018, d_svhn_loss: 0.0337, d_fake_loss: 0.0951, g_loss: 1.0970\n",
            "Step [34410/80000], d_real_loss: 0.0957, d_mnist_loss: 0.0668, d_svhn_loss: 0.0289, d_fake_loss: 0.1013, g_loss: 1.6773\n",
            "Step [34420/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0479, d_svhn_loss: 0.0261, d_fake_loss: 0.1309, g_loss: 1.0086\n",
            "Step [34430/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0041, d_svhn_loss: 0.0448, d_fake_loss: 0.1345, g_loss: 1.1067\n",
            "Step [34440/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0037, d_svhn_loss: 0.0410, d_fake_loss: 0.0385, g_loss: 1.0576\n",
            "Step [34450/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0031, d_svhn_loss: 0.0650, d_fake_loss: 0.0388, g_loss: 1.1767\n",
            "Step [34460/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0029, d_svhn_loss: 0.0556, d_fake_loss: 0.1724, g_loss: 1.0510\n",
            "Step [34470/80000], d_real_loss: 0.1274, d_mnist_loss: 0.0010, d_svhn_loss: 0.1264, d_fake_loss: 0.0399, g_loss: 1.1552\n",
            "Step [34480/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0035, d_svhn_loss: 0.0345, d_fake_loss: 0.0222, g_loss: 1.1570\n",
            "Step [34490/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0010, d_svhn_loss: 0.0510, d_fake_loss: 0.0797, g_loss: 1.1129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [34500/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0030, d_svhn_loss: 0.0164, d_fake_loss: 0.0176, g_loss: 1.0972\n",
            "saved ./samples_mnist_svhn/sample-34500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-34500-s-m.png\n",
            "Step [34510/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0353, d_svhn_loss: 0.0268, d_fake_loss: 0.0392, g_loss: 1.1483\n",
            "Step [34520/80000], d_real_loss: 0.2731, d_mnist_loss: 0.0126, d_svhn_loss: 0.2605, d_fake_loss: 0.0747, g_loss: 1.1365\n",
            "Step [34530/80000], d_real_loss: 0.1388, d_mnist_loss: 0.0024, d_svhn_loss: 0.1364, d_fake_loss: 0.0493, g_loss: 1.0766\n",
            "Step [34540/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0020, d_svhn_loss: 0.0748, d_fake_loss: 0.0281, g_loss: 1.0957\n",
            "Step [34550/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0015, d_svhn_loss: 0.0395, d_fake_loss: 0.0339, g_loss: 1.0826\n",
            "Step [34560/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0035, d_svhn_loss: 0.0353, d_fake_loss: 0.0664, g_loss: 1.1092\n",
            "Step [34570/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0040, d_svhn_loss: 0.0210, d_fake_loss: 0.0341, g_loss: 1.1619\n",
            "Step [34580/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0094, d_svhn_loss: 0.0303, d_fake_loss: 0.0268, g_loss: 1.0982\n",
            "Step [34590/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0021, d_svhn_loss: 0.0347, d_fake_loss: 0.0326, g_loss: 1.1059\n",
            "Step [34600/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0010, d_svhn_loss: 0.0318, d_fake_loss: 0.0285, g_loss: 1.1369\n",
            "Step [34610/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0016, d_svhn_loss: 0.0268, d_fake_loss: 0.0453, g_loss: 1.1155\n",
            "Step [34620/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0015, d_svhn_loss: 0.0347, d_fake_loss: 0.0564, g_loss: 1.3461\n",
            "Step [34630/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0011, d_svhn_loss: 0.0409, d_fake_loss: 0.0382, g_loss: 1.1015\n",
            "Step [34640/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0015, d_svhn_loss: 0.0254, d_fake_loss: 0.0343, g_loss: 1.1692\n",
            "Step [34650/80000], d_real_loss: 0.1457, d_mnist_loss: 0.0031, d_svhn_loss: 0.1426, d_fake_loss: 0.0680, g_loss: 1.1099\n",
            "Step [34660/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0008, d_svhn_loss: 0.0362, d_fake_loss: 0.1998, g_loss: 1.0983\n",
            "Step [34670/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0071, d_svhn_loss: 0.0360, d_fake_loss: 0.0653, g_loss: 1.0861\n",
            "Step [34680/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0301, d_svhn_loss: 0.0426, d_fake_loss: 0.0434, g_loss: 1.1209\n",
            "Step [34690/80000], d_real_loss: 0.1350, d_mnist_loss: 0.0011, d_svhn_loss: 0.1339, d_fake_loss: 0.0417, g_loss: 1.1112\n",
            "Step [34700/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0048, d_svhn_loss: 0.0387, d_fake_loss: 0.0254, g_loss: 1.2324\n",
            "Step [34710/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0022, d_svhn_loss: 0.0293, d_fake_loss: 0.1058, g_loss: 1.1419\n",
            "Step [34720/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0020, d_svhn_loss: 0.0319, d_fake_loss: 0.0281, g_loss: 1.1521\n",
            "Step [34730/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0108, d_svhn_loss: 0.0215, d_fake_loss: 0.0380, g_loss: 1.1894\n",
            "Step [34740/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0009, d_svhn_loss: 0.0248, d_fake_loss: 0.0302, g_loss: 1.1541\n",
            "Step [34750/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0030, d_svhn_loss: 0.0332, d_fake_loss: 0.0377, g_loss: 1.1693\n",
            "Step [34760/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0044, d_svhn_loss: 0.0270, d_fake_loss: 0.0291, g_loss: 1.2267\n",
            "Step [34770/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0006, d_svhn_loss: 0.0399, d_fake_loss: 0.0182, g_loss: 1.1132\n",
            "Step [34780/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0032, d_svhn_loss: 0.0289, d_fake_loss: 0.0659, g_loss: 1.1991\n",
            "Step [34790/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0013, d_svhn_loss: 0.0196, d_fake_loss: 0.0966, g_loss: 1.0999\n",
            "Step [34800/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0043, d_svhn_loss: 0.0203, d_fake_loss: 0.0223, g_loss: 1.0706\n",
            "Step [34810/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0048, d_svhn_loss: 0.0407, d_fake_loss: 0.0203, g_loss: 1.2528\n",
            "Step [34820/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0060, d_svhn_loss: 0.0268, d_fake_loss: 0.0367, g_loss: 1.2503\n",
            "Step [34830/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0027, d_svhn_loss: 0.0644, d_fake_loss: 0.0650, g_loss: 1.1669\n",
            "Step [34840/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0006, d_svhn_loss: 0.0678, d_fake_loss: 0.0377, g_loss: 1.1232\n",
            "Step [34850/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0012, d_svhn_loss: 0.0173, d_fake_loss: 0.0809, g_loss: 1.3234\n",
            "Step [34860/80000], d_real_loss: 0.1239, d_mnist_loss: 0.0013, d_svhn_loss: 0.1225, d_fake_loss: 0.0481, g_loss: 1.1856\n",
            "Step [34870/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0016, d_svhn_loss: 0.0293, d_fake_loss: 0.0384, g_loss: 1.2022\n",
            "Step [34880/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0158, d_svhn_loss: 0.0298, d_fake_loss: 0.0360, g_loss: 1.4396\n",
            "Step [34890/80000], d_real_loss: 0.1598, d_mnist_loss: 0.1309, d_svhn_loss: 0.0289, d_fake_loss: 0.0275, g_loss: 1.3781\n",
            "Step [34900/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0151, d_svhn_loss: 0.0628, d_fake_loss: 0.0373, g_loss: 1.3068\n",
            "Step [34910/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0163, d_svhn_loss: 0.0206, d_fake_loss: 0.0575, g_loss: 1.2110\n",
            "Step [34920/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0033, d_svhn_loss: 0.0387, d_fake_loss: 0.0440, g_loss: 1.2459\n",
            "Step [34930/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0023, d_svhn_loss: 0.0445, d_fake_loss: 0.0471, g_loss: 1.1920\n",
            "Step [34940/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0017, d_svhn_loss: 0.0166, d_fake_loss: 0.0656, g_loss: 1.2052\n",
            "Step [34950/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0025, d_svhn_loss: 0.0268, d_fake_loss: 0.0313, g_loss: 1.1586\n",
            "Step [34960/80000], d_real_loss: 0.1572, d_mnist_loss: 0.0022, d_svhn_loss: 0.1549, d_fake_loss: 0.1002, g_loss: 1.1758\n",
            "Step [34970/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0013, d_svhn_loss: 0.0710, d_fake_loss: 0.0295, g_loss: 1.1378\n",
            "Step [34980/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0010, d_svhn_loss: 0.0221, d_fake_loss: 0.0222, g_loss: 1.1850\n",
            "Step [34990/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0086, d_svhn_loss: 0.0816, d_fake_loss: 0.0554, g_loss: 1.1788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [35000/80000], d_real_loss: 0.0899, d_mnist_loss: 0.0574, d_svhn_loss: 0.0325, d_fake_loss: 0.0387, g_loss: 1.3305\n",
            "saved ./samples_mnist_svhn/sample-35000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-35000-s-m.png\n",
            "Step [35010/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0020, d_svhn_loss: 0.0260, d_fake_loss: 0.0363, g_loss: 1.1360\n",
            "Step [35020/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0009, d_svhn_loss: 0.0291, d_fake_loss: 0.0194, g_loss: 1.1511\n",
            "Step [35030/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0024, d_svhn_loss: 0.0794, d_fake_loss: 0.0272, g_loss: 1.1927\n",
            "Step [35040/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0032, d_svhn_loss: 0.0151, d_fake_loss: 0.0348, g_loss: 1.1643\n",
            "Step [35050/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0033, d_svhn_loss: 0.0345, d_fake_loss: 0.0534, g_loss: 1.1212\n",
            "Step [35060/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0110, d_svhn_loss: 0.0178, d_fake_loss: 0.0451, g_loss: 1.1651\n",
            "Step [35070/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0062, d_svhn_loss: 0.0454, d_fake_loss: 0.0261, g_loss: 1.1807\n",
            "Step [35080/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0010, d_svhn_loss: 0.0206, d_fake_loss: 0.0269, g_loss: 1.1389\n",
            "Step [35090/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0034, d_svhn_loss: 0.0366, d_fake_loss: 0.0359, g_loss: 1.1423\n",
            "Step [35100/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0034, d_svhn_loss: 0.0321, d_fake_loss: 0.0509, g_loss: 1.0895\n",
            "Step [35110/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0019, d_svhn_loss: 0.0471, d_fake_loss: 0.0515, g_loss: 1.1335\n",
            "Step [35120/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0037, d_svhn_loss: 0.0311, d_fake_loss: 0.0201, g_loss: 1.1466\n",
            "Step [35130/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0020, d_svhn_loss: 0.0565, d_fake_loss: 0.0375, g_loss: 1.1153\n",
            "Step [35140/80000], d_real_loss: 0.1499, d_mnist_loss: 0.0016, d_svhn_loss: 0.1482, d_fake_loss: 0.0749, g_loss: 1.0991\n",
            "Step [35150/80000], d_real_loss: 0.1379, d_mnist_loss: 0.0020, d_svhn_loss: 0.1359, d_fake_loss: 0.0680, g_loss: 1.1840\n",
            "Step [35160/80000], d_real_loss: 0.0989, d_mnist_loss: 0.0029, d_svhn_loss: 0.0960, d_fake_loss: 0.0422, g_loss: 1.1307\n",
            "Step [35170/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0038, d_svhn_loss: 0.0386, d_fake_loss: 0.0445, g_loss: 1.2321\n",
            "Step [35180/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0011, d_svhn_loss: 0.0480, d_fake_loss: 0.0601, g_loss: 1.1533\n",
            "Step [35190/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0039, d_svhn_loss: 0.0263, d_fake_loss: 0.0345, g_loss: 1.1506\n",
            "Step [35200/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0022, d_svhn_loss: 0.0338, d_fake_loss: 0.1406, g_loss: 1.2600\n",
            "Step [35210/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0020, d_svhn_loss: 0.0336, d_fake_loss: 0.0627, g_loss: 1.0920\n",
            "Step [35220/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0008, d_svhn_loss: 0.0540, d_fake_loss: 0.2101, g_loss: 1.1606\n",
            "Step [35230/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0066, d_svhn_loss: 0.0215, d_fake_loss: 0.0426, g_loss: 1.1564\n",
            "Step [35240/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0043, d_svhn_loss: 0.0832, d_fake_loss: 0.0526, g_loss: 1.0519\n",
            "Step [35250/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0014, d_svhn_loss: 0.0431, d_fake_loss: 0.0312, g_loss: 1.1044\n",
            "Step [35260/80000], d_real_loss: 0.1658, d_mnist_loss: 0.0040, d_svhn_loss: 0.1618, d_fake_loss: 0.0341, g_loss: 1.1931\n",
            "Step [35270/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0016, d_svhn_loss: 0.0194, d_fake_loss: 0.0274, g_loss: 1.1325\n",
            "Step [35280/80000], d_real_loss: 0.0948, d_mnist_loss: 0.0084, d_svhn_loss: 0.0864, d_fake_loss: 0.0406, g_loss: 1.0968\n",
            "Step [35290/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0012, d_svhn_loss: 0.0404, d_fake_loss: 0.0236, g_loss: 1.0968\n",
            "Step [35300/80000], d_real_loss: 0.0126, d_mnist_loss: 0.0014, d_svhn_loss: 0.0112, d_fake_loss: 0.0435, g_loss: 1.1075\n",
            "Step [35310/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0018, d_svhn_loss: 0.0754, d_fake_loss: 0.1021, g_loss: 1.0805\n",
            "Step [35320/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0027, d_svhn_loss: 0.0395, d_fake_loss: 0.0237, g_loss: 1.1150\n",
            "Step [35330/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0013, d_svhn_loss: 0.0386, d_fake_loss: 0.0474, g_loss: 1.1660\n",
            "Step [35340/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0128, d_svhn_loss: 0.0194, d_fake_loss: 0.0538, g_loss: 1.1410\n",
            "Step [35350/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0030, d_svhn_loss: 0.0582, d_fake_loss: 0.1369, g_loss: 1.0506\n",
            "Step [35360/80000], d_real_loss: 0.0142, d_mnist_loss: 0.0009, d_svhn_loss: 0.0134, d_fake_loss: 0.0254, g_loss: 1.1439\n",
            "Step [35370/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0034, d_svhn_loss: 0.0539, d_fake_loss: 0.0369, g_loss: 1.1417\n",
            "Step [35380/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0015, d_svhn_loss: 0.0288, d_fake_loss: 0.0610, g_loss: 1.0473\n",
            "Step [35390/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0014, d_svhn_loss: 0.0195, d_fake_loss: 0.0368, g_loss: 1.0959\n",
            "Step [35400/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0014, d_svhn_loss: 0.0341, d_fake_loss: 0.0281, g_loss: 1.1403\n",
            "Step [35410/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0056, d_svhn_loss: 0.0207, d_fake_loss: 0.0715, g_loss: 1.0545\n",
            "Step [35420/80000], d_real_loss: 0.0755, d_mnist_loss: 0.0081, d_svhn_loss: 0.0675, d_fake_loss: 0.0817, g_loss: 1.0590\n",
            "Step [35430/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0014, d_svhn_loss: 0.0439, d_fake_loss: 0.0328, g_loss: 1.0864\n",
            "Step [35440/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0019, d_svhn_loss: 0.0280, d_fake_loss: 0.0200, g_loss: 1.0994\n",
            "Step [35450/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0019, d_svhn_loss: 0.0292, d_fake_loss: 0.0331, g_loss: 1.1666\n",
            "Step [35460/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0032, d_svhn_loss: 0.0175, d_fake_loss: 0.0264, g_loss: 1.0667\n",
            "Step [35470/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0012, d_svhn_loss: 0.0498, d_fake_loss: 0.0629, g_loss: 1.1356\n",
            "Step [35480/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0048, d_svhn_loss: 0.0424, d_fake_loss: 0.0241, g_loss: 1.1562\n",
            "Step [35490/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0006, d_svhn_loss: 0.0303, d_fake_loss: 0.0301, g_loss: 1.1187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [35500/80000], d_real_loss: 0.1223, d_mnist_loss: 0.0012, d_svhn_loss: 0.1211, d_fake_loss: 0.0190, g_loss: 1.1084\n",
            "saved ./samples_mnist_svhn/sample-35500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-35500-s-m.png\n",
            "Step [35510/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0011, d_svhn_loss: 0.0275, d_fake_loss: 0.0637, g_loss: 1.1284\n",
            "Step [35520/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0062, d_svhn_loss: 0.0296, d_fake_loss: 0.0227, g_loss: 1.0631\n",
            "Step [35530/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0007, d_svhn_loss: 0.0710, d_fake_loss: 0.0239, g_loss: 1.1686\n",
            "Step [35540/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0101, d_svhn_loss: 0.0655, d_fake_loss: 0.0760, g_loss: 1.0673\n",
            "Step [35550/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0034, d_svhn_loss: 0.0239, d_fake_loss: 0.0216, g_loss: 1.1294\n",
            "Step [35560/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0051, d_svhn_loss: 0.0204, d_fake_loss: 0.0191, g_loss: 1.0653\n",
            "Step [35570/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0008, d_svhn_loss: 0.0343, d_fake_loss: 0.1001, g_loss: 1.1183\n",
            "Step [35580/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0006, d_svhn_loss: 0.0689, d_fake_loss: 0.0334, g_loss: 1.1722\n",
            "Step [35590/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0108, d_svhn_loss: 0.0488, d_fake_loss: 0.0272, g_loss: 1.1407\n",
            "Step [35600/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0008, d_svhn_loss: 0.0445, d_fake_loss: 0.0238, g_loss: 1.1237\n",
            "Step [35610/80000], d_real_loss: 0.0147, d_mnist_loss: 0.0006, d_svhn_loss: 0.0141, d_fake_loss: 0.0584, g_loss: 1.1940\n",
            "Step [35620/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0004, d_svhn_loss: 0.0213, d_fake_loss: 0.0419, g_loss: 1.1131\n",
            "Step [35630/80000], d_real_loss: 0.1041, d_mnist_loss: 0.0013, d_svhn_loss: 0.1028, d_fake_loss: 0.0130, g_loss: 1.1171\n",
            "Step [35640/80000], d_real_loss: 0.1609, d_mnist_loss: 0.0013, d_svhn_loss: 0.1596, d_fake_loss: 0.0308, g_loss: 1.0863\n",
            "Step [35650/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0015, d_svhn_loss: 0.0701, d_fake_loss: 0.0273, g_loss: 1.1208\n",
            "Step [35660/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0007, d_svhn_loss: 0.0657, d_fake_loss: 0.0311, g_loss: 1.1113\n",
            "Step [35670/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0007, d_svhn_loss: 0.0701, d_fake_loss: 0.0925, g_loss: 1.0888\n",
            "Step [35680/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0008, d_svhn_loss: 0.0340, d_fake_loss: 0.0768, g_loss: 1.1138\n",
            "Step [35690/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0038, d_svhn_loss: 0.0286, d_fake_loss: 0.0217, g_loss: 1.1215\n",
            "Step [35700/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0030, d_svhn_loss: 0.0358, d_fake_loss: 0.0318, g_loss: 1.0893\n",
            "Step [35710/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0009, d_svhn_loss: 0.0191, d_fake_loss: 0.0260, g_loss: 1.0790\n",
            "Step [35720/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0005, d_svhn_loss: 0.0636, d_fake_loss: 0.0374, g_loss: 1.0938\n",
            "Step [35730/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0009, d_svhn_loss: 0.0304, d_fake_loss: 0.0718, g_loss: 1.1415\n",
            "Step [35740/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0006, d_svhn_loss: 0.0325, d_fake_loss: 0.0826, g_loss: 1.1105\n",
            "Step [35750/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0007, d_svhn_loss: 0.0395, d_fake_loss: 0.0254, g_loss: 1.1254\n",
            "Step [35760/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0013, d_svhn_loss: 0.0216, d_fake_loss: 0.0227, g_loss: 1.1387\n",
            "Step [35770/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0005, d_svhn_loss: 0.0285, d_fake_loss: 0.0412, g_loss: 1.0961\n",
            "Step [35780/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0014, d_svhn_loss: 0.0453, d_fake_loss: 0.0438, g_loss: 1.1505\n",
            "Step [35790/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0007, d_svhn_loss: 0.0295, d_fake_loss: 0.0302, g_loss: 1.0991\n",
            "Step [35800/80000], d_real_loss: 0.0203, d_mnist_loss: 0.0009, d_svhn_loss: 0.0194, d_fake_loss: 0.0267, g_loss: 1.0952\n",
            "Step [35810/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0006, d_svhn_loss: 0.0346, d_fake_loss: 0.1737, g_loss: 1.0912\n",
            "Step [35820/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0039, d_svhn_loss: 0.0267, d_fake_loss: 0.0537, g_loss: 1.1228\n",
            "Step [35830/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0043, d_svhn_loss: 0.0340, d_fake_loss: 0.0293, g_loss: 1.0823\n",
            "Step [35840/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0008, d_svhn_loss: 0.0303, d_fake_loss: 0.0216, g_loss: 1.1290\n",
            "Step [35850/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0079, d_svhn_loss: 0.0235, d_fake_loss: 0.0264, g_loss: 1.0753\n",
            "Step [35860/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0125, d_svhn_loss: 0.0386, d_fake_loss: 0.0168, g_loss: 1.1644\n",
            "Step [35870/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0116, d_svhn_loss: 0.0374, d_fake_loss: 0.0215, g_loss: 1.0525\n",
            "Step [35880/80000], d_real_loss: 0.1272, d_mnist_loss: 0.0561, d_svhn_loss: 0.0711, d_fake_loss: 0.1349, g_loss: 1.0663\n",
            "Step [35890/80000], d_real_loss: 0.1404, d_mnist_loss: 0.0153, d_svhn_loss: 0.1251, d_fake_loss: 0.0688, g_loss: 1.3623\n",
            "Step [35900/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0052, d_svhn_loss: 0.0183, d_fake_loss: 0.0412, g_loss: 1.4910\n",
            "Step [35910/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0045, d_svhn_loss: 0.0250, d_fake_loss: 0.0479, g_loss: 1.3389\n",
            "Step [35920/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0342, d_svhn_loss: 0.0163, d_fake_loss: 0.0599, g_loss: 1.0878\n",
            "Step [35930/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0045, d_svhn_loss: 0.0661, d_fake_loss: 0.0606, g_loss: 1.0928\n",
            "Step [35940/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0020, d_svhn_loss: 0.0238, d_fake_loss: 0.0489, g_loss: 1.4124\n",
            "Step [35950/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0052, d_svhn_loss: 0.0415, d_fake_loss: 0.0351, g_loss: 1.1914\n",
            "Step [35960/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0058, d_svhn_loss: 0.0666, d_fake_loss: 0.0324, g_loss: 1.1666\n",
            "Step [35970/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0211, d_svhn_loss: 0.0479, d_fake_loss: 0.0635, g_loss: 1.0054\n",
            "Step [35980/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0015, d_svhn_loss: 0.0271, d_fake_loss: 0.0361, g_loss: 1.1457\n",
            "Step [35990/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0043, d_svhn_loss: 0.0462, d_fake_loss: 0.0378, g_loss: 1.2142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [36000/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0017, d_svhn_loss: 0.0439, d_fake_loss: 0.0218, g_loss: 1.1614\n",
            "saved ./samples_mnist_svhn/sample-36000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-36000-s-m.png\n",
            "Step [36010/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0027, d_svhn_loss: 0.0438, d_fake_loss: 0.0312, g_loss: 1.1933\n",
            "Step [36020/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0028, d_svhn_loss: 0.0219, d_fake_loss: 0.0825, g_loss: 1.1881\n",
            "Step [36030/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0016, d_svhn_loss: 0.0263, d_fake_loss: 0.0235, g_loss: 1.1235\n",
            "Step [36040/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0014, d_svhn_loss: 0.0248, d_fake_loss: 0.0321, g_loss: 1.1422\n",
            "Step [36050/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0053, d_svhn_loss: 0.0525, d_fake_loss: 0.1658, g_loss: 1.3037\n",
            "Step [36060/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0180, d_svhn_loss: 0.0284, d_fake_loss: 0.0340, g_loss: 1.0877\n",
            "Step [36070/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0025, d_svhn_loss: 0.0390, d_fake_loss: 0.0528, g_loss: 1.1092\n",
            "Step [36080/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0089, d_svhn_loss: 0.0248, d_fake_loss: 0.1923, g_loss: 1.1462\n",
            "Step [36090/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0055, d_svhn_loss: 0.0305, d_fake_loss: 0.0417, g_loss: 1.1868\n",
            "Step [36100/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0016, d_svhn_loss: 0.0254, d_fake_loss: 0.0289, g_loss: 1.1419\n",
            "Step [36110/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0081, d_svhn_loss: 0.0306, d_fake_loss: 0.0260, g_loss: 1.0825\n",
            "Step [36120/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0031, d_svhn_loss: 0.0338, d_fake_loss: 0.0842, g_loss: 1.1612\n",
            "Step [36130/80000], d_real_loss: 0.0924, d_mnist_loss: 0.0251, d_svhn_loss: 0.0674, d_fake_loss: 0.1019, g_loss: 1.2028\n",
            "Step [36140/80000], d_real_loss: 0.1092, d_mnist_loss: 0.0024, d_svhn_loss: 0.1068, d_fake_loss: 0.0810, g_loss: 1.2753\n",
            "Step [36150/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0019, d_svhn_loss: 0.0470, d_fake_loss: 0.1009, g_loss: 1.2984\n",
            "Step [36160/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0015, d_svhn_loss: 0.0380, d_fake_loss: 0.0350, g_loss: 1.1593\n",
            "Step [36170/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0126, d_svhn_loss: 0.0271, d_fake_loss: 0.0363, g_loss: 1.1133\n",
            "Step [36180/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0029, d_svhn_loss: 0.0394, d_fake_loss: 0.0214, g_loss: 1.1604\n",
            "Step [36190/80000], d_real_loss: 0.1024, d_mnist_loss: 0.0013, d_svhn_loss: 0.1011, d_fake_loss: 0.0346, g_loss: 1.1884\n",
            "Step [36200/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0014, d_svhn_loss: 0.0291, d_fake_loss: 0.0299, g_loss: 1.1300\n",
            "Step [36210/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0011, d_svhn_loss: 0.0350, d_fake_loss: 0.0390, g_loss: 1.2471\n",
            "Step [36220/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0081, d_svhn_loss: 0.0571, d_fake_loss: 0.0335, g_loss: 1.0795\n",
            "Step [36230/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0037, d_svhn_loss: 0.0380, d_fake_loss: 0.0249, g_loss: 1.1195\n",
            "Step [36240/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0016, d_svhn_loss: 0.0705, d_fake_loss: 0.0362, g_loss: 1.1467\n",
            "Step [36250/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0051, d_svhn_loss: 0.0281, d_fake_loss: 0.0628, g_loss: 1.0702\n",
            "Step [36260/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0010, d_svhn_loss: 0.0678, d_fake_loss: 0.0274, g_loss: 1.1143\n",
            "Step [36270/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0010, d_svhn_loss: 0.0504, d_fake_loss: 0.0279, g_loss: 1.1165\n",
            "Step [36280/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0037, d_svhn_loss: 0.0364, d_fake_loss: 0.0230, g_loss: 1.1610\n",
            "Step [36290/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0014, d_svhn_loss: 0.0616, d_fake_loss: 0.0275, g_loss: 1.1563\n",
            "Step [36300/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0027, d_svhn_loss: 0.0206, d_fake_loss: 0.0296, g_loss: 1.0879\n",
            "Step [36310/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0016, d_svhn_loss: 0.0221, d_fake_loss: 0.0619, g_loss: 1.1042\n",
            "Step [36320/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0008, d_svhn_loss: 0.0334, d_fake_loss: 0.0393, g_loss: 1.1084\n",
            "Step [36330/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0049, d_svhn_loss: 0.0227, d_fake_loss: 0.0439, g_loss: 1.0730\n",
            "Step [36340/80000], d_real_loss: 0.1010, d_mnist_loss: 0.0026, d_svhn_loss: 0.0984, d_fake_loss: 0.0623, g_loss: 1.1705\n",
            "Step [36350/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0018, d_svhn_loss: 0.0481, d_fake_loss: 0.0330, g_loss: 1.0984\n",
            "Step [36360/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0006, d_svhn_loss: 0.0362, d_fake_loss: 0.0248, g_loss: 1.1405\n",
            "Step [36370/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0075, d_svhn_loss: 0.0117, d_fake_loss: 0.0209, g_loss: 1.0797\n",
            "Step [36380/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0009, d_svhn_loss: 0.0191, d_fake_loss: 0.0405, g_loss: 1.0868\n",
            "Step [36390/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0010, d_svhn_loss: 0.0258, d_fake_loss: 0.0219, g_loss: 1.1354\n",
            "Step [36400/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0005, d_svhn_loss: 0.0206, d_fake_loss: 0.0643, g_loss: 1.1233\n",
            "Step [36410/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0021, d_svhn_loss: 0.0362, d_fake_loss: 0.0575, g_loss: 1.1692\n",
            "Step [36420/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0013, d_svhn_loss: 0.0170, d_fake_loss: 0.0352, g_loss: 1.1536\n",
            "Step [36430/80000], d_real_loss: 0.1165, d_mnist_loss: 0.0532, d_svhn_loss: 0.0633, d_fake_loss: 0.1615, g_loss: 1.4745\n",
            "Step [36440/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0137, d_svhn_loss: 0.0367, d_fake_loss: 0.0208, g_loss: 1.1006\n",
            "Step [36450/80000], d_real_loss: 0.1561, d_mnist_loss: 0.0140, d_svhn_loss: 0.1421, d_fake_loss: 0.0625, g_loss: 1.1253\n",
            "Step [36460/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0015, d_svhn_loss: 0.0207, d_fake_loss: 0.0523, g_loss: 1.1804\n",
            "Step [36470/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0063, d_svhn_loss: 0.0634, d_fake_loss: 0.0683, g_loss: 1.0586\n",
            "Step [36480/80000], d_real_loss: 0.1167, d_mnist_loss: 0.0174, d_svhn_loss: 0.0993, d_fake_loss: 0.0328, g_loss: 1.0016\n",
            "Step [36490/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0057, d_svhn_loss: 0.0326, d_fake_loss: 0.0689, g_loss: 1.0792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [36500/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0021, d_svhn_loss: 0.0188, d_fake_loss: 0.0353, g_loss: 1.1160\n",
            "saved ./samples_mnist_svhn/sample-36500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-36500-s-m.png\n",
            "Step [36510/80000], d_real_loss: 0.0930, d_mnist_loss: 0.0051, d_svhn_loss: 0.0880, d_fake_loss: 0.0601, g_loss: 1.0971\n",
            "Step [36520/80000], d_real_loss: 0.0767, d_mnist_loss: 0.0065, d_svhn_loss: 0.0702, d_fake_loss: 0.0262, g_loss: 1.1463\n",
            "Step [36530/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0012, d_svhn_loss: 0.0231, d_fake_loss: 0.0347, g_loss: 1.1155\n",
            "Step [36540/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0047, d_svhn_loss: 0.0419, d_fake_loss: 0.1082, g_loss: 1.1530\n",
            "Step [36550/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0010, d_svhn_loss: 0.0288, d_fake_loss: 0.0307, g_loss: 1.1355\n",
            "Step [36560/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0008, d_svhn_loss: 0.0271, d_fake_loss: 0.0592, g_loss: 1.1183\n",
            "Step [36570/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0016, d_svhn_loss: 0.0579, d_fake_loss: 0.0533, g_loss: 1.1348\n",
            "Step [36580/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0068, d_svhn_loss: 0.0431, d_fake_loss: 0.0385, g_loss: 1.0855\n",
            "Step [36590/80000], d_real_loss: 0.1106, d_mnist_loss: 0.0054, d_svhn_loss: 0.1052, d_fake_loss: 0.1466, g_loss: 1.1305\n",
            "Step [36600/80000], d_real_loss: 0.1595, d_mnist_loss: 0.0145, d_svhn_loss: 0.1450, d_fake_loss: 0.1074, g_loss: 1.0490\n",
            "Step [36610/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0081, d_svhn_loss: 0.0268, d_fake_loss: 0.0622, g_loss: 1.0789\n",
            "Step [36620/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0010, d_svhn_loss: 0.0271, d_fake_loss: 0.0222, g_loss: 1.0974\n",
            "Step [36630/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0011, d_svhn_loss: 0.0270, d_fake_loss: 0.0469, g_loss: 1.1712\n",
            "Step [36640/80000], d_real_loss: 0.1478, d_mnist_loss: 0.0023, d_svhn_loss: 0.1455, d_fake_loss: 0.0587, g_loss: 1.1162\n",
            "Step [36650/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0015, d_svhn_loss: 0.0256, d_fake_loss: 0.1020, g_loss: 1.1076\n",
            "Step [36660/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0032, d_svhn_loss: 0.0256, d_fake_loss: 0.0244, g_loss: 1.0871\n",
            "Step [36670/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0012, d_svhn_loss: 0.0335, d_fake_loss: 0.0201, g_loss: 1.1068\n",
            "Step [36680/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0028, d_svhn_loss: 0.0228, d_fake_loss: 0.0192, g_loss: 1.1060\n",
            "Step [36690/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0054, d_svhn_loss: 0.0665, d_fake_loss: 0.0389, g_loss: 1.0602\n",
            "Step [36700/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0009, d_svhn_loss: 0.0515, d_fake_loss: 0.0326, g_loss: 1.1764\n",
            "Step [36710/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0021, d_svhn_loss: 0.0236, d_fake_loss: 0.0834, g_loss: 1.1517\n",
            "Step [36720/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0022, d_svhn_loss: 0.0266, d_fake_loss: 0.0295, g_loss: 1.1593\n",
            "Step [36730/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0007, d_svhn_loss: 0.0213, d_fake_loss: 0.0325, g_loss: 1.1425\n",
            "Step [36740/80000], d_real_loss: 0.1243, d_mnist_loss: 0.0064, d_svhn_loss: 0.1179, d_fake_loss: 0.0249, g_loss: 1.2962\n",
            "Step [36750/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0036, d_svhn_loss: 0.0291, d_fake_loss: 0.0323, g_loss: 1.1546\n",
            "Step [36760/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0024, d_svhn_loss: 0.0320, d_fake_loss: 0.0458, g_loss: 1.1335\n",
            "Step [36770/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0070, d_svhn_loss: 0.0337, d_fake_loss: 0.0266, g_loss: 1.1586\n",
            "Step [36780/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0047, d_svhn_loss: 0.0451, d_fake_loss: 0.0232, g_loss: 1.1187\n",
            "Step [36790/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0012, d_svhn_loss: 0.0209, d_fake_loss: 0.0441, g_loss: 1.1829\n",
            "Step [36800/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0021, d_svhn_loss: 0.0490, d_fake_loss: 0.0338, g_loss: 1.0718\n",
            "Step [36810/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0040, d_svhn_loss: 0.0724, d_fake_loss: 0.0371, g_loss: 1.1151\n",
            "Step [36820/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0024, d_svhn_loss: 0.0381, d_fake_loss: 0.0393, g_loss: 1.1264\n",
            "Step [36830/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0006, d_svhn_loss: 0.0351, d_fake_loss: 0.0300, g_loss: 1.1178\n",
            "Step [36840/80000], d_real_loss: 0.1269, d_mnist_loss: 0.0012, d_svhn_loss: 0.1257, d_fake_loss: 0.0321, g_loss: 1.0812\n",
            "Step [36850/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0009, d_svhn_loss: 0.0355, d_fake_loss: 0.0566, g_loss: 1.0643\n",
            "Step [36860/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0004, d_svhn_loss: 0.0300, d_fake_loss: 0.0238, g_loss: 1.0857\n",
            "Step [36870/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0010, d_svhn_loss: 0.0726, d_fake_loss: 0.0903, g_loss: 1.1056\n",
            "Step [36880/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0004, d_svhn_loss: 0.0404, d_fake_loss: 0.0168, g_loss: 1.0985\n",
            "Step [36890/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0007, d_svhn_loss: 0.0387, d_fake_loss: 0.0402, g_loss: 1.1234\n",
            "Step [36900/80000], d_real_loss: 0.0213, d_mnist_loss: 0.0061, d_svhn_loss: 0.0152, d_fake_loss: 0.0440, g_loss: 1.0613\n",
            "Step [36910/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0039, d_svhn_loss: 0.0173, d_fake_loss: 0.0547, g_loss: 1.1660\n",
            "Step [36920/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0029, d_svhn_loss: 0.0522, d_fake_loss: 0.2260, g_loss: 1.0883\n",
            "Step [36930/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0023, d_svhn_loss: 0.0267, d_fake_loss: 0.0367, g_loss: 1.1199\n",
            "Step [36940/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0011, d_svhn_loss: 0.0296, d_fake_loss: 0.0317, g_loss: 1.1009\n",
            "Step [36950/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0018, d_svhn_loss: 0.0186, d_fake_loss: 0.0380, g_loss: 1.1678\n",
            "Step [36960/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0004, d_svhn_loss: 0.0252, d_fake_loss: 0.0699, g_loss: 1.1502\n",
            "Step [36970/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0019, d_svhn_loss: 0.0380, d_fake_loss: 0.0279, g_loss: 1.0977\n",
            "Step [36980/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0014, d_svhn_loss: 0.0290, d_fake_loss: 0.0381, g_loss: 1.3437\n",
            "Step [36990/80000], d_real_loss: 0.1398, d_mnist_loss: 0.0382, d_svhn_loss: 0.1017, d_fake_loss: 0.0726, g_loss: 1.0310\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [37000/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0237, d_svhn_loss: 0.0221, d_fake_loss: 0.0525, g_loss: 1.1059\n",
            "saved ./samples_mnist_svhn/sample-37000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-37000-s-m.png\n",
            "Step [37010/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0040, d_svhn_loss: 0.0443, d_fake_loss: 0.0697, g_loss: 1.0215\n",
            "Step [37020/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0068, d_svhn_loss: 0.0292, d_fake_loss: 0.0393, g_loss: 1.1663\n",
            "Step [37030/80000], d_real_loss: 0.1630, d_mnist_loss: 0.0093, d_svhn_loss: 0.1536, d_fake_loss: 0.0211, g_loss: 1.2637\n",
            "Step [37040/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0191, d_svhn_loss: 0.0540, d_fake_loss: 0.0377, g_loss: 1.0587\n",
            "Step [37050/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0077, d_svhn_loss: 0.0555, d_fake_loss: 0.0230, g_loss: 1.0911\n",
            "Step [37060/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0014, d_svhn_loss: 0.0242, d_fake_loss: 0.0343, g_loss: 1.1637\n",
            "Step [37070/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0046, d_svhn_loss: 0.0355, d_fake_loss: 0.0270, g_loss: 1.1594\n",
            "Step [37080/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0081, d_svhn_loss: 0.0288, d_fake_loss: 0.0193, g_loss: 1.1629\n",
            "Step [37090/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0027, d_svhn_loss: 0.0257, d_fake_loss: 0.0371, g_loss: 1.0586\n",
            "Step [37100/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0230, d_svhn_loss: 0.0254, d_fake_loss: 0.0205, g_loss: 1.1611\n",
            "Step [37110/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0064, d_svhn_loss: 0.0286, d_fake_loss: 0.0370, g_loss: 1.0270\n",
            "Step [37120/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0010, d_svhn_loss: 0.0313, d_fake_loss: 0.0456, g_loss: 1.1415\n",
            "Step [37130/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0035, d_svhn_loss: 0.0181, d_fake_loss: 0.0318, g_loss: 1.1999\n",
            "Step [37140/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0010, d_svhn_loss: 0.0278, d_fake_loss: 0.0331, g_loss: 1.2581\n",
            "Step [37150/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0012, d_svhn_loss: 0.0243, d_fake_loss: 0.0215, g_loss: 1.1994\n",
            "Step [37160/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0012, d_svhn_loss: 0.0266, d_fake_loss: 0.0254, g_loss: 1.1733\n",
            "Step [37170/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0042, d_svhn_loss: 0.0402, d_fake_loss: 0.0706, g_loss: 1.1281\n",
            "Step [37180/80000], d_real_loss: 0.1262, d_mnist_loss: 0.0010, d_svhn_loss: 0.1252, d_fake_loss: 0.0284, g_loss: 1.1301\n",
            "Step [37190/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0051, d_svhn_loss: 0.0242, d_fake_loss: 0.0463, g_loss: 1.1809\n",
            "Step [37200/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0013, d_svhn_loss: 0.0329, d_fake_loss: 0.0646, g_loss: 1.1273\n",
            "Step [37210/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0010, d_svhn_loss: 0.0415, d_fake_loss: 0.0448, g_loss: 1.1614\n",
            "Step [37220/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0008, d_svhn_loss: 0.0280, d_fake_loss: 0.0173, g_loss: 1.1586\n",
            "Step [37230/80000], d_real_loss: 0.0176, d_mnist_loss: 0.0019, d_svhn_loss: 0.0156, d_fake_loss: 0.0329, g_loss: 1.3136\n",
            "Step [37240/80000], d_real_loss: 0.1006, d_mnist_loss: 0.0007, d_svhn_loss: 0.0999, d_fake_loss: 0.0749, g_loss: 1.1083\n",
            "Step [37250/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0237, d_svhn_loss: 0.0297, d_fake_loss: 0.0609, g_loss: 1.1577\n",
            "Step [37260/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0082, d_svhn_loss: 0.0555, d_fake_loss: 0.0419, g_loss: 1.2314\n",
            "Step [37270/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0073, d_svhn_loss: 0.0322, d_fake_loss: 0.0271, g_loss: 1.3018\n",
            "Step [37280/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0034, d_svhn_loss: 0.0644, d_fake_loss: 0.0632, g_loss: 1.1504\n",
            "Step [37290/80000], d_real_loss: 0.1038, d_mnist_loss: 0.0356, d_svhn_loss: 0.0682, d_fake_loss: 0.0643, g_loss: 1.1692\n",
            "Step [37300/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0049, d_svhn_loss: 0.0364, d_fake_loss: 0.0404, g_loss: 1.2056\n",
            "Step [37310/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0127, d_svhn_loss: 0.0193, d_fake_loss: 0.0294, g_loss: 1.0968\n",
            "Step [37320/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0022, d_svhn_loss: 0.0385, d_fake_loss: 0.0389, g_loss: 1.1188\n",
            "Step [37330/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0034, d_svhn_loss: 0.0240, d_fake_loss: 0.0392, g_loss: 1.2056\n",
            "Step [37340/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0065, d_svhn_loss: 0.0196, d_fake_loss: 0.0332, g_loss: 1.1839\n",
            "Step [37350/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0038, d_svhn_loss: 0.0255, d_fake_loss: 0.0792, g_loss: 1.1574\n",
            "Step [37360/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0017, d_svhn_loss: 0.0231, d_fake_loss: 0.0437, g_loss: 1.1323\n",
            "Step [37370/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0015, d_svhn_loss: 0.0827, d_fake_loss: 0.0395, g_loss: 1.0851\n",
            "Step [37380/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0042, d_svhn_loss: 0.0401, d_fake_loss: 0.0377, g_loss: 1.1238\n",
            "Step [37390/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0007, d_svhn_loss: 0.0247, d_fake_loss: 0.0275, g_loss: 1.1215\n",
            "Step [37400/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0011, d_svhn_loss: 0.0322, d_fake_loss: 0.0492, g_loss: 1.1114\n",
            "Step [37410/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0011, d_svhn_loss: 0.0497, d_fake_loss: 0.0213, g_loss: 1.1124\n",
            "Step [37420/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0018, d_svhn_loss: 0.0374, d_fake_loss: 0.0279, g_loss: 1.1067\n",
            "Step [37430/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0014, d_svhn_loss: 0.0630, d_fake_loss: 0.1212, g_loss: 1.1732\n",
            "Step [37440/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0109, d_svhn_loss: 0.0261, d_fake_loss: 0.0222, g_loss: 0.9987\n",
            "Step [37450/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0053, d_svhn_loss: 0.0447, d_fake_loss: 0.0217, g_loss: 1.0689\n",
            "Step [37460/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0016, d_svhn_loss: 0.0616, d_fake_loss: 0.0612, g_loss: 1.1332\n",
            "Step [37470/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0032, d_svhn_loss: 0.0376, d_fake_loss: 0.0285, g_loss: 1.1719\n",
            "Step [37480/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0034, d_svhn_loss: 0.0197, d_fake_loss: 0.0573, g_loss: 1.1520\n",
            "Step [37490/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0022, d_svhn_loss: 0.0333, d_fake_loss: 0.1008, g_loss: 1.1274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [37500/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0008, d_svhn_loss: 0.0497, d_fake_loss: 0.1064, g_loss: 1.1440\n",
            "saved ./samples_mnist_svhn/sample-37500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-37500-s-m.png\n",
            "Step [37510/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0012, d_svhn_loss: 0.0631, d_fake_loss: 0.0197, g_loss: 1.1802\n",
            "Step [37520/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0009, d_svhn_loss: 0.0221, d_fake_loss: 0.0307, g_loss: 1.1772\n",
            "Step [37530/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0010, d_svhn_loss: 0.0199, d_fake_loss: 0.1111, g_loss: 1.2480\n",
            "Step [37540/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0072, d_svhn_loss: 0.0221, d_fake_loss: 0.0225, g_loss: 1.0674\n",
            "Step [37550/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0114, d_svhn_loss: 0.0270, d_fake_loss: 0.0260, g_loss: 1.0864\n",
            "Step [37560/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0017, d_svhn_loss: 0.0305, d_fake_loss: 0.0236, g_loss: 1.1263\n",
            "Step [37570/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0015, d_svhn_loss: 0.0252, d_fake_loss: 0.0290, g_loss: 1.1254\n",
            "Step [37580/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0008, d_svhn_loss: 0.0295, d_fake_loss: 0.0164, g_loss: 1.1445\n",
            "Step [37590/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0030, d_svhn_loss: 0.0314, d_fake_loss: 0.0888, g_loss: 1.9046\n",
            "Step [37600/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0032, d_svhn_loss: 0.0478, d_fake_loss: 0.0368, g_loss: 1.1905\n",
            "Step [37610/80000], d_real_loss: 0.1272, d_mnist_loss: 0.0016, d_svhn_loss: 0.1257, d_fake_loss: 0.2694, g_loss: 1.1229\n",
            "Step [37620/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0005, d_svhn_loss: 0.0261, d_fake_loss: 0.0237, g_loss: 1.0695\n",
            "Step [37630/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0042, d_svhn_loss: 0.0294, d_fake_loss: 0.0283, g_loss: 1.1168\n",
            "Step [37640/80000], d_real_loss: 0.0163, d_mnist_loss: 0.0007, d_svhn_loss: 0.0156, d_fake_loss: 0.0186, g_loss: 1.0985\n",
            "Step [37650/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0004, d_svhn_loss: 0.0328, d_fake_loss: 0.0885, g_loss: 1.0985\n",
            "Step [37660/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0030, d_svhn_loss: 0.0326, d_fake_loss: 0.0624, g_loss: 1.0651\n",
            "Step [37670/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0005, d_svhn_loss: 0.0367, d_fake_loss: 0.0276, g_loss: 1.1899\n",
            "Step [37680/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0009, d_svhn_loss: 0.0551, d_fake_loss: 0.0254, g_loss: 1.1075\n",
            "Step [37690/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0007, d_svhn_loss: 0.0178, d_fake_loss: 0.0411, g_loss: 1.1183\n",
            "Step [37700/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0006, d_svhn_loss: 0.0249, d_fake_loss: 0.0309, g_loss: 1.1558\n",
            "Step [37710/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0011, d_svhn_loss: 0.0256, d_fake_loss: 0.0329, g_loss: 1.1559\n",
            "Step [37720/80000], d_real_loss: 0.1106, d_mnist_loss: 0.0014, d_svhn_loss: 0.1092, d_fake_loss: 0.2189, g_loss: 1.1131\n",
            "Step [37730/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0059, d_svhn_loss: 0.0259, d_fake_loss: 0.0221, g_loss: 1.1164\n",
            "Step [37740/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0028, d_svhn_loss: 0.0193, d_fake_loss: 0.0230, g_loss: 1.0653\n",
            "Step [37750/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0059, d_svhn_loss: 0.0365, d_fake_loss: 0.0784, g_loss: 1.4062\n",
            "Step [37760/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0023, d_svhn_loss: 0.0318, d_fake_loss: 0.0136, g_loss: 1.1587\n",
            "Step [37770/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0011, d_svhn_loss: 0.0344, d_fake_loss: 0.0596, g_loss: 1.1045\n",
            "Step [37780/80000], d_real_loss: 0.0219, d_mnist_loss: 0.0014, d_svhn_loss: 0.0205, d_fake_loss: 0.0382, g_loss: 1.1665\n",
            "Step [37790/80000], d_real_loss: 0.0943, d_mnist_loss: 0.0041, d_svhn_loss: 0.0902, d_fake_loss: 0.0389, g_loss: 1.0933\n",
            "Step [37800/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0008, d_svhn_loss: 0.0859, d_fake_loss: 0.0252, g_loss: 1.0953\n",
            "Step [37810/80000], d_real_loss: 0.0137, d_mnist_loss: 0.0010, d_svhn_loss: 0.0127, d_fake_loss: 0.0170, g_loss: 1.1423\n",
            "Step [37820/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0028, d_svhn_loss: 0.0537, d_fake_loss: 0.0191, g_loss: 1.1112\n",
            "Step [37830/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0009, d_svhn_loss: 0.0225, d_fake_loss: 0.0227, g_loss: 1.0975\n",
            "Step [37840/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0011, d_svhn_loss: 0.0337, d_fake_loss: 0.0434, g_loss: 1.1207\n",
            "Step [37850/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0029, d_svhn_loss: 0.0407, d_fake_loss: 0.0481, g_loss: 1.1837\n",
            "Step [37860/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0028, d_svhn_loss: 0.0222, d_fake_loss: 0.0442, g_loss: 1.1009\n",
            "Step [37870/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0073, d_svhn_loss: 0.0387, d_fake_loss: 0.0558, g_loss: 1.0697\n",
            "Step [37880/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0043, d_svhn_loss: 0.0419, d_fake_loss: 0.0414, g_loss: 1.1400\n",
            "Step [37890/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0052, d_svhn_loss: 0.0277, d_fake_loss: 0.0272, g_loss: 1.0998\n",
            "Step [37900/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0038, d_svhn_loss: 0.0314, d_fake_loss: 0.0240, g_loss: 1.2134\n",
            "Step [37910/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0082, d_svhn_loss: 0.0395, d_fake_loss: 0.0288, g_loss: 1.1046\n",
            "Step [37920/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0006, d_svhn_loss: 0.0236, d_fake_loss: 0.0280, g_loss: 1.1590\n",
            "Step [37930/80000], d_real_loss: 0.0902, d_mnist_loss: 0.0008, d_svhn_loss: 0.0894, d_fake_loss: 0.0343, g_loss: 1.1443\n",
            "Step [37940/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0012, d_svhn_loss: 0.0283, d_fake_loss: 0.0330, g_loss: 1.1353\n",
            "Step [37950/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0025, d_svhn_loss: 0.0580, d_fake_loss: 0.0245, g_loss: 1.0895\n",
            "Step [37960/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0006, d_svhn_loss: 0.0449, d_fake_loss: 0.0236, g_loss: 1.1128\n",
            "Step [37970/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0012, d_svhn_loss: 0.0331, d_fake_loss: 0.1614, g_loss: 1.1487\n",
            "Step [37980/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0013, d_svhn_loss: 0.0492, d_fake_loss: 0.1371, g_loss: 1.0772\n",
            "Step [37990/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0034, d_svhn_loss: 0.0535, d_fake_loss: 0.0201, g_loss: 1.0999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [38000/80000], d_real_loss: 0.0792, d_mnist_loss: 0.0029, d_svhn_loss: 0.0763, d_fake_loss: 0.0379, g_loss: 1.0895\n",
            "saved ./samples_mnist_svhn/sample-38000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-38000-s-m.png\n",
            "Step [38010/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0009, d_svhn_loss: 0.0304, d_fake_loss: 0.0416, g_loss: 1.1726\n",
            "Step [38020/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0023, d_svhn_loss: 0.0306, d_fake_loss: 0.0460, g_loss: 1.2338\n",
            "Step [38030/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0027, d_svhn_loss: 0.0285, d_fake_loss: 0.0900, g_loss: 1.1150\n",
            "Step [38040/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0016, d_svhn_loss: 0.0219, d_fake_loss: 0.0924, g_loss: 1.1241\n",
            "Step [38050/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0024, d_svhn_loss: 0.0257, d_fake_loss: 0.1520, g_loss: 1.1773\n",
            "Step [38060/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0026, d_svhn_loss: 0.0508, d_fake_loss: 0.0773, g_loss: 1.1501\n",
            "Step [38070/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0005, d_svhn_loss: 0.0336, d_fake_loss: 0.0439, g_loss: 1.0896\n",
            "Step [38080/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0007, d_svhn_loss: 0.0501, d_fake_loss: 0.0227, g_loss: 1.1260\n",
            "Step [38090/80000], d_real_loss: 0.0151, d_mnist_loss: 0.0005, d_svhn_loss: 0.0146, d_fake_loss: 0.0211, g_loss: 1.1212\n",
            "Step [38100/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0055, d_svhn_loss: 0.0218, d_fake_loss: 0.0299, g_loss: 1.1501\n",
            "Step [38110/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0038, d_svhn_loss: 0.0452, d_fake_loss: 0.0447, g_loss: 1.1169\n",
            "Step [38120/80000], d_real_loss: 0.1526, d_mnist_loss: 0.0896, d_svhn_loss: 0.0630, d_fake_loss: 0.0569, g_loss: 1.3072\n",
            "Step [38130/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0084, d_svhn_loss: 0.0243, d_fake_loss: 0.0372, g_loss: 1.0923\n",
            "Step [38140/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0044, d_svhn_loss: 0.0291, d_fake_loss: 0.0207, g_loss: 1.1985\n",
            "Step [38150/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0211, d_svhn_loss: 0.0503, d_fake_loss: 0.0214, g_loss: 1.1298\n",
            "Step [38160/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0068, d_svhn_loss: 0.0774, d_fake_loss: 0.0668, g_loss: 1.1667\n",
            "Step [38170/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0048, d_svhn_loss: 0.0573, d_fake_loss: 0.1156, g_loss: 1.5995\n",
            "Step [38180/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0100, d_svhn_loss: 0.0295, d_fake_loss: 0.0351, g_loss: 1.0370\n",
            "Step [38190/80000], d_real_loss: 0.1350, d_mnist_loss: 0.0055, d_svhn_loss: 0.1295, d_fake_loss: 0.0414, g_loss: 1.1091\n",
            "Step [38200/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0167, d_svhn_loss: 0.0423, d_fake_loss: 0.0507, g_loss: 1.1376\n",
            "Step [38210/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0155, d_svhn_loss: 0.0382, d_fake_loss: 0.0327, g_loss: 1.1747\n",
            "Step [38220/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0011, d_svhn_loss: 0.0323, d_fake_loss: 0.0335, g_loss: 1.1077\n",
            "Step [38230/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0033, d_svhn_loss: 0.0259, d_fake_loss: 0.0454, g_loss: 1.1557\n",
            "Step [38240/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0021, d_svhn_loss: 0.0597, d_fake_loss: 0.0246, g_loss: 1.1459\n",
            "Step [38250/80000], d_real_loss: 0.0715, d_mnist_loss: 0.0020, d_svhn_loss: 0.0694, d_fake_loss: 0.0222, g_loss: 1.0559\n",
            "Step [38260/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0013, d_svhn_loss: 0.0209, d_fake_loss: 0.0279, g_loss: 1.1460\n",
            "Step [38270/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0010, d_svhn_loss: 0.0248, d_fake_loss: 0.0404, g_loss: 1.1513\n",
            "Step [38280/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0021, d_svhn_loss: 0.0427, d_fake_loss: 0.1744, g_loss: 1.1319\n",
            "Step [38290/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0016, d_svhn_loss: 0.0352, d_fake_loss: 0.0389, g_loss: 1.1540\n",
            "Step [38300/80000], d_real_loss: 0.1291, d_mnist_loss: 0.0016, d_svhn_loss: 0.1275, d_fake_loss: 0.0233, g_loss: 1.1598\n",
            "Step [38310/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0009, d_svhn_loss: 0.0407, d_fake_loss: 0.0324, g_loss: 1.1694\n",
            "Step [38320/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0084, d_svhn_loss: 0.0435, d_fake_loss: 0.1359, g_loss: 1.1202\n",
            "Step [38330/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0022, d_svhn_loss: 0.0506, d_fake_loss: 0.0206, g_loss: 1.1292\n",
            "Step [38340/80000], d_real_loss: 0.0828, d_mnist_loss: 0.0060, d_svhn_loss: 0.0768, d_fake_loss: 0.0856, g_loss: 1.0426\n",
            "Step [38350/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0017, d_svhn_loss: 0.0473, d_fake_loss: 0.0219, g_loss: 1.1319\n",
            "Step [38360/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0017, d_svhn_loss: 0.0182, d_fake_loss: 0.0168, g_loss: 1.1244\n",
            "Step [38370/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0027, d_svhn_loss: 0.0493, d_fake_loss: 0.0381, g_loss: 1.1265\n",
            "Step [38380/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0011, d_svhn_loss: 0.0435, d_fake_loss: 0.0424, g_loss: 1.1198\n",
            "Step [38390/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0018, d_svhn_loss: 0.0412, d_fake_loss: 0.0244, g_loss: 1.1701\n",
            "Step [38400/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0020, d_svhn_loss: 0.0507, d_fake_loss: 0.1045, g_loss: 1.1218\n",
            "Step [38410/80000], d_real_loss: 0.1408, d_mnist_loss: 0.0010, d_svhn_loss: 0.1398, d_fake_loss: 0.0900, g_loss: 1.1282\n",
            "Step [38420/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0038, d_svhn_loss: 0.0335, d_fake_loss: 0.0383, g_loss: 1.1689\n",
            "Step [38430/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0030, d_svhn_loss: 0.0370, d_fake_loss: 0.0186, g_loss: 1.1245\n",
            "Step [38440/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0009, d_svhn_loss: 0.0603, d_fake_loss: 0.0247, g_loss: 1.1013\n",
            "Step [38450/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0007, d_svhn_loss: 0.0324, d_fake_loss: 0.1836, g_loss: 1.1661\n",
            "Step [38460/80000], d_real_loss: 0.0926, d_mnist_loss: 0.0026, d_svhn_loss: 0.0900, d_fake_loss: 0.0288, g_loss: 1.0791\n",
            "Step [38470/80000], d_real_loss: 0.1919, d_mnist_loss: 0.0134, d_svhn_loss: 0.1785, d_fake_loss: 0.0579, g_loss: 1.1965\n",
            "Step [38480/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0015, d_svhn_loss: 0.0285, d_fake_loss: 0.0234, g_loss: 1.1075\n",
            "Step [38490/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0079, d_svhn_loss: 0.0546, d_fake_loss: 0.0223, g_loss: 1.0429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [38500/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0008, d_svhn_loss: 0.0232, d_fake_loss: 0.0377, g_loss: 1.0924\n",
            "saved ./samples_mnist_svhn/sample-38500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-38500-s-m.png\n",
            "Step [38510/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0007, d_svhn_loss: 0.0261, d_fake_loss: 0.0216, g_loss: 1.0859\n",
            "Step [38520/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0006, d_svhn_loss: 0.0250, d_fake_loss: 0.0285, g_loss: 1.0990\n",
            "Step [38530/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0013, d_svhn_loss: 0.0379, d_fake_loss: 0.0598, g_loss: 1.1101\n",
            "Step [38540/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0012, d_svhn_loss: 0.0236, d_fake_loss: 0.1249, g_loss: 1.0892\n",
            "Step [38550/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0008, d_svhn_loss: 0.0416, d_fake_loss: 0.0410, g_loss: 1.1172\n",
            "Step [38560/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0008, d_svhn_loss: 0.0644, d_fake_loss: 0.0274, g_loss: 1.0892\n",
            "Step [38570/80000], d_real_loss: 0.1562, d_mnist_loss: 0.0041, d_svhn_loss: 0.1522, d_fake_loss: 0.0991, g_loss: 1.1202\n",
            "Step [38580/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0015, d_svhn_loss: 0.0189, d_fake_loss: 0.0367, g_loss: 1.1343\n",
            "Step [38590/80000], d_real_loss: 0.1203, d_mnist_loss: 0.0008, d_svhn_loss: 0.1195, d_fake_loss: 0.0340, g_loss: 1.1397\n",
            "Step [38600/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0081, d_svhn_loss: 0.0382, d_fake_loss: 0.0354, g_loss: 1.1006\n",
            "Step [38610/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0024, d_svhn_loss: 0.0543, d_fake_loss: 0.0251, g_loss: 1.2601\n",
            "Step [38620/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0008, d_svhn_loss: 0.0439, d_fake_loss: 0.0199, g_loss: 1.1707\n",
            "Step [38630/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0034, d_svhn_loss: 0.0376, d_fake_loss: 0.1429, g_loss: 1.2512\n",
            "Step [38640/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0058, d_svhn_loss: 0.0843, d_fake_loss: 0.2019, g_loss: 1.1086\n",
            "Step [38650/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0009, d_svhn_loss: 0.0296, d_fake_loss: 0.0324, g_loss: 1.1904\n",
            "Step [38660/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0047, d_svhn_loss: 0.0329, d_fake_loss: 0.1248, g_loss: 1.1578\n",
            "Step [38670/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0888, d_svhn_loss: 0.0284, d_fake_loss: 0.1115, g_loss: 1.9102\n",
            "Step [38680/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0230, d_svhn_loss: 0.0191, d_fake_loss: 0.0307, g_loss: 1.2136\n",
            "Step [38690/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0262, d_svhn_loss: 0.0197, d_fake_loss: 0.1241, g_loss: 1.0481\n",
            "Step [38700/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0095, d_svhn_loss: 0.0478, d_fake_loss: 0.0355, g_loss: 1.0625\n",
            "Step [38710/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0015, d_svhn_loss: 0.0212, d_fake_loss: 0.0847, g_loss: 1.1771\n",
            "Step [38720/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0040, d_svhn_loss: 0.0632, d_fake_loss: 0.0413, g_loss: 1.0437\n",
            "Step [38730/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0048, d_svhn_loss: 0.0157, d_fake_loss: 0.0301, g_loss: 1.1393\n",
            "Step [38740/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0054, d_svhn_loss: 0.0246, d_fake_loss: 0.0562, g_loss: 1.3913\n",
            "Step [38750/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0028, d_svhn_loss: 0.0181, d_fake_loss: 0.0546, g_loss: 1.2308\n",
            "Step [38760/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0014, d_svhn_loss: 0.0649, d_fake_loss: 0.0324, g_loss: 1.1752\n",
            "Step [38770/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0029, d_svhn_loss: 0.0274, d_fake_loss: 0.0416, g_loss: 1.1819\n",
            "Step [38780/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0035, d_svhn_loss: 0.0229, d_fake_loss: 0.0268, g_loss: 1.0818\n",
            "Step [38790/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0041, d_svhn_loss: 0.0631, d_fake_loss: 0.0356, g_loss: 1.1128\n",
            "Step [38800/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0014, d_svhn_loss: 0.0751, d_fake_loss: 0.1590, g_loss: 1.0982\n",
            "Step [38810/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0036, d_svhn_loss: 0.0284, d_fake_loss: 0.0302, g_loss: 1.0918\n",
            "Step [38820/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0015, d_svhn_loss: 0.0298, d_fake_loss: 0.0339, g_loss: 1.1139\n",
            "Step [38830/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0009, d_svhn_loss: 0.0262, d_fake_loss: 0.0159, g_loss: 1.1115\n",
            "Step [38840/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0029, d_svhn_loss: 0.0604, d_fake_loss: 0.0381, g_loss: 1.1294\n",
            "Step [38850/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0017, d_svhn_loss: 0.0233, d_fake_loss: 0.1063, g_loss: 1.1572\n",
            "Step [38860/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0019, d_svhn_loss: 0.0283, d_fake_loss: 0.0337, g_loss: 1.1359\n",
            "Step [38870/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0008, d_svhn_loss: 0.0796, d_fake_loss: 0.0457, g_loss: 1.1348\n",
            "Step [38880/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0007, d_svhn_loss: 0.0612, d_fake_loss: 0.0535, g_loss: 1.1020\n",
            "Step [38890/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0046, d_svhn_loss: 0.0398, d_fake_loss: 0.1139, g_loss: 1.0754\n",
            "Step [38900/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0007, d_svhn_loss: 0.0175, d_fake_loss: 0.0864, g_loss: 1.0797\n",
            "Step [38910/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0011, d_svhn_loss: 0.0264, d_fake_loss: 0.0210, g_loss: 1.0845\n",
            "Step [38920/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0022, d_svhn_loss: 0.0662, d_fake_loss: 0.0232, g_loss: 1.1533\n",
            "Step [38930/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0085, d_svhn_loss: 0.0547, d_fake_loss: 0.0403, g_loss: 1.1576\n",
            "Step [38940/80000], d_real_loss: 0.0134, d_mnist_loss: 0.0015, d_svhn_loss: 0.0119, d_fake_loss: 0.0247, g_loss: 1.1126\n",
            "Step [38950/80000], d_real_loss: 0.0941, d_mnist_loss: 0.0039, d_svhn_loss: 0.0903, d_fake_loss: 0.0545, g_loss: 1.7658\n",
            "Step [38960/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0101, d_svhn_loss: 0.0349, d_fake_loss: 0.0435, g_loss: 1.2816\n",
            "Step [38970/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0013, d_svhn_loss: 0.0347, d_fake_loss: 0.0583, g_loss: 1.6233\n",
            "Step [38980/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0039, d_svhn_loss: 0.0320, d_fake_loss: 0.0344, g_loss: 1.0924\n",
            "Step [38990/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0040, d_svhn_loss: 0.0472, d_fake_loss: 0.0748, g_loss: 1.1334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [39000/80000], d_real_loss: 0.1183, d_mnist_loss: 0.0012, d_svhn_loss: 0.1171, d_fake_loss: 0.0993, g_loss: 1.1305\n",
            "saved ./samples_mnist_svhn/sample-39000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-39000-s-m.png\n",
            "Step [39010/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0070, d_svhn_loss: 0.0579, d_fake_loss: 0.0145, g_loss: 1.1107\n",
            "Step [39020/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0012, d_svhn_loss: 0.0264, d_fake_loss: 0.0236, g_loss: 1.1124\n",
            "Step [39030/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0039, d_svhn_loss: 0.0552, d_fake_loss: 0.0490, g_loss: 1.1128\n",
            "Step [39040/80000], d_real_loss: 0.1530, d_mnist_loss: 0.0006, d_svhn_loss: 0.1524, d_fake_loss: 0.0454, g_loss: 1.1323\n",
            "Step [39050/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0008, d_svhn_loss: 0.0456, d_fake_loss: 0.0510, g_loss: 1.1614\n",
            "Step [39060/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0037, d_svhn_loss: 0.0307, d_fake_loss: 0.0242, g_loss: 1.0737\n",
            "Step [39070/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0006, d_svhn_loss: 0.0274, d_fake_loss: 0.0294, g_loss: 1.1459\n",
            "Step [39080/80000], d_real_loss: 0.0780, d_mnist_loss: 0.0013, d_svhn_loss: 0.0767, d_fake_loss: 0.0418, g_loss: 1.0828\n",
            "Step [39090/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0007, d_svhn_loss: 0.0545, d_fake_loss: 0.0556, g_loss: 1.0798\n",
            "Step [39100/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0021, d_svhn_loss: 0.0299, d_fake_loss: 0.0593, g_loss: 1.1455\n",
            "Step [39110/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0016, d_svhn_loss: 0.0296, d_fake_loss: 0.0582, g_loss: 1.1288\n",
            "Step [39120/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0008, d_svhn_loss: 0.0286, d_fake_loss: 0.1004, g_loss: 1.0960\n",
            "Step [39130/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0009, d_svhn_loss: 0.0729, d_fake_loss: 0.0424, g_loss: 1.1240\n",
            "Step [39140/80000], d_real_loss: 0.1235, d_mnist_loss: 0.0008, d_svhn_loss: 0.1228, d_fake_loss: 0.0849, g_loss: 1.1337\n",
            "Step [39150/80000], d_real_loss: 0.0751, d_mnist_loss: 0.0020, d_svhn_loss: 0.0731, d_fake_loss: 0.0373, g_loss: 1.1087\n",
            "Step [39160/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0012, d_svhn_loss: 0.0195, d_fake_loss: 0.0383, g_loss: 1.0942\n",
            "Step [39170/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0017, d_svhn_loss: 0.0336, d_fake_loss: 0.0210, g_loss: 1.1269\n",
            "Step [39180/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0010, d_svhn_loss: 0.0306, d_fake_loss: 0.0321, g_loss: 1.1436\n",
            "Step [39190/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0006, d_svhn_loss: 0.0299, d_fake_loss: 0.0225, g_loss: 1.1493\n",
            "Step [39200/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0021, d_svhn_loss: 0.0209, d_fake_loss: 0.0191, g_loss: 1.1266\n",
            "Step [39210/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0005, d_svhn_loss: 0.0279, d_fake_loss: 0.0230, g_loss: 1.1039\n",
            "Step [39220/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0003, d_svhn_loss: 0.0297, d_fake_loss: 0.0219, g_loss: 1.0719\n",
            "Step [39230/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0007, d_svhn_loss: 0.0288, d_fake_loss: 0.0554, g_loss: 1.1166\n",
            "Step [39240/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0009, d_svhn_loss: 0.0403, d_fake_loss: 0.0380, g_loss: 1.1515\n",
            "Step [39250/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0013, d_svhn_loss: 0.0283, d_fake_loss: 0.0452, g_loss: 1.1093\n",
            "Step [39260/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0005, d_svhn_loss: 0.0276, d_fake_loss: 0.0234, g_loss: 1.1098\n",
            "Step [39270/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0005, d_svhn_loss: 0.0644, d_fake_loss: 0.0513, g_loss: 1.1047\n",
            "Step [39280/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0006, d_svhn_loss: 0.0426, d_fake_loss: 0.0235, g_loss: 1.1195\n",
            "Step [39290/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0004, d_svhn_loss: 0.0508, d_fake_loss: 0.0447, g_loss: 1.1300\n",
            "Step [39300/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0034, d_svhn_loss: 0.0235, d_fake_loss: 0.0700, g_loss: 1.0696\n",
            "Step [39310/80000], d_real_loss: 0.1324, d_mnist_loss: 0.0017, d_svhn_loss: 0.1307, d_fake_loss: 0.0914, g_loss: 1.0801\n",
            "Step [39320/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0024, d_svhn_loss: 0.0232, d_fake_loss: 0.0441, g_loss: 1.0917\n",
            "Step [39330/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0003, d_svhn_loss: 0.0528, d_fake_loss: 0.0269, g_loss: 1.1101\n",
            "Step [39340/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0013, d_svhn_loss: 0.0220, d_fake_loss: 0.0523, g_loss: 1.2580\n",
            "Step [39350/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0010, d_svhn_loss: 0.0205, d_fake_loss: 0.0449, g_loss: 1.0933\n",
            "Step [39360/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0008, d_svhn_loss: 0.0331, d_fake_loss: 0.0399, g_loss: 1.1520\n",
            "Step [39370/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0003, d_svhn_loss: 0.0258, d_fake_loss: 0.0690, g_loss: 1.0900\n",
            "Step [39380/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0009, d_svhn_loss: 0.0320, d_fake_loss: 0.0422, g_loss: 1.1642\n",
            "Step [39390/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0016, d_svhn_loss: 0.0263, d_fake_loss: 0.0387, g_loss: 1.0697\n",
            "Step [39400/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0010, d_svhn_loss: 0.0646, d_fake_loss: 0.0425, g_loss: 1.1568\n",
            "Step [39410/80000], d_real_loss: 0.1191, d_mnist_loss: 0.0008, d_svhn_loss: 0.1183, d_fake_loss: 0.1437, g_loss: 1.0742\n",
            "Step [39420/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0020, d_svhn_loss: 0.0166, d_fake_loss: 0.0237, g_loss: 1.1335\n",
            "Step [39430/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0011, d_svhn_loss: 0.0367, d_fake_loss: 0.0232, g_loss: 1.0918\n",
            "Step [39440/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0105, d_svhn_loss: 0.0275, d_fake_loss: 0.0255, g_loss: 1.1118\n",
            "Step [39450/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0010, d_svhn_loss: 0.0324, d_fake_loss: 0.0130, g_loss: 1.1873\n",
            "Step [39460/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0009, d_svhn_loss: 0.0297, d_fake_loss: 0.0306, g_loss: 1.1412\n",
            "Step [39470/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0004, d_svhn_loss: 0.0263, d_fake_loss: 0.0366, g_loss: 1.1438\n",
            "Step [39480/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0013, d_svhn_loss: 0.0287, d_fake_loss: 0.0873, g_loss: 1.1083\n",
            "Step [39490/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0040, d_svhn_loss: 0.0310, d_fake_loss: 0.0259, g_loss: 1.1212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [39500/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0021, d_svhn_loss: 0.0264, d_fake_loss: 0.0151, g_loss: 1.1205\n",
            "saved ./samples_mnist_svhn/sample-39500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-39500-s-m.png\n",
            "Step [39510/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0006, d_svhn_loss: 0.0361, d_fake_loss: 0.0409, g_loss: 1.2024\n",
            "Step [39520/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0004, d_svhn_loss: 0.0631, d_fake_loss: 0.0691, g_loss: 1.1237\n",
            "Step [39530/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0007, d_svhn_loss: 0.0205, d_fake_loss: 0.0327, g_loss: 1.1227\n",
            "Step [39540/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0013, d_svhn_loss: 0.0328, d_fake_loss: 0.0432, g_loss: 1.3359\n",
            "Step [39550/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0061, d_svhn_loss: 0.0536, d_fake_loss: 0.0557, g_loss: 1.0769\n",
            "Step [39560/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0041, d_svhn_loss: 0.0399, d_fake_loss: 0.0682, g_loss: 1.2164\n",
            "Step [39570/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0004, d_svhn_loss: 0.0230, d_fake_loss: 0.0284, g_loss: 1.1397\n",
            "Step [39580/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0024, d_svhn_loss: 0.0176, d_fake_loss: 0.0369, g_loss: 1.1081\n",
            "Step [39590/80000], d_real_loss: 0.0873, d_mnist_loss: 0.0013, d_svhn_loss: 0.0861, d_fake_loss: 0.0632, g_loss: 1.1388\n",
            "Step [39600/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0007, d_svhn_loss: 0.0400, d_fake_loss: 0.0279, g_loss: 1.1695\n",
            "Step [39610/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0004, d_svhn_loss: 0.0312, d_fake_loss: 0.0704, g_loss: 1.2687\n",
            "Step [39620/80000], d_real_loss: 0.1963, d_mnist_loss: 0.0005, d_svhn_loss: 0.1958, d_fake_loss: 0.0759, g_loss: 1.1105\n",
            "Step [39630/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0005, d_svhn_loss: 0.0391, d_fake_loss: 0.0319, g_loss: 1.1518\n",
            "Step [39640/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0077, d_svhn_loss: 0.0574, d_fake_loss: 0.0471, g_loss: 1.2282\n",
            "Step [39650/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0033, d_svhn_loss: 0.0557, d_fake_loss: 0.1093, g_loss: 1.1447\n",
            "Step [39660/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0008, d_svhn_loss: 0.0247, d_fake_loss: 0.0280, g_loss: 1.1377\n",
            "Step [39670/80000], d_real_loss: 0.1117, d_mnist_loss: 0.0004, d_svhn_loss: 0.1113, d_fake_loss: 0.0726, g_loss: 1.1592\n",
            "Step [39680/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0023, d_svhn_loss: 0.0188, d_fake_loss: 0.0583, g_loss: 1.2457\n",
            "Step [39690/80000], d_real_loss: 0.1421, d_mnist_loss: 0.0063, d_svhn_loss: 0.1358, d_fake_loss: 0.0326, g_loss: 1.1815\n",
            "Step [39700/80000], d_real_loss: 0.1057, d_mnist_loss: 0.0038, d_svhn_loss: 0.1019, d_fake_loss: 0.0359, g_loss: 1.1986\n",
            "Step [39710/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0012, d_svhn_loss: 0.0580, d_fake_loss: 0.1114, g_loss: 1.1653\n",
            "Step [39720/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0003, d_svhn_loss: 0.0459, d_fake_loss: 0.0617, g_loss: 1.1207\n",
            "Step [39730/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0009, d_svhn_loss: 0.0193, d_fake_loss: 0.0175, g_loss: 1.1130\n",
            "Step [39740/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0004, d_svhn_loss: 0.0912, d_fake_loss: 0.0221, g_loss: 1.1265\n",
            "Step [39750/80000], d_real_loss: 0.1500, d_mnist_loss: 0.0004, d_svhn_loss: 0.1495, d_fake_loss: 0.0805, g_loss: 1.0995\n",
            "Step [39760/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0007, d_svhn_loss: 0.0781, d_fake_loss: 0.0424, g_loss: 1.1426\n",
            "Step [39770/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0011, d_svhn_loss: 0.0503, d_fake_loss: 0.0175, g_loss: 1.1551\n",
            "Step [39780/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0008, d_svhn_loss: 0.0496, d_fake_loss: 0.1077, g_loss: 1.1167\n",
            "Step [39790/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0014, d_svhn_loss: 0.0298, d_fake_loss: 0.0259, g_loss: 1.1618\n",
            "Step [39800/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0007, d_svhn_loss: 0.0663, d_fake_loss: 0.0228, g_loss: 1.1255\n",
            "Step [39810/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0008, d_svhn_loss: 0.0293, d_fake_loss: 0.1033, g_loss: 1.0995\n",
            "Step [39820/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0037, d_svhn_loss: 0.0448, d_fake_loss: 0.0369, g_loss: 1.1514\n",
            "Step [39830/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0013, d_svhn_loss: 0.0561, d_fake_loss: 0.0194, g_loss: 1.1743\n",
            "Step [39840/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0026, d_svhn_loss: 0.0396, d_fake_loss: 0.0780, g_loss: 1.1158\n",
            "Step [39850/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0022, d_svhn_loss: 0.0243, d_fake_loss: 0.0310, g_loss: 1.1240\n",
            "Step [39860/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0013, d_svhn_loss: 0.0211, d_fake_loss: 0.0268, g_loss: 1.2187\n",
            "Step [39870/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0135, d_svhn_loss: 0.0414, d_fake_loss: 0.0441, g_loss: 1.0760\n",
            "Step [39880/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0051, d_svhn_loss: 0.0290, d_fake_loss: 0.0792, g_loss: 1.1632\n",
            "Step [39890/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0215, d_svhn_loss: 0.0348, d_fake_loss: 0.0316, g_loss: 1.0169\n",
            "Step [39900/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0129, d_svhn_loss: 0.0442, d_fake_loss: 0.0984, g_loss: 1.3310\n",
            "Step [39910/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0068, d_svhn_loss: 0.0320, d_fake_loss: 0.0267, g_loss: 1.2010\n",
            "Step [39920/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0142, d_svhn_loss: 0.0327, d_fake_loss: 0.1434, g_loss: 1.4298\n",
            "Step [39930/80000], d_real_loss: 0.0213, d_mnist_loss: 0.0022, d_svhn_loss: 0.0191, d_fake_loss: 0.0391, g_loss: 0.9479\n",
            "Step [39940/80000], d_real_loss: 0.0987, d_mnist_loss: 0.0650, d_svhn_loss: 0.0336, d_fake_loss: 0.1022, g_loss: 1.1652\n",
            "Step [39950/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0064, d_svhn_loss: 0.0289, d_fake_loss: 0.0555, g_loss: 1.3287\n",
            "Step [39960/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0020, d_svhn_loss: 0.0428, d_fake_loss: 0.0207, g_loss: 1.1341\n",
            "Step [39970/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0013, d_svhn_loss: 0.0294, d_fake_loss: 0.0444, g_loss: 1.1372\n",
            "Step [39980/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0021, d_svhn_loss: 0.0372, d_fake_loss: 0.1053, g_loss: 1.2050\n",
            "Step [39990/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0094, d_svhn_loss: 0.0221, d_fake_loss: 0.0465, g_loss: 1.2812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [40000/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0099, d_svhn_loss: 0.0300, d_fake_loss: 0.0773, g_loss: 1.3037\n",
            "saved ./samples_mnist_svhn/sample-40000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-40000-s-m.png\n",
            "Step [40010/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0062, d_svhn_loss: 0.0206, d_fake_loss: 0.0199, g_loss: 1.1337\n",
            "Step [40020/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0021, d_svhn_loss: 0.0204, d_fake_loss: 0.0540, g_loss: 1.1650\n",
            "Step [40030/80000], d_real_loss: 0.0807, d_mnist_loss: 0.0013, d_svhn_loss: 0.0794, d_fake_loss: 0.0632, g_loss: 1.1938\n",
            "Step [40040/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0235, d_svhn_loss: 0.0192, d_fake_loss: 0.0273, g_loss: 1.1542\n",
            "Step [40050/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0018, d_svhn_loss: 0.0579, d_fake_loss: 0.0172, g_loss: 1.1150\n",
            "Step [40060/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0111, d_svhn_loss: 0.0210, d_fake_loss: 0.0706, g_loss: 1.2422\n",
            "Step [40070/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0051, d_svhn_loss: 0.0487, d_fake_loss: 0.0296, g_loss: 1.3973\n",
            "Step [40080/80000], d_real_loss: 0.0909, d_mnist_loss: 0.0134, d_svhn_loss: 0.0774, d_fake_loss: 0.0227, g_loss: 1.3848\n",
            "Step [40090/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0018, d_svhn_loss: 0.0412, d_fake_loss: 0.0364, g_loss: 1.1002\n",
            "Step [40100/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0012, d_svhn_loss: 0.0194, d_fake_loss: 0.0374, g_loss: 1.0770\n",
            "Step [40110/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0013, d_svhn_loss: 0.0213, d_fake_loss: 0.0223, g_loss: 1.1211\n",
            "Step [40120/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0010, d_svhn_loss: 0.0373, d_fake_loss: 0.0187, g_loss: 1.1544\n",
            "Step [40130/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0022, d_svhn_loss: 0.0507, d_fake_loss: 0.1266, g_loss: 1.1343\n",
            "Step [40140/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0037, d_svhn_loss: 0.0197, d_fake_loss: 0.0386, g_loss: 1.0938\n",
            "Step [40150/80000], d_real_loss: 0.0917, d_mnist_loss: 0.0085, d_svhn_loss: 0.0832, d_fake_loss: 0.0514, g_loss: 1.0401\n",
            "Step [40160/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0014, d_svhn_loss: 0.0528, d_fake_loss: 0.0280, g_loss: 1.0722\n",
            "Step [40170/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0007, d_svhn_loss: 0.0617, d_fake_loss: 0.0624, g_loss: 1.0605\n",
            "Step [40180/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0034, d_svhn_loss: 0.0806, d_fake_loss: 0.0263, g_loss: 1.1638\n",
            "Step [40190/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0020, d_svhn_loss: 0.0400, d_fake_loss: 0.0314, g_loss: 1.1169\n",
            "Step [40200/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0085, d_svhn_loss: 0.0459, d_fake_loss: 0.0448, g_loss: 1.0521\n",
            "Step [40210/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0041, d_svhn_loss: 0.0586, d_fake_loss: 0.0269, g_loss: 1.0625\n",
            "Step [40220/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0010, d_svhn_loss: 0.0452, d_fake_loss: 0.0337, g_loss: 1.1362\n",
            "Step [40230/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0032, d_svhn_loss: 0.0172, d_fake_loss: 0.0200, g_loss: 1.1272\n",
            "Step [40240/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0007, d_svhn_loss: 0.0269, d_fake_loss: 0.1284, g_loss: 1.0875\n",
            "Step [40250/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0013, d_svhn_loss: 0.0224, d_fake_loss: 0.0470, g_loss: 1.1069\n",
            "Step [40260/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0005, d_svhn_loss: 0.0245, d_fake_loss: 0.0259, g_loss: 1.0959\n",
            "Step [40270/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0020, d_svhn_loss: 0.0317, d_fake_loss: 0.0214, g_loss: 1.1052\n",
            "Step [40280/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0096, d_svhn_loss: 0.0254, d_fake_loss: 0.0513, g_loss: 1.8936\n",
            "Step [40290/80000], d_real_loss: 0.3833, d_mnist_loss: 0.3523, d_svhn_loss: 0.0310, d_fake_loss: 0.2466, g_loss: 1.0555\n",
            "Step [40300/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0425, d_svhn_loss: 0.0168, d_fake_loss: 0.0595, g_loss: 1.0081\n",
            "Step [40310/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0049, d_svhn_loss: 0.0588, d_fake_loss: 0.0670, g_loss: 1.0900\n",
            "Step [40320/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0050, d_svhn_loss: 0.0220, d_fake_loss: 0.0634, g_loss: 1.1581\n",
            "Step [40330/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0062, d_svhn_loss: 0.0254, d_fake_loss: 0.1229, g_loss: 1.3627\n",
            "Step [40340/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0237, d_svhn_loss: 0.0180, d_fake_loss: 0.0237, g_loss: 1.2341\n",
            "Step [40350/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0031, d_svhn_loss: 0.0399, d_fake_loss: 0.0571, g_loss: 1.1766\n",
            "Step [40360/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0007, d_svhn_loss: 0.0457, d_fake_loss: 0.0302, g_loss: 1.1617\n",
            "Step [40370/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0025, d_svhn_loss: 0.0497, d_fake_loss: 0.0314, g_loss: 1.1815\n",
            "Step [40380/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0019, d_svhn_loss: 0.0320, d_fake_loss: 0.0265, g_loss: 1.1044\n",
            "Step [40390/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0031, d_svhn_loss: 0.0273, d_fake_loss: 0.0251, g_loss: 1.1286\n",
            "Step [40400/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0010, d_svhn_loss: 0.0556, d_fake_loss: 0.0327, g_loss: 1.1569\n",
            "Step [40410/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0020, d_svhn_loss: 0.0277, d_fake_loss: 0.0205, g_loss: 1.1211\n",
            "Step [40420/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0036, d_svhn_loss: 0.0421, d_fake_loss: 0.0228, g_loss: 1.0952\n",
            "Step [40430/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0010, d_svhn_loss: 0.0760, d_fake_loss: 0.0437, g_loss: 1.1354\n",
            "Step [40440/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0008, d_svhn_loss: 0.0452, d_fake_loss: 0.1532, g_loss: 1.1484\n",
            "Step [40450/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0019, d_svhn_loss: 0.0336, d_fake_loss: 0.1545, g_loss: 1.1388\n",
            "Step [40460/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0047, d_svhn_loss: 0.0234, d_fake_loss: 0.1145, g_loss: 1.1259\n",
            "Step [40470/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0018, d_svhn_loss: 0.0252, d_fake_loss: 0.0503, g_loss: 1.1841\n",
            "Step [40480/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0383, d_svhn_loss: 0.0366, d_fake_loss: 0.0551, g_loss: 1.1384\n",
            "Step [40490/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0055, d_svhn_loss: 0.0259, d_fake_loss: 0.0559, g_loss: 1.1881\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [40500/80000], d_real_loss: 0.0934, d_mnist_loss: 0.0020, d_svhn_loss: 0.0913, d_fake_loss: 0.0344, g_loss: 1.1309\n",
            "saved ./samples_mnist_svhn/sample-40500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-40500-s-m.png\n",
            "Step [40510/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0010, d_svhn_loss: 0.0250, d_fake_loss: 0.0208, g_loss: 1.1459\n",
            "Step [40520/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0023, d_svhn_loss: 0.0713, d_fake_loss: 0.0425, g_loss: 1.1743\n",
            "Step [40530/80000], d_real_loss: 0.0176, d_mnist_loss: 0.0013, d_svhn_loss: 0.0163, d_fake_loss: 0.0286, g_loss: 1.1052\n",
            "Step [40540/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0009, d_svhn_loss: 0.0320, d_fake_loss: 0.0189, g_loss: 1.0930\n",
            "Step [40550/80000], d_real_loss: 0.0142, d_mnist_loss: 0.0007, d_svhn_loss: 0.0135, d_fake_loss: 0.1339, g_loss: 1.1088\n",
            "Step [40560/80000], d_real_loss: 0.1664, d_mnist_loss: 0.0057, d_svhn_loss: 0.1608, d_fake_loss: 0.0303, g_loss: 1.0599\n",
            "Step [40570/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0008, d_svhn_loss: 0.0239, d_fake_loss: 0.0155, g_loss: 1.1256\n",
            "Step [40580/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0013, d_svhn_loss: 0.0347, d_fake_loss: 0.2150, g_loss: 1.1100\n",
            "Step [40590/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0017, d_svhn_loss: 0.0500, d_fake_loss: 0.0297, g_loss: 1.0805\n",
            "Step [40600/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0010, d_svhn_loss: 0.0552, d_fake_loss: 0.0449, g_loss: 1.1425\n",
            "Step [40610/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0011, d_svhn_loss: 0.0290, d_fake_loss: 0.0233, g_loss: 1.0930\n",
            "Step [40620/80000], d_real_loss: 0.0880, d_mnist_loss: 0.0005, d_svhn_loss: 0.0875, d_fake_loss: 0.0398, g_loss: 1.0882\n",
            "Step [40630/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0084, d_svhn_loss: 0.0360, d_fake_loss: 0.0183, g_loss: 1.1095\n",
            "Step [40640/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0024, d_svhn_loss: 0.0171, d_fake_loss: 0.0484, g_loss: 1.4767\n",
            "Step [40650/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0013, d_svhn_loss: 0.0243, d_fake_loss: 0.0310, g_loss: 1.1166\n",
            "Step [40660/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0015, d_svhn_loss: 0.0373, d_fake_loss: 0.0276, g_loss: 1.1146\n",
            "Step [40670/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0045, d_svhn_loss: 0.0434, d_fake_loss: 0.0231, g_loss: 1.1648\n",
            "Step [40680/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0008, d_svhn_loss: 0.0884, d_fake_loss: 0.0723, g_loss: 1.1284\n",
            "Step [40690/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0016, d_svhn_loss: 0.0589, d_fake_loss: 0.0203, g_loss: 1.1438\n",
            "Step [40700/80000], d_real_loss: 0.0193, d_mnist_loss: 0.0010, d_svhn_loss: 0.0182, d_fake_loss: 0.0189, g_loss: 1.1007\n",
            "Step [40710/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0004, d_svhn_loss: 0.0214, d_fake_loss: 0.0299, g_loss: 1.1183\n",
            "Step [40720/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0006, d_svhn_loss: 0.0638, d_fake_loss: 0.0252, g_loss: 1.0861\n",
            "Step [40730/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0108, d_svhn_loss: 0.0228, d_fake_loss: 0.0384, g_loss: 1.2053\n",
            "Step [40740/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0022, d_svhn_loss: 0.0348, d_fake_loss: 0.0343, g_loss: 1.1367\n",
            "Step [40750/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0012, d_svhn_loss: 0.0350, d_fake_loss: 0.0231, g_loss: 1.0981\n",
            "Step [40760/80000], d_real_loss: 0.1140, d_mnist_loss: 0.0017, d_svhn_loss: 0.1123, d_fake_loss: 0.0577, g_loss: 1.2232\n",
            "Step [40770/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0019, d_svhn_loss: 0.0450, d_fake_loss: 0.0342, g_loss: 1.0293\n",
            "Step [40780/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0046, d_svhn_loss: 0.0286, d_fake_loss: 0.0357, g_loss: 1.1168\n",
            "Step [40790/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0190, d_svhn_loss: 0.0246, d_fake_loss: 0.0170, g_loss: 1.1970\n",
            "Step [40800/80000], d_real_loss: 0.1099, d_mnist_loss: 0.0752, d_svhn_loss: 0.0347, d_fake_loss: 0.1322, g_loss: 1.2186\n",
            "Step [40810/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0050, d_svhn_loss: 0.0321, d_fake_loss: 0.0226, g_loss: 1.0970\n",
            "Step [40820/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0069, d_svhn_loss: 0.0313, d_fake_loss: 0.0378, g_loss: 1.1577\n",
            "Step [40830/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0035, d_svhn_loss: 0.0237, d_fake_loss: 0.0201, g_loss: 1.1352\n",
            "Step [40840/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0041, d_svhn_loss: 0.0434, d_fake_loss: 0.0236, g_loss: 1.1277\n",
            "Step [40850/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0044, d_svhn_loss: 0.0404, d_fake_loss: 0.0427, g_loss: 1.0862\n",
            "Step [40860/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0013, d_svhn_loss: 0.0240, d_fake_loss: 0.0631, g_loss: 1.1314\n",
            "Step [40870/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0027, d_svhn_loss: 0.0488, d_fake_loss: 0.0770, g_loss: 1.0669\n",
            "Step [40880/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0014, d_svhn_loss: 0.0178, d_fake_loss: 0.0838, g_loss: 1.0971\n",
            "Step [40890/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0039, d_svhn_loss: 0.0573, d_fake_loss: 0.0405, g_loss: 1.1607\n",
            "Step [40900/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0132, d_svhn_loss: 0.0329, d_fake_loss: 0.0321, g_loss: 1.0588\n",
            "Step [40910/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0009, d_svhn_loss: 0.0337, d_fake_loss: 0.0230, g_loss: 1.1449\n",
            "Step [40920/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0016, d_svhn_loss: 0.0288, d_fake_loss: 0.0228, g_loss: 1.1410\n",
            "Step [40930/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0010, d_svhn_loss: 0.0187, d_fake_loss: 0.0196, g_loss: 1.1910\n",
            "Step [40940/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0011, d_svhn_loss: 0.0235, d_fake_loss: 0.0951, g_loss: 1.3120\n",
            "Step [40950/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0011, d_svhn_loss: 0.0264, d_fake_loss: 0.0169, g_loss: 1.1619\n",
            "Step [40960/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0091, d_svhn_loss: 0.0211, d_fake_loss: 0.0482, g_loss: 1.2462\n",
            "Step [40970/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0010, d_svhn_loss: 0.0350, d_fake_loss: 0.0241, g_loss: 1.1009\n",
            "Step [40980/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0012, d_svhn_loss: 0.0203, d_fake_loss: 0.0577, g_loss: 1.3323\n",
            "Step [40990/80000], d_real_loss: 0.0188, d_mnist_loss: 0.0010, d_svhn_loss: 0.0178, d_fake_loss: 0.0550, g_loss: 1.1378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [41000/80000], d_real_loss: 0.1161, d_mnist_loss: 0.0013, d_svhn_loss: 0.1148, d_fake_loss: 0.1649, g_loss: 1.2199\n",
            "saved ./samples_mnist_svhn/sample-41000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-41000-s-m.png\n",
            "Step [41010/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0077, d_svhn_loss: 0.0324, d_fake_loss: 0.0332, g_loss: 1.2351\n",
            "Step [41020/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0032, d_svhn_loss: 0.0293, d_fake_loss: 0.0450, g_loss: 1.1318\n",
            "Step [41030/80000], d_real_loss: 0.0942, d_mnist_loss: 0.0076, d_svhn_loss: 0.0866, d_fake_loss: 0.0672, g_loss: 1.0204\n",
            "Step [41040/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0116, d_svhn_loss: 0.0242, d_fake_loss: 0.0477, g_loss: 1.1098\n",
            "Step [41050/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0018, d_svhn_loss: 0.0188, d_fake_loss: 0.0639, g_loss: 1.1209\n",
            "Step [41060/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0019, d_svhn_loss: 0.0384, d_fake_loss: 0.0426, g_loss: 1.2560\n",
            "Step [41070/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0011, d_svhn_loss: 0.0219, d_fake_loss: 0.0405, g_loss: 1.1533\n",
            "Step [41080/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0014, d_svhn_loss: 0.0290, d_fake_loss: 0.0296, g_loss: 1.1082\n",
            "Step [41090/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0052, d_svhn_loss: 0.0294, d_fake_loss: 0.1141, g_loss: 1.1895\n",
            "Step [41100/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0017, d_svhn_loss: 0.0333, d_fake_loss: 0.0449, g_loss: 1.1497\n",
            "Step [41110/80000], d_real_loss: 0.1494, d_mnist_loss: 0.0028, d_svhn_loss: 0.1466, d_fake_loss: 0.0637, g_loss: 1.1126\n",
            "Step [41120/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0026, d_svhn_loss: 0.0195, d_fake_loss: 0.0255, g_loss: 1.1767\n",
            "Step [41130/80000], d_real_loss: 0.0747, d_mnist_loss: 0.0079, d_svhn_loss: 0.0669, d_fake_loss: 0.0201, g_loss: 1.1261\n",
            "Step [41140/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0077, d_svhn_loss: 0.0426, d_fake_loss: 0.0300, g_loss: 1.1202\n",
            "Step [41150/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0024, d_svhn_loss: 0.0283, d_fake_loss: 0.0583, g_loss: 1.1555\n",
            "Step [41160/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0017, d_svhn_loss: 0.0360, d_fake_loss: 0.0238, g_loss: 1.0513\n",
            "Step [41170/80000], d_real_loss: 0.1102, d_mnist_loss: 0.0088, d_svhn_loss: 0.1014, d_fake_loss: 0.0953, g_loss: 1.1539\n",
            "Step [41180/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0015, d_svhn_loss: 0.0319, d_fake_loss: 0.0192, g_loss: 1.0746\n",
            "Step [41190/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0027, d_svhn_loss: 0.0236, d_fake_loss: 0.0203, g_loss: 1.0570\n",
            "Step [41200/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0017, d_svhn_loss: 0.0647, d_fake_loss: 0.0192, g_loss: 1.1126\n",
            "Step [41210/80000], d_real_loss: 0.2525, d_mnist_loss: 0.0012, d_svhn_loss: 0.2513, d_fake_loss: 0.2166, g_loss: 1.1028\n",
            "Step [41220/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0041, d_svhn_loss: 0.0398, d_fake_loss: 0.0248, g_loss: 1.1314\n",
            "Step [41230/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0020, d_svhn_loss: 0.0198, d_fake_loss: 0.0175, g_loss: 1.1393\n",
            "Step [41240/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0007, d_svhn_loss: 0.0513, d_fake_loss: 0.0256, g_loss: 1.1265\n",
            "Step [41250/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0008, d_svhn_loss: 0.0418, d_fake_loss: 0.0204, g_loss: 1.1073\n",
            "Step [41260/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0040, d_svhn_loss: 0.0525, d_fake_loss: 0.0152, g_loss: 1.0916\n",
            "Step [41270/80000], d_real_loss: 0.0213, d_mnist_loss: 0.0020, d_svhn_loss: 0.0194, d_fake_loss: 0.0160, g_loss: 1.1289\n",
            "Step [41280/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0006, d_svhn_loss: 0.0727, d_fake_loss: 0.0361, g_loss: 1.1184\n",
            "Step [41290/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0045, d_svhn_loss: 0.0271, d_fake_loss: 0.0153, g_loss: 1.1342\n",
            "Step [41300/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0022, d_svhn_loss: 0.0194, d_fake_loss: 0.0247, g_loss: 1.0870\n",
            "Step [41310/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0009, d_svhn_loss: 0.0305, d_fake_loss: 0.0400, g_loss: 1.1153\n",
            "Step [41320/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0005, d_svhn_loss: 0.0764, d_fake_loss: 0.0403, g_loss: 1.0996\n",
            "Step [41330/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0029, d_svhn_loss: 0.0207, d_fake_loss: 0.0347, g_loss: 1.0779\n",
            "Step [41340/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0011, d_svhn_loss: 0.0273, d_fake_loss: 0.0792, g_loss: 1.0940\n",
            "Step [41350/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0014, d_svhn_loss: 0.0251, d_fake_loss: 0.0252, g_loss: 1.1019\n",
            "Step [41360/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0007, d_svhn_loss: 0.0317, d_fake_loss: 0.0752, g_loss: 1.0894\n",
            "Step [41370/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0088, d_svhn_loss: 0.0540, d_fake_loss: 0.0463, g_loss: 1.0621\n",
            "Step [41380/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0008, d_svhn_loss: 0.0423, d_fake_loss: 0.0611, g_loss: 1.1310\n",
            "Step [41390/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0032, d_svhn_loss: 0.0277, d_fake_loss: 0.2404, g_loss: 1.1369\n",
            "Step [41400/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0021, d_svhn_loss: 0.0418, d_fake_loss: 0.0202, g_loss: 1.1081\n",
            "Step [41410/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0021, d_svhn_loss: 0.0322, d_fake_loss: 0.0200, g_loss: 1.1676\n",
            "Step [41420/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0011, d_svhn_loss: 0.0224, d_fake_loss: 0.0658, g_loss: 1.0932\n",
            "Step [41430/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0007, d_svhn_loss: 0.0476, d_fake_loss: 0.0521, g_loss: 1.0849\n",
            "Step [41440/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0015, d_svhn_loss: 0.0251, d_fake_loss: 0.0280, g_loss: 1.0927\n",
            "Step [41450/80000], d_real_loss: 0.0193, d_mnist_loss: 0.0037, d_svhn_loss: 0.0156, d_fake_loss: 0.2273, g_loss: 1.1455\n",
            "Step [41460/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0060, d_svhn_loss: 0.0181, d_fake_loss: 0.0429, g_loss: 1.0915\n",
            "Step [41470/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0013, d_svhn_loss: 0.0283, d_fake_loss: 0.0418, g_loss: 1.0947\n",
            "Step [41480/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0017, d_svhn_loss: 0.0279, d_fake_loss: 0.0146, g_loss: 1.1521\n",
            "Step [41490/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0007, d_svhn_loss: 0.0489, d_fake_loss: 0.0200, g_loss: 1.1240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [41500/80000], d_real_loss: 0.0701, d_mnist_loss: 0.0071, d_svhn_loss: 0.0630, d_fake_loss: 0.0506, g_loss: 1.0366\n",
            "saved ./samples_mnist_svhn/sample-41500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-41500-s-m.png\n",
            "Step [41510/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0005, d_svhn_loss: 0.0395, d_fake_loss: 0.0273, g_loss: 1.1033\n",
            "Step [41520/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0006, d_svhn_loss: 0.0264, d_fake_loss: 0.0278, g_loss: 1.1110\n",
            "Step [41530/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0010, d_svhn_loss: 0.0404, d_fake_loss: 0.0662, g_loss: 1.0962\n",
            "Step [41540/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0006, d_svhn_loss: 0.0308, d_fake_loss: 0.0310, g_loss: 1.1405\n",
            "Step [41550/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0007, d_svhn_loss: 0.0230, d_fake_loss: 0.0209, g_loss: 1.1182\n",
            "Step [41560/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0006, d_svhn_loss: 0.0662, d_fake_loss: 0.0728, g_loss: 1.1046\n",
            "Step [41570/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0005, d_svhn_loss: 0.0661, d_fake_loss: 0.0472, g_loss: 1.0888\n",
            "Step [41580/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0029, d_svhn_loss: 0.0305, d_fake_loss: 0.0199, g_loss: 1.1398\n",
            "Step [41590/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0007, d_svhn_loss: 0.0407, d_fake_loss: 0.0926, g_loss: 1.1319\n",
            "Step [41600/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0017, d_svhn_loss: 0.0203, d_fake_loss: 0.0215, g_loss: 1.1370\n",
            "Step [41610/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0010, d_svhn_loss: 0.0195, d_fake_loss: 0.0151, g_loss: 1.1203\n",
            "Step [41620/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0010, d_svhn_loss: 0.0294, d_fake_loss: 0.0234, g_loss: 1.1305\n",
            "Step [41630/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0020, d_svhn_loss: 0.0401, d_fake_loss: 0.0247, g_loss: 1.1680\n",
            "Step [41640/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0004, d_svhn_loss: 0.0235, d_fake_loss: 0.0214, g_loss: 1.0528\n",
            "Step [41650/80000], d_real_loss: 0.1394, d_mnist_loss: 0.0010, d_svhn_loss: 0.1384, d_fake_loss: 0.0612, g_loss: 1.0706\n",
            "Step [41660/80000], d_real_loss: 0.1175, d_mnist_loss: 0.0010, d_svhn_loss: 0.1164, d_fake_loss: 0.0425, g_loss: 1.0940\n",
            "Step [41670/80000], d_real_loss: 0.1451, d_mnist_loss: 0.0008, d_svhn_loss: 0.1442, d_fake_loss: 0.2250, g_loss: 1.1151\n",
            "Step [41680/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0004, d_svhn_loss: 0.0393, d_fake_loss: 0.0178, g_loss: 1.1055\n",
            "Step [41690/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0003, d_svhn_loss: 0.0283, d_fake_loss: 0.0473, g_loss: 1.1057\n",
            "Step [41700/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0011, d_svhn_loss: 0.0162, d_fake_loss: 0.0421, g_loss: 1.1240\n",
            "Step [41710/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0011, d_svhn_loss: 0.0416, d_fake_loss: 0.0329, g_loss: 1.0673\n",
            "Step [41720/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0005, d_svhn_loss: 0.0319, d_fake_loss: 0.0374, g_loss: 1.1305\n",
            "Step [41730/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0012, d_svhn_loss: 0.0205, d_fake_loss: 0.0542, g_loss: 1.3401\n",
            "Step [41740/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0009, d_svhn_loss: 0.0363, d_fake_loss: 0.0592, g_loss: 1.0778\n",
            "Step [41750/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0007, d_svhn_loss: 0.0203, d_fake_loss: 0.0508, g_loss: 1.1067\n",
            "Step [41760/80000], d_real_loss: 0.0170, d_mnist_loss: 0.0006, d_svhn_loss: 0.0164, d_fake_loss: 0.1060, g_loss: 1.2326\n",
            "Step [41770/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0013, d_svhn_loss: 0.0269, d_fake_loss: 0.0579, g_loss: 1.0875\n",
            "Step [41780/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0041, d_svhn_loss: 0.0306, d_fake_loss: 0.1613, g_loss: 1.1833\n",
            "Step [41790/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0033, d_svhn_loss: 0.0242, d_fake_loss: 0.0272, g_loss: 1.0881\n",
            "Step [41800/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0011, d_svhn_loss: 0.0184, d_fake_loss: 0.0268, g_loss: 1.1271\n",
            "Step [41810/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0011, d_svhn_loss: 0.0291, d_fake_loss: 0.0151, g_loss: 1.1118\n",
            "Step [41820/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0019, d_svhn_loss: 0.0605, d_fake_loss: 0.0164, g_loss: 1.1694\n",
            "Step [41830/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0258, d_svhn_loss: 0.0305, d_fake_loss: 0.0284, g_loss: 1.0396\n",
            "Step [41840/80000], d_real_loss: 0.1014, d_mnist_loss: 0.0170, d_svhn_loss: 0.0844, d_fake_loss: 0.0321, g_loss: 1.1088\n",
            "Step [41850/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0081, d_svhn_loss: 0.0223, d_fake_loss: 0.0668, g_loss: 1.2005\n",
            "Step [41860/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0057, d_svhn_loss: 0.0433, d_fake_loss: 0.0329, g_loss: 1.2742\n",
            "Step [41870/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0056, d_svhn_loss: 0.0311, d_fake_loss: 0.0262, g_loss: 1.1571\n",
            "Step [41880/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0020, d_svhn_loss: 0.0354, d_fake_loss: 0.1174, g_loss: 1.4873\n",
            "Step [41890/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0239, d_svhn_loss: 0.0318, d_fake_loss: 0.0255, g_loss: 1.4102\n",
            "Step [41900/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0012, d_svhn_loss: 0.0263, d_fake_loss: 0.0490, g_loss: 1.1478\n",
            "Step [41910/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0135, d_svhn_loss: 0.0408, d_fake_loss: 0.0255, g_loss: 1.2481\n",
            "Step [41920/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0066, d_svhn_loss: 0.0409, d_fake_loss: 0.0226, g_loss: 1.2056\n",
            "Step [41930/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0135, d_svhn_loss: 0.0364, d_fake_loss: 0.0363, g_loss: 1.3468\n",
            "Step [41940/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0018, d_svhn_loss: 0.0158, d_fake_loss: 0.0156, g_loss: 1.1895\n",
            "Step [41950/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0057, d_svhn_loss: 0.0575, d_fake_loss: 0.0675, g_loss: 1.2900\n",
            "Step [41960/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0017, d_svhn_loss: 0.0381, d_fake_loss: 0.0325, g_loss: 1.3763\n",
            "Step [41970/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0033, d_svhn_loss: 0.0206, d_fake_loss: 0.0290, g_loss: 1.0967\n",
            "Step [41980/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0017, d_svhn_loss: 0.0242, d_fake_loss: 0.0333, g_loss: 1.3432\n",
            "Step [41990/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0017, d_svhn_loss: 0.0351, d_fake_loss: 0.0638, g_loss: 1.2716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [42000/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0014, d_svhn_loss: 0.0354, d_fake_loss: 0.0692, g_loss: 1.0547\n",
            "saved ./samples_mnist_svhn/sample-42000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-42000-s-m.png\n",
            "Step [42010/80000], d_real_loss: 0.0147, d_mnist_loss: 0.0017, d_svhn_loss: 0.0130, d_fake_loss: 0.0291, g_loss: 1.1795\n",
            "Step [42020/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0015, d_svhn_loss: 0.0206, d_fake_loss: 0.0750, g_loss: 1.3046\n",
            "Step [42030/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0200, d_svhn_loss: 0.0241, d_fake_loss: 0.0252, g_loss: 1.1321\n",
            "Step [42040/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0015, d_svhn_loss: 0.0416, d_fake_loss: 0.0667, g_loss: 1.1268\n",
            "Step [42050/80000], d_real_loss: 0.1110, d_mnist_loss: 0.0033, d_svhn_loss: 0.1078, d_fake_loss: 0.0518, g_loss: 1.1695\n",
            "Step [42060/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0022, d_svhn_loss: 0.0432, d_fake_loss: 0.0538, g_loss: 1.2182\n",
            "Step [42070/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0048, d_svhn_loss: 0.0507, d_fake_loss: 0.0305, g_loss: 1.0783\n",
            "Step [42080/80000], d_real_loss: 0.1030, d_mnist_loss: 0.0033, d_svhn_loss: 0.0997, d_fake_loss: 0.0388, g_loss: 1.1506\n",
            "Step [42090/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0020, d_svhn_loss: 0.0208, d_fake_loss: 0.0196, g_loss: 1.1492\n",
            "Step [42100/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0083, d_svhn_loss: 0.0233, d_fake_loss: 0.0300, g_loss: 1.3340\n",
            "Step [42110/80000], d_real_loss: 0.1015, d_mnist_loss: 0.0084, d_svhn_loss: 0.0931, d_fake_loss: 0.0523, g_loss: 1.0716\n",
            "Step [42120/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0112, d_svhn_loss: 0.0162, d_fake_loss: 0.0690, g_loss: 1.1578\n",
            "Step [42130/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0044, d_svhn_loss: 0.0223, d_fake_loss: 0.0353, g_loss: 1.1906\n",
            "Step [42140/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0012, d_svhn_loss: 0.0292, d_fake_loss: 0.0491, g_loss: 1.1341\n",
            "Step [42150/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0043, d_svhn_loss: 0.0317, d_fake_loss: 0.0219, g_loss: 1.1537\n",
            "Step [42160/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0050, d_svhn_loss: 0.0264, d_fake_loss: 0.0202, g_loss: 1.1620\n",
            "Step [42170/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0015, d_svhn_loss: 0.0190, d_fake_loss: 0.0615, g_loss: 1.2297\n",
            "Step [42180/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0010, d_svhn_loss: 0.0458, d_fake_loss: 0.0503, g_loss: 1.1979\n",
            "Step [42190/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0019, d_svhn_loss: 0.0250, d_fake_loss: 0.0613, g_loss: 1.1322\n",
            "Step [42200/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0008, d_svhn_loss: 0.0565, d_fake_loss: 0.0448, g_loss: 1.3179\n",
            "Step [42210/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0118, d_svhn_loss: 0.0246, d_fake_loss: 0.0573, g_loss: 1.2108\n",
            "Step [42220/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0016, d_svhn_loss: 0.0325, d_fake_loss: 0.0382, g_loss: 1.2892\n",
            "Step [42230/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0016, d_svhn_loss: 0.0325, d_fake_loss: 0.0312, g_loss: 1.1116\n",
            "Step [42240/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0010, d_svhn_loss: 0.0483, d_fake_loss: 0.0932, g_loss: 1.1602\n",
            "Step [42250/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0012, d_svhn_loss: 0.0306, d_fake_loss: 0.0226, g_loss: 1.0804\n",
            "Step [42260/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0048, d_svhn_loss: 0.0204, d_fake_loss: 0.0487, g_loss: 1.1077\n",
            "Step [42270/80000], d_real_loss: 0.1357, d_mnist_loss: 0.0092, d_svhn_loss: 0.1265, d_fake_loss: 0.0332, g_loss: 1.1668\n",
            "Step [42280/80000], d_real_loss: 0.0855, d_mnist_loss: 0.0584, d_svhn_loss: 0.0270, d_fake_loss: 0.0569, g_loss: 1.1527\n",
            "Step [42290/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0099, d_svhn_loss: 0.0581, d_fake_loss: 0.0561, g_loss: 1.0496\n",
            "Step [42300/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0035, d_svhn_loss: 0.0336, d_fake_loss: 0.1443, g_loss: 1.0582\n",
            "Step [42310/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0274, d_svhn_loss: 0.0231, d_fake_loss: 0.0194, g_loss: 1.0566\n",
            "Step [42320/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0126, d_svhn_loss: 0.0231, d_fake_loss: 0.0273, g_loss: 1.1202\n",
            "Step [42330/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0088, d_svhn_loss: 0.0269, d_fake_loss: 0.0341, g_loss: 1.1909\n",
            "Step [42340/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0038, d_svhn_loss: 0.0646, d_fake_loss: 0.0242, g_loss: 1.0606\n",
            "Step [42350/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0035, d_svhn_loss: 0.0224, d_fake_loss: 0.0145, g_loss: 1.0616\n",
            "Step [42360/80000], d_real_loss: 0.0166, d_mnist_loss: 0.0035, d_svhn_loss: 0.0130, d_fake_loss: 0.0252, g_loss: 1.1610\n",
            "Step [42370/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0043, d_svhn_loss: 0.0705, d_fake_loss: 0.0319, g_loss: 1.0445\n",
            "Step [42380/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0046, d_svhn_loss: 0.0410, d_fake_loss: 0.0165, g_loss: 1.2264\n",
            "Step [42390/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0029, d_svhn_loss: 0.0214, d_fake_loss: 0.0184, g_loss: 1.1866\n",
            "Step [42400/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0049, d_svhn_loss: 0.0641, d_fake_loss: 0.0667, g_loss: 1.1792\n",
            "Step [42410/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0058, d_svhn_loss: 0.0189, d_fake_loss: 0.0203, g_loss: 1.1260\n",
            "Step [42420/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0010, d_svhn_loss: 0.0398, d_fake_loss: 0.1223, g_loss: 1.1211\n",
            "Step [42430/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0010, d_svhn_loss: 0.0383, d_fake_loss: 0.0554, g_loss: 1.1505\n",
            "Step [42440/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0008, d_svhn_loss: 0.0399, d_fake_loss: 0.0264, g_loss: 1.1371\n",
            "Step [42450/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0013, d_svhn_loss: 0.0488, d_fake_loss: 0.0769, g_loss: 1.1208\n",
            "Step [42460/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0035, d_svhn_loss: 0.0338, d_fake_loss: 0.0225, g_loss: 1.0768\n",
            "Step [42470/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0013, d_svhn_loss: 0.0298, d_fake_loss: 0.0737, g_loss: 1.1902\n",
            "Step [42480/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0008, d_svhn_loss: 0.0287, d_fake_loss: 0.0152, g_loss: 1.1252\n",
            "Step [42490/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0041, d_svhn_loss: 0.0368, d_fake_loss: 0.0468, g_loss: 1.2237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [42500/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0007, d_svhn_loss: 0.0475, d_fake_loss: 0.0339, g_loss: 1.1161\n",
            "saved ./samples_mnist_svhn/sample-42500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-42500-s-m.png\n",
            "Step [42510/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0006, d_svhn_loss: 0.0184, d_fake_loss: 0.0443, g_loss: 1.1581\n",
            "Step [42520/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0048, d_svhn_loss: 0.0202, d_fake_loss: 0.0192, g_loss: 1.1117\n",
            "Step [42530/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0168, d_svhn_loss: 0.0170, d_fake_loss: 0.0332, g_loss: 1.0335\n",
            "Step [42540/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0010, d_svhn_loss: 0.0266, d_fake_loss: 0.0578, g_loss: 1.1048\n",
            "Step [42550/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0018, d_svhn_loss: 0.0204, d_fake_loss: 0.0171, g_loss: 1.1367\n",
            "Step [42560/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0035, d_svhn_loss: 0.0233, d_fake_loss: 0.0302, g_loss: 1.0790\n",
            "Step [42570/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0017, d_svhn_loss: 0.0192, d_fake_loss: 0.0303, g_loss: 1.1361\n",
            "Step [42580/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0073, d_svhn_loss: 0.0629, d_fake_loss: 0.0427, g_loss: 1.0420\n",
            "Step [42590/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0012, d_svhn_loss: 0.0324, d_fake_loss: 0.0788, g_loss: 1.1098\n",
            "Step [42600/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0014, d_svhn_loss: 0.0214, d_fake_loss: 0.0499, g_loss: 1.1007\n",
            "Step [42610/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0031, d_svhn_loss: 0.0914, d_fake_loss: 0.0228, g_loss: 1.0754\n",
            "Step [42620/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0006, d_svhn_loss: 0.0531, d_fake_loss: 0.0361, g_loss: 1.0981\n",
            "Step [42630/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0007, d_svhn_loss: 0.0303, d_fake_loss: 0.0211, g_loss: 1.1199\n",
            "Step [42640/80000], d_real_loss: 0.1282, d_mnist_loss: 0.0029, d_svhn_loss: 0.1253, d_fake_loss: 0.1737, g_loss: 1.0581\n",
            "Step [42650/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0201, d_svhn_loss: 0.0303, d_fake_loss: 0.0679, g_loss: 1.0424\n",
            "Step [42660/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0028, d_svhn_loss: 0.0267, d_fake_loss: 0.0678, g_loss: 1.1601\n",
            "Step [42670/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0033, d_svhn_loss: 0.0453, d_fake_loss: 0.1254, g_loss: 1.1106\n",
            "Step [42680/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0027, d_svhn_loss: 0.0729, d_fake_loss: 0.0977, g_loss: 1.1856\n",
            "Step [42690/80000], d_real_loss: 0.0882, d_mnist_loss: 0.0029, d_svhn_loss: 0.0853, d_fake_loss: 0.0162, g_loss: 1.0568\n",
            "Step [42700/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0025, d_svhn_loss: 0.0193, d_fake_loss: 0.0272, g_loss: 1.0871\n",
            "Step [42710/80000], d_real_loss: 0.0801, d_mnist_loss: 0.0017, d_svhn_loss: 0.0784, d_fake_loss: 0.0252, g_loss: 1.1148\n",
            "Step [42720/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0004, d_svhn_loss: 0.0550, d_fake_loss: 0.0265, g_loss: 1.1118\n",
            "Step [42730/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0009, d_svhn_loss: 0.0283, d_fake_loss: 0.0206, g_loss: 1.0896\n",
            "Step [42740/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0010, d_svhn_loss: 0.0337, d_fake_loss: 0.0226, g_loss: 1.1144\n",
            "Step [42750/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0011, d_svhn_loss: 0.0431, d_fake_loss: 0.0150, g_loss: 1.1228\n",
            "Step [42760/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0010, d_svhn_loss: 0.0428, d_fake_loss: 0.1230, g_loss: 1.0846\n",
            "Step [42770/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0077, d_svhn_loss: 0.0219, d_fake_loss: 0.0238, g_loss: 1.2092\n",
            "Step [42780/80000], d_real_loss: 0.1066, d_mnist_loss: 0.0009, d_svhn_loss: 0.1057, d_fake_loss: 0.0365, g_loss: 1.0911\n",
            "Step [42790/80000], d_real_loss: 0.1048, d_mnist_loss: 0.0037, d_svhn_loss: 0.1012, d_fake_loss: 0.0484, g_loss: 1.1047\n",
            "Step [42800/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0010, d_svhn_loss: 0.0207, d_fake_loss: 0.0268, g_loss: 1.1024\n",
            "Step [42810/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0005, d_svhn_loss: 0.0271, d_fake_loss: 0.0419, g_loss: 1.1214\n",
            "Step [42820/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0009, d_svhn_loss: 0.0238, d_fake_loss: 0.0378, g_loss: 1.1202\n",
            "Step [42830/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0006, d_svhn_loss: 0.0368, d_fake_loss: 0.0313, g_loss: 1.1109\n",
            "Step [42840/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0039, d_svhn_loss: 0.0349, d_fake_loss: 0.0216, g_loss: 1.1530\n",
            "Step [42850/80000], d_real_loss: 0.1753, d_mnist_loss: 0.0018, d_svhn_loss: 0.1735, d_fake_loss: 0.1868, g_loss: 1.1321\n",
            "Step [42860/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0008, d_svhn_loss: 0.0309, d_fake_loss: 0.0164, g_loss: 1.1325\n",
            "Step [42870/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0028, d_svhn_loss: 0.0245, d_fake_loss: 0.0195, g_loss: 1.1302\n",
            "Step [42880/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0013, d_svhn_loss: 0.0339, d_fake_loss: 0.0904, g_loss: 1.1014\n",
            "Step [42890/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0014, d_svhn_loss: 0.0308, d_fake_loss: 0.0312, g_loss: 1.0631\n",
            "Step [42900/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0005, d_svhn_loss: 0.0238, d_fake_loss: 0.0215, g_loss: 1.1688\n",
            "Step [42910/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0011, d_svhn_loss: 0.0527, d_fake_loss: 0.0215, g_loss: 1.1135\n",
            "Step [42920/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0072, d_svhn_loss: 0.0234, d_fake_loss: 0.0321, g_loss: 1.0589\n",
            "Step [42930/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0066, d_svhn_loss: 0.0357, d_fake_loss: 0.0250, g_loss: 1.2151\n",
            "Step [42940/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0009, d_svhn_loss: 0.0654, d_fake_loss: 0.0378, g_loss: 1.1125\n",
            "Step [42950/80000], d_real_loss: 0.0203, d_mnist_loss: 0.0014, d_svhn_loss: 0.0189, d_fake_loss: 0.0599, g_loss: 1.0904\n",
            "Step [42960/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0007, d_svhn_loss: 0.0293, d_fake_loss: 0.0293, g_loss: 1.1238\n",
            "Step [42970/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0004, d_svhn_loss: 0.0264, d_fake_loss: 0.0809, g_loss: 1.1485\n",
            "Step [42980/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0018, d_svhn_loss: 0.0367, d_fake_loss: 0.0253, g_loss: 1.1266\n",
            "Step [42990/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0054, d_svhn_loss: 0.0321, d_fake_loss: 0.0406, g_loss: 1.1005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [43000/80000], d_real_loss: 0.1297, d_mnist_loss: 0.0008, d_svhn_loss: 0.1288, d_fake_loss: 0.0602, g_loss: 1.0898\n",
            "saved ./samples_mnist_svhn/sample-43000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-43000-s-m.png\n",
            "Step [43010/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0012, d_svhn_loss: 0.1066, d_fake_loss: 0.0551, g_loss: 1.3081\n",
            "Step [43020/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0007, d_svhn_loss: 0.0584, d_fake_loss: 0.1452, g_loss: 1.0516\n",
            "Step [43030/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0311, d_svhn_loss: 0.0234, d_fake_loss: 0.0763, g_loss: 1.1792\n",
            "Step [43040/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0236, d_svhn_loss: 0.0325, d_fake_loss: 0.0609, g_loss: 1.3469\n",
            "Step [43050/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0049, d_svhn_loss: 0.0209, d_fake_loss: 0.0421, g_loss: 1.1565\n",
            "Step [43060/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0058, d_svhn_loss: 0.0224, d_fake_loss: 0.0437, g_loss: 1.1752\n",
            "Step [43070/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0035, d_svhn_loss: 0.0363, d_fake_loss: 0.0966, g_loss: 1.1489\n",
            "Step [43080/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0046, d_svhn_loss: 0.0600, d_fake_loss: 0.0955, g_loss: 1.5174\n",
            "Step [43090/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0020, d_svhn_loss: 0.0502, d_fake_loss: 0.0404, g_loss: 1.1080\n",
            "Step [43100/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0022, d_svhn_loss: 0.0525, d_fake_loss: 0.0309, g_loss: 1.3208\n",
            "Step [43110/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0023, d_svhn_loss: 0.0278, d_fake_loss: 0.0780, g_loss: 1.0868\n",
            "Step [43120/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0023, d_svhn_loss: 0.0635, d_fake_loss: 0.0376, g_loss: 1.1357\n",
            "Step [43130/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0017, d_svhn_loss: 0.0427, d_fake_loss: 0.0213, g_loss: 1.1414\n",
            "Step [43140/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0022, d_svhn_loss: 0.0512, d_fake_loss: 0.0255, g_loss: 1.0899\n",
            "Step [43150/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0105, d_svhn_loss: 0.0490, d_fake_loss: 0.0429, g_loss: 1.1235\n",
            "Step [43160/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0050, d_svhn_loss: 0.0235, d_fake_loss: 0.0278, g_loss: 1.1387\n",
            "Step [43170/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0088, d_svhn_loss: 0.0235, d_fake_loss: 0.0715, g_loss: 1.1579\n",
            "Step [43180/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0035, d_svhn_loss: 0.0506, d_fake_loss: 0.0405, g_loss: 1.2025\n",
            "Step [43190/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0036, d_svhn_loss: 0.0868, d_fake_loss: 0.0215, g_loss: 1.1119\n",
            "Step [43200/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0039, d_svhn_loss: 0.0496, d_fake_loss: 0.0763, g_loss: 1.0581\n",
            "Step [43210/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0038, d_svhn_loss: 0.0223, d_fake_loss: 0.0960, g_loss: 1.1028\n",
            "Step [43220/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0057, d_svhn_loss: 0.0208, d_fake_loss: 0.0417, g_loss: 1.1767\n",
            "Step [43230/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0029, d_svhn_loss: 0.0225, d_fake_loss: 0.0482, g_loss: 1.1938\n",
            "Step [43240/80000], d_real_loss: 0.0799, d_mnist_loss: 0.0087, d_svhn_loss: 0.0712, d_fake_loss: 0.0300, g_loss: 1.0619\n",
            "Step [43250/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0016, d_svhn_loss: 0.0358, d_fake_loss: 0.0251, g_loss: 1.1495\n",
            "Step [43260/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0062, d_svhn_loss: 0.0304, d_fake_loss: 0.0491, g_loss: 1.1377\n",
            "Step [43270/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0051, d_svhn_loss: 0.0235, d_fake_loss: 0.0862, g_loss: 1.1002\n",
            "Step [43280/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0031, d_svhn_loss: 0.0436, d_fake_loss: 0.0540, g_loss: 1.1103\n",
            "Step [43290/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0012, d_svhn_loss: 0.0191, d_fake_loss: 0.0224, g_loss: 1.1218\n",
            "Step [43300/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0007, d_svhn_loss: 0.0494, d_fake_loss: 0.0251, g_loss: 1.1712\n",
            "Step [43310/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0010, d_svhn_loss: 0.0338, d_fake_loss: 0.0196, g_loss: 1.1670\n",
            "Step [43320/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0010, d_svhn_loss: 0.0189, d_fake_loss: 0.0289, g_loss: 1.1114\n",
            "Step [43330/80000], d_real_loss: 0.1051, d_mnist_loss: 0.0064, d_svhn_loss: 0.0987, d_fake_loss: 0.1016, g_loss: 1.1113\n",
            "Step [43340/80000], d_real_loss: 0.1570, d_mnist_loss: 0.0028, d_svhn_loss: 0.1542, d_fake_loss: 0.0219, g_loss: 1.1481\n",
            "Step [43350/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0076, d_svhn_loss: 0.0496, d_fake_loss: 0.0821, g_loss: 1.1647\n",
            "Step [43360/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0009, d_svhn_loss: 0.0345, d_fake_loss: 0.0450, g_loss: 1.1507\n",
            "Step [43370/80000], d_real_loss: 0.1165, d_mnist_loss: 0.0028, d_svhn_loss: 0.1138, d_fake_loss: 0.1294, g_loss: 1.2144\n",
            "Step [43380/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0016, d_svhn_loss: 0.0827, d_fake_loss: 0.1208, g_loss: 1.0926\n",
            "Step [43390/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0024, d_svhn_loss: 0.0352, d_fake_loss: 0.1331, g_loss: 1.0856\n",
            "Step [43400/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0055, d_svhn_loss: 0.0225, d_fake_loss: 0.0207, g_loss: 1.1289\n",
            "Step [43410/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0020, d_svhn_loss: 0.0153, d_fake_loss: 0.0294, g_loss: 1.0941\n",
            "Step [43420/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0041, d_svhn_loss: 0.0247, d_fake_loss: 0.0340, g_loss: 1.1368\n",
            "Step [43430/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0024, d_svhn_loss: 0.0297, d_fake_loss: 0.0256, g_loss: 1.0833\n",
            "Step [43440/80000], d_real_loss: 0.1146, d_mnist_loss: 0.0029, d_svhn_loss: 0.1117, d_fake_loss: 0.1430, g_loss: 1.1065\n",
            "Step [43450/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0037, d_svhn_loss: 0.0215, d_fake_loss: 0.0274, g_loss: 1.1284\n",
            "Step [43460/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0021, d_svhn_loss: 0.0366, d_fake_loss: 0.1494, g_loss: 1.0795\n",
            "Step [43470/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0012, d_svhn_loss: 0.0368, d_fake_loss: 0.0404, g_loss: 1.0893\n",
            "Step [43480/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0015, d_svhn_loss: 0.0181, d_fake_loss: 0.0336, g_loss: 1.0826\n",
            "Step [43490/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0027, d_svhn_loss: 0.0233, d_fake_loss: 0.0581, g_loss: 1.1172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [43500/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0042, d_svhn_loss: 0.0459, d_fake_loss: 0.0301, g_loss: 1.0602\n",
            "saved ./samples_mnist_svhn/sample-43500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-43500-s-m.png\n",
            "Step [43510/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0005, d_svhn_loss: 0.0287, d_fake_loss: 0.1492, g_loss: 1.0941\n",
            "Step [43520/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0008, d_svhn_loss: 0.0264, d_fake_loss: 0.0352, g_loss: 1.1092\n",
            "Step [43530/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0027, d_svhn_loss: 0.0199, d_fake_loss: 0.0371, g_loss: 1.0797\n",
            "Step [43540/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0006, d_svhn_loss: 0.0534, d_fake_loss: 0.0508, g_loss: 1.1348\n",
            "Step [43550/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0015, d_svhn_loss: 0.0308, d_fake_loss: 0.0456, g_loss: 1.0990\n",
            "Step [43560/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0012, d_svhn_loss: 0.0386, d_fake_loss: 0.0199, g_loss: 1.0946\n",
            "Step [43570/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0014, d_svhn_loss: 0.0209, d_fake_loss: 0.0373, g_loss: 1.1324\n",
            "Step [43580/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0006, d_svhn_loss: 0.0263, d_fake_loss: 0.0324, g_loss: 1.0944\n",
            "Step [43590/80000], d_real_loss: 0.1617, d_mnist_loss: 0.0007, d_svhn_loss: 0.1609, d_fake_loss: 0.0379, g_loss: 1.1269\n",
            "Step [43600/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0056, d_svhn_loss: 0.0275, d_fake_loss: 0.0166, g_loss: 1.1162\n",
            "Step [43610/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0019, d_svhn_loss: 0.0429, d_fake_loss: 0.0243, g_loss: 1.1164\n",
            "Step [43620/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0015, d_svhn_loss: 0.0278, d_fake_loss: 0.0248, g_loss: 1.0872\n",
            "Step [43630/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0027, d_svhn_loss: 0.0254, d_fake_loss: 0.0364, g_loss: 1.1300\n",
            "Step [43640/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0006, d_svhn_loss: 0.0497, d_fake_loss: 0.0384, g_loss: 1.1684\n",
            "Step [43650/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0026, d_svhn_loss: 0.0236, d_fake_loss: 0.0320, g_loss: 1.0834\n",
            "Step [43660/80000], d_real_loss: 0.0698, d_mnist_loss: 0.0021, d_svhn_loss: 0.0677, d_fake_loss: 0.0361, g_loss: 1.1947\n",
            "Step [43670/80000], d_real_loss: 0.0170, d_mnist_loss: 0.0007, d_svhn_loss: 0.0164, d_fake_loss: 0.0316, g_loss: 1.0548\n",
            "Step [43680/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0009, d_svhn_loss: 0.0306, d_fake_loss: 0.0306, g_loss: 1.2347\n",
            "Step [43690/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0012, d_svhn_loss: 0.0184, d_fake_loss: 0.0271, g_loss: 1.2425\n",
            "Step [43700/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0015, d_svhn_loss: 0.0296, d_fake_loss: 0.0371, g_loss: 1.1546\n",
            "Step [43710/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0005, d_svhn_loss: 0.0586, d_fake_loss: 0.0374, g_loss: 1.2049\n",
            "Step [43720/80000], d_real_loss: 0.0999, d_mnist_loss: 0.0009, d_svhn_loss: 0.0990, d_fake_loss: 0.0203, g_loss: 1.1167\n",
            "Step [43730/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0006, d_svhn_loss: 0.0282, d_fake_loss: 0.0506, g_loss: 1.1289\n",
            "Step [43740/80000], d_real_loss: 0.0153, d_mnist_loss: 0.0026, d_svhn_loss: 0.0127, d_fake_loss: 0.0419, g_loss: 0.9769\n",
            "Step [43750/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0016, d_svhn_loss: 0.0171, d_fake_loss: 0.0492, g_loss: 1.2481\n",
            "Step [43760/80000], d_real_loss: 0.1599, d_mnist_loss: 0.0012, d_svhn_loss: 0.1587, d_fake_loss: 0.0634, g_loss: 1.1201\n",
            "Step [43770/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0169, d_svhn_loss: 0.0184, d_fake_loss: 0.1450, g_loss: 0.9939\n",
            "Step [43780/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0025, d_svhn_loss: 0.0564, d_fake_loss: 0.0175, g_loss: 1.1145\n",
            "Step [43790/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0016, d_svhn_loss: 0.0721, d_fake_loss: 0.1173, g_loss: 1.2986\n",
            "Step [43800/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0007, d_svhn_loss: 0.0514, d_fake_loss: 0.0260, g_loss: 1.1135\n",
            "Step [43810/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0011, d_svhn_loss: 0.0210, d_fake_loss: 0.0417, g_loss: 1.1500\n",
            "Step [43820/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0055, d_svhn_loss: 0.0391, d_fake_loss: 0.0597, g_loss: 1.2712\n",
            "Step [43830/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0018, d_svhn_loss: 0.0321, d_fake_loss: 0.0347, g_loss: 1.2064\n",
            "Step [43840/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0007, d_svhn_loss: 0.0288, d_fake_loss: 0.0132, g_loss: 1.0878\n",
            "Step [43850/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0048, d_svhn_loss: 0.0764, d_fake_loss: 0.0265, g_loss: 1.1179\n",
            "Step [43860/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0015, d_svhn_loss: 0.0705, d_fake_loss: 0.3144, g_loss: 1.0838\n",
            "Step [43870/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0124, d_svhn_loss: 0.0649, d_fake_loss: 0.0331, g_loss: 1.0829\n",
            "Step [43880/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0013, d_svhn_loss: 0.0265, d_fake_loss: 0.0507, g_loss: 1.1046\n",
            "Step [43890/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0012, d_svhn_loss: 0.0273, d_fake_loss: 0.0369, g_loss: 1.1100\n",
            "Step [43900/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0015, d_svhn_loss: 0.0346, d_fake_loss: 0.1309, g_loss: 1.2444\n",
            "Step [43910/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0112, d_svhn_loss: 0.0288, d_fake_loss: 0.0185, g_loss: 1.1323\n",
            "Step [43920/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0010, d_svhn_loss: 0.0351, d_fake_loss: 0.0189, g_loss: 1.1172\n",
            "Step [43930/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0012, d_svhn_loss: 0.0619, d_fake_loss: 0.0326, g_loss: 1.0782\n",
            "Step [43940/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0012, d_svhn_loss: 0.0297, d_fake_loss: 0.0576, g_loss: 1.0835\n",
            "Step [43950/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0038, d_svhn_loss: 0.0311, d_fake_loss: 0.0643, g_loss: 1.1738\n",
            "Step [43960/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0013, d_svhn_loss: 0.0469, d_fake_loss: 0.0415, g_loss: 1.1067\n",
            "Step [43970/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0027, d_svhn_loss: 0.0324, d_fake_loss: 0.0408, g_loss: 1.0251\n",
            "Step [43980/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0048, d_svhn_loss: 0.0322, d_fake_loss: 0.0190, g_loss: 1.1257\n",
            "Step [43990/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0056, d_svhn_loss: 0.0474, d_fake_loss: 0.0860, g_loss: 1.1111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [44000/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0012, d_svhn_loss: 0.0704, d_fake_loss: 0.0557, g_loss: 1.2326\n",
            "saved ./samples_mnist_svhn/sample-44000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-44000-s-m.png\n",
            "Step [44010/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0018, d_svhn_loss: 0.0311, d_fake_loss: 0.0246, g_loss: 1.1305\n",
            "Step [44020/80000], d_real_loss: 0.1276, d_mnist_loss: 0.0012, d_svhn_loss: 0.1263, d_fake_loss: 0.0297, g_loss: 1.1770\n",
            "Step [44030/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0012, d_svhn_loss: 0.0186, d_fake_loss: 0.0879, g_loss: 1.1195\n",
            "Step [44040/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0012, d_svhn_loss: 0.0287, d_fake_loss: 0.0440, g_loss: 1.1526\n",
            "Step [44050/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0039, d_svhn_loss: 0.0531, d_fake_loss: 0.0245, g_loss: 1.1143\n",
            "Step [44060/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0018, d_svhn_loss: 0.0533, d_fake_loss: 0.0503, g_loss: 1.0747\n",
            "Step [44070/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0016, d_svhn_loss: 0.0227, d_fake_loss: 0.0434, g_loss: 1.0840\n",
            "Step [44080/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0038, d_svhn_loss: 0.0222, d_fake_loss: 0.0632, g_loss: 1.2255\n",
            "Step [44090/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0015, d_svhn_loss: 0.0318, d_fake_loss: 0.0378, g_loss: 1.0998\n",
            "Step [44100/80000], d_real_loss: 0.0189, d_mnist_loss: 0.0012, d_svhn_loss: 0.0177, d_fake_loss: 0.0203, g_loss: 1.1334\n",
            "Step [44110/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0015, d_svhn_loss: 0.0158, d_fake_loss: 0.0363, g_loss: 1.1243\n",
            "Step [44120/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0018, d_svhn_loss: 0.0303, d_fake_loss: 0.0211, g_loss: 1.0442\n",
            "Step [44130/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0006, d_svhn_loss: 0.0329, d_fake_loss: 0.0188, g_loss: 1.0992\n",
            "Step [44140/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0027, d_svhn_loss: 0.0257, d_fake_loss: 0.0172, g_loss: 1.1070\n",
            "Step [44150/80000], d_real_loss: 0.0994, d_mnist_loss: 0.0006, d_svhn_loss: 0.0988, d_fake_loss: 0.0846, g_loss: 1.1478\n",
            "Step [44160/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0027, d_svhn_loss: 0.0277, d_fake_loss: 0.0343, g_loss: 1.1324\n",
            "Step [44170/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0038, d_svhn_loss: 0.0157, d_fake_loss: 0.1143, g_loss: 1.1220\n",
            "Step [44180/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0012, d_svhn_loss: 0.0356, d_fake_loss: 0.0377, g_loss: 1.0871\n",
            "Step [44190/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0040, d_svhn_loss: 0.0644, d_fake_loss: 0.0531, g_loss: 1.1789\n",
            "Step [44200/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0018, d_svhn_loss: 0.0226, d_fake_loss: 0.0204, g_loss: 1.1499\n",
            "Step [44210/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0013, d_svhn_loss: 0.0282, d_fake_loss: 0.0341, g_loss: 1.1413\n",
            "Step [44220/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0018, d_svhn_loss: 0.0232, d_fake_loss: 0.0326, g_loss: 1.1971\n",
            "Step [44230/80000], d_real_loss: 0.1805, d_mnist_loss: 0.0017, d_svhn_loss: 0.1789, d_fake_loss: 0.0970, g_loss: 1.1135\n",
            "Step [44240/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0025, d_svhn_loss: 0.0281, d_fake_loss: 0.0363, g_loss: 1.1149\n",
            "Step [44250/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0025, d_svhn_loss: 0.0198, d_fake_loss: 0.0281, g_loss: 1.1319\n",
            "Step [44260/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0009, d_svhn_loss: 0.0188, d_fake_loss: 0.0318, g_loss: 1.1531\n",
            "Step [44270/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0084, d_svhn_loss: 0.0192, d_fake_loss: 0.0435, g_loss: 1.1170\n",
            "Step [44280/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0015, d_svhn_loss: 0.0236, d_fake_loss: 0.4355, g_loss: 3.3718\n",
            "Step [44290/80000], d_real_loss: 0.0976, d_mnist_loss: 0.0018, d_svhn_loss: 0.0958, d_fake_loss: 0.1912, g_loss: 1.1211\n",
            "Step [44300/80000], d_real_loss: 0.0824, d_mnist_loss: 0.0150, d_svhn_loss: 0.0674, d_fake_loss: 0.0499, g_loss: 1.0233\n",
            "Step [44310/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0038, d_svhn_loss: 0.0259, d_fake_loss: 0.0469, g_loss: 1.1035\n",
            "Step [44320/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0089, d_svhn_loss: 0.0409, d_fake_loss: 0.0447, g_loss: 1.0805\n",
            "Step [44330/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0180, d_svhn_loss: 0.0267, d_fake_loss: 0.1019, g_loss: 1.3523\n",
            "Step [44340/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0265, d_svhn_loss: 0.0338, d_fake_loss: 0.1527, g_loss: 1.0804\n",
            "Step [44350/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0043, d_svhn_loss: 0.0248, d_fake_loss: 0.2896, g_loss: 1.7424\n",
            "Step [44360/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0041, d_svhn_loss: 0.0395, d_fake_loss: 0.0137, g_loss: 1.0889\n",
            "Step [44370/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0069, d_svhn_loss: 0.0249, d_fake_loss: 0.0250, g_loss: 1.1813\n",
            "Step [44380/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0108, d_svhn_loss: 0.0276, d_fake_loss: 0.0201, g_loss: 1.0906\n",
            "Step [44390/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0029, d_svhn_loss: 0.0557, d_fake_loss: 0.0239, g_loss: 1.1204\n",
            "Step [44400/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0054, d_svhn_loss: 0.0449, d_fake_loss: 0.0369, g_loss: 1.1882\n",
            "Step [44410/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0036, d_svhn_loss: 0.0506, d_fake_loss: 0.0261, g_loss: 1.1512\n",
            "Step [44420/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0238, d_svhn_loss: 0.0313, d_fake_loss: 0.1116, g_loss: 1.0006\n",
            "Step [44430/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0091, d_svhn_loss: 0.0388, d_fake_loss: 0.0330, g_loss: 1.2929\n",
            "Step [44440/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0400, d_svhn_loss: 0.0196, d_fake_loss: 0.0317, g_loss: 1.1802\n",
            "Step [44450/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0144, d_svhn_loss: 0.0293, d_fake_loss: 0.0242, g_loss: 1.1530\n",
            "Step [44460/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0070, d_svhn_loss: 0.0511, d_fake_loss: 0.2283, g_loss: 1.2885\n",
            "Step [44470/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0048, d_svhn_loss: 0.0473, d_fake_loss: 0.0447, g_loss: 1.0671\n",
            "Step [44480/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0057, d_svhn_loss: 0.0162, d_fake_loss: 0.0804, g_loss: 1.2465\n",
            "Step [44490/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0059, d_svhn_loss: 0.0269, d_fake_loss: 0.2001, g_loss: 1.1088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [44500/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0079, d_svhn_loss: 0.0253, d_fake_loss: 0.0549, g_loss: 1.1171\n",
            "saved ./samples_mnist_svhn/sample-44500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-44500-s-m.png\n",
            "Step [44510/80000], d_real_loss: 0.0884, d_mnist_loss: 0.0207, d_svhn_loss: 0.0678, d_fake_loss: 0.0443, g_loss: 1.2387\n",
            "Step [44520/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0064, d_svhn_loss: 0.0207, d_fake_loss: 0.1049, g_loss: 1.3192\n",
            "Step [44530/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0085, d_svhn_loss: 0.0197, d_fake_loss: 0.0602, g_loss: 1.0159\n",
            "Step [44540/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0110, d_svhn_loss: 0.0493, d_fake_loss: 0.0344, g_loss: 1.1810\n",
            "Step [44550/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0054, d_svhn_loss: 0.0437, d_fake_loss: 0.0503, g_loss: 1.3128\n",
            "Step [44560/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0111, d_svhn_loss: 0.0619, d_fake_loss: 0.1142, g_loss: 1.1874\n",
            "Step [44570/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0049, d_svhn_loss: 0.0286, d_fake_loss: 0.1725, g_loss: 1.3127\n",
            "Step [44580/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0041, d_svhn_loss: 0.0235, d_fake_loss: 0.0722, g_loss: 1.2014\n",
            "Step [44590/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0050, d_svhn_loss: 0.0585, d_fake_loss: 0.0563, g_loss: 1.3713\n",
            "Step [44600/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0056, d_svhn_loss: 0.0309, d_fake_loss: 0.0434, g_loss: 1.1562\n",
            "Step [44610/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0185, d_svhn_loss: 0.0625, d_fake_loss: 0.2239, g_loss: 0.9881\n",
            "Step [44620/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0065, d_svhn_loss: 0.0187, d_fake_loss: 0.0430, g_loss: 1.2770\n",
            "Step [44630/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0097, d_svhn_loss: 0.0116, d_fake_loss: 0.0626, g_loss: 1.7875\n",
            "Step [44640/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0103, d_svhn_loss: 0.0359, d_fake_loss: 0.0579, g_loss: 1.1303\n",
            "Step [44650/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0087, d_svhn_loss: 0.0245, d_fake_loss: 0.0409, g_loss: 1.2466\n",
            "Step [44660/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0078, d_svhn_loss: 0.0645, d_fake_loss: 0.0287, g_loss: 1.1253\n",
            "Step [44670/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0137, d_svhn_loss: 0.0605, d_fake_loss: 0.0599, g_loss: 1.1292\n",
            "Step [44680/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0064, d_svhn_loss: 0.0358, d_fake_loss: 0.0287, g_loss: 1.2761\n",
            "Step [44690/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0073, d_svhn_loss: 0.0232, d_fake_loss: 0.0311, g_loss: 1.1221\n",
            "Step [44700/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0195, d_svhn_loss: 0.0541, d_fake_loss: 0.0423, g_loss: 1.2025\n",
            "Step [44710/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0068, d_svhn_loss: 0.0184, d_fake_loss: 0.0139, g_loss: 1.2011\n",
            "Step [44720/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0405, d_svhn_loss: 0.0122, d_fake_loss: 0.0480, g_loss: 1.2021\n",
            "Step [44730/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0205, d_svhn_loss: 0.0228, d_fake_loss: 0.0281, g_loss: 1.1768\n",
            "Step [44740/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0149, d_svhn_loss: 0.0192, d_fake_loss: 0.0373, g_loss: 1.0104\n",
            "Step [44750/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0102, d_svhn_loss: 0.0491, d_fake_loss: 0.0217, g_loss: 1.1038\n",
            "Step [44760/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0107, d_svhn_loss: 0.0241, d_fake_loss: 0.0520, g_loss: 1.1123\n",
            "Step [44770/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0070, d_svhn_loss: 0.0259, d_fake_loss: 0.0513, g_loss: 1.2549\n",
            "Step [44780/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0129, d_svhn_loss: 0.0437, d_fake_loss: 0.1251, g_loss: 1.0391\n",
            "Step [44790/80000], d_real_loss: 0.1248, d_mnist_loss: 0.0085, d_svhn_loss: 0.1162, d_fake_loss: 0.0335, g_loss: 1.1266\n",
            "Step [44800/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0188, d_svhn_loss: 0.0157, d_fake_loss: 0.0649, g_loss: 1.1220\n",
            "Step [44810/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0081, d_svhn_loss: 0.0204, d_fake_loss: 0.0427, g_loss: 1.2293\n",
            "Step [44820/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0105, d_svhn_loss: 0.0213, d_fake_loss: 0.1472, g_loss: 1.3316\n",
            "Step [44830/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0051, d_svhn_loss: 0.0201, d_fake_loss: 0.0783, g_loss: 1.5828\n",
            "Step [44840/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0079, d_svhn_loss: 0.0201, d_fake_loss: 0.0387, g_loss: 1.1384\n",
            "Step [44850/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0082, d_svhn_loss: 0.0449, d_fake_loss: 0.0241, g_loss: 1.0888\n",
            "Step [44860/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0047, d_svhn_loss: 0.0328, d_fake_loss: 0.0324, g_loss: 1.1588\n",
            "Step [44870/80000], d_real_loss: 0.0781, d_mnist_loss: 0.0488, d_svhn_loss: 0.0294, d_fake_loss: 0.0180, g_loss: 1.0740\n",
            "Step [44880/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0125, d_svhn_loss: 0.0182, d_fake_loss: 0.0408, g_loss: 1.1158\n",
            "Step [44890/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0187, d_svhn_loss: 0.0337, d_fake_loss: 0.1826, g_loss: 0.7641\n",
            "Step [44900/80000], d_real_loss: 0.1329, d_mnist_loss: 0.0084, d_svhn_loss: 0.1245, d_fake_loss: 0.0494, g_loss: 1.2944\n",
            "Step [44910/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0061, d_svhn_loss: 0.0150, d_fake_loss: 0.0255, g_loss: 1.4035\n",
            "Step [44920/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0091, d_svhn_loss: 0.0266, d_fake_loss: 0.0480, g_loss: 1.1497\n",
            "Step [44930/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0089, d_svhn_loss: 0.0209, d_fake_loss: 0.0660, g_loss: 1.3896\n",
            "Step [44940/80000], d_real_loss: 0.1420, d_mnist_loss: 0.0049, d_svhn_loss: 0.1371, d_fake_loss: 0.1501, g_loss: 1.0870\n",
            "Step [44950/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0039, d_svhn_loss: 0.0293, d_fake_loss: 0.0246, g_loss: 1.1583\n",
            "Step [44960/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0055, d_svhn_loss: 0.0197, d_fake_loss: 0.0432, g_loss: 1.1886\n",
            "Step [44970/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0052, d_svhn_loss: 0.0322, d_fake_loss: 0.0297, g_loss: 1.1792\n",
            "Step [44980/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0046, d_svhn_loss: 0.0494, d_fake_loss: 0.0343, g_loss: 1.0703\n",
            "Step [44990/80000], d_real_loss: 0.0922, d_mnist_loss: 0.0103, d_svhn_loss: 0.0819, d_fake_loss: 0.0550, g_loss: 1.1373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [45000/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0115, d_svhn_loss: 0.0243, d_fake_loss: 0.0372, g_loss: 1.3221\n",
            "saved ./samples_mnist_svhn/sample-45000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-45000-s-m.png\n",
            "Step [45010/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0047, d_svhn_loss: 0.0303, d_fake_loss: 0.0501, g_loss: 1.0709\n",
            "Step [45020/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0070, d_svhn_loss: 0.0207, d_fake_loss: 0.0721, g_loss: 1.3866\n",
            "Step [45030/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0110, d_svhn_loss: 0.0288, d_fake_loss: 0.0747, g_loss: 1.1167\n",
            "Step [45040/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0049, d_svhn_loss: 0.0203, d_fake_loss: 0.0250, g_loss: 1.1729\n",
            "Step [45050/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0052, d_svhn_loss: 0.0359, d_fake_loss: 0.0487, g_loss: 1.1309\n",
            "Step [45060/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0057, d_svhn_loss: 0.0195, d_fake_loss: 0.0187, g_loss: 1.2955\n",
            "Step [45070/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0061, d_svhn_loss: 0.0518, d_fake_loss: 0.0849, g_loss: 1.2965\n",
            "Step [45080/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0059, d_svhn_loss: 0.0196, d_fake_loss: 0.0876, g_loss: 1.2134\n",
            "Step [45090/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0034, d_svhn_loss: 0.0654, d_fake_loss: 0.0286, g_loss: 1.2799\n",
            "Step [45100/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0044, d_svhn_loss: 0.0249, d_fake_loss: 0.0539, g_loss: 1.1598\n",
            "Step [45110/80000], d_real_loss: 0.0853, d_mnist_loss: 0.0085, d_svhn_loss: 0.0768, d_fake_loss: 0.2007, g_loss: 1.5244\n",
            "Step [45120/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0068, d_svhn_loss: 0.0162, d_fake_loss: 0.0816, g_loss: 1.5697\n",
            "Step [45130/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0049, d_svhn_loss: 0.0142, d_fake_loss: 0.0317, g_loss: 1.2547\n",
            "Step [45140/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0079, d_svhn_loss: 0.0749, d_fake_loss: 0.0440, g_loss: 1.1348\n",
            "Step [45150/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0102, d_svhn_loss: 0.0570, d_fake_loss: 0.0332, g_loss: 1.1229\n",
            "Step [45160/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0142, d_svhn_loss: 0.0330, d_fake_loss: 0.0289, g_loss: 1.0870\n",
            "Step [45170/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0092, d_svhn_loss: 0.0246, d_fake_loss: 0.0769, g_loss: 1.1747\n",
            "Step [45180/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0076, d_svhn_loss: 0.0549, d_fake_loss: 0.0627, g_loss: 1.1382\n",
            "Step [45190/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0079, d_svhn_loss: 0.0538, d_fake_loss: 0.0184, g_loss: 1.1917\n",
            "Step [45200/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0080, d_svhn_loss: 0.0320, d_fake_loss: 0.0981, g_loss: 1.1580\n",
            "Step [45210/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0062, d_svhn_loss: 0.0349, d_fake_loss: 0.0734, g_loss: 1.4029\n",
            "Step [45220/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0061, d_svhn_loss: 0.0734, d_fake_loss: 0.0582, g_loss: 1.2349\n",
            "Step [45230/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0073, d_svhn_loss: 0.0238, d_fake_loss: 0.0506, g_loss: 1.3084\n",
            "Step [45240/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0065, d_svhn_loss: 0.0586, d_fake_loss: 0.0221, g_loss: 1.1736\n",
            "Step [45250/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0099, d_svhn_loss: 0.0223, d_fake_loss: 0.0247, g_loss: 1.1765\n",
            "Step [45260/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0087, d_svhn_loss: 0.0228, d_fake_loss: 0.0443, g_loss: 1.2070\n",
            "Step [45270/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0104, d_svhn_loss: 0.0323, d_fake_loss: 0.0312, g_loss: 1.1064\n",
            "Step [45280/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0115, d_svhn_loss: 0.0489, d_fake_loss: 0.1144, g_loss: 1.1479\n",
            "Step [45290/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0165, d_svhn_loss: 0.0458, d_fake_loss: 0.0286, g_loss: 1.1761\n",
            "Step [45300/80000], d_real_loss: 0.0759, d_mnist_loss: 0.0063, d_svhn_loss: 0.0696, d_fake_loss: 0.0695, g_loss: 1.2550\n",
            "Step [45310/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0091, d_svhn_loss: 0.0290, d_fake_loss: 0.1052, g_loss: 1.7239\n",
            "Step [45320/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0092, d_svhn_loss: 0.0485, d_fake_loss: 0.0397, g_loss: 1.2574\n",
            "Step [45330/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0086, d_svhn_loss: 0.0520, d_fake_loss: 0.0369, g_loss: 1.2156\n",
            "Step [45340/80000], d_real_loss: 0.0828, d_mnist_loss: 0.0093, d_svhn_loss: 0.0735, d_fake_loss: 0.1119, g_loss: 1.1348\n",
            "Step [45350/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0104, d_svhn_loss: 0.0369, d_fake_loss: 0.0256, g_loss: 1.2894\n",
            "Step [45360/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0097, d_svhn_loss: 0.0297, d_fake_loss: 0.0429, g_loss: 1.1662\n",
            "Step [45370/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0073, d_svhn_loss: 0.0248, d_fake_loss: 0.1142, g_loss: 1.4229\n",
            "Step [45380/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0067, d_svhn_loss: 0.0317, d_fake_loss: 0.0594, g_loss: 1.2562\n",
            "Step [45390/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0132, d_svhn_loss: 0.0276, d_fake_loss: 0.0909, g_loss: 1.6848\n",
            "Step [45400/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0106, d_svhn_loss: 0.0306, d_fake_loss: 0.0666, g_loss: 1.1885\n",
            "Step [45410/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0101, d_svhn_loss: 0.0568, d_fake_loss: 0.0241, g_loss: 1.1867\n",
            "Step [45420/80000], d_real_loss: 0.1814, d_mnist_loss: 0.0171, d_svhn_loss: 0.1643, d_fake_loss: 0.0697, g_loss: 1.2193\n",
            "Step [45430/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0075, d_svhn_loss: 0.0541, d_fake_loss: 0.0474, g_loss: 1.0595\n",
            "Step [45440/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0046, d_svhn_loss: 0.0337, d_fake_loss: 0.0499, g_loss: 0.9218\n",
            "Step [45450/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0113, d_svhn_loss: 0.0181, d_fake_loss: 0.0508, g_loss: 1.3104\n",
            "Step [45460/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0074, d_svhn_loss: 0.0249, d_fake_loss: 0.0476, g_loss: 1.4037\n",
            "Step [45470/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0084, d_svhn_loss: 0.0154, d_fake_loss: 0.0417, g_loss: 1.2877\n",
            "Step [45480/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0181, d_svhn_loss: 0.0263, d_fake_loss: 0.0343, g_loss: 1.2238\n",
            "Step [45490/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0120, d_svhn_loss: 0.0232, d_fake_loss: 0.0454, g_loss: 1.1819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [45500/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0099, d_svhn_loss: 0.0250, d_fake_loss: 0.0248, g_loss: 1.1992\n",
            "saved ./samples_mnist_svhn/sample-45500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-45500-s-m.png\n",
            "Step [45510/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0076, d_svhn_loss: 0.0458, d_fake_loss: 0.0449, g_loss: 1.2416\n",
            "Step [45520/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0070, d_svhn_loss: 0.0271, d_fake_loss: 0.0340, g_loss: 1.2276\n",
            "Step [45530/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0065, d_svhn_loss: 0.0589, d_fake_loss: 0.0297, g_loss: 1.1507\n",
            "Step [45540/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0064, d_svhn_loss: 0.0406, d_fake_loss: 0.0719, g_loss: 1.4895\n",
            "Step [45550/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0100, d_svhn_loss: 0.0434, d_fake_loss: 0.0274, g_loss: 1.1668\n",
            "Step [45560/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0067, d_svhn_loss: 0.0417, d_fake_loss: 0.0201, g_loss: 1.1569\n",
            "Step [45570/80000], d_real_loss: 0.0814, d_mnist_loss: 0.0045, d_svhn_loss: 0.0769, d_fake_loss: 0.0151, g_loss: 1.0974\n",
            "Step [45580/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0116, d_svhn_loss: 0.0199, d_fake_loss: 0.1059, g_loss: 1.4156\n",
            "Step [45590/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0078, d_svhn_loss: 0.0248, d_fake_loss: 0.0945, g_loss: 1.3826\n",
            "Step [45600/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0047, d_svhn_loss: 0.0211, d_fake_loss: 0.0952, g_loss: 1.1507\n",
            "Step [45610/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0045, d_svhn_loss: 0.0242, d_fake_loss: 0.0517, g_loss: 1.0370\n",
            "Step [45620/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0085, d_svhn_loss: 0.0251, d_fake_loss: 0.0211, g_loss: 1.3415\n",
            "Step [45630/80000], d_real_loss: 0.1215, d_mnist_loss: 0.0088, d_svhn_loss: 0.1128, d_fake_loss: 0.0945, g_loss: 1.1097\n",
            "Step [45640/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0106, d_svhn_loss: 0.0524, d_fake_loss: 0.0269, g_loss: 1.1602\n",
            "Step [45650/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0066, d_svhn_loss: 0.0517, d_fake_loss: 0.0362, g_loss: 1.1809\n",
            "Step [45660/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0092, d_svhn_loss: 0.0391, d_fake_loss: 0.0698, g_loss: 1.3719\n",
            "Step [45670/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0078, d_svhn_loss: 0.0171, d_fake_loss: 0.0281, g_loss: 1.2143\n",
            "Step [45680/80000], d_real_loss: 0.1071, d_mnist_loss: 0.0060, d_svhn_loss: 0.1011, d_fake_loss: 0.0779, g_loss: 1.2098\n",
            "Step [45690/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0055, d_svhn_loss: 0.0170, d_fake_loss: 0.0683, g_loss: 1.2222\n",
            "Step [45700/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0068, d_svhn_loss: 0.0359, d_fake_loss: 0.0362, g_loss: 1.1207\n",
            "Step [45710/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0074, d_svhn_loss: 0.0257, d_fake_loss: 0.0147, g_loss: 1.1344\n",
            "Step [45720/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0090, d_svhn_loss: 0.0157, d_fake_loss: 0.0221, g_loss: 1.2188\n",
            "Step [45730/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0075, d_svhn_loss: 0.0218, d_fake_loss: 0.0366, g_loss: 1.0721\n",
            "Step [45740/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0081, d_svhn_loss: 0.0187, d_fake_loss: 0.0430, g_loss: 1.1221\n",
            "Step [45750/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0162, d_svhn_loss: 0.0211, d_fake_loss: 0.0283, g_loss: 1.1688\n",
            "Step [45760/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0059, d_svhn_loss: 0.0239, d_fake_loss: 0.0432, g_loss: 1.5033\n",
            "Step [45770/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0064, d_svhn_loss: 0.0311, d_fake_loss: 0.0769, g_loss: 1.3648\n",
            "Step [45780/80000], d_real_loss: 0.1031, d_mnist_loss: 0.0093, d_svhn_loss: 0.0938, d_fake_loss: 0.1127, g_loss: 1.1700\n",
            "Step [45790/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0079, d_svhn_loss: 0.0474, d_fake_loss: 0.0367, g_loss: 1.1277\n",
            "Step [45800/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0057, d_svhn_loss: 0.0611, d_fake_loss: 0.0710, g_loss: 1.4657\n",
            "Step [45810/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0194, d_svhn_loss: 0.0473, d_fake_loss: 0.0603, g_loss: 1.4288\n",
            "Step [45820/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0067, d_svhn_loss: 0.0388, d_fake_loss: 0.1133, g_loss: 1.4324\n",
            "Step [45830/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0095, d_svhn_loss: 0.0445, d_fake_loss: 0.0812, g_loss: 1.2279\n",
            "Step [45840/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0064, d_svhn_loss: 0.0444, d_fake_loss: 0.0372, g_loss: 1.1310\n",
            "Step [45850/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0054, d_svhn_loss: 0.0367, d_fake_loss: 0.2023, g_loss: 1.1339\n",
            "Step [45860/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0043, d_svhn_loss: 0.0294, d_fake_loss: 0.0398, g_loss: 1.2160\n",
            "Step [45870/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0067, d_svhn_loss: 0.0461, d_fake_loss: 0.0687, g_loss: 1.1980\n",
            "Step [45880/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0061, d_svhn_loss: 0.0722, d_fake_loss: 0.0240, g_loss: 1.2491\n",
            "Step [45890/80000], d_real_loss: 0.1060, d_mnist_loss: 0.0058, d_svhn_loss: 0.1002, d_fake_loss: 0.0500, g_loss: 1.1441\n",
            "Step [45900/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0061, d_svhn_loss: 0.0386, d_fake_loss: 0.0508, g_loss: 1.1196\n",
            "Step [45910/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0074, d_svhn_loss: 0.0352, d_fake_loss: 0.0419, g_loss: 1.1550\n",
            "Step [45920/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0049, d_svhn_loss: 0.0267, d_fake_loss: 0.1084, g_loss: 1.2762\n",
            "Step [45930/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0109, d_svhn_loss: 0.0282, d_fake_loss: 0.0507, g_loss: 1.1244\n",
            "Step [45940/80000], d_real_loss: 0.1005, d_mnist_loss: 0.0155, d_svhn_loss: 0.0851, d_fake_loss: 0.0469, g_loss: 1.2065\n",
            "Step [45950/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0069, d_svhn_loss: 0.0395, d_fake_loss: 0.0386, g_loss: 1.1150\n",
            "Step [45960/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0071, d_svhn_loss: 0.0377, d_fake_loss: 0.0387, g_loss: 1.2500\n",
            "Step [45970/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0085, d_svhn_loss: 0.0468, d_fake_loss: 0.0629, g_loss: 1.0194\n",
            "Step [45980/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0105, d_svhn_loss: 0.0184, d_fake_loss: 0.0321, g_loss: 1.3995\n",
            "Step [45990/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0082, d_svhn_loss: 0.0616, d_fake_loss: 0.0343, g_loss: 1.0486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [46000/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0066, d_svhn_loss: 0.0418, d_fake_loss: 0.0559, g_loss: 1.1608\n",
            "saved ./samples_mnist_svhn/sample-46000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-46000-s-m.png\n",
            "Step [46010/80000], d_real_loss: 0.1295, d_mnist_loss: 0.0188, d_svhn_loss: 0.1107, d_fake_loss: 0.1772, g_loss: 1.1281\n",
            "Step [46020/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0121, d_svhn_loss: 0.0237, d_fake_loss: 0.0946, g_loss: 1.2189\n",
            "Step [46030/80000], d_real_loss: 0.1050, d_mnist_loss: 0.0092, d_svhn_loss: 0.0958, d_fake_loss: 0.0576, g_loss: 1.1863\n",
            "Step [46040/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0095, d_svhn_loss: 0.0416, d_fake_loss: 0.0589, g_loss: 1.1443\n",
            "Step [46050/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0075, d_svhn_loss: 0.0170, d_fake_loss: 0.0866, g_loss: 1.1377\n",
            "Step [46060/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0050, d_svhn_loss: 0.0244, d_fake_loss: 0.0196, g_loss: 1.1909\n",
            "Step [46070/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0071, d_svhn_loss: 0.0520, d_fake_loss: 0.0500, g_loss: 1.1976\n",
            "Step [46080/80000], d_real_loss: 0.0873, d_mnist_loss: 0.0180, d_svhn_loss: 0.0693, d_fake_loss: 0.0803, g_loss: 1.1885\n",
            "Step [46090/80000], d_real_loss: 0.1393, d_mnist_loss: 0.0237, d_svhn_loss: 0.1156, d_fake_loss: 0.0234, g_loss: 1.0887\n",
            "Step [46100/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0055, d_svhn_loss: 0.0470, d_fake_loss: 0.0278, g_loss: 1.2407\n",
            "Step [46110/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0095, d_svhn_loss: 0.0326, d_fake_loss: 0.0429, g_loss: 1.7158\n",
            "Step [46120/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0057, d_svhn_loss: 0.0295, d_fake_loss: 0.0552, g_loss: 1.0970\n",
            "Step [46130/80000], d_real_loss: 0.1715, d_mnist_loss: 0.0056, d_svhn_loss: 0.1659, d_fake_loss: 0.0368, g_loss: 1.2894\n",
            "Step [46140/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0110, d_svhn_loss: 0.0200, d_fake_loss: 0.1176, g_loss: 1.0960\n",
            "Step [46150/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0084, d_svhn_loss: 0.0183, d_fake_loss: 0.1108, g_loss: 1.2200\n",
            "Step [46160/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0059, d_svhn_loss: 0.0285, d_fake_loss: 0.0284, g_loss: 1.1810\n",
            "Step [46170/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0061, d_svhn_loss: 0.0212, d_fake_loss: 0.0217, g_loss: 1.1947\n",
            "Step [46180/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0056, d_svhn_loss: 0.0344, d_fake_loss: 0.0264, g_loss: 1.1223\n",
            "Step [46190/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0060, d_svhn_loss: 0.0371, d_fake_loss: 0.0486, g_loss: 1.0933\n",
            "Step [46200/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0064, d_svhn_loss: 0.0288, d_fake_loss: 0.0284, g_loss: 1.1074\n",
            "Step [46210/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0108, d_svhn_loss: 0.0542, d_fake_loss: 0.0457, g_loss: 1.2462\n",
            "Step [46220/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0045, d_svhn_loss: 0.0625, d_fake_loss: 0.0245, g_loss: 1.2936\n",
            "Step [46230/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0048, d_svhn_loss: 0.0393, d_fake_loss: 0.0192, g_loss: 1.1769\n",
            "Step [46240/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0166, d_svhn_loss: 0.0259, d_fake_loss: 0.0498, g_loss: 1.1481\n",
            "Step [46250/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0053, d_svhn_loss: 0.0434, d_fake_loss: 0.1632, g_loss: 1.2067\n",
            "Step [46260/80000], d_real_loss: 0.1312, d_mnist_loss: 0.0099, d_svhn_loss: 0.1213, d_fake_loss: 0.0795, g_loss: 1.0276\n",
            "Step [46270/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0098, d_svhn_loss: 0.0124, d_fake_loss: 0.0702, g_loss: 1.2928\n",
            "Step [46280/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0046, d_svhn_loss: 0.0269, d_fake_loss: 0.0918, g_loss: 1.1922\n",
            "Step [46290/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0201, d_svhn_loss: 0.0195, d_fake_loss: 0.0689, g_loss: 1.1893\n",
            "Step [46300/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0088, d_svhn_loss: 0.0243, d_fake_loss: 0.0201, g_loss: 1.1152\n",
            "Step [46310/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0035, d_svhn_loss: 0.0550, d_fake_loss: 0.0390, g_loss: 1.2525\n",
            "Step [46320/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0078, d_svhn_loss: 0.0497, d_fake_loss: 0.0479, g_loss: 1.0937\n",
            "Step [46330/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0076, d_svhn_loss: 0.0232, d_fake_loss: 0.0334, g_loss: 1.1969\n",
            "Step [46340/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0083, d_svhn_loss: 0.0214, d_fake_loss: 0.0401, g_loss: 1.1193\n",
            "Step [46350/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0070, d_svhn_loss: 0.0229, d_fake_loss: 0.0387, g_loss: 1.2412\n",
            "Step [46360/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0038, d_svhn_loss: 0.0205, d_fake_loss: 0.0302, g_loss: 1.3719\n",
            "Step [46370/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0048, d_svhn_loss: 0.0254, d_fake_loss: 0.0303, g_loss: 1.1819\n",
            "Step [46380/80000], d_real_loss: 0.1018, d_mnist_loss: 0.0077, d_svhn_loss: 0.0940, d_fake_loss: 0.0267, g_loss: 1.2137\n",
            "Step [46390/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0039, d_svhn_loss: 0.0500, d_fake_loss: 0.0546, g_loss: 1.2593\n",
            "Step [46400/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0088, d_svhn_loss: 0.0474, d_fake_loss: 0.1072, g_loss: 1.1261\n",
            "Step [46410/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0063, d_svhn_loss: 0.0222, d_fake_loss: 0.0216, g_loss: 1.1418\n",
            "Step [46420/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0039, d_svhn_loss: 0.0209, d_fake_loss: 0.0229, g_loss: 1.2097\n",
            "Step [46430/80000], d_real_loss: 0.1000, d_mnist_loss: 0.0150, d_svhn_loss: 0.0850, d_fake_loss: 0.0517, g_loss: 1.3796\n",
            "Step [46440/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0092, d_svhn_loss: 0.0368, d_fake_loss: 0.0674, g_loss: 1.1330\n",
            "Step [46450/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0063, d_svhn_loss: 0.0183, d_fake_loss: 0.0350, g_loss: 1.2036\n",
            "Step [46460/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0105, d_svhn_loss: 0.0305, d_fake_loss: 0.0222, g_loss: 1.1868\n",
            "Step [46470/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0057, d_svhn_loss: 0.0230, d_fake_loss: 0.2050, g_loss: 1.5226\n",
            "Step [46480/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0104, d_svhn_loss: 0.0302, d_fake_loss: 0.0755, g_loss: 1.2523\n",
            "Step [46490/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0052, d_svhn_loss: 0.0720, d_fake_loss: 0.0647, g_loss: 1.7490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [46500/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0053, d_svhn_loss: 0.0148, d_fake_loss: 0.0174, g_loss: 1.2019\n",
            "saved ./samples_mnist_svhn/sample-46500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-46500-s-m.png\n",
            "Step [46510/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0048, d_svhn_loss: 0.0229, d_fake_loss: 0.0394, g_loss: 1.1647\n",
            "Step [46520/80000], d_real_loss: 0.1196, d_mnist_loss: 0.0064, d_svhn_loss: 0.1131, d_fake_loss: 0.0165, g_loss: 1.2518\n",
            "Step [46530/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0078, d_svhn_loss: 0.0343, d_fake_loss: 0.0609, g_loss: 1.2573\n",
            "Step [46540/80000], d_real_loss: 0.1045, d_mnist_loss: 0.0072, d_svhn_loss: 0.0973, d_fake_loss: 0.0225, g_loss: 1.2250\n",
            "Step [46550/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0156, d_svhn_loss: 0.0413, d_fake_loss: 0.0796, g_loss: 0.9943\n",
            "Step [46560/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0056, d_svhn_loss: 0.0289, d_fake_loss: 0.0325, g_loss: 1.1486\n",
            "Step [46570/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0071, d_svhn_loss: 0.0366, d_fake_loss: 0.0363, g_loss: 1.1107\n",
            "Step [46580/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0111, d_svhn_loss: 0.0273, d_fake_loss: 0.0628, g_loss: 1.2660\n",
            "Step [46590/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0052, d_svhn_loss: 0.0520, d_fake_loss: 0.0489, g_loss: 1.1102\n",
            "Step [46600/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0073, d_svhn_loss: 0.1007, d_fake_loss: 0.1382, g_loss: 1.1424\n",
            "Step [46610/80000], d_real_loss: 0.1048, d_mnist_loss: 0.0058, d_svhn_loss: 0.0990, d_fake_loss: 0.0270, g_loss: 1.2761\n",
            "Step [46620/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0078, d_svhn_loss: 0.0189, d_fake_loss: 0.0519, g_loss: 1.1809\n",
            "Step [46630/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0095, d_svhn_loss: 0.0255, d_fake_loss: 0.0353, g_loss: 1.1374\n",
            "Step [46640/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0054, d_svhn_loss: 0.0679, d_fake_loss: 0.0298, g_loss: 1.2067\n",
            "Step [46650/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0052, d_svhn_loss: 0.0564, d_fake_loss: 0.0346, g_loss: 1.4946\n",
            "Step [46660/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0193, d_svhn_loss: 0.0168, d_fake_loss: 0.0189, g_loss: 1.0577\n",
            "Step [46670/80000], d_real_loss: 0.1199, d_mnist_loss: 0.0174, d_svhn_loss: 0.1025, d_fake_loss: 0.0302, g_loss: 1.0968\n",
            "Step [46680/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0063, d_svhn_loss: 0.0254, d_fake_loss: 0.0909, g_loss: 1.1542\n",
            "Step [46690/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0026, d_svhn_loss: 0.0248, d_fake_loss: 0.0878, g_loss: 1.1798\n",
            "Step [46700/80000], d_real_loss: 0.0704, d_mnist_loss: 0.0073, d_svhn_loss: 0.0631, d_fake_loss: 0.0452, g_loss: 1.0979\n",
            "Step [46710/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0105, d_svhn_loss: 0.0614, d_fake_loss: 0.0336, g_loss: 1.0704\n",
            "Step [46720/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0221, d_svhn_loss: 0.0179, d_fake_loss: 0.0487, g_loss: 1.0553\n",
            "Step [46730/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0166, d_svhn_loss: 0.0328, d_fake_loss: 0.0235, g_loss: 1.1494\n",
            "Step [46740/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0084, d_svhn_loss: 0.0297, d_fake_loss: 0.0157, g_loss: 1.1179\n",
            "Step [46750/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0084, d_svhn_loss: 0.0262, d_fake_loss: 0.0369, g_loss: 1.2621\n",
            "Step [46760/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0093, d_svhn_loss: 0.0223, d_fake_loss: 0.0949, g_loss: 1.0279\n",
            "Step [46770/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0069, d_svhn_loss: 0.0455, d_fake_loss: 0.0448, g_loss: 1.0887\n",
            "Step [46780/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0065, d_svhn_loss: 0.0474, d_fake_loss: 0.0152, g_loss: 1.1293\n",
            "Step [46790/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0078, d_svhn_loss: 0.0298, d_fake_loss: 0.0248, g_loss: 1.3416\n",
            "Step [46800/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0068, d_svhn_loss: 0.0568, d_fake_loss: 0.0202, g_loss: 1.2120\n",
            "Step [46810/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0140, d_svhn_loss: 0.0592, d_fake_loss: 0.0587, g_loss: 1.1528\n",
            "Step [46820/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0053, d_svhn_loss: 0.0272, d_fake_loss: 0.0156, g_loss: 1.2011\n",
            "Step [46830/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0052, d_svhn_loss: 0.0349, d_fake_loss: 0.0443, g_loss: 1.1121\n",
            "Step [46840/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0078, d_svhn_loss: 0.0260, d_fake_loss: 0.0497, g_loss: 1.0751\n",
            "Step [46850/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0045, d_svhn_loss: 0.0222, d_fake_loss: 0.0380, g_loss: 1.0869\n",
            "Step [46860/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0035, d_svhn_loss: 0.0544, d_fake_loss: 0.0967, g_loss: 1.0404\n",
            "Step [46870/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0077, d_svhn_loss: 0.0219, d_fake_loss: 0.0662, g_loss: 1.1042\n",
            "Step [46880/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0091, d_svhn_loss: 0.0169, d_fake_loss: 0.0160, g_loss: 1.1224\n",
            "Step [46890/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0100, d_svhn_loss: 0.0393, d_fake_loss: 0.0170, g_loss: 1.1705\n",
            "Step [46900/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0040, d_svhn_loss: 0.0578, d_fake_loss: 0.0236, g_loss: 1.0969\n",
            "Step [46910/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0043, d_svhn_loss: 0.0217, d_fake_loss: 0.0417, g_loss: 1.1816\n",
            "Step [46920/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0116, d_svhn_loss: 0.0174, d_fake_loss: 0.0157, g_loss: 1.1014\n",
            "Step [46930/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0048, d_svhn_loss: 0.0431, d_fake_loss: 0.0375, g_loss: 1.2326\n",
            "Step [46940/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0040, d_svhn_loss: 0.0293, d_fake_loss: 0.0306, g_loss: 1.1223\n",
            "Step [46950/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0064, d_svhn_loss: 0.0476, d_fake_loss: 0.0367, g_loss: 1.0949\n",
            "Step [46960/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0056, d_svhn_loss: 0.0350, d_fake_loss: 0.0275, g_loss: 1.0876\n",
            "Step [46970/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0065, d_svhn_loss: 0.0281, d_fake_loss: 0.0439, g_loss: 1.1817\n",
            "Step [46980/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0040, d_svhn_loss: 0.0435, d_fake_loss: 0.0527, g_loss: 1.1128\n",
            "Step [46990/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0069, d_svhn_loss: 0.0280, d_fake_loss: 0.0227, g_loss: 1.1478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [47000/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0161, d_svhn_loss: 0.0186, d_fake_loss: 0.0342, g_loss: 1.1489\n",
            "saved ./samples_mnist_svhn/sample-47000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-47000-s-m.png\n",
            "Step [47010/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0128, d_svhn_loss: 0.0369, d_fake_loss: 0.0665, g_loss: 1.2078\n",
            "Step [47020/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0200, d_svhn_loss: 0.0611, d_fake_loss: 0.1224, g_loss: 1.2817\n",
            "Step [47030/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0184, d_svhn_loss: 0.0316, d_fake_loss: 0.0358, g_loss: 1.1278\n",
            "Step [47040/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0133, d_svhn_loss: 0.0467, d_fake_loss: 0.0298, g_loss: 1.0204\n",
            "Step [47050/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0124, d_svhn_loss: 0.0543, d_fake_loss: 0.0644, g_loss: 1.0450\n",
            "Step [47060/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0097, d_svhn_loss: 0.0319, d_fake_loss: 0.0240, g_loss: 1.1571\n",
            "Step [47070/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0178, d_svhn_loss: 0.0203, d_fake_loss: 0.0625, g_loss: 1.3859\n",
            "Step [47080/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0043, d_svhn_loss: 0.0194, d_fake_loss: 0.0468, g_loss: 1.3356\n",
            "Step [47090/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0257, d_svhn_loss: 0.0146, d_fake_loss: 0.0312, g_loss: 1.1056\n",
            "Step [47100/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0074, d_svhn_loss: 0.0666, d_fake_loss: 0.0510, g_loss: 1.1741\n",
            "Step [47110/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0074, d_svhn_loss: 0.0323, d_fake_loss: 0.0323, g_loss: 1.3065\n",
            "Step [47120/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0045, d_svhn_loss: 0.0543, d_fake_loss: 0.0234, g_loss: 1.0944\n",
            "Step [47130/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0061, d_svhn_loss: 0.0599, d_fake_loss: 0.0217, g_loss: 1.1016\n",
            "Step [47140/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0116, d_svhn_loss: 0.0315, d_fake_loss: 0.0345, g_loss: 1.2204\n",
            "Step [47150/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0153, d_svhn_loss: 0.0217, d_fake_loss: 0.0188, g_loss: 1.1675\n",
            "Step [47160/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0130, d_svhn_loss: 0.0286, d_fake_loss: 0.0644, g_loss: 1.2903\n",
            "Step [47170/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0444, d_svhn_loss: 0.0127, d_fake_loss: 0.3450, g_loss: 1.9106\n",
            "Step [47180/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0112, d_svhn_loss: 0.0334, d_fake_loss: 0.0237, g_loss: 1.2369\n",
            "Step [47190/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0084, d_svhn_loss: 0.0276, d_fake_loss: 0.0478, g_loss: 1.3669\n",
            "Step [47200/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0076, d_svhn_loss: 0.0261, d_fake_loss: 0.0726, g_loss: 1.2362\n",
            "Step [47210/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0072, d_svhn_loss: 0.0238, d_fake_loss: 0.1155, g_loss: 1.1387\n",
            "Step [47220/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0043, d_svhn_loss: 0.0166, d_fake_loss: 0.0470, g_loss: 1.2623\n",
            "Step [47230/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0131, d_svhn_loss: 0.0295, d_fake_loss: 0.1364, g_loss: 1.3332\n",
            "Step [47240/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0077, d_svhn_loss: 0.0238, d_fake_loss: 0.0194, g_loss: 1.2469\n",
            "Step [47250/80000], d_real_loss: 0.0890, d_mnist_loss: 0.0060, d_svhn_loss: 0.0831, d_fake_loss: 0.0898, g_loss: 1.1118\n",
            "Step [47260/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0064, d_svhn_loss: 0.0287, d_fake_loss: 0.0216, g_loss: 1.1864\n",
            "Step [47270/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0060, d_svhn_loss: 0.0256, d_fake_loss: 0.0722, g_loss: 0.9694\n",
            "Step [47280/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0054, d_svhn_loss: 0.0736, d_fake_loss: 0.0379, g_loss: 1.1274\n",
            "Step [47290/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0066, d_svhn_loss: 0.0460, d_fake_loss: 0.1534, g_loss: 1.1528\n",
            "Step [47300/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0069, d_svhn_loss: 0.0716, d_fake_loss: 0.0504, g_loss: 1.1069\n",
            "Step [47310/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0067, d_svhn_loss: 0.0388, d_fake_loss: 0.0359, g_loss: 1.2768\n",
            "Step [47320/80000], d_real_loss: 0.0883, d_mnist_loss: 0.0273, d_svhn_loss: 0.0609, d_fake_loss: 0.0448, g_loss: 0.9979\n",
            "Step [47330/80000], d_real_loss: 0.1185, d_mnist_loss: 0.0078, d_svhn_loss: 0.1107, d_fake_loss: 0.1069, g_loss: 1.1380\n",
            "Step [47340/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0116, d_svhn_loss: 0.0448, d_fake_loss: 0.0298, g_loss: 1.1611\n",
            "Step [47350/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0068, d_svhn_loss: 0.0235, d_fake_loss: 0.0470, g_loss: 1.1368\n",
            "Step [47360/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0057, d_svhn_loss: 0.0282, d_fake_loss: 0.1421, g_loss: 1.4877\n",
            "Step [47370/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0087, d_svhn_loss: 0.0234, d_fake_loss: 0.0171, g_loss: 1.1259\n",
            "Step [47380/80000], d_real_loss: 0.0798, d_mnist_loss: 0.0063, d_svhn_loss: 0.0735, d_fake_loss: 0.0449, g_loss: 1.5146\n",
            "Step [47390/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0077, d_svhn_loss: 0.0208, d_fake_loss: 0.1100, g_loss: 1.2703\n",
            "Step [47400/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0159, d_svhn_loss: 0.0260, d_fake_loss: 0.0492, g_loss: 1.0718\n",
            "Step [47410/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0126, d_svhn_loss: 0.0361, d_fake_loss: 0.0419, g_loss: 1.1843\n",
            "Step [47420/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0099, d_svhn_loss: 0.0219, d_fake_loss: 0.1799, g_loss: 1.9398\n",
            "Step [47430/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0105, d_svhn_loss: 0.0181, d_fake_loss: 0.0356, g_loss: 1.1568\n",
            "Step [47440/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0082, d_svhn_loss: 0.0226, d_fake_loss: 0.0254, g_loss: 1.1057\n",
            "Step [47450/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0094, d_svhn_loss: 0.0409, d_fake_loss: 0.0457, g_loss: 1.2369\n",
            "Step [47460/80000], d_real_loss: 0.0803, d_mnist_loss: 0.0093, d_svhn_loss: 0.0711, d_fake_loss: 0.0304, g_loss: 1.2601\n",
            "Step [47470/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0133, d_svhn_loss: 0.0487, d_fake_loss: 0.0372, g_loss: 1.3598\n",
            "Step [47480/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0072, d_svhn_loss: 0.0600, d_fake_loss: 0.0794, g_loss: 1.1103\n",
            "Step [47490/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0050, d_svhn_loss: 0.0336, d_fake_loss: 0.0231, g_loss: 1.1301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [47500/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0093, d_svhn_loss: 0.0475, d_fake_loss: 0.0486, g_loss: 1.0199\n",
            "saved ./samples_mnist_svhn/sample-47500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-47500-s-m.png\n",
            "Step [47510/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0062, d_svhn_loss: 0.0593, d_fake_loss: 0.0324, g_loss: 1.2408\n",
            "Step [47520/80000], d_real_loss: 0.1811, d_mnist_loss: 0.0063, d_svhn_loss: 0.1747, d_fake_loss: 0.0591, g_loss: 1.2184\n",
            "Step [47530/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0057, d_svhn_loss: 0.0311, d_fake_loss: 0.0464, g_loss: 1.2507\n",
            "Step [47540/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0047, d_svhn_loss: 0.0484, d_fake_loss: 0.0998, g_loss: 1.2330\n",
            "Step [47550/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0069, d_svhn_loss: 0.0333, d_fake_loss: 0.0174, g_loss: 1.1989\n",
            "Step [47560/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0098, d_svhn_loss: 0.0387, d_fake_loss: 0.0355, g_loss: 1.2312\n",
            "Step [47570/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0053, d_svhn_loss: 0.0184, d_fake_loss: 0.0505, g_loss: 1.2034\n",
            "Step [47580/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0183, d_svhn_loss: 0.0222, d_fake_loss: 0.0896, g_loss: 1.0726\n",
            "Step [47590/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0061, d_svhn_loss: 0.0408, d_fake_loss: 0.0187, g_loss: 1.1331\n",
            "Step [47600/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0146, d_svhn_loss: 0.0309, d_fake_loss: 0.2176, g_loss: 1.5959\n",
            "Step [47610/80000], d_real_loss: 0.0728, d_mnist_loss: 0.0085, d_svhn_loss: 0.0642, d_fake_loss: 0.0287, g_loss: 1.2184\n",
            "Step [47620/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0058, d_svhn_loss: 0.0192, d_fake_loss: 0.0137, g_loss: 1.1709\n",
            "Step [47630/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0171, d_svhn_loss: 0.0363, d_fake_loss: 0.0352, g_loss: 1.1453\n",
            "Step [47640/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0062, d_svhn_loss: 0.0313, d_fake_loss: 0.0510, g_loss: 1.0437\n",
            "Step [47650/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0093, d_svhn_loss: 0.0342, d_fake_loss: 0.0525, g_loss: 1.1119\n",
            "Step [47660/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0096, d_svhn_loss: 0.0656, d_fake_loss: 0.2091, g_loss: 1.4822\n",
            "Step [47670/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0140, d_svhn_loss: 0.0545, d_fake_loss: 0.0447, g_loss: 1.0901\n",
            "Step [47680/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0206, d_svhn_loss: 0.0263, d_fake_loss: 0.1077, g_loss: 1.2553\n",
            "Step [47690/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0074, d_svhn_loss: 0.0336, d_fake_loss: 0.0329, g_loss: 1.2110\n",
            "Step [47700/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0110, d_svhn_loss: 0.0375, d_fake_loss: 0.0290, g_loss: 1.1795\n",
            "Step [47710/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0054, d_svhn_loss: 0.0688, d_fake_loss: 0.0346, g_loss: 1.2088\n",
            "Step [47720/80000], d_real_loss: 0.0680, d_mnist_loss: 0.0059, d_svhn_loss: 0.0621, d_fake_loss: 0.0261, g_loss: 1.2444\n",
            "Step [47730/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0086, d_svhn_loss: 0.0664, d_fake_loss: 0.0334, g_loss: 1.2003\n",
            "Step [47740/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0080, d_svhn_loss: 0.0182, d_fake_loss: 0.0248, g_loss: 1.1588\n",
            "Step [47750/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0103, d_svhn_loss: 0.0183, d_fake_loss: 0.0384, g_loss: 1.1860\n",
            "Step [47760/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0056, d_svhn_loss: 0.0228, d_fake_loss: 0.0252, g_loss: 1.0890\n",
            "Step [47770/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0057, d_svhn_loss: 0.0364, d_fake_loss: 0.1575, g_loss: 1.2006\n",
            "Step [47780/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0095, d_svhn_loss: 0.0308, d_fake_loss: 0.0643, g_loss: 1.2861\n",
            "Step [47790/80000], d_real_loss: 0.1176, d_mnist_loss: 0.0123, d_svhn_loss: 0.1054, d_fake_loss: 0.0148, g_loss: 1.3097\n",
            "Step [47800/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0089, d_svhn_loss: 0.0291, d_fake_loss: 0.0261, g_loss: 1.1363\n",
            "Step [47810/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0062, d_svhn_loss: 0.0510, d_fake_loss: 0.0289, g_loss: 1.1954\n",
            "Step [47820/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0061, d_svhn_loss: 0.0259, d_fake_loss: 0.0305, g_loss: 1.1184\n",
            "Step [47830/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0066, d_svhn_loss: 0.0289, d_fake_loss: 0.0410, g_loss: 1.4031\n",
            "Step [47840/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0043, d_svhn_loss: 0.0297, d_fake_loss: 0.0392, g_loss: 1.2217\n",
            "Step [47850/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0075, d_svhn_loss: 0.0332, d_fake_loss: 0.0206, g_loss: 1.1393\n",
            "Step [47860/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0055, d_svhn_loss: 0.0246, d_fake_loss: 0.0787, g_loss: 1.3605\n",
            "Step [47870/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0046, d_svhn_loss: 0.0358, d_fake_loss: 0.0437, g_loss: 1.1440\n",
            "Step [47880/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0058, d_svhn_loss: 0.0631, d_fake_loss: 0.0571, g_loss: 1.1142\n",
            "Step [47890/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0047, d_svhn_loss: 0.0151, d_fake_loss: 0.0259, g_loss: 1.1248\n",
            "Step [47900/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0054, d_svhn_loss: 0.0291, d_fake_loss: 0.0687, g_loss: 1.2961\n",
            "Step [47910/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0066, d_svhn_loss: 0.0186, d_fake_loss: 0.0344, g_loss: 1.0633\n",
            "Step [47920/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0259, d_svhn_loss: 0.0231, d_fake_loss: 0.0822, g_loss: 1.6951\n",
            "Step [47930/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0069, d_svhn_loss: 0.0208, d_fake_loss: 0.0573, g_loss: 1.1188\n",
            "Step [47940/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0072, d_svhn_loss: 0.0365, d_fake_loss: 0.0415, g_loss: 1.2771\n",
            "Step [47950/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0077, d_svhn_loss: 0.0217, d_fake_loss: 0.0210, g_loss: 1.0468\n",
            "Step [47960/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0055, d_svhn_loss: 0.0172, d_fake_loss: 0.0874, g_loss: 1.1173\n",
            "Step [47970/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0050, d_svhn_loss: 0.0356, d_fake_loss: 0.0182, g_loss: 1.2565\n",
            "Step [47980/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0072, d_svhn_loss: 0.0376, d_fake_loss: 0.0332, g_loss: 1.1268\n",
            "Step [47990/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0043, d_svhn_loss: 0.0617, d_fake_loss: 0.1172, g_loss: 1.1742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [48000/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0161, d_svhn_loss: 0.0180, d_fake_loss: 0.0751, g_loss: 1.0616\n",
            "saved ./samples_mnist_svhn/sample-48000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-48000-s-m.png\n",
            "Step [48010/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0039, d_svhn_loss: 0.0207, d_fake_loss: 0.0279, g_loss: 1.2242\n",
            "Step [48020/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0071, d_svhn_loss: 0.0218, d_fake_loss: 0.0451, g_loss: 1.1774\n",
            "Step [48030/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0169, d_svhn_loss: 0.0329, d_fake_loss: 0.0660, g_loss: 1.2722\n",
            "Step [48040/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0046, d_svhn_loss: 0.0216, d_fake_loss: 0.0340, g_loss: 1.1264\n",
            "Step [48050/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0080, d_svhn_loss: 0.0380, d_fake_loss: 0.0374, g_loss: 1.3853\n",
            "Step [48060/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0090, d_svhn_loss: 0.0777, d_fake_loss: 0.1326, g_loss: 1.0533\n",
            "Step [48070/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0086, d_svhn_loss: 0.0301, d_fake_loss: 0.0844, g_loss: 0.9794\n",
            "Step [48080/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0044, d_svhn_loss: 0.0210, d_fake_loss: 0.0954, g_loss: 1.1422\n",
            "Step [48090/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0113, d_svhn_loss: 0.0366, d_fake_loss: 0.0260, g_loss: 1.2107\n",
            "Step [48100/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0074, d_svhn_loss: 0.0376, d_fake_loss: 0.0475, g_loss: 1.1497\n",
            "Step [48110/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0055, d_svhn_loss: 0.0169, d_fake_loss: 0.0683, g_loss: 1.3081\n",
            "Step [48120/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0069, d_svhn_loss: 0.0351, d_fake_loss: 0.0190, g_loss: 1.1827\n",
            "Step [48130/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0045, d_svhn_loss: 0.0401, d_fake_loss: 0.0309, g_loss: 1.0651\n",
            "Step [48140/80000], d_real_loss: 0.0779, d_mnist_loss: 0.0282, d_svhn_loss: 0.0497, d_fake_loss: 0.0375, g_loss: 0.9644\n",
            "Step [48150/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0078, d_svhn_loss: 0.0276, d_fake_loss: 0.0798, g_loss: 1.1132\n",
            "Step [48160/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0072, d_svhn_loss: 0.0188, d_fake_loss: 0.0274, g_loss: 1.2829\n",
            "Step [48170/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0093, d_svhn_loss: 0.0228, d_fake_loss: 0.0483, g_loss: 1.2385\n",
            "Step [48180/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0058, d_svhn_loss: 0.0227, d_fake_loss: 0.0671, g_loss: 1.4172\n",
            "Step [48190/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0134, d_svhn_loss: 0.0534, d_fake_loss: 0.0792, g_loss: 1.4015\n",
            "Step [48200/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0077, d_svhn_loss: 0.0231, d_fake_loss: 0.0225, g_loss: 1.1934\n",
            "Step [48210/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0078, d_svhn_loss: 0.0283, d_fake_loss: 0.0166, g_loss: 1.1877\n",
            "Step [48220/80000], d_real_loss: 0.1297, d_mnist_loss: 0.0056, d_svhn_loss: 0.1241, d_fake_loss: 0.0203, g_loss: 1.2130\n",
            "Step [48230/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0075, d_svhn_loss: 0.0276, d_fake_loss: 0.0651, g_loss: 0.9970\n",
            "Step [48240/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0042, d_svhn_loss: 0.0537, d_fake_loss: 0.0472, g_loss: 1.1806\n",
            "Step [48250/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0108, d_svhn_loss: 0.0315, d_fake_loss: 0.0521, g_loss: 1.3661\n",
            "Step [48260/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0103, d_svhn_loss: 0.0187, d_fake_loss: 0.0570, g_loss: 1.1884\n",
            "Step [48270/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0103, d_svhn_loss: 0.0178, d_fake_loss: 0.0687, g_loss: 1.1264\n",
            "Step [48280/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0110, d_svhn_loss: 0.0681, d_fake_loss: 0.0502, g_loss: 1.3384\n",
            "Step [48290/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0082, d_svhn_loss: 0.0494, d_fake_loss: 0.0128, g_loss: 1.2067\n",
            "Step [48300/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0098, d_svhn_loss: 0.0364, d_fake_loss: 0.0287, g_loss: 1.3015\n",
            "Step [48310/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0063, d_svhn_loss: 0.0217, d_fake_loss: 0.0391, g_loss: 1.1957\n",
            "Step [48320/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0038, d_svhn_loss: 0.0600, d_fake_loss: 0.0803, g_loss: 1.1586\n",
            "Step [48330/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0050, d_svhn_loss: 0.0276, d_fake_loss: 0.0844, g_loss: 1.2185\n",
            "Step [48340/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0055, d_svhn_loss: 0.0218, d_fake_loss: 0.0256, g_loss: 1.0719\n",
            "Step [48350/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0152, d_svhn_loss: 0.0137, d_fake_loss: 0.0356, g_loss: 1.1570\n",
            "Step [48360/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0046, d_svhn_loss: 0.0565, d_fake_loss: 0.0365, g_loss: 1.2289\n",
            "Step [48370/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0095, d_svhn_loss: 0.0573, d_fake_loss: 0.0644, g_loss: 1.2304\n",
            "Step [48380/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0054, d_svhn_loss: 0.0783, d_fake_loss: 0.0527, g_loss: 1.2608\n",
            "Step [48390/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0147, d_svhn_loss: 0.0367, d_fake_loss: 0.0305, g_loss: 1.2261\n",
            "Step [48400/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0220, d_svhn_loss: 0.0194, d_fake_loss: 0.0398, g_loss: 1.2737\n",
            "Step [48410/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0034, d_svhn_loss: 0.0265, d_fake_loss: 0.0751, g_loss: 1.2726\n",
            "Step [48420/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0056, d_svhn_loss: 0.0213, d_fake_loss: 0.0161, g_loss: 1.1361\n",
            "Step [48430/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0078, d_svhn_loss: 0.0230, d_fake_loss: 0.0210, g_loss: 1.2012\n",
            "Step [48440/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0065, d_svhn_loss: 0.0272, d_fake_loss: 0.0391, g_loss: 1.3247\n",
            "Step [48450/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0091, d_svhn_loss: 0.0173, d_fake_loss: 0.1222, g_loss: 1.0908\n",
            "Step [48460/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0072, d_svhn_loss: 0.0552, d_fake_loss: 0.1045, g_loss: 1.1773\n",
            "Step [48470/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0086, d_svhn_loss: 0.0286, d_fake_loss: 0.0328, g_loss: 1.2768\n",
            "Step [48480/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0066, d_svhn_loss: 0.0454, d_fake_loss: 0.0449, g_loss: 1.1163\n",
            "Step [48490/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0062, d_svhn_loss: 0.0308, d_fake_loss: 0.0186, g_loss: 1.2144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [48500/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0045, d_svhn_loss: 0.0307, d_fake_loss: 0.0555, g_loss: 1.2574\n",
            "saved ./samples_mnist_svhn/sample-48500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-48500-s-m.png\n",
            "Step [48510/80000], d_real_loss: 0.0911, d_mnist_loss: 0.0055, d_svhn_loss: 0.0856, d_fake_loss: 0.0590, g_loss: 1.0763\n",
            "Step [48520/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0097, d_svhn_loss: 0.0138, d_fake_loss: 0.0471, g_loss: 1.4324\n",
            "Step [48530/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0079, d_svhn_loss: 0.0142, d_fake_loss: 0.3070, g_loss: 1.3808\n",
            "Step [48540/80000], d_real_loss: 0.0766, d_mnist_loss: 0.0085, d_svhn_loss: 0.0681, d_fake_loss: 0.0185, g_loss: 1.1702\n",
            "Step [48550/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0072, d_svhn_loss: 0.0244, d_fake_loss: 0.1013, g_loss: 1.1518\n",
            "Step [48560/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0076, d_svhn_loss: 0.0409, d_fake_loss: 0.0364, g_loss: 1.2924\n",
            "Step [48570/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0086, d_svhn_loss: 0.0267, d_fake_loss: 0.0201, g_loss: 1.1874\n",
            "Step [48580/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0041, d_svhn_loss: 0.0373, d_fake_loss: 0.0563, g_loss: 1.2065\n",
            "Step [48590/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0066, d_svhn_loss: 0.0486, d_fake_loss: 0.0662, g_loss: 1.3350\n",
            "Step [48600/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0052, d_svhn_loss: 0.0270, d_fake_loss: 0.0992, g_loss: 1.1948\n",
            "Step [48610/80000], d_real_loss: 0.0808, d_mnist_loss: 0.0084, d_svhn_loss: 0.0724, d_fake_loss: 0.0208, g_loss: 1.1104\n",
            "Step [48620/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0098, d_svhn_loss: 0.0552, d_fake_loss: 0.0211, g_loss: 1.1588\n",
            "Step [48630/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0066, d_svhn_loss: 0.0203, d_fake_loss: 0.0131, g_loss: 1.1265\n",
            "Step [48640/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0064, d_svhn_loss: 0.0322, d_fake_loss: 0.0327, g_loss: 1.1523\n",
            "Step [48650/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0045, d_svhn_loss: 0.0459, d_fake_loss: 0.0498, g_loss: 1.1598\n",
            "Step [48660/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0057, d_svhn_loss: 0.0282, d_fake_loss: 0.0731, g_loss: 1.4899\n",
            "Step [48670/80000], d_real_loss: 0.1204, d_mnist_loss: 0.0154, d_svhn_loss: 0.1050, d_fake_loss: 0.0640, g_loss: 1.1888\n",
            "Step [48680/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0085, d_svhn_loss: 0.0293, d_fake_loss: 0.0429, g_loss: 1.1761\n",
            "Step [48690/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0064, d_svhn_loss: 0.0546, d_fake_loss: 0.0949, g_loss: 1.2529\n",
            "Step [48700/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0124, d_svhn_loss: 0.0189, d_fake_loss: 0.0793, g_loss: 0.9082\n",
            "Step [48710/80000], d_real_loss: 0.1097, d_mnist_loss: 0.0067, d_svhn_loss: 0.1030, d_fake_loss: 0.0359, g_loss: 1.1333\n",
            "Step [48720/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0110, d_svhn_loss: 0.0198, d_fake_loss: 0.0347, g_loss: 1.3555\n",
            "Step [48730/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0083, d_svhn_loss: 0.0279, d_fake_loss: 0.1052, g_loss: 1.4673\n",
            "Step [48740/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0062, d_svhn_loss: 0.0301, d_fake_loss: 0.0430, g_loss: 1.1690\n",
            "Step [48750/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0070, d_svhn_loss: 0.0290, d_fake_loss: 0.0347, g_loss: 1.3519\n",
            "Step [48760/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0078, d_svhn_loss: 0.0563, d_fake_loss: 0.0270, g_loss: 1.2651\n",
            "Step [48770/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0090, d_svhn_loss: 0.0195, d_fake_loss: 0.0362, g_loss: 1.3668\n",
            "Step [48780/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0076, d_svhn_loss: 0.0873, d_fake_loss: 0.0866, g_loss: 1.1319\n",
            "Step [48790/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0085, d_svhn_loss: 0.0178, d_fake_loss: 0.0193, g_loss: 1.2234\n",
            "Step [48800/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0116, d_svhn_loss: 0.0540, d_fake_loss: 0.0301, g_loss: 1.2755\n",
            "Step [48810/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0091, d_svhn_loss: 0.0367, d_fake_loss: 0.0236, g_loss: 1.1274\n",
            "Step [48820/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0078, d_svhn_loss: 0.0695, d_fake_loss: 0.0481, g_loss: 1.0866\n",
            "Step [48830/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0083, d_svhn_loss: 0.0226, d_fake_loss: 0.0167, g_loss: 1.1463\n",
            "Step [48840/80000], d_real_loss: 0.0856, d_mnist_loss: 0.0069, d_svhn_loss: 0.0787, d_fake_loss: 0.1530, g_loss: 1.5617\n",
            "Step [48850/80000], d_real_loss: 0.1381, d_mnist_loss: 0.0129, d_svhn_loss: 0.1251, d_fake_loss: 0.0724, g_loss: 1.2393\n",
            "Step [48860/80000], d_real_loss: 0.0826, d_mnist_loss: 0.0117, d_svhn_loss: 0.0709, d_fake_loss: 0.0296, g_loss: 1.2751\n",
            "Step [48870/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0164, d_svhn_loss: 0.0373, d_fake_loss: 0.0286, g_loss: 1.1309\n",
            "Step [48880/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0202, d_svhn_loss: 0.0296, d_fake_loss: 0.0707, g_loss: 1.2502\n",
            "Step [48890/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0080, d_svhn_loss: 0.0243, d_fake_loss: 0.0559, g_loss: 1.1036\n",
            "Step [48900/80000], d_real_loss: 0.0775, d_mnist_loss: 0.0133, d_svhn_loss: 0.0642, d_fake_loss: 0.1288, g_loss: 1.1809\n",
            "Step [48910/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0102, d_svhn_loss: 0.0269, d_fake_loss: 0.0411, g_loss: 1.0831\n",
            "Step [48920/80000], d_real_loss: 0.1274, d_mnist_loss: 0.0050, d_svhn_loss: 0.1223, d_fake_loss: 0.0242, g_loss: 1.2417\n",
            "Step [48930/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0079, d_svhn_loss: 0.0709, d_fake_loss: 0.1443, g_loss: 1.2427\n",
            "Step [48940/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0108, d_svhn_loss: 0.0736, d_fake_loss: 0.1176, g_loss: 1.3897\n",
            "Step [48950/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0069, d_svhn_loss: 0.0434, d_fake_loss: 0.0468, g_loss: 1.3259\n",
            "Step [48960/80000], d_real_loss: 0.1488, d_mnist_loss: 0.0081, d_svhn_loss: 0.1407, d_fake_loss: 0.0393, g_loss: 1.2464\n",
            "Step [48970/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0110, d_svhn_loss: 0.0405, d_fake_loss: 0.0652, g_loss: 1.0792\n",
            "Step [48980/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0089, d_svhn_loss: 0.0278, d_fake_loss: 0.0184, g_loss: 1.2147\n",
            "Step [48990/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0093, d_svhn_loss: 0.0098, d_fake_loss: 0.0187, g_loss: 1.3242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [49000/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0137, d_svhn_loss: 0.0478, d_fake_loss: 0.0414, g_loss: 1.2880\n",
            "saved ./samples_mnist_svhn/sample-49000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-49000-s-m.png\n",
            "Step [49010/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0058, d_svhn_loss: 0.0329, d_fake_loss: 0.0363, g_loss: 1.1798\n",
            "Step [49020/80000], d_real_loss: 0.0799, d_mnist_loss: 0.0049, d_svhn_loss: 0.0751, d_fake_loss: 0.1606, g_loss: 1.1871\n",
            "Step [49030/80000], d_real_loss: 0.1950, d_mnist_loss: 0.0072, d_svhn_loss: 0.1878, d_fake_loss: 0.0524, g_loss: 1.0749\n",
            "Step [49040/80000], d_real_loss: 0.1258, d_mnist_loss: 0.0130, d_svhn_loss: 0.1127, d_fake_loss: 0.0686, g_loss: 1.0886\n",
            "Step [49050/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0099, d_svhn_loss: 0.0617, d_fake_loss: 0.0130, g_loss: 1.1559\n",
            "Step [49060/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0073, d_svhn_loss: 0.0146, d_fake_loss: 0.0256, g_loss: 1.1367\n",
            "Step [49070/80000], d_real_loss: 0.1226, d_mnist_loss: 0.0071, d_svhn_loss: 0.1155, d_fake_loss: 0.1467, g_loss: 1.1985\n",
            "Step [49080/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0080, d_svhn_loss: 0.0205, d_fake_loss: 0.0411, g_loss: 1.2523\n",
            "Step [49090/80000], d_real_loss: 0.1738, d_mnist_loss: 0.0106, d_svhn_loss: 0.1632, d_fake_loss: 0.0180, g_loss: 1.1227\n",
            "Step [49100/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0069, d_svhn_loss: 0.0555, d_fake_loss: 0.0333, g_loss: 1.1067\n",
            "Step [49110/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0060, d_svhn_loss: 0.0208, d_fake_loss: 0.0303, g_loss: 1.3396\n",
            "Step [49120/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0110, d_svhn_loss: 0.0484, d_fake_loss: 0.0522, g_loss: 1.1866\n",
            "Step [49130/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0042, d_svhn_loss: 0.0388, d_fake_loss: 0.0347, g_loss: 1.2641\n",
            "Step [49140/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0037, d_svhn_loss: 0.0261, d_fake_loss: 0.0537, g_loss: 1.1546\n",
            "Step [49150/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0049, d_svhn_loss: 0.0640, d_fake_loss: 0.0205, g_loss: 1.3094\n",
            "Step [49160/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0062, d_svhn_loss: 0.0397, d_fake_loss: 0.0131, g_loss: 1.1165\n",
            "Step [49170/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0067, d_svhn_loss: 0.0236, d_fake_loss: 0.0279, g_loss: 1.0995\n",
            "Step [49180/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0069, d_svhn_loss: 0.0338, d_fake_loss: 0.0706, g_loss: 1.1246\n",
            "Step [49190/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0043, d_svhn_loss: 0.0474, d_fake_loss: 0.0807, g_loss: 1.1076\n",
            "Step [49200/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0050, d_svhn_loss: 0.0195, d_fake_loss: 0.0381, g_loss: 1.0558\n",
            "Step [49210/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0063, d_svhn_loss: 0.0335, d_fake_loss: 0.0591, g_loss: 1.0346\n",
            "Step [49220/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0077, d_svhn_loss: 0.0151, d_fake_loss: 0.0766, g_loss: 1.0717\n",
            "Step [49230/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0075, d_svhn_loss: 0.0232, d_fake_loss: 0.0335, g_loss: 1.1391\n",
            "Step [49240/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0033, d_svhn_loss: 0.0649, d_fake_loss: 0.0974, g_loss: 1.3220\n",
            "Step [49250/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0059, d_svhn_loss: 0.0679, d_fake_loss: 0.0545, g_loss: 1.1425\n",
            "Step [49260/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0057, d_svhn_loss: 0.0662, d_fake_loss: 0.1032, g_loss: 1.1676\n",
            "Step [49270/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0052, d_svhn_loss: 0.0495, d_fake_loss: 0.0892, g_loss: 0.9949\n",
            "Step [49280/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0098, d_svhn_loss: 0.0323, d_fake_loss: 0.0417, g_loss: 1.2098\n",
            "Step [49290/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0048, d_svhn_loss: 0.0319, d_fake_loss: 0.0214, g_loss: 1.1577\n",
            "Step [49300/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0089, d_svhn_loss: 0.0721, d_fake_loss: 0.0386, g_loss: 1.1999\n",
            "Step [49310/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0084, d_svhn_loss: 0.0171, d_fake_loss: 0.0349, g_loss: 1.2098\n",
            "Step [49320/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0050, d_svhn_loss: 0.0723, d_fake_loss: 0.0419, g_loss: 1.2814\n",
            "Step [49330/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0038, d_svhn_loss: 0.0215, d_fake_loss: 0.0503, g_loss: 1.1470\n",
            "Step [49340/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0058, d_svhn_loss: 0.0835, d_fake_loss: 0.0521, g_loss: 1.3369\n",
            "Step [49350/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0053, d_svhn_loss: 0.0368, d_fake_loss: 0.0547, g_loss: 1.1019\n",
            "Step [49360/80000], d_real_loss: 0.0951, d_mnist_loss: 0.0088, d_svhn_loss: 0.0862, d_fake_loss: 0.0845, g_loss: 1.1514\n",
            "Step [49370/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0104, d_svhn_loss: 0.0345, d_fake_loss: 0.0310, g_loss: 1.1783\n",
            "Step [49380/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0048, d_svhn_loss: 0.0244, d_fake_loss: 0.0516, g_loss: 1.2087\n",
            "Step [49390/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0055, d_svhn_loss: 0.0425, d_fake_loss: 0.0664, g_loss: 1.1263\n",
            "Step [49400/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0067, d_svhn_loss: 0.0261, d_fake_loss: 0.0292, g_loss: 1.1588\n",
            "Step [49410/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0105, d_svhn_loss: 0.0193, d_fake_loss: 0.0300, g_loss: 1.0026\n",
            "Step [49420/80000], d_real_loss: 0.0224, d_mnist_loss: 0.0073, d_svhn_loss: 0.0152, d_fake_loss: 0.0264, g_loss: 1.1873\n",
            "Step [49430/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0089, d_svhn_loss: 0.0192, d_fake_loss: 0.0490, g_loss: 1.3242\n",
            "Step [49440/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0089, d_svhn_loss: 0.0390, d_fake_loss: 0.0509, g_loss: 1.2281\n",
            "Step [49450/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0111, d_svhn_loss: 0.0193, d_fake_loss: 0.0830, g_loss: 0.9196\n",
            "Step [49460/80000], d_real_loss: 0.0857, d_mnist_loss: 0.0103, d_svhn_loss: 0.0754, d_fake_loss: 0.0684, g_loss: 1.2469\n",
            "Step [49470/80000], d_real_loss: 0.1385, d_mnist_loss: 0.0090, d_svhn_loss: 0.1295, d_fake_loss: 0.0999, g_loss: 1.3566\n",
            "Step [49480/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0142, d_svhn_loss: 0.0238, d_fake_loss: 0.0336, g_loss: 1.2613\n",
            "Step [49490/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0067, d_svhn_loss: 0.0240, d_fake_loss: 0.0473, g_loss: 1.2226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [49500/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0143, d_svhn_loss: 0.0341, d_fake_loss: 0.0261, g_loss: 1.1640\n",
            "saved ./samples_mnist_svhn/sample-49500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-49500-s-m.png\n",
            "Step [49510/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0054, d_svhn_loss: 0.0245, d_fake_loss: 0.0653, g_loss: 1.4757\n",
            "Step [49520/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0098, d_svhn_loss: 0.0280, d_fake_loss: 0.0219, g_loss: 1.1763\n",
            "Step [49530/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0055, d_svhn_loss: 0.0322, d_fake_loss: 0.0820, g_loss: 1.1722\n",
            "Step [49540/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0076, d_svhn_loss: 0.0226, d_fake_loss: 0.0233, g_loss: 1.3457\n",
            "Step [49550/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0057, d_svhn_loss: 0.0462, d_fake_loss: 0.0559, g_loss: 1.2475\n",
            "Step [49560/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0524, d_svhn_loss: 0.0238, d_fake_loss: 0.0381, g_loss: 0.9813\n",
            "Step [49570/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0087, d_svhn_loss: 0.0287, d_fake_loss: 0.1351, g_loss: 0.9974\n",
            "Step [49580/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0068, d_svhn_loss: 0.0194, d_fake_loss: 0.0177, g_loss: 1.1392\n",
            "Step [49590/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0059, d_svhn_loss: 0.0220, d_fake_loss: 0.0290, g_loss: 1.2752\n",
            "Step [49600/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0102, d_svhn_loss: 0.0611, d_fake_loss: 0.0283, g_loss: 1.1231\n",
            "Step [49610/80000], d_real_loss: 0.1407, d_mnist_loss: 0.0069, d_svhn_loss: 0.1338, d_fake_loss: 0.0313, g_loss: 1.2455\n",
            "Step [49620/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0142, d_svhn_loss: 0.0398, d_fake_loss: 0.0339, g_loss: 1.2169\n",
            "Step [49630/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0051, d_svhn_loss: 0.0279, d_fake_loss: 0.0327, g_loss: 1.2881\n",
            "Step [49640/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0034, d_svhn_loss: 0.0224, d_fake_loss: 0.0275, g_loss: 1.1370\n",
            "Step [49650/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0113, d_svhn_loss: 0.0199, d_fake_loss: 0.1993, g_loss: 1.1026\n",
            "Step [49660/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0042, d_svhn_loss: 0.0191, d_fake_loss: 0.0518, g_loss: 1.2139\n",
            "Step [49670/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0048, d_svhn_loss: 0.0603, d_fake_loss: 0.0197, g_loss: 1.1277\n",
            "Step [49680/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0054, d_svhn_loss: 0.0232, d_fake_loss: 0.0439, g_loss: 1.2799\n",
            "Step [49690/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0060, d_svhn_loss: 0.0759, d_fake_loss: 0.0415, g_loss: 1.1917\n",
            "Step [49700/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0093, d_svhn_loss: 0.0557, d_fake_loss: 0.0677, g_loss: 1.2910\n",
            "Step [49710/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0050, d_svhn_loss: 0.0262, d_fake_loss: 0.0331, g_loss: 1.2042\n",
            "Step [49720/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0046, d_svhn_loss: 0.0586, d_fake_loss: 0.0331, g_loss: 1.1289\n",
            "Step [49730/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0041, d_svhn_loss: 0.0458, d_fake_loss: 0.0124, g_loss: 1.0882\n",
            "Step [49740/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0075, d_svhn_loss: 0.0201, d_fake_loss: 0.0632, g_loss: 1.1292\n",
            "Step [49750/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0043, d_svhn_loss: 0.0198, d_fake_loss: 0.0554, g_loss: 1.2211\n",
            "Step [49760/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0068, d_svhn_loss: 0.0150, d_fake_loss: 0.0269, g_loss: 1.1366\n",
            "Step [49770/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0044, d_svhn_loss: 0.0188, d_fake_loss: 0.0234, g_loss: 1.0949\n",
            "Step [49780/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0070, d_svhn_loss: 0.0541, d_fake_loss: 0.0424, g_loss: 1.1423\n",
            "Step [49790/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0050, d_svhn_loss: 0.0580, d_fake_loss: 0.0439, g_loss: 1.1507\n",
            "Step [49800/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0047, d_svhn_loss: 0.0630, d_fake_loss: 0.0315, g_loss: 1.1190\n",
            "Step [49810/80000], d_real_loss: 0.1153, d_mnist_loss: 0.0049, d_svhn_loss: 0.1105, d_fake_loss: 0.0992, g_loss: 1.1734\n",
            "Step [49820/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0037, d_svhn_loss: 0.0519, d_fake_loss: 0.1035, g_loss: 1.3967\n",
            "Step [49830/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0192, d_svhn_loss: 0.0404, d_fake_loss: 0.0870, g_loss: 1.1206\n",
            "Step [49840/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0052, d_svhn_loss: 0.0212, d_fake_loss: 0.0222, g_loss: 1.1792\n",
            "Step [49850/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0054, d_svhn_loss: 0.0380, d_fake_loss: 0.0332, g_loss: 1.1377\n",
            "Step [49860/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0047, d_svhn_loss: 0.0215, d_fake_loss: 0.0159, g_loss: 1.1861\n",
            "Step [49870/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0037, d_svhn_loss: 0.0531, d_fake_loss: 0.0816, g_loss: 1.1699\n",
            "Step [49880/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0029, d_svhn_loss: 0.0207, d_fake_loss: 0.0228, g_loss: 1.3855\n",
            "Step [49890/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0030, d_svhn_loss: 0.0550, d_fake_loss: 0.0346, g_loss: 1.1369\n",
            "Step [49900/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0033, d_svhn_loss: 0.0340, d_fake_loss: 0.0517, g_loss: 1.1816\n",
            "Step [49910/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0029, d_svhn_loss: 0.0243, d_fake_loss: 0.0265, g_loss: 1.1860\n",
            "Step [49920/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0057, d_svhn_loss: 0.0285, d_fake_loss: 0.0241, g_loss: 1.1711\n",
            "Step [49930/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0308, d_svhn_loss: 0.0421, d_fake_loss: 0.0652, g_loss: 1.0544\n",
            "Step [49940/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0072, d_svhn_loss: 0.0175, d_fake_loss: 0.0211, g_loss: 1.4092\n",
            "Step [49950/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0053, d_svhn_loss: 0.0433, d_fake_loss: 0.0384, g_loss: 1.3374\n",
            "Step [49960/80000], d_real_loss: 0.0964, d_mnist_loss: 0.0048, d_svhn_loss: 0.0916, d_fake_loss: 0.0596, g_loss: 1.1751\n",
            "Step [49970/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0066, d_svhn_loss: 0.0229, d_fake_loss: 0.0304, g_loss: 1.3350\n",
            "Step [49980/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0114, d_svhn_loss: 0.0564, d_fake_loss: 0.0338, g_loss: 1.1692\n",
            "Step [49990/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0043, d_svhn_loss: 0.0326, d_fake_loss: 0.0233, g_loss: 1.1407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [50000/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0048, d_svhn_loss: 0.0301, d_fake_loss: 0.1969, g_loss: 1.0888\n",
            "saved ./samples_mnist_svhn/sample-50000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-50000-s-m.png\n",
            "Step [50010/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0042, d_svhn_loss: 0.0270, d_fake_loss: 0.0893, g_loss: 1.2909\n",
            "Step [50020/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0047, d_svhn_loss: 0.0541, d_fake_loss: 0.0439, g_loss: 1.2854\n",
            "Step [50030/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0071, d_svhn_loss: 0.0559, d_fake_loss: 0.0740, g_loss: 1.2246\n",
            "Step [50040/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0056, d_svhn_loss: 0.0209, d_fake_loss: 0.0159, g_loss: 1.2096\n",
            "Step [50050/80000], d_real_loss: 0.1038, d_mnist_loss: 0.0050, d_svhn_loss: 0.0989, d_fake_loss: 0.0226, g_loss: 1.1717\n",
            "Step [50060/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0069, d_svhn_loss: 0.0158, d_fake_loss: 0.0490, g_loss: 1.2057\n",
            "Step [50070/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0090, d_svhn_loss: 0.0277, d_fake_loss: 0.0491, g_loss: 0.9512\n",
            "Step [50080/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0082, d_svhn_loss: 0.0354, d_fake_loss: 0.0198, g_loss: 1.1201\n",
            "Step [50090/80000], d_real_loss: 0.0827, d_mnist_loss: 0.0048, d_svhn_loss: 0.0779, d_fake_loss: 0.1164, g_loss: 1.0010\n",
            "Step [50100/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0068, d_svhn_loss: 0.0198, d_fake_loss: 0.0263, g_loss: 1.1536\n",
            "Step [50110/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0063, d_svhn_loss: 0.0749, d_fake_loss: 0.0366, g_loss: 1.2789\n",
            "Step [50120/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0131, d_svhn_loss: 0.0440, d_fake_loss: 0.0866, g_loss: 1.0721\n",
            "Step [50130/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0122, d_svhn_loss: 0.0420, d_fake_loss: 0.0204, g_loss: 1.2454\n",
            "Step [50140/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0058, d_svhn_loss: 0.0321, d_fake_loss: 0.0874, g_loss: 1.5758\n",
            "Step [50150/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0058, d_svhn_loss: 0.0248, d_fake_loss: 0.0463, g_loss: 1.1425\n",
            "Step [50160/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0084, d_svhn_loss: 0.0832, d_fake_loss: 0.0262, g_loss: 1.1927\n",
            "Step [50170/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0060, d_svhn_loss: 0.0535, d_fake_loss: 0.0769, g_loss: 1.1475\n",
            "Step [50180/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0102, d_svhn_loss: 0.0338, d_fake_loss: 0.0757, g_loss: 1.1342\n",
            "Step [50190/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0074, d_svhn_loss: 0.0342, d_fake_loss: 0.0199, g_loss: 1.1526\n",
            "Step [50200/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0280, d_svhn_loss: 0.0290, d_fake_loss: 0.1098, g_loss: 1.0778\n",
            "Step [50210/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0185, d_svhn_loss: 0.0471, d_fake_loss: 0.0465, g_loss: 1.1179\n",
            "Step [50220/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0062, d_svhn_loss: 0.0441, d_fake_loss: 0.0152, g_loss: 1.1760\n",
            "Step [50230/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0114, d_svhn_loss: 0.0253, d_fake_loss: 0.0288, g_loss: 1.2643\n",
            "Step [50240/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0131, d_svhn_loss: 0.0406, d_fake_loss: 0.0380, g_loss: 1.1666\n",
            "Step [50250/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0114, d_svhn_loss: 0.0802, d_fake_loss: 0.0480, g_loss: 1.1997\n",
            "Step [50260/80000], d_real_loss: 0.0903, d_mnist_loss: 0.0082, d_svhn_loss: 0.0821, d_fake_loss: 0.0807, g_loss: 1.1186\n",
            "Step [50270/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0058, d_svhn_loss: 0.0443, d_fake_loss: 0.0429, g_loss: 1.2837\n",
            "Step [50280/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0086, d_svhn_loss: 0.0455, d_fake_loss: 0.0144, g_loss: 1.1497\n",
            "Step [50290/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0119, d_svhn_loss: 0.0468, d_fake_loss: 0.0382, g_loss: 1.1705\n",
            "Step [50300/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0050, d_svhn_loss: 0.0385, d_fake_loss: 0.0272, g_loss: 1.3023\n",
            "Step [50310/80000], d_real_loss: 0.0735, d_mnist_loss: 0.0086, d_svhn_loss: 0.0649, d_fake_loss: 0.0302, g_loss: 1.1676\n",
            "Step [50320/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0105, d_svhn_loss: 0.0435, d_fake_loss: 0.0484, g_loss: 1.2594\n",
            "Step [50330/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0053, d_svhn_loss: 0.0255, d_fake_loss: 0.0261, g_loss: 1.3226\n",
            "Step [50340/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0140, d_svhn_loss: 0.0214, d_fake_loss: 0.0144, g_loss: 1.1430\n",
            "Step [50350/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0063, d_svhn_loss: 0.0458, d_fake_loss: 0.0332, g_loss: 1.1599\n",
            "Step [50360/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0170, d_svhn_loss: 0.0311, d_fake_loss: 0.0266, g_loss: 1.2065\n",
            "Step [50370/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0066, d_svhn_loss: 0.0336, d_fake_loss: 0.0620, g_loss: 1.1977\n",
            "Step [50380/80000], d_real_loss: 0.1222, d_mnist_loss: 0.0062, d_svhn_loss: 0.1160, d_fake_loss: 0.0464, g_loss: 1.2846\n",
            "Step [50390/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0165, d_svhn_loss: 0.0219, d_fake_loss: 0.0550, g_loss: 1.1097\n",
            "Step [50400/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0062, d_svhn_loss: 0.0317, d_fake_loss: 0.0909, g_loss: 1.1652\n",
            "Step [50410/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0109, d_svhn_loss: 0.0335, d_fake_loss: 0.0666, g_loss: 1.2200\n",
            "Step [50420/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0047, d_svhn_loss: 0.0370, d_fake_loss: 0.0316, g_loss: 1.4221\n",
            "Step [50430/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0050, d_svhn_loss: 0.0289, d_fake_loss: 0.0250, g_loss: 1.4656\n",
            "Step [50440/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0065, d_svhn_loss: 0.0501, d_fake_loss: 0.0800, g_loss: 1.3318\n",
            "Step [50450/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0051, d_svhn_loss: 0.0216, d_fake_loss: 0.0267, g_loss: 1.2868\n",
            "Step [50460/80000], d_real_loss: 0.0803, d_mnist_loss: 0.0102, d_svhn_loss: 0.0701, d_fake_loss: 0.0732, g_loss: 1.2145\n",
            "Step [50470/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0086, d_svhn_loss: 0.0202, d_fake_loss: 0.0431, g_loss: 1.1515\n",
            "Step [50480/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0086, d_svhn_loss: 0.0289, d_fake_loss: 0.0544, g_loss: 1.3655\n",
            "Step [50490/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0033, d_svhn_loss: 0.0170, d_fake_loss: 0.0379, g_loss: 1.0218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [50500/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0075, d_svhn_loss: 0.0266, d_fake_loss: 0.0312, g_loss: 1.1650\n",
            "saved ./samples_mnist_svhn/sample-50500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-50500-s-m.png\n",
            "Step [50510/80000], d_real_loss: 0.1037, d_mnist_loss: 0.0079, d_svhn_loss: 0.0958, d_fake_loss: 0.0761, g_loss: 1.1607\n",
            "Step [50520/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0056, d_svhn_loss: 0.0249, d_fake_loss: 0.0403, g_loss: 1.2616\n",
            "Step [50530/80000], d_real_loss: 0.1306, d_mnist_loss: 0.0096, d_svhn_loss: 0.1209, d_fake_loss: 0.1092, g_loss: 1.2808\n",
            "Step [50540/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0144, d_svhn_loss: 0.0374, d_fake_loss: 0.0515, g_loss: 1.1501\n",
            "Step [50550/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0055, d_svhn_loss: 0.0287, d_fake_loss: 0.0906, g_loss: 1.2799\n",
            "Step [50560/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0059, d_svhn_loss: 0.0341, d_fake_loss: 0.0391, g_loss: 1.2102\n",
            "Step [50570/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0077, d_svhn_loss: 0.0507, d_fake_loss: 0.0400, g_loss: 1.1490\n",
            "Step [50580/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0054, d_svhn_loss: 0.0221, d_fake_loss: 0.0178, g_loss: 1.5124\n",
            "Step [50590/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0147, d_svhn_loss: 0.0545, d_fake_loss: 0.0169, g_loss: 1.2027\n",
            "Step [50600/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0057, d_svhn_loss: 0.0295, d_fake_loss: 0.0520, g_loss: 1.2610\n",
            "Step [50610/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0044, d_svhn_loss: 0.0533, d_fake_loss: 0.1610, g_loss: 0.9841\n",
            "Step [50620/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0059, d_svhn_loss: 0.0217, d_fake_loss: 0.0953, g_loss: 1.1594\n",
            "Step [50630/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0048, d_svhn_loss: 0.0214, d_fake_loss: 0.0297, g_loss: 1.1661\n",
            "Step [50640/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0050, d_svhn_loss: 0.0263, d_fake_loss: 0.0375, g_loss: 1.2713\n",
            "Step [50650/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0221, d_svhn_loss: 0.0176, d_fake_loss: 0.0589, g_loss: 1.1605\n",
            "Step [50660/80000], d_real_loss: 0.1017, d_mnist_loss: 0.0169, d_svhn_loss: 0.0848, d_fake_loss: 0.0542, g_loss: 0.9726\n",
            "Step [50670/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0095, d_svhn_loss: 0.0285, d_fake_loss: 0.0373, g_loss: 1.2976\n",
            "Step [50680/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0059, d_svhn_loss: 0.0208, d_fake_loss: 0.0762, g_loss: 1.3516\n",
            "Step [50690/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0070, d_svhn_loss: 0.0502, d_fake_loss: 0.0142, g_loss: 1.2728\n",
            "Step [50700/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0053, d_svhn_loss: 0.0848, d_fake_loss: 0.0968, g_loss: 1.1501\n",
            "Step [50710/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0058, d_svhn_loss: 0.0386, d_fake_loss: 0.0180, g_loss: 1.2093\n",
            "Step [50720/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0077, d_svhn_loss: 0.0164, d_fake_loss: 0.0382, g_loss: 1.2480\n",
            "Step [50730/80000], d_real_loss: 0.1605, d_mnist_loss: 0.0048, d_svhn_loss: 0.1557, d_fake_loss: 0.0519, g_loss: 1.2803\n",
            "Step [50740/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0044, d_svhn_loss: 0.0496, d_fake_loss: 0.0220, g_loss: 1.2296\n",
            "Step [50750/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0074, d_svhn_loss: 0.0238, d_fake_loss: 0.0233, g_loss: 1.2322\n",
            "Step [50760/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0187, d_svhn_loss: 0.0328, d_fake_loss: 0.0853, g_loss: 1.1098\n",
            "Step [50770/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0117, d_svhn_loss: 0.0192, d_fake_loss: 0.0479, g_loss: 1.1200\n",
            "Step [50780/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0086, d_svhn_loss: 0.0245, d_fake_loss: 0.0648, g_loss: 1.2019\n",
            "Step [50790/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0067, d_svhn_loss: 0.0327, d_fake_loss: 0.0145, g_loss: 1.1406\n",
            "Step [50800/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0155, d_svhn_loss: 0.0458, d_fake_loss: 0.1884, g_loss: 1.1853\n",
            "Step [50810/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0520, d_svhn_loss: 0.0223, d_fake_loss: 0.0172, g_loss: 1.1065\n",
            "Step [50820/80000], d_real_loss: 0.1593, d_mnist_loss: 0.0156, d_svhn_loss: 0.1437, d_fake_loss: 0.0596, g_loss: 1.0574\n",
            "Step [50830/80000], d_real_loss: 0.1322, d_mnist_loss: 0.0056, d_svhn_loss: 0.1266, d_fake_loss: 0.0440, g_loss: 1.1644\n",
            "Step [50840/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0058, d_svhn_loss: 0.0199, d_fake_loss: 0.0163, g_loss: 1.1578\n",
            "Step [50850/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0130, d_svhn_loss: 0.0622, d_fake_loss: 0.0651, g_loss: 1.1880\n",
            "Step [50860/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0103, d_svhn_loss: 0.0711, d_fake_loss: 0.0540, g_loss: 1.1218\n",
            "Step [50870/80000], d_real_loss: 0.0908, d_mnist_loss: 0.0041, d_svhn_loss: 0.0867, d_fake_loss: 0.0463, g_loss: 1.2214\n",
            "Step [50880/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0065, d_svhn_loss: 0.0266, d_fake_loss: 0.1071, g_loss: 1.0267\n",
            "Step [50890/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0063, d_svhn_loss: 0.0225, d_fake_loss: 0.0358, g_loss: 1.4199\n",
            "Step [50900/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0047, d_svhn_loss: 0.0371, d_fake_loss: 0.0328, g_loss: 1.1809\n",
            "Step [50910/80000], d_real_loss: 0.0682, d_mnist_loss: 0.0041, d_svhn_loss: 0.0641, d_fake_loss: 0.0438, g_loss: 1.2184\n",
            "Step [50920/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0052, d_svhn_loss: 0.0353, d_fake_loss: 0.0354, g_loss: 1.2392\n",
            "Step [50930/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0090, d_svhn_loss: 0.0322, d_fake_loss: 0.0326, g_loss: 1.2972\n",
            "Step [50940/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0060, d_svhn_loss: 0.0276, d_fake_loss: 0.0255, g_loss: 1.1596\n",
            "Step [50950/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0054, d_svhn_loss: 0.0362, d_fake_loss: 0.0325, g_loss: 1.1739\n",
            "Step [50960/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0043, d_svhn_loss: 0.0462, d_fake_loss: 0.0224, g_loss: 1.2837\n",
            "Step [50970/80000], d_real_loss: 0.1466, d_mnist_loss: 0.0068, d_svhn_loss: 0.1398, d_fake_loss: 0.0503, g_loss: 1.1530\n",
            "Step [50980/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0140, d_svhn_loss: 0.0206, d_fake_loss: 0.0359, g_loss: 1.1533\n",
            "Step [50990/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0086, d_svhn_loss: 0.0375, d_fake_loss: 0.0182, g_loss: 1.1088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [51000/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0064, d_svhn_loss: 0.0289, d_fake_loss: 0.0178, g_loss: 1.2522\n",
            "saved ./samples_mnist_svhn/sample-51000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-51000-s-m.png\n",
            "Step [51010/80000], d_real_loss: 0.1010, d_mnist_loss: 0.0088, d_svhn_loss: 0.0921, d_fake_loss: 0.0219, g_loss: 1.1218\n",
            "Step [51020/80000], d_real_loss: 0.2064, d_mnist_loss: 0.0066, d_svhn_loss: 0.1998, d_fake_loss: 0.0491, g_loss: 1.2069\n",
            "Step [51030/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0059, d_svhn_loss: 0.0207, d_fake_loss: 0.0753, g_loss: 1.1833\n",
            "Step [51040/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0063, d_svhn_loss: 0.0221, d_fake_loss: 0.0708, g_loss: 1.2106\n",
            "Step [51050/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0100, d_svhn_loss: 0.0277, d_fake_loss: 0.0393, g_loss: 1.2177\n",
            "Step [51060/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0072, d_svhn_loss: 0.0393, d_fake_loss: 0.0234, g_loss: 1.2426\n",
            "Step [51070/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0203, d_svhn_loss: 0.0334, d_fake_loss: 0.0306, g_loss: 1.1886\n",
            "Step [51080/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0042, d_svhn_loss: 0.0529, d_fake_loss: 0.0812, g_loss: 1.1698\n",
            "Step [51090/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0125, d_svhn_loss: 0.0166, d_fake_loss: 0.0309, g_loss: 1.1567\n",
            "Step [51100/80000], d_real_loss: 0.1178, d_mnist_loss: 0.0088, d_svhn_loss: 0.1090, d_fake_loss: 0.0628, g_loss: 1.1621\n",
            "Step [51110/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0176, d_svhn_loss: 0.0353, d_fake_loss: 0.0764, g_loss: 0.9645\n",
            "Step [51120/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0103, d_svhn_loss: 0.0131, d_fake_loss: 0.0187, g_loss: 1.1568\n",
            "Step [51130/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0101, d_svhn_loss: 0.0207, d_fake_loss: 0.0514, g_loss: 1.3277\n",
            "Step [51140/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0054, d_svhn_loss: 0.0226, d_fake_loss: 0.0238, g_loss: 1.2538\n",
            "Step [51150/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0052, d_svhn_loss: 0.0274, d_fake_loss: 0.0242, g_loss: 1.1803\n",
            "Step [51160/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0038, d_svhn_loss: 0.0715, d_fake_loss: 0.0301, g_loss: 1.2499\n",
            "Step [51170/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0040, d_svhn_loss: 0.0272, d_fake_loss: 0.0368, g_loss: 1.3682\n",
            "Step [51180/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0048, d_svhn_loss: 0.0286, d_fake_loss: 0.0885, g_loss: 1.2125\n",
            "Step [51190/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0188, d_svhn_loss: 0.0296, d_fake_loss: 0.0999, g_loss: 1.1102\n",
            "Step [51200/80000], d_real_loss: 0.0712, d_mnist_loss: 0.0035, d_svhn_loss: 0.0677, d_fake_loss: 0.0612, g_loss: 1.3564\n",
            "Step [51210/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0038, d_svhn_loss: 0.0777, d_fake_loss: 0.0239, g_loss: 1.1583\n",
            "Step [51220/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0073, d_svhn_loss: 0.0387, d_fake_loss: 0.0470, g_loss: 1.0710\n",
            "Step [51230/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0058, d_svhn_loss: 0.0516, d_fake_loss: 0.0410, g_loss: 1.2464\n",
            "Step [51240/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0064, d_svhn_loss: 0.0320, d_fake_loss: 0.0667, g_loss: 1.1465\n",
            "Step [51250/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0034, d_svhn_loss: 0.0414, d_fake_loss: 0.0282, g_loss: 1.2379\n",
            "Step [51260/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0047, d_svhn_loss: 0.0523, d_fake_loss: 0.0799, g_loss: 1.1021\n",
            "Step [51270/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0072, d_svhn_loss: 0.0417, d_fake_loss: 0.0310, g_loss: 1.0819\n",
            "Step [51280/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0032, d_svhn_loss: 0.0215, d_fake_loss: 0.0247, g_loss: 1.1143\n",
            "Step [51290/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0115, d_svhn_loss: 0.0237, d_fake_loss: 0.0336, g_loss: 1.1536\n",
            "Step [51300/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0060, d_svhn_loss: 0.0545, d_fake_loss: 0.0267, g_loss: 1.2567\n",
            "Step [51310/80000], d_real_loss: 0.1002, d_mnist_loss: 0.0028, d_svhn_loss: 0.0974, d_fake_loss: 0.1899, g_loss: 1.0668\n",
            "Step [51320/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0052, d_svhn_loss: 0.0508, d_fake_loss: 0.0258, g_loss: 1.1756\n",
            "Step [51330/80000], d_real_loss: 0.1408, d_mnist_loss: 0.0047, d_svhn_loss: 0.1361, d_fake_loss: 0.0344, g_loss: 1.1836\n",
            "Step [51340/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0060, d_svhn_loss: 0.0649, d_fake_loss: 0.0771, g_loss: 1.2936\n",
            "Step [51350/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0065, d_svhn_loss: 0.0429, d_fake_loss: 0.0662, g_loss: 1.3183\n",
            "Step [51360/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0032, d_svhn_loss: 0.0334, d_fake_loss: 0.0391, g_loss: 1.0900\n",
            "Step [51370/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0053, d_svhn_loss: 0.0239, d_fake_loss: 0.0829, g_loss: 1.1821\n",
            "Step [51380/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0058, d_svhn_loss: 0.0266, d_fake_loss: 0.0377, g_loss: 1.1879\n",
            "Step [51390/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0041, d_svhn_loss: 0.0140, d_fake_loss: 0.0518, g_loss: 1.2030\n",
            "Step [51400/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0105, d_svhn_loss: 0.0358, d_fake_loss: 0.0264, g_loss: 1.1001\n",
            "Step [51410/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0035, d_svhn_loss: 0.0164, d_fake_loss: 0.0248, g_loss: 1.2127\n",
            "Step [51420/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0075, d_svhn_loss: 0.0370, d_fake_loss: 0.0391, g_loss: 1.1377\n",
            "Step [51430/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0028, d_svhn_loss: 0.0299, d_fake_loss: 0.0238, g_loss: 1.3235\n",
            "Step [51440/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0044, d_svhn_loss: 0.0534, d_fake_loss: 0.0397, g_loss: 1.1818\n",
            "Step [51450/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0052, d_svhn_loss: 0.0511, d_fake_loss: 0.0298, g_loss: 1.1024\n",
            "Step [51460/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0082, d_svhn_loss: 0.0300, d_fake_loss: 0.0305, g_loss: 1.1084\n",
            "Step [51470/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0055, d_svhn_loss: 0.0282, d_fake_loss: 0.0339, g_loss: 1.2108\n",
            "Step [51480/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0036, d_svhn_loss: 0.0195, d_fake_loss: 0.0213, g_loss: 1.1442\n",
            "Step [51490/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0040, d_svhn_loss: 0.0314, d_fake_loss: 0.0256, g_loss: 1.1469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [51500/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0035, d_svhn_loss: 0.0370, d_fake_loss: 0.0521, g_loss: 1.2207\n",
            "saved ./samples_mnist_svhn/sample-51500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-51500-s-m.png\n",
            "Step [51510/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0048, d_svhn_loss: 0.0244, d_fake_loss: 0.0384, g_loss: 1.1345\n",
            "Step [51520/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0058, d_svhn_loss: 0.0241, d_fake_loss: 0.0255, g_loss: 1.1533\n",
            "Step [51530/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0082, d_svhn_loss: 0.0187, d_fake_loss: 0.0241, g_loss: 1.1944\n",
            "Step [51540/80000], d_real_loss: 0.1223, d_mnist_loss: 0.0087, d_svhn_loss: 0.1136, d_fake_loss: 0.0771, g_loss: 1.2579\n",
            "Step [51550/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0038, d_svhn_loss: 0.0358, d_fake_loss: 0.0551, g_loss: 1.3724\n",
            "Step [51560/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0055, d_svhn_loss: 0.0311, d_fake_loss: 0.0226, g_loss: 1.3390\n",
            "Step [51570/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0086, d_svhn_loss: 0.0330, d_fake_loss: 0.0396, g_loss: 1.2525\n",
            "Step [51580/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0043, d_svhn_loss: 0.0206, d_fake_loss: 0.0210, g_loss: 1.3092\n",
            "Step [51590/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0208, d_svhn_loss: 0.0269, d_fake_loss: 0.0867, g_loss: 1.0703\n",
            "Step [51600/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0099, d_svhn_loss: 0.0417, d_fake_loss: 0.0200, g_loss: 1.2681\n",
            "Step [51610/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0039, d_svhn_loss: 0.0482, d_fake_loss: 0.0508, g_loss: 1.2708\n",
            "Step [51620/80000], d_real_loss: 0.1023, d_mnist_loss: 0.0062, d_svhn_loss: 0.0961, d_fake_loss: 0.0269, g_loss: 1.3778\n",
            "Step [51630/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0169, d_svhn_loss: 0.0520, d_fake_loss: 0.0542, g_loss: 1.1232\n",
            "Step [51640/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0061, d_svhn_loss: 0.0523, d_fake_loss: 0.0801, g_loss: 1.7693\n",
            "Step [51650/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0113, d_svhn_loss: 0.0672, d_fake_loss: 0.0441, g_loss: 1.0216\n",
            "Step [51660/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0087, d_svhn_loss: 0.0203, d_fake_loss: 0.0968, g_loss: 1.2201\n",
            "Step [51670/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0062, d_svhn_loss: 0.0480, d_fake_loss: 0.0347, g_loss: 1.2267\n",
            "Step [51680/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0048, d_svhn_loss: 0.0343, d_fake_loss: 0.0473, g_loss: 1.1316\n",
            "Step [51690/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0119, d_svhn_loss: 0.0368, d_fake_loss: 0.0375, g_loss: 1.1392\n",
            "Step [51700/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0046, d_svhn_loss: 0.0486, d_fake_loss: 0.0244, g_loss: 1.2655\n",
            "Step [51710/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0099, d_svhn_loss: 0.0368, d_fake_loss: 0.0901, g_loss: 1.2564\n",
            "Step [51720/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0046, d_svhn_loss: 0.0473, d_fake_loss: 0.0212, g_loss: 1.2371\n",
            "Step [51730/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0039, d_svhn_loss: 0.0314, d_fake_loss: 0.0237, g_loss: 1.2548\n",
            "Step [51740/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0077, d_svhn_loss: 0.0273, d_fake_loss: 0.0831, g_loss: 1.2067\n",
            "Step [51750/80000], d_real_loss: 0.0654, d_mnist_loss: 0.0041, d_svhn_loss: 0.0614, d_fake_loss: 0.0340, g_loss: 1.2006\n",
            "Step [51760/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0115, d_svhn_loss: 0.0604, d_fake_loss: 0.0699, g_loss: 1.0573\n",
            "Step [51770/80000], d_real_loss: 0.1280, d_mnist_loss: 0.0072, d_svhn_loss: 0.1208, d_fake_loss: 0.0888, g_loss: 1.1787\n",
            "Step [51780/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0068, d_svhn_loss: 0.0323, d_fake_loss: 0.0221, g_loss: 1.1026\n",
            "Step [51790/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0048, d_svhn_loss: 0.0273, d_fake_loss: 0.0271, g_loss: 1.2243\n",
            "Step [51800/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0035, d_svhn_loss: 0.0142, d_fake_loss: 0.0474, g_loss: 1.2441\n",
            "Step [51810/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0061, d_svhn_loss: 0.0380, d_fake_loss: 0.0186, g_loss: 1.2102\n",
            "Step [51820/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0074, d_svhn_loss: 0.0169, d_fake_loss: 0.0357, g_loss: 1.2162\n",
            "Step [51830/80000], d_real_loss: 0.2138, d_mnist_loss: 0.0026, d_svhn_loss: 0.2112, d_fake_loss: 0.2570, g_loss: 1.1556\n",
            "Step [51840/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0063, d_svhn_loss: 0.0281, d_fake_loss: 0.0212, g_loss: 1.2006\n",
            "Step [51850/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0036, d_svhn_loss: 0.0318, d_fake_loss: 0.1260, g_loss: 1.1156\n",
            "Step [51860/80000], d_real_loss: 0.1076, d_mnist_loss: 0.0065, d_svhn_loss: 0.1011, d_fake_loss: 0.0257, g_loss: 1.1918\n",
            "Step [51870/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0047, d_svhn_loss: 0.0506, d_fake_loss: 0.0181, g_loss: 1.1756\n",
            "Step [51880/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0135, d_svhn_loss: 0.0206, d_fake_loss: 0.0473, g_loss: 1.2487\n",
            "Step [51890/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0030, d_svhn_loss: 0.0242, d_fake_loss: 0.0450, g_loss: 1.2721\n",
            "Step [51900/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0104, d_svhn_loss: 0.0276, d_fake_loss: 0.0371, g_loss: 1.1473\n",
            "Step [51910/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0034, d_svhn_loss: 0.0284, d_fake_loss: 0.0749, g_loss: 1.2331\n",
            "Step [51920/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0027, d_svhn_loss: 0.0234, d_fake_loss: 0.0755, g_loss: 1.1416\n",
            "Step [51930/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0102, d_svhn_loss: 0.0370, d_fake_loss: 0.0189, g_loss: 1.1061\n",
            "Step [51940/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0083, d_svhn_loss: 0.0546, d_fake_loss: 0.0275, g_loss: 1.2298\n",
            "Step [51950/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0118, d_svhn_loss: 0.0341, d_fake_loss: 0.1466, g_loss: 1.3228\n",
            "Step [51960/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0068, d_svhn_loss: 0.0528, d_fake_loss: 0.0172, g_loss: 1.1199\n",
            "Step [51970/80000], d_real_loss: 0.0993, d_mnist_loss: 0.0042, d_svhn_loss: 0.0951, d_fake_loss: 0.0481, g_loss: 1.0642\n",
            "Step [51980/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0051, d_svhn_loss: 0.0222, d_fake_loss: 0.0794, g_loss: 1.2683\n",
            "Step [51990/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0039, d_svhn_loss: 0.0384, d_fake_loss: 0.0226, g_loss: 1.1831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [52000/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0263, d_svhn_loss: 0.0445, d_fake_loss: 0.0700, g_loss: 0.9398\n",
            "saved ./samples_mnist_svhn/sample-52000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-52000-s-m.png\n",
            "Step [52010/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0086, d_svhn_loss: 0.0384, d_fake_loss: 0.0788, g_loss: 1.3176\n",
            "Step [52020/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0045, d_svhn_loss: 0.0311, d_fake_loss: 0.0172, g_loss: 1.3638\n",
            "Step [52030/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0142, d_svhn_loss: 0.0171, d_fake_loss: 0.0432, g_loss: 1.2130\n",
            "Step [52040/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0043, d_svhn_loss: 0.0726, d_fake_loss: 0.0424, g_loss: 1.2066\n",
            "Step [52050/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0121, d_svhn_loss: 0.0165, d_fake_loss: 0.0395, g_loss: 1.0722\n",
            "Step [52060/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0047, d_svhn_loss: 0.0182, d_fake_loss: 0.0380, g_loss: 1.3682\n",
            "Step [52070/80000], d_real_loss: 0.0715, d_mnist_loss: 0.0037, d_svhn_loss: 0.0678, d_fake_loss: 0.0335, g_loss: 1.4829\n",
            "Step [52080/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0057, d_svhn_loss: 0.0481, d_fake_loss: 0.0369, g_loss: 1.1604\n",
            "Step [52090/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0072, d_svhn_loss: 0.0317, d_fake_loss: 0.0461, g_loss: 1.2114\n",
            "Step [52100/80000], d_real_loss: 0.0658, d_mnist_loss: 0.0055, d_svhn_loss: 0.0604, d_fake_loss: 0.0357, g_loss: 1.2240\n",
            "Step [52110/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0050, d_svhn_loss: 0.0324, d_fake_loss: 0.0372, g_loss: 1.3568\n",
            "Step [52120/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0061, d_svhn_loss: 0.0572, d_fake_loss: 0.0127, g_loss: 1.1980\n",
            "Step [52130/80000], d_real_loss: 0.0798, d_mnist_loss: 0.0136, d_svhn_loss: 0.0662, d_fake_loss: 0.0229, g_loss: 1.1829\n",
            "Step [52140/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0058, d_svhn_loss: 0.0270, d_fake_loss: 0.0246, g_loss: 1.2419\n",
            "Step [52150/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0070, d_svhn_loss: 0.0628, d_fake_loss: 0.0180, g_loss: 1.2173\n",
            "Step [52160/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0050, d_svhn_loss: 0.0177, d_fake_loss: 0.0883, g_loss: 1.1991\n",
            "Step [52170/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0056, d_svhn_loss: 0.0140, d_fake_loss: 0.0432, g_loss: 1.3133\n",
            "Step [52180/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0050, d_svhn_loss: 0.0370, d_fake_loss: 0.0276, g_loss: 1.1079\n",
            "Step [52190/80000], d_real_loss: 0.1040, d_mnist_loss: 0.0040, d_svhn_loss: 0.1001, d_fake_loss: 0.1379, g_loss: 1.2319\n",
            "Step [52200/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0074, d_svhn_loss: 0.0459, d_fake_loss: 0.0567, g_loss: 1.3324\n",
            "Step [52210/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0105, d_svhn_loss: 0.0424, d_fake_loss: 0.0452, g_loss: 1.1232\n",
            "Step [52220/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0043, d_svhn_loss: 0.0158, d_fake_loss: 0.1188, g_loss: 1.2182\n",
            "Step [52230/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0060, d_svhn_loss: 0.0560, d_fake_loss: 0.0628, g_loss: 1.2478\n",
            "Step [52240/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0068, d_svhn_loss: 0.0134, d_fake_loss: 0.0520, g_loss: 1.3480\n",
            "Step [52250/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0041, d_svhn_loss: 0.0210, d_fake_loss: 0.0801, g_loss: 1.1762\n",
            "Step [52260/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0065, d_svhn_loss: 0.0484, d_fake_loss: 0.0363, g_loss: 1.0823\n",
            "Step [52270/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0059, d_svhn_loss: 0.0453, d_fake_loss: 0.0372, g_loss: 1.1801\n",
            "Step [52280/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0073, d_svhn_loss: 0.0268, d_fake_loss: 0.0495, g_loss: 1.1567\n",
            "Step [52290/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0036, d_svhn_loss: 0.0455, d_fake_loss: 0.0301, g_loss: 1.1477\n",
            "Step [52300/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0037, d_svhn_loss: 0.0654, d_fake_loss: 0.0736, g_loss: 1.2465\n",
            "Step [52310/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0053, d_svhn_loss: 0.0270, d_fake_loss: 0.0708, g_loss: 1.2837\n",
            "Step [52320/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0037, d_svhn_loss: 0.0483, d_fake_loss: 0.0661, g_loss: 1.1166\n",
            "Step [52330/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0062, d_svhn_loss: 0.0396, d_fake_loss: 0.0376, g_loss: 1.2946\n",
            "Step [52340/80000], d_real_loss: 0.1059, d_mnist_loss: 0.0028, d_svhn_loss: 0.1031, d_fake_loss: 0.0441, g_loss: 1.2368\n",
            "Step [52350/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0045, d_svhn_loss: 0.0227, d_fake_loss: 0.0431, g_loss: 1.1954\n",
            "Step [52360/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0059, d_svhn_loss: 0.0362, d_fake_loss: 0.0181, g_loss: 1.2110\n",
            "Step [52370/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0046, d_svhn_loss: 0.0275, d_fake_loss: 0.0621, g_loss: 1.3426\n",
            "Step [52380/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0037, d_svhn_loss: 0.0274, d_fake_loss: 0.0405, g_loss: 1.1676\n",
            "Step [52390/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0046, d_svhn_loss: 0.0199, d_fake_loss: 0.0300, g_loss: 1.2418\n",
            "Step [52400/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0080, d_svhn_loss: 0.0224, d_fake_loss: 0.0167, g_loss: 1.2171\n",
            "Step [52410/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0045, d_svhn_loss: 0.0304, d_fake_loss: 0.0203, g_loss: 1.1271\n",
            "Step [52420/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0036, d_svhn_loss: 0.0312, d_fake_loss: 0.0177, g_loss: 1.1812\n",
            "Step [52430/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0069, d_svhn_loss: 0.0273, d_fake_loss: 0.0475, g_loss: 1.3930\n",
            "Step [52440/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0068, d_svhn_loss: 0.0291, d_fake_loss: 0.0827, g_loss: 1.4754\n",
            "Step [52450/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0027, d_svhn_loss: 0.0726, d_fake_loss: 0.0746, g_loss: 1.2288\n",
            "Step [52460/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0038, d_svhn_loss: 0.0240, d_fake_loss: 0.0400, g_loss: 1.0792\n",
            "Step [52470/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0062, d_svhn_loss: 0.0523, d_fake_loss: 0.0242, g_loss: 1.2126\n",
            "Step [52480/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0046, d_svhn_loss: 0.0260, d_fake_loss: 0.0515, g_loss: 1.2734\n",
            "Step [52490/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0041, d_svhn_loss: 0.0526, d_fake_loss: 0.0226, g_loss: 1.2362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [52500/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0055, d_svhn_loss: 0.0662, d_fake_loss: 0.0586, g_loss: 1.1651\n",
            "saved ./samples_mnist_svhn/sample-52500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-52500-s-m.png\n",
            "Step [52510/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0054, d_svhn_loss: 0.0374, d_fake_loss: 0.0226, g_loss: 1.1205\n",
            "Step [52520/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0048, d_svhn_loss: 0.0281, d_fake_loss: 0.0216, g_loss: 1.2112\n",
            "Step [52530/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0048, d_svhn_loss: 0.0256, d_fake_loss: 0.0424, g_loss: 1.1886\n",
            "Step [52540/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0077, d_svhn_loss: 0.0175, d_fake_loss: 0.0257, g_loss: 1.1550\n",
            "Step [52550/80000], d_real_loss: 0.0880, d_mnist_loss: 0.0051, d_svhn_loss: 0.0830, d_fake_loss: 0.1171, g_loss: 1.1484\n",
            "Step [52560/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0049, d_svhn_loss: 0.0519, d_fake_loss: 0.0295, g_loss: 1.1318\n",
            "Step [52570/80000], d_real_loss: 0.1503, d_mnist_loss: 0.0071, d_svhn_loss: 0.1432, d_fake_loss: 0.0395, g_loss: 1.0880\n",
            "Step [52580/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0044, d_svhn_loss: 0.0229, d_fake_loss: 0.0281, g_loss: 1.1535\n",
            "Step [52590/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0063, d_svhn_loss: 0.0359, d_fake_loss: 0.0260, g_loss: 1.1765\n",
            "Step [52600/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0057, d_svhn_loss: 0.0202, d_fake_loss: 0.0518, g_loss: 1.1516\n",
            "Step [52610/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0174, d_svhn_loss: 0.0138, d_fake_loss: 0.1175, g_loss: 1.2672\n",
            "Step [52620/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0074, d_svhn_loss: 0.0230, d_fake_loss: 0.0378, g_loss: 1.1580\n",
            "Step [52630/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0036, d_svhn_loss: 0.0533, d_fake_loss: 0.1226, g_loss: 1.4242\n",
            "Step [52640/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0042, d_svhn_loss: 0.0241, d_fake_loss: 0.1124, g_loss: 1.2074\n",
            "Step [52650/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0066, d_svhn_loss: 0.0365, d_fake_loss: 0.0188, g_loss: 1.2395\n",
            "Step [52660/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0058, d_svhn_loss: 0.0683, d_fake_loss: 0.1206, g_loss: 1.2780\n",
            "Step [52670/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0049, d_svhn_loss: 0.0380, d_fake_loss: 0.0476, g_loss: 1.1750\n",
            "Step [52680/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0074, d_svhn_loss: 0.0232, d_fake_loss: 0.0313, g_loss: 1.0192\n",
            "Step [52690/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0046, d_svhn_loss: 0.0584, d_fake_loss: 0.0653, g_loss: 1.2358\n",
            "Step [52700/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0053, d_svhn_loss: 0.0391, d_fake_loss: 0.0371, g_loss: 1.3235\n",
            "Step [52710/80000], d_real_loss: 0.1084, d_mnist_loss: 0.0049, d_svhn_loss: 0.1035, d_fake_loss: 0.1032, g_loss: 1.2992\n",
            "Step [52720/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0053, d_svhn_loss: 0.0331, d_fake_loss: 0.1258, g_loss: 1.2690\n",
            "Step [52730/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0035, d_svhn_loss: 0.0233, d_fake_loss: 0.0490, g_loss: 1.2128\n",
            "Step [52740/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0068, d_svhn_loss: 0.0487, d_fake_loss: 0.0227, g_loss: 1.1683\n",
            "Step [52750/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0045, d_svhn_loss: 0.0242, d_fake_loss: 0.0738, g_loss: 1.0208\n",
            "Step [52760/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0374, d_svhn_loss: 0.0323, d_fake_loss: 0.0632, g_loss: 1.1517\n",
            "Step [52770/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0113, d_svhn_loss: 0.0249, d_fake_loss: 0.0180, g_loss: 1.2278\n",
            "Step [52780/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0043, d_svhn_loss: 0.0164, d_fake_loss: 0.0206, g_loss: 1.1655\n",
            "Step [52790/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0047, d_svhn_loss: 0.0483, d_fake_loss: 0.0226, g_loss: 1.1999\n",
            "Step [52800/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0056, d_svhn_loss: 0.0375, d_fake_loss: 0.0419, g_loss: 1.2200\n",
            "Step [52810/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0036, d_svhn_loss: 0.0325, d_fake_loss: 0.0537, g_loss: 1.1894\n",
            "Step [52820/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0043, d_svhn_loss: 0.0207, d_fake_loss: 0.0231, g_loss: 1.1977\n",
            "Step [52830/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0072, d_svhn_loss: 0.0368, d_fake_loss: 0.0375, g_loss: 1.2432\n",
            "Step [52840/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0066, d_svhn_loss: 0.0176, d_fake_loss: 0.0490, g_loss: 1.2115\n",
            "Step [52850/80000], d_real_loss: 0.0161, d_mnist_loss: 0.0066, d_svhn_loss: 0.0095, d_fake_loss: 0.0328, g_loss: 1.3294\n",
            "Step [52860/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0050, d_svhn_loss: 0.0268, d_fake_loss: 0.0687, g_loss: 1.3238\n",
            "Step [52870/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0087, d_svhn_loss: 0.0187, d_fake_loss: 0.0307, g_loss: 1.1956\n",
            "Step [52880/80000], d_real_loss: 0.1081, d_mnist_loss: 0.0079, d_svhn_loss: 0.1002, d_fake_loss: 0.1978, g_loss: 1.2628\n",
            "Step [52890/80000], d_real_loss: 0.0882, d_mnist_loss: 0.0069, d_svhn_loss: 0.0813, d_fake_loss: 0.0295, g_loss: 1.1817\n",
            "Step [52900/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0032, d_svhn_loss: 0.0328, d_fake_loss: 0.0929, g_loss: 1.2018\n",
            "Step [52910/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0200, d_svhn_loss: 0.0216, d_fake_loss: 0.0419, g_loss: 1.1391\n",
            "Step [52920/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0043, d_svhn_loss: 0.0250, d_fake_loss: 0.0184, g_loss: 1.1652\n",
            "Step [52930/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0032, d_svhn_loss: 0.0417, d_fake_loss: 0.0436, g_loss: 1.2709\n",
            "Step [52940/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0030, d_svhn_loss: 0.0281, d_fake_loss: 0.0289, g_loss: 1.1842\n",
            "Step [52950/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0055, d_svhn_loss: 0.0417, d_fake_loss: 0.0414, g_loss: 1.0393\n",
            "Step [52960/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0192, d_svhn_loss: 0.0208, d_fake_loss: 0.0340, g_loss: 1.1470\n",
            "Step [52970/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0030, d_svhn_loss: 0.0203, d_fake_loss: 0.0472, g_loss: 1.2622\n",
            "Step [52980/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0035, d_svhn_loss: 0.0391, d_fake_loss: 0.0517, g_loss: 1.3463\n",
            "Step [52990/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0097, d_svhn_loss: 0.0222, d_fake_loss: 0.0336, g_loss: 1.2778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [53000/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0033, d_svhn_loss: 0.0433, d_fake_loss: 0.0703, g_loss: 1.2543\n",
            "saved ./samples_mnist_svhn/sample-53000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-53000-s-m.png\n",
            "Step [53010/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0066, d_svhn_loss: 0.0280, d_fake_loss: 0.0340, g_loss: 1.1457\n",
            "Step [53020/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0053, d_svhn_loss: 0.0201, d_fake_loss: 0.0556, g_loss: 1.1639\n",
            "Step [53030/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0036, d_svhn_loss: 0.0290, d_fake_loss: 0.0205, g_loss: 1.1565\n",
            "Step [53040/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0086, d_svhn_loss: 0.0241, d_fake_loss: 0.0268, g_loss: 1.2123\n",
            "Step [53050/80000], d_real_loss: 0.0144, d_mnist_loss: 0.0041, d_svhn_loss: 0.0102, d_fake_loss: 0.0244, g_loss: 1.1538\n",
            "Step [53060/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0048, d_svhn_loss: 0.0359, d_fake_loss: 0.0451, g_loss: 1.2070\n",
            "Step [53070/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0063, d_svhn_loss: 0.0468, d_fake_loss: 0.0229, g_loss: 1.1618\n",
            "Step [53080/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0137, d_svhn_loss: 0.0310, d_fake_loss: 0.0366, g_loss: 1.0962\n",
            "Step [53090/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0063, d_svhn_loss: 0.0423, d_fake_loss: 0.0394, g_loss: 1.2124\n",
            "Step [53100/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0071, d_svhn_loss: 0.0425, d_fake_loss: 0.0271, g_loss: 1.2312\n",
            "Step [53110/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0165, d_svhn_loss: 0.0498, d_fake_loss: 0.0477, g_loss: 1.1746\n",
            "Step [53120/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0060, d_svhn_loss: 0.0442, d_fake_loss: 0.0391, g_loss: 1.2257\n",
            "Step [53130/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0043, d_svhn_loss: 0.0415, d_fake_loss: 0.0537, g_loss: 1.1152\n",
            "Step [53140/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0058, d_svhn_loss: 0.0181, d_fake_loss: 0.0137, g_loss: 1.1622\n",
            "Step [53150/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0038, d_svhn_loss: 0.0241, d_fake_loss: 0.0227, g_loss: 1.2272\n",
            "Step [53160/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0100, d_svhn_loss: 0.0228, d_fake_loss: 0.0430, g_loss: 1.2508\n",
            "Step [53170/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0085, d_svhn_loss: 0.0260, d_fake_loss: 0.0290, g_loss: 1.1000\n",
            "Step [53180/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0050, d_svhn_loss: 0.0196, d_fake_loss: 0.0209, g_loss: 1.1730\n",
            "Step [53190/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0099, d_svhn_loss: 0.0255, d_fake_loss: 0.0246, g_loss: 1.0923\n",
            "Step [53200/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0045, d_svhn_loss: 0.0280, d_fake_loss: 0.0375, g_loss: 1.1510\n",
            "Step [53210/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0032, d_svhn_loss: 0.0208, d_fake_loss: 0.0993, g_loss: 1.0448\n",
            "Step [53220/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0038, d_svhn_loss: 0.0291, d_fake_loss: 0.0148, g_loss: 1.1669\n",
            "Step [53230/80000], d_real_loss: 0.1400, d_mnist_loss: 0.0036, d_svhn_loss: 0.1364, d_fake_loss: 0.0317, g_loss: 1.1512\n",
            "Step [53240/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0061, d_svhn_loss: 0.0321, d_fake_loss: 0.0536, g_loss: 1.1143\n",
            "Step [53250/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0055, d_svhn_loss: 0.0477, d_fake_loss: 0.0417, g_loss: 1.1794\n",
            "Step [53260/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0077, d_svhn_loss: 0.0358, d_fake_loss: 0.0420, g_loss: 1.1049\n",
            "Step [53270/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0037, d_svhn_loss: 0.0313, d_fake_loss: 0.0474, g_loss: 1.1494\n",
            "Step [53280/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0048, d_svhn_loss: 0.0219, d_fake_loss: 0.0263, g_loss: 1.2215\n",
            "Step [53290/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0044, d_svhn_loss: 0.0274, d_fake_loss: 0.0266, g_loss: 1.1429\n",
            "Step [53300/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0077, d_svhn_loss: 0.0249, d_fake_loss: 0.0471, g_loss: 1.1711\n",
            "Step [53310/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0043, d_svhn_loss: 0.0300, d_fake_loss: 0.0423, g_loss: 1.1039\n",
            "Step [53320/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0034, d_svhn_loss: 0.0498, d_fake_loss: 0.0614, g_loss: 1.1858\n",
            "Step [53330/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0032, d_svhn_loss: 0.0445, d_fake_loss: 0.0354, g_loss: 1.1731\n",
            "Step [53340/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0043, d_svhn_loss: 0.0346, d_fake_loss: 0.0283, g_loss: 1.1819\n",
            "Step [53350/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0182, d_svhn_loss: 0.0184, d_fake_loss: 0.0575, g_loss: 1.1472\n",
            "Step [53360/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0133, d_svhn_loss: 0.0455, d_fake_loss: 0.0333, g_loss: 1.2194\n",
            "Step [53370/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0026, d_svhn_loss: 0.0298, d_fake_loss: 0.0220, g_loss: 1.1391\n",
            "Step [53380/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0207, d_svhn_loss: 0.0133, d_fake_loss: 0.0101, g_loss: 1.1432\n",
            "Step [53390/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0036, d_svhn_loss: 0.0512, d_fake_loss: 0.0258, g_loss: 1.2846\n",
            "Step [53400/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0038, d_svhn_loss: 0.0410, d_fake_loss: 0.0289, g_loss: 1.3407\n",
            "Step [53410/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0044, d_svhn_loss: 0.0501, d_fake_loss: 0.0276, g_loss: 1.2234\n",
            "Step [53420/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0050, d_svhn_loss: 0.0186, d_fake_loss: 0.0498, g_loss: 1.1599\n",
            "Step [53430/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0041, d_svhn_loss: 0.0466, d_fake_loss: 0.0322, g_loss: 1.1196\n",
            "Step [53440/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0232, d_svhn_loss: 0.0235, d_fake_loss: 0.0705, g_loss: 1.1660\n",
            "Step [53450/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0099, d_svhn_loss: 0.0354, d_fake_loss: 0.0559, g_loss: 1.1921\n",
            "Step [53460/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0039, d_svhn_loss: 0.0327, d_fake_loss: 0.0673, g_loss: 1.1458\n",
            "Step [53470/80000], d_real_loss: 0.1441, d_mnist_loss: 0.0108, d_svhn_loss: 0.1333, d_fake_loss: 0.0836, g_loss: 1.2665\n",
            "Step [53480/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0061, d_svhn_loss: 0.0194, d_fake_loss: 0.0279, g_loss: 1.1464\n",
            "Step [53490/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0035, d_svhn_loss: 0.0233, d_fake_loss: 0.0917, g_loss: 1.1100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [53500/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0047, d_svhn_loss: 0.0513, d_fake_loss: 0.0254, g_loss: 1.1511\n",
            "saved ./samples_mnist_svhn/sample-53500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-53500-s-m.png\n",
            "Step [53510/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0091, d_svhn_loss: 0.0565, d_fake_loss: 0.0314, g_loss: 1.1624\n",
            "Step [53520/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0055, d_svhn_loss: 0.0474, d_fake_loss: 0.0236, g_loss: 1.1714\n",
            "Step [53530/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0041, d_svhn_loss: 0.0365, d_fake_loss: 0.0500, g_loss: 1.1925\n",
            "Step [53540/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0068, d_svhn_loss: 0.0168, d_fake_loss: 0.0430, g_loss: 1.2452\n",
            "Step [53550/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0089, d_svhn_loss: 0.0435, d_fake_loss: 0.0473, g_loss: 1.0898\n",
            "Step [53560/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0159, d_svhn_loss: 0.0624, d_fake_loss: 0.0893, g_loss: 1.2377\n",
            "Step [53570/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0070, d_svhn_loss: 0.0602, d_fake_loss: 0.0700, g_loss: 1.2104\n",
            "Step [53580/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0035, d_svhn_loss: 0.0209, d_fake_loss: 0.0345, g_loss: 1.2005\n",
            "Step [53590/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0055, d_svhn_loss: 0.0256, d_fake_loss: 0.0258, g_loss: 1.3035\n",
            "Step [53600/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0061, d_svhn_loss: 0.0394, d_fake_loss: 0.0565, g_loss: 1.1173\n",
            "Step [53610/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0164, d_svhn_loss: 0.0227, d_fake_loss: 0.0199, g_loss: 1.1668\n",
            "Step [53620/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0086, d_svhn_loss: 0.0271, d_fake_loss: 0.0560, g_loss: 1.2957\n",
            "Step [53630/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0082, d_svhn_loss: 0.0287, d_fake_loss: 0.0447, g_loss: 1.2117\n",
            "Step [53640/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0280, d_svhn_loss: 0.0154, d_fake_loss: 0.0172, g_loss: 1.1469\n",
            "Step [53650/80000], d_real_loss: 0.0803, d_mnist_loss: 0.0265, d_svhn_loss: 0.0538, d_fake_loss: 0.1236, g_loss: 1.3087\n",
            "Step [53660/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0061, d_svhn_loss: 0.0429, d_fake_loss: 0.0737, g_loss: 1.2806\n",
            "Step [53670/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0156, d_svhn_loss: 0.0612, d_fake_loss: 0.0817, g_loss: 1.4362\n",
            "Step [53680/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0055, d_svhn_loss: 0.0215, d_fake_loss: 0.0729, g_loss: 1.3620\n",
            "Step [53690/80000], d_real_loss: 0.1309, d_mnist_loss: 0.0030, d_svhn_loss: 0.1279, d_fake_loss: 0.0314, g_loss: 1.2339\n",
            "Step [53700/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0070, d_svhn_loss: 0.0132, d_fake_loss: 0.0641, g_loss: 1.0440\n",
            "Step [53710/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0132, d_svhn_loss: 0.0375, d_fake_loss: 0.0433, g_loss: 1.0762\n",
            "Step [53720/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0062, d_svhn_loss: 0.0264, d_fake_loss: 0.0449, g_loss: 1.1595\n",
            "Step [53730/80000], d_real_loss: 0.1488, d_mnist_loss: 0.0051, d_svhn_loss: 0.1437, d_fake_loss: 0.0780, g_loss: 1.2354\n",
            "Step [53740/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0078, d_svhn_loss: 0.0172, d_fake_loss: 0.0208, g_loss: 1.1849\n",
            "Step [53750/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0087, d_svhn_loss: 0.0278, d_fake_loss: 0.0410, g_loss: 1.2267\n",
            "Step [53760/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0127, d_svhn_loss: 0.0227, d_fake_loss: 0.0220, g_loss: 1.1798\n",
            "Step [53770/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0050, d_svhn_loss: 0.0300, d_fake_loss: 0.0337, g_loss: 1.1185\n",
            "Step [53780/80000], d_real_loss: 0.0671, d_mnist_loss: 0.0066, d_svhn_loss: 0.0605, d_fake_loss: 0.0340, g_loss: 1.1701\n",
            "Step [53790/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0095, d_svhn_loss: 0.0324, d_fake_loss: 0.0223, g_loss: 1.1606\n",
            "Step [53800/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0025, d_svhn_loss: 0.0204, d_fake_loss: 0.0352, g_loss: 1.2343\n",
            "Step [53810/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0093, d_svhn_loss: 0.0252, d_fake_loss: 0.0197, g_loss: 1.2949\n",
            "Step [53820/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0046, d_svhn_loss: 0.0219, d_fake_loss: 0.0354, g_loss: 1.1759\n",
            "Step [53830/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0063, d_svhn_loss: 0.0170, d_fake_loss: 0.0782, g_loss: 1.1577\n",
            "Step [53840/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0040, d_svhn_loss: 0.0440, d_fake_loss: 0.1138, g_loss: 1.1779\n",
            "Step [53850/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0031, d_svhn_loss: 0.0377, d_fake_loss: 0.0188, g_loss: 1.3323\n",
            "Step [53860/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0156, d_svhn_loss: 0.0694, d_fake_loss: 0.0989, g_loss: 1.2656\n",
            "Step [53870/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0072, d_svhn_loss: 0.0332, d_fake_loss: 0.0414, g_loss: 1.2930\n",
            "Step [53880/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0043, d_svhn_loss: 0.0370, d_fake_loss: 0.0194, g_loss: 1.1433\n",
            "Step [53890/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0033, d_svhn_loss: 0.0578, d_fake_loss: 0.0187, g_loss: 1.2567\n",
            "Step [53900/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0073, d_svhn_loss: 0.0452, d_fake_loss: 0.0273, g_loss: 1.2324\n",
            "Step [53910/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0043, d_svhn_loss: 0.0211, d_fake_loss: 0.0297, g_loss: 1.1817\n",
            "Step [53920/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0093, d_svhn_loss: 0.0201, d_fake_loss: 0.0366, g_loss: 1.0633\n",
            "Step [53930/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0039, d_svhn_loss: 0.0205, d_fake_loss: 0.0304, g_loss: 1.1833\n",
            "Step [53940/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0161, d_svhn_loss: 0.0135, d_fake_loss: 0.0697, g_loss: 1.2884\n",
            "Step [53950/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0115, d_svhn_loss: 0.0220, d_fake_loss: 0.0410, g_loss: 1.2078\n",
            "Step [53960/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0033, d_svhn_loss: 0.0234, d_fake_loss: 0.0163, g_loss: 1.2175\n",
            "Step [53970/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0036, d_svhn_loss: 0.0150, d_fake_loss: 0.0235, g_loss: 1.2138\n",
            "Step [53980/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0052, d_svhn_loss: 0.0711, d_fake_loss: 0.0592, g_loss: 0.9878\n",
            "Step [53990/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0082, d_svhn_loss: 0.0505, d_fake_loss: 0.0280, g_loss: 1.2327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [54000/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0062, d_svhn_loss: 0.0214, d_fake_loss: 0.0319, g_loss: 1.0862\n",
            "saved ./samples_mnist_svhn/sample-54000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-54000-s-m.png\n",
            "Step [54010/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0118, d_svhn_loss: 0.0180, d_fake_loss: 0.0330, g_loss: 1.2453\n",
            "Step [54020/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0039, d_svhn_loss: 0.0522, d_fake_loss: 0.0546, g_loss: 1.1919\n",
            "Step [54030/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0041, d_svhn_loss: 0.0878, d_fake_loss: 0.0783, g_loss: 1.1535\n",
            "Step [54040/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0048, d_svhn_loss: 0.0484, d_fake_loss: 0.0238, g_loss: 1.2032\n",
            "Step [54050/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0040, d_svhn_loss: 0.0187, d_fake_loss: 0.0369, g_loss: 1.0574\n",
            "Step [54060/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0038, d_svhn_loss: 0.0531, d_fake_loss: 0.0571, g_loss: 1.1743\n",
            "Step [54070/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0047, d_svhn_loss: 0.0461, d_fake_loss: 0.0409, g_loss: 1.2017\n",
            "Step [54080/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0089, d_svhn_loss: 0.0271, d_fake_loss: 0.0303, g_loss: 1.1232\n",
            "Step [54090/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0187, d_svhn_loss: 0.0403, d_fake_loss: 0.1000, g_loss: 1.1173\n",
            "Step [54100/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0033, d_svhn_loss: 0.0289, d_fake_loss: 0.0344, g_loss: 1.2123\n",
            "Step [54110/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0022, d_svhn_loss: 0.0445, d_fake_loss: 0.0105, g_loss: 1.1801\n",
            "Step [54120/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0065, d_svhn_loss: 0.0200, d_fake_loss: 0.0577, g_loss: 1.1640\n",
            "Step [54130/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0107, d_svhn_loss: 0.0562, d_fake_loss: 0.0133, g_loss: 1.1674\n",
            "Step [54140/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0116, d_svhn_loss: 0.0377, d_fake_loss: 0.0856, g_loss: 1.0575\n",
            "Step [54150/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0034, d_svhn_loss: 0.0230, d_fake_loss: 0.0549, g_loss: 1.3342\n",
            "Step [54160/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0096, d_svhn_loss: 0.0159, d_fake_loss: 0.0158, g_loss: 1.2660\n",
            "Step [54170/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0051, d_svhn_loss: 0.0213, d_fake_loss: 0.0557, g_loss: 1.2211\n",
            "Step [54180/80000], d_real_loss: 0.0972, d_mnist_loss: 0.0369, d_svhn_loss: 0.0603, d_fake_loss: 0.0233, g_loss: 1.2195\n",
            "Step [54190/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0066, d_svhn_loss: 0.0188, d_fake_loss: 0.0217, g_loss: 1.2398\n",
            "Step [54200/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0032, d_svhn_loss: 0.0524, d_fake_loss: 0.0237, g_loss: 1.3034\n",
            "Step [54210/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0195, d_svhn_loss: 0.0209, d_fake_loss: 0.0441, g_loss: 1.2506\n",
            "Step [54220/80000], d_real_loss: 0.0680, d_mnist_loss: 0.0088, d_svhn_loss: 0.0592, d_fake_loss: 0.0238, g_loss: 1.3538\n",
            "Step [54230/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0031, d_svhn_loss: 0.0195, d_fake_loss: 0.0578, g_loss: 1.1640\n",
            "Step [54240/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0043, d_svhn_loss: 0.0467, d_fake_loss: 0.0362, g_loss: 1.1150\n",
            "Step [54250/80000], d_real_loss: 0.0994, d_mnist_loss: 0.0054, d_svhn_loss: 0.0940, d_fake_loss: 0.0409, g_loss: 1.1979\n",
            "Step [54260/80000], d_real_loss: 0.1143, d_mnist_loss: 0.0128, d_svhn_loss: 0.1014, d_fake_loss: 0.1137, g_loss: 1.2904\n",
            "Step [54270/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0031, d_svhn_loss: 0.0235, d_fake_loss: 0.0261, g_loss: 1.1477\n",
            "Step [54280/80000], d_real_loss: 0.1038, d_mnist_loss: 0.0093, d_svhn_loss: 0.0945, d_fake_loss: 0.0255, g_loss: 1.1153\n",
            "Step [54290/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0041, d_svhn_loss: 0.0225, d_fake_loss: 0.0647, g_loss: 1.1803\n",
            "Step [54300/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0037, d_svhn_loss: 0.0399, d_fake_loss: 0.0404, g_loss: 1.1199\n",
            "Step [54310/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0046, d_svhn_loss: 0.0224, d_fake_loss: 0.0349, g_loss: 1.1888\n",
            "Step [54320/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0034, d_svhn_loss: 0.0561, d_fake_loss: 0.0766, g_loss: 1.3376\n",
            "Step [54330/80000], d_real_loss: 0.1189, d_mnist_loss: 0.0285, d_svhn_loss: 0.0904, d_fake_loss: 0.1034, g_loss: 1.1833\n",
            "Step [54340/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0050, d_svhn_loss: 0.0278, d_fake_loss: 0.0284, g_loss: 1.2092\n",
            "Step [54350/80000], d_real_loss: 0.0981, d_mnist_loss: 0.0195, d_svhn_loss: 0.0787, d_fake_loss: 0.0605, g_loss: 1.2600\n",
            "Step [54360/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0070, d_svhn_loss: 0.0422, d_fake_loss: 0.0504, g_loss: 1.1812\n",
            "Step [54370/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0040, d_svhn_loss: 0.0218, d_fake_loss: 0.0426, g_loss: 1.1896\n",
            "Step [54380/80000], d_real_loss: 0.1028, d_mnist_loss: 0.0024, d_svhn_loss: 0.1003, d_fake_loss: 0.0396, g_loss: 1.2515\n",
            "Step [54390/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0045, d_svhn_loss: 0.0153, d_fake_loss: 0.0298, g_loss: 1.2281\n",
            "Step [54400/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0050, d_svhn_loss: 0.0293, d_fake_loss: 0.0340, g_loss: 1.1382\n",
            "Step [54410/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0047, d_svhn_loss: 0.0743, d_fake_loss: 0.0166, g_loss: 1.1885\n",
            "Step [54420/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0031, d_svhn_loss: 0.0364, d_fake_loss: 0.0444, g_loss: 1.1114\n",
            "Step [54430/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0030, d_svhn_loss: 0.0167, d_fake_loss: 0.0201, g_loss: 1.1256\n",
            "Step [54440/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0101, d_svhn_loss: 0.0176, d_fake_loss: 0.0382, g_loss: 1.2500\n",
            "Step [54450/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0033, d_svhn_loss: 0.0273, d_fake_loss: 0.0242, g_loss: 1.2623\n",
            "Step [54460/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0057, d_svhn_loss: 0.0237, d_fake_loss: 0.0605, g_loss: 1.2196\n",
            "Step [54470/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0037, d_svhn_loss: 0.0356, d_fake_loss: 0.0535, g_loss: 1.3223\n",
            "Step [54480/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0039, d_svhn_loss: 0.0223, d_fake_loss: 0.0267, g_loss: 1.1871\n",
            "Step [54490/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0100, d_svhn_loss: 0.0212, d_fake_loss: 0.0330, g_loss: 1.2289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [54500/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0094, d_svhn_loss: 0.0198, d_fake_loss: 0.0402, g_loss: 1.1758\n",
            "saved ./samples_mnist_svhn/sample-54500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-54500-s-m.png\n",
            "Step [54510/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0051, d_svhn_loss: 0.0238, d_fake_loss: 0.0209, g_loss: 1.2190\n",
            "Step [54520/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0137, d_svhn_loss: 0.0169, d_fake_loss: 0.0369, g_loss: 1.1115\n",
            "Step [54530/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0044, d_svhn_loss: 0.0254, d_fake_loss: 0.0598, g_loss: 1.2927\n",
            "Step [54540/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0150, d_svhn_loss: 0.0547, d_fake_loss: 0.0329, g_loss: 1.1750\n",
            "Step [54550/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0053, d_svhn_loss: 0.0265, d_fake_loss: 0.0405, g_loss: 1.1777\n",
            "Step [54560/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0061, d_svhn_loss: 0.0373, d_fake_loss: 0.0243, g_loss: 1.1569\n",
            "Step [54570/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0040, d_svhn_loss: 0.0213, d_fake_loss: 0.0779, g_loss: 1.2186\n",
            "Step [54580/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0066, d_svhn_loss: 0.0325, d_fake_loss: 0.0647, g_loss: 1.2110\n",
            "Step [54590/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0082, d_svhn_loss: 0.0322, d_fake_loss: 0.0417, g_loss: 1.3022\n",
            "Step [54600/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0053, d_svhn_loss: 0.0229, d_fake_loss: 0.0184, g_loss: 1.1707\n",
            "Step [54610/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0183, d_svhn_loss: 0.0150, d_fake_loss: 0.0619, g_loss: 1.1473\n",
            "Step [54620/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0090, d_svhn_loss: 0.0190, d_fake_loss: 0.0222, g_loss: 1.2211\n",
            "Step [54630/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0078, d_svhn_loss: 0.0257, d_fake_loss: 0.0211, g_loss: 1.2811\n",
            "Step [54640/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0035, d_svhn_loss: 0.0224, d_fake_loss: 0.0354, g_loss: 1.2699\n",
            "Step [54650/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0083, d_svhn_loss: 0.0151, d_fake_loss: 0.0407, g_loss: 1.1690\n",
            "Step [54660/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0038, d_svhn_loss: 0.0684, d_fake_loss: 0.0278, g_loss: 1.1904\n",
            "Step [54670/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0045, d_svhn_loss: 0.0195, d_fake_loss: 0.0204, g_loss: 1.2419\n",
            "Step [54680/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0064, d_svhn_loss: 0.0321, d_fake_loss: 0.0266, g_loss: 1.3331\n",
            "Step [54690/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0061, d_svhn_loss: 0.0302, d_fake_loss: 0.0235, g_loss: 1.2380\n",
            "Step [54700/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0197, d_svhn_loss: 0.0412, d_fake_loss: 0.0234, g_loss: 1.2005\n",
            "Step [54710/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0116, d_svhn_loss: 0.0199, d_fake_loss: 0.0130, g_loss: 1.1415\n",
            "Step [54720/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0116, d_svhn_loss: 0.0415, d_fake_loss: 0.0491, g_loss: 1.0810\n",
            "Step [54730/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0065, d_svhn_loss: 0.0547, d_fake_loss: 0.0611, g_loss: 1.0834\n",
            "Step [54740/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0045, d_svhn_loss: 0.0316, d_fake_loss: 0.0421, g_loss: 1.1534\n",
            "Step [54750/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0044, d_svhn_loss: 0.0220, d_fake_loss: 0.0138, g_loss: 1.2066\n",
            "Step [54760/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0070, d_svhn_loss: 0.0166, d_fake_loss: 0.0328, g_loss: 1.0541\n",
            "Step [54770/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0040, d_svhn_loss: 0.0290, d_fake_loss: 0.0704, g_loss: 1.1823\n",
            "Step [54780/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0034, d_svhn_loss: 0.0557, d_fake_loss: 0.0479, g_loss: 1.2317\n",
            "Step [54790/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0129, d_svhn_loss: 0.0238, d_fake_loss: 0.0785, g_loss: 1.0578\n",
            "Step [54800/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0027, d_svhn_loss: 0.0352, d_fake_loss: 0.1103, g_loss: 1.1582\n",
            "Step [54810/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0049, d_svhn_loss: 0.0148, d_fake_loss: 0.0238, g_loss: 1.2953\n",
            "Step [54820/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0049, d_svhn_loss: 0.0152, d_fake_loss: 0.1245, g_loss: 1.2221\n",
            "Step [54830/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0078, d_svhn_loss: 0.0278, d_fake_loss: 0.0197, g_loss: 1.1913\n",
            "Step [54840/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0036, d_svhn_loss: 0.0233, d_fake_loss: 0.0174, g_loss: 1.1475\n",
            "Step [54850/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0044, d_svhn_loss: 0.0240, d_fake_loss: 0.1059, g_loss: 1.2447\n",
            "Step [54860/80000], d_real_loss: 0.1505, d_mnist_loss: 0.0147, d_svhn_loss: 0.1358, d_fake_loss: 0.0564, g_loss: 1.1835\n",
            "Step [54870/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0034, d_svhn_loss: 0.0239, d_fake_loss: 0.0264, g_loss: 1.1695\n",
            "Step [54880/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0040, d_svhn_loss: 0.0252, d_fake_loss: 0.0271, g_loss: 1.2558\n",
            "Step [54890/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0033, d_svhn_loss: 0.0300, d_fake_loss: 0.0228, g_loss: 1.1489\n",
            "Step [54900/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0123, d_svhn_loss: 0.0247, d_fake_loss: 0.0199, g_loss: 1.1854\n",
            "Step [54910/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0102, d_svhn_loss: 0.0274, d_fake_loss: 0.0148, g_loss: 1.1160\n",
            "Step [54920/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0059, d_svhn_loss: 0.0302, d_fake_loss: 0.0174, g_loss: 1.1498\n",
            "Step [54930/80000], d_real_loss: 0.2246, d_mnist_loss: 0.0200, d_svhn_loss: 0.2046, d_fake_loss: 0.0724, g_loss: 1.1534\n",
            "Step [54940/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0041, d_svhn_loss: 0.0608, d_fake_loss: 0.0419, g_loss: 1.1388\n",
            "Step [54950/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0033, d_svhn_loss: 0.0547, d_fake_loss: 0.0491, g_loss: 1.1986\n",
            "Step [54960/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0035, d_svhn_loss: 0.0564, d_fake_loss: 0.0177, g_loss: 1.0787\n",
            "Step [54970/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0031, d_svhn_loss: 0.0576, d_fake_loss: 0.0381, g_loss: 1.1287\n",
            "Step [54980/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0084, d_svhn_loss: 0.0235, d_fake_loss: 0.0278, g_loss: 1.2661\n",
            "Step [54990/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0097, d_svhn_loss: 0.0248, d_fake_loss: 0.0453, g_loss: 1.1029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [55000/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0036, d_svhn_loss: 0.0193, d_fake_loss: 0.0144, g_loss: 1.2320\n",
            "saved ./samples_mnist_svhn/sample-55000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-55000-s-m.png\n",
            "Step [55010/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0034, d_svhn_loss: 0.0550, d_fake_loss: 0.0842, g_loss: 1.2556\n",
            "Step [55020/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0041, d_svhn_loss: 0.0269, d_fake_loss: 0.0245, g_loss: 1.3098\n",
            "Step [55030/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0035, d_svhn_loss: 0.0304, d_fake_loss: 0.0615, g_loss: 1.3645\n",
            "Step [55040/80000], d_real_loss: 0.0792, d_mnist_loss: 0.0099, d_svhn_loss: 0.0693, d_fake_loss: 0.0890, g_loss: 1.1915\n",
            "Step [55050/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0117, d_svhn_loss: 0.0275, d_fake_loss: 0.0490, g_loss: 1.0346\n",
            "Step [55060/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0053, d_svhn_loss: 0.0251, d_fake_loss: 0.0412, g_loss: 1.3241\n",
            "Step [55070/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0042, d_svhn_loss: 0.0255, d_fake_loss: 0.0235, g_loss: 1.1949\n",
            "Step [55080/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0107, d_svhn_loss: 0.0214, d_fake_loss: 0.0246, g_loss: 1.0884\n",
            "Step [55090/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0062, d_svhn_loss: 0.0304, d_fake_loss: 0.0227, g_loss: 1.1678\n",
            "Step [55100/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0032, d_svhn_loss: 0.0209, d_fake_loss: 0.0299, g_loss: 1.2667\n",
            "Step [55110/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0103, d_svhn_loss: 0.0201, d_fake_loss: 0.0317, g_loss: 1.1226\n",
            "Step [55120/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0100, d_svhn_loss: 0.0185, d_fake_loss: 0.0623, g_loss: 1.3506\n",
            "Step [55130/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0043, d_svhn_loss: 0.0235, d_fake_loss: 0.0656, g_loss: 1.2064\n",
            "Step [55140/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0103, d_svhn_loss: 0.0474, d_fake_loss: 0.0320, g_loss: 1.0867\n",
            "Step [55150/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0108, d_svhn_loss: 0.0460, d_fake_loss: 0.0353, g_loss: 1.1632\n",
            "Step [55160/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0050, d_svhn_loss: 0.0342, d_fake_loss: 0.0354, g_loss: 1.0607\n",
            "Step [55170/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0038, d_svhn_loss: 0.0169, d_fake_loss: 0.0487, g_loss: 1.3036\n",
            "Step [55180/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0072, d_svhn_loss: 0.0533, d_fake_loss: 0.1329, g_loss: 1.1374\n",
            "Step [55190/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0045, d_svhn_loss: 0.0394, d_fake_loss: 0.0745, g_loss: 1.1788\n",
            "Step [55200/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0149, d_svhn_loss: 0.0159, d_fake_loss: 0.0997, g_loss: 1.0058\n",
            "Step [55210/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0044, d_svhn_loss: 0.0238, d_fake_loss: 0.0309, g_loss: 1.1735\n",
            "Step [55220/80000], d_real_loss: 0.1325, d_mnist_loss: 0.0127, d_svhn_loss: 0.1198, d_fake_loss: 0.0921, g_loss: 1.3228\n",
            "Step [55230/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0021, d_svhn_loss: 0.0556, d_fake_loss: 0.0761, g_loss: 1.3389\n",
            "Step [55240/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0067, d_svhn_loss: 0.0276, d_fake_loss: 0.0279, g_loss: 1.3885\n",
            "Step [55250/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0113, d_svhn_loss: 0.0275, d_fake_loss: 0.0489, g_loss: 1.3773\n",
            "Step [55260/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0035, d_svhn_loss: 0.0562, d_fake_loss: 0.0146, g_loss: 1.2415\n",
            "Step [55270/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0029, d_svhn_loss: 0.0358, d_fake_loss: 0.0247, g_loss: 1.2128\n",
            "Step [55280/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0045, d_svhn_loss: 0.0147, d_fake_loss: 0.0260, g_loss: 1.2318\n",
            "Step [55290/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0030, d_svhn_loss: 0.0225, d_fake_loss: 0.0280, g_loss: 1.1996\n",
            "Step [55300/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0042, d_svhn_loss: 0.0193, d_fake_loss: 0.0210, g_loss: 1.1765\n",
            "Step [55310/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0030, d_svhn_loss: 0.0654, d_fake_loss: 0.0269, g_loss: 1.1774\n",
            "Step [55320/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0028, d_svhn_loss: 0.0325, d_fake_loss: 0.0258, g_loss: 1.2199\n",
            "Step [55330/80000], d_real_loss: 0.0179, d_mnist_loss: 0.0025, d_svhn_loss: 0.0153, d_fake_loss: 0.0575, g_loss: 1.2456\n",
            "Step [55340/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0118, d_svhn_loss: 0.0498, d_fake_loss: 0.0650, g_loss: 1.1573\n",
            "Step [55350/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0021, d_svhn_loss: 0.0196, d_fake_loss: 0.0168, g_loss: 1.1624\n",
            "Step [55360/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0051, d_svhn_loss: 0.0375, d_fake_loss: 0.0212, g_loss: 1.2605\n",
            "Step [55370/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0023, d_svhn_loss: 0.0521, d_fake_loss: 0.0333, g_loss: 1.0876\n",
            "Step [55380/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0020, d_svhn_loss: 0.0168, d_fake_loss: 0.0302, g_loss: 1.1084\n",
            "Step [55390/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0026, d_svhn_loss: 0.0287, d_fake_loss: 0.0382, g_loss: 1.1847\n",
            "Step [55400/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0069, d_svhn_loss: 0.0148, d_fake_loss: 0.0397, g_loss: 1.1169\n",
            "Step [55410/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0027, d_svhn_loss: 0.0360, d_fake_loss: 0.0281, g_loss: 1.1587\n",
            "Step [55420/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0028, d_svhn_loss: 0.0563, d_fake_loss: 0.0789, g_loss: 1.1669\n",
            "Step [55430/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0051, d_svhn_loss: 0.0493, d_fake_loss: 0.0134, g_loss: 1.1731\n",
            "Step [55440/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0036, d_svhn_loss: 0.0328, d_fake_loss: 0.0459, g_loss: 1.2247\n",
            "Step [55450/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0029, d_svhn_loss: 0.0257, d_fake_loss: 0.0289, g_loss: 1.1172\n",
            "Step [55460/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0054, d_svhn_loss: 0.0273, d_fake_loss: 0.0220, g_loss: 1.1034\n",
            "Step [55470/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0128, d_svhn_loss: 0.0222, d_fake_loss: 0.0529, g_loss: 1.2772\n",
            "Step [55480/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0027, d_svhn_loss: 0.0426, d_fake_loss: 0.0249, g_loss: 1.1404\n",
            "Step [55490/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0105, d_svhn_loss: 0.0206, d_fake_loss: 0.0196, g_loss: 1.2321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [55500/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0028, d_svhn_loss: 0.0300, d_fake_loss: 0.1687, g_loss: 1.2029\n",
            "saved ./samples_mnist_svhn/sample-55500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-55500-s-m.png\n",
            "Step [55510/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0078, d_svhn_loss: 0.0397, d_fake_loss: 0.0348, g_loss: 1.2646\n",
            "Step [55520/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0029, d_svhn_loss: 0.0269, d_fake_loss: 0.0765, g_loss: 1.3527\n",
            "Step [55530/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0028, d_svhn_loss: 0.0226, d_fake_loss: 0.0266, g_loss: 1.0771\n",
            "Step [55540/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0140, d_svhn_loss: 0.0281, d_fake_loss: 0.1286, g_loss: 1.2165\n",
            "Step [55550/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0048, d_svhn_loss: 0.0204, d_fake_loss: 0.0223, g_loss: 1.2424\n",
            "Step [55560/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0045, d_svhn_loss: 0.0201, d_fake_loss: 0.0163, g_loss: 1.1920\n",
            "Step [55570/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0034, d_svhn_loss: 0.0204, d_fake_loss: 0.0601, g_loss: 1.1450\n",
            "Step [55580/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0032, d_svhn_loss: 0.0252, d_fake_loss: 0.0907, g_loss: 1.1761\n",
            "Step [55590/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0040, d_svhn_loss: 0.0472, d_fake_loss: 0.0197, g_loss: 1.2444\n",
            "Step [55600/80000], d_real_loss: 0.0850, d_mnist_loss: 0.0021, d_svhn_loss: 0.0830, d_fake_loss: 0.0197, g_loss: 1.1725\n",
            "Step [55610/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0071, d_svhn_loss: 0.0145, d_fake_loss: 0.0659, g_loss: 1.2248\n",
            "Step [55620/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0043, d_svhn_loss: 0.0210, d_fake_loss: 0.0145, g_loss: 1.1915\n",
            "Step [55630/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0055, d_svhn_loss: 0.0217, d_fake_loss: 0.0193, g_loss: 1.1992\n",
            "Step [55640/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0153, d_svhn_loss: 0.0379, d_fake_loss: 0.0584, g_loss: 1.1385\n",
            "Step [55650/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0161, d_svhn_loss: 0.0207, d_fake_loss: 0.0542, g_loss: 1.0213\n",
            "Step [55660/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0036, d_svhn_loss: 0.0297, d_fake_loss: 0.0742, g_loss: 1.3715\n",
            "Step [55670/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0061, d_svhn_loss: 0.0185, d_fake_loss: 0.0602, g_loss: 1.3674\n",
            "Step [55680/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0098, d_svhn_loss: 0.0185, d_fake_loss: 0.0286, g_loss: 1.3265\n",
            "Step [55690/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0071, d_svhn_loss: 0.0584, d_fake_loss: 0.0420, g_loss: 1.1528\n",
            "Step [55700/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0068, d_svhn_loss: 0.0310, d_fake_loss: 0.0806, g_loss: 1.1300\n",
            "Step [55710/80000], d_real_loss: 0.0744, d_mnist_loss: 0.0104, d_svhn_loss: 0.0639, d_fake_loss: 0.0350, g_loss: 1.0549\n",
            "Step [55720/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0042, d_svhn_loss: 0.0270, d_fake_loss: 0.0243, g_loss: 1.2177\n",
            "Step [55730/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0076, d_svhn_loss: 0.0188, d_fake_loss: 0.0346, g_loss: 1.0235\n",
            "Step [55740/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0019, d_svhn_loss: 0.0175, d_fake_loss: 0.0240, g_loss: 1.1811\n",
            "Step [55750/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0031, d_svhn_loss: 0.0423, d_fake_loss: 0.0140, g_loss: 1.1329\n",
            "Step [55760/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0067, d_svhn_loss: 0.0198, d_fake_loss: 0.0571, g_loss: 1.2927\n",
            "Step [55770/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0042, d_svhn_loss: 0.0307, d_fake_loss: 0.0242, g_loss: 1.1925\n",
            "Step [55780/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0065, d_svhn_loss: 0.0206, d_fake_loss: 0.0243, g_loss: 1.1538\n",
            "Step [55790/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0030, d_svhn_loss: 0.0351, d_fake_loss: 0.0344, g_loss: 1.1627\n",
            "Step [55800/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0066, d_svhn_loss: 0.0195, d_fake_loss: 0.0839, g_loss: 1.1396\n",
            "Step [55810/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0041, d_svhn_loss: 0.0586, d_fake_loss: 0.0219, g_loss: 1.2445\n",
            "Step [55820/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0065, d_svhn_loss: 0.0542, d_fake_loss: 0.0157, g_loss: 1.1343\n",
            "Step [55830/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0120, d_svhn_loss: 0.0468, d_fake_loss: 0.0590, g_loss: 1.1433\n",
            "Step [55840/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0083, d_svhn_loss: 0.0152, d_fake_loss: 0.0141, g_loss: 1.1620\n",
            "Step [55850/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0065, d_svhn_loss: 0.0147, d_fake_loss: 0.0319, g_loss: 1.0609\n",
            "Step [55860/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0070, d_svhn_loss: 0.0272, d_fake_loss: 0.0252, g_loss: 1.0761\n",
            "Step [55870/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0044, d_svhn_loss: 0.0230, d_fake_loss: 0.0235, g_loss: 1.0880\n",
            "Step [55880/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0030, d_svhn_loss: 0.0208, d_fake_loss: 0.0482, g_loss: 1.1801\n",
            "Step [55890/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0038, d_svhn_loss: 0.0199, d_fake_loss: 0.0427, g_loss: 1.0986\n",
            "Step [55900/80000], d_real_loss: 0.1219, d_mnist_loss: 0.0031, d_svhn_loss: 0.1188, d_fake_loss: 0.0480, g_loss: 1.0714\n",
            "Step [55910/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0080, d_svhn_loss: 0.0226, d_fake_loss: 0.0323, g_loss: 1.2231\n",
            "Step [55920/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0033, d_svhn_loss: 0.0261, d_fake_loss: 0.0304, g_loss: 1.2889\n",
            "Step [55930/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0035, d_svhn_loss: 0.0262, d_fake_loss: 0.0197, g_loss: 1.2060\n",
            "Step [55940/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0029, d_svhn_loss: 0.0295, d_fake_loss: 0.0674, g_loss: 1.1655\n",
            "Step [55950/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0029, d_svhn_loss: 0.0277, d_fake_loss: 0.0187, g_loss: 1.1357\n",
            "Step [55960/80000], d_real_loss: 0.0147, d_mnist_loss: 0.0025, d_svhn_loss: 0.0123, d_fake_loss: 0.0219, g_loss: 1.1802\n",
            "Step [55970/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0033, d_svhn_loss: 0.0580, d_fake_loss: 0.0239, g_loss: 1.2397\n",
            "Step [55980/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0039, d_svhn_loss: 0.0365, d_fake_loss: 0.0428, g_loss: 1.0901\n",
            "Step [55990/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0045, d_svhn_loss: 0.0490, d_fake_loss: 0.0331, g_loss: 1.1908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [56000/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0034, d_svhn_loss: 0.0282, d_fake_loss: 0.1482, g_loss: 1.1189\n",
            "saved ./samples_mnist_svhn/sample-56000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-56000-s-m.png\n",
            "Step [56010/80000], d_real_loss: 0.1683, d_mnist_loss: 0.0046, d_svhn_loss: 0.1637, d_fake_loss: 0.0168, g_loss: 1.1378\n",
            "Step [56020/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0055, d_svhn_loss: 0.0331, d_fake_loss: 0.0386, g_loss: 1.1897\n",
            "Step [56030/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0034, d_svhn_loss: 0.0255, d_fake_loss: 0.0230, g_loss: 1.1520\n",
            "Step [56040/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0056, d_svhn_loss: 0.0276, d_fake_loss: 0.0365, g_loss: 1.0994\n",
            "Step [56050/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0048, d_svhn_loss: 0.0291, d_fake_loss: 0.0308, g_loss: 1.1482\n",
            "Step [56060/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0039, d_svhn_loss: 0.0490, d_fake_loss: 0.0211, g_loss: 1.1507\n",
            "Step [56070/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0048, d_svhn_loss: 0.0237, d_fake_loss: 0.0167, g_loss: 1.0992\n",
            "Step [56080/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0047, d_svhn_loss: 0.0197, d_fake_loss: 0.0168, g_loss: 1.1625\n",
            "Step [56090/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0030, d_svhn_loss: 0.0509, d_fake_loss: 0.0204, g_loss: 1.1370\n",
            "Step [56100/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0038, d_svhn_loss: 0.0240, d_fake_loss: 0.0622, g_loss: 1.1416\n",
            "Step [56110/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0026, d_svhn_loss: 0.0334, d_fake_loss: 0.0145, g_loss: 1.1916\n",
            "Step [56120/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0027, d_svhn_loss: 0.0439, d_fake_loss: 0.0548, g_loss: 1.1696\n",
            "Step [56130/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0027, d_svhn_loss: 0.0642, d_fake_loss: 0.0586, g_loss: 1.1618\n",
            "Step [56140/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0039, d_svhn_loss: 0.0228, d_fake_loss: 0.1117, g_loss: 1.1215\n",
            "Step [56150/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0095, d_svhn_loss: 0.0400, d_fake_loss: 0.1347, g_loss: 1.2104\n",
            "Step [56160/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0029, d_svhn_loss: 0.0383, d_fake_loss: 0.0206, g_loss: 1.2828\n",
            "Step [56170/80000], d_real_loss: 0.0184, d_mnist_loss: 0.0037, d_svhn_loss: 0.0147, d_fake_loss: 0.0362, g_loss: 1.2581\n",
            "Step [56180/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0078, d_svhn_loss: 0.0173, d_fake_loss: 0.0254, g_loss: 1.1457\n",
            "Step [56190/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0077, d_svhn_loss: 0.0344, d_fake_loss: 0.0158, g_loss: 1.2683\n",
            "Step [56200/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0042, d_svhn_loss: 0.0240, d_fake_loss: 0.0733, g_loss: 1.2695\n",
            "Step [56210/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0045, d_svhn_loss: 0.0159, d_fake_loss: 0.0544, g_loss: 1.1636\n",
            "Step [56220/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0026, d_svhn_loss: 0.0237, d_fake_loss: 0.0307, g_loss: 1.2540\n",
            "Step [56230/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0062, d_svhn_loss: 0.0148, d_fake_loss: 0.0454, g_loss: 1.2172\n",
            "Step [56240/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0216, d_svhn_loss: 0.0157, d_fake_loss: 0.0170, g_loss: 1.2833\n",
            "Step [56250/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0053, d_svhn_loss: 0.0211, d_fake_loss: 0.0571, g_loss: 1.1805\n",
            "Step [56260/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0044, d_svhn_loss: 0.0606, d_fake_loss: 0.0146, g_loss: 1.0745\n",
            "Step [56270/80000], d_real_loss: 0.0797, d_mnist_loss: 0.0041, d_svhn_loss: 0.0756, d_fake_loss: 0.0121, g_loss: 1.1440\n",
            "Step [56280/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0123, d_svhn_loss: 0.0174, d_fake_loss: 0.0343, g_loss: 1.2343\n",
            "Step [56290/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0021, d_svhn_loss: 0.0293, d_fake_loss: 0.0179, g_loss: 1.1567\n",
            "Step [56300/80000], d_real_loss: 0.0143, d_mnist_loss: 0.0046, d_svhn_loss: 0.0097, d_fake_loss: 0.0412, g_loss: 1.1621\n",
            "Step [56310/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0030, d_svhn_loss: 0.0453, d_fake_loss: 0.0247, g_loss: 1.1541\n",
            "Step [56320/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0073, d_svhn_loss: 0.0381, d_fake_loss: 0.0160, g_loss: 1.1621\n",
            "Step [56330/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0034, d_svhn_loss: 0.0251, d_fake_loss: 0.1286, g_loss: 1.0505\n",
            "Step [56340/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0041, d_svhn_loss: 0.0536, d_fake_loss: 0.0478, g_loss: 1.2191\n",
            "Step [56350/80000], d_real_loss: 0.1477, d_mnist_loss: 0.0038, d_svhn_loss: 0.1439, d_fake_loss: 0.0872, g_loss: 1.0925\n",
            "Step [56360/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0155, d_svhn_loss: 0.0538, d_fake_loss: 0.0205, g_loss: 1.2335\n",
            "Step [56370/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0032, d_svhn_loss: 0.0496, d_fake_loss: 0.0439, g_loss: 1.0640\n",
            "Step [56380/80000], d_real_loss: 0.1268, d_mnist_loss: 0.0034, d_svhn_loss: 0.1233, d_fake_loss: 0.0186, g_loss: 1.1555\n",
            "Step [56390/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0095, d_svhn_loss: 0.0319, d_fake_loss: 0.0342, g_loss: 1.1574\n",
            "Step [56400/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0051, d_svhn_loss: 0.0497, d_fake_loss: 0.0225, g_loss: 1.0983\n",
            "Step [56410/80000], d_real_loss: 0.1206, d_mnist_loss: 0.0347, d_svhn_loss: 0.0858, d_fake_loss: 0.0381, g_loss: 1.0776\n",
            "Step [56420/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0040, d_svhn_loss: 0.0323, d_fake_loss: 0.0136, g_loss: 1.1511\n",
            "Step [56430/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0101, d_svhn_loss: 0.0308, d_fake_loss: 0.0291, g_loss: 1.1981\n",
            "Step [56440/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0085, d_svhn_loss: 0.0189, d_fake_loss: 0.0399, g_loss: 1.2532\n",
            "Step [56450/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0025, d_svhn_loss: 0.0216, d_fake_loss: 0.0359, g_loss: 1.1742\n",
            "Step [56460/80000], d_real_loss: 0.1068, d_mnist_loss: 0.0027, d_svhn_loss: 0.1041, d_fake_loss: 0.0784, g_loss: 1.1393\n",
            "Step [56470/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0044, d_svhn_loss: 0.0225, d_fake_loss: 0.1056, g_loss: 1.0144\n",
            "Step [56480/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0046, d_svhn_loss: 0.0273, d_fake_loss: 0.1026, g_loss: 1.0977\n",
            "Step [56490/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0069, d_svhn_loss: 0.0419, d_fake_loss: 0.0283, g_loss: 1.1473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [56500/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0060, d_svhn_loss: 0.0274, d_fake_loss: 0.0119, g_loss: 1.1929\n",
            "saved ./samples_mnist_svhn/sample-56500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-56500-s-m.png\n",
            "Step [56510/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0040, d_svhn_loss: 0.0290, d_fake_loss: 0.0186, g_loss: 1.1327\n",
            "Step [56520/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0089, d_svhn_loss: 0.0210, d_fake_loss: 0.2144, g_loss: 1.2553\n",
            "Step [56530/80000], d_real_loss: 0.0754, d_mnist_loss: 0.0250, d_svhn_loss: 0.0505, d_fake_loss: 0.0348, g_loss: 1.2375\n",
            "Step [56540/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0164, d_svhn_loss: 0.0193, d_fake_loss: 0.0279, g_loss: 1.1705\n",
            "Step [56550/80000], d_real_loss: 0.0961, d_mnist_loss: 0.0029, d_svhn_loss: 0.0932, d_fake_loss: 0.1828, g_loss: 1.0805\n",
            "Step [56560/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0080, d_svhn_loss: 0.0331, d_fake_loss: 0.0296, g_loss: 1.1039\n",
            "Step [56570/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0026, d_svhn_loss: 0.0180, d_fake_loss: 0.0367, g_loss: 1.2388\n",
            "Step [56580/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0130, d_svhn_loss: 0.0356, d_fake_loss: 0.0509, g_loss: 1.2543\n",
            "Step [56590/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0031, d_svhn_loss: 0.0186, d_fake_loss: 0.0210, g_loss: 1.1174\n",
            "Step [56600/80000], d_real_loss: 0.1040, d_mnist_loss: 0.0106, d_svhn_loss: 0.0934, d_fake_loss: 0.0904, g_loss: 1.1155\n",
            "Step [56610/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0092, d_svhn_loss: 0.0207, d_fake_loss: 0.0171, g_loss: 1.1988\n",
            "Step [56620/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0095, d_svhn_loss: 0.0165, d_fake_loss: 0.0211, g_loss: 1.0641\n",
            "Step [56630/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0044, d_svhn_loss: 0.0265, d_fake_loss: 0.0248, g_loss: 1.1965\n",
            "Step [56640/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0028, d_svhn_loss: 0.0158, d_fake_loss: 0.0282, g_loss: 1.3073\n",
            "Step [56650/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0027, d_svhn_loss: 0.0237, d_fake_loss: 0.0642, g_loss: 1.1312\n",
            "Step [56660/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0043, d_svhn_loss: 0.0355, d_fake_loss: 0.0584, g_loss: 1.2220\n",
            "Step [56670/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0036, d_svhn_loss: 0.0319, d_fake_loss: 0.0445, g_loss: 1.0806\n",
            "Step [56680/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0043, d_svhn_loss: 0.0167, d_fake_loss: 0.0532, g_loss: 1.1810\n",
            "Step [56690/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0033, d_svhn_loss: 0.0620, d_fake_loss: 0.0373, g_loss: 1.2873\n",
            "Step [56700/80000], d_real_loss: 0.1069, d_mnist_loss: 0.0031, d_svhn_loss: 0.1038, d_fake_loss: 0.0168, g_loss: 1.1012\n",
            "Step [56710/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0056, d_svhn_loss: 0.0245, d_fake_loss: 0.0530, g_loss: 1.0100\n",
            "Step [56720/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0023, d_svhn_loss: 0.0819, d_fake_loss: 0.0231, g_loss: 1.1959\n",
            "Step [56730/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0029, d_svhn_loss: 0.0465, d_fake_loss: 0.1717, g_loss: 1.1736\n",
            "Step [56740/80000], d_real_loss: 0.1074, d_mnist_loss: 0.0061, d_svhn_loss: 0.1013, d_fake_loss: 0.0273, g_loss: 1.2467\n",
            "Step [56750/80000], d_real_loss: 0.0895, d_mnist_loss: 0.0103, d_svhn_loss: 0.0791, d_fake_loss: 0.0815, g_loss: 1.1276\n",
            "Step [56760/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0036, d_svhn_loss: 0.0449, d_fake_loss: 0.0271, g_loss: 1.2280\n",
            "Step [56770/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0026, d_svhn_loss: 0.0219, d_fake_loss: 0.0239, g_loss: 1.1530\n",
            "Step [56780/80000], d_real_loss: 0.0695, d_mnist_loss: 0.0039, d_svhn_loss: 0.0656, d_fake_loss: 0.0386, g_loss: 1.1395\n",
            "Step [56790/80000], d_real_loss: 0.0978, d_mnist_loss: 0.0024, d_svhn_loss: 0.0954, d_fake_loss: 0.1068, g_loss: 1.1344\n",
            "Step [56800/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0048, d_svhn_loss: 0.0305, d_fake_loss: 0.0197, g_loss: 1.1230\n",
            "Step [56810/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0115, d_svhn_loss: 0.0290, d_fake_loss: 0.0762, g_loss: 1.1113\n",
            "Step [56820/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0048, d_svhn_loss: 0.0177, d_fake_loss: 0.0223, g_loss: 1.1444\n",
            "Step [56830/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0043, d_svhn_loss: 0.0363, d_fake_loss: 0.0481, g_loss: 1.2895\n",
            "Step [56840/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0047, d_svhn_loss: 0.0217, d_fake_loss: 0.0457, g_loss: 1.1637\n",
            "Step [56850/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0047, d_svhn_loss: 0.0254, d_fake_loss: 0.0227, g_loss: 1.2201\n",
            "Step [56860/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0063, d_svhn_loss: 0.0222, d_fake_loss: 0.0205, g_loss: 1.2050\n",
            "Step [56870/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0072, d_svhn_loss: 0.0282, d_fake_loss: 0.0277, g_loss: 1.0982\n",
            "Step [56880/80000], d_real_loss: 0.0145, d_mnist_loss: 0.0033, d_svhn_loss: 0.0112, d_fake_loss: 0.0150, g_loss: 1.1918\n",
            "Step [56890/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0043, d_svhn_loss: 0.0231, d_fake_loss: 0.0351, g_loss: 1.1640\n",
            "Step [56900/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0073, d_svhn_loss: 0.0256, d_fake_loss: 0.0679, g_loss: 1.1869\n",
            "Step [56910/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0038, d_svhn_loss: 0.0270, d_fake_loss: 0.0531, g_loss: 1.1926\n",
            "Step [56920/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0032, d_svhn_loss: 0.0629, d_fake_loss: 0.0591, g_loss: 1.1246\n",
            "Step [56930/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0033, d_svhn_loss: 0.0240, d_fake_loss: 0.1378, g_loss: 1.0823\n",
            "Step [56940/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0034, d_svhn_loss: 0.0242, d_fake_loss: 0.0553, g_loss: 1.0147\n",
            "Step [56950/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0025, d_svhn_loss: 0.0232, d_fake_loss: 0.0269, g_loss: 1.1700\n",
            "Step [56960/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0021, d_svhn_loss: 0.0346, d_fake_loss: 0.0324, g_loss: 1.1370\n",
            "Step [56970/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0058, d_svhn_loss: 0.0164, d_fake_loss: 0.0373, g_loss: 1.1947\n",
            "Step [56980/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0215, d_svhn_loss: 0.0351, d_fake_loss: 0.0388, g_loss: 1.1665\n",
            "Step [56990/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0042, d_svhn_loss: 0.0191, d_fake_loss: 0.0299, g_loss: 1.1283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [57000/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0041, d_svhn_loss: 0.0154, d_fake_loss: 0.0376, g_loss: 1.3218\n",
            "saved ./samples_mnist_svhn/sample-57000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-57000-s-m.png\n",
            "Step [57010/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0042, d_svhn_loss: 0.0316, d_fake_loss: 0.0321, g_loss: 1.2324\n",
            "Step [57020/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0041, d_svhn_loss: 0.0331, d_fake_loss: 0.0788, g_loss: 1.3757\n",
            "Step [57030/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0160, d_svhn_loss: 0.0540, d_fake_loss: 0.0529, g_loss: 1.1442\n",
            "Step [57040/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0116, d_svhn_loss: 0.0212, d_fake_loss: 0.0196, g_loss: 1.2178\n",
            "Step [57050/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0044, d_svhn_loss: 0.0191, d_fake_loss: 0.0338, g_loss: 1.2125\n",
            "Step [57060/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0046, d_svhn_loss: 0.0215, d_fake_loss: 0.0180, g_loss: 1.0938\n",
            "Step [57070/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0030, d_svhn_loss: 0.0567, d_fake_loss: 0.0224, g_loss: 1.0994\n",
            "Step [57080/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0103, d_svhn_loss: 0.0206, d_fake_loss: 0.0273, g_loss: 1.0634\n",
            "Step [57090/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0037, d_svhn_loss: 0.0386, d_fake_loss: 0.0544, g_loss: 1.2024\n",
            "Step [57100/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0047, d_svhn_loss: 0.0183, d_fake_loss: 0.0292, g_loss: 1.1926\n",
            "Step [57110/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0031, d_svhn_loss: 0.0575, d_fake_loss: 0.0547, g_loss: 1.1384\n",
            "Step [57120/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0068, d_svhn_loss: 0.0153, d_fake_loss: 0.0349, g_loss: 1.3210\n",
            "Step [57130/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0067, d_svhn_loss: 0.0187, d_fake_loss: 0.0670, g_loss: 1.0965\n",
            "Step [57140/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0266, d_svhn_loss: 0.0166, d_fake_loss: 0.0598, g_loss: 1.0047\n",
            "Step [57150/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0076, d_svhn_loss: 0.0274, d_fake_loss: 0.0525, g_loss: 1.0924\n",
            "Step [57160/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0029, d_svhn_loss: 0.0149, d_fake_loss: 0.0537, g_loss: 1.1290\n",
            "Step [57170/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0048, d_svhn_loss: 0.0317, d_fake_loss: 0.0195, g_loss: 1.1867\n",
            "Step [57180/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0048, d_svhn_loss: 0.0624, d_fake_loss: 0.1051, g_loss: 1.2869\n",
            "Step [57190/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0040, d_svhn_loss: 0.0155, d_fake_loss: 0.0308, g_loss: 1.2130\n",
            "Step [57200/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0033, d_svhn_loss: 0.0588, d_fake_loss: 0.0447, g_loss: 1.2215\n",
            "Step [57210/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0042, d_svhn_loss: 0.0293, d_fake_loss: 0.0291, g_loss: 1.2430\n",
            "Step [57220/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0079, d_svhn_loss: 0.0648, d_fake_loss: 0.0422, g_loss: 1.2782\n",
            "Step [57230/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0031, d_svhn_loss: 0.0173, d_fake_loss: 0.0267, g_loss: 1.2174\n",
            "Step [57240/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0073, d_svhn_loss: 0.0261, d_fake_loss: 0.0704, g_loss: 1.1076\n",
            "Step [57250/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0060, d_svhn_loss: 0.0165, d_fake_loss: 0.0273, g_loss: 1.1786\n",
            "Step [57260/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0065, d_svhn_loss: 0.0178, d_fake_loss: 0.0163, g_loss: 1.2138\n",
            "Step [57270/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0030, d_svhn_loss: 0.0257, d_fake_loss: 0.0530, g_loss: 1.2064\n",
            "Step [57280/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0030, d_svhn_loss: 0.0207, d_fake_loss: 0.0390, g_loss: 1.1280\n",
            "Step [57290/80000], d_real_loss: 0.0821, d_mnist_loss: 0.0045, d_svhn_loss: 0.0776, d_fake_loss: 0.0856, g_loss: 1.1002\n",
            "Step [57300/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0127, d_svhn_loss: 0.0194, d_fake_loss: 0.0247, g_loss: 1.0628\n",
            "Step [57310/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0120, d_svhn_loss: 0.0386, d_fake_loss: 0.0396, g_loss: 1.1682\n",
            "Step [57320/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0026, d_svhn_loss: 0.0554, d_fake_loss: 0.0362, g_loss: 1.2152\n",
            "Step [57330/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0032, d_svhn_loss: 0.0365, d_fake_loss: 0.0465, g_loss: 1.1017\n",
            "Step [57340/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0072, d_svhn_loss: 0.0231, d_fake_loss: 0.0203, g_loss: 1.2036\n",
            "Step [57350/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0071, d_svhn_loss: 0.0324, d_fake_loss: 0.0328, g_loss: 1.1187\n",
            "Step [57360/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0064, d_svhn_loss: 0.0264, d_fake_loss: 0.0169, g_loss: 1.1652\n",
            "Step [57370/80000], d_real_loss: 0.0705, d_mnist_loss: 0.0059, d_svhn_loss: 0.0645, d_fake_loss: 0.0288, g_loss: 1.1628\n",
            "Step [57380/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0035, d_svhn_loss: 0.0411, d_fake_loss: 0.0924, g_loss: 1.0929\n",
            "Step [57390/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0040, d_svhn_loss: 0.0347, d_fake_loss: 0.0313, g_loss: 1.1599\n",
            "Step [57400/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0029, d_svhn_loss: 0.0684, d_fake_loss: 0.0630, g_loss: 1.1322\n",
            "Step [57410/80000], d_real_loss: 0.0793, d_mnist_loss: 0.0062, d_svhn_loss: 0.0731, d_fake_loss: 0.0393, g_loss: 1.1561\n",
            "Step [57420/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0087, d_svhn_loss: 0.0251, d_fake_loss: 0.0267, g_loss: 1.1027\n",
            "Step [57430/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0064, d_svhn_loss: 0.0236, d_fake_loss: 0.0397, g_loss: 1.1952\n",
            "Step [57440/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0036, d_svhn_loss: 0.0255, d_fake_loss: 0.0392, g_loss: 1.1223\n",
            "Step [57450/80000], d_real_loss: 0.1113, d_mnist_loss: 0.0023, d_svhn_loss: 0.1090, d_fake_loss: 0.0258, g_loss: 1.1599\n",
            "Step [57460/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0037, d_svhn_loss: 0.0213, d_fake_loss: 0.0287, g_loss: 1.2155\n",
            "Step [57470/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0025, d_svhn_loss: 0.0263, d_fake_loss: 0.0198, g_loss: 1.1999\n",
            "Step [57480/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0156, d_svhn_loss: 0.0227, d_fake_loss: 0.0239, g_loss: 1.1747\n",
            "Step [57490/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0046, d_svhn_loss: 0.0416, d_fake_loss: 0.0213, g_loss: 1.1701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [57500/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0073, d_svhn_loss: 0.0215, d_fake_loss: 0.0291, g_loss: 1.2362\n",
            "saved ./samples_mnist_svhn/sample-57500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-57500-s-m.png\n",
            "Step [57510/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0021, d_svhn_loss: 0.0373, d_fake_loss: 0.0308, g_loss: 1.1233\n",
            "Step [57520/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0070, d_svhn_loss: 0.0197, d_fake_loss: 0.0379, g_loss: 1.1337\n",
            "Step [57530/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0062, d_svhn_loss: 0.0158, d_fake_loss: 0.0171, g_loss: 1.1434\n",
            "Step [57540/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0033, d_svhn_loss: 0.0222, d_fake_loss: 0.0696, g_loss: 1.2684\n",
            "Step [57550/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0029, d_svhn_loss: 0.0405, d_fake_loss: 0.0476, g_loss: 1.0807\n",
            "Step [57560/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0034, d_svhn_loss: 0.0228, d_fake_loss: 0.0572, g_loss: 1.3076\n",
            "Step [57570/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0036, d_svhn_loss: 0.0397, d_fake_loss: 0.0660, g_loss: 1.1303\n",
            "Step [57580/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0027, d_svhn_loss: 0.0605, d_fake_loss: 0.0563, g_loss: 1.1882\n",
            "Step [57590/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0037, d_svhn_loss: 0.0176, d_fake_loss: 0.0432, g_loss: 1.1610\n",
            "Step [57600/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0220, d_svhn_loss: 0.0291, d_fake_loss: 0.0188, g_loss: 1.0932\n",
            "Step [57610/80000], d_real_loss: 0.1077, d_mnist_loss: 0.0042, d_svhn_loss: 0.1035, d_fake_loss: 0.0573, g_loss: 1.1550\n",
            "Step [57620/80000], d_real_loss: 0.0171, d_mnist_loss: 0.0023, d_svhn_loss: 0.0148, d_fake_loss: 0.0334, g_loss: 1.2005\n",
            "Step [57630/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0042, d_svhn_loss: 0.0312, d_fake_loss: 0.0222, g_loss: 1.1213\n",
            "Step [57640/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0126, d_svhn_loss: 0.0505, d_fake_loss: 0.0727, g_loss: 1.1392\n",
            "Step [57650/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0046, d_svhn_loss: 0.0742, d_fake_loss: 0.1344, g_loss: 1.2161\n",
            "Step [57660/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0069, d_svhn_loss: 0.0370, d_fake_loss: 0.0271, g_loss: 1.1965\n",
            "Step [57670/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0047, d_svhn_loss: 0.0344, d_fake_loss: 0.0299, g_loss: 1.0661\n",
            "Step [57680/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0064, d_svhn_loss: 0.0323, d_fake_loss: 0.0289, g_loss: 1.1157\n",
            "Step [57690/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0039, d_svhn_loss: 0.0407, d_fake_loss: 0.0224, g_loss: 1.1264\n",
            "Step [57700/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0042, d_svhn_loss: 0.0601, d_fake_loss: 0.0218, g_loss: 1.1232\n",
            "Step [57710/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0023, d_svhn_loss: 0.0307, d_fake_loss: 0.0477, g_loss: 1.1062\n",
            "Step [57720/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0033, d_svhn_loss: 0.0378, d_fake_loss: 0.0221, g_loss: 1.1580\n",
            "Step [57730/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0039, d_svhn_loss: 0.0197, d_fake_loss: 0.0348, g_loss: 1.1918\n",
            "Step [57740/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0023, d_svhn_loss: 0.0229, d_fake_loss: 0.0249, g_loss: 1.1492\n",
            "Step [57750/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0138, d_svhn_loss: 0.0325, d_fake_loss: 0.0550, g_loss: 1.1136\n",
            "Step [57760/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0034, d_svhn_loss: 0.0462, d_fake_loss: 0.0302, g_loss: 1.2146\n",
            "Step [57770/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0027, d_svhn_loss: 0.0265, d_fake_loss: 0.0400, g_loss: 1.1500\n",
            "Step [57780/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0046, d_svhn_loss: 0.0256, d_fake_loss: 0.1042, g_loss: 1.1962\n",
            "Step [57790/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0044, d_svhn_loss: 0.0461, d_fake_loss: 0.0217, g_loss: 1.0443\n",
            "Step [57800/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0032, d_svhn_loss: 0.0523, d_fake_loss: 0.0289, g_loss: 1.2288\n",
            "Step [57810/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0056, d_svhn_loss: 0.0820, d_fake_loss: 0.1222, g_loss: 1.1772\n",
            "Step [57820/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0029, d_svhn_loss: 0.0172, d_fake_loss: 0.0462, g_loss: 1.1367\n",
            "Step [57830/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0036, d_svhn_loss: 0.0357, d_fake_loss: 0.0250, g_loss: 1.0551\n",
            "Step [57840/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0051, d_svhn_loss: 0.0472, d_fake_loss: 0.0778, g_loss: 1.0471\n",
            "Step [57850/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0027, d_svhn_loss: 0.0407, d_fake_loss: 0.1200, g_loss: 1.1703\n",
            "Step [57860/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0064, d_svhn_loss: 0.0480, d_fake_loss: 0.0500, g_loss: 1.2265\n",
            "Step [57870/80000], d_real_loss: 0.1440, d_mnist_loss: 0.0032, d_svhn_loss: 0.1408, d_fake_loss: 0.0345, g_loss: 1.1242\n",
            "Step [57880/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0040, d_svhn_loss: 0.0220, d_fake_loss: 0.0214, g_loss: 1.1636\n",
            "Step [57890/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0066, d_svhn_loss: 0.0712, d_fake_loss: 0.0378, g_loss: 1.1709\n",
            "Step [57900/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0028, d_svhn_loss: 0.0307, d_fake_loss: 0.1174, g_loss: 1.1605\n",
            "Step [57910/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0056, d_svhn_loss: 0.0500, d_fake_loss: 0.0286, g_loss: 1.2165\n",
            "Step [57920/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0022, d_svhn_loss: 0.0225, d_fake_loss: 0.0160, g_loss: 1.0982\n",
            "Step [57930/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0038, d_svhn_loss: 0.0239, d_fake_loss: 0.0251, g_loss: 1.0918\n",
            "Step [57940/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0031, d_svhn_loss: 0.0460, d_fake_loss: 0.0304, g_loss: 1.0854\n",
            "Step [57950/80000], d_real_loss: 0.0797, d_mnist_loss: 0.0097, d_svhn_loss: 0.0701, d_fake_loss: 0.0749, g_loss: 0.9697\n",
            "Step [57960/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0110, d_svhn_loss: 0.0317, d_fake_loss: 0.1045, g_loss: 1.1788\n",
            "Step [57970/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0066, d_svhn_loss: 0.0607, d_fake_loss: 0.0209, g_loss: 1.1044\n",
            "Step [57980/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0028, d_svhn_loss: 0.0415, d_fake_loss: 0.1150, g_loss: 1.2322\n",
            "Step [57990/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0080, d_svhn_loss: 0.0366, d_fake_loss: 0.0366, g_loss: 1.0939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [58000/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0028, d_svhn_loss: 0.0307, d_fake_loss: 0.0184, g_loss: 1.1734\n",
            "saved ./samples_mnist_svhn/sample-58000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-58000-s-m.png\n",
            "Step [58010/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0030, d_svhn_loss: 0.0879, d_fake_loss: 0.0455, g_loss: 1.1001\n",
            "Step [58020/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0054, d_svhn_loss: 0.0288, d_fake_loss: 0.0196, g_loss: 1.1130\n",
            "Step [58030/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0035, d_svhn_loss: 0.0414, d_fake_loss: 0.0208, g_loss: 1.2091\n",
            "Step [58040/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0031, d_svhn_loss: 0.0422, d_fake_loss: 0.0254, g_loss: 1.0782\n",
            "Step [58050/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0246, d_svhn_loss: 0.0631, d_fake_loss: 0.0296, g_loss: 1.0254\n",
            "Step [58060/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0046, d_svhn_loss: 0.0249, d_fake_loss: 0.0285, g_loss: 1.3218\n",
            "Step [58070/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0139, d_svhn_loss: 0.0476, d_fake_loss: 0.0563, g_loss: 1.0247\n",
            "Step [58080/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0034, d_svhn_loss: 0.0446, d_fake_loss: 0.0367, g_loss: 1.1021\n",
            "Step [58090/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0054, d_svhn_loss: 0.0474, d_fake_loss: 0.0411, g_loss: 1.2549\n",
            "Step [58100/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0044, d_svhn_loss: 0.0475, d_fake_loss: 0.0415, g_loss: 1.1266\n",
            "Step [58110/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0027, d_svhn_loss: 0.0251, d_fake_loss: 0.0302, g_loss: 1.1063\n",
            "Step [58120/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0037, d_svhn_loss: 0.0236, d_fake_loss: 0.0295, g_loss: 1.1800\n",
            "Step [58130/80000], d_real_loss: 0.1052, d_mnist_loss: 0.0037, d_svhn_loss: 0.1015, d_fake_loss: 0.0234, g_loss: 1.2028\n",
            "Step [58140/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0047, d_svhn_loss: 0.0379, d_fake_loss: 0.0688, g_loss: 1.1243\n",
            "Step [58150/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0042, d_svhn_loss: 0.0657, d_fake_loss: 0.0501, g_loss: 1.1245\n",
            "Step [58160/80000], d_real_loss: 0.0193, d_mnist_loss: 0.0028, d_svhn_loss: 0.0165, d_fake_loss: 0.0205, g_loss: 1.1594\n",
            "Step [58170/80000], d_real_loss: 0.1104, d_mnist_loss: 0.0058, d_svhn_loss: 0.1045, d_fake_loss: 0.1142, g_loss: 1.1701\n",
            "Step [58180/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0074, d_svhn_loss: 0.0293, d_fake_loss: 0.0249, g_loss: 1.1233\n",
            "Step [58190/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0041, d_svhn_loss: 0.0313, d_fake_loss: 0.0276, g_loss: 1.1138\n",
            "Step [58200/80000], d_real_loss: 0.1333, d_mnist_loss: 0.0030, d_svhn_loss: 0.1303, d_fake_loss: 0.0973, g_loss: 1.1142\n",
            "Step [58210/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0025, d_svhn_loss: 0.0354, d_fake_loss: 0.0230, g_loss: 1.2406\n",
            "Step [58220/80000], d_real_loss: 0.0150, d_mnist_loss: 0.0034, d_svhn_loss: 0.0116, d_fake_loss: 0.0475, g_loss: 1.1998\n",
            "Step [58230/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0017, d_svhn_loss: 0.0358, d_fake_loss: 0.0671, g_loss: 1.2213\n",
            "Step [58240/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0151, d_svhn_loss: 0.0301, d_fake_loss: 0.1025, g_loss: 1.1984\n",
            "Step [58250/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0025, d_svhn_loss: 0.0307, d_fake_loss: 0.0216, g_loss: 1.2673\n",
            "Step [58260/80000], d_real_loss: 0.0807, d_mnist_loss: 0.0024, d_svhn_loss: 0.0783, d_fake_loss: 0.1105, g_loss: 1.1534\n",
            "Step [58270/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0081, d_svhn_loss: 0.0408, d_fake_loss: 0.0260, g_loss: 1.2659\n",
            "Step [58280/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0051, d_svhn_loss: 0.0189, d_fake_loss: 0.0455, g_loss: 1.2519\n",
            "Step [58290/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0072, d_svhn_loss: 0.0591, d_fake_loss: 0.0262, g_loss: 1.2399\n",
            "Step [58300/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0031, d_svhn_loss: 0.0366, d_fake_loss: 0.2185, g_loss: 1.2695\n",
            "Step [58310/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0037, d_svhn_loss: 0.0155, d_fake_loss: 0.0284, g_loss: 1.2568\n",
            "Step [58320/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0033, d_svhn_loss: 0.0745, d_fake_loss: 0.0223, g_loss: 1.2176\n",
            "Step [58330/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0043, d_svhn_loss: 0.0610, d_fake_loss: 0.0216, g_loss: 1.2936\n",
            "Step [58340/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0038, d_svhn_loss: 0.0571, d_fake_loss: 0.0257, g_loss: 1.1200\n",
            "Step [58350/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0043, d_svhn_loss: 0.0481, d_fake_loss: 0.0329, g_loss: 1.1732\n",
            "Step [58360/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0031, d_svhn_loss: 0.0692, d_fake_loss: 0.0421, g_loss: 1.2051\n",
            "Step [58370/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0042, d_svhn_loss: 0.0701, d_fake_loss: 0.1234, g_loss: 1.0228\n",
            "Step [58380/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0046, d_svhn_loss: 0.0905, d_fake_loss: 0.0434, g_loss: 1.1807\n",
            "Step [58390/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0048, d_svhn_loss: 0.0228, d_fake_loss: 0.0132, g_loss: 1.1659\n",
            "Step [58400/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0036, d_svhn_loss: 0.0275, d_fake_loss: 0.0949, g_loss: 1.1666\n",
            "Step [58410/80000], d_real_loss: 0.1013, d_mnist_loss: 0.0041, d_svhn_loss: 0.0972, d_fake_loss: 0.0479, g_loss: 1.2080\n",
            "Step [58420/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0048, d_svhn_loss: 0.0235, d_fake_loss: 0.0235, g_loss: 1.2023\n",
            "Step [58430/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0058, d_svhn_loss: 0.0547, d_fake_loss: 0.0293, g_loss: 1.1923\n",
            "Step [58440/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0044, d_svhn_loss: 0.0360, d_fake_loss: 0.0334, g_loss: 1.1109\n",
            "Step [58450/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0049, d_svhn_loss: 0.0374, d_fake_loss: 0.0183, g_loss: 1.1322\n",
            "Step [58460/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0023, d_svhn_loss: 0.0220, d_fake_loss: 0.0149, g_loss: 1.1593\n",
            "Step [58470/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0021, d_svhn_loss: 0.0440, d_fake_loss: 0.0192, g_loss: 1.1548\n",
            "Step [58480/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0031, d_svhn_loss: 0.0245, d_fake_loss: 0.0692, g_loss: 1.2211\n",
            "Step [58490/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0040, d_svhn_loss: 0.0352, d_fake_loss: 0.0301, g_loss: 1.0059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [58500/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0075, d_svhn_loss: 0.0364, d_fake_loss: 0.0839, g_loss: 1.1463\n",
            "saved ./samples_mnist_svhn/sample-58500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-58500-s-m.png\n",
            "Step [58510/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0201, d_svhn_loss: 0.0154, d_fake_loss: 0.0585, g_loss: 1.2769\n",
            "Step [58520/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0079, d_svhn_loss: 0.0263, d_fake_loss: 0.0180, g_loss: 1.2032\n",
            "Step [58530/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0041, d_svhn_loss: 0.0567, d_fake_loss: 0.0394, g_loss: 1.0740\n",
            "Step [58540/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0040, d_svhn_loss: 0.0243, d_fake_loss: 0.0173, g_loss: 1.1433\n",
            "Step [58550/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0075, d_svhn_loss: 0.0188, d_fake_loss: 0.0512, g_loss: 1.1099\n",
            "Step [58560/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0035, d_svhn_loss: 0.0370, d_fake_loss: 0.0216, g_loss: 1.1759\n",
            "Step [58570/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0062, d_svhn_loss: 0.0450, d_fake_loss: 0.0749, g_loss: 1.2378\n",
            "Step [58580/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0042, d_svhn_loss: 0.0193, d_fake_loss: 0.0188, g_loss: 1.2296\n",
            "Step [58590/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0092, d_svhn_loss: 0.0162, d_fake_loss: 0.0161, g_loss: 1.2155\n",
            "Step [58600/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0076, d_svhn_loss: 0.0345, d_fake_loss: 0.0407, g_loss: 1.1018\n",
            "Step [58610/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0061, d_svhn_loss: 0.0234, d_fake_loss: 0.0368, g_loss: 1.1473\n",
            "Step [58620/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0105, d_svhn_loss: 0.0274, d_fake_loss: 0.0214, g_loss: 1.1797\n",
            "Step [58630/80000], d_real_loss: 0.0969, d_mnist_loss: 0.0062, d_svhn_loss: 0.0908, d_fake_loss: 0.0301, g_loss: 1.2434\n",
            "Step [58640/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0044, d_svhn_loss: 0.0300, d_fake_loss: 0.0949, g_loss: 1.0601\n",
            "Step [58650/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0070, d_svhn_loss: 0.0132, d_fake_loss: 0.0175, g_loss: 1.1858\n",
            "Step [58660/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0037, d_svhn_loss: 0.0160, d_fake_loss: 0.0155, g_loss: 1.1078\n",
            "Step [58670/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0027, d_svhn_loss: 0.0398, d_fake_loss: 0.0398, g_loss: 1.0566\n",
            "Step [58680/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0039, d_svhn_loss: 0.0198, d_fake_loss: 0.0329, g_loss: 1.1266\n",
            "Step [58690/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0047, d_svhn_loss: 0.0590, d_fake_loss: 0.0294, g_loss: 1.1911\n",
            "Step [58700/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0048, d_svhn_loss: 0.0260, d_fake_loss: 0.0862, g_loss: 1.2386\n",
            "Step [58710/80000], d_real_loss: 0.1355, d_mnist_loss: 0.0047, d_svhn_loss: 0.1307, d_fake_loss: 0.1010, g_loss: 1.1329\n",
            "Step [58720/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0032, d_svhn_loss: 0.0355, d_fake_loss: 0.0471, g_loss: 1.1660\n",
            "Step [58730/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0285, d_svhn_loss: 0.0310, d_fake_loss: 0.0346, g_loss: 1.2127\n",
            "Step [58740/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0053, d_svhn_loss: 0.0256, d_fake_loss: 0.0581, g_loss: 1.1931\n",
            "Step [58750/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0031, d_svhn_loss: 0.0152, d_fake_loss: 0.0332, g_loss: 1.1673\n",
            "Step [58760/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0032, d_svhn_loss: 0.0375, d_fake_loss: 0.0235, g_loss: 1.1087\n",
            "Step [58770/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0025, d_svhn_loss: 0.0736, d_fake_loss: 0.0379, g_loss: 1.1227\n",
            "Step [58780/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0042, d_svhn_loss: 0.0247, d_fake_loss: 0.0231, g_loss: 1.1851\n",
            "Step [58790/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0040, d_svhn_loss: 0.0488, d_fake_loss: 0.1425, g_loss: 1.0908\n",
            "Step [58800/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0043, d_svhn_loss: 0.0282, d_fake_loss: 0.0215, g_loss: 1.1110\n",
            "Step [58810/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0047, d_svhn_loss: 0.0225, d_fake_loss: 0.0227, g_loss: 1.1581\n",
            "Step [58820/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0093, d_svhn_loss: 0.0189, d_fake_loss: 0.0519, g_loss: 1.1171\n",
            "Step [58830/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0033, d_svhn_loss: 0.0321, d_fake_loss: 0.0909, g_loss: 1.1828\n",
            "Step [58840/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0050, d_svhn_loss: 0.0370, d_fake_loss: 0.1014, g_loss: 1.1776\n",
            "Step [58850/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0075, d_svhn_loss: 0.0314, d_fake_loss: 0.0265, g_loss: 1.1704\n",
            "Step [58860/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0023, d_svhn_loss: 0.0520, d_fake_loss: 0.0178, g_loss: 1.1649\n",
            "Step [58870/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0077, d_svhn_loss: 0.0508, d_fake_loss: 0.0241, g_loss: 1.1593\n",
            "Step [58880/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0098, d_svhn_loss: 0.0432, d_fake_loss: 0.0255, g_loss: 1.1383\n",
            "Step [58890/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0026, d_svhn_loss: 0.0319, d_fake_loss: 0.0269, g_loss: 1.1978\n",
            "Step [58900/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0027, d_svhn_loss: 0.0232, d_fake_loss: 0.0228, g_loss: 1.1685\n",
            "Step [58910/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0018, d_svhn_loss: 0.0199, d_fake_loss: 0.0245, g_loss: 1.1192\n",
            "Step [58920/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0017, d_svhn_loss: 0.0416, d_fake_loss: 0.0543, g_loss: 1.1205\n",
            "Step [58930/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0196, d_svhn_loss: 0.0167, d_fake_loss: 0.0264, g_loss: 1.0786\n",
            "Step [58940/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0022, d_svhn_loss: 0.0362, d_fake_loss: 0.0731, g_loss: 1.1522\n",
            "Step [58950/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0035, d_svhn_loss: 0.0247, d_fake_loss: 0.0244, g_loss: 1.1899\n",
            "Step [58960/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0015, d_svhn_loss: 0.0216, d_fake_loss: 0.0743, g_loss: 1.1403\n",
            "Step [58970/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0047, d_svhn_loss: 0.0547, d_fake_loss: 0.0931, g_loss: 1.1293\n",
            "Step [58980/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0083, d_svhn_loss: 0.0214, d_fake_loss: 0.0325, g_loss: 1.1946\n",
            "Step [58990/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0022, d_svhn_loss: 0.0214, d_fake_loss: 0.1177, g_loss: 1.1309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [59000/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0038, d_svhn_loss: 0.0161, d_fake_loss: 0.0366, g_loss: 1.1572\n",
            "saved ./samples_mnist_svhn/sample-59000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-59000-s-m.png\n",
            "Step [59010/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0040, d_svhn_loss: 0.0325, d_fake_loss: 0.0184, g_loss: 1.1600\n",
            "Step [59020/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0069, d_svhn_loss: 0.0170, d_fake_loss: 0.0376, g_loss: 1.1623\n",
            "Step [59030/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0029, d_svhn_loss: 0.0250, d_fake_loss: 0.1110, g_loss: 1.1217\n",
            "Step [59040/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0108, d_svhn_loss: 0.0231, d_fake_loss: 0.0108, g_loss: 1.1411\n",
            "Step [59050/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0055, d_svhn_loss: 0.0200, d_fake_loss: 0.0123, g_loss: 1.1536\n",
            "Step [59060/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0027, d_svhn_loss: 0.0243, d_fake_loss: 0.0526, g_loss: 1.2671\n",
            "Step [59070/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0034, d_svhn_loss: 0.0446, d_fake_loss: 0.0197, g_loss: 1.1554\n",
            "Step [59080/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0022, d_svhn_loss: 0.0274, d_fake_loss: 0.0144, g_loss: 1.2064\n",
            "Step [59090/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0203, d_svhn_loss: 0.0295, d_fake_loss: 0.0188, g_loss: 1.1293\n",
            "Step [59100/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0027, d_svhn_loss: 0.0372, d_fake_loss: 0.0158, g_loss: 1.0998\n",
            "Step [59110/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0063, d_svhn_loss: 0.0392, d_fake_loss: 0.0151, g_loss: 1.2045\n",
            "Step [59120/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0029, d_svhn_loss: 0.0309, d_fake_loss: 0.0261, g_loss: 1.1501\n",
            "Step [59130/80000], d_real_loss: 0.0849, d_mnist_loss: 0.0037, d_svhn_loss: 0.0812, d_fake_loss: 0.0398, g_loss: 1.1711\n",
            "Step [59140/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0038, d_svhn_loss: 0.0772, d_fake_loss: 0.0467, g_loss: 1.3520\n",
            "Step [59150/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0036, d_svhn_loss: 0.0257, d_fake_loss: 0.0428, g_loss: 1.1966\n",
            "Step [59160/80000], d_real_loss: 0.0203, d_mnist_loss: 0.0056, d_svhn_loss: 0.0147, d_fake_loss: 0.0880, g_loss: 1.1560\n",
            "Step [59170/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0039, d_svhn_loss: 0.0802, d_fake_loss: 0.0332, g_loss: 1.1179\n",
            "Step [59180/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0040, d_svhn_loss: 0.0827, d_fake_loss: 0.0182, g_loss: 1.2550\n",
            "Step [59190/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0188, d_svhn_loss: 0.0234, d_fake_loss: 0.1196, g_loss: 1.3948\n",
            "Step [59200/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0095, d_svhn_loss: 0.0233, d_fake_loss: 0.0295, g_loss: 1.4023\n",
            "Step [59210/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0025, d_svhn_loss: 0.0373, d_fake_loss: 0.0241, g_loss: 1.1533\n",
            "Step [59220/80000], d_real_loss: 0.0161, d_mnist_loss: 0.0029, d_svhn_loss: 0.0132, d_fake_loss: 0.1626, g_loss: 1.2314\n",
            "Step [59230/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0050, d_svhn_loss: 0.0285, d_fake_loss: 0.0529, g_loss: 1.2248\n",
            "Step [59240/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0081, d_svhn_loss: 0.0240, d_fake_loss: 0.0260, g_loss: 1.2639\n",
            "Step [59250/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0033, d_svhn_loss: 0.0289, d_fake_loss: 0.1430, g_loss: 1.6884\n",
            "Step [59260/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0062, d_svhn_loss: 0.0543, d_fake_loss: 0.0750, g_loss: 1.3408\n",
            "Step [59270/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0063, d_svhn_loss: 0.0147, d_fake_loss: 0.0193, g_loss: 1.3432\n",
            "Step [59280/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0055, d_svhn_loss: 0.0315, d_fake_loss: 0.0286, g_loss: 1.1216\n",
            "Step [59290/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0049, d_svhn_loss: 0.0198, d_fake_loss: 0.0455, g_loss: 1.2221\n",
            "Step [59300/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0063, d_svhn_loss: 0.0259, d_fake_loss: 0.0284, g_loss: 1.2509\n",
            "Step [59310/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0051, d_svhn_loss: 0.0275, d_fake_loss: 0.0240, g_loss: 1.1778\n",
            "Step [59320/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0034, d_svhn_loss: 0.0477, d_fake_loss: 0.0160, g_loss: 1.2511\n",
            "Step [59330/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0101, d_svhn_loss: 0.0213, d_fake_loss: 0.0257, g_loss: 1.3375\n",
            "Step [59340/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0039, d_svhn_loss: 0.0203, d_fake_loss: 0.0191, g_loss: 1.1461\n",
            "Step [59350/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0054, d_svhn_loss: 0.0417, d_fake_loss: 0.0527, g_loss: 1.1803\n",
            "Step [59360/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0023, d_svhn_loss: 0.0349, d_fake_loss: 0.0132, g_loss: 1.1662\n",
            "Step [59370/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0067, d_svhn_loss: 0.0699, d_fake_loss: 0.0414, g_loss: 1.3073\n",
            "Step [59380/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0108, d_svhn_loss: 0.0144, d_fake_loss: 0.0161, g_loss: 1.1542\n",
            "Step [59390/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0026, d_svhn_loss: 0.0233, d_fake_loss: 0.0152, g_loss: 1.1627\n",
            "Step [59400/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0043, d_svhn_loss: 0.0355, d_fake_loss: 0.0790, g_loss: 1.2347\n",
            "Step [59410/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0091, d_svhn_loss: 0.0657, d_fake_loss: 0.0186, g_loss: 1.0589\n",
            "Step [59420/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0028, d_svhn_loss: 0.0229, d_fake_loss: 0.0286, g_loss: 1.1132\n",
            "Step [59430/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0043, d_svhn_loss: 0.0261, d_fake_loss: 0.0232, g_loss: 1.1440\n",
            "Step [59440/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0073, d_svhn_loss: 0.0207, d_fake_loss: 0.0199, g_loss: 1.1535\n",
            "Step [59450/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0039, d_svhn_loss: 0.0582, d_fake_loss: 0.0798, g_loss: 1.1670\n",
            "Step [59460/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0045, d_svhn_loss: 0.0381, d_fake_loss: 0.0282, g_loss: 1.1353\n",
            "Step [59470/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0077, d_svhn_loss: 0.0271, d_fake_loss: 0.0236, g_loss: 1.1055\n",
            "Step [59480/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0029, d_svhn_loss: 0.0627, d_fake_loss: 0.0168, g_loss: 1.1466\n",
            "Step [59490/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0029, d_svhn_loss: 0.0213, d_fake_loss: 0.0601, g_loss: 1.0380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [59500/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0032, d_svhn_loss: 0.0261, d_fake_loss: 0.0305, g_loss: 1.1417\n",
            "saved ./samples_mnist_svhn/sample-59500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-59500-s-m.png\n",
            "Step [59510/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0031, d_svhn_loss: 0.0339, d_fake_loss: 0.0241, g_loss: 1.1731\n",
            "Step [59520/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0027, d_svhn_loss: 0.0173, d_fake_loss: 0.0280, g_loss: 1.2042\n",
            "Step [59530/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0065, d_svhn_loss: 0.0179, d_fake_loss: 0.0162, g_loss: 1.1606\n",
            "Step [59540/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0018, d_svhn_loss: 0.0281, d_fake_loss: 0.0739, g_loss: 1.1761\n",
            "Step [59550/80000], d_real_loss: 0.1007, d_mnist_loss: 0.0063, d_svhn_loss: 0.0944, d_fake_loss: 0.0292, g_loss: 1.2815\n",
            "Step [59560/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0027, d_svhn_loss: 0.0340, d_fake_loss: 0.0500, g_loss: 1.0971\n",
            "Step [59570/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0037, d_svhn_loss: 0.0449, d_fake_loss: 0.0678, g_loss: 1.1131\n",
            "Step [59580/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0016, d_svhn_loss: 0.0193, d_fake_loss: 0.0215, g_loss: 1.1663\n",
            "Step [59590/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0057, d_svhn_loss: 0.0257, d_fake_loss: 0.0264, g_loss: 1.1360\n",
            "Step [59600/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0097, d_svhn_loss: 0.0531, d_fake_loss: 0.0445, g_loss: 1.1595\n",
            "Step [59610/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0029, d_svhn_loss: 0.0463, d_fake_loss: 0.0735, g_loss: 1.3291\n",
            "Step [59620/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0028, d_svhn_loss: 0.0210, d_fake_loss: 0.0349, g_loss: 1.2500\n",
            "Step [59630/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0023, d_svhn_loss: 0.0204, d_fake_loss: 0.0200, g_loss: 1.1925\n",
            "Step [59640/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0132, d_svhn_loss: 0.0401, d_fake_loss: 0.0536, g_loss: 1.1211\n",
            "Step [59650/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0133, d_svhn_loss: 0.0360, d_fake_loss: 0.0723, g_loss: 1.0927\n",
            "Step [59660/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0026, d_svhn_loss: 0.0573, d_fake_loss: 0.0307, g_loss: 1.1339\n",
            "Step [59670/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0024, d_svhn_loss: 0.0637, d_fake_loss: 0.0301, g_loss: 1.1604\n",
            "Step [59680/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0028, d_svhn_loss: 0.0358, d_fake_loss: 0.0529, g_loss: 1.1961\n",
            "Step [59690/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0044, d_svhn_loss: 0.0157, d_fake_loss: 0.0421, g_loss: 1.1351\n",
            "Step [59700/80000], d_real_loss: 0.1016, d_mnist_loss: 0.0034, d_svhn_loss: 0.0982, d_fake_loss: 0.0979, g_loss: 1.1872\n",
            "Step [59710/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0190, d_svhn_loss: 0.0310, d_fake_loss: 0.0467, g_loss: 1.1354\n",
            "Step [59720/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0053, d_svhn_loss: 0.0237, d_fake_loss: 0.0284, g_loss: 1.1059\n",
            "Step [59730/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0038, d_svhn_loss: 0.0366, d_fake_loss: 0.0525, g_loss: 1.1321\n",
            "Step [59740/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0062, d_svhn_loss: 0.0406, d_fake_loss: 0.0786, g_loss: 1.1646\n",
            "Step [59750/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0039, d_svhn_loss: 0.0269, d_fake_loss: 0.0273, g_loss: 1.0899\n",
            "Step [59760/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0034, d_svhn_loss: 0.0212, d_fake_loss: 0.0259, g_loss: 1.1498\n",
            "Step [59770/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0019, d_svhn_loss: 0.0466, d_fake_loss: 0.0247, g_loss: 1.1569\n",
            "Step [59780/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0071, d_svhn_loss: 0.0175, d_fake_loss: 0.0357, g_loss: 1.2131\n",
            "Step [59790/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0050, d_svhn_loss: 0.0412, d_fake_loss: 0.0170, g_loss: 1.2571\n",
            "Step [59800/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0025, d_svhn_loss: 0.0686, d_fake_loss: 0.1154, g_loss: 1.0683\n",
            "Step [59810/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0033, d_svhn_loss: 0.0309, d_fake_loss: 0.0205, g_loss: 1.1762\n",
            "Step [59820/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0069, d_svhn_loss: 0.0442, d_fake_loss: 0.0439, g_loss: 1.3712\n",
            "Step [59830/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0023, d_svhn_loss: 0.0221, d_fake_loss: 0.0268, g_loss: 1.1713\n",
            "Step [59840/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0118, d_svhn_loss: 0.0611, d_fake_loss: 0.0207, g_loss: 1.1609\n",
            "Step [59850/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0033, d_svhn_loss: 0.0183, d_fake_loss: 0.0294, g_loss: 1.1622\n",
            "Step [59860/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0029, d_svhn_loss: 0.0377, d_fake_loss: 0.0616, g_loss: 1.2085\n",
            "Step [59870/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0020, d_svhn_loss: 0.0240, d_fake_loss: 0.0491, g_loss: 1.2006\n",
            "Step [59880/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0035, d_svhn_loss: 0.0176, d_fake_loss: 0.0201, g_loss: 1.1755\n",
            "Step [59890/80000], d_real_loss: 0.0912, d_mnist_loss: 0.0057, d_svhn_loss: 0.0856, d_fake_loss: 0.0612, g_loss: 1.0854\n",
            "Step [59900/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0032, d_svhn_loss: 0.0372, d_fake_loss: 0.0215, g_loss: 1.1949\n",
            "Step [59910/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0062, d_svhn_loss: 0.0204, d_fake_loss: 0.0496, g_loss: 1.1514\n",
            "Step [59920/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0025, d_svhn_loss: 0.0230, d_fake_loss: 0.0290, g_loss: 1.1069\n",
            "Step [59930/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0078, d_svhn_loss: 0.0371, d_fake_loss: 0.0182, g_loss: 1.1046\n",
            "Step [59940/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0059, d_svhn_loss: 0.0356, d_fake_loss: 0.0510, g_loss: 1.1417\n",
            "Step [59950/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0021, d_svhn_loss: 0.0207, d_fake_loss: 0.2737, g_loss: 1.1697\n",
            "Step [59960/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0021, d_svhn_loss: 0.0195, d_fake_loss: 0.0812, g_loss: 1.1659\n",
            "Step [59970/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0032, d_svhn_loss: 0.0753, d_fake_loss: 0.0259, g_loss: 1.1247\n",
            "Step [59980/80000], d_real_loss: 0.0732, d_mnist_loss: 0.0155, d_svhn_loss: 0.0577, d_fake_loss: 0.0442, g_loss: 1.1811\n",
            "Step [59990/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0187, d_svhn_loss: 0.0432, d_fake_loss: 0.0272, g_loss: 1.1690\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [60000/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0027, d_svhn_loss: 0.0196, d_fake_loss: 0.0342, g_loss: 1.1327\n",
            "saved ./samples_mnist_svhn/sample-60000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-60000-s-m.png\n",
            "Step [60010/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0043, d_svhn_loss: 0.0680, d_fake_loss: 0.0167, g_loss: 1.1492\n",
            "Step [60020/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0037, d_svhn_loss: 0.0269, d_fake_loss: 0.0138, g_loss: 1.1727\n",
            "Step [60030/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0043, d_svhn_loss: 0.0203, d_fake_loss: 0.0195, g_loss: 1.1553\n",
            "Step [60040/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0024, d_svhn_loss: 0.0218, d_fake_loss: 0.0158, g_loss: 1.1608\n",
            "Step [60050/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0094, d_svhn_loss: 0.0576, d_fake_loss: 0.0710, g_loss: 1.3074\n",
            "Step [60060/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0297, d_svhn_loss: 0.0211, d_fake_loss: 0.0417, g_loss: 1.1112\n",
            "Step [60070/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0040, d_svhn_loss: 0.0523, d_fake_loss: 0.0383, g_loss: 1.3106\n",
            "Step [60080/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0091, d_svhn_loss: 0.0156, d_fake_loss: 0.0428, g_loss: 1.3220\n",
            "Step [60090/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0054, d_svhn_loss: 0.0255, d_fake_loss: 0.0165, g_loss: 1.1583\n",
            "Step [60100/80000], d_real_loss: 0.0862, d_mnist_loss: 0.0053, d_svhn_loss: 0.0809, d_fake_loss: 0.1196, g_loss: 1.1786\n",
            "Step [60110/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0034, d_svhn_loss: 0.0731, d_fake_loss: 0.1119, g_loss: 1.1393\n",
            "Step [60120/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0222, d_svhn_loss: 0.0181, d_fake_loss: 0.0243, g_loss: 1.1491\n",
            "Step [60130/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0094, d_svhn_loss: 0.0311, d_fake_loss: 0.0141, g_loss: 1.1370\n",
            "Step [60140/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0039, d_svhn_loss: 0.0571, d_fake_loss: 0.0194, g_loss: 1.1334\n",
            "Step [60150/80000], d_real_loss: 0.0188, d_mnist_loss: 0.0049, d_svhn_loss: 0.0138, d_fake_loss: 0.1743, g_loss: 1.2208\n",
            "Step [60160/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0129, d_svhn_loss: 0.0550, d_fake_loss: 0.1070, g_loss: 1.0818\n",
            "Step [60170/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0115, d_svhn_loss: 0.0194, d_fake_loss: 0.0193, g_loss: 1.1414\n",
            "Step [60180/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0126, d_svhn_loss: 0.0270, d_fake_loss: 0.0436, g_loss: 1.1346\n",
            "Step [60190/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0064, d_svhn_loss: 0.0357, d_fake_loss: 0.0878, g_loss: 1.1086\n",
            "Step [60200/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0053, d_svhn_loss: 0.0624, d_fake_loss: 0.0337, g_loss: 1.1958\n",
            "Step [60210/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0100, d_svhn_loss: 0.0164, d_fake_loss: 0.0626, g_loss: 1.1743\n",
            "Step [60220/80000], d_real_loss: 0.0203, d_mnist_loss: 0.0072, d_svhn_loss: 0.0131, d_fake_loss: 0.0172, g_loss: 1.2015\n",
            "Step [60230/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0021, d_svhn_loss: 0.0176, d_fake_loss: 0.0131, g_loss: 1.1667\n",
            "Step [60240/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0033, d_svhn_loss: 0.0526, d_fake_loss: 0.0291, g_loss: 1.1645\n",
            "Step [60250/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0068, d_svhn_loss: 0.0598, d_fake_loss: 0.0965, g_loss: 1.0680\n",
            "Step [60260/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0018, d_svhn_loss: 0.0368, d_fake_loss: 0.0204, g_loss: 1.1837\n",
            "Step [60270/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0048, d_svhn_loss: 0.0495, d_fake_loss: 0.0647, g_loss: 1.2064\n",
            "Step [60280/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0066, d_svhn_loss: 0.0235, d_fake_loss: 0.0234, g_loss: 1.1391\n",
            "Step [60290/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0035, d_svhn_loss: 0.0291, d_fake_loss: 0.0433, g_loss: 1.1149\n",
            "Step [60300/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0050, d_svhn_loss: 0.0198, d_fake_loss: 0.0362, g_loss: 1.1271\n",
            "Step [60310/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0033, d_svhn_loss: 0.0344, d_fake_loss: 0.1017, g_loss: 1.2142\n",
            "Step [60320/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0058, d_svhn_loss: 0.0733, d_fake_loss: 0.0164, g_loss: 1.1534\n",
            "Step [60330/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0034, d_svhn_loss: 0.0333, d_fake_loss: 0.0169, g_loss: 1.2424\n",
            "Step [60340/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0063, d_svhn_loss: 0.0594, d_fake_loss: 0.0330, g_loss: 1.1185\n",
            "Step [60350/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0026, d_svhn_loss: 0.0191, d_fake_loss: 0.0395, g_loss: 1.2387\n",
            "Step [60360/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0073, d_svhn_loss: 0.0253, d_fake_loss: 0.0303, g_loss: 1.1906\n",
            "Step [60370/80000], d_real_loss: 0.1022, d_mnist_loss: 0.0023, d_svhn_loss: 0.0999, d_fake_loss: 0.0261, g_loss: 1.1553\n",
            "Step [60380/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0031, d_svhn_loss: 0.0307, d_fake_loss: 0.0196, g_loss: 1.1330\n",
            "Step [60390/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0048, d_svhn_loss: 0.0237, d_fake_loss: 0.0241, g_loss: 1.2115\n",
            "Step [60400/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0024, d_svhn_loss: 0.0196, d_fake_loss: 0.0213, g_loss: 1.2103\n",
            "Step [60410/80000], d_real_loss: 0.1058, d_mnist_loss: 0.0036, d_svhn_loss: 0.1022, d_fake_loss: 0.0177, g_loss: 1.1627\n",
            "Step [60420/80000], d_real_loss: 0.0903, d_mnist_loss: 0.0028, d_svhn_loss: 0.0875, d_fake_loss: 0.0942, g_loss: 1.1095\n",
            "Step [60430/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0033, d_svhn_loss: 0.0256, d_fake_loss: 0.0152, g_loss: 1.1308\n",
            "Step [60440/80000], d_real_loss: 0.0161, d_mnist_loss: 0.0058, d_svhn_loss: 0.0103, d_fake_loss: 0.0822, g_loss: 1.1423\n",
            "Step [60450/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0028, d_svhn_loss: 0.0246, d_fake_loss: 0.0200, g_loss: 1.1746\n",
            "Step [60460/80000], d_real_loss: 0.0847, d_mnist_loss: 0.0013, d_svhn_loss: 0.0834, d_fake_loss: 0.0859, g_loss: 1.1720\n",
            "Step [60470/80000], d_real_loss: 0.0978, d_mnist_loss: 0.0023, d_svhn_loss: 0.0955, d_fake_loss: 0.2053, g_loss: 1.1455\n",
            "Step [60480/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0049, d_svhn_loss: 0.0299, d_fake_loss: 0.0251, g_loss: 1.1867\n",
            "Step [60490/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0027, d_svhn_loss: 0.0474, d_fake_loss: 0.0201, g_loss: 1.1562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [60500/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0029, d_svhn_loss: 0.0232, d_fake_loss: 0.0255, g_loss: 1.2537\n",
            "saved ./samples_mnist_svhn/sample-60500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-60500-s-m.png\n",
            "Step [60510/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0027, d_svhn_loss: 0.0362, d_fake_loss: 0.0356, g_loss: 1.2027\n",
            "Step [60520/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0030, d_svhn_loss: 0.0579, d_fake_loss: 0.0134, g_loss: 1.1419\n",
            "Step [60530/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0140, d_svhn_loss: 0.0147, d_fake_loss: 0.0147, g_loss: 1.0989\n",
            "Step [60540/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0025, d_svhn_loss: 0.0327, d_fake_loss: 0.0143, g_loss: 1.1889\n",
            "Step [60550/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0010, d_svhn_loss: 0.0393, d_fake_loss: 0.0228, g_loss: 1.1781\n",
            "Step [60560/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0020, d_svhn_loss: 0.0212, d_fake_loss: 0.0191, g_loss: 1.2351\n",
            "Step [60570/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0048, d_svhn_loss: 0.0803, d_fake_loss: 0.0579, g_loss: 1.1164\n",
            "Step [60580/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0023, d_svhn_loss: 0.0223, d_fake_loss: 0.0178, g_loss: 1.1753\n",
            "Step [60590/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0026, d_svhn_loss: 0.0161, d_fake_loss: 0.0195, g_loss: 1.1074\n",
            "Step [60600/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0082, d_svhn_loss: 0.0289, d_fake_loss: 0.0108, g_loss: 1.1604\n",
            "Step [60610/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0014, d_svhn_loss: 0.0602, d_fake_loss: 0.0642, g_loss: 1.1271\n",
            "Step [60620/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0027, d_svhn_loss: 0.0173, d_fake_loss: 0.0333, g_loss: 1.1797\n",
            "Step [60630/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0027, d_svhn_loss: 0.0170, d_fake_loss: 0.0438, g_loss: 1.2893\n",
            "Step [60640/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0027, d_svhn_loss: 0.0218, d_fake_loss: 0.0513, g_loss: 1.2570\n",
            "Step [60650/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0039, d_svhn_loss: 0.0192, d_fake_loss: 0.0523, g_loss: 1.1630\n",
            "Step [60660/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0051, d_svhn_loss: 0.0243, d_fake_loss: 0.0153, g_loss: 1.2230\n",
            "Step [60670/80000], d_real_loss: 0.0164, d_mnist_loss: 0.0030, d_svhn_loss: 0.0134, d_fake_loss: 0.0371, g_loss: 1.1304\n",
            "Step [60680/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0087, d_svhn_loss: 0.0297, d_fake_loss: 0.1287, g_loss: 1.1531\n",
            "Step [60690/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0023, d_svhn_loss: 0.0189, d_fake_loss: 0.0320, g_loss: 1.1440\n",
            "Step [60700/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0024, d_svhn_loss: 0.0213, d_fake_loss: 0.0159, g_loss: 1.1431\n",
            "Step [60710/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0041, d_svhn_loss: 0.0216, d_fake_loss: 0.0405, g_loss: 1.0766\n",
            "Step [60720/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0058, d_svhn_loss: 0.0195, d_fake_loss: 0.0369, g_loss: 1.2097\n",
            "Step [60730/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0028, d_svhn_loss: 0.0292, d_fake_loss: 0.0163, g_loss: 1.1912\n",
            "Step [60740/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0070, d_svhn_loss: 0.0252, d_fake_loss: 0.0180, g_loss: 1.0883\n",
            "Step [60750/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0042, d_svhn_loss: 0.0347, d_fake_loss: 0.0355, g_loss: 1.1562\n",
            "Step [60760/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0029, d_svhn_loss: 0.0438, d_fake_loss: 0.0351, g_loss: 1.1823\n",
            "Step [60770/80000], d_real_loss: 0.1026, d_mnist_loss: 0.0032, d_svhn_loss: 0.0994, d_fake_loss: 0.1978, g_loss: 1.0931\n",
            "Step [60780/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0028, d_svhn_loss: 0.0669, d_fake_loss: 0.0960, g_loss: 1.1611\n",
            "Step [60790/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0035, d_svhn_loss: 0.0288, d_fake_loss: 0.0128, g_loss: 1.2754\n",
            "Step [60800/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0038, d_svhn_loss: 0.0196, d_fake_loss: 0.0245, g_loss: 1.1846\n",
            "Step [60810/80000], d_real_loss: 0.0821, d_mnist_loss: 0.0080, d_svhn_loss: 0.0741, d_fake_loss: 0.0525, g_loss: 1.1490\n",
            "Step [60820/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0047, d_svhn_loss: 0.0217, d_fake_loss: 0.0275, g_loss: 1.1397\n",
            "Step [60830/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0023, d_svhn_loss: 0.0453, d_fake_loss: 0.0450, g_loss: 1.1375\n",
            "Step [60840/80000], d_real_loss: 0.0145, d_mnist_loss: 0.0016, d_svhn_loss: 0.0129, d_fake_loss: 0.0367, g_loss: 1.1852\n",
            "Step [60850/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0017, d_svhn_loss: 0.0316, d_fake_loss: 0.0112, g_loss: 1.2094\n",
            "Step [60860/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0076, d_svhn_loss: 0.0262, d_fake_loss: 0.0229, g_loss: 1.1298\n",
            "Step [60870/80000], d_real_loss: 0.0224, d_mnist_loss: 0.0016, d_svhn_loss: 0.0208, d_fake_loss: 0.0223, g_loss: 1.1619\n",
            "Step [60880/80000], d_real_loss: 0.0171, d_mnist_loss: 0.0045, d_svhn_loss: 0.0127, d_fake_loss: 0.0280, g_loss: 1.1447\n",
            "Step [60890/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0039, d_svhn_loss: 0.0170, d_fake_loss: 0.0235, g_loss: 1.1314\n",
            "Step [60900/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0021, d_svhn_loss: 0.0209, d_fake_loss: 0.0130, g_loss: 1.2293\n",
            "Step [60910/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0018, d_svhn_loss: 0.0318, d_fake_loss: 0.0450, g_loss: 1.1358\n",
            "Step [60920/80000], d_real_loss: 0.1789, d_mnist_loss: 0.0080, d_svhn_loss: 0.1708, d_fake_loss: 0.1364, g_loss: 1.1113\n",
            "Step [60930/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0086, d_svhn_loss: 0.0176, d_fake_loss: 0.0193, g_loss: 1.2415\n",
            "Step [60940/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0018, d_svhn_loss: 0.0227, d_fake_loss: 0.0177, g_loss: 1.1498\n",
            "Step [60950/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0066, d_svhn_loss: 0.0447, d_fake_loss: 0.0434, g_loss: 1.0923\n",
            "Step [60960/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0037, d_svhn_loss: 0.0517, d_fake_loss: 0.0635, g_loss: 1.1247\n",
            "Step [60970/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0017, d_svhn_loss: 0.0345, d_fake_loss: 0.0274, g_loss: 1.2176\n",
            "Step [60980/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0082, d_svhn_loss: 0.0293, d_fake_loss: 0.0321, g_loss: 1.1151\n",
            "Step [60990/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0033, d_svhn_loss: 0.0152, d_fake_loss: 0.0211, g_loss: 1.1351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [61000/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0042, d_svhn_loss: 0.0444, d_fake_loss: 0.0366, g_loss: 1.1119\n",
            "saved ./samples_mnist_svhn/sample-61000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-61000-s-m.png\n",
            "Step [61010/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0035, d_svhn_loss: 0.0250, d_fake_loss: 0.0606, g_loss: 1.1373\n",
            "Step [61020/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0017, d_svhn_loss: 0.0270, d_fake_loss: 0.0257, g_loss: 1.2036\n",
            "Step [61030/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0082, d_svhn_loss: 0.0226, d_fake_loss: 0.0298, g_loss: 1.2221\n",
            "Step [61040/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0078, d_svhn_loss: 0.0368, d_fake_loss: 0.0328, g_loss: 1.0508\n",
            "Step [61050/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0048, d_svhn_loss: 0.0271, d_fake_loss: 0.0609, g_loss: 1.0031\n",
            "Step [61060/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0034, d_svhn_loss: 0.0464, d_fake_loss: 0.0281, g_loss: 1.1142\n",
            "Step [61070/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0091, d_svhn_loss: 0.0226, d_fake_loss: 0.0812, g_loss: 1.1169\n",
            "Step [61080/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0025, d_svhn_loss: 0.0366, d_fake_loss: 0.0232, g_loss: 1.0900\n",
            "Step [61090/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0027, d_svhn_loss: 0.0654, d_fake_loss: 0.0192, g_loss: 1.1744\n",
            "Step [61100/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0022, d_svhn_loss: 0.0233, d_fake_loss: 0.0177, g_loss: 1.1779\n",
            "Step [61110/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0022, d_svhn_loss: 0.0208, d_fake_loss: 0.0330, g_loss: 1.3093\n",
            "Step [61120/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0029, d_svhn_loss: 0.0240, d_fake_loss: 0.0215, g_loss: 1.2139\n",
            "Step [61130/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0036, d_svhn_loss: 0.0221, d_fake_loss: 0.0410, g_loss: 1.3074\n",
            "Step [61140/80000], d_real_loss: 0.0179, d_mnist_loss: 0.0036, d_svhn_loss: 0.0143, d_fake_loss: 0.0951, g_loss: 1.2117\n",
            "Step [61150/80000], d_real_loss: 0.0213, d_mnist_loss: 0.0017, d_svhn_loss: 0.0196, d_fake_loss: 0.0139, g_loss: 1.1341\n",
            "Step [61160/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0022, d_svhn_loss: 0.0403, d_fake_loss: 0.0190, g_loss: 1.1813\n",
            "Step [61170/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0090, d_svhn_loss: 0.0198, d_fake_loss: 0.0324, g_loss: 1.1379\n",
            "Step [61180/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0067, d_svhn_loss: 0.0381, d_fake_loss: 0.0340, g_loss: 1.2390\n",
            "Step [61190/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0120, d_svhn_loss: 0.0292, d_fake_loss: 0.0938, g_loss: 1.1591\n",
            "Step [61200/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0096, d_svhn_loss: 0.0416, d_fake_loss: 0.1819, g_loss: 1.3381\n",
            "Step [61210/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0045, d_svhn_loss: 0.0347, d_fake_loss: 0.0495, g_loss: 1.1827\n",
            "Step [61220/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0037, d_svhn_loss: 0.0281, d_fake_loss: 0.0312, g_loss: 1.3556\n",
            "Step [61230/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0026, d_svhn_loss: 0.0214, d_fake_loss: 0.0358, g_loss: 1.1450\n",
            "Step [61240/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0143, d_svhn_loss: 0.0200, d_fake_loss: 0.0337, g_loss: 1.1555\n",
            "Step [61250/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0190, d_svhn_loss: 0.0138, d_fake_loss: 0.0413, g_loss: 1.2846\n",
            "Step [61260/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0029, d_svhn_loss: 0.0199, d_fake_loss: 0.0225, g_loss: 1.1258\n",
            "Step [61270/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0065, d_svhn_loss: 0.0302, d_fake_loss: 0.0620, g_loss: 1.2206\n",
            "Step [61280/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0022, d_svhn_loss: 0.0256, d_fake_loss: 0.0334, g_loss: 1.2579\n",
            "Step [61290/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0026, d_svhn_loss: 0.0213, d_fake_loss: 0.0130, g_loss: 1.2108\n",
            "Step [61300/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0138, d_svhn_loss: 0.0491, d_fake_loss: 0.0195, g_loss: 1.1548\n",
            "Step [61310/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0020, d_svhn_loss: 0.0212, d_fake_loss: 0.0374, g_loss: 1.1400\n",
            "Step [61320/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0021, d_svhn_loss: 0.0300, d_fake_loss: 0.0740, g_loss: 1.2195\n",
            "Step [61330/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0037, d_svhn_loss: 0.0275, d_fake_loss: 0.0281, g_loss: 1.1513\n",
            "Step [61340/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0040, d_svhn_loss: 0.0196, d_fake_loss: 0.0541, g_loss: 1.1478\n",
            "Step [61350/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0017, d_svhn_loss: 0.0218, d_fake_loss: 0.0159, g_loss: 1.1581\n",
            "Step [61360/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0014, d_svhn_loss: 0.0540, d_fake_loss: 0.0289, g_loss: 1.1540\n",
            "Step [61370/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0036, d_svhn_loss: 0.0451, d_fake_loss: 0.0289, g_loss: 1.1579\n",
            "Step [61380/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0078, d_svhn_loss: 0.0195, d_fake_loss: 0.0350, g_loss: 1.1591\n",
            "Step [61390/80000], d_real_loss: 0.0161, d_mnist_loss: 0.0023, d_svhn_loss: 0.0138, d_fake_loss: 0.0317, g_loss: 1.1290\n",
            "Step [61400/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0020, d_svhn_loss: 0.0316, d_fake_loss: 0.0242, g_loss: 1.0900\n",
            "Step [61410/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0025, d_svhn_loss: 0.0366, d_fake_loss: 0.0224, g_loss: 1.2333\n",
            "Step [61420/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0045, d_svhn_loss: 0.0159, d_fake_loss: 0.0319, g_loss: 1.1172\n",
            "Step [61430/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0018, d_svhn_loss: 0.0466, d_fake_loss: 0.0336, g_loss: 1.1187\n",
            "Step [61440/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0027, d_svhn_loss: 0.0654, d_fake_loss: 0.0748, g_loss: 1.0695\n",
            "Step [61450/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0288, d_svhn_loss: 0.0271, d_fake_loss: 0.0465, g_loss: 1.1015\n",
            "Step [61460/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0059, d_svhn_loss: 0.0158, d_fake_loss: 0.0075, g_loss: 1.2271\n",
            "Step [61470/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0024, d_svhn_loss: 0.0224, d_fake_loss: 0.0317, g_loss: 1.2476\n",
            "Step [61480/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0077, d_svhn_loss: 0.0183, d_fake_loss: 0.0179, g_loss: 1.1500\n",
            "Step [61490/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0048, d_svhn_loss: 0.0304, d_fake_loss: 0.0478, g_loss: 1.2361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [61500/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0108, d_svhn_loss: 0.0145, d_fake_loss: 0.0192, g_loss: 1.1697\n",
            "saved ./samples_mnist_svhn/sample-61500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-61500-s-m.png\n",
            "Step [61510/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0051, d_svhn_loss: 0.0223, d_fake_loss: 0.0420, g_loss: 1.1393\n",
            "Step [61520/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0040, d_svhn_loss: 0.0222, d_fake_loss: 0.0233, g_loss: 1.2456\n",
            "Step [61530/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0026, d_svhn_loss: 0.0623, d_fake_loss: 0.1434, g_loss: 1.1237\n",
            "Step [61540/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0043, d_svhn_loss: 0.0235, d_fake_loss: 0.0185, g_loss: 1.1400\n",
            "Step [61550/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0024, d_svhn_loss: 0.0587, d_fake_loss: 0.1366, g_loss: 1.1426\n",
            "Step [61560/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0046, d_svhn_loss: 0.0217, d_fake_loss: 0.0136, g_loss: 1.1847\n",
            "Step [61570/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0063, d_svhn_loss: 0.0418, d_fake_loss: 0.0644, g_loss: 1.1162\n",
            "Step [61580/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0030, d_svhn_loss: 0.0302, d_fake_loss: 0.0669, g_loss: 1.1377\n",
            "Step [61590/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0034, d_svhn_loss: 0.0151, d_fake_loss: 0.0120, g_loss: 1.1508\n",
            "Step [61600/80000], d_real_loss: 0.0869, d_mnist_loss: 0.0022, d_svhn_loss: 0.0847, d_fake_loss: 0.0161, g_loss: 1.0721\n",
            "Step [61610/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0029, d_svhn_loss: 0.0235, d_fake_loss: 0.0214, g_loss: 1.2372\n",
            "Step [61620/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0043, d_svhn_loss: 0.0235, d_fake_loss: 0.0310, g_loss: 1.0847\n",
            "Step [61630/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0183, d_svhn_loss: 0.0261, d_fake_loss: 0.0243, g_loss: 1.0267\n",
            "Step [61640/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0031, d_svhn_loss: 0.0236, d_fake_loss: 0.0215, g_loss: 1.1770\n",
            "Step [61650/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0030, d_svhn_loss: 0.0477, d_fake_loss: 0.0140, g_loss: 1.1040\n",
            "Step [61660/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0049, d_svhn_loss: 0.0227, d_fake_loss: 0.0137, g_loss: 1.1977\n",
            "Step [61670/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0030, d_svhn_loss: 0.0184, d_fake_loss: 0.0216, g_loss: 1.2531\n",
            "Step [61680/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0025, d_svhn_loss: 0.0228, d_fake_loss: 0.0633, g_loss: 1.2550\n",
            "Step [61690/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0039, d_svhn_loss: 0.0194, d_fake_loss: 0.0202, g_loss: 1.1823\n",
            "Step [61700/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0027, d_svhn_loss: 0.0447, d_fake_loss: 0.0435, g_loss: 1.1817\n",
            "Step [61710/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0031, d_svhn_loss: 0.0197, d_fake_loss: 0.0164, g_loss: 1.1791\n",
            "Step [61720/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0044, d_svhn_loss: 0.0163, d_fake_loss: 0.0194, g_loss: 1.1999\n",
            "Step [61730/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0015, d_svhn_loss: 0.0455, d_fake_loss: 0.1007, g_loss: 1.2051\n",
            "Step [61740/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0027, d_svhn_loss: 0.0232, d_fake_loss: 0.0541, g_loss: 1.1603\n",
            "Step [61750/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0067, d_svhn_loss: 0.0434, d_fake_loss: 0.0285, g_loss: 1.2070\n",
            "Step [61760/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0036, d_svhn_loss: 0.0784, d_fake_loss: 0.0390, g_loss: 1.1845\n",
            "Step [61770/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0014, d_svhn_loss: 0.0260, d_fake_loss: 0.0179, g_loss: 1.2294\n",
            "Step [61780/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0020, d_svhn_loss: 0.0766, d_fake_loss: 0.0663, g_loss: 1.2627\n",
            "Step [61790/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0031, d_svhn_loss: 0.0234, d_fake_loss: 0.0266, g_loss: 1.1457\n",
            "Step [61800/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0158, d_svhn_loss: 0.0451, d_fake_loss: 0.1110, g_loss: 1.2938\n",
            "Step [61810/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0040, d_svhn_loss: 0.0564, d_fake_loss: 0.0134, g_loss: 1.1207\n",
            "Step [61820/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0070, d_svhn_loss: 0.0195, d_fake_loss: 0.0239, g_loss: 1.1789\n",
            "Step [61830/80000], d_real_loss: 0.0960, d_mnist_loss: 0.0017, d_svhn_loss: 0.0943, d_fake_loss: 0.0219, g_loss: 1.1741\n",
            "Step [61840/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0014, d_svhn_loss: 0.0421, d_fake_loss: 0.0289, g_loss: 1.1579\n",
            "Step [61850/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0034, d_svhn_loss: 0.0239, d_fake_loss: 0.0238, g_loss: 1.1797\n",
            "Step [61860/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0022, d_svhn_loss: 0.0195, d_fake_loss: 0.0423, g_loss: 1.2038\n",
            "Step [61870/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0023, d_svhn_loss: 0.0189, d_fake_loss: 0.0327, g_loss: 1.1855\n",
            "Step [61880/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0020, d_svhn_loss: 0.0225, d_fake_loss: 0.0309, g_loss: 1.1308\n",
            "Step [61890/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0093, d_svhn_loss: 0.0189, d_fake_loss: 0.0650, g_loss: 1.3877\n",
            "Step [61900/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0055, d_svhn_loss: 0.0200, d_fake_loss: 0.0346, g_loss: 1.1362\n",
            "Step [61910/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0017, d_svhn_loss: 0.0292, d_fake_loss: 0.0164, g_loss: 1.2423\n",
            "Step [61920/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0019, d_svhn_loss: 0.0212, d_fake_loss: 0.0231, g_loss: 1.1788\n",
            "Step [61930/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0022, d_svhn_loss: 0.0335, d_fake_loss: 0.0909, g_loss: 1.1741\n",
            "Step [61940/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0047, d_svhn_loss: 0.0170, d_fake_loss: 0.0702, g_loss: 1.1311\n",
            "Step [61950/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0027, d_svhn_loss: 0.0195, d_fake_loss: 0.0284, g_loss: 1.1672\n",
            "Step [61960/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0135, d_svhn_loss: 0.0280, d_fake_loss: 0.0323, g_loss: 1.0670\n",
            "Step [61970/80000], d_real_loss: 0.0905, d_mnist_loss: 0.0041, d_svhn_loss: 0.0864, d_fake_loss: 0.0150, g_loss: 1.1897\n",
            "Step [61980/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0018, d_svhn_loss: 0.0222, d_fake_loss: 0.0116, g_loss: 1.1859\n",
            "Step [61990/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0103, d_svhn_loss: 0.0293, d_fake_loss: 0.1925, g_loss: 1.2527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [62000/80000], d_real_loss: 0.1919, d_mnist_loss: 0.0042, d_svhn_loss: 0.1877, d_fake_loss: 0.0187, g_loss: 1.0840\n",
            "saved ./samples_mnist_svhn/sample-62000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-62000-s-m.png\n",
            "Step [62010/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0021, d_svhn_loss: 0.0317, d_fake_loss: 0.0254, g_loss: 1.1379\n",
            "Step [62020/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0032, d_svhn_loss: 0.0185, d_fake_loss: 0.0257, g_loss: 1.1558\n",
            "Step [62030/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0032, d_svhn_loss: 0.0536, d_fake_loss: 0.0576, g_loss: 1.1116\n",
            "Step [62040/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0023, d_svhn_loss: 0.0511, d_fake_loss: 0.0426, g_loss: 1.1507\n",
            "Step [62050/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0082, d_svhn_loss: 0.0464, d_fake_loss: 0.0311, g_loss: 1.1346\n",
            "Step [62060/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0021, d_svhn_loss: 0.0540, d_fake_loss: 0.0335, g_loss: 1.1969\n",
            "Step [62070/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0041, d_svhn_loss: 0.0375, d_fake_loss: 0.0252, g_loss: 1.1513\n",
            "Step [62080/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0013, d_svhn_loss: 0.0231, d_fake_loss: 0.0297, g_loss: 1.1859\n",
            "Step [62090/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0018, d_svhn_loss: 0.0397, d_fake_loss: 0.0390, g_loss: 1.0653\n",
            "Step [62100/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0033, d_svhn_loss: 0.0226, d_fake_loss: 0.0903, g_loss: 1.0820\n",
            "Step [62110/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0030, d_svhn_loss: 0.0213, d_fake_loss: 0.0333, g_loss: 1.1012\n",
            "Step [62120/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0124, d_svhn_loss: 0.0212, d_fake_loss: 0.0426, g_loss: 1.0775\n",
            "Step [62130/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0033, d_svhn_loss: 0.0223, d_fake_loss: 0.0124, g_loss: 1.1352\n",
            "Step [62140/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0017, d_svhn_loss: 0.0377, d_fake_loss: 0.0258, g_loss: 1.1493\n",
            "Step [62150/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0045, d_svhn_loss: 0.0305, d_fake_loss: 0.0672, g_loss: 1.1305\n",
            "Step [62160/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0063, d_svhn_loss: 0.0352, d_fake_loss: 0.0376, g_loss: 1.2427\n",
            "Step [62170/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0026, d_svhn_loss: 0.0206, d_fake_loss: 0.0319, g_loss: 1.0628\n",
            "Step [62180/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0036, d_svhn_loss: 0.0173, d_fake_loss: 0.0104, g_loss: 1.1647\n",
            "Step [62190/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0075, d_svhn_loss: 0.0343, d_fake_loss: 0.0478, g_loss: 1.1139\n",
            "Step [62200/80000], d_real_loss: 0.1437, d_mnist_loss: 0.0106, d_svhn_loss: 0.1331, d_fake_loss: 0.0269, g_loss: 1.1278\n",
            "Step [62210/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0035, d_svhn_loss: 0.0250, d_fake_loss: 0.0148, g_loss: 1.1379\n",
            "Step [62220/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0120, d_svhn_loss: 0.0523, d_fake_loss: 0.0229, g_loss: 1.0469\n",
            "Step [62230/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0051, d_svhn_loss: 0.0303, d_fake_loss: 0.0119, g_loss: 1.1516\n",
            "Step [62240/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0121, d_svhn_loss: 0.0370, d_fake_loss: 0.0983, g_loss: 1.1074\n",
            "Step [62250/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0131, d_svhn_loss: 0.0164, d_fake_loss: 0.0123, g_loss: 1.1583\n",
            "Step [62260/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0023, d_svhn_loss: 0.0476, d_fake_loss: 0.0368, g_loss: 1.1565\n",
            "Step [62270/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0047, d_svhn_loss: 0.0249, d_fake_loss: 0.0275, g_loss: 1.2612\n",
            "Step [62280/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0052, d_svhn_loss: 0.0651, d_fake_loss: 0.0214, g_loss: 1.1186\n",
            "Step [62290/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0040, d_svhn_loss: 0.0399, d_fake_loss: 0.0214, g_loss: 1.1101\n",
            "Step [62300/80000], d_real_loss: 0.0156, d_mnist_loss: 0.0032, d_svhn_loss: 0.0124, d_fake_loss: 0.0226, g_loss: 1.1461\n",
            "Step [62310/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0020, d_svhn_loss: 0.0706, d_fake_loss: 0.0267, g_loss: 1.1190\n",
            "Step [62320/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0028, d_svhn_loss: 0.0667, d_fake_loss: 0.0119, g_loss: 1.1523\n",
            "Step [62330/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0219, d_svhn_loss: 0.0290, d_fake_loss: 0.0742, g_loss: 1.1995\n",
            "Step [62340/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0022, d_svhn_loss: 0.0502, d_fake_loss: 0.0388, g_loss: 1.2065\n",
            "Step [62350/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0033, d_svhn_loss: 0.0179, d_fake_loss: 0.0210, g_loss: 1.1414\n",
            "Step [62360/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0023, d_svhn_loss: 0.0284, d_fake_loss: 0.0207, g_loss: 1.1487\n",
            "Step [62370/80000], d_real_loss: 0.0169, d_mnist_loss: 0.0028, d_svhn_loss: 0.0141, d_fake_loss: 0.0487, g_loss: 1.2409\n",
            "Step [62380/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0030, d_svhn_loss: 0.0362, d_fake_loss: 0.0376, g_loss: 1.1034\n",
            "Step [62390/80000], d_real_loss: 0.0189, d_mnist_loss: 0.0072, d_svhn_loss: 0.0117, d_fake_loss: 0.0115, g_loss: 1.1851\n",
            "Step [62400/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0065, d_svhn_loss: 0.0315, d_fake_loss: 0.0192, g_loss: 1.0830\n",
            "Step [62410/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0023, d_svhn_loss: 0.0286, d_fake_loss: 0.0145, g_loss: 1.1827\n",
            "Step [62420/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0016, d_svhn_loss: 0.0200, d_fake_loss: 0.0967, g_loss: 1.2115\n",
            "Step [62430/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0020, d_svhn_loss: 0.0645, d_fake_loss: 0.0850, g_loss: 1.0920\n",
            "Step [62440/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0183, d_svhn_loss: 0.0187, d_fake_loss: 0.0165, g_loss: 1.1449\n",
            "Step [62450/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0023, d_svhn_loss: 0.0240, d_fake_loss: 0.0135, g_loss: 1.1764\n",
            "Step [62460/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0014, d_svhn_loss: 0.0485, d_fake_loss: 0.0277, g_loss: 1.1126\n",
            "Step [62470/80000], d_real_loss: 0.0987, d_mnist_loss: 0.0054, d_svhn_loss: 0.0933, d_fake_loss: 0.0367, g_loss: 1.1915\n",
            "Step [62480/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0042, d_svhn_loss: 0.0193, d_fake_loss: 0.0223, g_loss: 1.1570\n",
            "Step [62490/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0110, d_svhn_loss: 0.0186, d_fake_loss: 0.0599, g_loss: 1.2015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [62500/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0019, d_svhn_loss: 0.0189, d_fake_loss: 0.0383, g_loss: 1.1647\n",
            "saved ./samples_mnist_svhn/sample-62500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-62500-s-m.png\n",
            "Step [62510/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0048, d_svhn_loss: 0.0181, d_fake_loss: 0.0268, g_loss: 1.1617\n",
            "Step [62520/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0020, d_svhn_loss: 0.0575, d_fake_loss: 0.0218, g_loss: 1.1199\n",
            "Step [62530/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0070, d_svhn_loss: 0.0165, d_fake_loss: 0.0186, g_loss: 1.1626\n",
            "Step [62540/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0087, d_svhn_loss: 0.0270, d_fake_loss: 0.0317, g_loss: 1.2690\n",
            "Step [62550/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0144, d_svhn_loss: 0.0200, d_fake_loss: 0.0388, g_loss: 1.2484\n",
            "Step [62560/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0017, d_svhn_loss: 0.0163, d_fake_loss: 0.0252, g_loss: 1.1742\n",
            "Step [62570/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0012, d_svhn_loss: 0.0856, d_fake_loss: 0.0314, g_loss: 1.1184\n",
            "Step [62580/80000], d_real_loss: 0.0165, d_mnist_loss: 0.0023, d_svhn_loss: 0.0142, d_fake_loss: 0.0402, g_loss: 1.2030\n",
            "Step [62590/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0016, d_svhn_loss: 0.0507, d_fake_loss: 0.0118, g_loss: 1.1964\n",
            "Step [62600/80000], d_real_loss: 0.0776, d_mnist_loss: 0.0020, d_svhn_loss: 0.0756, d_fake_loss: 0.0601, g_loss: 1.0617\n",
            "Step [62610/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0013, d_svhn_loss: 0.0225, d_fake_loss: 0.0780, g_loss: 1.1447\n",
            "Step [62620/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0027, d_svhn_loss: 0.0308, d_fake_loss: 0.0232, g_loss: 1.1141\n",
            "Step [62630/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0028, d_svhn_loss: 0.0331, d_fake_loss: 0.0308, g_loss: 1.1104\n",
            "Step [62640/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0106, d_svhn_loss: 0.0371, d_fake_loss: 0.0127, g_loss: 1.1473\n",
            "Step [62650/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0015, d_svhn_loss: 0.0210, d_fake_loss: 0.0471, g_loss: 1.1873\n",
            "Step [62660/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0072, d_svhn_loss: 0.0690, d_fake_loss: 0.0243, g_loss: 1.1392\n",
            "Step [62670/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0028, d_svhn_loss: 0.0297, d_fake_loss: 0.0561, g_loss: 1.2058\n",
            "Step [62680/80000], d_real_loss: 0.0150, d_mnist_loss: 0.0013, d_svhn_loss: 0.0137, d_fake_loss: 0.0056, g_loss: 1.0835\n",
            "Step [62690/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0028, d_svhn_loss: 0.0421, d_fake_loss: 0.0116, g_loss: 1.1526\n",
            "Step [62700/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0030, d_svhn_loss: 0.0167, d_fake_loss: 0.0220, g_loss: 1.1588\n",
            "Step [62710/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0018, d_svhn_loss: 0.0231, d_fake_loss: 0.0227, g_loss: 1.1842\n",
            "Step [62720/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0041, d_svhn_loss: 0.0420, d_fake_loss: 0.0121, g_loss: 1.1911\n",
            "Step [62730/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0026, d_svhn_loss: 0.0473, d_fake_loss: 0.0193, g_loss: 1.1487\n",
            "Step [62740/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0020, d_svhn_loss: 0.0377, d_fake_loss: 0.0171, g_loss: 1.1356\n",
            "Step [62750/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0027, d_svhn_loss: 0.0164, d_fake_loss: 0.0496, g_loss: 1.1147\n",
            "Step [62760/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0031, d_svhn_loss: 0.0515, d_fake_loss: 0.0147, g_loss: 1.1497\n",
            "Step [62770/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0029, d_svhn_loss: 0.0143, d_fake_loss: 0.0255, g_loss: 1.1413\n",
            "Step [62780/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0026, d_svhn_loss: 0.0257, d_fake_loss: 0.0624, g_loss: 1.1200\n",
            "Step [62790/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0018, d_svhn_loss: 0.0183, d_fake_loss: 0.0783, g_loss: 1.1002\n",
            "Step [62800/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0020, d_svhn_loss: 0.0152, d_fake_loss: 0.0117, g_loss: 1.1341\n",
            "Step [62810/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0072, d_svhn_loss: 0.0233, d_fake_loss: 0.0404, g_loss: 1.3195\n",
            "Step [62820/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0075, d_svhn_loss: 0.0509, d_fake_loss: 0.0151, g_loss: 1.1498\n",
            "Step [62830/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0043, d_svhn_loss: 0.0268, d_fake_loss: 0.0455, g_loss: 1.1333\n",
            "Step [62840/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0046, d_svhn_loss: 0.0223, d_fake_loss: 0.0540, g_loss: 1.0679\n",
            "Step [62850/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0028, d_svhn_loss: 0.0354, d_fake_loss: 0.0262, g_loss: 1.1231\n",
            "Step [62860/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0101, d_svhn_loss: 0.0325, d_fake_loss: 0.0433, g_loss: 1.1778\n",
            "Step [62870/80000], d_real_loss: 0.1687, d_mnist_loss: 0.0043, d_svhn_loss: 0.1644, d_fake_loss: 0.0122, g_loss: 1.1427\n",
            "Step [62880/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0020, d_svhn_loss: 0.0279, d_fake_loss: 0.0163, g_loss: 1.0744\n",
            "Step [62890/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0043, d_svhn_loss: 0.0164, d_fake_loss: 0.0104, g_loss: 1.0900\n",
            "Step [62900/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0043, d_svhn_loss: 0.0294, d_fake_loss: 0.0871, g_loss: 1.1944\n",
            "Step [62910/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0021, d_svhn_loss: 0.0508, d_fake_loss: 0.0272, g_loss: 1.2426\n",
            "Step [62920/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0087, d_svhn_loss: 0.0342, d_fake_loss: 0.0194, g_loss: 1.1490\n",
            "Step [62930/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0061, d_svhn_loss: 0.0164, d_fake_loss: 0.0323, g_loss: 1.1755\n",
            "Step [62940/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0085, d_svhn_loss: 0.0192, d_fake_loss: 0.0332, g_loss: 1.2148\n",
            "Step [62950/80000], d_real_loss: 0.1018, d_mnist_loss: 0.0116, d_svhn_loss: 0.0902, d_fake_loss: 0.0795, g_loss: 1.2071\n",
            "Step [62960/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0018, d_svhn_loss: 0.0177, d_fake_loss: 0.0448, g_loss: 1.1799\n",
            "Step [62970/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0044, d_svhn_loss: 0.0194, d_fake_loss: 0.0271, g_loss: 1.1884\n",
            "Step [62980/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0023, d_svhn_loss: 0.0416, d_fake_loss: 0.0280, g_loss: 1.2209\n",
            "Step [62990/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0014, d_svhn_loss: 0.0229, d_fake_loss: 0.0613, g_loss: 1.1377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [63000/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0016, d_svhn_loss: 0.0263, d_fake_loss: 0.0110, g_loss: 1.1810\n",
            "saved ./samples_mnist_svhn/sample-63000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-63000-s-m.png\n",
            "Step [63010/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0022, d_svhn_loss: 0.0662, d_fake_loss: 0.0245, g_loss: 1.1278\n",
            "Step [63020/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0044, d_svhn_loss: 0.0187, d_fake_loss: 0.0250, g_loss: 1.1712\n",
            "Step [63030/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0111, d_svhn_loss: 0.0195, d_fake_loss: 0.0293, g_loss: 1.0885\n",
            "Step [63040/80000], d_real_loss: 0.0219, d_mnist_loss: 0.0023, d_svhn_loss: 0.0196, d_fake_loss: 0.0236, g_loss: 1.2012\n",
            "Step [63050/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0047, d_svhn_loss: 0.0198, d_fake_loss: 0.0320, g_loss: 1.2440\n",
            "Step [63060/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0063, d_svhn_loss: 0.0186, d_fake_loss: 0.0175, g_loss: 1.1775\n",
            "Step [63070/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0047, d_svhn_loss: 0.0435, d_fake_loss: 0.0404, g_loss: 1.1559\n",
            "Step [63080/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0034, d_svhn_loss: 0.0195, d_fake_loss: 0.0298, g_loss: 1.1107\n",
            "Step [63090/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0058, d_svhn_loss: 0.0347, d_fake_loss: 0.0943, g_loss: 1.1102\n",
            "Step [63100/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0043, d_svhn_loss: 0.0173, d_fake_loss: 0.0294, g_loss: 1.1030\n",
            "Step [63110/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0071, d_svhn_loss: 0.0583, d_fake_loss: 0.0346, g_loss: 1.1745\n",
            "Step [63120/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0050, d_svhn_loss: 0.0189, d_fake_loss: 0.0133, g_loss: 1.2361\n",
            "Step [63130/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0059, d_svhn_loss: 0.0204, d_fake_loss: 0.1186, g_loss: 1.3313\n",
            "Step [63140/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0043, d_svhn_loss: 0.0280, d_fake_loss: 0.0199, g_loss: 1.1906\n",
            "Step [63150/80000], d_real_loss: 0.0224, d_mnist_loss: 0.0034, d_svhn_loss: 0.0190, d_fake_loss: 0.0101, g_loss: 1.1827\n",
            "Step [63160/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0021, d_svhn_loss: 0.0383, d_fake_loss: 0.0220, g_loss: 1.0926\n",
            "Step [63170/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0021, d_svhn_loss: 0.0217, d_fake_loss: 0.0230, g_loss: 1.0974\n",
            "Step [63180/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0112, d_svhn_loss: 0.0113, d_fake_loss: 0.0093, g_loss: 1.1130\n",
            "Step [63190/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0074, d_svhn_loss: 0.0328, d_fake_loss: 0.0519, g_loss: 1.1476\n",
            "Step [63200/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0040, d_svhn_loss: 0.0503, d_fake_loss: 0.0225, g_loss: 1.1542\n",
            "Step [63210/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0046, d_svhn_loss: 0.0292, d_fake_loss: 0.0122, g_loss: 1.1893\n",
            "Step [63220/80000], d_real_loss: 0.0224, d_mnist_loss: 0.0050, d_svhn_loss: 0.0174, d_fake_loss: 0.0407, g_loss: 1.1821\n",
            "Step [63230/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0037, d_svhn_loss: 0.0163, d_fake_loss: 0.0576, g_loss: 1.2543\n",
            "Step [63240/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0232, d_svhn_loss: 0.0294, d_fake_loss: 0.0215, g_loss: 1.1811\n",
            "Step [63250/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0137, d_svhn_loss: 0.0208, d_fake_loss: 0.0072, g_loss: 1.2355\n",
            "Step [63260/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0029, d_svhn_loss: 0.0624, d_fake_loss: 0.0585, g_loss: 1.1390\n",
            "Step [63270/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0016, d_svhn_loss: 0.0232, d_fake_loss: 0.0143, g_loss: 1.1448\n",
            "Step [63280/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0046, d_svhn_loss: 0.0175, d_fake_loss: 0.0096, g_loss: 1.1673\n",
            "Step [63290/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0158, d_svhn_loss: 0.0190, d_fake_loss: 0.0352, g_loss: 1.2266\n",
            "Step [63300/80000], d_real_loss: 0.0122, d_mnist_loss: 0.0021, d_svhn_loss: 0.0101, d_fake_loss: 0.0300, g_loss: 1.1758\n",
            "Step [63310/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0015, d_svhn_loss: 0.0305, d_fake_loss: 0.1151, g_loss: 1.1295\n",
            "Step [63320/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0278, d_svhn_loss: 0.0109, d_fake_loss: 0.0309, g_loss: 1.2186\n",
            "Step [63330/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0028, d_svhn_loss: 0.0405, d_fake_loss: 0.0113, g_loss: 1.1120\n",
            "Step [63340/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0061, d_svhn_loss: 0.0175, d_fake_loss: 0.0107, g_loss: 1.1392\n",
            "Step [63350/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0018, d_svhn_loss: 0.0190, d_fake_loss: 0.0383, g_loss: 1.1290\n",
            "Step [63360/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0077, d_svhn_loss: 0.0149, d_fake_loss: 0.0256, g_loss: 1.1294\n",
            "Step [63370/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0020, d_svhn_loss: 0.0470, d_fake_loss: 0.0805, g_loss: 1.1519\n",
            "Step [63380/80000], d_real_loss: 0.0135, d_mnist_loss: 0.0011, d_svhn_loss: 0.0124, d_fake_loss: 0.0693, g_loss: 1.1642\n",
            "Step [63390/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0037, d_svhn_loss: 0.0224, d_fake_loss: 0.0141, g_loss: 1.2194\n",
            "Step [63400/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0070, d_svhn_loss: 0.0233, d_fake_loss: 0.0110, g_loss: 1.1350\n",
            "Step [63410/80000], d_real_loss: 0.0159, d_mnist_loss: 0.0015, d_svhn_loss: 0.0144, d_fake_loss: 0.0312, g_loss: 1.2873\n",
            "Step [63420/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0029, d_svhn_loss: 0.0518, d_fake_loss: 0.0414, g_loss: 1.1648\n",
            "Step [63430/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0020, d_svhn_loss: 0.0602, d_fake_loss: 0.0255, g_loss: 1.1112\n",
            "Step [63440/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0069, d_svhn_loss: 0.0392, d_fake_loss: 0.0745, g_loss: 1.1862\n",
            "Step [63450/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0076, d_svhn_loss: 0.0513, d_fake_loss: 0.0392, g_loss: 1.1712\n",
            "Step [63460/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0023, d_svhn_loss: 0.0343, d_fake_loss: 0.1358, g_loss: 1.1909\n",
            "Step [63470/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0020, d_svhn_loss: 0.0207, d_fake_loss: 0.0341, g_loss: 1.2898\n",
            "Step [63480/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0150, d_svhn_loss: 0.0425, d_fake_loss: 0.0406, g_loss: 1.1179\n",
            "Step [63490/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0025, d_svhn_loss: 0.0285, d_fake_loss: 0.0269, g_loss: 1.1690\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [63500/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0056, d_svhn_loss: 0.0234, d_fake_loss: 0.0196, g_loss: 1.1548\n",
            "saved ./samples_mnist_svhn/sample-63500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-63500-s-m.png\n",
            "Step [63510/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0091, d_svhn_loss: 0.0161, d_fake_loss: 0.0439, g_loss: 1.1258\n",
            "Step [63520/80000], d_real_loss: 0.1176, d_mnist_loss: 0.0041, d_svhn_loss: 0.1136, d_fake_loss: 0.0287, g_loss: 1.1789\n",
            "Step [63530/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0020, d_svhn_loss: 0.0174, d_fake_loss: 0.0250, g_loss: 1.1394\n",
            "Step [63540/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0041, d_svhn_loss: 0.0280, d_fake_loss: 0.0341, g_loss: 0.9847\n",
            "Step [63550/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0032, d_svhn_loss: 0.0227, d_fake_loss: 0.0228, g_loss: 1.2485\n",
            "Step [63560/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0015, d_svhn_loss: 0.0199, d_fake_loss: 0.0285, g_loss: 1.1209\n",
            "Step [63570/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0022, d_svhn_loss: 0.0219, d_fake_loss: 0.0255, g_loss: 1.2037\n",
            "Step [63580/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0017, d_svhn_loss: 0.0168, d_fake_loss: 0.0566, g_loss: 1.0718\n",
            "Step [63590/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0045, d_svhn_loss: 0.0270, d_fake_loss: 0.0111, g_loss: 1.1504\n",
            "Step [63600/80000], d_real_loss: 0.0135, d_mnist_loss: 0.0016, d_svhn_loss: 0.0119, d_fake_loss: 0.0211, g_loss: 1.0979\n",
            "Step [63610/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0021, d_svhn_loss: 0.0372, d_fake_loss: 0.0781, g_loss: 1.1159\n",
            "Step [63620/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0027, d_svhn_loss: 0.0715, d_fake_loss: 0.0441, g_loss: 1.0802\n",
            "Step [63630/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0026, d_svhn_loss: 0.0259, d_fake_loss: 0.0150, g_loss: 1.1203\n",
            "Step [63640/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0156, d_svhn_loss: 0.0196, d_fake_loss: 0.0513, g_loss: 1.0964\n",
            "Step [63650/80000], d_real_loss: 0.0281, d_mnist_loss: 0.0030, d_svhn_loss: 0.0251, d_fake_loss: 0.0193, g_loss: 1.1434\n",
            "Step [63660/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0030, d_svhn_loss: 0.0205, d_fake_loss: 0.0136, g_loss: 1.1487\n",
            "Step [63670/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0028, d_svhn_loss: 0.0224, d_fake_loss: 0.0456, g_loss: 1.1299\n",
            "Step [63680/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0028, d_svhn_loss: 0.0215, d_fake_loss: 0.0130, g_loss: 1.1249\n",
            "Step [63690/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0021, d_svhn_loss: 0.0219, d_fake_loss: 0.0203, g_loss: 1.1045\n",
            "Step [63700/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0023, d_svhn_loss: 0.0250, d_fake_loss: 0.0449, g_loss: 1.1163\n",
            "Step [63710/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0021, d_svhn_loss: 0.0348, d_fake_loss: 0.0381, g_loss: 1.1863\n",
            "Step [63720/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0018, d_svhn_loss: 0.0291, d_fake_loss: 0.0114, g_loss: 1.1559\n",
            "Step [63730/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0018, d_svhn_loss: 0.0169, d_fake_loss: 0.0610, g_loss: 1.2028\n",
            "Step [63740/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0017, d_svhn_loss: 0.0325, d_fake_loss: 0.1882, g_loss: 1.3096\n",
            "Step [63750/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0052, d_svhn_loss: 0.0377, d_fake_loss: 0.0191, g_loss: 1.1404\n",
            "Step [63760/80000], d_real_loss: 0.0219, d_mnist_loss: 0.0016, d_svhn_loss: 0.0203, d_fake_loss: 0.0184, g_loss: 1.1366\n",
            "Step [63770/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0040, d_svhn_loss: 0.0133, d_fake_loss: 0.0106, g_loss: 1.1296\n",
            "Step [63780/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0024, d_svhn_loss: 0.0415, d_fake_loss: 0.0380, g_loss: 1.1059\n",
            "Step [63790/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0063, d_svhn_loss: 0.0432, d_fake_loss: 0.0255, g_loss: 1.0873\n",
            "Step [63800/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0047, d_svhn_loss: 0.0280, d_fake_loss: 0.0155, g_loss: 1.1351\n",
            "Step [63810/80000], d_real_loss: 0.0176, d_mnist_loss: 0.0010, d_svhn_loss: 0.0166, d_fake_loss: 0.0343, g_loss: 1.1224\n",
            "Step [63820/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0018, d_svhn_loss: 0.0339, d_fake_loss: 0.0741, g_loss: 1.1363\n",
            "Step [63830/80000], d_real_loss: 0.0150, d_mnist_loss: 0.0021, d_svhn_loss: 0.0129, d_fake_loss: 0.0151, g_loss: 1.0938\n",
            "Step [63840/80000], d_real_loss: 0.0189, d_mnist_loss: 0.0017, d_svhn_loss: 0.0172, d_fake_loss: 0.0586, g_loss: 1.1212\n",
            "Step [63850/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0017, d_svhn_loss: 0.0226, d_fake_loss: 0.0150, g_loss: 1.1650\n",
            "Step [63860/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0025, d_svhn_loss: 0.0371, d_fake_loss: 0.0149, g_loss: 1.1044\n",
            "Step [63870/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0128, d_svhn_loss: 0.0174, d_fake_loss: 0.0155, g_loss: 1.1130\n",
            "Step [63880/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0026, d_svhn_loss: 0.0239, d_fake_loss: 0.0221, g_loss: 1.0577\n",
            "Step [63890/80000], d_real_loss: 0.1467, d_mnist_loss: 0.0027, d_svhn_loss: 0.1440, d_fake_loss: 0.0939, g_loss: 1.1338\n",
            "Step [63900/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0133, d_svhn_loss: 0.0224, d_fake_loss: 0.0565, g_loss: 1.4498\n",
            "Step [63910/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0044, d_svhn_loss: 0.0257, d_fake_loss: 0.0429, g_loss: 1.3104\n",
            "Step [63920/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0096, d_svhn_loss: 0.0477, d_fake_loss: 0.0108, g_loss: 1.1400\n",
            "Step [63930/80000], d_real_loss: 0.0769, d_mnist_loss: 0.0227, d_svhn_loss: 0.0543, d_fake_loss: 0.0773, g_loss: 1.1809\n",
            "Step [63940/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0039, d_svhn_loss: 0.0266, d_fake_loss: 0.0241, g_loss: 1.1604\n",
            "Step [63950/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0021, d_svhn_loss: 0.0321, d_fake_loss: 0.0081, g_loss: 1.1528\n",
            "Step [63960/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0158, d_svhn_loss: 0.0135, d_fake_loss: 0.0232, g_loss: 1.1633\n",
            "Step [63970/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0028, d_svhn_loss: 0.0166, d_fake_loss: 0.0311, g_loss: 1.2592\n",
            "Step [63980/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0016, d_svhn_loss: 0.0207, d_fake_loss: 0.0157, g_loss: 1.1922\n",
            "Step [63990/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0026, d_svhn_loss: 0.0223, d_fake_loss: 0.0119, g_loss: 1.2028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [64000/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0021, d_svhn_loss: 0.0255, d_fake_loss: 0.0362, g_loss: 1.1818\n",
            "saved ./samples_mnist_svhn/sample-64000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-64000-s-m.png\n",
            "Step [64010/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0033, d_svhn_loss: 0.0282, d_fake_loss: 0.0165, g_loss: 1.0768\n",
            "Step [64020/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0055, d_svhn_loss: 0.0231, d_fake_loss: 0.0171, g_loss: 1.2156\n",
            "Step [64030/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0027, d_svhn_loss: 0.0259, d_fake_loss: 0.0390, g_loss: 1.1354\n",
            "Step [64040/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0201, d_svhn_loss: 0.0490, d_fake_loss: 0.0197, g_loss: 1.1499\n",
            "Step [64050/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0023, d_svhn_loss: 0.0263, d_fake_loss: 0.0151, g_loss: 1.1467\n",
            "Step [64060/80000], d_real_loss: 0.0164, d_mnist_loss: 0.0022, d_svhn_loss: 0.0142, d_fake_loss: 0.0170, g_loss: 1.1384\n",
            "Step [64070/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0020, d_svhn_loss: 0.0411, d_fake_loss: 0.0079, g_loss: 1.1371\n",
            "Step [64080/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0051, d_svhn_loss: 0.0210, d_fake_loss: 0.0309, g_loss: 1.2031\n",
            "Step [64090/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0015, d_svhn_loss: 0.0191, d_fake_loss: 0.0171, g_loss: 1.1146\n",
            "Step [64100/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0026, d_svhn_loss: 0.0198, d_fake_loss: 0.0357, g_loss: 1.1668\n",
            "Step [64110/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0047, d_svhn_loss: 0.0214, d_fake_loss: 0.0165, g_loss: 1.1872\n",
            "Step [64120/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0019, d_svhn_loss: 0.0308, d_fake_loss: 0.0468, g_loss: 1.1682\n",
            "Step [64130/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0052, d_svhn_loss: 0.0130, d_fake_loss: 0.0891, g_loss: 1.0961\n",
            "Step [64140/80000], d_real_loss: 0.0171, d_mnist_loss: 0.0029, d_svhn_loss: 0.0142, d_fake_loss: 0.0130, g_loss: 1.1677\n",
            "Step [64150/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0027, d_svhn_loss: 0.0188, d_fake_loss: 0.0140, g_loss: 1.2280\n",
            "Step [64160/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0023, d_svhn_loss: 0.0177, d_fake_loss: 0.0129, g_loss: 1.2346\n",
            "Step [64170/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0082, d_svhn_loss: 0.0210, d_fake_loss: 0.0405, g_loss: 1.0837\n",
            "Step [64180/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0023, d_svhn_loss: 0.0173, d_fake_loss: 0.0088, g_loss: 1.1272\n",
            "Step [64190/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0044, d_svhn_loss: 0.0232, d_fake_loss: 0.0197, g_loss: 1.1437\n",
            "Step [64200/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0017, d_svhn_loss: 0.0310, d_fake_loss: 0.0237, g_loss: 1.1458\n",
            "Step [64210/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0027, d_svhn_loss: 0.0189, d_fake_loss: 0.0627, g_loss: 1.1527\n",
            "Step [64220/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0105, d_svhn_loss: 0.0173, d_fake_loss: 0.0095, g_loss: 1.2326\n",
            "Step [64230/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0039, d_svhn_loss: 0.0186, d_fake_loss: 0.0198, g_loss: 1.1256\n",
            "Step [64240/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0028, d_svhn_loss: 0.0162, d_fake_loss: 0.0108, g_loss: 1.1869\n",
            "Step [64250/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0022, d_svhn_loss: 0.0216, d_fake_loss: 0.0151, g_loss: 1.1133\n",
            "Step [64260/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0057, d_svhn_loss: 0.0177, d_fake_loss: 0.0202, g_loss: 1.0619\n",
            "Step [64270/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0122, d_svhn_loss: 0.0245, d_fake_loss: 0.0367, g_loss: 1.2041\n",
            "Step [64280/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0016, d_svhn_loss: 0.0198, d_fake_loss: 0.0141, g_loss: 1.1248\n",
            "Step [64290/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0133, d_svhn_loss: 0.0507, d_fake_loss: 0.0314, g_loss: 1.1710\n",
            "Step [64300/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0037, d_svhn_loss: 0.0264, d_fake_loss: 0.0113, g_loss: 1.1054\n",
            "Step [64310/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0019, d_svhn_loss: 0.0358, d_fake_loss: 0.0333, g_loss: 1.1517\n",
            "Step [64320/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0019, d_svhn_loss: 0.0191, d_fake_loss: 0.0128, g_loss: 1.1647\n",
            "Step [64330/80000], d_real_loss: 0.0946, d_mnist_loss: 0.0022, d_svhn_loss: 0.0925, d_fake_loss: 0.0198, g_loss: 1.1189\n",
            "Step [64340/80000], d_real_loss: 0.1297, d_mnist_loss: 0.0064, d_svhn_loss: 0.1233, d_fake_loss: 0.0144, g_loss: 1.1787\n",
            "Step [64350/80000], d_real_loss: 0.0907, d_mnist_loss: 0.0019, d_svhn_loss: 0.0887, d_fake_loss: 0.0461, g_loss: 1.1330\n",
            "Step [64360/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0044, d_svhn_loss: 0.0313, d_fake_loss: 0.0295, g_loss: 1.2233\n",
            "Step [64370/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0027, d_svhn_loss: 0.0314, d_fake_loss: 0.0128, g_loss: 1.1123\n",
            "Step [64380/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0022, d_svhn_loss: 0.0444, d_fake_loss: 0.0178, g_loss: 1.1412\n",
            "Step [64390/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0013, d_svhn_loss: 0.0193, d_fake_loss: 0.0385, g_loss: 1.1201\n",
            "Step [64400/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0051, d_svhn_loss: 0.0154, d_fake_loss: 0.0119, g_loss: 1.1206\n",
            "Step [64410/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0034, d_svhn_loss: 0.0380, d_fake_loss: 0.0485, g_loss: 1.1694\n",
            "Step [64420/80000], d_real_loss: 0.0134, d_mnist_loss: 0.0018, d_svhn_loss: 0.0116, d_fake_loss: 0.0239, g_loss: 1.2357\n",
            "Step [64430/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0075, d_svhn_loss: 0.0161, d_fake_loss: 0.1002, g_loss: 1.0332\n",
            "Step [64440/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0028, d_svhn_loss: 0.0585, d_fake_loss: 0.0371, g_loss: 1.0832\n",
            "Step [64450/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0019, d_svhn_loss: 0.0356, d_fake_loss: 0.0407, g_loss: 1.1921\n",
            "Step [64460/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0013, d_svhn_loss: 0.0224, d_fake_loss: 0.0149, g_loss: 1.0897\n",
            "Step [64470/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0034, d_svhn_loss: 0.0156, d_fake_loss: 0.0401, g_loss: 1.0882\n",
            "Step [64480/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0018, d_svhn_loss: 0.0178, d_fake_loss: 0.0180, g_loss: 1.0473\n",
            "Step [64490/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0056, d_svhn_loss: 0.0335, d_fake_loss: 0.0304, g_loss: 1.0451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [64500/80000], d_real_loss: 0.0165, d_mnist_loss: 0.0022, d_svhn_loss: 0.0143, d_fake_loss: 0.0129, g_loss: 1.0905\n",
            "saved ./samples_mnist_svhn/sample-64500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-64500-s-m.png\n",
            "Step [64510/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0019, d_svhn_loss: 0.0242, d_fake_loss: 0.0171, g_loss: 1.2401\n",
            "Step [64520/80000], d_real_loss: 0.0169, d_mnist_loss: 0.0047, d_svhn_loss: 0.0122, d_fake_loss: 0.0366, g_loss: 1.1794\n",
            "Step [64530/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0026, d_svhn_loss: 0.0359, d_fake_loss: 0.0206, g_loss: 1.1752\n",
            "Step [64540/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0023, d_svhn_loss: 0.0149, d_fake_loss: 0.0423, g_loss: 1.1162\n",
            "Step [64550/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0089, d_svhn_loss: 0.0359, d_fake_loss: 0.0387, g_loss: 1.0695\n",
            "Step [64560/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0022, d_svhn_loss: 0.0557, d_fake_loss: 0.1158, g_loss: 1.1022\n",
            "Step [64570/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0048, d_svhn_loss: 0.0266, d_fake_loss: 0.0255, g_loss: 1.1721\n",
            "Step [64580/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0018, d_svhn_loss: 0.0163, d_fake_loss: 0.0144, g_loss: 1.1676\n",
            "Step [64590/80000], d_real_loss: 0.0213, d_mnist_loss: 0.0031, d_svhn_loss: 0.0182, d_fake_loss: 0.0331, g_loss: 1.0981\n",
            "Step [64600/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0019, d_svhn_loss: 0.0167, d_fake_loss: 0.0170, g_loss: 1.1320\n",
            "Step [64610/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0018, d_svhn_loss: 0.0165, d_fake_loss: 0.0279, g_loss: 1.1721\n",
            "Step [64620/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0011, d_svhn_loss: 0.0205, d_fake_loss: 0.0281, g_loss: 1.0798\n",
            "Step [64630/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0110, d_svhn_loss: 0.0257, d_fake_loss: 0.0173, g_loss: 1.1569\n",
            "Step [64640/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0013, d_svhn_loss: 0.0202, d_fake_loss: 0.0323, g_loss: 1.1667\n",
            "Step [64650/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0042, d_svhn_loss: 0.0660, d_fake_loss: 0.1575, g_loss: 1.1623\n",
            "Step [64660/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0037, d_svhn_loss: 0.0216, d_fake_loss: 0.0261, g_loss: 1.1740\n",
            "Step [64670/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0093, d_svhn_loss: 0.0181, d_fake_loss: 0.0127, g_loss: 1.1254\n",
            "Step [64680/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0127, d_svhn_loss: 0.0361, d_fake_loss: 0.0183, g_loss: 1.1552\n",
            "Step [64690/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0013, d_svhn_loss: 0.0168, d_fake_loss: 0.0181, g_loss: 1.2311\n",
            "Step [64700/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0056, d_svhn_loss: 0.0478, d_fake_loss: 0.0171, g_loss: 1.1779\n",
            "Step [64710/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0014, d_svhn_loss: 0.0281, d_fake_loss: 0.0406, g_loss: 1.0763\n",
            "Step [64720/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0022, d_svhn_loss: 0.0156, d_fake_loss: 0.0544, g_loss: 1.1614\n",
            "Step [64730/80000], d_real_loss: 0.0878, d_mnist_loss: 0.0007, d_svhn_loss: 0.0871, d_fake_loss: 0.1289, g_loss: 1.1866\n",
            "Step [64740/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0010, d_svhn_loss: 0.0168, d_fake_loss: 0.0576, g_loss: 1.2515\n",
            "Step [64750/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0079, d_svhn_loss: 0.0164, d_fake_loss: 0.0266, g_loss: 1.1149\n",
            "Step [64760/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0040, d_svhn_loss: 0.0573, d_fake_loss: 0.0330, g_loss: 1.1549\n",
            "Step [64770/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0014, d_svhn_loss: 0.0159, d_fake_loss: 0.0800, g_loss: 1.3334\n",
            "Step [64780/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0019, d_svhn_loss: 0.0642, d_fake_loss: 0.0517, g_loss: 1.1011\n",
            "Step [64790/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0014, d_svhn_loss: 0.0249, d_fake_loss: 0.0323, g_loss: 1.1128\n",
            "Step [64800/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0023, d_svhn_loss: 0.0150, d_fake_loss: 0.0527, g_loss: 1.3451\n",
            "Step [64810/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0105, d_svhn_loss: 0.0202, d_fake_loss: 0.0165, g_loss: 1.1654\n",
            "Step [64820/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0097, d_svhn_loss: 0.0123, d_fake_loss: 0.0268, g_loss: 1.0856\n",
            "Step [64830/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0061, d_svhn_loss: 0.0287, d_fake_loss: 0.0257, g_loss: 1.1827\n",
            "Step [64840/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0026, d_svhn_loss: 0.0183, d_fake_loss: 0.0354, g_loss: 1.1637\n",
            "Step [64850/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0029, d_svhn_loss: 0.0225, d_fake_loss: 0.0466, g_loss: 1.0659\n",
            "Step [64860/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0022, d_svhn_loss: 0.0294, d_fake_loss: 0.0269, g_loss: 1.1269\n",
            "Step [64870/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0039, d_svhn_loss: 0.0134, d_fake_loss: 0.0689, g_loss: 1.0073\n",
            "Step [64880/80000], d_real_loss: 0.0129, d_mnist_loss: 0.0028, d_svhn_loss: 0.0102, d_fake_loss: 0.0794, g_loss: 1.1605\n",
            "Step [64890/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0024, d_svhn_loss: 0.0310, d_fake_loss: 0.0191, g_loss: 1.1272\n",
            "Step [64900/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0024, d_svhn_loss: 0.0194, d_fake_loss: 0.0746, g_loss: 1.2966\n",
            "Step [64910/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0059, d_svhn_loss: 0.0432, d_fake_loss: 0.0317, g_loss: 1.1443\n",
            "Step [64920/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0069, d_svhn_loss: 0.0545, d_fake_loss: 0.0643, g_loss: 1.0918\n",
            "Step [64930/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0103, d_svhn_loss: 0.0453, d_fake_loss: 0.0148, g_loss: 1.2004\n",
            "Step [64940/80000], d_real_loss: 0.0154, d_mnist_loss: 0.0022, d_svhn_loss: 0.0132, d_fake_loss: 0.0270, g_loss: 1.1771\n",
            "Step [64950/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0013, d_svhn_loss: 0.0186, d_fake_loss: 0.0138, g_loss: 1.1829\n",
            "Step [64960/80000], d_real_loss: 0.1140, d_mnist_loss: 0.0023, d_svhn_loss: 0.1117, d_fake_loss: 0.0243, g_loss: 1.2488\n",
            "Step [64970/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0037, d_svhn_loss: 0.0345, d_fake_loss: 0.0913, g_loss: 1.3633\n",
            "Step [64980/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0025, d_svhn_loss: 0.0194, d_fake_loss: 0.0249, g_loss: 1.2023\n",
            "Step [64990/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0027, d_svhn_loss: 0.0258, d_fake_loss: 0.0186, g_loss: 1.1575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [65000/80000], d_real_loss: 0.0932, d_mnist_loss: 0.0030, d_svhn_loss: 0.0902, d_fake_loss: 0.0154, g_loss: 1.1174\n",
            "saved ./samples_mnist_svhn/sample-65000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-65000-s-m.png\n",
            "Step [65010/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0023, d_svhn_loss: 0.0155, d_fake_loss: 0.0810, g_loss: 1.2335\n",
            "Step [65020/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0016, d_svhn_loss: 0.0361, d_fake_loss: 0.0386, g_loss: 1.2417\n",
            "Step [65030/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0025, d_svhn_loss: 0.0760, d_fake_loss: 0.0240, g_loss: 1.1757\n",
            "Step [65040/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0016, d_svhn_loss: 0.0255, d_fake_loss: 0.0200, g_loss: 1.3708\n",
            "Step [65050/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0149, d_svhn_loss: 0.0220, d_fake_loss: 0.0592, g_loss: 1.1558\n",
            "Step [65060/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0066, d_svhn_loss: 0.0121, d_fake_loss: 0.0492, g_loss: 1.1373\n",
            "Step [65070/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0038, d_svhn_loss: 0.0403, d_fake_loss: 0.0134, g_loss: 1.1433\n",
            "Step [65080/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0040, d_svhn_loss: 0.0379, d_fake_loss: 0.0345, g_loss: 1.1809\n",
            "Step [65090/80000], d_real_loss: 0.0219, d_mnist_loss: 0.0089, d_svhn_loss: 0.0130, d_fake_loss: 0.0288, g_loss: 1.1158\n",
            "Step [65100/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0050, d_svhn_loss: 0.0170, d_fake_loss: 0.0160, g_loss: 1.1662\n",
            "Step [65110/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0034, d_svhn_loss: 0.0293, d_fake_loss: 0.0131, g_loss: 1.2541\n",
            "Step [65120/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0063, d_svhn_loss: 0.0342, d_fake_loss: 0.0133, g_loss: 1.2401\n",
            "Step [65130/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0021, d_svhn_loss: 0.0286, d_fake_loss: 0.0335, g_loss: 1.1064\n",
            "Step [65140/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0046, d_svhn_loss: 0.0195, d_fake_loss: 0.0411, g_loss: 1.1731\n",
            "Step [65150/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0032, d_svhn_loss: 0.0242, d_fake_loss: 0.0151, g_loss: 1.1297\n",
            "Step [65160/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0065, d_svhn_loss: 0.0178, d_fake_loss: 0.0325, g_loss: 1.1305\n",
            "Step [65170/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0025, d_svhn_loss: 0.0201, d_fake_loss: 0.0105, g_loss: 1.2402\n",
            "Step [65180/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0028, d_svhn_loss: 0.0178, d_fake_loss: 0.0607, g_loss: 1.3200\n",
            "Step [65190/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0139, d_svhn_loss: 0.0188, d_fake_loss: 0.0209, g_loss: 1.0491\n",
            "Step [65200/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0047, d_svhn_loss: 0.0576, d_fake_loss: 0.0496, g_loss: 1.0778\n",
            "Step [65210/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0041, d_svhn_loss: 0.0145, d_fake_loss: 0.0098, g_loss: 1.1186\n",
            "Step [65220/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0049, d_svhn_loss: 0.0302, d_fake_loss: 0.0070, g_loss: 1.1532\n",
            "Step [65230/80000], d_real_loss: 0.0130, d_mnist_loss: 0.0017, d_svhn_loss: 0.0113, d_fake_loss: 0.0187, g_loss: 1.1559\n",
            "Step [65240/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0038, d_svhn_loss: 0.0180, d_fake_loss: 0.0057, g_loss: 1.1723\n",
            "Step [65250/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0071, d_svhn_loss: 0.0233, d_fake_loss: 0.0356, g_loss: 1.0510\n",
            "Step [65260/80000], d_real_loss: 0.0153, d_mnist_loss: 0.0020, d_svhn_loss: 0.0133, d_fake_loss: 0.0264, g_loss: 1.1916\n",
            "Step [65270/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0028, d_svhn_loss: 0.0484, d_fake_loss: 0.0084, g_loss: 1.1556\n",
            "Step [65280/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0056, d_svhn_loss: 0.0179, d_fake_loss: 0.0090, g_loss: 1.1724\n",
            "Step [65290/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0033, d_svhn_loss: 0.0286, d_fake_loss: 0.1078, g_loss: 1.0749\n",
            "Step [65300/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0067, d_svhn_loss: 0.0285, d_fake_loss: 0.0141, g_loss: 1.1584\n",
            "Step [65310/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0158, d_svhn_loss: 0.0199, d_fake_loss: 0.0152, g_loss: 1.0943\n",
            "Step [65320/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0088, d_svhn_loss: 0.0407, d_fake_loss: 0.0159, g_loss: 1.2081\n",
            "Step [65330/80000], d_real_loss: 0.1362, d_mnist_loss: 0.0021, d_svhn_loss: 0.1341, d_fake_loss: 0.0130, g_loss: 1.1395\n",
            "Step [65340/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0037, d_svhn_loss: 0.0347, d_fake_loss: 0.0690, g_loss: 1.0961\n",
            "Step [65350/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0021, d_svhn_loss: 0.0333, d_fake_loss: 0.0323, g_loss: 1.1093\n",
            "Step [65360/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0020, d_svhn_loss: 0.0556, d_fake_loss: 0.1010, g_loss: 1.1146\n",
            "Step [65370/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0037, d_svhn_loss: 0.0222, d_fake_loss: 0.0486, g_loss: 1.1728\n",
            "Step [65380/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0065, d_svhn_loss: 0.0157, d_fake_loss: 0.0237, g_loss: 1.0836\n",
            "Step [65390/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0069, d_svhn_loss: 0.0313, d_fake_loss: 0.0084, g_loss: 1.0973\n",
            "Step [65400/80000], d_real_loss: 0.0150, d_mnist_loss: 0.0026, d_svhn_loss: 0.0124, d_fake_loss: 0.0122, g_loss: 1.1315\n",
            "Step [65410/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0035, d_svhn_loss: 0.0307, d_fake_loss: 0.0159, g_loss: 1.2724\n",
            "Step [65420/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0033, d_svhn_loss: 0.0305, d_fake_loss: 0.0497, g_loss: 1.0644\n",
            "Step [65430/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0022, d_svhn_loss: 0.0263, d_fake_loss: 0.0282, g_loss: 1.1493\n",
            "Step [65440/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0032, d_svhn_loss: 0.0657, d_fake_loss: 0.0156, g_loss: 1.0316\n",
            "Step [65450/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0077, d_svhn_loss: 0.0211, d_fake_loss: 0.0535, g_loss: 1.2308\n",
            "Step [65460/80000], d_real_loss: 0.0140, d_mnist_loss: 0.0031, d_svhn_loss: 0.0109, d_fake_loss: 0.0215, g_loss: 1.2248\n",
            "Step [65470/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0064, d_svhn_loss: 0.0601, d_fake_loss: 0.0738, g_loss: 1.2625\n",
            "Step [65480/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0081, d_svhn_loss: 0.0261, d_fake_loss: 0.0204, g_loss: 1.1300\n",
            "Step [65490/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0115, d_svhn_loss: 0.0141, d_fake_loss: 0.0714, g_loss: 1.2865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [65500/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0030, d_svhn_loss: 0.0344, d_fake_loss: 0.0365, g_loss: 1.1810\n",
            "saved ./samples_mnist_svhn/sample-65500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-65500-s-m.png\n",
            "Step [65510/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0055, d_svhn_loss: 0.0170, d_fake_loss: 0.0213, g_loss: 1.0804\n",
            "Step [65520/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0027, d_svhn_loss: 0.0579, d_fake_loss: 0.0161, g_loss: 1.1437\n",
            "Step [65530/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0023, d_svhn_loss: 0.0175, d_fake_loss: 0.0331, g_loss: 1.1468\n",
            "Step [65540/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0098, d_svhn_loss: 0.0341, d_fake_loss: 0.0762, g_loss: 1.1035\n",
            "Step [65550/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0041, d_svhn_loss: 0.0166, d_fake_loss: 0.0147, g_loss: 1.1364\n",
            "Step [65560/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0017, d_svhn_loss: 0.0240, d_fake_loss: 0.0978, g_loss: 1.1587\n",
            "Step [65570/80000], d_real_loss: 0.0175, d_mnist_loss: 0.0030, d_svhn_loss: 0.0145, d_fake_loss: 0.0143, g_loss: 1.1191\n",
            "Step [65580/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0053, d_svhn_loss: 0.0287, d_fake_loss: 0.0167, g_loss: 1.1500\n",
            "Step [65590/80000], d_real_loss: 0.0166, d_mnist_loss: 0.0028, d_svhn_loss: 0.0139, d_fake_loss: 0.0196, g_loss: 1.1950\n",
            "Step [65600/80000], d_real_loss: 0.1171, d_mnist_loss: 0.0014, d_svhn_loss: 0.1158, d_fake_loss: 0.0206, g_loss: 1.0768\n",
            "Step [65610/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0019, d_svhn_loss: 0.0163, d_fake_loss: 0.0167, g_loss: 1.1571\n",
            "Step [65620/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0020, d_svhn_loss: 0.0561, d_fake_loss: 0.1614, g_loss: 1.0914\n",
            "Step [65630/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0114, d_svhn_loss: 0.0186, d_fake_loss: 0.0718, g_loss: 1.0933\n",
            "Step [65640/80000], d_real_loss: 0.0164, d_mnist_loss: 0.0023, d_svhn_loss: 0.0141, d_fake_loss: 0.0136, g_loss: 1.1183\n",
            "Step [65650/80000], d_real_loss: 0.0188, d_mnist_loss: 0.0025, d_svhn_loss: 0.0163, d_fake_loss: 0.0121, g_loss: 1.1485\n",
            "Step [65660/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0067, d_svhn_loss: 0.0350, d_fake_loss: 0.0160, g_loss: 1.1544\n",
            "Step [65670/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0029, d_svhn_loss: 0.0413, d_fake_loss: 0.0091, g_loss: 1.1184\n",
            "Step [65680/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0063, d_svhn_loss: 0.0174, d_fake_loss: 0.0318, g_loss: 1.1125\n",
            "Step [65690/80000], d_real_loss: 0.0158, d_mnist_loss: 0.0019, d_svhn_loss: 0.0138, d_fake_loss: 0.0981, g_loss: 1.1169\n",
            "Step [65700/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0013, d_svhn_loss: 0.0353, d_fake_loss: 0.0223, g_loss: 1.1090\n",
            "Step [65710/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0032, d_svhn_loss: 0.0324, d_fake_loss: 0.0272, g_loss: 1.1316\n",
            "Step [65720/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0037, d_svhn_loss: 0.0170, d_fake_loss: 0.0162, g_loss: 1.1124\n",
            "Step [65730/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0031, d_svhn_loss: 0.0780, d_fake_loss: 0.0541, g_loss: 1.0933\n",
            "Step [65740/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0044, d_svhn_loss: 0.0176, d_fake_loss: 0.0261, g_loss: 1.2036\n",
            "Step [65750/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0017, d_svhn_loss: 0.0237, d_fake_loss: 0.0113, g_loss: 1.1006\n",
            "Step [65760/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0023, d_svhn_loss: 0.0350, d_fake_loss: 0.0212, g_loss: 1.1064\n",
            "Step [65770/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0029, d_svhn_loss: 0.0461, d_fake_loss: 0.0429, g_loss: 1.1548\n",
            "Step [65780/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0022, d_svhn_loss: 0.0418, d_fake_loss: 0.0133, g_loss: 1.1545\n",
            "Step [65790/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0033, d_svhn_loss: 0.0168, d_fake_loss: 0.0162, g_loss: 1.1242\n",
            "Step [65800/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0020, d_svhn_loss: 0.0406, d_fake_loss: 0.0180, g_loss: 1.2337\n",
            "Step [65810/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0035, d_svhn_loss: 0.0500, d_fake_loss: 0.0628, g_loss: 1.0814\n",
            "Step [65820/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0042, d_svhn_loss: 0.0276, d_fake_loss: 0.0350, g_loss: 1.1928\n",
            "Step [65830/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0122, d_svhn_loss: 0.0283, d_fake_loss: 0.0308, g_loss: 1.1807\n",
            "Step [65840/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0026, d_svhn_loss: 0.0267, d_fake_loss: 0.0229, g_loss: 1.2039\n",
            "Step [65850/80000], d_real_loss: 0.0930, d_mnist_loss: 0.0009, d_svhn_loss: 0.0920, d_fake_loss: 0.0748, g_loss: 1.2144\n",
            "Step [65860/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0022, d_svhn_loss: 0.0260, d_fake_loss: 0.0163, g_loss: 1.1281\n",
            "Step [65870/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0065, d_svhn_loss: 0.0116, d_fake_loss: 0.0303, g_loss: 1.1406\n",
            "Step [65880/80000], d_real_loss: 0.0224, d_mnist_loss: 0.0077, d_svhn_loss: 0.0147, d_fake_loss: 0.0079, g_loss: 1.1128\n",
            "Step [65890/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0017, d_svhn_loss: 0.0223, d_fake_loss: 0.0183, g_loss: 1.1624\n",
            "Step [65900/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0042, d_svhn_loss: 0.0328, d_fake_loss: 0.0192, g_loss: 1.1273\n",
            "Step [65910/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0028, d_svhn_loss: 0.0354, d_fake_loss: 0.0403, g_loss: 1.2035\n",
            "Step [65920/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0094, d_svhn_loss: 0.0636, d_fake_loss: 0.0256, g_loss: 1.1315\n",
            "Step [65930/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0086, d_svhn_loss: 0.0217, d_fake_loss: 0.0133, g_loss: 1.1356\n",
            "Step [65940/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0019, d_svhn_loss: 0.0702, d_fake_loss: 0.0406, g_loss: 1.4268\n",
            "Step [65950/80000], d_real_loss: 0.0148, d_mnist_loss: 0.0032, d_svhn_loss: 0.0116, d_fake_loss: 0.0877, g_loss: 1.0243\n",
            "Step [65960/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0045, d_svhn_loss: 0.0226, d_fake_loss: 0.0347, g_loss: 1.1205\n",
            "Step [65970/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0070, d_svhn_loss: 0.0251, d_fake_loss: 0.0288, g_loss: 1.2286\n",
            "Step [65980/80000], d_real_loss: 0.0957, d_mnist_loss: 0.0023, d_svhn_loss: 0.0934, d_fake_loss: 0.0142, g_loss: 1.2034\n",
            "Step [65990/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0035, d_svhn_loss: 0.0428, d_fake_loss: 0.0192, g_loss: 1.2297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [66000/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0023, d_svhn_loss: 0.0158, d_fake_loss: 0.0206, g_loss: 1.2035\n",
            "saved ./samples_mnist_svhn/sample-66000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-66000-s-m.png\n",
            "Step [66010/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0019, d_svhn_loss: 0.0213, d_fake_loss: 0.0138, g_loss: 1.2120\n",
            "Step [66020/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0287, d_svhn_loss: 0.0186, d_fake_loss: 0.0136, g_loss: 1.1838\n",
            "Step [66030/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0025, d_svhn_loss: 0.0260, d_fake_loss: 0.0744, g_loss: 1.1678\n",
            "Step [66040/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0023, d_svhn_loss: 0.0229, d_fake_loss: 0.0900, g_loss: 1.2175\n",
            "Step [66050/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0056, d_svhn_loss: 0.0180, d_fake_loss: 0.0133, g_loss: 1.1581\n",
            "Step [66060/80000], d_real_loss: 0.0106, d_mnist_loss: 0.0025, d_svhn_loss: 0.0081, d_fake_loss: 0.0757, g_loss: 1.2252\n",
            "Step [66070/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0032, d_svhn_loss: 0.0310, d_fake_loss: 0.0330, g_loss: 1.1431\n",
            "Step [66080/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0048, d_svhn_loss: 0.0258, d_fake_loss: 0.0192, g_loss: 1.2538\n",
            "Step [66090/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0110, d_svhn_loss: 0.0233, d_fake_loss: 0.0183, g_loss: 1.2720\n",
            "Step [66100/80000], d_real_loss: 0.0174, d_mnist_loss: 0.0019, d_svhn_loss: 0.0155, d_fake_loss: 0.0751, g_loss: 0.9995\n",
            "Step [66110/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0024, d_svhn_loss: 0.0251, d_fake_loss: 0.0465, g_loss: 1.1476\n",
            "Step [66120/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0025, d_svhn_loss: 0.0530, d_fake_loss: 0.0368, g_loss: 1.2513\n",
            "Step [66130/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0018, d_svhn_loss: 0.0221, d_fake_loss: 0.0287, g_loss: 1.2363\n",
            "Step [66140/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0151, d_svhn_loss: 0.0207, d_fake_loss: 0.0229, g_loss: 1.1379\n",
            "Step [66150/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0027, d_svhn_loss: 0.0279, d_fake_loss: 0.0187, g_loss: 1.2235\n",
            "Step [66160/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0021, d_svhn_loss: 0.0194, d_fake_loss: 0.0396, g_loss: 1.1149\n",
            "Step [66170/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0034, d_svhn_loss: 0.0337, d_fake_loss: 0.0422, g_loss: 1.1152\n",
            "Step [66180/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0058, d_svhn_loss: 0.0248, d_fake_loss: 0.0397, g_loss: 1.3298\n",
            "Step [66190/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0017, d_svhn_loss: 0.0177, d_fake_loss: 0.0191, g_loss: 1.1447\n",
            "Step [66200/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0022, d_svhn_loss: 0.0284, d_fake_loss: 0.0140, g_loss: 1.2097\n",
            "Step [66210/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0021, d_svhn_loss: 0.0223, d_fake_loss: 0.0644, g_loss: 1.1744\n",
            "Step [66220/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0027, d_svhn_loss: 0.0352, d_fake_loss: 0.0124, g_loss: 1.1499\n",
            "Step [66230/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0029, d_svhn_loss: 0.0261, d_fake_loss: 0.0182, g_loss: 1.1895\n",
            "Step [66240/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0072, d_svhn_loss: 0.0186, d_fake_loss: 0.0563, g_loss: 1.1365\n",
            "Step [66250/80000], d_real_loss: 0.0853, d_mnist_loss: 0.0045, d_svhn_loss: 0.0808, d_fake_loss: 0.1003, g_loss: 1.1641\n",
            "Step [66260/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0039, d_svhn_loss: 0.0335, d_fake_loss: 0.0270, g_loss: 1.2054\n",
            "Step [66270/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0038, d_svhn_loss: 0.0232, d_fake_loss: 0.0137, g_loss: 1.2285\n",
            "Step [66280/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0210, d_svhn_loss: 0.0246, d_fake_loss: 0.0586, g_loss: 1.1227\n",
            "Step [66290/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0056, d_svhn_loss: 0.0343, d_fake_loss: 0.0216, g_loss: 1.1103\n",
            "Step [66300/80000], d_real_loss: 0.0150, d_mnist_loss: 0.0029, d_svhn_loss: 0.0121, d_fake_loss: 0.0167, g_loss: 1.1485\n",
            "Step [66310/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0062, d_svhn_loss: 0.0225, d_fake_loss: 0.0169, g_loss: 1.1555\n",
            "Step [66320/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0018, d_svhn_loss: 0.0211, d_fake_loss: 0.0247, g_loss: 1.1648\n",
            "Step [66330/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0031, d_svhn_loss: 0.0224, d_fake_loss: 0.0287, g_loss: 1.2357\n",
            "Step [66340/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0072, d_svhn_loss: 0.0166, d_fake_loss: 0.0263, g_loss: 1.0955\n",
            "Step [66350/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0102, d_svhn_loss: 0.0185, d_fake_loss: 0.1109, g_loss: 1.1865\n",
            "Step [66360/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0247, d_svhn_loss: 0.0216, d_fake_loss: 0.0094, g_loss: 1.1191\n",
            "Step [66370/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0023, d_svhn_loss: 0.0187, d_fake_loss: 0.0346, g_loss: 1.0782\n",
            "Step [66380/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0049, d_svhn_loss: 0.0246, d_fake_loss: 0.0267, g_loss: 1.2223\n",
            "Step [66390/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0015, d_svhn_loss: 0.0207, d_fake_loss: 0.0533, g_loss: 1.1503\n",
            "Step [66400/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0013, d_svhn_loss: 0.0330, d_fake_loss: 0.0140, g_loss: 1.2032\n",
            "Step [66410/80000], d_real_loss: 0.0153, d_mnist_loss: 0.0016, d_svhn_loss: 0.0137, d_fake_loss: 0.0696, g_loss: 1.1341\n",
            "Step [66420/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0036, d_svhn_loss: 0.0190, d_fake_loss: 0.0596, g_loss: 1.1324\n",
            "Step [66430/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0098, d_svhn_loss: 0.0394, d_fake_loss: 0.0497, g_loss: 1.1095\n",
            "Step [66440/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0012, d_svhn_loss: 0.0165, d_fake_loss: 0.0209, g_loss: 1.1861\n",
            "Step [66450/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0025, d_svhn_loss: 0.0223, d_fake_loss: 0.0222, g_loss: 1.2362\n",
            "Step [66460/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0038, d_svhn_loss: 0.0276, d_fake_loss: 0.0503, g_loss: 1.2107\n",
            "Step [66470/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0034, d_svhn_loss: 0.0175, d_fake_loss: 0.0819, g_loss: 1.2697\n",
            "Step [66480/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0014, d_svhn_loss: 0.0257, d_fake_loss: 0.0217, g_loss: 1.1755\n",
            "Step [66490/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0047, d_svhn_loss: 0.0550, d_fake_loss: 0.0211, g_loss: 1.1744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [66500/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0041, d_svhn_loss: 0.0243, d_fake_loss: 0.0926, g_loss: 1.2105\n",
            "saved ./samples_mnist_svhn/sample-66500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-66500-s-m.png\n",
            "Step [66510/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0015, d_svhn_loss: 0.0553, d_fake_loss: 0.0261, g_loss: 1.1743\n",
            "Step [66520/80000], d_real_loss: 0.0167, d_mnist_loss: 0.0020, d_svhn_loss: 0.0148, d_fake_loss: 0.0582, g_loss: 1.1341\n",
            "Step [66530/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0038, d_svhn_loss: 0.0434, d_fake_loss: 0.0081, g_loss: 1.1491\n",
            "Step [66540/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0019, d_svhn_loss: 0.0416, d_fake_loss: 0.0298, g_loss: 1.1657\n",
            "Step [66550/80000], d_real_loss: 0.1747, d_mnist_loss: 0.0030, d_svhn_loss: 0.1717, d_fake_loss: 0.0283, g_loss: 1.2426\n",
            "Step [66560/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0027, d_svhn_loss: 0.0210, d_fake_loss: 0.0240, g_loss: 1.2106\n",
            "Step [66570/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0017, d_svhn_loss: 0.0205, d_fake_loss: 0.0551, g_loss: 1.2135\n",
            "Step [66580/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0015, d_svhn_loss: 0.0305, d_fake_loss: 0.0111, g_loss: 1.1250\n",
            "Step [66590/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0016, d_svhn_loss: 0.0239, d_fake_loss: 0.0277, g_loss: 1.1590\n",
            "Step [66600/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0058, d_svhn_loss: 0.0277, d_fake_loss: 0.0166, g_loss: 1.1561\n",
            "Step [66610/80000], d_real_loss: 0.0155, d_mnist_loss: 0.0024, d_svhn_loss: 0.0131, d_fake_loss: 0.0462, g_loss: 1.2189\n",
            "Step [66620/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0021, d_svhn_loss: 0.0477, d_fake_loss: 0.0149, g_loss: 1.0778\n",
            "Step [66630/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0020, d_svhn_loss: 0.0328, d_fake_loss: 0.0151, g_loss: 1.2059\n",
            "Step [66640/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0021, d_svhn_loss: 0.0330, d_fake_loss: 0.0169, g_loss: 1.1364\n",
            "Step [66650/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0018, d_svhn_loss: 0.0351, d_fake_loss: 0.0170, g_loss: 1.1490\n",
            "Step [66660/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0019, d_svhn_loss: 0.0351, d_fake_loss: 0.0106, g_loss: 1.1686\n",
            "Step [66670/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0149, d_svhn_loss: 0.0200, d_fake_loss: 0.0183, g_loss: 1.1568\n",
            "Step [66680/80000], d_real_loss: 0.1643, d_mnist_loss: 0.0016, d_svhn_loss: 0.1627, d_fake_loss: 0.0321, g_loss: 1.3996\n",
            "Step [66690/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0058, d_svhn_loss: 0.0202, d_fake_loss: 0.0198, g_loss: 1.2082\n",
            "Step [66700/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0051, d_svhn_loss: 0.0410, d_fake_loss: 0.0356, g_loss: 1.0771\n",
            "Step [66710/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0031, d_svhn_loss: 0.0255, d_fake_loss: 0.0499, g_loss: 1.0969\n",
            "Step [66720/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0050, d_svhn_loss: 0.0235, d_fake_loss: 0.0127, g_loss: 1.1368\n",
            "Step [66730/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0014, d_svhn_loss: 0.0442, d_fake_loss: 0.0168, g_loss: 1.1095\n",
            "Step [66740/80000], d_real_loss: 0.0169, d_mnist_loss: 0.0016, d_svhn_loss: 0.0152, d_fake_loss: 0.0347, g_loss: 1.0413\n",
            "Step [66750/80000], d_real_loss: 0.0156, d_mnist_loss: 0.0013, d_svhn_loss: 0.0143, d_fake_loss: 0.0482, g_loss: 1.1141\n",
            "Step [66760/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0052, d_svhn_loss: 0.0193, d_fake_loss: 0.0168, g_loss: 1.2472\n",
            "Step [66770/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0063, d_svhn_loss: 0.0258, d_fake_loss: 0.0233, g_loss: 1.1687\n",
            "Step [66780/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0028, d_svhn_loss: 0.0178, d_fake_loss: 0.0929, g_loss: 1.1119\n",
            "Step [66790/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0023, d_svhn_loss: 0.0374, d_fake_loss: 0.0210, g_loss: 1.1004\n",
            "Step [66800/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0029, d_svhn_loss: 0.0295, d_fake_loss: 0.0280, g_loss: 1.1791\n",
            "Step [66810/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0025, d_svhn_loss: 0.0223, d_fake_loss: 0.0125, g_loss: 1.1234\n",
            "Step [66820/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0027, d_svhn_loss: 0.0285, d_fake_loss: 0.0081, g_loss: 1.1295\n",
            "Step [66830/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0020, d_svhn_loss: 0.0383, d_fake_loss: 0.0370, g_loss: 1.1507\n",
            "Step [66840/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0024, d_svhn_loss: 0.0349, d_fake_loss: 0.0552, g_loss: 1.1496\n",
            "Step [66850/80000], d_real_loss: 0.0184, d_mnist_loss: 0.0021, d_svhn_loss: 0.0162, d_fake_loss: 0.0690, g_loss: 1.1401\n",
            "Step [66860/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0026, d_svhn_loss: 0.0384, d_fake_loss: 0.0542, g_loss: 1.1016\n",
            "Step [66870/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0059, d_svhn_loss: 0.0145, d_fake_loss: 0.0218, g_loss: 1.1087\n",
            "Step [66880/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0018, d_svhn_loss: 0.0357, d_fake_loss: 0.0154, g_loss: 1.1501\n",
            "Step [66890/80000], d_real_loss: 0.0213, d_mnist_loss: 0.0022, d_svhn_loss: 0.0191, d_fake_loss: 0.0265, g_loss: 1.2225\n",
            "Step [66900/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0074, d_svhn_loss: 0.0484, d_fake_loss: 0.0117, g_loss: 1.1575\n",
            "Step [66910/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0027, d_svhn_loss: 0.0159, d_fake_loss: 0.0158, g_loss: 1.1716\n",
            "Step [66920/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0094, d_svhn_loss: 0.0332, d_fake_loss: 0.0366, g_loss: 1.1359\n",
            "Step [66930/80000], d_real_loss: 0.0145, d_mnist_loss: 0.0024, d_svhn_loss: 0.0120, d_fake_loss: 0.0155, g_loss: 1.1643\n",
            "Step [66940/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0016, d_svhn_loss: 0.0210, d_fake_loss: 0.1361, g_loss: 1.1442\n",
            "Step [66950/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0125, d_svhn_loss: 0.0212, d_fake_loss: 0.0171, g_loss: 1.1178\n",
            "Step [66960/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0023, d_svhn_loss: 0.0164, d_fake_loss: 0.0269, g_loss: 1.1372\n",
            "Step [66970/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0107, d_svhn_loss: 0.0381, d_fake_loss: 0.0304, g_loss: 1.1054\n",
            "Step [66980/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0011, d_svhn_loss: 0.0207, d_fake_loss: 0.0191, g_loss: 1.1293\n",
            "Step [66990/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0030, d_svhn_loss: 0.0465, d_fake_loss: 0.0151, g_loss: 1.1428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [67000/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0016, d_svhn_loss: 0.0347, d_fake_loss: 0.0147, g_loss: 1.1755\n",
            "saved ./samples_mnist_svhn/sample-67000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-67000-s-m.png\n",
            "Step [67010/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0012, d_svhn_loss: 0.0205, d_fake_loss: 0.0174, g_loss: 1.1947\n",
            "Step [67020/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0035, d_svhn_loss: 0.0410, d_fake_loss: 0.0117, g_loss: 1.1691\n",
            "Step [67030/80000], d_real_loss: 0.1297, d_mnist_loss: 0.0036, d_svhn_loss: 0.1260, d_fake_loss: 0.0344, g_loss: 1.1640\n",
            "Step [67040/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0012, d_svhn_loss: 0.0565, d_fake_loss: 0.0132, g_loss: 1.0945\n",
            "Step [67050/80000], d_real_loss: 0.0145, d_mnist_loss: 0.0020, d_svhn_loss: 0.0125, d_fake_loss: 0.0852, g_loss: 1.1894\n",
            "Step [67060/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0146, d_svhn_loss: 0.0172, d_fake_loss: 0.0237, g_loss: 1.2374\n",
            "Step [67070/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0041, d_svhn_loss: 0.0157, d_fake_loss: 0.0353, g_loss: 1.1098\n",
            "Step [67080/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0021, d_svhn_loss: 0.0521, d_fake_loss: 0.0112, g_loss: 1.1184\n",
            "Step [67090/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0018, d_svhn_loss: 0.0268, d_fake_loss: 0.0417, g_loss: 1.1379\n",
            "Step [67100/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0020, d_svhn_loss: 0.0613, d_fake_loss: 0.0135, g_loss: 1.1234\n",
            "Step [67110/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0022, d_svhn_loss: 0.0163, d_fake_loss: 0.0137, g_loss: 1.1217\n",
            "Step [67120/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0061, d_svhn_loss: 0.0344, d_fake_loss: 0.0252, g_loss: 1.1810\n",
            "Step [67130/80000], d_real_loss: 0.0171, d_mnist_loss: 0.0014, d_svhn_loss: 0.0157, d_fake_loss: 0.0271, g_loss: 1.2007\n",
            "Step [67140/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0015, d_svhn_loss: 0.0224, d_fake_loss: 0.0385, g_loss: 1.1746\n",
            "Step [67150/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0014, d_svhn_loss: 0.0432, d_fake_loss: 0.0335, g_loss: 1.1409\n",
            "Step [67160/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0024, d_svhn_loss: 0.0232, d_fake_loss: 0.0251, g_loss: 1.1272\n",
            "Step [67170/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0026, d_svhn_loss: 0.0147, d_fake_loss: 0.0416, g_loss: 1.0894\n",
            "Step [67180/80000], d_real_loss: 0.0162, d_mnist_loss: 0.0015, d_svhn_loss: 0.0147, d_fake_loss: 0.0245, g_loss: 1.1793\n",
            "Step [67190/80000], d_real_loss: 0.0188, d_mnist_loss: 0.0019, d_svhn_loss: 0.0169, d_fake_loss: 0.0112, g_loss: 1.1611\n",
            "Step [67200/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0017, d_svhn_loss: 0.0213, d_fake_loss: 0.0401, g_loss: 1.0933\n",
            "Step [67210/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0069, d_svhn_loss: 0.0277, d_fake_loss: 0.0265, g_loss: 1.1356\n",
            "Step [67220/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0019, d_svhn_loss: 0.0256, d_fake_loss: 0.0349, g_loss: 1.2614\n",
            "Step [67230/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0031, d_svhn_loss: 0.0281, d_fake_loss: 0.0128, g_loss: 1.1457\n",
            "Step [67240/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0056, d_svhn_loss: 0.0209, d_fake_loss: 0.0129, g_loss: 1.1212\n",
            "Step [67250/80000], d_real_loss: 0.0184, d_mnist_loss: 0.0020, d_svhn_loss: 0.0165, d_fake_loss: 0.0942, g_loss: 1.0979\n",
            "Step [67260/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0017, d_svhn_loss: 0.0249, d_fake_loss: 0.0161, g_loss: 1.1875\n",
            "Step [67270/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0103, d_svhn_loss: 0.0203, d_fake_loss: 0.0291, g_loss: 1.1640\n",
            "Step [67280/80000], d_real_loss: 0.0171, d_mnist_loss: 0.0026, d_svhn_loss: 0.0145, d_fake_loss: 0.0314, g_loss: 1.1962\n",
            "Step [67290/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0017, d_svhn_loss: 0.0442, d_fake_loss: 0.0423, g_loss: 1.2094\n",
            "Step [67300/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0018, d_svhn_loss: 0.0240, d_fake_loss: 0.0119, g_loss: 1.1790\n",
            "Step [67310/80000], d_real_loss: 0.1008, d_mnist_loss: 0.0404, d_svhn_loss: 0.0604, d_fake_loss: 0.1058, g_loss: 1.1857\n",
            "Step [67320/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0045, d_svhn_loss: 0.0167, d_fake_loss: 0.0143, g_loss: 1.0919\n",
            "Step [67330/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0026, d_svhn_loss: 0.0363, d_fake_loss: 0.0540, g_loss: 1.1109\n",
            "Step [67340/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0015, d_svhn_loss: 0.0583, d_fake_loss: 0.0251, g_loss: 1.1617\n",
            "Step [67350/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0018, d_svhn_loss: 0.0229, d_fake_loss: 0.0142, g_loss: 1.1963\n",
            "Step [67360/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0044, d_svhn_loss: 0.0299, d_fake_loss: 0.0178, g_loss: 1.1287\n",
            "Step [67370/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0049, d_svhn_loss: 0.0370, d_fake_loss: 0.0146, g_loss: 1.0959\n",
            "Step [67380/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0031, d_svhn_loss: 0.0253, d_fake_loss: 0.0202, g_loss: 1.2212\n",
            "Step [67390/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0030, d_svhn_loss: 0.0186, d_fake_loss: 0.0399, g_loss: 1.1960\n",
            "Step [67400/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0014, d_svhn_loss: 0.0326, d_fake_loss: 0.0171, g_loss: 1.2612\n",
            "Step [67410/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0033, d_svhn_loss: 0.0706, d_fake_loss: 0.0942, g_loss: 1.1469\n",
            "Step [67420/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0072, d_svhn_loss: 0.0128, d_fake_loss: 0.0299, g_loss: 1.3159\n",
            "Step [67430/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0031, d_svhn_loss: 0.0143, d_fake_loss: 0.0072, g_loss: 1.1603\n",
            "Step [67440/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0102, d_svhn_loss: 0.0144, d_fake_loss: 0.0259, g_loss: 1.1846\n",
            "Step [67450/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0046, d_svhn_loss: 0.0197, d_fake_loss: 0.0151, g_loss: 1.1578\n",
            "Step [67460/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0023, d_svhn_loss: 0.0334, d_fake_loss: 0.0128, g_loss: 1.0963\n",
            "Step [67470/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0043, d_svhn_loss: 0.0246, d_fake_loss: 0.0553, g_loss: 1.2119\n",
            "Step [67480/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0031, d_svhn_loss: 0.0210, d_fake_loss: 0.0539, g_loss: 1.1434\n",
            "Step [67490/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0018, d_svhn_loss: 0.0396, d_fake_loss: 0.0056, g_loss: 1.1883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [67500/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0063, d_svhn_loss: 0.0360, d_fake_loss: 0.0067, g_loss: 1.1978\n",
            "saved ./samples_mnist_svhn/sample-67500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-67500-s-m.png\n",
            "Step [67510/80000], d_real_loss: 0.0157, d_mnist_loss: 0.0029, d_svhn_loss: 0.0128, d_fake_loss: 0.0189, g_loss: 1.1477\n",
            "Step [67520/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0045, d_svhn_loss: 0.0530, d_fake_loss: 0.0837, g_loss: 1.3206\n",
            "Step [67530/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0020, d_svhn_loss: 0.0657, d_fake_loss: 0.0213, g_loss: 1.1476\n",
            "Step [67540/80000], d_real_loss: 0.0193, d_mnist_loss: 0.0048, d_svhn_loss: 0.0144, d_fake_loss: 0.0384, g_loss: 1.1759\n",
            "Step [67550/80000], d_real_loss: 0.0176, d_mnist_loss: 0.0025, d_svhn_loss: 0.0151, d_fake_loss: 0.0254, g_loss: 1.2129\n",
            "Step [67560/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0037, d_svhn_loss: 0.0302, d_fake_loss: 0.0118, g_loss: 1.1460\n",
            "Step [67570/80000], d_real_loss: 0.0709, d_mnist_loss: 0.0016, d_svhn_loss: 0.0693, d_fake_loss: 0.0283, g_loss: 1.1705\n",
            "Step [67580/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0033, d_svhn_loss: 0.0470, d_fake_loss: 0.0146, g_loss: 1.0972\n",
            "Step [67590/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0033, d_svhn_loss: 0.0183, d_fake_loss: 0.0122, g_loss: 1.1114\n",
            "Step [67600/80000], d_real_loss: 0.0138, d_mnist_loss: 0.0030, d_svhn_loss: 0.0108, d_fake_loss: 0.0162, g_loss: 1.2100\n",
            "Step [67610/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0015, d_svhn_loss: 0.0204, d_fake_loss: 0.0222, g_loss: 1.4241\n",
            "Step [67620/80000], d_real_loss: 0.0162, d_mnist_loss: 0.0021, d_svhn_loss: 0.0141, d_fake_loss: 0.0101, g_loss: 1.1797\n",
            "Step [67630/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0022, d_svhn_loss: 0.0205, d_fake_loss: 0.0106, g_loss: 1.1159\n",
            "Step [67640/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0068, d_svhn_loss: 0.0125, d_fake_loss: 0.0567, g_loss: 1.1333\n",
            "Step [67650/80000], d_real_loss: 0.0152, d_mnist_loss: 0.0020, d_svhn_loss: 0.0132, d_fake_loss: 0.0231, g_loss: 1.0676\n",
            "Step [67660/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0044, d_svhn_loss: 0.0189, d_fake_loss: 0.0360, g_loss: 1.1314\n",
            "Step [67670/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0025, d_svhn_loss: 0.0280, d_fake_loss: 0.0534, g_loss: 1.1920\n",
            "Step [67680/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0049, d_svhn_loss: 0.0248, d_fake_loss: 0.0150, g_loss: 1.1499\n",
            "Step [67690/80000], d_real_loss: 0.0188, d_mnist_loss: 0.0015, d_svhn_loss: 0.0173, d_fake_loss: 0.0213, g_loss: 1.1473\n",
            "Step [67700/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0053, d_svhn_loss: 0.0119, d_fake_loss: 0.0073, g_loss: 1.1205\n",
            "Step [67710/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0032, d_svhn_loss: 0.0166, d_fake_loss: 0.0719, g_loss: 1.1596\n",
            "Step [67720/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0049, d_svhn_loss: 0.0146, d_fake_loss: 0.0117, g_loss: 1.1634\n",
            "Step [67730/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0049, d_svhn_loss: 0.0326, d_fake_loss: 0.0200, g_loss: 1.1401\n",
            "Step [67740/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0052, d_svhn_loss: 0.0160, d_fake_loss: 0.0454, g_loss: 1.1678\n",
            "Step [67750/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0085, d_svhn_loss: 0.0137, d_fake_loss: 0.0863, g_loss: 1.1017\n",
            "Step [67760/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0017, d_svhn_loss: 0.0235, d_fake_loss: 0.0895, g_loss: 1.1660\n",
            "Step [67770/80000], d_real_loss: 0.0143, d_mnist_loss: 0.0025, d_svhn_loss: 0.0118, d_fake_loss: 0.0229, g_loss: 1.1285\n",
            "Step [67780/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0045, d_svhn_loss: 0.0202, d_fake_loss: 0.0205, g_loss: 1.1721\n",
            "Step [67790/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0097, d_svhn_loss: 0.0641, d_fake_loss: 0.0420, g_loss: 1.1106\n",
            "Step [67800/80000], d_real_loss: 0.0135, d_mnist_loss: 0.0020, d_svhn_loss: 0.0115, d_fake_loss: 0.0629, g_loss: 1.1259\n",
            "Step [67810/80000], d_real_loss: 0.0119, d_mnist_loss: 0.0015, d_svhn_loss: 0.0105, d_fake_loss: 0.0710, g_loss: 1.1567\n",
            "Step [67820/80000], d_real_loss: 0.0159, d_mnist_loss: 0.0008, d_svhn_loss: 0.0151, d_fake_loss: 0.0168, g_loss: 1.1259\n",
            "Step [67830/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0011, d_svhn_loss: 0.0187, d_fake_loss: 0.0276, g_loss: 1.1491\n",
            "Step [67840/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0035, d_svhn_loss: 0.0247, d_fake_loss: 0.0286, g_loss: 1.1073\n",
            "Step [67850/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0019, d_svhn_loss: 0.0182, d_fake_loss: 0.0107, g_loss: 1.1191\n",
            "Step [67860/80000], d_real_loss: 0.0144, d_mnist_loss: 0.0014, d_svhn_loss: 0.0131, d_fake_loss: 0.0239, g_loss: 1.1827\n",
            "Step [67870/80000], d_real_loss: 0.0188, d_mnist_loss: 0.0011, d_svhn_loss: 0.0177, d_fake_loss: 0.0533, g_loss: 1.1081\n",
            "Step [67880/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0022, d_svhn_loss: 0.0573, d_fake_loss: 0.0197, g_loss: 1.0885\n",
            "Step [67890/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0015, d_svhn_loss: 0.0195, d_fake_loss: 0.0087, g_loss: 1.1061\n",
            "Step [67900/80000], d_real_loss: 0.0726, d_mnist_loss: 0.0022, d_svhn_loss: 0.0704, d_fake_loss: 0.0285, g_loss: 1.1781\n",
            "Step [67910/80000], d_real_loss: 0.0171, d_mnist_loss: 0.0014, d_svhn_loss: 0.0158, d_fake_loss: 0.0411, g_loss: 1.1158\n",
            "Step [67920/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0056, d_svhn_loss: 0.0150, d_fake_loss: 0.0164, g_loss: 1.0908\n",
            "Step [67930/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0014, d_svhn_loss: 0.0546, d_fake_loss: 0.0858, g_loss: 1.1296\n",
            "Step [67940/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0014, d_svhn_loss: 0.0289, d_fake_loss: 0.0434, g_loss: 1.1113\n",
            "Step [67950/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0019, d_svhn_loss: 0.0317, d_fake_loss: 0.0099, g_loss: 1.1436\n",
            "Step [67960/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0029, d_svhn_loss: 0.0247, d_fake_loss: 0.0096, g_loss: 1.1602\n",
            "Step [67970/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0012, d_svhn_loss: 0.0246, d_fake_loss: 0.0255, g_loss: 1.1222\n",
            "Step [67980/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0014, d_svhn_loss: 0.0399, d_fake_loss: 0.0110, g_loss: 1.0743\n",
            "Step [67990/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0022, d_svhn_loss: 0.0221, d_fake_loss: 0.0171, g_loss: 1.1615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [68000/80000], d_real_loss: 0.1081, d_mnist_loss: 0.0024, d_svhn_loss: 0.1057, d_fake_loss: 0.0295, g_loss: 1.0822\n",
            "saved ./samples_mnist_svhn/sample-68000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-68000-s-m.png\n",
            "Step [68010/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0072, d_svhn_loss: 0.0263, d_fake_loss: 0.0135, g_loss: 1.0760\n",
            "Step [68020/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0010, d_svhn_loss: 0.0452, d_fake_loss: 0.0278, g_loss: 1.1091\n",
            "Step [68030/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0015, d_svhn_loss: 0.0831, d_fake_loss: 0.0260, g_loss: 1.1009\n",
            "Step [68040/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0026, d_svhn_loss: 0.0154, d_fake_loss: 0.0126, g_loss: 1.1815\n",
            "Step [68050/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0012, d_svhn_loss: 0.0160, d_fake_loss: 0.0236, g_loss: 1.1341\n",
            "Step [68060/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0019, d_svhn_loss: 0.0226, d_fake_loss: 0.0594, g_loss: 1.2757\n",
            "Step [68070/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0146, d_svhn_loss: 0.0656, d_fake_loss: 0.0915, g_loss: 1.1398\n",
            "Step [68080/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0128, d_svhn_loss: 0.0235, d_fake_loss: 0.0522, g_loss: 1.1866\n",
            "Step [68090/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0145, d_svhn_loss: 0.0588, d_fake_loss: 0.0295, g_loss: 1.1461\n",
            "Step [68100/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0067, d_svhn_loss: 0.0515, d_fake_loss: 0.0184, g_loss: 1.0922\n",
            "Step [68110/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0036, d_svhn_loss: 0.0168, d_fake_loss: 0.0249, g_loss: 1.1710\n",
            "Step [68120/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0024, d_svhn_loss: 0.0194, d_fake_loss: 0.0139, g_loss: 1.1464\n",
            "Step [68130/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0032, d_svhn_loss: 0.0238, d_fake_loss: 0.0386, g_loss: 1.2779\n",
            "Step [68140/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0047, d_svhn_loss: 0.0407, d_fake_loss: 0.0143, g_loss: 1.1293\n",
            "Step [68150/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0100, d_svhn_loss: 0.0175, d_fake_loss: 0.0220, g_loss: 1.1765\n",
            "Step [68160/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0018, d_svhn_loss: 0.0216, d_fake_loss: 0.0428, g_loss: 1.1671\n",
            "Step [68170/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0035, d_svhn_loss: 0.0254, d_fake_loss: 0.0582, g_loss: 1.1599\n",
            "Step [68180/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0012, d_svhn_loss: 0.0222, d_fake_loss: 0.0220, g_loss: 1.2671\n",
            "Step [68190/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0018, d_svhn_loss: 0.0330, d_fake_loss: 0.0121, g_loss: 1.1730\n",
            "Step [68200/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0015, d_svhn_loss: 0.0203, d_fake_loss: 0.0200, g_loss: 1.1820\n",
            "Step [68210/80000], d_real_loss: 0.0188, d_mnist_loss: 0.0023, d_svhn_loss: 0.0165, d_fake_loss: 0.0155, g_loss: 1.1364\n",
            "Step [68220/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0046, d_svhn_loss: 0.0534, d_fake_loss: 0.0248, g_loss: 1.1268\n",
            "Step [68230/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0020, d_svhn_loss: 0.0161, d_fake_loss: 0.0237, g_loss: 1.1252\n",
            "Step [68240/80000], d_real_loss: 0.0159, d_mnist_loss: 0.0016, d_svhn_loss: 0.0142, d_fake_loss: 0.0290, g_loss: 1.1426\n",
            "Step [68250/80000], d_real_loss: 0.1141, d_mnist_loss: 0.0025, d_svhn_loss: 0.1116, d_fake_loss: 0.0428, g_loss: 1.1999\n",
            "Step [68260/80000], d_real_loss: 0.0153, d_mnist_loss: 0.0035, d_svhn_loss: 0.0117, d_fake_loss: 0.0112, g_loss: 1.1212\n",
            "Step [68270/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0035, d_svhn_loss: 0.0174, d_fake_loss: 0.0558, g_loss: 1.2030\n",
            "Step [68280/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0055, d_svhn_loss: 0.0386, d_fake_loss: 0.0102, g_loss: 1.0499\n",
            "Step [68290/80000], d_real_loss: 0.0153, d_mnist_loss: 0.0026, d_svhn_loss: 0.0127, d_fake_loss: 0.0328, g_loss: 1.1260\n",
            "Step [68300/80000], d_real_loss: 0.0140, d_mnist_loss: 0.0039, d_svhn_loss: 0.0101, d_fake_loss: 0.0376, g_loss: 1.1901\n",
            "Step [68310/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0032, d_svhn_loss: 0.0226, d_fake_loss: 0.0372, g_loss: 1.1727\n",
            "Step [68320/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0047, d_svhn_loss: 0.0364, d_fake_loss: 0.0528, g_loss: 1.2930\n",
            "Step [68330/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0094, d_svhn_loss: 0.0145, d_fake_loss: 0.0220, g_loss: 1.2088\n",
            "Step [68340/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0025, d_svhn_loss: 0.0187, d_fake_loss: 0.0132, g_loss: 1.2824\n",
            "Step [68350/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0051, d_svhn_loss: 0.0235, d_fake_loss: 0.0251, g_loss: 1.0538\n",
            "Step [68360/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0028, d_svhn_loss: 0.0468, d_fake_loss: 0.0325, g_loss: 1.0242\n",
            "Step [68370/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0088, d_svhn_loss: 0.0149, d_fake_loss: 0.0186, g_loss: 1.2965\n",
            "Step [68380/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0033, d_svhn_loss: 0.0320, d_fake_loss: 0.0720, g_loss: 1.0793\n",
            "Step [68390/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0072, d_svhn_loss: 0.0558, d_fake_loss: 0.0386, g_loss: 1.1376\n",
            "Step [68400/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0052, d_svhn_loss: 0.0190, d_fake_loss: 0.0334, g_loss: 1.1330\n",
            "Step [68410/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0046, d_svhn_loss: 0.0213, d_fake_loss: 0.0526, g_loss: 1.0915\n",
            "Step [68420/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0081, d_svhn_loss: 0.0501, d_fake_loss: 0.0412, g_loss: 1.2219\n",
            "Step [68430/80000], d_real_loss: 0.0732, d_mnist_loss: 0.0056, d_svhn_loss: 0.0676, d_fake_loss: 0.0334, g_loss: 1.1876\n",
            "Step [68440/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0088, d_svhn_loss: 0.0267, d_fake_loss: 0.0246, g_loss: 1.1855\n",
            "Step [68450/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0109, d_svhn_loss: 0.0581, d_fake_loss: 0.0870, g_loss: 1.1549\n",
            "Step [68460/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0030, d_svhn_loss: 0.0157, d_fake_loss: 0.0091, g_loss: 1.1879\n",
            "Step [68470/80000], d_real_loss: 0.0108, d_mnist_loss: 0.0021, d_svhn_loss: 0.0088, d_fake_loss: 0.0290, g_loss: 1.1234\n",
            "Step [68480/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0022, d_svhn_loss: 0.0205, d_fake_loss: 0.0125, g_loss: 1.0936\n",
            "Step [68490/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0034, d_svhn_loss: 0.0458, d_fake_loss: 0.1131, g_loss: 1.1228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [68500/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0050, d_svhn_loss: 0.0253, d_fake_loss: 0.0209, g_loss: 1.1387\n",
            "saved ./samples_mnist_svhn/sample-68500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-68500-s-m.png\n",
            "Step [68510/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0037, d_svhn_loss: 0.0356, d_fake_loss: 0.0220, g_loss: 1.1944\n",
            "Step [68520/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0019, d_svhn_loss: 0.0293, d_fake_loss: 0.0081, g_loss: 1.1634\n",
            "Step [68530/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0075, d_svhn_loss: 0.0715, d_fake_loss: 0.0122, g_loss: 1.0615\n",
            "Step [68540/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0018, d_svhn_loss: 0.0203, d_fake_loss: 0.0089, g_loss: 1.1855\n",
            "Step [68550/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0018, d_svhn_loss: 0.0655, d_fake_loss: 0.0087, g_loss: 1.1493\n",
            "Step [68560/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0035, d_svhn_loss: 0.0343, d_fake_loss: 0.0258, g_loss: 1.1539\n",
            "Step [68570/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0033, d_svhn_loss: 0.0309, d_fake_loss: 0.0236, g_loss: 1.1187\n",
            "Step [68580/80000], d_real_loss: 0.0166, d_mnist_loss: 0.0032, d_svhn_loss: 0.0133, d_fake_loss: 0.0246, g_loss: 1.1454\n",
            "Step [68590/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0033, d_svhn_loss: 0.0206, d_fake_loss: 0.0104, g_loss: 1.0970\n",
            "Step [68600/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0056, d_svhn_loss: 0.0407, d_fake_loss: 0.0170, g_loss: 1.1293\n",
            "Step [68610/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0047, d_svhn_loss: 0.0185, d_fake_loss: 0.0115, g_loss: 1.1292\n",
            "Step [68620/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0025, d_svhn_loss: 0.0197, d_fake_loss: 0.0396, g_loss: 1.1249\n",
            "Step [68630/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0067, d_svhn_loss: 0.0114, d_fake_loss: 0.0633, g_loss: 1.1350\n",
            "Step [68640/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0041, d_svhn_loss: 0.0186, d_fake_loss: 0.0147, g_loss: 1.1728\n",
            "Step [68650/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0071, d_svhn_loss: 0.0187, d_fake_loss: 0.0349, g_loss: 1.1491\n",
            "Step [68660/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0018, d_svhn_loss: 0.0181, d_fake_loss: 0.0354, g_loss: 1.1278\n",
            "Step [68670/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0029, d_svhn_loss: 0.0338, d_fake_loss: 0.0164, g_loss: 1.4031\n",
            "Step [68680/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0073, d_svhn_loss: 0.0149, d_fake_loss: 0.0130, g_loss: 1.1115\n",
            "Step [68690/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0060, d_svhn_loss: 0.0400, d_fake_loss: 0.0302, g_loss: 1.1373\n",
            "Step [68700/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0044, d_svhn_loss: 0.0720, d_fake_loss: 0.0246, g_loss: 1.1317\n",
            "Step [68710/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0025, d_svhn_loss: 0.0169, d_fake_loss: 0.0140, g_loss: 1.1779\n",
            "Step [68720/80000], d_real_loss: 0.0155, d_mnist_loss: 0.0015, d_svhn_loss: 0.0140, d_fake_loss: 0.0190, g_loss: 1.1537\n",
            "Step [68730/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0059, d_svhn_loss: 0.0491, d_fake_loss: 0.0158, g_loss: 1.1441\n",
            "Step [68740/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0028, d_svhn_loss: 0.0557, d_fake_loss: 0.0502, g_loss: 1.2058\n",
            "Step [68750/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0104, d_svhn_loss: 0.0334, d_fake_loss: 0.1286, g_loss: 1.1799\n",
            "Step [68760/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0030, d_svhn_loss: 0.0177, d_fake_loss: 0.0172, g_loss: 1.1632\n",
            "Step [68770/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0016, d_svhn_loss: 0.0329, d_fake_loss: 0.0197, g_loss: 1.1426\n",
            "Step [68780/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0016, d_svhn_loss: 0.0181, d_fake_loss: 0.0315, g_loss: 1.1202\n",
            "Step [68790/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0013, d_svhn_loss: 0.0183, d_fake_loss: 0.0083, g_loss: 1.1561\n",
            "Step [68800/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0019, d_svhn_loss: 0.0389, d_fake_loss: 0.0210, g_loss: 1.1366\n",
            "Step [68810/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0049, d_svhn_loss: 0.0128, d_fake_loss: 0.0165, g_loss: 1.1489\n",
            "Step [68820/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0043, d_svhn_loss: 0.0273, d_fake_loss: 0.0186, g_loss: 1.1481\n",
            "Step [68830/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0011, d_svhn_loss: 0.0250, d_fake_loss: 0.0151, g_loss: 1.1562\n",
            "Step [68840/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0012, d_svhn_loss: 0.0363, d_fake_loss: 0.0277, g_loss: 1.1253\n",
            "Step [68850/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0029, d_svhn_loss: 0.0548, d_fake_loss: 0.0192, g_loss: 1.1171\n",
            "Step [68860/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0066, d_svhn_loss: 0.0754, d_fake_loss: 0.0496, g_loss: 1.2028\n",
            "Step [68870/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0039, d_svhn_loss: 0.0267, d_fake_loss: 0.0272, g_loss: 1.1726\n",
            "Step [68880/80000], d_real_loss: 0.0170, d_mnist_loss: 0.0016, d_svhn_loss: 0.0154, d_fake_loss: 0.0136, g_loss: 1.1351\n",
            "Step [68890/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0028, d_svhn_loss: 0.0159, d_fake_loss: 0.0530, g_loss: 1.0884\n",
            "Step [68900/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0046, d_svhn_loss: 0.0216, d_fake_loss: 0.0259, g_loss: 1.1650\n",
            "Step [68910/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0015, d_svhn_loss: 0.0262, d_fake_loss: 0.0354, g_loss: 1.1597\n",
            "Step [68920/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0085, d_svhn_loss: 0.0156, d_fake_loss: 0.0223, g_loss: 1.0856\n",
            "Step [68930/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0049, d_svhn_loss: 0.0165, d_fake_loss: 0.1114, g_loss: 1.2335\n",
            "Step [68940/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0048, d_svhn_loss: 0.0293, d_fake_loss: 0.0217, g_loss: 1.1527\n",
            "Step [68950/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0050, d_svhn_loss: 0.0187, d_fake_loss: 0.0103, g_loss: 1.1049\n",
            "Step [68960/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0018, d_svhn_loss: 0.0167, d_fake_loss: 0.0285, g_loss: 1.0974\n",
            "Step [68970/80000], d_real_loss: 0.0152, d_mnist_loss: 0.0034, d_svhn_loss: 0.0118, d_fake_loss: 0.0157, g_loss: 1.2076\n",
            "Step [68980/80000], d_real_loss: 0.0193, d_mnist_loss: 0.0053, d_svhn_loss: 0.0140, d_fake_loss: 0.0231, g_loss: 1.1293\n",
            "Step [68990/80000], d_real_loss: 0.0158, d_mnist_loss: 0.0026, d_svhn_loss: 0.0132, d_fake_loss: 0.0128, g_loss: 1.1131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [69000/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0034, d_svhn_loss: 0.0185, d_fake_loss: 0.0135, g_loss: 1.1278\n",
            "saved ./samples_mnist_svhn/sample-69000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-69000-s-m.png\n",
            "Step [69010/80000], d_real_loss: 0.0160, d_mnist_loss: 0.0012, d_svhn_loss: 0.0148, d_fake_loss: 0.0615, g_loss: 1.1851\n",
            "Step [69020/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0021, d_svhn_loss: 0.0697, d_fake_loss: 0.0241, g_loss: 1.1662\n",
            "Step [69030/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0040, d_svhn_loss: 0.0372, d_fake_loss: 0.2658, g_loss: 1.1182\n",
            "Step [69040/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0051, d_svhn_loss: 0.0210, d_fake_loss: 0.0156, g_loss: 1.1008\n",
            "Step [69050/80000], d_real_loss: 0.0146, d_mnist_loss: 0.0027, d_svhn_loss: 0.0118, d_fake_loss: 0.0108, g_loss: 1.1411\n",
            "Step [69060/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0018, d_svhn_loss: 0.0234, d_fake_loss: 0.0573, g_loss: 1.1078\n",
            "Step [69070/80000], d_real_loss: 0.0219, d_mnist_loss: 0.0013, d_svhn_loss: 0.0206, d_fake_loss: 0.0189, g_loss: 1.0911\n",
            "Step [69080/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0124, d_svhn_loss: 0.0293, d_fake_loss: 0.0193, g_loss: 1.1776\n",
            "Step [69090/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0013, d_svhn_loss: 0.0177, d_fake_loss: 0.0168, g_loss: 1.0678\n",
            "Step [69100/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0096, d_svhn_loss: 0.0535, d_fake_loss: 0.1073, g_loss: 1.0621\n",
            "Step [69110/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0048, d_svhn_loss: 0.0359, d_fake_loss: 0.0162, g_loss: 1.2206\n",
            "Step [69120/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0029, d_svhn_loss: 0.0155, d_fake_loss: 0.0247, g_loss: 1.1677\n",
            "Step [69130/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0068, d_svhn_loss: 0.0356, d_fake_loss: 0.0132, g_loss: 1.1010\n",
            "Step [69140/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0019, d_svhn_loss: 0.0225, d_fake_loss: 0.0211, g_loss: 1.0876\n",
            "Step [69150/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0023, d_svhn_loss: 0.0158, d_fake_loss: 0.0151, g_loss: 1.1092\n",
            "Step [69160/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0019, d_svhn_loss: 0.0208, d_fake_loss: 0.0499, g_loss: 1.1216\n",
            "Step [69170/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0017, d_svhn_loss: 0.0183, d_fake_loss: 0.0097, g_loss: 1.1004\n",
            "Step [69180/80000], d_real_loss: 0.0168, d_mnist_loss: 0.0015, d_svhn_loss: 0.0153, d_fake_loss: 0.0128, g_loss: 1.0949\n",
            "Step [69190/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0025, d_svhn_loss: 0.0378, d_fake_loss: 0.0626, g_loss: 1.0972\n",
            "Step [69200/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0107, d_svhn_loss: 0.0190, d_fake_loss: 0.0145, g_loss: 1.0753\n",
            "Step [69210/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0015, d_svhn_loss: 0.0546, d_fake_loss: 0.0383, g_loss: 1.1080\n",
            "Step [69220/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0013, d_svhn_loss: 0.0665, d_fake_loss: 0.0089, g_loss: 1.1088\n",
            "Step [69230/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0016, d_svhn_loss: 0.0188, d_fake_loss: 0.0221, g_loss: 1.0814\n",
            "Step [69240/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0018, d_svhn_loss: 0.0185, d_fake_loss: 0.0502, g_loss: 1.1319\n",
            "Step [69250/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0017, d_svhn_loss: 0.0203, d_fake_loss: 0.0195, g_loss: 1.1264\n",
            "Step [69260/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0030, d_svhn_loss: 0.0336, d_fake_loss: 0.0126, g_loss: 1.0802\n",
            "Step [69270/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0103, d_svhn_loss: 0.0266, d_fake_loss: 0.0370, g_loss: 1.1042\n",
            "Step [69280/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0015, d_svhn_loss: 0.0269, d_fake_loss: 0.0184, g_loss: 1.0789\n",
            "Step [69290/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0051, d_svhn_loss: 0.0217, d_fake_loss: 0.0730, g_loss: 1.0932\n",
            "Step [69300/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0032, d_svhn_loss: 0.0249, d_fake_loss: 0.0145, g_loss: 1.1183\n",
            "Step [69310/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0049, d_svhn_loss: 0.0206, d_fake_loss: 0.0443, g_loss: 1.1274\n",
            "Step [69320/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0053, d_svhn_loss: 0.0274, d_fake_loss: 0.0247, g_loss: 1.1789\n",
            "Step [69330/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0020, d_svhn_loss: 0.0385, d_fake_loss: 0.0407, g_loss: 1.1047\n",
            "Step [69340/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0014, d_svhn_loss: 0.0458, d_fake_loss: 0.0122, g_loss: 1.1373\n",
            "Step [69350/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0013, d_svhn_loss: 0.0202, d_fake_loss: 0.0456, g_loss: 1.1245\n",
            "Step [69360/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0029, d_svhn_loss: 0.0226, d_fake_loss: 0.0093, g_loss: 1.1353\n",
            "Step [69370/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0020, d_svhn_loss: 0.0215, d_fake_loss: 0.0649, g_loss: 1.1343\n",
            "Step [69380/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0016, d_svhn_loss: 0.0296, d_fake_loss: 0.0432, g_loss: 1.1637\n",
            "Step [69390/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0046, d_svhn_loss: 0.0189, d_fake_loss: 0.0431, g_loss: 1.0498\n",
            "Step [69400/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0032, d_svhn_loss: 0.0341, d_fake_loss: 0.0446, g_loss: 1.0038\n",
            "Step [69410/80000], d_real_loss: 0.0176, d_mnist_loss: 0.0043, d_svhn_loss: 0.0134, d_fake_loss: 0.0199, g_loss: 1.1597\n",
            "Step [69420/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0013, d_svhn_loss: 0.0168, d_fake_loss: 0.0373, g_loss: 1.1839\n",
            "Step [69430/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0081, d_svhn_loss: 0.0165, d_fake_loss: 0.0110, g_loss: 1.1272\n",
            "Step [69440/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0025, d_svhn_loss: 0.0214, d_fake_loss: 0.0093, g_loss: 1.1308\n",
            "Step [69450/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0071, d_svhn_loss: 0.0141, d_fake_loss: 0.0215, g_loss: 1.1406\n",
            "Step [69460/80000], d_real_loss: 0.0146, d_mnist_loss: 0.0010, d_svhn_loss: 0.0136, d_fake_loss: 0.0294, g_loss: 1.2070\n",
            "Step [69470/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0014, d_svhn_loss: 0.0185, d_fake_loss: 0.0128, g_loss: 1.1208\n",
            "Step [69480/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0068, d_svhn_loss: 0.0440, d_fake_loss: 0.0221, g_loss: 1.1077\n",
            "Step [69490/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0050, d_svhn_loss: 0.0278, d_fake_loss: 0.0184, g_loss: 1.1776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [69500/80000], d_real_loss: 0.0109, d_mnist_loss: 0.0012, d_svhn_loss: 0.0097, d_fake_loss: 0.0254, g_loss: 1.1421\n",
            "saved ./samples_mnist_svhn/sample-69500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-69500-s-m.png\n",
            "Step [69510/80000], d_real_loss: 0.0951, d_mnist_loss: 0.0015, d_svhn_loss: 0.0935, d_fake_loss: 0.0539, g_loss: 1.0957\n",
            "Step [69520/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0014, d_svhn_loss: 0.0235, d_fake_loss: 0.0157, g_loss: 1.0902\n",
            "Step [69530/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0028, d_svhn_loss: 0.0294, d_fake_loss: 0.0340, g_loss: 1.0778\n",
            "Step [69540/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0052, d_svhn_loss: 0.0153, d_fake_loss: 0.0233, g_loss: 1.1822\n",
            "Step [69550/80000], d_real_loss: 0.0170, d_mnist_loss: 0.0032, d_svhn_loss: 0.0139, d_fake_loss: 0.0393, g_loss: 1.1665\n",
            "Step [69560/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0014, d_svhn_loss: 0.0288, d_fake_loss: 0.0251, g_loss: 1.1431\n",
            "Step [69570/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0025, d_svhn_loss: 0.0169, d_fake_loss: 0.0133, g_loss: 1.1335\n",
            "Step [69580/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0019, d_svhn_loss: 0.0256, d_fake_loss: 0.0118, g_loss: 1.1397\n",
            "Step [69590/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0119, d_svhn_loss: 0.0288, d_fake_loss: 0.0161, g_loss: 1.1294\n",
            "Step [69600/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0024, d_svhn_loss: 0.0276, d_fake_loss: 0.0267, g_loss: 1.1928\n",
            "Step [69610/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0068, d_svhn_loss: 0.0430, d_fake_loss: 0.0116, g_loss: 1.0689\n",
            "Step [69620/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0052, d_svhn_loss: 0.0796, d_fake_loss: 0.0337, g_loss: 1.1043\n",
            "Step [69630/80000], d_real_loss: 0.0995, d_mnist_loss: 0.0031, d_svhn_loss: 0.0963, d_fake_loss: 0.0717, g_loss: 1.1362\n",
            "Step [69640/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0010, d_svhn_loss: 0.0168, d_fake_loss: 0.0478, g_loss: 1.1915\n",
            "Step [69650/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0026, d_svhn_loss: 0.0442, d_fake_loss: 0.0279, g_loss: 1.1527\n",
            "Step [69660/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0058, d_svhn_loss: 0.0156, d_fake_loss: 0.0449, g_loss: 1.0911\n",
            "Step [69670/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0025, d_svhn_loss: 0.0405, d_fake_loss: 0.0873, g_loss: 1.1953\n",
            "Step [69680/80000], d_real_loss: 0.0141, d_mnist_loss: 0.0015, d_svhn_loss: 0.0126, d_fake_loss: 0.0125, g_loss: 1.1686\n",
            "Step [69690/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0037, d_svhn_loss: 0.0800, d_fake_loss: 0.1303, g_loss: 1.1578\n",
            "Step [69700/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0039, d_svhn_loss: 0.0280, d_fake_loss: 0.0679, g_loss: 1.1250\n",
            "Step [69710/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0022, d_svhn_loss: 0.0179, d_fake_loss: 0.0183, g_loss: 1.2434\n",
            "Step [69720/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0096, d_svhn_loss: 0.0391, d_fake_loss: 0.0413, g_loss: 1.1901\n",
            "Step [69730/80000], d_real_loss: 0.0168, d_mnist_loss: 0.0029, d_svhn_loss: 0.0139, d_fake_loss: 0.0730, g_loss: 1.1202\n",
            "Step [69740/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0030, d_svhn_loss: 0.0155, d_fake_loss: 0.0302, g_loss: 1.1944\n",
            "Step [69750/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0043, d_svhn_loss: 0.0414, d_fake_loss: 0.0086, g_loss: 1.1477\n",
            "Step [69760/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0036, d_svhn_loss: 0.0146, d_fake_loss: 0.0207, g_loss: 1.1501\n",
            "Step [69770/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0101, d_svhn_loss: 0.0186, d_fake_loss: 0.0221, g_loss: 1.2540\n",
            "Step [69780/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0057, d_svhn_loss: 0.0192, d_fake_loss: 0.0235, g_loss: 1.1198\n",
            "Step [69790/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0042, d_svhn_loss: 0.0149, d_fake_loss: 0.0134, g_loss: 1.2499\n",
            "Step [69800/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0082, d_svhn_loss: 0.0218, d_fake_loss: 0.1034, g_loss: 1.1324\n",
            "Step [69810/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0084, d_svhn_loss: 0.0245, d_fake_loss: 0.0151, g_loss: 1.2202\n",
            "Step [69820/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0114, d_svhn_loss: 0.0225, d_fake_loss: 0.0212, g_loss: 1.1029\n",
            "Step [69830/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0034, d_svhn_loss: 0.0176, d_fake_loss: 0.0276, g_loss: 1.0939\n",
            "Step [69840/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0028, d_svhn_loss: 0.0304, d_fake_loss: 0.0097, g_loss: 1.1117\n",
            "Step [69850/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0097, d_svhn_loss: 0.0166, d_fake_loss: 0.0173, g_loss: 1.1213\n",
            "Step [69860/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0034, d_svhn_loss: 0.0199, d_fake_loss: 0.0461, g_loss: 1.2047\n",
            "Step [69870/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0041, d_svhn_loss: 0.0316, d_fake_loss: 0.0176, g_loss: 1.1883\n",
            "Step [69880/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0015, d_svhn_loss: 0.0216, d_fake_loss: 0.1690, g_loss: 1.1777\n",
            "Step [69890/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0047, d_svhn_loss: 0.0320, d_fake_loss: 0.0617, g_loss: 1.0094\n",
            "Step [69900/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0044, d_svhn_loss: 0.0294, d_fake_loss: 0.0124, g_loss: 1.1084\n",
            "Step [69910/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0029, d_svhn_loss: 0.0211, d_fake_loss: 0.0649, g_loss: 1.0890\n",
            "Step [69920/80000], d_real_loss: 0.0099, d_mnist_loss: 0.0024, d_svhn_loss: 0.0074, d_fake_loss: 0.0470, g_loss: 1.1657\n",
            "Step [69930/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0034, d_svhn_loss: 0.0228, d_fake_loss: 0.0116, g_loss: 1.1983\n",
            "Step [69940/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0045, d_svhn_loss: 0.0209, d_fake_loss: 0.0299, g_loss: 1.1796\n",
            "Step [69950/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0022, d_svhn_loss: 0.0180, d_fake_loss: 0.0262, g_loss: 1.1585\n",
            "Step [69960/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0023, d_svhn_loss: 0.0181, d_fake_loss: 0.0270, g_loss: 1.2153\n",
            "Step [69970/80000], d_real_loss: 0.0149, d_mnist_loss: 0.0035, d_svhn_loss: 0.0115, d_fake_loss: 0.0165, g_loss: 1.1675\n",
            "Step [69980/80000], d_real_loss: 0.0749, d_mnist_loss: 0.0075, d_svhn_loss: 0.0673, d_fake_loss: 0.0349, g_loss: 1.0974\n",
            "Step [69990/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0039, d_svhn_loss: 0.0185, d_fake_loss: 0.0334, g_loss: 1.1194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [70000/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0019, d_svhn_loss: 0.0533, d_fake_loss: 0.0104, g_loss: 1.1199\n",
            "saved ./samples_mnist_svhn/sample-70000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-70000-s-m.png\n",
            "Step [70010/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0029, d_svhn_loss: 0.0144, d_fake_loss: 0.0261, g_loss: 1.2095\n",
            "Step [70020/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0020, d_svhn_loss: 0.0187, d_fake_loss: 0.0121, g_loss: 1.0824\n",
            "Step [70030/80000], d_real_loss: 0.0312, d_mnist_loss: 0.0032, d_svhn_loss: 0.0280, d_fake_loss: 0.0465, g_loss: 1.1039\n",
            "Step [70040/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0019, d_svhn_loss: 0.0510, d_fake_loss: 0.0112, g_loss: 1.2015\n",
            "Step [70050/80000], d_real_loss: 0.0161, d_mnist_loss: 0.0024, d_svhn_loss: 0.0137, d_fake_loss: 0.0558, g_loss: 1.1397\n",
            "Step [70060/80000], d_real_loss: 0.0134, d_mnist_loss: 0.0031, d_svhn_loss: 0.0102, d_fake_loss: 0.0153, g_loss: 1.1632\n",
            "Step [70070/80000], d_real_loss: 0.0152, d_mnist_loss: 0.0024, d_svhn_loss: 0.0128, d_fake_loss: 0.0155, g_loss: 1.1442\n",
            "Step [70080/80000], d_real_loss: 0.0161, d_mnist_loss: 0.0025, d_svhn_loss: 0.0135, d_fake_loss: 0.0216, g_loss: 1.1965\n",
            "Step [70090/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0019, d_svhn_loss: 0.0190, d_fake_loss: 0.0355, g_loss: 1.1309\n",
            "Step [70100/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0112, d_svhn_loss: 0.0198, d_fake_loss: 0.0193, g_loss: 1.1459\n",
            "Step [70110/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0041, d_svhn_loss: 0.0385, d_fake_loss: 0.0372, g_loss: 1.1393\n",
            "Step [70120/80000], d_real_loss: 0.0136, d_mnist_loss: 0.0028, d_svhn_loss: 0.0108, d_fake_loss: 0.0169, g_loss: 1.1555\n",
            "Step [70130/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0023, d_svhn_loss: 0.0611, d_fake_loss: 0.0167, g_loss: 1.2233\n",
            "Step [70140/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0063, d_svhn_loss: 0.0423, d_fake_loss: 0.0122, g_loss: 1.1221\n",
            "Step [70150/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0022, d_svhn_loss: 0.0204, d_fake_loss: 0.0104, g_loss: 1.2021\n",
            "Step [70160/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0034, d_svhn_loss: 0.0235, d_fake_loss: 0.0393, g_loss: 1.1244\n",
            "Step [70170/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0107, d_svhn_loss: 0.0218, d_fake_loss: 0.0295, g_loss: 1.2689\n",
            "Step [70180/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0035, d_svhn_loss: 0.0328, d_fake_loss: 0.0134, g_loss: 1.2020\n",
            "Step [70190/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0079, d_svhn_loss: 0.0356, d_fake_loss: 0.0275, g_loss: 1.1511\n",
            "Step [70200/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0025, d_svhn_loss: 0.0205, d_fake_loss: 0.0235, g_loss: 1.1384\n",
            "Step [70210/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0170, d_svhn_loss: 0.0252, d_fake_loss: 0.0218, g_loss: 1.1053\n",
            "Step [70220/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0035, d_svhn_loss: 0.0370, d_fake_loss: 0.0321, g_loss: 1.1612\n",
            "Step [70230/80000], d_real_loss: 0.1186, d_mnist_loss: 0.0074, d_svhn_loss: 0.1111, d_fake_loss: 0.0126, g_loss: 1.2379\n",
            "Step [70240/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0100, d_svhn_loss: 0.0170, d_fake_loss: 0.0216, g_loss: 1.2257\n",
            "Step [70250/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0061, d_svhn_loss: 0.0191, d_fake_loss: 0.0327, g_loss: 1.1162\n",
            "Step [70260/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0012, d_svhn_loss: 0.0582, d_fake_loss: 0.0334, g_loss: 1.1332\n",
            "Step [70270/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0031, d_svhn_loss: 0.0370, d_fake_loss: 0.0118, g_loss: 1.1903\n",
            "Step [70280/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0038, d_svhn_loss: 0.0187, d_fake_loss: 0.0121, g_loss: 1.1137\n",
            "Step [70290/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0045, d_svhn_loss: 0.0260, d_fake_loss: 0.0139, g_loss: 1.1106\n",
            "Step [70300/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0017, d_svhn_loss: 0.0177, d_fake_loss: 0.0661, g_loss: 1.1497\n",
            "Step [70310/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0014, d_svhn_loss: 0.0292, d_fake_loss: 0.0087, g_loss: 1.1597\n",
            "Step [70320/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0012, d_svhn_loss: 0.0174, d_fake_loss: 0.0428, g_loss: 1.1146\n",
            "Step [70330/80000], d_real_loss: 0.0179, d_mnist_loss: 0.0034, d_svhn_loss: 0.0145, d_fake_loss: 0.0249, g_loss: 1.0885\n",
            "Step [70340/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0044, d_svhn_loss: 0.0142, d_fake_loss: 0.0141, g_loss: 1.1156\n",
            "Step [70350/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0020, d_svhn_loss: 0.0302, d_fake_loss: 0.0383, g_loss: 1.1443\n",
            "Step [70360/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0011, d_svhn_loss: 0.0227, d_fake_loss: 0.0103, g_loss: 1.1533\n",
            "Step [70370/80000], d_real_loss: 0.0133, d_mnist_loss: 0.0015, d_svhn_loss: 0.0119, d_fake_loss: 0.0748, g_loss: 1.1239\n",
            "Step [70380/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0098, d_svhn_loss: 0.0384, d_fake_loss: 0.0455, g_loss: 1.1118\n",
            "Step [70390/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0065, d_svhn_loss: 0.0256, d_fake_loss: 0.0172, g_loss: 1.1417\n",
            "Step [70400/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0029, d_svhn_loss: 0.0198, d_fake_loss: 0.0082, g_loss: 1.1872\n",
            "Step [70410/80000], d_real_loss: 0.0147, d_mnist_loss: 0.0044, d_svhn_loss: 0.0103, d_fake_loss: 0.0200, g_loss: 1.1339\n",
            "Step [70420/80000], d_real_loss: 0.0203, d_mnist_loss: 0.0013, d_svhn_loss: 0.0190, d_fake_loss: 0.0910, g_loss: 1.1518\n",
            "Step [70430/80000], d_real_loss: 0.0176, d_mnist_loss: 0.0024, d_svhn_loss: 0.0152, d_fake_loss: 0.0298, g_loss: 1.0826\n",
            "Step [70440/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0013, d_svhn_loss: 0.0194, d_fake_loss: 0.0185, g_loss: 1.1662\n",
            "Step [70450/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0023, d_svhn_loss: 0.0269, d_fake_loss: 0.0147, g_loss: 1.1006\n",
            "Step [70460/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0063, d_svhn_loss: 0.0555, d_fake_loss: 0.0139, g_loss: 1.1583\n",
            "Step [70470/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0015, d_svhn_loss: 0.0481, d_fake_loss: 0.0102, g_loss: 1.1426\n",
            "Step [70480/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0053, d_svhn_loss: 0.0199, d_fake_loss: 0.0484, g_loss: 1.3139\n",
            "Step [70490/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0053, d_svhn_loss: 0.0335, d_fake_loss: 0.0257, g_loss: 1.1301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [70500/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0025, d_svhn_loss: 0.0170, d_fake_loss: 0.0536, g_loss: 1.1136\n",
            "saved ./samples_mnist_svhn/sample-70500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-70500-s-m.png\n",
            "Step [70510/80000], d_real_loss: 0.0157, d_mnist_loss: 0.0026, d_svhn_loss: 0.0131, d_fake_loss: 0.0559, g_loss: 1.1697\n",
            "Step [70520/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0015, d_svhn_loss: 0.0421, d_fake_loss: 0.0247, g_loss: 1.1188\n",
            "Step [70530/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0142, d_svhn_loss: 0.0395, d_fake_loss: 0.1885, g_loss: 1.1688\n",
            "Step [70540/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0015, d_svhn_loss: 0.0264, d_fake_loss: 0.0159, g_loss: 1.1480\n",
            "Step [70550/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0014, d_svhn_loss: 0.0168, d_fake_loss: 0.0186, g_loss: 1.1610\n",
            "Step [70560/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0063, d_svhn_loss: 0.0117, d_fake_loss: 0.0156, g_loss: 1.1204\n",
            "Step [70570/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0015, d_svhn_loss: 0.0165, d_fake_loss: 0.1182, g_loss: 1.1271\n",
            "Step [70580/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0013, d_svhn_loss: 0.0356, d_fake_loss: 0.0110, g_loss: 1.1430\n",
            "Step [70590/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0014, d_svhn_loss: 0.0158, d_fake_loss: 0.0187, g_loss: 1.1357\n",
            "Step [70600/80000], d_real_loss: 0.0154, d_mnist_loss: 0.0017, d_svhn_loss: 0.0137, d_fake_loss: 0.0090, g_loss: 1.1139\n",
            "Step [70610/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0033, d_svhn_loss: 0.0158, d_fake_loss: 0.0594, g_loss: 1.1711\n",
            "Step [70620/80000], d_real_loss: 0.0189, d_mnist_loss: 0.0024, d_svhn_loss: 0.0165, d_fake_loss: 0.0224, g_loss: 1.0822\n",
            "Step [70630/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0104, d_svhn_loss: 0.0201, d_fake_loss: 0.0174, g_loss: 1.0990\n",
            "Step [70640/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0040, d_svhn_loss: 0.0427, d_fake_loss: 0.1068, g_loss: 1.1362\n",
            "Step [70650/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0035, d_svhn_loss: 0.0142, d_fake_loss: 0.0155, g_loss: 1.1129\n",
            "Step [70660/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0042, d_svhn_loss: 0.0516, d_fake_loss: 0.0157, g_loss: 1.0938\n",
            "Step [70670/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0019, d_svhn_loss: 0.0247, d_fake_loss: 0.0254, g_loss: 1.1287\n",
            "Step [70680/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0127, d_svhn_loss: 0.0284, d_fake_loss: 0.0335, g_loss: 1.1088\n",
            "Step [70690/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0039, d_svhn_loss: 0.0230, d_fake_loss: 0.0443, g_loss: 1.1523\n",
            "Step [70700/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0034, d_svhn_loss: 0.0165, d_fake_loss: 0.0083, g_loss: 1.1289\n",
            "Step [70710/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0043, d_svhn_loss: 0.0144, d_fake_loss: 0.0119, g_loss: 1.0944\n",
            "Step [70720/80000], d_real_loss: 0.0165, d_mnist_loss: 0.0024, d_svhn_loss: 0.0141, d_fake_loss: 0.0075, g_loss: 1.0758\n",
            "Step [70730/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0015, d_svhn_loss: 0.0502, d_fake_loss: 0.0124, g_loss: 1.1130\n",
            "Step [70740/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0029, d_svhn_loss: 0.0494, d_fake_loss: 0.0118, g_loss: 1.1210\n",
            "Step [70750/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0025, d_svhn_loss: 0.0303, d_fake_loss: 0.0127, g_loss: 1.0905\n",
            "Step [70760/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0020, d_svhn_loss: 0.0324, d_fake_loss: 0.0763, g_loss: 1.1077\n",
            "Step [70770/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0015, d_svhn_loss: 0.0223, d_fake_loss: 0.0655, g_loss: 1.0821\n",
            "Step [70780/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0072, d_svhn_loss: 0.0279, d_fake_loss: 0.0122, g_loss: 1.1474\n",
            "Step [70790/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0054, d_svhn_loss: 0.0275, d_fake_loss: 0.0144, g_loss: 1.1144\n",
            "Step [70800/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0013, d_svhn_loss: 0.0585, d_fake_loss: 0.0158, g_loss: 1.1225\n",
            "Step [70810/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0025, d_svhn_loss: 0.0168, d_fake_loss: 0.0090, g_loss: 1.1142\n",
            "Step [70820/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0030, d_svhn_loss: 0.0377, d_fake_loss: 0.0183, g_loss: 1.2297\n",
            "Step [70830/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0088, d_svhn_loss: 0.0221, d_fake_loss: 0.0114, g_loss: 1.2002\n",
            "Step [70840/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0025, d_svhn_loss: 0.0147, d_fake_loss: 0.0116, g_loss: 1.1109\n",
            "Step [70850/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0017, d_svhn_loss: 0.0168, d_fake_loss: 0.0122, g_loss: 1.1112\n",
            "Step [70860/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0041, d_svhn_loss: 0.0160, d_fake_loss: 0.0308, g_loss: 1.0748\n",
            "Step [70870/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0039, d_svhn_loss: 0.0461, d_fake_loss: 0.0177, g_loss: 1.1510\n",
            "Step [70880/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0016, d_svhn_loss: 0.0237, d_fake_loss: 0.0464, g_loss: 1.1296\n",
            "Step [70890/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0015, d_svhn_loss: 0.0377, d_fake_loss: 0.0833, g_loss: 1.1885\n",
            "Step [70900/80000], d_real_loss: 0.0224, d_mnist_loss: 0.0017, d_svhn_loss: 0.0207, d_fake_loss: 0.0698, g_loss: 1.1137\n",
            "Step [70910/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0028, d_svhn_loss: 0.0182, d_fake_loss: 0.0256, g_loss: 1.1196\n",
            "Step [70920/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0108, d_svhn_loss: 0.0098, d_fake_loss: 0.0131, g_loss: 1.1140\n",
            "Step [70930/80000], d_real_loss: 0.1200, d_mnist_loss: 0.0030, d_svhn_loss: 0.1169, d_fake_loss: 0.0299, g_loss: 1.0777\n",
            "Step [70940/80000], d_real_loss: 0.0163, d_mnist_loss: 0.0014, d_svhn_loss: 0.0149, d_fake_loss: 0.0211, g_loss: 1.1089\n",
            "Step [70950/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0028, d_svhn_loss: 0.0197, d_fake_loss: 0.0125, g_loss: 1.1501\n",
            "Step [70960/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0023, d_svhn_loss: 0.0213, d_fake_loss: 0.0290, g_loss: 1.1309\n",
            "Step [70970/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0079, d_svhn_loss: 0.0200, d_fake_loss: 0.0457, g_loss: 1.0982\n",
            "Step [70980/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0017, d_svhn_loss: 0.0206, d_fake_loss: 0.0198, g_loss: 1.1888\n",
            "Step [70990/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0026, d_svhn_loss: 0.0483, d_fake_loss: 0.0197, g_loss: 1.2003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [71000/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0014, d_svhn_loss: 0.0220, d_fake_loss: 0.0496, g_loss: 1.1676\n",
            "saved ./samples_mnist_svhn/sample-71000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-71000-s-m.png\n",
            "Step [71010/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0046, d_svhn_loss: 0.0185, d_fake_loss: 0.0146, g_loss: 1.0978\n",
            "Step [71020/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0016, d_svhn_loss: 0.0251, d_fake_loss: 0.0678, g_loss: 1.1267\n",
            "Step [71030/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0021, d_svhn_loss: 0.0208, d_fake_loss: 0.0164, g_loss: 1.1038\n",
            "Step [71040/80000], d_real_loss: 0.0961, d_mnist_loss: 0.0018, d_svhn_loss: 0.0943, d_fake_loss: 0.0340, g_loss: 1.1260\n",
            "Step [71050/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0041, d_svhn_loss: 0.0156, d_fake_loss: 0.0369, g_loss: 1.1106\n",
            "Step [71060/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0049, d_svhn_loss: 0.0172, d_fake_loss: 0.0132, g_loss: 1.0959\n",
            "Step [71070/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0028, d_svhn_loss: 0.0158, d_fake_loss: 0.0255, g_loss: 1.0875\n",
            "Step [71080/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0019, d_svhn_loss: 0.0239, d_fake_loss: 0.0306, g_loss: 1.0477\n",
            "Step [71090/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0043, d_svhn_loss: 0.0222, d_fake_loss: 0.0138, g_loss: 1.0888\n",
            "Step [71100/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0035, d_svhn_loss: 0.0180, d_fake_loss: 0.0184, g_loss: 1.1080\n",
            "Step [71110/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0023, d_svhn_loss: 0.0221, d_fake_loss: 0.0147, g_loss: 1.0909\n",
            "Step [71120/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0021, d_svhn_loss: 0.0255, d_fake_loss: 0.0569, g_loss: 1.2339\n",
            "Step [71130/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0099, d_svhn_loss: 0.0177, d_fake_loss: 0.0379, g_loss: 1.2182\n",
            "Step [71140/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0040, d_svhn_loss: 0.0154, d_fake_loss: 0.0336, g_loss: 1.1504\n",
            "Step [71150/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0040, d_svhn_loss: 0.0227, d_fake_loss: 0.0087, g_loss: 1.2622\n",
            "Step [71160/80000], d_real_loss: 0.0138, d_mnist_loss: 0.0019, d_svhn_loss: 0.0119, d_fake_loss: 0.0152, g_loss: 1.1247\n",
            "Step [71170/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0025, d_svhn_loss: 0.0205, d_fake_loss: 0.0116, g_loss: 1.1283\n",
            "Step [71180/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0118, d_svhn_loss: 0.0155, d_fake_loss: 0.0450, g_loss: 1.1490\n",
            "Step [71190/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0014, d_svhn_loss: 0.0205, d_fake_loss: 0.0214, g_loss: 1.1267\n",
            "Step [71200/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0032, d_svhn_loss: 0.0148, d_fake_loss: 0.0287, g_loss: 1.1566\n",
            "Step [71210/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0074, d_svhn_loss: 0.0241, d_fake_loss: 0.0199, g_loss: 1.2336\n",
            "Step [71220/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0042, d_svhn_loss: 0.0296, d_fake_loss: 0.0424, g_loss: 1.1440\n",
            "Step [71230/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0070, d_svhn_loss: 0.0212, d_fake_loss: 0.0187, g_loss: 1.1823\n",
            "Step [71240/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0031, d_svhn_loss: 0.0319, d_fake_loss: 0.0379, g_loss: 1.1069\n",
            "Step [71250/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0070, d_svhn_loss: 0.0201, d_fake_loss: 0.0140, g_loss: 1.1372\n",
            "Step [71260/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0042, d_svhn_loss: 0.0409, d_fake_loss: 0.0208, g_loss: 1.1993\n",
            "Step [71270/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0034, d_svhn_loss: 0.0216, d_fake_loss: 0.0803, g_loss: 1.1914\n",
            "Step [71280/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0026, d_svhn_loss: 0.0241, d_fake_loss: 0.0658, g_loss: 1.1198\n",
            "Step [71290/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0021, d_svhn_loss: 0.0163, d_fake_loss: 0.0392, g_loss: 1.0973\n",
            "Step [71300/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0026, d_svhn_loss: 0.0349, d_fake_loss: 0.0316, g_loss: 1.1111\n",
            "Step [71310/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0022, d_svhn_loss: 0.0199, d_fake_loss: 0.0425, g_loss: 1.1531\n",
            "Step [71320/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0059, d_svhn_loss: 0.0198, d_fake_loss: 0.0274, g_loss: 1.1132\n",
            "Step [71330/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0060, d_svhn_loss: 0.0214, d_fake_loss: 0.0102, g_loss: 1.1367\n",
            "Step [71340/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0029, d_svhn_loss: 0.0510, d_fake_loss: 0.0138, g_loss: 1.1367\n",
            "Step [71350/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0046, d_svhn_loss: 0.0134, d_fake_loss: 0.0235, g_loss: 1.2389\n",
            "Step [71360/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0056, d_svhn_loss: 0.0590, d_fake_loss: 0.0101, g_loss: 1.0881\n",
            "Step [71370/80000], d_real_loss: 0.0219, d_mnist_loss: 0.0027, d_svhn_loss: 0.0192, d_fake_loss: 0.0186, g_loss: 1.2270\n",
            "Step [71380/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0015, d_svhn_loss: 0.0407, d_fake_loss: 0.0250, g_loss: 1.1319\n",
            "Step [71390/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0073, d_svhn_loss: 0.0220, d_fake_loss: 0.0262, g_loss: 1.4925\n",
            "Step [71400/80000], d_real_loss: 0.0094, d_mnist_loss: 0.0010, d_svhn_loss: 0.0084, d_fake_loss: 0.0261, g_loss: 1.1538\n",
            "Step [71410/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0043, d_svhn_loss: 0.0359, d_fake_loss: 0.0401, g_loss: 1.1491\n",
            "Step [71420/80000], d_real_loss: 0.0175, d_mnist_loss: 0.0044, d_svhn_loss: 0.0131, d_fake_loss: 0.0120, g_loss: 1.1368\n",
            "Step [71430/80000], d_real_loss: 0.0143, d_mnist_loss: 0.0037, d_svhn_loss: 0.0106, d_fake_loss: 0.0155, g_loss: 1.1722\n",
            "Step [71440/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0023, d_svhn_loss: 0.0157, d_fake_loss: 0.0098, g_loss: 1.1863\n",
            "Step [71450/80000], d_real_loss: 0.0169, d_mnist_loss: 0.0032, d_svhn_loss: 0.0138, d_fake_loss: 0.0352, g_loss: 1.0649\n",
            "Step [71460/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0143, d_svhn_loss: 0.0122, d_fake_loss: 0.1090, g_loss: 1.3564\n",
            "Step [71470/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0079, d_svhn_loss: 0.0705, d_fake_loss: 0.0216, g_loss: 1.0784\n",
            "Step [71480/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0048, d_svhn_loss: 0.0135, d_fake_loss: 0.0099, g_loss: 1.1516\n",
            "Step [71490/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0075, d_svhn_loss: 0.0157, d_fake_loss: 0.0125, g_loss: 1.1077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [71500/80000], d_real_loss: 0.0162, d_mnist_loss: 0.0031, d_svhn_loss: 0.0131, d_fake_loss: 0.0270, g_loss: 1.2068\n",
            "saved ./samples_mnist_svhn/sample-71500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-71500-s-m.png\n",
            "Step [71510/80000], d_real_loss: 0.0142, d_mnist_loss: 0.0014, d_svhn_loss: 0.0128, d_fake_loss: 0.0094, g_loss: 1.1199\n",
            "Step [71520/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0158, d_svhn_loss: 0.0243, d_fake_loss: 0.0105, g_loss: 1.1836\n",
            "Step [71530/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0033, d_svhn_loss: 0.0315, d_fake_loss: 0.0282, g_loss: 1.1535\n",
            "Step [71540/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0041, d_svhn_loss: 0.0349, d_fake_loss: 0.0543, g_loss: 1.1453\n",
            "Step [71550/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0176, d_svhn_loss: 0.0143, d_fake_loss: 0.0860, g_loss: 1.0960\n",
            "Step [71560/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0014, d_svhn_loss: 0.0183, d_fake_loss: 0.0152, g_loss: 1.1102\n",
            "Step [71570/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0053, d_svhn_loss: 0.0279, d_fake_loss: 0.0419, g_loss: 1.4075\n",
            "Step [71580/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0080, d_svhn_loss: 0.0134, d_fake_loss: 0.0132, g_loss: 1.2844\n",
            "Step [71590/80000], d_real_loss: 0.0193, d_mnist_loss: 0.0029, d_svhn_loss: 0.0164, d_fake_loss: 0.0355, g_loss: 1.1649\n",
            "Step [71600/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0062, d_svhn_loss: 0.0425, d_fake_loss: 0.0175, g_loss: 1.0816\n",
            "Step [71610/80000], d_real_loss: 0.0162, d_mnist_loss: 0.0035, d_svhn_loss: 0.0128, d_fake_loss: 0.0384, g_loss: 1.0728\n",
            "Step [71620/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0080, d_svhn_loss: 0.0266, d_fake_loss: 0.0214, g_loss: 1.1500\n",
            "Step [71630/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0045, d_svhn_loss: 0.0241, d_fake_loss: 0.0165, g_loss: 1.1421\n",
            "Step [71640/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0020, d_svhn_loss: 0.0166, d_fake_loss: 0.0425, g_loss: 1.1242\n",
            "Step [71650/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0045, d_svhn_loss: 0.0127, d_fake_loss: 0.0210, g_loss: 1.1714\n",
            "Step [71660/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0017, d_svhn_loss: 0.0199, d_fake_loss: 0.1713, g_loss: 1.0961\n",
            "Step [71670/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0058, d_svhn_loss: 0.0410, d_fake_loss: 0.0152, g_loss: 1.1280\n",
            "Step [71680/80000], d_real_loss: 0.0163, d_mnist_loss: 0.0017, d_svhn_loss: 0.0146, d_fake_loss: 0.0136, g_loss: 1.1070\n",
            "Step [71690/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0012, d_svhn_loss: 0.0161, d_fake_loss: 0.0110, g_loss: 1.0959\n",
            "Step [71700/80000], d_real_loss: 0.0163, d_mnist_loss: 0.0020, d_svhn_loss: 0.0143, d_fake_loss: 0.0408, g_loss: 1.0783\n",
            "Step [71710/80000], d_real_loss: 0.0170, d_mnist_loss: 0.0018, d_svhn_loss: 0.0153, d_fake_loss: 0.0235, g_loss: 1.1090\n",
            "Step [71720/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0016, d_svhn_loss: 0.0485, d_fake_loss: 0.0462, g_loss: 1.0761\n",
            "Step [71730/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0073, d_svhn_loss: 0.0168, d_fake_loss: 0.0328, g_loss: 1.1554\n",
            "Step [71740/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0013, d_svhn_loss: 0.0307, d_fake_loss: 0.0075, g_loss: 1.1357\n",
            "Step [71750/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0024, d_svhn_loss: 0.0171, d_fake_loss: 0.0136, g_loss: 1.1055\n",
            "Step [71760/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0010, d_svhn_loss: 0.0162, d_fake_loss: 0.0185, g_loss: 1.1563\n",
            "Step [71770/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0013, d_svhn_loss: 0.0487, d_fake_loss: 0.0355, g_loss: 1.1034\n",
            "Step [71780/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0021, d_svhn_loss: 0.0199, d_fake_loss: 0.0342, g_loss: 1.1458\n",
            "Step [71790/80000], d_real_loss: 0.0167, d_mnist_loss: 0.0017, d_svhn_loss: 0.0151, d_fake_loss: 0.0137, g_loss: 1.1472\n",
            "Step [71800/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0047, d_svhn_loss: 0.0216, d_fake_loss: 0.0402, g_loss: 1.1003\n",
            "Step [71810/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0018, d_svhn_loss: 0.0354, d_fake_loss: 0.0308, g_loss: 1.1099\n",
            "Step [71820/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0042, d_svhn_loss: 0.0460, d_fake_loss: 0.0220, g_loss: 1.1254\n",
            "Step [71830/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0015, d_svhn_loss: 0.0368, d_fake_loss: 0.0164, g_loss: 1.1500\n",
            "Step [71840/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0029, d_svhn_loss: 0.0267, d_fake_loss: 0.0470, g_loss: 1.1785\n",
            "Step [71850/80000], d_real_loss: 0.0941, d_mnist_loss: 0.0017, d_svhn_loss: 0.0924, d_fake_loss: 0.0199, g_loss: 1.1850\n",
            "Step [71860/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0043, d_svhn_loss: 0.0209, d_fake_loss: 0.0102, g_loss: 1.1216\n",
            "Step [71870/80000], d_real_loss: 0.0135, d_mnist_loss: 0.0016, d_svhn_loss: 0.0118, d_fake_loss: 0.0079, g_loss: 1.1409\n",
            "Step [71880/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0012, d_svhn_loss: 0.0227, d_fake_loss: 0.0152, g_loss: 1.1695\n",
            "Step [71890/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0016, d_svhn_loss: 0.0247, d_fake_loss: 0.0164, g_loss: 1.1071\n",
            "Step [71900/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0012, d_svhn_loss: 0.0235, d_fake_loss: 0.0106, g_loss: 1.1050\n",
            "Step [71910/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0061, d_svhn_loss: 0.0144, d_fake_loss: 0.0088, g_loss: 1.1352\n",
            "Step [71920/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0015, d_svhn_loss: 0.0197, d_fake_loss: 0.0127, g_loss: 1.1390\n",
            "Step [71930/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0016, d_svhn_loss: 0.0360, d_fake_loss: 0.0142, g_loss: 1.1436\n",
            "Step [71940/80000], d_real_loss: 0.0155, d_mnist_loss: 0.0016, d_svhn_loss: 0.0139, d_fake_loss: 0.0303, g_loss: 1.1054\n",
            "Step [71950/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0190, d_svhn_loss: 0.0189, d_fake_loss: 0.0155, g_loss: 1.1291\n",
            "Step [71960/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0017, d_svhn_loss: 0.0252, d_fake_loss: 0.0183, g_loss: 1.1257\n",
            "Step [71970/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0015, d_svhn_loss: 0.0163, d_fake_loss: 0.1067, g_loss: 1.1242\n",
            "Step [71980/80000], d_real_loss: 0.0162, d_mnist_loss: 0.0029, d_svhn_loss: 0.0133, d_fake_loss: 0.0079, g_loss: 1.0900\n",
            "Step [71990/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0039, d_svhn_loss: 0.0260, d_fake_loss: 0.0130, g_loss: 1.1233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [72000/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0015, d_svhn_loss: 0.0634, d_fake_loss: 0.0076, g_loss: 1.1309\n",
            "saved ./samples_mnist_svhn/sample-72000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-72000-s-m.png\n",
            "Step [72010/80000], d_real_loss: 0.0140, d_mnist_loss: 0.0020, d_svhn_loss: 0.0120, d_fake_loss: 0.0595, g_loss: 1.0768\n",
            "Step [72020/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0025, d_svhn_loss: 0.0239, d_fake_loss: 0.0466, g_loss: 1.1024\n",
            "Step [72030/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0014, d_svhn_loss: 0.0492, d_fake_loss: 0.0142, g_loss: 1.2181\n",
            "Step [72040/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0017, d_svhn_loss: 0.0174, d_fake_loss: 0.0170, g_loss: 1.0781\n",
            "Step [72050/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0197, d_svhn_loss: 0.0182, d_fake_loss: 0.0249, g_loss: 1.1714\n",
            "Step [72060/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0177, d_svhn_loss: 0.0245, d_fake_loss: 0.0236, g_loss: 1.1346\n",
            "Step [72070/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0075, d_svhn_loss: 0.0245, d_fake_loss: 0.0196, g_loss: 1.0672\n",
            "Step [72080/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0014, d_svhn_loss: 0.0242, d_fake_loss: 0.0168, g_loss: 1.1048\n",
            "Step [72090/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0013, d_svhn_loss: 0.0263, d_fake_loss: 0.0521, g_loss: 1.1288\n",
            "Step [72100/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0047, d_svhn_loss: 0.0143, d_fake_loss: 0.0087, g_loss: 1.1139\n",
            "Step [72110/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0017, d_svhn_loss: 0.0178, d_fake_loss: 0.0105, g_loss: 1.1448\n",
            "Step [72120/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0096, d_svhn_loss: 0.0154, d_fake_loss: 0.0118, g_loss: 1.1250\n",
            "Step [72130/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0018, d_svhn_loss: 0.0265, d_fake_loss: 0.0124, g_loss: 1.1161\n",
            "Step [72140/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0075, d_svhn_loss: 0.0150, d_fake_loss: 0.0166, g_loss: 1.1074\n",
            "Step [72150/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0025, d_svhn_loss: 0.0197, d_fake_loss: 0.1928, g_loss: 1.1399\n",
            "Step [72160/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0013, d_svhn_loss: 0.0447, d_fake_loss: 0.0136, g_loss: 1.1058\n",
            "Step [72170/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0031, d_svhn_loss: 0.0192, d_fake_loss: 0.0228, g_loss: 1.1397\n",
            "Step [72180/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0065, d_svhn_loss: 0.0114, d_fake_loss: 0.0548, g_loss: 1.0718\n",
            "Step [72190/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0063, d_svhn_loss: 0.0243, d_fake_loss: 0.0190, g_loss: 1.0693\n",
            "Step [72200/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0042, d_svhn_loss: 0.0185, d_fake_loss: 0.0267, g_loss: 1.1208\n",
            "Step [72210/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0012, d_svhn_loss: 0.0559, d_fake_loss: 0.0105, g_loss: 1.1446\n",
            "Step [72220/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0031, d_svhn_loss: 0.0216, d_fake_loss: 0.0090, g_loss: 1.1033\n",
            "Step [72230/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0035, d_svhn_loss: 0.0155, d_fake_loss: 0.0144, g_loss: 1.0996\n",
            "Step [72240/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0028, d_svhn_loss: 0.0522, d_fake_loss: 0.0172, g_loss: 1.0985\n",
            "Step [72250/80000], d_real_loss: 0.0140, d_mnist_loss: 0.0019, d_svhn_loss: 0.0121, d_fake_loss: 0.0539, g_loss: 1.0890\n",
            "Step [72260/80000], d_real_loss: 0.0164, d_mnist_loss: 0.0014, d_svhn_loss: 0.0150, d_fake_loss: 0.0170, g_loss: 1.0880\n",
            "Step [72270/80000], d_real_loss: 0.0136, d_mnist_loss: 0.0012, d_svhn_loss: 0.0125, d_fake_loss: 0.0342, g_loss: 1.1200\n",
            "Step [72280/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0061, d_svhn_loss: 0.0173, d_fake_loss: 0.0102, g_loss: 1.1097\n",
            "Step [72290/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0060, d_svhn_loss: 0.0200, d_fake_loss: 0.0103, g_loss: 1.1148\n",
            "Step [72300/80000], d_real_loss: 0.0125, d_mnist_loss: 0.0022, d_svhn_loss: 0.0103, d_fake_loss: 0.0139, g_loss: 1.1027\n",
            "Step [72310/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0039, d_svhn_loss: 0.0295, d_fake_loss: 0.0491, g_loss: 1.0807\n",
            "Step [72320/80000], d_real_loss: 0.0129, d_mnist_loss: 0.0029, d_svhn_loss: 0.0100, d_fake_loss: 0.0060, g_loss: 1.0751\n",
            "Step [72330/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0048, d_svhn_loss: 0.0537, d_fake_loss: 0.0111, g_loss: 1.1209\n",
            "Step [72340/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0022, d_svhn_loss: 0.0312, d_fake_loss: 0.0058, g_loss: 1.0966\n",
            "Step [72350/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0022, d_svhn_loss: 0.0210, d_fake_loss: 0.0192, g_loss: 1.1130\n",
            "Step [72360/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0016, d_svhn_loss: 0.0155, d_fake_loss: 0.0317, g_loss: 1.1051\n",
            "Step [72370/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0016, d_svhn_loss: 0.0269, d_fake_loss: 0.0134, g_loss: 1.0940\n",
            "Step [72380/80000], d_real_loss: 0.0113, d_mnist_loss: 0.0019, d_svhn_loss: 0.0094, d_fake_loss: 0.0136, g_loss: 1.1544\n",
            "Step [72390/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0069, d_svhn_loss: 0.0138, d_fake_loss: 0.0113, g_loss: 1.1753\n",
            "Step [72400/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0088, d_svhn_loss: 0.0148, d_fake_loss: 0.0337, g_loss: 1.1749\n",
            "Step [72410/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0074, d_svhn_loss: 0.0200, d_fake_loss: 0.0105, g_loss: 1.1761\n",
            "Step [72420/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0019, d_svhn_loss: 0.0324, d_fake_loss: 0.0101, g_loss: 1.1674\n",
            "Step [72430/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0053, d_svhn_loss: 0.0502, d_fake_loss: 0.0456, g_loss: 1.1249\n",
            "Step [72440/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0044, d_svhn_loss: 0.0467, d_fake_loss: 0.0397, g_loss: 1.0937\n",
            "Step [72450/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0084, d_svhn_loss: 0.0157, d_fake_loss: 0.0148, g_loss: 1.0570\n",
            "Step [72460/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0017, d_svhn_loss: 0.0165, d_fake_loss: 0.0209, g_loss: 1.1089\n",
            "Step [72470/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0034, d_svhn_loss: 0.0201, d_fake_loss: 0.1075, g_loss: 1.1112\n",
            "Step [72480/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0027, d_svhn_loss: 0.0483, d_fake_loss: 0.0102, g_loss: 1.0896\n",
            "Step [72490/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0063, d_svhn_loss: 0.0189, d_fake_loss: 0.0142, g_loss: 1.0790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [72500/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0015, d_svhn_loss: 0.0482, d_fake_loss: 0.0261, g_loss: 1.1503\n",
            "saved ./samples_mnist_svhn/sample-72500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-72500-s-m.png\n",
            "Step [72510/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0153, d_svhn_loss: 0.0130, d_fake_loss: 0.0278, g_loss: 1.1316\n",
            "Step [72520/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0013, d_svhn_loss: 0.0221, d_fake_loss: 0.0301, g_loss: 1.1188\n",
            "Step [72530/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0022, d_svhn_loss: 0.0227, d_fake_loss: 0.0141, g_loss: 1.1179\n",
            "Step [72540/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0013, d_svhn_loss: 0.0243, d_fake_loss: 0.0283, g_loss: 1.1021\n",
            "Step [72550/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0018, d_svhn_loss: 0.0327, d_fake_loss: 0.0200, g_loss: 1.1279\n",
            "Step [72560/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0089, d_svhn_loss: 0.0138, d_fake_loss: 0.0234, g_loss: 1.1672\n",
            "Step [72570/80000], d_real_loss: 0.0129, d_mnist_loss: 0.0018, d_svhn_loss: 0.0111, d_fake_loss: 0.1149, g_loss: 1.1214\n",
            "Step [72580/80000], d_real_loss: 0.0701, d_mnist_loss: 0.0014, d_svhn_loss: 0.0687, d_fake_loss: 0.0476, g_loss: 1.1121\n",
            "Step [72590/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0021, d_svhn_loss: 0.0367, d_fake_loss: 0.0216, g_loss: 1.1196\n",
            "Step [72600/80000], d_real_loss: 0.0140, d_mnist_loss: 0.0017, d_svhn_loss: 0.0124, d_fake_loss: 0.0130, g_loss: 1.1029\n",
            "Step [72610/80000], d_real_loss: 0.1160, d_mnist_loss: 0.0029, d_svhn_loss: 0.1131, d_fake_loss: 0.0111, g_loss: 1.1334\n",
            "Step [72620/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0090, d_svhn_loss: 0.0583, d_fake_loss: 0.0132, g_loss: 1.1262\n",
            "Step [72630/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0057, d_svhn_loss: 0.0142, d_fake_loss: 0.0154, g_loss: 1.0469\n",
            "Step [72640/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0014, d_svhn_loss: 0.0679, d_fake_loss: 0.0240, g_loss: 1.1078\n",
            "Step [72650/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0026, d_svhn_loss: 0.0385, d_fake_loss: 0.0344, g_loss: 1.0894\n",
            "Step [72660/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0014, d_svhn_loss: 0.0209, d_fake_loss: 0.0158, g_loss: 1.1469\n",
            "Step [72670/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0055, d_svhn_loss: 0.0166, d_fake_loss: 0.0197, g_loss: 1.1335\n",
            "Step [72680/80000], d_real_loss: 0.0127, d_mnist_loss: 0.0026, d_svhn_loss: 0.0101, d_fake_loss: 0.0788, g_loss: 1.1511\n",
            "Step [72690/80000], d_real_loss: 0.0136, d_mnist_loss: 0.0026, d_svhn_loss: 0.0110, d_fake_loss: 0.0268, g_loss: 1.2242\n",
            "Step [72700/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0027, d_svhn_loss: 0.0620, d_fake_loss: 0.0832, g_loss: 1.0914\n",
            "Step [72710/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0085, d_svhn_loss: 0.0166, d_fake_loss: 0.0175, g_loss: 1.1687\n",
            "Step [72720/80000], d_real_loss: 0.0158, d_mnist_loss: 0.0018, d_svhn_loss: 0.0140, d_fake_loss: 0.0668, g_loss: 1.1197\n",
            "Step [72730/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0099, d_svhn_loss: 0.0300, d_fake_loss: 0.0798, g_loss: 1.1887\n",
            "Step [72740/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0017, d_svhn_loss: 0.0193, d_fake_loss: 0.0164, g_loss: 1.1582\n",
            "Step [72750/80000], d_real_loss: 0.0151, d_mnist_loss: 0.0024, d_svhn_loss: 0.0127, d_fake_loss: 0.1552, g_loss: 1.1434\n",
            "Step [72760/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0061, d_svhn_loss: 0.0216, d_fake_loss: 0.0481, g_loss: 1.1464\n",
            "Step [72770/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0011, d_svhn_loss: 0.0285, d_fake_loss: 0.1603, g_loss: 1.1345\n",
            "Step [72780/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0030, d_svhn_loss: 0.0148, d_fake_loss: 0.0104, g_loss: 1.1186\n",
            "Step [72790/80000], d_real_loss: 0.0150, d_mnist_loss: 0.0018, d_svhn_loss: 0.0132, d_fake_loss: 0.0720, g_loss: 1.1348\n",
            "Step [72800/80000], d_real_loss: 0.0174, d_mnist_loss: 0.0063, d_svhn_loss: 0.0111, d_fake_loss: 0.0149, g_loss: 1.1115\n",
            "Step [72810/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0050, d_svhn_loss: 0.0132, d_fake_loss: 0.0091, g_loss: 1.1195\n",
            "Step [72820/80000], d_real_loss: 0.0106, d_mnist_loss: 0.0019, d_svhn_loss: 0.0087, d_fake_loss: 0.0588, g_loss: 1.1456\n",
            "Step [72830/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0145, d_svhn_loss: 0.0113, d_fake_loss: 0.0168, g_loss: 1.1151\n",
            "Step [72840/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0033, d_svhn_loss: 0.0157, d_fake_loss: 0.0126, g_loss: 1.2138\n",
            "Step [72850/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0012, d_svhn_loss: 0.0354, d_fake_loss: 0.0192, g_loss: 1.1142\n",
            "Step [72860/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0043, d_svhn_loss: 0.0293, d_fake_loss: 0.0394, g_loss: 1.0925\n",
            "Step [72870/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0026, d_svhn_loss: 0.0213, d_fake_loss: 0.0147, g_loss: 1.1299\n",
            "Step [72880/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0087, d_svhn_loss: 0.0145, d_fake_loss: 0.0180, g_loss: 1.1560\n",
            "Step [72890/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0013, d_svhn_loss: 0.0230, d_fake_loss: 0.0176, g_loss: 1.1125\n",
            "Step [72900/80000], d_real_loss: 0.0158, d_mnist_loss: 0.0025, d_svhn_loss: 0.0132, d_fake_loss: 0.0213, g_loss: 1.1182\n",
            "Step [72910/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0019, d_svhn_loss: 0.0251, d_fake_loss: 0.0124, g_loss: 1.0963\n",
            "Step [72920/80000], d_real_loss: 0.0137, d_mnist_loss: 0.0007, d_svhn_loss: 0.0131, d_fake_loss: 0.0073, g_loss: 1.1176\n",
            "Step [72930/80000], d_real_loss: 0.0141, d_mnist_loss: 0.0017, d_svhn_loss: 0.0124, d_fake_loss: 0.0077, g_loss: 1.1238\n",
            "Step [72940/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0070, d_svhn_loss: 0.0187, d_fake_loss: 0.0127, g_loss: 1.2115\n",
            "Step [72950/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0012, d_svhn_loss: 0.0184, d_fake_loss: 0.0118, g_loss: 1.1179\n",
            "Step [72960/80000], d_real_loss: 0.0799, d_mnist_loss: 0.0590, d_svhn_loss: 0.0209, d_fake_loss: 0.0165, g_loss: 1.0236\n",
            "Step [72970/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0019, d_svhn_loss: 0.0221, d_fake_loss: 0.0163, g_loss: 1.0912\n",
            "Step [72980/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0049, d_svhn_loss: 0.0194, d_fake_loss: 0.1359, g_loss: 1.2247\n",
            "Step [72990/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0042, d_svhn_loss: 0.0329, d_fake_loss: 0.0902, g_loss: 1.1040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [73000/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0059, d_svhn_loss: 0.0382, d_fake_loss: 0.0367, g_loss: 1.1993\n",
            "saved ./samples_mnist_svhn/sample-73000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-73000-s-m.png\n",
            "Step [73010/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0020, d_svhn_loss: 0.0264, d_fake_loss: 0.0110, g_loss: 1.1303\n",
            "Step [73020/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0205, d_svhn_loss: 0.0269, d_fake_loss: 0.0191, g_loss: 1.1594\n",
            "Step [73030/80000], d_real_loss: 0.0184, d_mnist_loss: 0.0029, d_svhn_loss: 0.0155, d_fake_loss: 0.0518, g_loss: 1.2836\n",
            "Step [73040/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0029, d_svhn_loss: 0.0197, d_fake_loss: 0.0485, g_loss: 1.2122\n",
            "Step [73050/80000], d_real_loss: 0.0170, d_mnist_loss: 0.0021, d_svhn_loss: 0.0150, d_fake_loss: 0.0144, g_loss: 1.1578\n",
            "Step [73060/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0036, d_svhn_loss: 0.0161, d_fake_loss: 0.0162, g_loss: 1.1796\n",
            "Step [73070/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0020, d_svhn_loss: 0.0225, d_fake_loss: 0.0172, g_loss: 1.2001\n",
            "Step [73080/80000], d_real_loss: 0.0157, d_mnist_loss: 0.0044, d_svhn_loss: 0.0113, d_fake_loss: 0.0137, g_loss: 1.1495\n",
            "Step [73090/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0022, d_svhn_loss: 0.0170, d_fake_loss: 0.0129, g_loss: 1.1733\n",
            "Step [73100/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0052, d_svhn_loss: 0.0199, d_fake_loss: 0.0511, g_loss: 1.1874\n",
            "Step [73110/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0040, d_svhn_loss: 0.0429, d_fake_loss: 0.0447, g_loss: 1.1084\n",
            "Step [73120/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0017, d_svhn_loss: 0.0488, d_fake_loss: 0.0166, g_loss: 1.2215\n",
            "Step [73130/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0123, d_svhn_loss: 0.0530, d_fake_loss: 0.0099, g_loss: 1.1310\n",
            "Step [73140/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0026, d_svhn_loss: 0.0245, d_fake_loss: 0.0316, g_loss: 1.1904\n",
            "Step [73150/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0059, d_svhn_loss: 0.0239, d_fake_loss: 0.0423, g_loss: 1.4077\n",
            "Step [73160/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0120, d_svhn_loss: 0.0133, d_fake_loss: 0.0655, g_loss: 1.1210\n",
            "Step [73170/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0102, d_svhn_loss: 0.0113, d_fake_loss: 0.0077, g_loss: 1.1199\n",
            "Step [73180/80000], d_real_loss: 0.0164, d_mnist_loss: 0.0016, d_svhn_loss: 0.0148, d_fake_loss: 0.0144, g_loss: 1.1162\n",
            "Step [73190/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0054, d_svhn_loss: 0.0260, d_fake_loss: 0.0102, g_loss: 1.1462\n",
            "Step [73200/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0018, d_svhn_loss: 0.0162, d_fake_loss: 0.0107, g_loss: 1.1216\n",
            "Step [73210/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0091, d_svhn_loss: 0.0284, d_fake_loss: 0.1012, g_loss: 1.2816\n",
            "Step [73220/80000], d_real_loss: 0.0219, d_mnist_loss: 0.0031, d_svhn_loss: 0.0188, d_fake_loss: 0.0322, g_loss: 1.2331\n",
            "Step [73230/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0017, d_svhn_loss: 0.0169, d_fake_loss: 0.0602, g_loss: 1.1586\n",
            "Step [73240/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0027, d_svhn_loss: 0.0170, d_fake_loss: 0.0068, g_loss: 1.2091\n",
            "Step [73250/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0032, d_svhn_loss: 0.0271, d_fake_loss: 0.0094, g_loss: 1.1948\n",
            "Step [73260/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0052, d_svhn_loss: 0.0210, d_fake_loss: 0.0162, g_loss: 1.1219\n",
            "Step [73270/80000], d_real_loss: 0.0151, d_mnist_loss: 0.0018, d_svhn_loss: 0.0133, d_fake_loss: 0.0193, g_loss: 1.1369\n",
            "Step [73280/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0017, d_svhn_loss: 0.0210, d_fake_loss: 0.0072, g_loss: 1.1918\n",
            "Step [73290/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0027, d_svhn_loss: 0.0252, d_fake_loss: 0.0254, g_loss: 1.1162\n",
            "Step [73300/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0043, d_svhn_loss: 0.0221, d_fake_loss: 0.0137, g_loss: 1.1311\n",
            "Step [73310/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0026, d_svhn_loss: 0.0190, d_fake_loss: 0.0155, g_loss: 1.1016\n",
            "Step [73320/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0234, d_svhn_loss: 0.0290, d_fake_loss: 0.0194, g_loss: 1.2021\n",
            "Step [73330/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0030, d_svhn_loss: 0.0254, d_fake_loss: 0.0166, g_loss: 1.1503\n",
            "Step [73340/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0051, d_svhn_loss: 0.0260, d_fake_loss: 0.0514, g_loss: 1.0865\n",
            "Step [73350/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0028, d_svhn_loss: 0.0155, d_fake_loss: 0.1272, g_loss: 1.2171\n",
            "Step [73360/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0049, d_svhn_loss: 0.0168, d_fake_loss: 0.0172, g_loss: 1.1279\n",
            "Step [73370/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0033, d_svhn_loss: 0.0234, d_fake_loss: 0.1225, g_loss: 1.1206\n",
            "Step [73380/80000], d_real_loss: 0.0193, d_mnist_loss: 0.0027, d_svhn_loss: 0.0166, d_fake_loss: 0.0201, g_loss: 1.1178\n",
            "Step [73390/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0012, d_svhn_loss: 0.0169, d_fake_loss: 0.0467, g_loss: 1.0792\n",
            "Step [73400/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0021, d_svhn_loss: 0.0230, d_fake_loss: 0.0176, g_loss: 1.1252\n",
            "Step [73410/80000], d_real_loss: 0.0158, d_mnist_loss: 0.0020, d_svhn_loss: 0.0138, d_fake_loss: 0.0119, g_loss: 1.1237\n",
            "Step [73420/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0030, d_svhn_loss: 0.0377, d_fake_loss: 0.0095, g_loss: 1.1312\n",
            "Step [73430/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0044, d_svhn_loss: 0.0174, d_fake_loss: 0.1226, g_loss: 1.0840\n",
            "Step [73440/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0070, d_svhn_loss: 0.0408, d_fake_loss: 0.0186, g_loss: 1.1908\n",
            "Step [73450/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0051, d_svhn_loss: 0.0386, d_fake_loss: 0.0415, g_loss: 1.1094\n",
            "Step [73460/80000], d_real_loss: 0.0188, d_mnist_loss: 0.0016, d_svhn_loss: 0.0173, d_fake_loss: 0.0140, g_loss: 1.1586\n",
            "Step [73470/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0020, d_svhn_loss: 0.0158, d_fake_loss: 0.0277, g_loss: 1.0819\n",
            "Step [73480/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0036, d_svhn_loss: 0.0315, d_fake_loss: 0.0094, g_loss: 1.1302\n",
            "Step [73490/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0019, d_svhn_loss: 0.0178, d_fake_loss: 0.0457, g_loss: 1.1260\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [73500/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0014, d_svhn_loss: 0.0417, d_fake_loss: 0.0257, g_loss: 1.0972\n",
            "saved ./samples_mnist_svhn/sample-73500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-73500-s-m.png\n",
            "Step [73510/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0095, d_svhn_loss: 0.0174, d_fake_loss: 0.0165, g_loss: 1.1278\n",
            "Step [73520/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0012, d_svhn_loss: 0.0199, d_fake_loss: 0.0133, g_loss: 1.1451\n",
            "Step [73530/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0057, d_svhn_loss: 0.0381, d_fake_loss: 0.1035, g_loss: 1.1231\n",
            "Step [73540/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0012, d_svhn_loss: 0.0591, d_fake_loss: 0.0222, g_loss: 1.1034\n",
            "Step [73550/80000], d_real_loss: 0.0940, d_mnist_loss: 0.0012, d_svhn_loss: 0.0928, d_fake_loss: 0.0687, g_loss: 1.1093\n",
            "Step [73560/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0014, d_svhn_loss: 0.0216, d_fake_loss: 0.0224, g_loss: 1.0776\n",
            "Step [73570/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0018, d_svhn_loss: 0.0153, d_fake_loss: 0.0251, g_loss: 1.1733\n",
            "Step [73580/80000], d_real_loss: 0.0189, d_mnist_loss: 0.0027, d_svhn_loss: 0.0162, d_fake_loss: 0.0252, g_loss: 1.1070\n",
            "Step [73590/80000], d_real_loss: 0.0152, d_mnist_loss: 0.0019, d_svhn_loss: 0.0133, d_fake_loss: 0.0200, g_loss: 1.1211\n",
            "Step [73600/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0025, d_svhn_loss: 0.0210, d_fake_loss: 0.0085, g_loss: 1.1230\n",
            "Step [73610/80000], d_real_loss: 0.1046, d_mnist_loss: 0.0041, d_svhn_loss: 0.1004, d_fake_loss: 0.0127, g_loss: 1.0747\n",
            "Step [73620/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0046, d_svhn_loss: 0.0252, d_fake_loss: 0.0239, g_loss: 1.0800\n",
            "Step [73630/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0034, d_svhn_loss: 0.0144, d_fake_loss: 0.0211, g_loss: 1.1017\n",
            "Step [73640/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0010, d_svhn_loss: 0.0182, d_fake_loss: 0.0116, g_loss: 1.1225\n",
            "Step [73650/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0015, d_svhn_loss: 0.0171, d_fake_loss: 0.0082, g_loss: 1.1137\n",
            "Step [73660/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0087, d_svhn_loss: 0.0274, d_fake_loss: 0.0184, g_loss: 1.0967\n",
            "Step [73670/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0020, d_svhn_loss: 0.0186, d_fake_loss: 0.0064, g_loss: 1.0641\n",
            "Step [73680/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0046, d_svhn_loss: 0.0379, d_fake_loss: 0.0126, g_loss: 1.1871\n",
            "Step [73690/80000], d_real_loss: 0.0155, d_mnist_loss: 0.0048, d_svhn_loss: 0.0107, d_fake_loss: 0.0453, g_loss: 1.1539\n",
            "Step [73700/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0012, d_svhn_loss: 0.0323, d_fake_loss: 0.0299, g_loss: 1.1008\n",
            "Step [73710/80000], d_real_loss: 0.0147, d_mnist_loss: 0.0012, d_svhn_loss: 0.0134, d_fake_loss: 0.0194, g_loss: 1.1037\n",
            "Step [73720/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0008, d_svhn_loss: 0.0194, d_fake_loss: 0.0101, g_loss: 1.0964\n",
            "Step [73730/80000], d_real_loss: 0.0125, d_mnist_loss: 0.0020, d_svhn_loss: 0.0105, d_fake_loss: 0.0292, g_loss: 1.0959\n",
            "Step [73740/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0087, d_svhn_loss: 0.0161, d_fake_loss: 0.0207, g_loss: 1.2828\n",
            "Step [73750/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0019, d_svhn_loss: 0.0454, d_fake_loss: 0.0581, g_loss: 1.0710\n",
            "Step [73760/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0035, d_svhn_loss: 0.0173, d_fake_loss: 0.0312, g_loss: 1.1693\n",
            "Step [73770/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0134, d_svhn_loss: 0.0115, d_fake_loss: 0.0273, g_loss: 1.1415\n",
            "Step [73780/80000], d_real_loss: 0.0961, d_mnist_loss: 0.0153, d_svhn_loss: 0.0808, d_fake_loss: 0.0064, g_loss: 1.0492\n",
            "Step [73790/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0010, d_svhn_loss: 0.0176, d_fake_loss: 0.0110, g_loss: 1.1342\n",
            "Step [73800/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0016, d_svhn_loss: 0.0192, d_fake_loss: 0.0225, g_loss: 1.1612\n",
            "Step [73810/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0019, d_svhn_loss: 0.0210, d_fake_loss: 0.0403, g_loss: 1.0849\n",
            "Step [73820/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0077, d_svhn_loss: 0.0155, d_fake_loss: 0.0356, g_loss: 1.0850\n",
            "Step [73830/80000], d_real_loss: 0.0117, d_mnist_loss: 0.0012, d_svhn_loss: 0.0105, d_fake_loss: 0.0168, g_loss: 1.0642\n",
            "Step [73840/80000], d_real_loss: 0.0169, d_mnist_loss: 0.0027, d_svhn_loss: 0.0143, d_fake_loss: 0.0151, g_loss: 1.1012\n",
            "Step [73850/80000], d_real_loss: 0.0143, d_mnist_loss: 0.0028, d_svhn_loss: 0.0115, d_fake_loss: 0.0102, g_loss: 1.1208\n",
            "Step [73860/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0008, d_svhn_loss: 0.0667, d_fake_loss: 0.0194, g_loss: 1.1607\n",
            "Step [73870/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0017, d_svhn_loss: 0.0291, d_fake_loss: 0.0103, g_loss: 1.1230\n",
            "Step [73880/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0038, d_svhn_loss: 0.0373, d_fake_loss: 0.0168, g_loss: 1.1194\n",
            "Step [73890/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0027, d_svhn_loss: 0.0214, d_fake_loss: 0.0072, g_loss: 1.1838\n",
            "Step [73900/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0016, d_svhn_loss: 0.0236, d_fake_loss: 0.0362, g_loss: 1.1198\n",
            "Step [73910/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0028, d_svhn_loss: 0.0622, d_fake_loss: 0.0450, g_loss: 1.2474\n",
            "Step [73920/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0013, d_svhn_loss: 0.0540, d_fake_loss: 0.0216, g_loss: 1.0940\n",
            "Step [73930/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0014, d_svhn_loss: 0.0301, d_fake_loss: 0.0229, g_loss: 1.1361\n",
            "Step [73940/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0044, d_svhn_loss: 0.0182, d_fake_loss: 0.0067, g_loss: 1.1508\n",
            "Step [73950/80000], d_real_loss: 0.0133, d_mnist_loss: 0.0023, d_svhn_loss: 0.0110, d_fake_loss: 0.0281, g_loss: 1.0956\n",
            "Step [73960/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0010, d_svhn_loss: 0.0512, d_fake_loss: 0.0084, g_loss: 1.1816\n",
            "Step [73970/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0015, d_svhn_loss: 0.0276, d_fake_loss: 0.0446, g_loss: 1.1041\n",
            "Step [73980/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0014, d_svhn_loss: 0.0166, d_fake_loss: 0.0097, g_loss: 1.0998\n",
            "Step [73990/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0057, d_svhn_loss: 0.0231, d_fake_loss: 0.0100, g_loss: 1.0772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [74000/80000], d_real_loss: 0.0154, d_mnist_loss: 0.0016, d_svhn_loss: 0.0138, d_fake_loss: 0.0365, g_loss: 1.1051\n",
            "saved ./samples_mnist_svhn/sample-74000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-74000-s-m.png\n",
            "Step [74010/80000], d_real_loss: 0.0113, d_mnist_loss: 0.0030, d_svhn_loss: 0.0083, d_fake_loss: 0.0203, g_loss: 1.0697\n",
            "Step [74020/80000], d_real_loss: 0.0224, d_mnist_loss: 0.0035, d_svhn_loss: 0.0189, d_fake_loss: 0.0088, g_loss: 1.1536\n",
            "Step [74030/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0040, d_svhn_loss: 0.0166, d_fake_loss: 0.0108, g_loss: 1.1225\n",
            "Step [74040/80000], d_real_loss: 0.0174, d_mnist_loss: 0.0011, d_svhn_loss: 0.0164, d_fake_loss: 0.0091, g_loss: 1.1151\n",
            "Step [74050/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0028, d_svhn_loss: 0.0209, d_fake_loss: 0.0127, g_loss: 1.1118\n",
            "Step [74060/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0009, d_svhn_loss: 0.0255, d_fake_loss: 0.0105, g_loss: 1.1120\n",
            "Step [74070/80000], d_real_loss: 0.0126, d_mnist_loss: 0.0021, d_svhn_loss: 0.0105, d_fake_loss: 0.0363, g_loss: 1.1345\n",
            "Step [74080/80000], d_real_loss: 0.1331, d_mnist_loss: 0.0980, d_svhn_loss: 0.0351, d_fake_loss: 0.2125, g_loss: 1.4732\n",
            "Step [74090/80000], d_real_loss: 0.0148, d_mnist_loss: 0.0012, d_svhn_loss: 0.0135, d_fake_loss: 0.0808, g_loss: 1.2422\n",
            "Step [74100/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0125, d_svhn_loss: 0.0260, d_fake_loss: 0.0374, g_loss: 1.0758\n",
            "Step [74110/80000], d_real_loss: 0.0175, d_mnist_loss: 0.0023, d_svhn_loss: 0.0152, d_fake_loss: 0.0269, g_loss: 1.2133\n",
            "Step [74120/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0026, d_svhn_loss: 0.0233, d_fake_loss: 0.1057, g_loss: 1.2938\n",
            "Step [74130/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0045, d_svhn_loss: 0.0301, d_fake_loss: 0.0135, g_loss: 1.1975\n",
            "Step [74140/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0024, d_svhn_loss: 0.0293, d_fake_loss: 0.0425, g_loss: 1.1369\n",
            "Step [74150/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0018, d_svhn_loss: 0.0205, d_fake_loss: 0.0365, g_loss: 1.1503\n",
            "Step [74160/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0066, d_svhn_loss: 0.0204, d_fake_loss: 0.0199, g_loss: 1.1407\n",
            "Step [74170/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0042, d_svhn_loss: 0.0173, d_fake_loss: 0.0494, g_loss: 1.1225\n",
            "Step [74180/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0046, d_svhn_loss: 0.0182, d_fake_loss: 0.0133, g_loss: 1.1716\n",
            "Step [74190/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0023, d_svhn_loss: 0.0480, d_fake_loss: 0.0281, g_loss: 1.0228\n",
            "Step [74200/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0040, d_svhn_loss: 0.0159, d_fake_loss: 0.0151, g_loss: 1.0883\n",
            "Step [74210/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0034, d_svhn_loss: 0.0519, d_fake_loss: 0.0755, g_loss: 1.2098\n",
            "Step [74220/80000], d_real_loss: 0.0157, d_mnist_loss: 0.0039, d_svhn_loss: 0.0117, d_fake_loss: 0.0340, g_loss: 1.0734\n",
            "Step [74230/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0021, d_svhn_loss: 0.0207, d_fake_loss: 0.0280, g_loss: 1.1747\n",
            "Step [74240/80000], d_real_loss: 0.0156, d_mnist_loss: 0.0027, d_svhn_loss: 0.0129, d_fake_loss: 0.0441, g_loss: 1.1280\n",
            "Step [74250/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0028, d_svhn_loss: 0.0193, d_fake_loss: 0.0305, g_loss: 1.1041\n",
            "Step [74260/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0034, d_svhn_loss: 0.0769, d_fake_loss: 0.0380, g_loss: 1.1738\n",
            "Step [74270/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0031, d_svhn_loss: 0.0324, d_fake_loss: 0.0142, g_loss: 1.0576\n",
            "Step [74280/80000], d_real_loss: 0.0155, d_mnist_loss: 0.0034, d_svhn_loss: 0.0122, d_fake_loss: 0.0119, g_loss: 1.1760\n",
            "Step [74290/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0064, d_svhn_loss: 0.0354, d_fake_loss: 0.0378, g_loss: 1.1416\n",
            "Step [74300/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0028, d_svhn_loss: 0.0692, d_fake_loss: 0.0277, g_loss: 1.1302\n",
            "Step [74310/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0090, d_svhn_loss: 0.0167, d_fake_loss: 0.0203, g_loss: 1.1142\n",
            "Step [74320/80000], d_real_loss: 0.0174, d_mnist_loss: 0.0062, d_svhn_loss: 0.0111, d_fake_loss: 0.0190, g_loss: 1.1709\n",
            "Step [74330/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0049, d_svhn_loss: 0.0150, d_fake_loss: 0.0121, g_loss: 1.1619\n",
            "Step [74340/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0046, d_svhn_loss: 0.0509, d_fake_loss: 0.0428, g_loss: 1.1492\n",
            "Step [74350/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0038, d_svhn_loss: 0.0358, d_fake_loss: 0.0179, g_loss: 1.1467\n",
            "Step [74360/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0035, d_svhn_loss: 0.0404, d_fake_loss: 0.0125, g_loss: 1.1691\n",
            "Step [74370/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0037, d_svhn_loss: 0.0135, d_fake_loss: 0.0143, g_loss: 1.0821\n",
            "Step [74380/80000], d_real_loss: 0.0151, d_mnist_loss: 0.0045, d_svhn_loss: 0.0107, d_fake_loss: 0.0194, g_loss: 1.0973\n",
            "Step [74390/80000], d_real_loss: 0.0134, d_mnist_loss: 0.0051, d_svhn_loss: 0.0082, d_fake_loss: 0.0320, g_loss: 1.2484\n",
            "Step [74400/80000], d_real_loss: 0.0169, d_mnist_loss: 0.0028, d_svhn_loss: 0.0141, d_fake_loss: 0.0223, g_loss: 1.1642\n",
            "Step [74410/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0039, d_svhn_loss: 0.0183, d_fake_loss: 0.0432, g_loss: 1.1873\n",
            "Step [74420/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0033, d_svhn_loss: 0.0197, d_fake_loss: 0.0428, g_loss: 1.1298\n",
            "Step [74430/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0026, d_svhn_loss: 0.0463, d_fake_loss: 0.0572, g_loss: 1.0692\n",
            "Step [74440/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0030, d_svhn_loss: 0.0182, d_fake_loss: 0.0273, g_loss: 1.2961\n",
            "Step [74450/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0026, d_svhn_loss: 0.0184, d_fake_loss: 0.0327, g_loss: 1.2451\n",
            "Step [74460/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0042, d_svhn_loss: 0.0152, d_fake_loss: 0.0261, g_loss: 1.1959\n",
            "Step [74470/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0035, d_svhn_loss: 0.0147, d_fake_loss: 0.0290, g_loss: 1.2253\n",
            "Step [74480/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0102, d_svhn_loss: 0.0199, d_fake_loss: 0.0139, g_loss: 1.1301\n",
            "Step [74490/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0024, d_svhn_loss: 0.0149, d_fake_loss: 0.0107, g_loss: 1.0724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [74500/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0033, d_svhn_loss: 0.0230, d_fake_loss: 0.1785, g_loss: 0.7366\n",
            "saved ./samples_mnist_svhn/sample-74500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-74500-s-m.png\n",
            "Step [74510/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0122, d_svhn_loss: 0.0207, d_fake_loss: 0.0232, g_loss: 1.2453\n",
            "Step [74520/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0089, d_svhn_loss: 0.0159, d_fake_loss: 0.0405, g_loss: 1.1995\n",
            "Step [74530/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0033, d_svhn_loss: 0.0240, d_fake_loss: 0.0134, g_loss: 1.1891\n",
            "Step [74540/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0082, d_svhn_loss: 0.0471, d_fake_loss: 0.1227, g_loss: 1.2013\n",
            "Step [74550/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0042, d_svhn_loss: 0.0338, d_fake_loss: 0.0278, g_loss: 1.1648\n",
            "Step [74560/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0052, d_svhn_loss: 0.0434, d_fake_loss: 0.0206, g_loss: 1.1972\n",
            "Step [74570/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0022, d_svhn_loss: 0.0189, d_fake_loss: 0.0283, g_loss: 1.0555\n",
            "Step [74580/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0075, d_svhn_loss: 0.0548, d_fake_loss: 0.0206, g_loss: 1.1159\n",
            "Step [74590/80000], d_real_loss: 0.1101, d_mnist_loss: 0.0026, d_svhn_loss: 0.1074, d_fake_loss: 0.0079, g_loss: 1.1469\n",
            "Step [74600/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0062, d_svhn_loss: 0.0173, d_fake_loss: 0.0108, g_loss: 1.2984\n",
            "Step [74610/80000], d_real_loss: 0.0155, d_mnist_loss: 0.0038, d_svhn_loss: 0.0118, d_fake_loss: 0.0139, g_loss: 1.1726\n",
            "Step [74620/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0034, d_svhn_loss: 0.0196, d_fake_loss: 0.0084, g_loss: 1.1549\n",
            "Step [74630/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0066, d_svhn_loss: 0.0262, d_fake_loss: 0.0140, g_loss: 1.1833\n",
            "Step [74640/80000], d_real_loss: 0.0133, d_mnist_loss: 0.0025, d_svhn_loss: 0.0108, d_fake_loss: 0.0117, g_loss: 1.1363\n",
            "Step [74650/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0025, d_svhn_loss: 0.0217, d_fake_loss: 0.0579, g_loss: 1.3744\n",
            "Step [74660/80000], d_real_loss: 0.0138, d_mnist_loss: 0.0031, d_svhn_loss: 0.0107, d_fake_loss: 0.0086, g_loss: 1.1830\n",
            "Step [74670/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0066, d_svhn_loss: 0.0176, d_fake_loss: 0.0210, g_loss: 1.0831\n",
            "Step [74680/80000], d_real_loss: 0.0170, d_mnist_loss: 0.0024, d_svhn_loss: 0.0146, d_fake_loss: 0.0171, g_loss: 1.1400\n",
            "Step [74690/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0030, d_svhn_loss: 0.0275, d_fake_loss: 0.0175, g_loss: 1.1780\n",
            "Step [74700/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0028, d_svhn_loss: 0.0584, d_fake_loss: 0.0106, g_loss: 1.0964\n",
            "Step [74710/80000], d_real_loss: 0.0132, d_mnist_loss: 0.0029, d_svhn_loss: 0.0103, d_fake_loss: 0.0485, g_loss: 1.2507\n",
            "Step [74720/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0076, d_svhn_loss: 0.0343, d_fake_loss: 0.2509, g_loss: 1.0790\n",
            "Step [74730/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0122, d_svhn_loss: 0.0273, d_fake_loss: 0.0207, g_loss: 1.1642\n",
            "Step [74740/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0024, d_svhn_loss: 0.0199, d_fake_loss: 0.0094, g_loss: 1.1484\n",
            "Step [74750/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0126, d_svhn_loss: 0.0121, d_fake_loss: 0.0664, g_loss: 1.0783\n",
            "Step [74760/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0074, d_svhn_loss: 0.0123, d_fake_loss: 0.0291, g_loss: 1.1085\n",
            "Step [74770/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0033, d_svhn_loss: 0.0178, d_fake_loss: 0.0090, g_loss: 1.1175\n",
            "Step [74780/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0021, d_svhn_loss: 0.0400, d_fake_loss: 0.0175, g_loss: 1.0842\n",
            "Step [74790/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0026, d_svhn_loss: 0.0249, d_fake_loss: 0.0543, g_loss: 1.1021\n",
            "Step [74800/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0026, d_svhn_loss: 0.0184, d_fake_loss: 0.0100, g_loss: 1.1262\n",
            "Step [74810/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0039, d_svhn_loss: 0.0386, d_fake_loss: 0.0430, g_loss: 1.0341\n",
            "Step [74820/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0024, d_svhn_loss: 0.0299, d_fake_loss: 0.0495, g_loss: 1.1495\n",
            "Step [74830/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0027, d_svhn_loss: 0.0155, d_fake_loss: 0.0121, g_loss: 1.1420\n",
            "Step [74840/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0065, d_svhn_loss: 0.0113, d_fake_loss: 0.0251, g_loss: 1.1150\n",
            "Step [74850/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0021, d_svhn_loss: 0.0159, d_fake_loss: 0.0276, g_loss: 1.1605\n",
            "Step [74860/80000], d_real_loss: 0.0189, d_mnist_loss: 0.0030, d_svhn_loss: 0.0159, d_fake_loss: 0.0129, g_loss: 1.2115\n",
            "Step [74870/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0037, d_svhn_loss: 0.0450, d_fake_loss: 0.0086, g_loss: 1.1220\n",
            "Step [74880/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0053, d_svhn_loss: 0.0169, d_fake_loss: 0.0152, g_loss: 1.1365\n",
            "Step [74890/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0045, d_svhn_loss: 0.0176, d_fake_loss: 0.0375, g_loss: 1.1237\n",
            "Step [74900/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0079, d_svhn_loss: 0.0100, d_fake_loss: 0.0591, g_loss: 1.0356\n",
            "Step [74910/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0027, d_svhn_loss: 0.0220, d_fake_loss: 0.0073, g_loss: 1.1115\n",
            "Step [74920/80000], d_real_loss: 0.1500, d_mnist_loss: 0.0025, d_svhn_loss: 0.1475, d_fake_loss: 0.0248, g_loss: 1.0590\n",
            "Step [74930/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0088, d_svhn_loss: 0.0242, d_fake_loss: 0.1041, g_loss: 1.1309\n",
            "Step [74940/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0023, d_svhn_loss: 0.0413, d_fake_loss: 0.0108, g_loss: 1.0663\n",
            "Step [74950/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0049, d_svhn_loss: 0.0360, d_fake_loss: 0.0289, g_loss: 1.1363\n",
            "Step [74960/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0046, d_svhn_loss: 0.0227, d_fake_loss: 0.0077, g_loss: 1.2134\n",
            "Step [74970/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0030, d_svhn_loss: 0.0187, d_fake_loss: 0.0137, g_loss: 1.2033\n",
            "Step [74980/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0027, d_svhn_loss: 0.0181, d_fake_loss: 0.0257, g_loss: 1.2895\n",
            "Step [74990/80000], d_real_loss: 0.0157, d_mnist_loss: 0.0028, d_svhn_loss: 0.0128, d_fake_loss: 0.0244, g_loss: 1.1462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [75000/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0055, d_svhn_loss: 0.0176, d_fake_loss: 0.0169, g_loss: 1.1947\n",
            "saved ./samples_mnist_svhn/sample-75000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-75000-s-m.png\n",
            "Step [75010/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0059, d_svhn_loss: 0.0240, d_fake_loss: 0.0156, g_loss: 1.1645\n",
            "Step [75020/80000], d_real_loss: 0.0179, d_mnist_loss: 0.0024, d_svhn_loss: 0.0155, d_fake_loss: 0.0228, g_loss: 1.1725\n",
            "Step [75030/80000], d_real_loss: 0.0175, d_mnist_loss: 0.0047, d_svhn_loss: 0.0128, d_fake_loss: 0.0179, g_loss: 1.1711\n",
            "Step [75040/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0027, d_svhn_loss: 0.0233, d_fake_loss: 0.0151, g_loss: 1.1719\n",
            "Step [75050/80000], d_real_loss: 0.0885, d_mnist_loss: 0.0015, d_svhn_loss: 0.0869, d_fake_loss: 0.1218, g_loss: 1.2080\n",
            "Step [75060/80000], d_real_loss: 0.0167, d_mnist_loss: 0.0025, d_svhn_loss: 0.0142, d_fake_loss: 0.0171, g_loss: 1.1349\n",
            "Step [75070/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0019, d_svhn_loss: 0.0202, d_fake_loss: 0.0069, g_loss: 1.1104\n",
            "Step [75080/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0019, d_svhn_loss: 0.0310, d_fake_loss: 0.0278, g_loss: 1.1996\n",
            "Step [75090/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0193, d_svhn_loss: 0.0164, d_fake_loss: 0.0099, g_loss: 1.1166\n",
            "Step [75100/80000], d_real_loss: 0.0143, d_mnist_loss: 0.0033, d_svhn_loss: 0.0110, d_fake_loss: 0.0178, g_loss: 1.1550\n",
            "Step [75110/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0068, d_svhn_loss: 0.0516, d_fake_loss: 0.0488, g_loss: 1.2252\n",
            "Step [75120/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0034, d_svhn_loss: 0.0170, d_fake_loss: 0.0104, g_loss: 1.1562\n",
            "Step [75130/80000], d_real_loss: 0.0168, d_mnist_loss: 0.0016, d_svhn_loss: 0.0153, d_fake_loss: 0.0110, g_loss: 1.1782\n",
            "Step [75140/80000], d_real_loss: 0.0152, d_mnist_loss: 0.0021, d_svhn_loss: 0.0130, d_fake_loss: 0.0327, g_loss: 1.0659\n",
            "Step [75150/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0032, d_svhn_loss: 0.0163, d_fake_loss: 0.0447, g_loss: 1.2494\n",
            "Step [75160/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0029, d_svhn_loss: 0.0209, d_fake_loss: 0.0163, g_loss: 1.1611\n",
            "Step [75170/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0023, d_svhn_loss: 0.0386, d_fake_loss: 0.0111, g_loss: 1.1063\n",
            "Step [75180/80000], d_real_loss: 0.0174, d_mnist_loss: 0.0020, d_svhn_loss: 0.0154, d_fake_loss: 0.0139, g_loss: 1.0523\n",
            "Step [75190/80000], d_real_loss: 0.0163, d_mnist_loss: 0.0017, d_svhn_loss: 0.0146, d_fake_loss: 0.0107, g_loss: 1.1166\n",
            "Step [75200/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0014, d_svhn_loss: 0.0349, d_fake_loss: 0.0858, g_loss: 1.2738\n",
            "Step [75210/80000], d_real_loss: 0.0180, d_mnist_loss: 0.0070, d_svhn_loss: 0.0110, d_fake_loss: 0.0149, g_loss: 1.1676\n",
            "Step [75220/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0042, d_svhn_loss: 0.0139, d_fake_loss: 0.0195, g_loss: 1.1011\n",
            "Step [75230/80000], d_real_loss: 0.0148, d_mnist_loss: 0.0020, d_svhn_loss: 0.0128, d_fake_loss: 0.1159, g_loss: 1.1347\n",
            "Step [75240/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0064, d_svhn_loss: 0.0162, d_fake_loss: 0.0371, g_loss: 1.1166\n",
            "Step [75250/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0014, d_svhn_loss: 0.0176, d_fake_loss: 0.0327, g_loss: 1.0905\n",
            "Step [75260/80000], d_real_loss: 0.0146, d_mnist_loss: 0.0025, d_svhn_loss: 0.0121, d_fake_loss: 0.0184, g_loss: 1.1160\n",
            "Step [75270/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0040, d_svhn_loss: 0.0690, d_fake_loss: 0.0538, g_loss: 1.0438\n",
            "Step [75280/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0042, d_svhn_loss: 0.0235, d_fake_loss: 0.0207, g_loss: 1.1814\n",
            "Step [75290/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0049, d_svhn_loss: 0.0200, d_fake_loss: 0.0549, g_loss: 1.1191\n",
            "Step [75300/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0088, d_svhn_loss: 0.0176, d_fake_loss: 0.0261, g_loss: 1.1616\n",
            "Step [75310/80000], d_real_loss: 0.0796, d_mnist_loss: 0.0036, d_svhn_loss: 0.0760, d_fake_loss: 0.0130, g_loss: 1.1969\n",
            "Step [75320/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0037, d_svhn_loss: 0.0153, d_fake_loss: 0.0097, g_loss: 1.1810\n",
            "Step [75330/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0046, d_svhn_loss: 0.0183, d_fake_loss: 0.0086, g_loss: 1.1646\n",
            "Step [75340/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0036, d_svhn_loss: 0.0201, d_fake_loss: 0.0334, g_loss: 1.0796\n",
            "Step [75350/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0034, d_svhn_loss: 0.0216, d_fake_loss: 0.0312, g_loss: 1.1101\n",
            "Step [75360/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0029, d_svhn_loss: 0.0430, d_fake_loss: 0.0080, g_loss: 1.1741\n",
            "Step [75370/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0126, d_svhn_loss: 0.0161, d_fake_loss: 0.0239, g_loss: 1.3031\n",
            "Step [75380/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0021, d_svhn_loss: 0.0209, d_fake_loss: 0.0109, g_loss: 1.1068\n",
            "Step [75390/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0030, d_svhn_loss: 0.0464, d_fake_loss: 0.0079, g_loss: 1.2116\n",
            "Step [75400/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0023, d_svhn_loss: 0.0181, d_fake_loss: 0.0204, g_loss: 1.1652\n",
            "Step [75410/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0053, d_svhn_loss: 0.0196, d_fake_loss: 0.0174, g_loss: 1.0834\n",
            "Step [75420/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0033, d_svhn_loss: 0.0154, d_fake_loss: 0.0274, g_loss: 1.2988\n",
            "Step [75430/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0125, d_svhn_loss: 0.0666, d_fake_loss: 0.0259, g_loss: 1.1311\n",
            "Step [75440/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0032, d_svhn_loss: 0.0262, d_fake_loss: 0.0242, g_loss: 1.1714\n",
            "Step [75450/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0117, d_svhn_loss: 0.0231, d_fake_loss: 0.1181, g_loss: 1.2058\n",
            "Step [75460/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0311, d_svhn_loss: 0.0149, d_fake_loss: 0.0347, g_loss: 1.1615\n",
            "Step [75470/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0037, d_svhn_loss: 0.0170, d_fake_loss: 0.0109, g_loss: 1.1054\n",
            "Step [75480/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0015, d_svhn_loss: 0.0190, d_fake_loss: 0.0149, g_loss: 1.1099\n",
            "Step [75490/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0069, d_svhn_loss: 0.0431, d_fake_loss: 0.0338, g_loss: 1.1072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [75500/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0034, d_svhn_loss: 0.0707, d_fake_loss: 0.0265, g_loss: 1.1486\n",
            "saved ./samples_mnist_svhn/sample-75500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-75500-s-m.png\n",
            "Step [75510/80000], d_real_loss: 0.0168, d_mnist_loss: 0.0028, d_svhn_loss: 0.0139, d_fake_loss: 0.0191, g_loss: 1.1389\n",
            "Step [75520/80000], d_real_loss: 0.0169, d_mnist_loss: 0.0025, d_svhn_loss: 0.0144, d_fake_loss: 0.0405, g_loss: 1.1523\n",
            "Step [75530/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0025, d_svhn_loss: 0.0171, d_fake_loss: 0.0420, g_loss: 1.1428\n",
            "Step [75540/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0026, d_svhn_loss: 0.0208, d_fake_loss: 0.0129, g_loss: 1.1762\n",
            "Step [75550/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0032, d_svhn_loss: 0.0197, d_fake_loss: 0.0335, g_loss: 1.1212\n",
            "Step [75560/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0031, d_svhn_loss: 0.0312, d_fake_loss: 0.0417, g_loss: 1.1501\n",
            "Step [75570/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0020, d_svhn_loss: 0.0371, d_fake_loss: 0.0144, g_loss: 1.1649\n",
            "Step [75580/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0046, d_svhn_loss: 0.0131, d_fake_loss: 0.1034, g_loss: 1.1479\n",
            "Step [75590/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0082, d_svhn_loss: 0.0113, d_fake_loss: 0.0294, g_loss: 1.1536\n",
            "Step [75600/80000], d_real_loss: 0.0125, d_mnist_loss: 0.0025, d_svhn_loss: 0.0100, d_fake_loss: 0.0183, g_loss: 1.1223\n",
            "Step [75610/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0021, d_svhn_loss: 0.0312, d_fake_loss: 0.0290, g_loss: 1.1360\n",
            "Step [75620/80000], d_real_loss: 0.0174, d_mnist_loss: 0.0058, d_svhn_loss: 0.0116, d_fake_loss: 0.0275, g_loss: 1.1375\n",
            "Step [75630/80000], d_real_loss: 0.0184, d_mnist_loss: 0.0017, d_svhn_loss: 0.0167, d_fake_loss: 0.0134, g_loss: 1.1626\n",
            "Step [75640/80000], d_real_loss: 0.0142, d_mnist_loss: 0.0036, d_svhn_loss: 0.0106, d_fake_loss: 0.0112, g_loss: 1.1144\n",
            "Step [75650/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0065, d_svhn_loss: 0.0190, d_fake_loss: 0.0073, g_loss: 1.1438\n",
            "Step [75660/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0025, d_svhn_loss: 0.0271, d_fake_loss: 0.0089, g_loss: 1.1230\n",
            "Step [75670/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0132, d_svhn_loss: 0.0210, d_fake_loss: 0.0428, g_loss: 1.1906\n",
            "Step [75680/80000], d_real_loss: 0.0201, d_mnist_loss: 0.0033, d_svhn_loss: 0.0168, d_fake_loss: 0.0634, g_loss: 1.1675\n",
            "Step [75690/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0016, d_svhn_loss: 0.0166, d_fake_loss: 0.0092, g_loss: 1.1479\n",
            "Step [75700/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0031, d_svhn_loss: 0.0238, d_fake_loss: 0.0198, g_loss: 1.2002\n",
            "Step [75710/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0049, d_svhn_loss: 0.0172, d_fake_loss: 0.0132, g_loss: 1.1189\n",
            "Step [75720/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0017, d_svhn_loss: 0.0187, d_fake_loss: 0.0600, g_loss: 1.1437\n",
            "Step [75730/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0016, d_svhn_loss: 0.0175, d_fake_loss: 0.0106, g_loss: 1.1767\n",
            "Step [75740/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0015, d_svhn_loss: 0.0176, d_fake_loss: 0.0270, g_loss: 1.1662\n",
            "Step [75750/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0037, d_svhn_loss: 0.0184, d_fake_loss: 0.0211, g_loss: 1.0770\n",
            "Step [75760/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0028, d_svhn_loss: 0.0209, d_fake_loss: 0.0213, g_loss: 1.1262\n",
            "Step [75770/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0034, d_svhn_loss: 0.0517, d_fake_loss: 0.0198, g_loss: 1.1694\n",
            "Step [75780/80000], d_real_loss: 0.0133, d_mnist_loss: 0.0021, d_svhn_loss: 0.0112, d_fake_loss: 0.0135, g_loss: 1.1414\n",
            "Step [75790/80000], d_real_loss: 0.1044, d_mnist_loss: 0.0067, d_svhn_loss: 0.0977, d_fake_loss: 0.0119, g_loss: 1.1550\n",
            "Step [75800/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0020, d_svhn_loss: 0.0306, d_fake_loss: 0.0174, g_loss: 1.1381\n",
            "Step [75810/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0046, d_svhn_loss: 0.0202, d_fake_loss: 0.0224, g_loss: 1.1547\n",
            "Step [75820/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0052, d_svhn_loss: 0.0421, d_fake_loss: 0.0160, g_loss: 1.1735\n",
            "Step [75830/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0017, d_svhn_loss: 0.0662, d_fake_loss: 0.0179, g_loss: 1.2698\n",
            "Step [75840/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0044, d_svhn_loss: 0.0370, d_fake_loss: 0.0259, g_loss: 1.1086\n",
            "Step [75850/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0031, d_svhn_loss: 0.0259, d_fake_loss: 0.0281, g_loss: 1.2737\n",
            "Step [75860/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0042, d_svhn_loss: 0.0180, d_fake_loss: 0.0201, g_loss: 1.1459\n",
            "Step [75870/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0026, d_svhn_loss: 0.0311, d_fake_loss: 0.0332, g_loss: 1.2389\n",
            "Step [75880/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0031, d_svhn_loss: 0.0147, d_fake_loss: 0.0257, g_loss: 1.1217\n",
            "Step [75890/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0101, d_svhn_loss: 0.0107, d_fake_loss: 0.0169, g_loss: 1.2176\n",
            "Step [75900/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0034, d_svhn_loss: 0.0319, d_fake_loss: 0.0197, g_loss: 1.1454\n",
            "Step [75910/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0047, d_svhn_loss: 0.0235, d_fake_loss: 0.0063, g_loss: 1.2115\n",
            "Step [75920/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0032, d_svhn_loss: 0.0449, d_fake_loss: 0.0181, g_loss: 1.1518\n",
            "Step [75930/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0029, d_svhn_loss: 0.0237, d_fake_loss: 0.0181, g_loss: 1.1080\n",
            "Step [75940/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0020, d_svhn_loss: 0.0197, d_fake_loss: 0.0142, g_loss: 1.1685\n",
            "Step [75950/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0027, d_svhn_loss: 0.0277, d_fake_loss: 0.0360, g_loss: 1.1710\n",
            "Step [75960/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0095, d_svhn_loss: 0.0156, d_fake_loss: 0.0315, g_loss: 1.3536\n",
            "Step [75970/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0041, d_svhn_loss: 0.0161, d_fake_loss: 0.0110, g_loss: 1.1309\n",
            "Step [75980/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0046, d_svhn_loss: 0.0258, d_fake_loss: 0.0143, g_loss: 1.1818\n",
            "Step [75990/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0068, d_svhn_loss: 0.0518, d_fake_loss: 0.0400, g_loss: 1.1657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [76000/80000], d_real_loss: 0.0113, d_mnist_loss: 0.0020, d_svhn_loss: 0.0093, d_fake_loss: 0.0060, g_loss: 1.1018\n",
            "saved ./samples_mnist_svhn/sample-76000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-76000-s-m.png\n",
            "Step [76010/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0065, d_svhn_loss: 0.0359, d_fake_loss: 0.0230, g_loss: 1.1728\n",
            "Step [76020/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0030, d_svhn_loss: 0.0352, d_fake_loss: 0.0937, g_loss: 1.1558\n",
            "Step [76030/80000], d_real_loss: 0.0212, d_mnist_loss: 0.0018, d_svhn_loss: 0.0193, d_fake_loss: 0.0092, g_loss: 1.1902\n",
            "Step [76040/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0030, d_svhn_loss: 0.0221, d_fake_loss: 0.1102, g_loss: 1.1284\n",
            "Step [76050/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0054, d_svhn_loss: 0.0177, d_fake_loss: 0.0083, g_loss: 1.1825\n",
            "Step [76060/80000], d_real_loss: 0.0138, d_mnist_loss: 0.0027, d_svhn_loss: 0.0111, d_fake_loss: 0.0215, g_loss: 1.1468\n",
            "Step [76070/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0038, d_svhn_loss: 0.0211, d_fake_loss: 0.0327, g_loss: 1.1490\n",
            "Step [76080/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0057, d_svhn_loss: 0.0154, d_fake_loss: 0.0112, g_loss: 1.1695\n",
            "Step [76090/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0023, d_svhn_loss: 0.0242, d_fake_loss: 0.0181, g_loss: 1.1440\n",
            "Step [76100/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0032, d_svhn_loss: 0.0153, d_fake_loss: 0.0234, g_loss: 1.0666\n",
            "Step [76110/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0039, d_svhn_loss: 0.0219, d_fake_loss: 0.0107, g_loss: 1.1623\n",
            "Step [76120/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0014, d_svhn_loss: 0.0165, d_fake_loss: 0.0330, g_loss: 1.1006\n",
            "Step [76130/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0026, d_svhn_loss: 0.0286, d_fake_loss: 0.0123, g_loss: 1.0936\n",
            "Step [76140/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0054, d_svhn_loss: 0.0156, d_fake_loss: 0.0273, g_loss: 1.1392\n",
            "Step [76150/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0026, d_svhn_loss: 0.0319, d_fake_loss: 0.0116, g_loss: 1.1236\n",
            "Step [76160/80000], d_real_loss: 0.0850, d_mnist_loss: 0.0031, d_svhn_loss: 0.0819, d_fake_loss: 0.0282, g_loss: 1.3108\n",
            "Step [76170/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0053, d_svhn_loss: 0.0267, d_fake_loss: 0.0192, g_loss: 1.1271\n",
            "Step [76180/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0015, d_svhn_loss: 0.0316, d_fake_loss: 0.0215, g_loss: 1.1725\n",
            "Step [76190/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0028, d_svhn_loss: 0.0222, d_fake_loss: 0.0239, g_loss: 1.3569\n",
            "Step [76200/80000], d_real_loss: 0.0170, d_mnist_loss: 0.0024, d_svhn_loss: 0.0146, d_fake_loss: 0.0454, g_loss: 1.0314\n",
            "Step [76210/80000], d_real_loss: 0.0231, d_mnist_loss: 0.0030, d_svhn_loss: 0.0201, d_fake_loss: 0.0191, g_loss: 1.1346\n",
            "Step [76220/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0068, d_svhn_loss: 0.0161, d_fake_loss: 0.0256, g_loss: 1.2168\n",
            "Step [76230/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0024, d_svhn_loss: 0.0191, d_fake_loss: 0.0523, g_loss: 1.2536\n",
            "Step [76240/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0021, d_svhn_loss: 0.0371, d_fake_loss: 0.0172, g_loss: 1.1243\n",
            "Step [76250/80000], d_real_loss: 0.1198, d_mnist_loss: 0.0133, d_svhn_loss: 0.1065, d_fake_loss: 0.0082, g_loss: 1.1807\n",
            "Step [76260/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0042, d_svhn_loss: 0.0145, d_fake_loss: 0.0431, g_loss: 1.2285\n",
            "Step [76270/80000], d_real_loss: 0.0132, d_mnist_loss: 0.0017, d_svhn_loss: 0.0116, d_fake_loss: 0.0159, g_loss: 1.1966\n",
            "Step [76280/80000], d_real_loss: 0.0158, d_mnist_loss: 0.0055, d_svhn_loss: 0.0102, d_fake_loss: 0.0571, g_loss: 1.2000\n",
            "Step [76290/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0021, d_svhn_loss: 0.0339, d_fake_loss: 0.0132, g_loss: 1.2532\n",
            "Step [76300/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0022, d_svhn_loss: 0.0368, d_fake_loss: 0.0108, g_loss: 1.2495\n",
            "Step [76310/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0022, d_svhn_loss: 0.0265, d_fake_loss: 0.0388, g_loss: 1.2326\n",
            "Step [76320/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0014, d_svhn_loss: 0.0201, d_fake_loss: 0.0133, g_loss: 1.1991\n",
            "Step [76330/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0022, d_svhn_loss: 0.0366, d_fake_loss: 0.0747, g_loss: 1.1532\n",
            "Step [76340/80000], d_real_loss: 0.0195, d_mnist_loss: 0.0028, d_svhn_loss: 0.0166, d_fake_loss: 0.0251, g_loss: 1.2157\n",
            "Step [76350/80000], d_real_loss: 0.0170, d_mnist_loss: 0.0023, d_svhn_loss: 0.0147, d_fake_loss: 0.0224, g_loss: 1.3176\n",
            "Step [76360/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0024, d_svhn_loss: 0.0211, d_fake_loss: 0.0110, g_loss: 1.2730\n",
            "Step [76370/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0020, d_svhn_loss: 0.0429, d_fake_loss: 0.0705, g_loss: 1.1563\n",
            "Step [76380/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0128, d_svhn_loss: 0.0146, d_fake_loss: 0.0144, g_loss: 1.2838\n",
            "Step [76390/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0025, d_svhn_loss: 0.0278, d_fake_loss: 0.0246, g_loss: 1.3495\n",
            "Step [76400/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0045, d_svhn_loss: 0.0254, d_fake_loss: 0.0101, g_loss: 1.1777\n",
            "Step [76410/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0014, d_svhn_loss: 0.0325, d_fake_loss: 0.0172, g_loss: 1.3483\n",
            "Step [76420/80000], d_real_loss: 0.0245, d_mnist_loss: 0.0061, d_svhn_loss: 0.0185, d_fake_loss: 0.0594, g_loss: 1.1419\n",
            "Step [76430/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0023, d_svhn_loss: 0.0168, d_fake_loss: 0.0131, g_loss: 1.1439\n",
            "Step [76440/80000], d_real_loss: 0.0149, d_mnist_loss: 0.0019, d_svhn_loss: 0.0130, d_fake_loss: 0.0076, g_loss: 1.1911\n",
            "Step [76450/80000], d_real_loss: 0.0137, d_mnist_loss: 0.0022, d_svhn_loss: 0.0116, d_fake_loss: 0.0088, g_loss: 1.1455\n",
            "Step [76460/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0021, d_svhn_loss: 0.0324, d_fake_loss: 0.0250, g_loss: 1.1874\n",
            "Step [76470/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0025, d_svhn_loss: 0.0153, d_fake_loss: 0.0115, g_loss: 1.0743\n",
            "Step [76480/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0193, d_svhn_loss: 0.0161, d_fake_loss: 0.0110, g_loss: 1.0923\n",
            "Step [76490/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0018, d_svhn_loss: 0.0333, d_fake_loss: 0.0197, g_loss: 1.1598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [76500/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0038, d_svhn_loss: 0.0148, d_fake_loss: 0.0122, g_loss: 1.1148\n",
            "saved ./samples_mnist_svhn/sample-76500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-76500-s-m.png\n",
            "Step [76510/80000], d_real_loss: 0.0213, d_mnist_loss: 0.0018, d_svhn_loss: 0.0195, d_fake_loss: 0.0169, g_loss: 1.1347\n",
            "Step [76520/80000], d_real_loss: 0.0150, d_mnist_loss: 0.0017, d_svhn_loss: 0.0133, d_fake_loss: 0.0428, g_loss: 1.1680\n",
            "Step [76530/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0026, d_svhn_loss: 0.0259, d_fake_loss: 0.0445, g_loss: 1.1151\n",
            "Step [76540/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0022, d_svhn_loss: 0.0150, d_fake_loss: 0.0322, g_loss: 1.1850\n",
            "Step [76550/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0020, d_svhn_loss: 0.0302, d_fake_loss: 0.0147, g_loss: 1.1868\n",
            "Step [76560/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0051, d_svhn_loss: 0.0172, d_fake_loss: 0.0566, g_loss: 1.1012\n",
            "Step [76570/80000], d_real_loss: 0.0175, d_mnist_loss: 0.0015, d_svhn_loss: 0.0160, d_fake_loss: 0.0110, g_loss: 1.1790\n",
            "Step [76580/80000], d_real_loss: 0.0198, d_mnist_loss: 0.0036, d_svhn_loss: 0.0162, d_fake_loss: 0.0174, g_loss: 1.1476\n",
            "Step [76590/80000], d_real_loss: 0.0150, d_mnist_loss: 0.0012, d_svhn_loss: 0.0137, d_fake_loss: 0.1485, g_loss: 1.1890\n",
            "Step [76600/80000], d_real_loss: 0.0176, d_mnist_loss: 0.0018, d_svhn_loss: 0.0157, d_fake_loss: 0.0143, g_loss: 1.0616\n",
            "Step [76610/80000], d_real_loss: 0.1373, d_mnist_loss: 0.0075, d_svhn_loss: 0.1298, d_fake_loss: 0.0317, g_loss: 1.0887\n",
            "Step [76620/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0020, d_svhn_loss: 0.0608, d_fake_loss: 0.0534, g_loss: 1.0920\n",
            "Step [76630/80000], d_real_loss: 0.0134, d_mnist_loss: 0.0015, d_svhn_loss: 0.0119, d_fake_loss: 0.0128, g_loss: 1.1861\n",
            "Step [76640/80000], d_real_loss: 0.0275, d_mnist_loss: 0.0028, d_svhn_loss: 0.0248, d_fake_loss: 0.0137, g_loss: 1.2491\n",
            "Step [76650/80000], d_real_loss: 0.0208, d_mnist_loss: 0.0027, d_svhn_loss: 0.0181, d_fake_loss: 0.0134, g_loss: 1.1922\n",
            "Step [76660/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0076, d_svhn_loss: 0.0263, d_fake_loss: 0.0396, g_loss: 1.1975\n",
            "Step [76670/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0019, d_svhn_loss: 0.0412, d_fake_loss: 0.0279, g_loss: 1.2561\n",
            "Step [76680/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0062, d_svhn_loss: 0.0140, d_fake_loss: 0.0125, g_loss: 1.0920\n",
            "Step [76690/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0084, d_svhn_loss: 0.0328, d_fake_loss: 0.0704, g_loss: 1.0845\n",
            "Step [76700/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0024, d_svhn_loss: 0.0196, d_fake_loss: 0.0113, g_loss: 1.1690\n",
            "Step [76710/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0020, d_svhn_loss: 0.0185, d_fake_loss: 0.0225, g_loss: 1.1261\n",
            "Step [76720/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0056, d_svhn_loss: 0.0172, d_fake_loss: 0.0394, g_loss: 1.1273\n",
            "Step [76730/80000], d_real_loss: 0.0712, d_mnist_loss: 0.0021, d_svhn_loss: 0.0691, d_fake_loss: 0.0444, g_loss: 1.1180\n",
            "Step [76740/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0049, d_svhn_loss: 0.0197, d_fake_loss: 0.0080, g_loss: 1.1607\n",
            "Step [76750/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0012, d_svhn_loss: 0.0197, d_fake_loss: 0.0317, g_loss: 1.2148\n",
            "Step [76760/80000], d_real_loss: 0.0220, d_mnist_loss: 0.0084, d_svhn_loss: 0.0135, d_fake_loss: 0.0331, g_loss: 1.1851\n",
            "Step [76770/80000], d_real_loss: 0.0161, d_mnist_loss: 0.0048, d_svhn_loss: 0.0113, d_fake_loss: 0.0230, g_loss: 1.3317\n",
            "Step [76780/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0036, d_svhn_loss: 0.0250, d_fake_loss: 0.0118, g_loss: 1.1090\n",
            "Step [76790/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0076, d_svhn_loss: 0.0277, d_fake_loss: 0.0091, g_loss: 1.0690\n",
            "Step [76800/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0079, d_svhn_loss: 0.0146, d_fake_loss: 0.0174, g_loss: 1.1637\n",
            "Step [76810/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0048, d_svhn_loss: 0.0277, d_fake_loss: 0.0628, g_loss: 1.1483\n",
            "Step [76820/80000], d_real_loss: 0.0207, d_mnist_loss: 0.0072, d_svhn_loss: 0.0134, d_fake_loss: 0.1202, g_loss: 1.1976\n",
            "Step [76830/80000], d_real_loss: 0.0853, d_mnist_loss: 0.0067, d_svhn_loss: 0.0786, d_fake_loss: 0.0118, g_loss: 1.1570\n",
            "Step [76840/80000], d_real_loss: 0.0257, d_mnist_loss: 0.0037, d_svhn_loss: 0.0220, d_fake_loss: 0.0141, g_loss: 1.1056\n",
            "Step [76850/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0016, d_svhn_loss: 0.0189, d_fake_loss: 0.0086, g_loss: 1.2220\n",
            "Step [76860/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0016, d_svhn_loss: 0.0252, d_fake_loss: 0.0441, g_loss: 1.0397\n",
            "Step [76870/80000], d_real_loss: 0.0173, d_mnist_loss: 0.0035, d_svhn_loss: 0.0138, d_fake_loss: 0.0487, g_loss: 1.1848\n",
            "Step [76880/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0021, d_svhn_loss: 0.0165, d_fake_loss: 0.0129, g_loss: 1.0936\n",
            "Step [76890/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0033, d_svhn_loss: 0.0286, d_fake_loss: 0.0151, g_loss: 1.1340\n",
            "Step [76900/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0029, d_svhn_loss: 0.0197, d_fake_loss: 0.0188, g_loss: 1.1325\n",
            "Step [76910/80000], d_real_loss: 0.0178, d_mnist_loss: 0.0050, d_svhn_loss: 0.0128, d_fake_loss: 0.0418, g_loss: 1.2172\n",
            "Step [76920/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0061, d_svhn_loss: 0.0360, d_fake_loss: 0.0083, g_loss: 1.1914\n",
            "Step [76930/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0027, d_svhn_loss: 0.0610, d_fake_loss: 0.0804, g_loss: 1.1758\n",
            "Step [76940/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0018, d_svhn_loss: 0.0424, d_fake_loss: 0.0196, g_loss: 1.1746\n",
            "Step [76950/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0020, d_svhn_loss: 0.0180, d_fake_loss: 0.0110, g_loss: 1.1018\n",
            "Step [76960/80000], d_real_loss: 0.0143, d_mnist_loss: 0.0020, d_svhn_loss: 0.0123, d_fake_loss: 0.0268, g_loss: 1.1371\n",
            "Step [76970/80000], d_real_loss: 0.0242, d_mnist_loss: 0.0019, d_svhn_loss: 0.0223, d_fake_loss: 0.0279, g_loss: 1.1295\n",
            "Step [76980/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0036, d_svhn_loss: 0.0210, d_fake_loss: 0.0220, g_loss: 1.1796\n",
            "Step [76990/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0084, d_svhn_loss: 0.0168, d_fake_loss: 0.0139, g_loss: 1.2049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [77000/80000], d_real_loss: 0.0188, d_mnist_loss: 0.0013, d_svhn_loss: 0.0175, d_fake_loss: 0.0093, g_loss: 1.1625\n",
            "saved ./samples_mnist_svhn/sample-77000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-77000-s-m.png\n",
            "Step [77010/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0031, d_svhn_loss: 0.0171, d_fake_loss: 0.0201, g_loss: 1.2802\n",
            "Step [77020/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0023, d_svhn_loss: 0.0213, d_fake_loss: 0.0152, g_loss: 1.1196\n",
            "Step [77030/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0019, d_svhn_loss: 0.0664, d_fake_loss: 0.0363, g_loss: 1.1312\n",
            "Step [77040/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0043, d_svhn_loss: 0.0174, d_fake_loss: 0.0150, g_loss: 1.2096\n",
            "Step [77050/80000], d_real_loss: 0.0144, d_mnist_loss: 0.0022, d_svhn_loss: 0.0122, d_fake_loss: 0.0173, g_loss: 1.1905\n",
            "Step [77060/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0016, d_svhn_loss: 0.0344, d_fake_loss: 0.0084, g_loss: 1.1781\n",
            "Step [77070/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0019, d_svhn_loss: 0.0211, d_fake_loss: 0.0135, g_loss: 1.1469\n",
            "Step [77080/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0058, d_svhn_loss: 0.0338, d_fake_loss: 0.0228, g_loss: 1.0774\n",
            "Step [77090/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0045, d_svhn_loss: 0.0173, d_fake_loss: 0.0254, g_loss: 1.0741\n",
            "Step [77100/80000], d_real_loss: 0.0234, d_mnist_loss: 0.0081, d_svhn_loss: 0.0153, d_fake_loss: 0.0809, g_loss: 1.2478\n",
            "Step [77110/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0021, d_svhn_loss: 0.0493, d_fake_loss: 0.1219, g_loss: 1.1621\n",
            "Step [77120/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0014, d_svhn_loss: 0.0262, d_fake_loss: 0.0225, g_loss: 1.1314\n",
            "Step [77130/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0075, d_svhn_loss: 0.0195, d_fake_loss: 0.0246, g_loss: 1.1927\n",
            "Step [77140/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0085, d_svhn_loss: 0.0256, d_fake_loss: 0.0251, g_loss: 1.0562\n",
            "Step [77150/80000], d_real_loss: 0.0206, d_mnist_loss: 0.0022, d_svhn_loss: 0.0184, d_fake_loss: 0.0396, g_loss: 1.3427\n",
            "Step [77160/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0038, d_svhn_loss: 0.0732, d_fake_loss: 0.0342, g_loss: 1.1845\n",
            "Step [77170/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0017, d_svhn_loss: 0.0174, d_fake_loss: 0.0172, g_loss: 1.1157\n",
            "Step [77180/80000], d_real_loss: 0.0227, d_mnist_loss: 0.0106, d_svhn_loss: 0.0121, d_fake_loss: 0.0464, g_loss: 1.1294\n",
            "Step [77190/80000], d_real_loss: 0.0239, d_mnist_loss: 0.0021, d_svhn_loss: 0.0218, d_fake_loss: 0.0216, g_loss: 1.1159\n",
            "Step [77200/80000], d_real_loss: 0.0184, d_mnist_loss: 0.0035, d_svhn_loss: 0.0150, d_fake_loss: 0.0220, g_loss: 1.1412\n",
            "Step [77210/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0075, d_svhn_loss: 0.0174, d_fake_loss: 0.0131, g_loss: 1.1176\n",
            "Step [77220/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0188, d_svhn_loss: 0.0183, d_fake_loss: 0.0127, g_loss: 1.2646\n",
            "Step [77230/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0118, d_svhn_loss: 0.0131, d_fake_loss: 0.0132, g_loss: 1.1793\n",
            "Step [77240/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0118, d_svhn_loss: 0.0224, d_fake_loss: 0.0143, g_loss: 1.0853\n",
            "Step [77250/80000], d_real_loss: 0.0175, d_mnist_loss: 0.0027, d_svhn_loss: 0.0148, d_fake_loss: 0.0419, g_loss: 1.1619\n",
            "Step [77260/80000], d_real_loss: 0.0203, d_mnist_loss: 0.0055, d_svhn_loss: 0.0148, d_fake_loss: 0.0224, g_loss: 1.0718\n",
            "Step [77270/80000], d_real_loss: 0.0166, d_mnist_loss: 0.0027, d_svhn_loss: 0.0140, d_fake_loss: 0.0132, g_loss: 1.1575\n",
            "Step [77280/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0030, d_svhn_loss: 0.0503, d_fake_loss: 0.0213, g_loss: 1.1369\n",
            "Step [77290/80000], d_real_loss: 0.0269, d_mnist_loss: 0.0039, d_svhn_loss: 0.0231, d_fake_loss: 0.0105, g_loss: 1.1199\n",
            "Step [77300/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0026, d_svhn_loss: 0.0179, d_fake_loss: 0.0109, g_loss: 1.1442\n",
            "Step [77310/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0060, d_svhn_loss: 0.0127, d_fake_loss: 0.0070, g_loss: 1.1717\n",
            "Step [77320/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0037, d_svhn_loss: 0.0570, d_fake_loss: 0.0135, g_loss: 1.1652\n",
            "Step [77330/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0086, d_svhn_loss: 0.0300, d_fake_loss: 0.0322, g_loss: 1.2122\n",
            "Step [77340/80000], d_real_loss: 0.0203, d_mnist_loss: 0.0029, d_svhn_loss: 0.0173, d_fake_loss: 0.0089, g_loss: 1.0744\n",
            "Step [77350/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0021, d_svhn_loss: 0.0231, d_fake_loss: 0.0123, g_loss: 1.1212\n",
            "Step [77360/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0074, d_svhn_loss: 0.0160, d_fake_loss: 0.0842, g_loss: 1.1204\n",
            "Step [77370/80000], d_real_loss: 0.0712, d_mnist_loss: 0.0138, d_svhn_loss: 0.0574, d_fake_loss: 0.0237, g_loss: 1.1238\n",
            "Step [77380/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0045, d_svhn_loss: 0.0746, d_fake_loss: 0.0120, g_loss: 1.0880\n",
            "Step [77390/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0125, d_svhn_loss: 0.0205, d_fake_loss: 0.0119, g_loss: 1.0720\n",
            "Step [77400/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0145, d_svhn_loss: 0.0361, d_fake_loss: 0.0133, g_loss: 1.1518\n",
            "Step [77410/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0042, d_svhn_loss: 0.0230, d_fake_loss: 0.0075, g_loss: 1.0871\n",
            "Step [77420/80000], d_real_loss: 0.0154, d_mnist_loss: 0.0026, d_svhn_loss: 0.0128, d_fake_loss: 0.0123, g_loss: 1.1331\n",
            "Step [77430/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0023, d_svhn_loss: 0.0745, d_fake_loss: 0.0686, g_loss: 1.1231\n",
            "Step [77440/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0068, d_svhn_loss: 0.0137, d_fake_loss: 0.0193, g_loss: 1.1566\n",
            "Step [77450/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0032, d_svhn_loss: 0.0450, d_fake_loss: 0.0463, g_loss: 1.1613\n",
            "Step [77460/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0107, d_svhn_loss: 0.0503, d_fake_loss: 0.0151, g_loss: 1.1809\n",
            "Step [77470/80000], d_real_loss: 0.0157, d_mnist_loss: 0.0027, d_svhn_loss: 0.0130, d_fake_loss: 0.0323, g_loss: 1.2855\n",
            "Step [77480/80000], d_real_loss: 0.1071, d_mnist_loss: 0.0031, d_svhn_loss: 0.1039, d_fake_loss: 0.0214, g_loss: 1.0774\n",
            "Step [77490/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0053, d_svhn_loss: 0.0213, d_fake_loss: 0.0247, g_loss: 1.1342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [77500/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0057, d_svhn_loss: 0.0209, d_fake_loss: 0.0150, g_loss: 1.0877\n",
            "saved ./samples_mnist_svhn/sample-77500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-77500-s-m.png\n",
            "Step [77510/80000], d_real_loss: 0.0168, d_mnist_loss: 0.0021, d_svhn_loss: 0.0147, d_fake_loss: 0.0129, g_loss: 1.0981\n",
            "Step [77520/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0020, d_svhn_loss: 0.0181, d_fake_loss: 0.0325, g_loss: 1.1521\n",
            "Step [77530/80000], d_real_loss: 0.0263, d_mnist_loss: 0.0065, d_svhn_loss: 0.0198, d_fake_loss: 0.0112, g_loss: 1.1964\n",
            "Step [77540/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0089, d_svhn_loss: 0.0574, d_fake_loss: 0.0174, g_loss: 1.2207\n",
            "Step [77550/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0022, d_svhn_loss: 0.0161, d_fake_loss: 0.0090, g_loss: 1.1678\n",
            "Step [77560/80000], d_real_loss: 0.0237, d_mnist_loss: 0.0014, d_svhn_loss: 0.0223, d_fake_loss: 0.0090, g_loss: 1.1421\n",
            "Step [77570/80000], d_real_loss: 0.0144, d_mnist_loss: 0.0019, d_svhn_loss: 0.0125, d_fake_loss: 0.0203, g_loss: 1.0862\n",
            "Step [77580/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0013, d_svhn_loss: 0.0168, d_fake_loss: 0.0286, g_loss: 1.0555\n",
            "Step [77590/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0068, d_svhn_loss: 0.0292, d_fake_loss: 0.0181, g_loss: 1.1133\n",
            "Step [77600/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0023, d_svhn_loss: 0.0484, d_fake_loss: 0.0222, g_loss: 1.1400\n",
            "Step [77610/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0129, d_svhn_loss: 0.0222, d_fake_loss: 0.0122, g_loss: 1.1633\n",
            "Step [77620/80000], d_real_loss: 0.0153, d_mnist_loss: 0.0041, d_svhn_loss: 0.0112, d_fake_loss: 0.0073, g_loss: 1.1875\n",
            "Step [77630/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0036, d_svhn_loss: 0.0384, d_fake_loss: 0.0316, g_loss: 1.1678\n",
            "Step [77640/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0075, d_svhn_loss: 0.0247, d_fake_loss: 0.0121, g_loss: 1.1207\n",
            "Step [77650/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0047, d_svhn_loss: 0.0275, d_fake_loss: 0.0187, g_loss: 1.1650\n",
            "Step [77660/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0018, d_svhn_loss: 0.0173, d_fake_loss: 0.0149, g_loss: 1.1925\n",
            "Step [77670/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0061, d_svhn_loss: 0.0314, d_fake_loss: 0.0227, g_loss: 1.1706\n",
            "Step [77680/80000], d_real_loss: 0.0194, d_mnist_loss: 0.0014, d_svhn_loss: 0.0179, d_fake_loss: 0.0092, g_loss: 1.0988\n",
            "Step [77690/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0069, d_svhn_loss: 0.0452, d_fake_loss: 0.0822, g_loss: 1.1285\n",
            "Step [77700/80000], d_real_loss: 0.0259, d_mnist_loss: 0.0051, d_svhn_loss: 0.0208, d_fake_loss: 0.0076, g_loss: 1.1552\n",
            "Step [77710/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0047, d_svhn_loss: 0.0352, d_fake_loss: 0.0458, g_loss: 1.1478\n",
            "Step [77720/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0047, d_svhn_loss: 0.0138, d_fake_loss: 0.0137, g_loss: 1.1538\n",
            "Step [77730/80000], d_real_loss: 0.0155, d_mnist_loss: 0.0022, d_svhn_loss: 0.0133, d_fake_loss: 0.0097, g_loss: 1.1793\n",
            "Step [77740/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0061, d_svhn_loss: 0.0131, d_fake_loss: 0.1115, g_loss: 1.0629\n",
            "Step [77750/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0101, d_svhn_loss: 0.0270, d_fake_loss: 0.1016, g_loss: 1.0905\n",
            "Step [77760/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0094, d_svhn_loss: 0.0179, d_fake_loss: 0.0241, g_loss: 1.1814\n",
            "Step [77770/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0022, d_svhn_loss: 0.0498, d_fake_loss: 0.0811, g_loss: 1.1110\n",
            "Step [77780/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0016, d_svhn_loss: 0.0443, d_fake_loss: 0.0260, g_loss: 1.1382\n",
            "Step [77790/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0019, d_svhn_loss: 0.0249, d_fake_loss: 0.0123, g_loss: 1.1606\n",
            "Step [77800/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0046, d_svhn_loss: 0.0204, d_fake_loss: 0.0139, g_loss: 1.1354\n",
            "Step [77810/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0024, d_svhn_loss: 0.0592, d_fake_loss: 0.0716, g_loss: 1.1756\n",
            "Step [77820/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0043, d_svhn_loss: 0.0183, d_fake_loss: 0.0427, g_loss: 1.2040\n",
            "Step [77830/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0068, d_svhn_loss: 0.0372, d_fake_loss: 0.0477, g_loss: 1.0897\n",
            "Step [77840/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0057, d_svhn_loss: 0.0420, d_fake_loss: 0.0144, g_loss: 1.1105\n",
            "Step [77850/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0055, d_svhn_loss: 0.0733, d_fake_loss: 0.0221, g_loss: 1.1471\n",
            "Step [77860/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0022, d_svhn_loss: 0.0161, d_fake_loss: 0.0194, g_loss: 1.2827\n",
            "Step [77870/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0021, d_svhn_loss: 0.0266, d_fake_loss: 0.0193, g_loss: 1.1427\n",
            "Step [77880/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0200, d_svhn_loss: 0.0237, d_fake_loss: 0.0585, g_loss: 1.3092\n",
            "Step [77890/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0035, d_svhn_loss: 0.0183, d_fake_loss: 0.0245, g_loss: 1.2029\n",
            "Step [77900/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0021, d_svhn_loss: 0.0232, d_fake_loss: 0.0116, g_loss: 1.1246\n",
            "Step [77910/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0074, d_svhn_loss: 0.0415, d_fake_loss: 0.0218, g_loss: 1.2047\n",
            "Step [77920/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0026, d_svhn_loss: 0.0448, d_fake_loss: 0.0321, g_loss: 1.1383\n",
            "Step [77930/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0264, d_svhn_loss: 0.0498, d_fake_loss: 0.0222, g_loss: 1.0501\n",
            "Step [77940/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0172, d_svhn_loss: 0.0275, d_fake_loss: 0.0142, g_loss: 1.1205\n",
            "Step [77950/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0064, d_svhn_loss: 0.0247, d_fake_loss: 0.0226, g_loss: 1.3156\n",
            "Step [77960/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0078, d_svhn_loss: 0.0170, d_fake_loss: 0.0243, g_loss: 1.1424\n",
            "Step [77970/80000], d_real_loss: 0.0273, d_mnist_loss: 0.0017, d_svhn_loss: 0.0256, d_fake_loss: 0.0165, g_loss: 1.1630\n",
            "Step [77980/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0055, d_svhn_loss: 0.0230, d_fake_loss: 0.0245, g_loss: 1.1094\n",
            "Step [77990/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0056, d_svhn_loss: 0.0184, d_fake_loss: 0.0252, g_loss: 1.2887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [78000/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0017, d_svhn_loss: 0.0538, d_fake_loss: 0.0204, g_loss: 1.1198\n",
            "saved ./samples_mnist_svhn/sample-78000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-78000-s-m.png\n",
            "Step [78010/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0036, d_svhn_loss: 0.0208, d_fake_loss: 0.0634, g_loss: 1.3036\n",
            "Step [78020/80000], d_real_loss: 0.0168, d_mnist_loss: 0.0050, d_svhn_loss: 0.0118, d_fake_loss: 0.0087, g_loss: 1.1070\n",
            "Step [78030/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0041, d_svhn_loss: 0.0672, d_fake_loss: 0.0265, g_loss: 1.1793\n",
            "Step [78040/80000], d_real_loss: 0.0211, d_mnist_loss: 0.0060, d_svhn_loss: 0.0151, d_fake_loss: 0.0334, g_loss: 1.1418\n",
            "Step [78050/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0031, d_svhn_loss: 0.0467, d_fake_loss: 0.0727, g_loss: 1.1482\n",
            "Step [78060/80000], d_real_loss: 0.0133, d_mnist_loss: 0.0014, d_svhn_loss: 0.0118, d_fake_loss: 0.1081, g_loss: 1.2212\n",
            "Step [78070/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0129, d_svhn_loss: 0.0489, d_fake_loss: 0.0237, g_loss: 1.1444\n",
            "Step [78080/80000], d_real_loss: 0.0200, d_mnist_loss: 0.0024, d_svhn_loss: 0.0176, d_fake_loss: 0.0463, g_loss: 1.1987\n",
            "Step [78090/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0034, d_svhn_loss: 0.0170, d_fake_loss: 0.0279, g_loss: 1.1805\n",
            "Step [78100/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0056, d_svhn_loss: 0.0333, d_fake_loss: 0.0110, g_loss: 1.1616\n",
            "Step [78110/80000], d_real_loss: 0.0205, d_mnist_loss: 0.0064, d_svhn_loss: 0.0141, d_fake_loss: 0.1122, g_loss: 1.1259\n",
            "Step [78120/80000], d_real_loss: 0.0126, d_mnist_loss: 0.0018, d_svhn_loss: 0.0108, d_fake_loss: 0.0445, g_loss: 1.1693\n",
            "Step [78130/80000], d_real_loss: 0.0210, d_mnist_loss: 0.0024, d_svhn_loss: 0.0186, d_fake_loss: 0.0217, g_loss: 1.1254\n",
            "Step [78140/80000], d_real_loss: 0.1212, d_mnist_loss: 0.0030, d_svhn_loss: 0.1183, d_fake_loss: 0.0893, g_loss: 1.2904\n",
            "Step [78150/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0023, d_svhn_loss: 0.0168, d_fake_loss: 0.0368, g_loss: 1.2066\n",
            "Step [78160/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0057, d_svhn_loss: 0.0428, d_fake_loss: 0.0238, g_loss: 1.1053\n",
            "Step [78170/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0022, d_svhn_loss: 0.0174, d_fake_loss: 0.0242, g_loss: 1.1558\n",
            "Step [78180/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0017, d_svhn_loss: 0.0322, d_fake_loss: 0.0204, g_loss: 1.1110\n",
            "Step [78190/80000], d_real_loss: 0.0146, d_mnist_loss: 0.0021, d_svhn_loss: 0.0125, d_fake_loss: 0.0242, g_loss: 1.1053\n",
            "Step [78200/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0024, d_svhn_loss: 0.0238, d_fake_loss: 0.0502, g_loss: 1.0998\n",
            "Step [78210/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0031, d_svhn_loss: 0.0604, d_fake_loss: 0.0672, g_loss: 1.1445\n",
            "Step [78220/80000], d_real_loss: 0.0191, d_mnist_loss: 0.0049, d_svhn_loss: 0.0142, d_fake_loss: 0.0156, g_loss: 1.1208\n",
            "Step [78230/80000], d_real_loss: 0.0644, d_mnist_loss: 0.0449, d_svhn_loss: 0.0196, d_fake_loss: 0.0650, g_loss: 1.1876\n",
            "Step [78240/80000], d_real_loss: 0.0187, d_mnist_loss: 0.0040, d_svhn_loss: 0.0147, d_fake_loss: 0.0197, g_loss: 1.0512\n",
            "Step [78250/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0065, d_svhn_loss: 0.0369, d_fake_loss: 0.0085, g_loss: 1.0489\n",
            "Step [78260/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0013, d_svhn_loss: 0.0556, d_fake_loss: 0.0112, g_loss: 1.0882\n",
            "Step [78270/80000], d_real_loss: 0.0183, d_mnist_loss: 0.0030, d_svhn_loss: 0.0154, d_fake_loss: 0.0103, g_loss: 1.0990\n",
            "Step [78280/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0024, d_svhn_loss: 0.0162, d_fake_loss: 0.0130, g_loss: 1.0814\n",
            "Step [78290/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0074, d_svhn_loss: 0.0422, d_fake_loss: 0.0223, g_loss: 1.1525\n",
            "Step [78300/80000], d_real_loss: 0.0225, d_mnist_loss: 0.0043, d_svhn_loss: 0.0182, d_fake_loss: 0.0075, g_loss: 1.1301\n",
            "Step [78310/80000], d_real_loss: 0.0163, d_mnist_loss: 0.0042, d_svhn_loss: 0.0120, d_fake_loss: 0.0171, g_loss: 1.1171\n",
            "Step [78320/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0055, d_svhn_loss: 0.0285, d_fake_loss: 0.0764, g_loss: 1.0702\n",
            "Step [78330/80000], d_real_loss: 0.0278, d_mnist_loss: 0.0016, d_svhn_loss: 0.0262, d_fake_loss: 0.0136, g_loss: 1.1073\n",
            "Step [78340/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0022, d_svhn_loss: 0.0235, d_fake_loss: 0.0247, g_loss: 1.1083\n",
            "Step [78350/80000], d_real_loss: 0.0203, d_mnist_loss: 0.0022, d_svhn_loss: 0.0181, d_fake_loss: 0.0492, g_loss: 1.1040\n",
            "Step [78360/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0009, d_svhn_loss: 0.0257, d_fake_loss: 0.0109, g_loss: 1.1179\n",
            "Step [78370/80000], d_real_loss: 0.0134, d_mnist_loss: 0.0008, d_svhn_loss: 0.0126, d_fake_loss: 0.0198, g_loss: 1.1041\n",
            "Step [78380/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0057, d_svhn_loss: 0.0222, d_fake_loss: 0.0496, g_loss: 1.1695\n",
            "Step [78390/80000], d_real_loss: 0.0152, d_mnist_loss: 0.0014, d_svhn_loss: 0.0138, d_fake_loss: 0.0145, g_loss: 1.1613\n",
            "Step [78400/80000], d_real_loss: 0.0249, d_mnist_loss: 0.0030, d_svhn_loss: 0.0220, d_fake_loss: 0.0109, g_loss: 1.0997\n",
            "Step [78410/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0041, d_svhn_loss: 0.0264, d_fake_loss: 0.0441, g_loss: 1.0999\n",
            "Step [78420/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0012, d_svhn_loss: 0.0307, d_fake_loss: 0.0283, g_loss: 1.1164\n",
            "Step [78430/80000], d_real_loss: 0.0109, d_mnist_loss: 0.0012, d_svhn_loss: 0.0097, d_fake_loss: 0.0128, g_loss: 1.2128\n",
            "Step [78440/80000], d_real_loss: 0.0141, d_mnist_loss: 0.0016, d_svhn_loss: 0.0125, d_fake_loss: 0.0535, g_loss: 1.1224\n",
            "Step [78450/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0031, d_svhn_loss: 0.0233, d_fake_loss: 0.0124, g_loss: 1.1229\n",
            "Step [78460/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0017, d_svhn_loss: 0.0244, d_fake_loss: 0.0569, g_loss: 1.0970\n",
            "Step [78470/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0020, d_svhn_loss: 0.0533, d_fake_loss: 0.0581, g_loss: 1.1132\n",
            "Step [78480/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0025, d_svhn_loss: 0.0306, d_fake_loss: 0.0287, g_loss: 1.0866\n",
            "Step [78490/80000], d_real_loss: 0.0223, d_mnist_loss: 0.0040, d_svhn_loss: 0.0182, d_fake_loss: 0.0157, g_loss: 1.1605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [78500/80000], d_real_loss: 0.0193, d_mnist_loss: 0.0027, d_svhn_loss: 0.0165, d_fake_loss: 0.0131, g_loss: 1.2102\n",
            "saved ./samples_mnist_svhn/sample-78500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-78500-s-m.png\n",
            "Step [78510/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0012, d_svhn_loss: 0.0534, d_fake_loss: 0.0094, g_loss: 1.1834\n",
            "Step [78520/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0113, d_svhn_loss: 0.0390, d_fake_loss: 0.0101, g_loss: 1.2654\n",
            "Step [78530/80000], d_real_loss: 0.0857, d_mnist_loss: 0.0153, d_svhn_loss: 0.0704, d_fake_loss: 0.0352, g_loss: 1.2244\n",
            "Step [78540/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0025, d_svhn_loss: 0.0237, d_fake_loss: 0.0143, g_loss: 1.1254\n",
            "Step [78550/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0014, d_svhn_loss: 0.0239, d_fake_loss: 0.0543, g_loss: 1.1623\n",
            "Step [78560/80000], d_real_loss: 0.0142, d_mnist_loss: 0.0018, d_svhn_loss: 0.0124, d_fake_loss: 0.0182, g_loss: 1.1383\n",
            "Step [78570/80000], d_real_loss: 0.0153, d_mnist_loss: 0.0015, d_svhn_loss: 0.0138, d_fake_loss: 0.0557, g_loss: 1.2132\n",
            "Step [78580/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0065, d_svhn_loss: 0.0196, d_fake_loss: 0.0317, g_loss: 1.2022\n",
            "Step [78590/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0086, d_svhn_loss: 0.0176, d_fake_loss: 0.1609, g_loss: 1.1265\n",
            "Step [78600/80000], d_real_loss: 0.0144, d_mnist_loss: 0.0030, d_svhn_loss: 0.0114, d_fake_loss: 0.0520, g_loss: 1.2328\n",
            "Step [78610/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0039, d_svhn_loss: 0.0247, d_fake_loss: 0.0196, g_loss: 1.1579\n",
            "Step [78620/80000], d_real_loss: 0.0217, d_mnist_loss: 0.0053, d_svhn_loss: 0.0164, d_fake_loss: 0.0152, g_loss: 1.1277\n",
            "Step [78630/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0073, d_svhn_loss: 0.0323, d_fake_loss: 0.0171, g_loss: 1.1443\n",
            "Step [78640/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0024, d_svhn_loss: 0.0223, d_fake_loss: 0.0600, g_loss: 1.2202\n",
            "Step [78650/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0117, d_svhn_loss: 0.0397, d_fake_loss: 0.0182, g_loss: 1.1301\n",
            "Step [78660/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0021, d_svhn_loss: 0.0731, d_fake_loss: 0.0459, g_loss: 1.1666\n",
            "Step [78670/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0037, d_svhn_loss: 0.0233, d_fake_loss: 0.0279, g_loss: 1.2106\n",
            "Step [78680/80000], d_real_loss: 0.0157, d_mnist_loss: 0.0024, d_svhn_loss: 0.0133, d_fake_loss: 0.0176, g_loss: 1.1825\n",
            "Step [78690/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0054, d_svhn_loss: 0.0313, d_fake_loss: 0.0279, g_loss: 1.1626\n",
            "Step [78700/80000], d_real_loss: 0.0209, d_mnist_loss: 0.0039, d_svhn_loss: 0.0170, d_fake_loss: 0.0208, g_loss: 1.0963\n",
            "Step [78710/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0036, d_svhn_loss: 0.0398, d_fake_loss: 0.0085, g_loss: 1.1676\n",
            "Step [78720/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0133, d_svhn_loss: 0.0343, d_fake_loss: 0.0105, g_loss: 1.1986\n",
            "Step [78730/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0023, d_svhn_loss: 0.0271, d_fake_loss: 0.0122, g_loss: 1.2129\n",
            "Step [78740/80000], d_real_loss: 0.0132, d_mnist_loss: 0.0031, d_svhn_loss: 0.0102, d_fake_loss: 0.0297, g_loss: 1.1608\n",
            "Step [78750/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0249, d_svhn_loss: 0.0222, d_fake_loss: 0.0091, g_loss: 1.1794\n",
            "Step [78760/80000], d_real_loss: 0.0250, d_mnist_loss: 0.0043, d_svhn_loss: 0.0208, d_fake_loss: 0.0538, g_loss: 1.0865\n",
            "Step [78770/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0030, d_svhn_loss: 0.0187, d_fake_loss: 0.0279, g_loss: 1.0754\n",
            "Step [78780/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0028, d_svhn_loss: 0.0261, d_fake_loss: 0.0160, g_loss: 1.1344\n",
            "Step [78790/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0029, d_svhn_loss: 0.0308, d_fake_loss: 0.0084, g_loss: 1.1392\n",
            "Step [78800/80000], d_real_loss: 0.0162, d_mnist_loss: 0.0024, d_svhn_loss: 0.0138, d_fake_loss: 0.1147, g_loss: 1.0991\n",
            "Step [78810/80000], d_real_loss: 0.0144, d_mnist_loss: 0.0019, d_svhn_loss: 0.0124, d_fake_loss: 0.0446, g_loss: 1.1001\n",
            "Step [78820/80000], d_real_loss: 0.0157, d_mnist_loss: 0.0016, d_svhn_loss: 0.0141, d_fake_loss: 0.0229, g_loss: 1.1055\n",
            "Step [78830/80000], d_real_loss: 0.0224, d_mnist_loss: 0.0025, d_svhn_loss: 0.0199, d_fake_loss: 0.0127, g_loss: 1.1453\n",
            "Step [78840/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0091, d_svhn_loss: 0.0532, d_fake_loss: 0.0295, g_loss: 1.1585\n",
            "Step [78850/80000], d_real_loss: 0.0186, d_mnist_loss: 0.0056, d_svhn_loss: 0.0130, d_fake_loss: 0.0274, g_loss: 1.1109\n",
            "Step [78860/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0039, d_svhn_loss: 0.0222, d_fake_loss: 0.0272, g_loss: 1.1344\n",
            "Step [78870/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0026, d_svhn_loss: 0.0164, d_fake_loss: 0.0393, g_loss: 1.1411\n",
            "Step [78880/80000], d_real_loss: 0.0204, d_mnist_loss: 0.0043, d_svhn_loss: 0.0161, d_fake_loss: 0.0162, g_loss: 1.0982\n",
            "Step [78890/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0039, d_svhn_loss: 0.0199, d_fake_loss: 0.0085, g_loss: 1.1360\n",
            "Step [78900/80000], d_real_loss: 0.0216, d_mnist_loss: 0.0026, d_svhn_loss: 0.0189, d_fake_loss: 0.0277, g_loss: 1.1130\n",
            "Step [78910/80000], d_real_loss: 0.0185, d_mnist_loss: 0.0053, d_svhn_loss: 0.0132, d_fake_loss: 0.0139, g_loss: 1.1354\n",
            "Step [78920/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0023, d_svhn_loss: 0.0322, d_fake_loss: 0.0074, g_loss: 1.1338\n",
            "Step [78930/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0020, d_svhn_loss: 0.0273, d_fake_loss: 0.0133, g_loss: 1.0833\n",
            "Step [78940/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0087, d_svhn_loss: 0.0191, d_fake_loss: 0.0297, g_loss: 1.0798\n",
            "Step [78950/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0056, d_svhn_loss: 0.0380, d_fake_loss: 0.0082, g_loss: 1.2362\n",
            "Step [78960/80000], d_real_loss: 0.0230, d_mnist_loss: 0.0079, d_svhn_loss: 0.0151, d_fake_loss: 0.0418, g_loss: 1.0929\n",
            "Step [78970/80000], d_real_loss: 0.0137, d_mnist_loss: 0.0020, d_svhn_loss: 0.0117, d_fake_loss: 0.2455, g_loss: 1.0384\n",
            "Step [78980/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0025, d_svhn_loss: 0.0575, d_fake_loss: 0.0380, g_loss: 1.0383\n",
            "Step [78990/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0023, d_svhn_loss: 0.0446, d_fake_loss: 0.0135, g_loss: 1.1056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [79000/80000], d_real_loss: 0.0177, d_mnist_loss: 0.0031, d_svhn_loss: 0.0146, d_fake_loss: 0.0153, g_loss: 1.0969\n",
            "saved ./samples_mnist_svhn/sample-79000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-79000-s-m.png\n",
            "Step [79010/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0027, d_svhn_loss: 0.0188, d_fake_loss: 0.0510, g_loss: 1.1550\n",
            "Step [79020/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0047, d_svhn_loss: 0.0167, d_fake_loss: 0.0166, g_loss: 1.1483\n",
            "Step [79030/80000], d_real_loss: 0.0087, d_mnist_loss: 0.0014, d_svhn_loss: 0.0073, d_fake_loss: 0.0094, g_loss: 1.1141\n",
            "Step [79040/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0020, d_svhn_loss: 0.0161, d_fake_loss: 0.0212, g_loss: 1.0916\n",
            "Step [79050/80000], d_real_loss: 0.0221, d_mnist_loss: 0.0021, d_svhn_loss: 0.0200, d_fake_loss: 0.0100, g_loss: 1.1319\n",
            "Step [79060/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0042, d_svhn_loss: 0.0155, d_fake_loss: 0.0534, g_loss: 1.0887\n",
            "Step [79070/80000], d_real_loss: 0.0192, d_mnist_loss: 0.0032, d_svhn_loss: 0.0160, d_fake_loss: 0.0206, g_loss: 1.1306\n",
            "Step [79080/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0046, d_svhn_loss: 0.0305, d_fake_loss: 0.0098, g_loss: 1.1595\n",
            "Step [79090/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0030, d_svhn_loss: 0.0284, d_fake_loss: 0.0259, g_loss: 1.1068\n",
            "Step [79100/80000], d_real_loss: 0.0162, d_mnist_loss: 0.0017, d_svhn_loss: 0.0144, d_fake_loss: 0.0106, g_loss: 1.1120\n",
            "Step [79110/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0120, d_svhn_loss: 0.0441, d_fake_loss: 0.0603, g_loss: 1.0884\n",
            "Step [79120/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0017, d_svhn_loss: 0.0245, d_fake_loss: 0.0136, g_loss: 1.1211\n",
            "Step [79130/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0040, d_svhn_loss: 0.0404, d_fake_loss: 0.0089, g_loss: 1.1124\n",
            "Step [79140/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0064, d_svhn_loss: 0.0277, d_fake_loss: 0.0163, g_loss: 1.0509\n",
            "Step [79150/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0056, d_svhn_loss: 0.0172, d_fake_loss: 0.0121, g_loss: 1.0843\n",
            "Step [79160/80000], d_real_loss: 0.0228, d_mnist_loss: 0.0028, d_svhn_loss: 0.0200, d_fake_loss: 0.0184, g_loss: 1.1282\n",
            "Step [79170/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0046, d_svhn_loss: 0.0322, d_fake_loss: 0.0282, g_loss: 1.1522\n",
            "Step [79180/80000], d_real_loss: 0.0182, d_mnist_loss: 0.0064, d_svhn_loss: 0.0119, d_fake_loss: 0.0618, g_loss: 1.0955\n",
            "Step [79190/80000], d_real_loss: 0.0252, d_mnist_loss: 0.0023, d_svhn_loss: 0.0229, d_fake_loss: 0.0094, g_loss: 1.1165\n",
            "Step [79200/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0087, d_svhn_loss: 0.0168, d_fake_loss: 0.0480, g_loss: 1.1467\n",
            "Step [79210/80000], d_real_loss: 0.0908, d_mnist_loss: 0.0023, d_svhn_loss: 0.0885, d_fake_loss: 0.0190, g_loss: 1.0890\n",
            "Step [79220/80000], d_real_loss: 0.0172, d_mnist_loss: 0.0035, d_svhn_loss: 0.0137, d_fake_loss: 0.0415, g_loss: 1.1114\n",
            "Step [79230/80000], d_real_loss: 0.0927, d_mnist_loss: 0.0025, d_svhn_loss: 0.0902, d_fake_loss: 0.0422, g_loss: 1.1337\n",
            "Step [79240/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0017, d_svhn_loss: 0.0267, d_fake_loss: 0.0130, g_loss: 1.0852\n",
            "Step [79250/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0010, d_svhn_loss: 0.0304, d_fake_loss: 0.0141, g_loss: 1.1077\n",
            "Step [79260/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0027, d_svhn_loss: 0.0191, d_fake_loss: 0.0091, g_loss: 1.1635\n",
            "Step [79270/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0025, d_svhn_loss: 0.0225, d_fake_loss: 0.0577, g_loss: 1.0893\n",
            "Step [79280/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0023, d_svhn_loss: 0.0366, d_fake_loss: 0.0163, g_loss: 1.1141\n",
            "Step [79290/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0021, d_svhn_loss: 0.0193, d_fake_loss: 0.0132, g_loss: 1.1507\n",
            "Step [79300/80000], d_real_loss: 0.0190, d_mnist_loss: 0.0018, d_svhn_loss: 0.0172, d_fake_loss: 0.0092, g_loss: 1.1979\n",
            "Step [79310/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0044, d_svhn_loss: 0.0289, d_fake_loss: 0.0187, g_loss: 1.0888\n",
            "Step [79320/80000], d_real_loss: 0.0229, d_mnist_loss: 0.0014, d_svhn_loss: 0.0215, d_fake_loss: 0.0155, g_loss: 1.1338\n",
            "Step [79330/80000], d_real_loss: 0.0159, d_mnist_loss: 0.0022, d_svhn_loss: 0.0137, d_fake_loss: 0.0116, g_loss: 1.1782\n",
            "Step [79340/80000], d_real_loss: 0.0184, d_mnist_loss: 0.0014, d_svhn_loss: 0.0170, d_fake_loss: 0.0402, g_loss: 1.1285\n",
            "Step [79350/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0051, d_svhn_loss: 0.0611, d_fake_loss: 0.0206, g_loss: 1.0826\n",
            "Step [79360/80000], d_real_loss: 0.0168, d_mnist_loss: 0.0015, d_svhn_loss: 0.0153, d_fake_loss: 0.0111, g_loss: 1.1284\n",
            "Step [79370/80000], d_real_loss: 0.0199, d_mnist_loss: 0.0010, d_svhn_loss: 0.0188, d_fake_loss: 0.0084, g_loss: 1.1720\n",
            "Step [79380/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0078, d_svhn_loss: 0.0318, d_fake_loss: 0.0106, g_loss: 1.1984\n",
            "Step [79390/80000], d_real_loss: 0.0147, d_mnist_loss: 0.0034, d_svhn_loss: 0.0113, d_fake_loss: 0.0444, g_loss: 1.0616\n",
            "Step [79400/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0271, d_svhn_loss: 0.0116, d_fake_loss: 0.0274, g_loss: 1.1090\n",
            "Step [79410/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0052, d_svhn_loss: 0.0247, d_fake_loss: 0.0081, g_loss: 1.1323\n",
            "Step [79420/80000], d_real_loss: 0.0248, d_mnist_loss: 0.0014, d_svhn_loss: 0.0234, d_fake_loss: 0.0153, g_loss: 1.1284\n",
            "Step [79430/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0020, d_svhn_loss: 0.0236, d_fake_loss: 0.0100, g_loss: 1.1884\n",
            "Step [79440/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0053, d_svhn_loss: 0.0214, d_fake_loss: 0.0200, g_loss: 1.1071\n",
            "Step [79450/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0016, d_svhn_loss: 0.0343, d_fake_loss: 0.0136, g_loss: 1.0962\n",
            "Step [79460/80000], d_real_loss: 0.0196, d_mnist_loss: 0.0020, d_svhn_loss: 0.0176, d_fake_loss: 0.0537, g_loss: 1.0867\n",
            "Step [79470/80000], d_real_loss: 0.0236, d_mnist_loss: 0.0022, d_svhn_loss: 0.0215, d_fake_loss: 0.0100, g_loss: 1.1177\n",
            "Step [79480/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0063, d_svhn_loss: 0.0211, d_fake_loss: 0.0205, g_loss: 1.0697\n",
            "Step [79490/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0070, d_svhn_loss: 0.0352, d_fake_loss: 0.0612, g_loss: 1.1290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [79500/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0045, d_svhn_loss: 0.0302, d_fake_loss: 0.0293, g_loss: 1.1430\n",
            "saved ./samples_mnist_svhn/sample-79500-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-79500-s-m.png\n",
            "Step [79510/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0061, d_svhn_loss: 0.0199, d_fake_loss: 0.0138, g_loss: 1.0786\n",
            "Step [79520/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0046, d_svhn_loss: 0.0283, d_fake_loss: 0.0095, g_loss: 1.1069\n",
            "Step [79530/80000], d_real_loss: 0.0218, d_mnist_loss: 0.0018, d_svhn_loss: 0.0200, d_fake_loss: 0.0377, g_loss: 1.1388\n",
            "Step [79540/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0019, d_svhn_loss: 0.0247, d_fake_loss: 0.0349, g_loss: 1.1416\n",
            "Step [79550/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0008, d_svhn_loss: 0.0298, d_fake_loss: 0.0376, g_loss: 1.1202\n",
            "Step [79560/80000], d_real_loss: 0.1031, d_mnist_loss: 0.0023, d_svhn_loss: 0.1008, d_fake_loss: 0.0343, g_loss: 1.1581\n",
            "Step [79570/80000], d_real_loss: 0.0262, d_mnist_loss: 0.0049, d_svhn_loss: 0.0214, d_fake_loss: 0.0592, g_loss: 1.1789\n",
            "Step [79580/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0012, d_svhn_loss: 0.0334, d_fake_loss: 0.0255, g_loss: 1.1474\n",
            "Step [79590/80000], d_real_loss: 0.0232, d_mnist_loss: 0.0047, d_svhn_loss: 0.0184, d_fake_loss: 0.0095, g_loss: 1.1504\n",
            "Step [79600/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0093, d_svhn_loss: 0.0222, d_fake_loss: 0.0083, g_loss: 1.0933\n",
            "Step [79610/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0041, d_svhn_loss: 0.0302, d_fake_loss: 0.0119, g_loss: 1.0946\n",
            "Step [79620/80000], d_real_loss: 0.0167, d_mnist_loss: 0.0013, d_svhn_loss: 0.0154, d_fake_loss: 0.0573, g_loss: 1.1127\n",
            "Step [79630/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0024, d_svhn_loss: 0.0299, d_fake_loss: 0.0179, g_loss: 1.0971\n",
            "Step [79640/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0019, d_svhn_loss: 0.0312, d_fake_loss: 0.0178, g_loss: 1.0961\n",
            "Step [79650/80000], d_real_loss: 0.0095, d_mnist_loss: 0.0015, d_svhn_loss: 0.0081, d_fake_loss: 0.0374, g_loss: 1.4129\n",
            "Step [79660/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0027, d_svhn_loss: 0.0364, d_fake_loss: 0.0555, g_loss: 1.1636\n",
            "Step [79670/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0011, d_svhn_loss: 0.0345, d_fake_loss: 0.0198, g_loss: 1.1181\n",
            "Step [79680/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0159, d_svhn_loss: 0.0258, d_fake_loss: 0.0423, g_loss: 1.1901\n",
            "Step [79690/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0011, d_svhn_loss: 0.0279, d_fake_loss: 0.0153, g_loss: 1.1486\n",
            "Step [79700/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0037, d_svhn_loss: 0.0549, d_fake_loss: 0.0496, g_loss: 1.2693\n",
            "Step [79710/80000], d_real_loss: 0.0215, d_mnist_loss: 0.0041, d_svhn_loss: 0.0174, d_fake_loss: 0.1493, g_loss: 1.1601\n",
            "Step [79720/80000], d_real_loss: 0.0181, d_mnist_loss: 0.0039, d_svhn_loss: 0.0142, d_fake_loss: 0.0143, g_loss: 1.0788\n",
            "Step [79730/80000], d_real_loss: 0.0151, d_mnist_loss: 0.0010, d_svhn_loss: 0.0140, d_fake_loss: 0.0170, g_loss: 1.0971\n",
            "Step [79740/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0029, d_svhn_loss: 0.0734, d_fake_loss: 0.0494, g_loss: 1.1369\n",
            "Step [79750/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0013, d_svhn_loss: 0.0534, d_fake_loss: 0.0601, g_loss: 1.0921\n",
            "Step [79760/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0047, d_svhn_loss: 0.0501, d_fake_loss: 0.0127, g_loss: 1.0728\n",
            "Step [79770/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0040, d_svhn_loss: 0.0594, d_fake_loss: 0.0544, g_loss: 1.1395\n",
            "Step [79780/80000], d_real_loss: 0.0202, d_mnist_loss: 0.0047, d_svhn_loss: 0.0155, d_fake_loss: 0.0072, g_loss: 1.2666\n",
            "Step [79790/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0010, d_svhn_loss: 0.0348, d_fake_loss: 0.1066, g_loss: 1.1590\n",
            "Step [79800/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0021, d_svhn_loss: 0.0278, d_fake_loss: 0.0118, g_loss: 1.1035\n",
            "Step [79810/80000], d_real_loss: 0.0247, d_mnist_loss: 0.0024, d_svhn_loss: 0.0223, d_fake_loss: 0.0338, g_loss: 1.3135\n",
            "Step [79820/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0028, d_svhn_loss: 0.0219, d_fake_loss: 0.0160, g_loss: 1.0368\n",
            "Step [79830/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0044, d_svhn_loss: 0.0254, d_fake_loss: 0.0264, g_loss: 1.1626\n",
            "Step [79840/80000], d_real_loss: 0.0866, d_mnist_loss: 0.0207, d_svhn_loss: 0.0659, d_fake_loss: 0.0092, g_loss: 1.1491\n",
            "Step [79850/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0043, d_svhn_loss: 0.0285, d_fake_loss: 0.0123, g_loss: 1.1423\n",
            "Step [79860/80000], d_real_loss: 0.1038, d_mnist_loss: 0.0032, d_svhn_loss: 0.1006, d_fake_loss: 0.0178, g_loss: 1.0714\n",
            "Step [79870/80000], d_real_loss: 0.0168, d_mnist_loss: 0.0035, d_svhn_loss: 0.0133, d_fake_loss: 0.0129, g_loss: 1.1368\n",
            "Step [79880/80000], d_real_loss: 0.0197, d_mnist_loss: 0.0024, d_svhn_loss: 0.0173, d_fake_loss: 0.0361, g_loss: 1.2282\n",
            "Step [79890/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0117, d_svhn_loss: 0.0218, d_fake_loss: 0.0259, g_loss: 1.1324\n",
            "Step [79900/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0060, d_svhn_loss: 0.0250, d_fake_loss: 0.0227, g_loss: 1.1674\n",
            "Step [79910/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0132, d_svhn_loss: 0.0150, d_fake_loss: 0.0473, g_loss: 1.1124\n",
            "Step [79920/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0054, d_svhn_loss: 0.0256, d_fake_loss: 0.0297, g_loss: 1.0910\n",
            "Step [79930/80000], d_real_loss: 0.0162, d_mnist_loss: 0.0020, d_svhn_loss: 0.0143, d_fake_loss: 0.0122, g_loss: 1.1905\n",
            "Step [79940/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0026, d_svhn_loss: 0.0245, d_fake_loss: 0.0142, g_loss: 1.1441\n",
            "Step [79950/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0059, d_svhn_loss: 0.0211, d_fake_loss: 0.0238, g_loss: 1.2405\n",
            "Step [79960/80000], d_real_loss: 0.0780, d_mnist_loss: 0.0029, d_svhn_loss: 0.0751, d_fake_loss: 0.0157, g_loss: 1.2067\n",
            "Step [79970/80000], d_real_loss: 0.0214, d_mnist_loss: 0.0023, d_svhn_loss: 0.0191, d_fake_loss: 0.0135, g_loss: 1.2115\n",
            "Step [79980/80000], d_real_loss: 0.0179, d_mnist_loss: 0.0051, d_svhn_loss: 0.0128, d_fake_loss: 0.0206, g_loss: 1.1323\n",
            "Step [79990/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0115, d_svhn_loss: 0.0169, d_fake_loss: 0.0143, g_loss: 1.1435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [80000/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0029, d_svhn_loss: 0.0292, d_fake_loss: 0.0359, g_loss: 1.1078\n",
            "saved ./samples_mnist_svhn/sample-80000-m-s.png\n",
            "saved ./samples_mnist_svhn/sample-80000-s-m.png\n"
          ]
        }
      ],
      "source": [
        "d_real_loss_list, d_mnist_loss_list, d_svhn_loss_list, d_fake_loss_list, g_loss_list = train(svhn_loader, mnist_loader, sample_path=sample_path1, model_path=model_path1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4EI9ir31Lh8"
      },
      "source": [
        "*To install the results from the workshop of colab*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4I-Vhp0iDptg"
      },
      "outputs": [],
      "source": [
        "import os, tarfile\n",
        " \n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def make_targz_one_by_one(output_filename, source_dir):\n",
        "  tar = tarfile.open(output_filename,\"w\")\n",
        "  for root,dir_name,files_list in os.walk(source_dir):\n",
        "    for file in files_list:\n",
        "      pathfile = os.path.join(root, file)\n",
        "      tar.add(pathfile)\n",
        "  tar.close()\n",
        "  files.download(output_filename)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Plot the loss results during the training*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "4NrJ6u1fW4Ho",
        "outputId": "0e3e7e53-5295-4d21-fb82-3e544761eaf1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "classes = [d_real_loss_list,d_mnist_loss_list,d_svhn_loss_list,d_fake_loss_list,g_loss_list]\n",
        "labels = ['d_real_loss','d_mnist_loss','d_svhn_loss','d_fake_loss','g_loss']\n",
        "\n",
        "for plt_index in range(1,6):\n",
        "    ax = fig.add_subplot(3,2,plt_index)\n",
        "    plt.plot(range(train_iters+1), classes[plt_index-1], label = labels[plt_index-1])\n",
        "    plt.xlabel(\"iters\")\n",
        "    plt.ylabel(\"loss values\")\n",
        "    pass\n",
        "\n",
        "plt.title(\"The figure of loss in transformation betweem mnist and svhn\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NzZL6rzGiyT6"
      },
      "source": [
        "**Part4 Adapt to new dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhZEbjpJ0p_f"
      },
      "source": [
        "*The function to implement the transformation of the size of every images*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3E0TMGkCAWv"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os.path\n",
        "import glob\n",
        "def convertjpg(jpgfile,outdir,width=32,height=32):\n",
        "    img=Image.open(jpgfile)\n",
        "    try:\n",
        "        new_img=img.resize((width,height),Image.BILINEAR)   \n",
        "        new_img.save(os.path.join(outdir,os.path.basename(jpgfile)))\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "for jpgfile in glob.glob(\"C:/Users/62300/Documents/MCE/deep learning/images/*.jpg\"):\n",
        "    convertjpg(jpgfile,\"C:/Users/62300/Documents/MCE/deep learning/fashion_product_images_small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gscAfBj-03nk"
      },
      "source": [
        "*Training process*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TZPIP5BRiyT9"
      },
      "outputs": [],
      "source": [
        "sample_path2 = './samples_fashion'\n",
        "model_path2 = './models_fashion'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fQ7oQdO3biRr"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(model_path2):\n",
        "    os.makedirs(model_path2)\n",
        "if not os.path.exists(sample_path2):\n",
        "    os.makedirs(sample_path2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMey43VG098K"
      },
      "source": [
        "*The function used to unzip the zip document*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Icg1kbkdWXwp"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_file = zipfile.ZipFile('./fashion_product_images_small.zip')\n",
        "zip_list = zip_file.namelist() \n",
        "\n",
        "for f in zip_list:\n",
        "    zip_file.extract(f, '/content') \n",
        " \n",
        "zip_file.close() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2Fw73_eniyT-"
      },
      "outputs": [],
      "source": [
        "#get the dataset of fashion_product_images_small\n",
        "data1 = MyDataset(\"/content/fashion_product_images_small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Y-OJ4mYaiyT_"
      },
      "outputs": [],
      "source": [
        "#generate the fashion_product_images_small dataloader\n",
        "fashion_loader = DataLoader(data1, batch_size=64, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "b725f13af4464aa98cb65f087673cd43",
            "27cdd0152cb1498d8ef213828f933821",
            "5cf121e25b6f461998cc4d88881a99e0",
            "b3c32f318a8a4db2830a7781f08baa0e",
            "0fec1020d4ba47039df35e6c7e8cf35d",
            "dab0463e26b84f1c94acdde847c5c4e5",
            "93c3e990699a46889bbb96cd3117825d",
            "3ddd790981cd47378ad7163d3072ea8a",
            "5ae1a283beb640d89bc8af1e561488f0",
            "6a294c33d65b4a9ca4e2167a99a3ae4a",
            "ec9f50bbbaa544679570b24d34058347",
            "c898205ecbe94fdca3ed32633e566dc4",
            "c7fa1d70aaf54d00849f2935200ccd18",
            "eb62930646634f049c448098eb58fb2d",
            "20849f9d84694715898811b94e4f26fc",
            "49323395137a4d52bf640b1c7017e940",
            "9be35c985e1844598095d7b0ad9b2231",
            "c9f955df43174d6c869613cb249916e9",
            "aaeab01448df4b9398941b0732ff5963",
            "9b1393b1adf7452fbfd1b70501d6154a",
            "b36a629381f64e8689d9ad7776152bb4",
            "c082c2579a804ba18f772c421041fd22",
            "785d9a8de5134c8cb7b2ff376e28e2d3",
            "40dc87c29ddf4b5492c9cd4815901dfa",
            "0460c1b1009d40d587d64b88e7ff1172",
            "99a7609660564bbd81350c1d515ce0c7",
            "e8b177753bf2412197a026a2fa4ef3bb",
            "c4553930f4234235869c97bd984f60d1",
            "1d25b63c7bc14828b8334b934c4d0b0a",
            "0262a1fa4d484af08bb470fdb5ce78ae",
            "eee2dbf7e8474a2793b24facba444164",
            "644aecb3d2fd46d4bb716d9cea3379aa",
            "8fc8052595734712867bd44cfd7d0102",
            "241b44a4e794488ab1a14366409f5921",
            "5fc7cfe45bbd4bcd90ed72c7901b2c3d",
            "3a5c68b8ec234f12ba5ea654dd095a7d",
            "2d0aaeef4f7c411e97a45397cc035e0a",
            "04c779916f08432bbaba5331856c478d",
            "7faff432e19a4ec9a31688b5875b4fca",
            "20eb3d40c9b2474987da694fdfb422e2",
            "1ba2627bae08419297d628a0c88a566e",
            "2335781a1c9e451888e00e4552dcb68b",
            "024464c2b39c4f75bea37fb2e838e487",
            "a3404d41b07e4c7da789d04d56b8551b"
          ]
        },
        "id": "V0s5tyWIiyUA",
        "outputId": "af1bb79d-8c41-4298-cde3-627fed30b2f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./Fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b725f13af4464aa98cb65f087673cd43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/26421880 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./Fashionmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./Fashionmnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./Fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c898205ecbe94fdca3ed32633e566dc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/29515 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./Fashionmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./Fashionmnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./Fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "785d9a8de5134c8cb7b2ff376e28e2d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4422102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./Fashionmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./Fashionmnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./Fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "241b44a4e794488ab1a14366409f5921",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5148 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./Fashionmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./Fashionmnist/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#generate the fashion mnist dataloader\n",
        "Fashionmnist_loader = get_loader_fashion(image_size, batch_size, num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8WIIE1QqIEx",
        "outputId": "2b14cc76-1279-4c7d-8e2b-382a2d74e261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [10/80000], d_real_loss: 0.5605, d_mnist_loss: 0.2489, d_svhn_loss: 0.3116, d_fake_loss: 0.5536, g_loss: 1.6397\n",
            "Step [20/80000], d_real_loss: 0.3071, d_mnist_loss: 0.2252, d_svhn_loss: 0.0819, d_fake_loss: 1.1515, g_loss: 1.9518\n",
            "Step [30/80000], d_real_loss: 1.2973, d_mnist_loss: 0.5733, d_svhn_loss: 0.7241, d_fake_loss: 0.7664, g_loss: 1.4946\n",
            "Step [40/80000], d_real_loss: 0.7076, d_mnist_loss: 0.2406, d_svhn_loss: 0.4669, d_fake_loss: 0.8503, g_loss: 1.2400\n",
            "Step [50/80000], d_real_loss: 0.5895, d_mnist_loss: 0.2166, d_svhn_loss: 0.3729, d_fake_loss: 0.6088, g_loss: 1.7787\n",
            "Step [60/80000], d_real_loss: 0.7331, d_mnist_loss: 0.2228, d_svhn_loss: 0.5104, d_fake_loss: 0.6417, g_loss: 1.2463\n",
            "Step [70/80000], d_real_loss: 0.5622, d_mnist_loss: 0.2035, d_svhn_loss: 0.3587, d_fake_loss: 0.5390, g_loss: 1.1724\n",
            "Step [80/80000], d_real_loss: 0.9748, d_mnist_loss: 0.5313, d_svhn_loss: 0.4435, d_fake_loss: 1.3244, g_loss: 2.8657\n",
            "Step [90/80000], d_real_loss: 0.4660, d_mnist_loss: 0.2871, d_svhn_loss: 0.1789, d_fake_loss: 0.5504, g_loss: 1.2211\n",
            "Step [100/80000], d_real_loss: 0.7327, d_mnist_loss: 0.3700, d_svhn_loss: 0.3627, d_fake_loss: 0.4333, g_loss: 1.0648\n",
            "Step [110/80000], d_real_loss: 0.6096, d_mnist_loss: 0.3000, d_svhn_loss: 0.3096, d_fake_loss: 0.6109, g_loss: 0.8890\n",
            "Step [120/80000], d_real_loss: 0.4688, d_mnist_loss: 0.3107, d_svhn_loss: 0.1581, d_fake_loss: 0.4034, g_loss: 0.9709\n",
            "Step [130/80000], d_real_loss: 0.6549, d_mnist_loss: 0.3318, d_svhn_loss: 0.3230, d_fake_loss: 0.6925, g_loss: 0.9415\n",
            "Step [140/80000], d_real_loss: 0.5686, d_mnist_loss: 0.3801, d_svhn_loss: 0.1885, d_fake_loss: 0.6249, g_loss: 1.0199\n",
            "Step [150/80000], d_real_loss: 0.4299, d_mnist_loss: 0.3232, d_svhn_loss: 0.1067, d_fake_loss: 0.5905, g_loss: 0.9728\n",
            "Step [160/80000], d_real_loss: 0.6624, d_mnist_loss: 0.3825, d_svhn_loss: 0.2799, d_fake_loss: 0.6177, g_loss: 1.4008\n",
            "Step [170/80000], d_real_loss: 0.9551, d_mnist_loss: 0.3590, d_svhn_loss: 0.5961, d_fake_loss: 0.3935, g_loss: 0.9961\n",
            "Step [180/80000], d_real_loss: 0.6277, d_mnist_loss: 0.3973, d_svhn_loss: 0.2304, d_fake_loss: 0.7604, g_loss: 1.6910\n",
            "Step [190/80000], d_real_loss: 0.6256, d_mnist_loss: 0.5697, d_svhn_loss: 0.0560, d_fake_loss: 0.5869, g_loss: 1.4541\n",
            "Step [200/80000], d_real_loss: 0.6489, d_mnist_loss: 0.4330, d_svhn_loss: 0.2159, d_fake_loss: 0.4149, g_loss: 1.0938\n",
            "Step [210/80000], d_real_loss: 0.4724, d_mnist_loss: 0.3987, d_svhn_loss: 0.0737, d_fake_loss: 0.4981, g_loss: 1.3159\n",
            "Step [220/80000], d_real_loss: 0.4006, d_mnist_loss: 0.3036, d_svhn_loss: 0.0970, d_fake_loss: 0.2923, g_loss: 1.1202\n",
            "Step [230/80000], d_real_loss: 0.7169, d_mnist_loss: 0.3895, d_svhn_loss: 0.3274, d_fake_loss: 0.5150, g_loss: 1.2935\n",
            "Step [240/80000], d_real_loss: 0.6451, d_mnist_loss: 0.3726, d_svhn_loss: 0.2725, d_fake_loss: 0.5158, g_loss: 1.1168\n",
            "Step [250/80000], d_real_loss: 0.5219, d_mnist_loss: 0.3870, d_svhn_loss: 0.1349, d_fake_loss: 0.8507, g_loss: 1.3055\n",
            "Step [260/80000], d_real_loss: 0.5645, d_mnist_loss: 0.3232, d_svhn_loss: 0.2413, d_fake_loss: 0.6680, g_loss: 1.2008\n",
            "Step [270/80000], d_real_loss: 0.3932, d_mnist_loss: 0.3022, d_svhn_loss: 0.0910, d_fake_loss: 0.3600, g_loss: 0.9756\n",
            "Step [280/80000], d_real_loss: 0.5791, d_mnist_loss: 0.2397, d_svhn_loss: 0.3395, d_fake_loss: 0.3622, g_loss: 1.1610\n",
            "Step [290/80000], d_real_loss: 0.8850, d_mnist_loss: 0.3798, d_svhn_loss: 0.5052, d_fake_loss: 0.4587, g_loss: 0.9341\n",
            "Step [300/80000], d_real_loss: 0.9618, d_mnist_loss: 0.2567, d_svhn_loss: 0.7050, d_fake_loss: 0.6729, g_loss: 1.2382\n",
            "Step [310/80000], d_real_loss: 0.5641, d_mnist_loss: 0.3259, d_svhn_loss: 0.2382, d_fake_loss: 0.5791, g_loss: 1.2394\n",
            "Step [320/80000], d_real_loss: 0.2900, d_mnist_loss: 0.1924, d_svhn_loss: 0.0976, d_fake_loss: 0.2755, g_loss: 1.1058\n",
            "Step [330/80000], d_real_loss: 0.4624, d_mnist_loss: 0.2253, d_svhn_loss: 0.2371, d_fake_loss: 0.2072, g_loss: 1.1985\n",
            "Step [340/80000], d_real_loss: 0.4791, d_mnist_loss: 0.3701, d_svhn_loss: 0.1090, d_fake_loss: 0.3314, g_loss: 1.4748\n",
            "Step [350/80000], d_real_loss: 0.3945, d_mnist_loss: 0.2586, d_svhn_loss: 0.1359, d_fake_loss: 0.3297, g_loss: 1.0730\n",
            "Step [360/80000], d_real_loss: 0.5160, d_mnist_loss: 0.3148, d_svhn_loss: 0.2012, d_fake_loss: 0.7907, g_loss: 1.1661\n",
            "Step [370/80000], d_real_loss: 0.4288, d_mnist_loss: 0.2932, d_svhn_loss: 0.1356, d_fake_loss: 0.2200, g_loss: 1.0102\n",
            "Step [380/80000], d_real_loss: 0.7133, d_mnist_loss: 0.2157, d_svhn_loss: 0.4975, d_fake_loss: 0.4786, g_loss: 1.4206\n",
            "Step [390/80000], d_real_loss: 0.4114, d_mnist_loss: 0.1749, d_svhn_loss: 0.2365, d_fake_loss: 0.2291, g_loss: 1.0760\n",
            "Step [400/80000], d_real_loss: 1.0390, d_mnist_loss: 0.3609, d_svhn_loss: 0.6782, d_fake_loss: 0.7240, g_loss: 1.4997\n",
            "Step [410/80000], d_real_loss: 0.5463, d_mnist_loss: 0.3017, d_svhn_loss: 0.2446, d_fake_loss: 0.3812, g_loss: 1.0280\n",
            "Step [420/80000], d_real_loss: 0.4185, d_mnist_loss: 0.1526, d_svhn_loss: 0.2659, d_fake_loss: 0.3299, g_loss: 1.2470\n",
            "Step [430/80000], d_real_loss: 0.4588, d_mnist_loss: 0.2709, d_svhn_loss: 0.1879, d_fake_loss: 0.5174, g_loss: 1.2739\n",
            "Step [440/80000], d_real_loss: 0.2866, d_mnist_loss: 0.1294, d_svhn_loss: 0.1572, d_fake_loss: 0.3098, g_loss: 1.2218\n",
            "Step [450/80000], d_real_loss: 0.5130, d_mnist_loss: 0.3252, d_svhn_loss: 0.1878, d_fake_loss: 0.3455, g_loss: 1.1377\n",
            "Step [460/80000], d_real_loss: 0.3547, d_mnist_loss: 0.1401, d_svhn_loss: 0.2146, d_fake_loss: 0.2216, g_loss: 1.2191\n",
            "Step [470/80000], d_real_loss: 0.5900, d_mnist_loss: 0.3821, d_svhn_loss: 0.2078, d_fake_loss: 0.2935, g_loss: 1.1874\n",
            "Step [480/80000], d_real_loss: 0.5460, d_mnist_loss: 0.2603, d_svhn_loss: 0.2857, d_fake_loss: 0.2570, g_loss: 1.3952\n",
            "Step [490/80000], d_real_loss: 0.3641, d_mnist_loss: 0.2723, d_svhn_loss: 0.0919, d_fake_loss: 0.5510, g_loss: 1.2666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [500/80000], d_real_loss: 0.6125, d_mnist_loss: 0.2152, d_svhn_loss: 0.3973, d_fake_loss: 0.4577, g_loss: 1.4288\n",
            "saved ./samples_fashion/sample-500-m-s.png\n",
            "saved ./samples_fashion/sample-500-s-m.png\n",
            "Step [510/80000], d_real_loss: 0.4807, d_mnist_loss: 0.2987, d_svhn_loss: 0.1820, d_fake_loss: 0.4884, g_loss: 1.2529\n",
            "Step [520/80000], d_real_loss: 0.3889, d_mnist_loss: 0.2161, d_svhn_loss: 0.1728, d_fake_loss: 0.4810, g_loss: 1.2709\n",
            "Step [530/80000], d_real_loss: 0.3643, d_mnist_loss: 0.2442, d_svhn_loss: 0.1201, d_fake_loss: 0.2365, g_loss: 1.2973\n",
            "Step [540/80000], d_real_loss: 0.3282, d_mnist_loss: 0.2650, d_svhn_loss: 0.0632, d_fake_loss: 0.3818, g_loss: 1.8127\n",
            "Step [550/80000], d_real_loss: 0.2815, d_mnist_loss: 0.1575, d_svhn_loss: 0.1241, d_fake_loss: 0.4153, g_loss: 1.3322\n",
            "Step [560/80000], d_real_loss: 0.5054, d_mnist_loss: 0.1759, d_svhn_loss: 0.3295, d_fake_loss: 0.4804, g_loss: 1.3027\n",
            "Step [570/80000], d_real_loss: 0.3421, d_mnist_loss: 0.0986, d_svhn_loss: 0.2434, d_fake_loss: 0.3637, g_loss: 1.6414\n",
            "Step [580/80000], d_real_loss: 0.2080, d_mnist_loss: 0.1413, d_svhn_loss: 0.0667, d_fake_loss: 0.2324, g_loss: 1.1733\n",
            "Step [590/80000], d_real_loss: 0.4186, d_mnist_loss: 0.1882, d_svhn_loss: 0.2304, d_fake_loss: 0.2431, g_loss: 1.4103\n",
            "Step [600/80000], d_real_loss: 0.3785, d_mnist_loss: 0.2103, d_svhn_loss: 0.1682, d_fake_loss: 0.4616, g_loss: 1.5402\n",
            "Step [610/80000], d_real_loss: 0.4808, d_mnist_loss: 0.3119, d_svhn_loss: 0.1689, d_fake_loss: 0.3219, g_loss: 1.4266\n",
            "Step [620/80000], d_real_loss: 0.2614, d_mnist_loss: 0.1823, d_svhn_loss: 0.0791, d_fake_loss: 0.4104, g_loss: 1.1481\n",
            "Step [630/80000], d_real_loss: 0.4104, d_mnist_loss: 0.1177, d_svhn_loss: 0.2927, d_fake_loss: 0.3285, g_loss: 1.3402\n",
            "Step [640/80000], d_real_loss: 0.3859, d_mnist_loss: 0.2785, d_svhn_loss: 0.1074, d_fake_loss: 0.4984, g_loss: 1.3089\n",
            "Step [650/80000], d_real_loss: 0.5112, d_mnist_loss: 0.2745, d_svhn_loss: 0.2367, d_fake_loss: 0.4099, g_loss: 1.4596\n",
            "Step [660/80000], d_real_loss: 0.3551, d_mnist_loss: 0.2078, d_svhn_loss: 0.1473, d_fake_loss: 0.3230, g_loss: 1.3854\n",
            "Step [670/80000], d_real_loss: 0.3511, d_mnist_loss: 0.2003, d_svhn_loss: 0.1508, d_fake_loss: 0.4216, g_loss: 1.4556\n",
            "Step [680/80000], d_real_loss: 0.2838, d_mnist_loss: 0.2242, d_svhn_loss: 0.0596, d_fake_loss: 0.3010, g_loss: 1.2357\n",
            "Step [690/80000], d_real_loss: 0.5666, d_mnist_loss: 0.1337, d_svhn_loss: 0.4329, d_fake_loss: 0.4368, g_loss: 1.2843\n",
            "Step [700/80000], d_real_loss: 0.2797, d_mnist_loss: 0.1386, d_svhn_loss: 0.1412, d_fake_loss: 0.4221, g_loss: 1.9210\n",
            "Step [710/80000], d_real_loss: 0.4919, d_mnist_loss: 0.3328, d_svhn_loss: 0.1591, d_fake_loss: 0.3421, g_loss: 1.2105\n",
            "Step [720/80000], d_real_loss: 0.4088, d_mnist_loss: 0.1952, d_svhn_loss: 0.2136, d_fake_loss: 0.3393, g_loss: 1.1412\n",
            "Step [730/80000], d_real_loss: 0.6572, d_mnist_loss: 0.1598, d_svhn_loss: 0.4975, d_fake_loss: 0.2873, g_loss: 1.4790\n",
            "Step [740/80000], d_real_loss: 0.3951, d_mnist_loss: 0.2973, d_svhn_loss: 0.0979, d_fake_loss: 0.3222, g_loss: 1.4927\n",
            "Step [750/80000], d_real_loss: 0.3495, d_mnist_loss: 0.2582, d_svhn_loss: 0.0914, d_fake_loss: 0.3735, g_loss: 1.1148\n",
            "Step [760/80000], d_real_loss: 0.5477, d_mnist_loss: 0.1004, d_svhn_loss: 0.4473, d_fake_loss: 0.7638, g_loss: 1.9631\n",
            "Step [770/80000], d_real_loss: 0.4307, d_mnist_loss: 0.2919, d_svhn_loss: 0.1389, d_fake_loss: 0.2745, g_loss: 1.1286\n",
            "Step [780/80000], d_real_loss: 0.6656, d_mnist_loss: 0.3028, d_svhn_loss: 0.3628, d_fake_loss: 0.2981, g_loss: 1.3551\n",
            "Step [790/80000], d_real_loss: 0.3713, d_mnist_loss: 0.3052, d_svhn_loss: 0.0661, d_fake_loss: 0.2839, g_loss: 1.2650\n",
            "Step [800/80000], d_real_loss: 0.3354, d_mnist_loss: 0.1368, d_svhn_loss: 0.1986, d_fake_loss: 0.3254, g_loss: 1.4981\n",
            "Step [810/80000], d_real_loss: 0.2316, d_mnist_loss: 0.1894, d_svhn_loss: 0.0422, d_fake_loss: 0.3076, g_loss: 1.0457\n",
            "Step [820/80000], d_real_loss: 0.4650, d_mnist_loss: 0.2929, d_svhn_loss: 0.1721, d_fake_loss: 0.4214, g_loss: 1.6281\n",
            "Step [830/80000], d_real_loss: 0.3205, d_mnist_loss: 0.1839, d_svhn_loss: 0.1367, d_fake_loss: 0.4085, g_loss: 1.2707\n",
            "Step [840/80000], d_real_loss: 0.4376, d_mnist_loss: 0.2593, d_svhn_loss: 0.1782, d_fake_loss: 0.3116, g_loss: 1.4462\n",
            "Step [850/80000], d_real_loss: 0.4061, d_mnist_loss: 0.2230, d_svhn_loss: 0.1831, d_fake_loss: 0.1706, g_loss: 1.1676\n",
            "Step [860/80000], d_real_loss: 0.4009, d_mnist_loss: 0.2967, d_svhn_loss: 0.1041, d_fake_loss: 0.4072, g_loss: 1.1042\n",
            "Step [870/80000], d_real_loss: 0.4340, d_mnist_loss: 0.1953, d_svhn_loss: 0.2387, d_fake_loss: 0.2121, g_loss: 1.1662\n",
            "Step [880/80000], d_real_loss: 0.2305, d_mnist_loss: 0.1783, d_svhn_loss: 0.0522, d_fake_loss: 0.2092, g_loss: 1.2517\n",
            "Step [890/80000], d_real_loss: 0.4525, d_mnist_loss: 0.3318, d_svhn_loss: 0.1207, d_fake_loss: 0.3022, g_loss: 1.4827\n",
            "Step [900/80000], d_real_loss: 0.2196, d_mnist_loss: 0.1508, d_svhn_loss: 0.0688, d_fake_loss: 0.3574, g_loss: 1.2570\n",
            "Step [910/80000], d_real_loss: 0.2281, d_mnist_loss: 0.1247, d_svhn_loss: 0.1033, d_fake_loss: 0.3686, g_loss: 1.5055\n",
            "Step [920/80000], d_real_loss: 0.3578, d_mnist_loss: 0.1473, d_svhn_loss: 0.2105, d_fake_loss: 0.5826, g_loss: 1.3253\n",
            "Step [930/80000], d_real_loss: 0.3596, d_mnist_loss: 0.2288, d_svhn_loss: 0.1308, d_fake_loss: 0.3179, g_loss: 1.2901\n",
            "Step [940/80000], d_real_loss: 0.2091, d_mnist_loss: 0.1256, d_svhn_loss: 0.0835, d_fake_loss: 0.2488, g_loss: 1.5448\n",
            "Step [950/80000], d_real_loss: 0.2552, d_mnist_loss: 0.2013, d_svhn_loss: 0.0539, d_fake_loss: 0.2781, g_loss: 1.3818\n",
            "Step [960/80000], d_real_loss: 0.4707, d_mnist_loss: 0.0997, d_svhn_loss: 0.3710, d_fake_loss: 0.1616, g_loss: 1.4563\n",
            "Step [970/80000], d_real_loss: 0.2513, d_mnist_loss: 0.1261, d_svhn_loss: 0.1252, d_fake_loss: 0.4864, g_loss: 1.4557\n",
            "Step [980/80000], d_real_loss: 0.2841, d_mnist_loss: 0.1783, d_svhn_loss: 0.1059, d_fake_loss: 0.4106, g_loss: 1.6466\n",
            "Step [990/80000], d_real_loss: 0.2795, d_mnist_loss: 0.1532, d_svhn_loss: 0.1264, d_fake_loss: 0.3793, g_loss: 1.0536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [1000/80000], d_real_loss: 0.3454, d_mnist_loss: 0.1397, d_svhn_loss: 0.2057, d_fake_loss: 0.3061, g_loss: 1.2015\n",
            "saved ./samples_fashion/sample-1000-m-s.png\n",
            "saved ./samples_fashion/sample-1000-s-m.png\n",
            "Step [1010/80000], d_real_loss: 0.2687, d_mnist_loss: 0.1762, d_svhn_loss: 0.0926, d_fake_loss: 0.3188, g_loss: 1.6512\n",
            "Step [1020/80000], d_real_loss: 0.2388, d_mnist_loss: 0.1508, d_svhn_loss: 0.0881, d_fake_loss: 0.2431, g_loss: 1.6155\n",
            "Step [1030/80000], d_real_loss: 0.5074, d_mnist_loss: 0.1577, d_svhn_loss: 0.3497, d_fake_loss: 0.3473, g_loss: 1.6367\n",
            "Step [1040/80000], d_real_loss: 0.3067, d_mnist_loss: 0.2098, d_svhn_loss: 0.0969, d_fake_loss: 0.1883, g_loss: 0.9490\n",
            "Step [1050/80000], d_real_loss: 0.1913, d_mnist_loss: 0.0716, d_svhn_loss: 0.1197, d_fake_loss: 0.2115, g_loss: 1.4529\n",
            "Step [1060/80000], d_real_loss: 0.2887, d_mnist_loss: 0.2387, d_svhn_loss: 0.0500, d_fake_loss: 0.4106, g_loss: 1.6640\n",
            "Step [1070/80000], d_real_loss: 0.4028, d_mnist_loss: 0.3236, d_svhn_loss: 0.0793, d_fake_loss: 0.3229, g_loss: 1.3806\n",
            "Step [1080/80000], d_real_loss: 0.3692, d_mnist_loss: 0.1053, d_svhn_loss: 0.2638, d_fake_loss: 0.2586, g_loss: 1.4914\n",
            "Step [1090/80000], d_real_loss: 0.3522, d_mnist_loss: 0.2626, d_svhn_loss: 0.0896, d_fake_loss: 0.2109, g_loss: 1.3387\n",
            "Step [1100/80000], d_real_loss: 0.5523, d_mnist_loss: 0.2787, d_svhn_loss: 0.2737, d_fake_loss: 0.2405, g_loss: 1.2082\n",
            "Step [1110/80000], d_real_loss: 0.3109, d_mnist_loss: 0.0870, d_svhn_loss: 0.2239, d_fake_loss: 0.3491, g_loss: 1.3973\n",
            "Step [1120/80000], d_real_loss: 0.4519, d_mnist_loss: 0.1491, d_svhn_loss: 0.3028, d_fake_loss: 0.1401, g_loss: 1.0102\n",
            "Step [1130/80000], d_real_loss: 0.2587, d_mnist_loss: 0.1842, d_svhn_loss: 0.0745, d_fake_loss: 0.1854, g_loss: 1.3950\n",
            "Step [1140/80000], d_real_loss: 0.4216, d_mnist_loss: 0.2235, d_svhn_loss: 0.1981, d_fake_loss: 0.1510, g_loss: 1.7381\n",
            "Step [1150/80000], d_real_loss: 0.2181, d_mnist_loss: 0.1361, d_svhn_loss: 0.0819, d_fake_loss: 0.2488, g_loss: 1.4219\n",
            "Step [1160/80000], d_real_loss: 0.5773, d_mnist_loss: 0.3278, d_svhn_loss: 0.2495, d_fake_loss: 0.3742, g_loss: 1.5553\n",
            "Step [1170/80000], d_real_loss: 0.4133, d_mnist_loss: 0.2618, d_svhn_loss: 0.1515, d_fake_loss: 0.2072, g_loss: 0.9995\n",
            "Step [1180/80000], d_real_loss: 0.2350, d_mnist_loss: 0.1365, d_svhn_loss: 0.0984, d_fake_loss: 0.2997, g_loss: 1.4119\n",
            "Step [1190/80000], d_real_loss: 0.3634, d_mnist_loss: 0.2612, d_svhn_loss: 0.1022, d_fake_loss: 0.2010, g_loss: 1.3143\n",
            "Step [1200/80000], d_real_loss: 0.2460, d_mnist_loss: 0.0811, d_svhn_loss: 0.1649, d_fake_loss: 0.2368, g_loss: 1.4777\n",
            "Step [1210/80000], d_real_loss: 0.1606, d_mnist_loss: 0.0786, d_svhn_loss: 0.0820, d_fake_loss: 0.1552, g_loss: 1.2910\n",
            "Step [1220/80000], d_real_loss: 0.6442, d_mnist_loss: 0.1595, d_svhn_loss: 0.4847, d_fake_loss: 0.3985, g_loss: 1.2360\n",
            "Step [1230/80000], d_real_loss: 0.3649, d_mnist_loss: 0.1932, d_svhn_loss: 0.1718, d_fake_loss: 0.2141, g_loss: 1.2523\n",
            "Step [1240/80000], d_real_loss: 0.2256, d_mnist_loss: 0.1487, d_svhn_loss: 0.0769, d_fake_loss: 0.2013, g_loss: 1.4177\n",
            "Step [1250/80000], d_real_loss: 0.2168, d_mnist_loss: 0.1055, d_svhn_loss: 0.1113, d_fake_loss: 0.2200, g_loss: 1.7807\n",
            "Step [1260/80000], d_real_loss: 0.2137, d_mnist_loss: 0.1569, d_svhn_loss: 0.0568, d_fake_loss: 0.2658, g_loss: 1.7819\n",
            "Step [1270/80000], d_real_loss: 0.4180, d_mnist_loss: 0.2044, d_svhn_loss: 0.2136, d_fake_loss: 0.1944, g_loss: 1.3406\n",
            "Step [1280/80000], d_real_loss: 0.2441, d_mnist_loss: 0.0831, d_svhn_loss: 0.1610, d_fake_loss: 0.2497, g_loss: 1.6366\n",
            "Step [1290/80000], d_real_loss: 0.1745, d_mnist_loss: 0.0711, d_svhn_loss: 0.1034, d_fake_loss: 0.1698, g_loss: 0.7479\n",
            "Step [1300/80000], d_real_loss: 0.2068, d_mnist_loss: 0.0843, d_svhn_loss: 0.1225, d_fake_loss: 0.1988, g_loss: 1.0930\n",
            "Step [1310/80000], d_real_loss: 0.2329, d_mnist_loss: 0.1094, d_svhn_loss: 0.1235, d_fake_loss: 0.2064, g_loss: 1.1208\n",
            "Step [1320/80000], d_real_loss: 0.1657, d_mnist_loss: 0.0970, d_svhn_loss: 0.0686, d_fake_loss: 0.1372, g_loss: 1.2297\n",
            "Step [1330/80000], d_real_loss: 0.2608, d_mnist_loss: 0.1486, d_svhn_loss: 0.1122, d_fake_loss: 0.3937, g_loss: 2.0394\n",
            "Step [1340/80000], d_real_loss: 0.3611, d_mnist_loss: 0.2193, d_svhn_loss: 0.1418, d_fake_loss: 0.4154, g_loss: 1.7462\n",
            "Step [1350/80000], d_real_loss: 0.2798, d_mnist_loss: 0.1332, d_svhn_loss: 0.1466, d_fake_loss: 0.1771, g_loss: 1.7950\n",
            "Step [1360/80000], d_real_loss: 0.3346, d_mnist_loss: 0.0971, d_svhn_loss: 0.2375, d_fake_loss: 0.1463, g_loss: 1.1858\n",
            "Step [1370/80000], d_real_loss: 0.2896, d_mnist_loss: 0.1282, d_svhn_loss: 0.1614, d_fake_loss: 0.1449, g_loss: 1.3759\n",
            "Step [1380/80000], d_real_loss: 0.4283, d_mnist_loss: 0.1931, d_svhn_loss: 0.2351, d_fake_loss: 0.2878, g_loss: 1.4659\n",
            "Step [1390/80000], d_real_loss: 0.1562, d_mnist_loss: 0.0591, d_svhn_loss: 0.0971, d_fake_loss: 0.1738, g_loss: 1.1467\n",
            "Step [1400/80000], d_real_loss: 0.1294, d_mnist_loss: 0.0558, d_svhn_loss: 0.0736, d_fake_loss: 0.1590, g_loss: 1.4505\n",
            "Step [1410/80000], d_real_loss: 0.5734, d_mnist_loss: 0.2459, d_svhn_loss: 0.3275, d_fake_loss: 0.2623, g_loss: 1.3931\n",
            "Step [1420/80000], d_real_loss: 0.1885, d_mnist_loss: 0.0673, d_svhn_loss: 0.1212, d_fake_loss: 0.2492, g_loss: 1.6553\n",
            "Step [1430/80000], d_real_loss: 0.1784, d_mnist_loss: 0.0872, d_svhn_loss: 0.0912, d_fake_loss: 0.3525, g_loss: 1.5929\n",
            "Step [1440/80000], d_real_loss: 0.2415, d_mnist_loss: 0.0667, d_svhn_loss: 0.1749, d_fake_loss: 0.1617, g_loss: 0.7395\n",
            "Step [1450/80000], d_real_loss: 0.2408, d_mnist_loss: 0.1357, d_svhn_loss: 0.1051, d_fake_loss: 0.1699, g_loss: 1.2595\n",
            "Step [1460/80000], d_real_loss: 0.2396, d_mnist_loss: 0.0832, d_svhn_loss: 0.1564, d_fake_loss: 0.1231, g_loss: 0.8824\n",
            "Step [1470/80000], d_real_loss: 0.3150, d_mnist_loss: 0.0806, d_svhn_loss: 0.2344, d_fake_loss: 0.1470, g_loss: 1.0478\n",
            "Step [1480/80000], d_real_loss: 0.2513, d_mnist_loss: 0.1516, d_svhn_loss: 0.0997, d_fake_loss: 0.1748, g_loss: 1.0650\n",
            "Step [1490/80000], d_real_loss: 0.2119, d_mnist_loss: 0.0990, d_svhn_loss: 0.1128, d_fake_loss: 0.2521, g_loss: 1.6060\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [1500/80000], d_real_loss: 0.2101, d_mnist_loss: 0.1561, d_svhn_loss: 0.0540, d_fake_loss: 0.1045, g_loss: 0.7956\n",
            "saved ./samples_fashion/sample-1500-m-s.png\n",
            "saved ./samples_fashion/sample-1500-s-m.png\n",
            "Step [1510/80000], d_real_loss: 0.2134, d_mnist_loss: 0.0984, d_svhn_loss: 0.1151, d_fake_loss: 0.1400, g_loss: 1.4792\n",
            "Step [1520/80000], d_real_loss: 0.1744, d_mnist_loss: 0.0883, d_svhn_loss: 0.0861, d_fake_loss: 0.1629, g_loss: 1.4852\n",
            "Step [1530/80000], d_real_loss: 0.2260, d_mnist_loss: 0.1476, d_svhn_loss: 0.0785, d_fake_loss: 0.3062, g_loss: 1.3781\n",
            "Step [1540/80000], d_real_loss: 0.3032, d_mnist_loss: 0.2238, d_svhn_loss: 0.0794, d_fake_loss: 0.3798, g_loss: 2.1137\n",
            "Step [1550/80000], d_real_loss: 0.1692, d_mnist_loss: 0.0616, d_svhn_loss: 0.1076, d_fake_loss: 0.2787, g_loss: 1.2846\n",
            "Step [1560/80000], d_real_loss: 0.2048, d_mnist_loss: 0.0598, d_svhn_loss: 0.1449, d_fake_loss: 0.1620, g_loss: 0.9895\n",
            "Step [1570/80000], d_real_loss: 0.3437, d_mnist_loss: 0.1234, d_svhn_loss: 0.2203, d_fake_loss: 0.1196, g_loss: 1.1924\n",
            "Step [1580/80000], d_real_loss: 0.2908, d_mnist_loss: 0.0994, d_svhn_loss: 0.1913, d_fake_loss: 0.1821, g_loss: 1.3780\n",
            "Step [1590/80000], d_real_loss: 0.2358, d_mnist_loss: 0.0556, d_svhn_loss: 0.1802, d_fake_loss: 0.1047, g_loss: 1.2145\n",
            "Step [1600/80000], d_real_loss: 0.2008, d_mnist_loss: 0.0836, d_svhn_loss: 0.1172, d_fake_loss: 0.2294, g_loss: 1.1634\n",
            "Step [1610/80000], d_real_loss: 0.2614, d_mnist_loss: 0.0498, d_svhn_loss: 0.2115, d_fake_loss: 0.1705, g_loss: 1.2291\n",
            "Step [1620/80000], d_real_loss: 0.1363, d_mnist_loss: 0.0321, d_svhn_loss: 0.1042, d_fake_loss: 0.1907, g_loss: 1.6750\n",
            "Step [1630/80000], d_real_loss: 0.3110, d_mnist_loss: 0.0828, d_svhn_loss: 0.2282, d_fake_loss: 0.1514, g_loss: 1.3000\n",
            "Step [1640/80000], d_real_loss: 0.3855, d_mnist_loss: 0.2239, d_svhn_loss: 0.1617, d_fake_loss: 0.1851, g_loss: 0.9802\n",
            "Step [1650/80000], d_real_loss: 0.3052, d_mnist_loss: 0.1598, d_svhn_loss: 0.1454, d_fake_loss: 0.3301, g_loss: 0.8483\n",
            "Step [1660/80000], d_real_loss: 0.2059, d_mnist_loss: 0.0990, d_svhn_loss: 0.1069, d_fake_loss: 0.2385, g_loss: 1.1443\n",
            "Step [1670/80000], d_real_loss: 0.0995, d_mnist_loss: 0.0387, d_svhn_loss: 0.0607, d_fake_loss: 0.2000, g_loss: 1.3900\n",
            "Step [1680/80000], d_real_loss: 0.2260, d_mnist_loss: 0.1620, d_svhn_loss: 0.0640, d_fake_loss: 0.1644, g_loss: 1.6879\n",
            "Step [1690/80000], d_real_loss: 0.2278, d_mnist_loss: 0.1283, d_svhn_loss: 0.0995, d_fake_loss: 0.2297, g_loss: 1.1546\n",
            "Step [1700/80000], d_real_loss: 0.1277, d_mnist_loss: 0.0462, d_svhn_loss: 0.0815, d_fake_loss: 0.1466, g_loss: 1.0503\n",
            "Step [1710/80000], d_real_loss: 0.2337, d_mnist_loss: 0.0943, d_svhn_loss: 0.1394, d_fake_loss: 0.1413, g_loss: 1.4637\n",
            "Step [1720/80000], d_real_loss: 0.5543, d_mnist_loss: 0.4575, d_svhn_loss: 0.0968, d_fake_loss: 0.5321, g_loss: 1.4884\n",
            "Step [1730/80000], d_real_loss: 0.2862, d_mnist_loss: 0.2076, d_svhn_loss: 0.0785, d_fake_loss: 0.1968, g_loss: 1.1552\n",
            "Step [1740/80000], d_real_loss: 0.2623, d_mnist_loss: 0.0748, d_svhn_loss: 0.1874, d_fake_loss: 0.1938, g_loss: 1.4289\n",
            "Step [1750/80000], d_real_loss: 0.1052, d_mnist_loss: 0.0341, d_svhn_loss: 0.0712, d_fake_loss: 0.1291, g_loss: 1.3252\n",
            "Step [1760/80000], d_real_loss: 0.1485, d_mnist_loss: 0.0574, d_svhn_loss: 0.0911, d_fake_loss: 0.2490, g_loss: 1.5153\n",
            "Step [1770/80000], d_real_loss: 0.2792, d_mnist_loss: 0.0549, d_svhn_loss: 0.2243, d_fake_loss: 0.1873, g_loss: 0.5927\n",
            "Step [1780/80000], d_real_loss: 0.2583, d_mnist_loss: 0.0363, d_svhn_loss: 0.2220, d_fake_loss: 0.4068, g_loss: 1.3109\n",
            "Step [1790/80000], d_real_loss: 0.2278, d_mnist_loss: 0.1584, d_svhn_loss: 0.0694, d_fake_loss: 0.2485, g_loss: 1.1650\n",
            "Step [1800/80000], d_real_loss: 0.2709, d_mnist_loss: 0.0878, d_svhn_loss: 0.1830, d_fake_loss: 0.1776, g_loss: 0.9769\n",
            "Step [1810/80000], d_real_loss: 0.0970, d_mnist_loss: 0.0350, d_svhn_loss: 0.0620, d_fake_loss: 0.0878, g_loss: 1.2947\n",
            "Step [1820/80000], d_real_loss: 0.3817, d_mnist_loss: 0.0448, d_svhn_loss: 0.3369, d_fake_loss: 0.2986, g_loss: 1.0840\n",
            "Step [1830/80000], d_real_loss: 0.4009, d_mnist_loss: 0.2894, d_svhn_loss: 0.1114, d_fake_loss: 0.2715, g_loss: 1.7538\n",
            "Step [1840/80000], d_real_loss: 0.2977, d_mnist_loss: 0.1867, d_svhn_loss: 0.1110, d_fake_loss: 0.2408, g_loss: 1.3489\n",
            "Step [1850/80000], d_real_loss: 0.2012, d_mnist_loss: 0.1004, d_svhn_loss: 0.1007, d_fake_loss: 0.1539, g_loss: 1.2372\n",
            "Step [1860/80000], d_real_loss: 0.2833, d_mnist_loss: 0.1126, d_svhn_loss: 0.1707, d_fake_loss: 0.0967, g_loss: 1.1831\n",
            "Step [1870/80000], d_real_loss: 0.2280, d_mnist_loss: 0.0613, d_svhn_loss: 0.1667, d_fake_loss: 0.2106, g_loss: 1.5574\n",
            "Step [1880/80000], d_real_loss: 0.2487, d_mnist_loss: 0.0727, d_svhn_loss: 0.1760, d_fake_loss: 0.2760, g_loss: 1.3752\n",
            "Step [1890/80000], d_real_loss: 0.3992, d_mnist_loss: 0.3170, d_svhn_loss: 0.0822, d_fake_loss: 0.2087, g_loss: 1.1756\n",
            "Step [1900/80000], d_real_loss: 0.1475, d_mnist_loss: 0.0515, d_svhn_loss: 0.0960, d_fake_loss: 0.3217, g_loss: 2.1500\n",
            "Step [1910/80000], d_real_loss: 0.1502, d_mnist_loss: 0.0618, d_svhn_loss: 0.0884, d_fake_loss: 0.3316, g_loss: 1.7066\n",
            "Step [1920/80000], d_real_loss: 0.3010, d_mnist_loss: 0.0617, d_svhn_loss: 0.2393, d_fake_loss: 0.1543, g_loss: 1.2029\n",
            "Step [1930/80000], d_real_loss: 0.2839, d_mnist_loss: 0.0356, d_svhn_loss: 0.2484, d_fake_loss: 0.1117, g_loss: 1.5002\n",
            "Step [1940/80000], d_real_loss: 0.2194, d_mnist_loss: 0.0394, d_svhn_loss: 0.1800, d_fake_loss: 0.1690, g_loss: 1.2118\n",
            "Step [1950/80000], d_real_loss: 0.1992, d_mnist_loss: 0.1059, d_svhn_loss: 0.0933, d_fake_loss: 0.5051, g_loss: 2.4104\n",
            "Step [1960/80000], d_real_loss: 0.5383, d_mnist_loss: 0.3688, d_svhn_loss: 0.1695, d_fake_loss: 0.2784, g_loss: 1.8284\n",
            "Step [1970/80000], d_real_loss: 0.2062, d_mnist_loss: 0.0783, d_svhn_loss: 0.1280, d_fake_loss: 0.4407, g_loss: 1.9784\n",
            "Step [1980/80000], d_real_loss: 0.2843, d_mnist_loss: 0.1194, d_svhn_loss: 0.1650, d_fake_loss: 0.1153, g_loss: 1.0027\n",
            "Step [1990/80000], d_real_loss: 0.1791, d_mnist_loss: 0.0475, d_svhn_loss: 0.1316, d_fake_loss: 0.6643, g_loss: 1.8671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [2000/80000], d_real_loss: 0.1281, d_mnist_loss: 0.0622, d_svhn_loss: 0.0659, d_fake_loss: 0.1562, g_loss: 1.3980\n",
            "saved ./samples_fashion/sample-2000-m-s.png\n",
            "saved ./samples_fashion/sample-2000-s-m.png\n",
            "Step [2010/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0339, d_svhn_loss: 0.0353, d_fake_loss: 0.1660, g_loss: 1.5156\n",
            "Step [2020/80000], d_real_loss: 0.2362, d_mnist_loss: 0.0567, d_svhn_loss: 0.1794, d_fake_loss: 0.1058, g_loss: 1.2172\n",
            "Step [2030/80000], d_real_loss: 0.1557, d_mnist_loss: 0.0798, d_svhn_loss: 0.0759, d_fake_loss: 0.0979, g_loss: 1.2722\n",
            "Step [2040/80000], d_real_loss: 0.2388, d_mnist_loss: 0.1401, d_svhn_loss: 0.0987, d_fake_loss: 0.3465, g_loss: 1.7249\n",
            "Step [2050/80000], d_real_loss: 0.8988, d_mnist_loss: 0.0894, d_svhn_loss: 0.8094, d_fake_loss: 0.1948, g_loss: 1.0404\n",
            "Step [2060/80000], d_real_loss: 0.2795, d_mnist_loss: 0.1581, d_svhn_loss: 0.1214, d_fake_loss: 0.1313, g_loss: 0.8642\n",
            "Step [2070/80000], d_real_loss: 0.4211, d_mnist_loss: 0.0977, d_svhn_loss: 0.3234, d_fake_loss: 0.2647, g_loss: 1.3291\n",
            "Step [2080/80000], d_real_loss: 0.1521, d_mnist_loss: 0.0495, d_svhn_loss: 0.1026, d_fake_loss: 0.1644, g_loss: 0.7357\n",
            "Step [2090/80000], d_real_loss: 0.3503, d_mnist_loss: 0.0521, d_svhn_loss: 0.2982, d_fake_loss: 0.2700, g_loss: 0.5474\n",
            "Step [2100/80000], d_real_loss: 0.1324, d_mnist_loss: 0.0372, d_svhn_loss: 0.0952, d_fake_loss: 0.1803, g_loss: 1.3537\n",
            "Step [2110/80000], d_real_loss: 0.1842, d_mnist_loss: 0.0693, d_svhn_loss: 0.1149, d_fake_loss: 0.2049, g_loss: 1.5216\n",
            "Step [2120/80000], d_real_loss: 0.1851, d_mnist_loss: 0.0797, d_svhn_loss: 0.1053, d_fake_loss: 0.1714, g_loss: 0.9313\n",
            "Step [2130/80000], d_real_loss: 0.2213, d_mnist_loss: 0.1614, d_svhn_loss: 0.0598, d_fake_loss: 0.2341, g_loss: 1.4184\n",
            "Step [2140/80000], d_real_loss: 0.1702, d_mnist_loss: 0.0852, d_svhn_loss: 0.0851, d_fake_loss: 0.0988, g_loss: 1.1855\n",
            "Step [2150/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0381, d_svhn_loss: 0.0698, d_fake_loss: 0.1501, g_loss: 1.4722\n",
            "Step [2160/80000], d_real_loss: 0.3038, d_mnist_loss: 0.1853, d_svhn_loss: 0.1185, d_fake_loss: 0.2601, g_loss: 0.9304\n",
            "Step [2170/80000], d_real_loss: 0.1270, d_mnist_loss: 0.0601, d_svhn_loss: 0.0670, d_fake_loss: 0.1030, g_loss: 1.4233\n",
            "Step [2180/80000], d_real_loss: 0.2941, d_mnist_loss: 0.1245, d_svhn_loss: 0.1696, d_fake_loss: 0.1543, g_loss: 1.4927\n",
            "Step [2190/80000], d_real_loss: 0.0856, d_mnist_loss: 0.0329, d_svhn_loss: 0.0526, d_fake_loss: 0.3463, g_loss: 1.9439\n",
            "Step [2200/80000], d_real_loss: 0.1212, d_mnist_loss: 0.0440, d_svhn_loss: 0.0772, d_fake_loss: 0.1673, g_loss: 1.5028\n",
            "Step [2210/80000], d_real_loss: 0.1864, d_mnist_loss: 0.0930, d_svhn_loss: 0.0934, d_fake_loss: 0.1525, g_loss: 0.9653\n",
            "Step [2220/80000], d_real_loss: 0.1241, d_mnist_loss: 0.0693, d_svhn_loss: 0.0548, d_fake_loss: 0.1209, g_loss: 0.9563\n",
            "Step [2230/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0360, d_svhn_loss: 0.0519, d_fake_loss: 0.1768, g_loss: 1.5290\n",
            "Step [2240/80000], d_real_loss: 0.2068, d_mnist_loss: 0.1516, d_svhn_loss: 0.0552, d_fake_loss: 0.1037, g_loss: 1.0008\n",
            "Step [2250/80000], d_real_loss: 0.2419, d_mnist_loss: 0.0556, d_svhn_loss: 0.1864, d_fake_loss: 0.0903, g_loss: 1.2727\n",
            "Step [2260/80000], d_real_loss: 0.3434, d_mnist_loss: 0.0537, d_svhn_loss: 0.2897, d_fake_loss: 0.4411, g_loss: 0.5880\n",
            "Step [2270/80000], d_real_loss: 0.1739, d_mnist_loss: 0.0642, d_svhn_loss: 0.1097, d_fake_loss: 0.4304, g_loss: 1.9904\n",
            "Step [2280/80000], d_real_loss: 0.0859, d_mnist_loss: 0.0456, d_svhn_loss: 0.0403, d_fake_loss: 0.0850, g_loss: 1.3586\n",
            "Step [2290/80000], d_real_loss: 0.4492, d_mnist_loss: 0.0997, d_svhn_loss: 0.3495, d_fake_loss: 0.4360, g_loss: 1.2995\n",
            "Step [2300/80000], d_real_loss: 0.0977, d_mnist_loss: 0.0328, d_svhn_loss: 0.0649, d_fake_loss: 0.0598, g_loss: 0.9551\n",
            "Step [2310/80000], d_real_loss: 0.1465, d_mnist_loss: 0.0555, d_svhn_loss: 0.0909, d_fake_loss: 0.0750, g_loss: 0.9757\n",
            "Step [2320/80000], d_real_loss: 0.2589, d_mnist_loss: 0.0429, d_svhn_loss: 0.2160, d_fake_loss: 0.1497, g_loss: 1.0920\n",
            "Step [2330/80000], d_real_loss: 0.1647, d_mnist_loss: 0.0655, d_svhn_loss: 0.0991, d_fake_loss: 0.1820, g_loss: 0.6667\n",
            "Step [2340/80000], d_real_loss: 0.1350, d_mnist_loss: 0.0584, d_svhn_loss: 0.0767, d_fake_loss: 0.1161, g_loss: 1.2073\n",
            "Step [2350/80000], d_real_loss: 0.1723, d_mnist_loss: 0.0708, d_svhn_loss: 0.1015, d_fake_loss: 0.0986, g_loss: 1.1215\n",
            "Step [2360/80000], d_real_loss: 0.1644, d_mnist_loss: 0.0607, d_svhn_loss: 0.1036, d_fake_loss: 0.1987, g_loss: 1.8038\n",
            "Step [2370/80000], d_real_loss: 0.4799, d_mnist_loss: 0.0512, d_svhn_loss: 0.4286, d_fake_loss: 0.3525, g_loss: 1.6367\n",
            "Step [2380/80000], d_real_loss: 0.4287, d_mnist_loss: 0.0633, d_svhn_loss: 0.3653, d_fake_loss: 0.4351, g_loss: 2.0862\n",
            "Step [2390/80000], d_real_loss: 1.5524, d_mnist_loss: 0.0690, d_svhn_loss: 1.4834, d_fake_loss: 1.0470, g_loss: 1.2412\n",
            "Step [2400/80000], d_real_loss: 0.1408, d_mnist_loss: 0.0275, d_svhn_loss: 0.1134, d_fake_loss: 0.1646, g_loss: 1.2435\n",
            "Step [2410/80000], d_real_loss: 0.2967, d_mnist_loss: 0.0438, d_svhn_loss: 0.2529, d_fake_loss: 0.1291, g_loss: 1.1611\n",
            "Step [2420/80000], d_real_loss: 0.1545, d_mnist_loss: 0.0347, d_svhn_loss: 0.1197, d_fake_loss: 0.1219, g_loss: 1.4711\n",
            "Step [2430/80000], d_real_loss: 0.1591, d_mnist_loss: 0.0840, d_svhn_loss: 0.0751, d_fake_loss: 0.0772, g_loss: 1.3232\n",
            "Step [2440/80000], d_real_loss: 0.6715, d_mnist_loss: 0.2489, d_svhn_loss: 0.4225, d_fake_loss: 0.2780, g_loss: 1.1629\n",
            "Step [2450/80000], d_real_loss: 0.1310, d_mnist_loss: 0.0520, d_svhn_loss: 0.0790, d_fake_loss: 0.1290, g_loss: 0.9027\n",
            "Step [2460/80000], d_real_loss: 0.1438, d_mnist_loss: 0.0647, d_svhn_loss: 0.0791, d_fake_loss: 0.0698, g_loss: 1.1060\n",
            "Step [2470/80000], d_real_loss: 0.1855, d_mnist_loss: 0.0724, d_svhn_loss: 0.1132, d_fake_loss: 0.0957, g_loss: 1.3297\n",
            "Step [2480/80000], d_real_loss: 0.2467, d_mnist_loss: 0.0745, d_svhn_loss: 0.1721, d_fake_loss: 0.1384, g_loss: 0.7808\n",
            "Step [2490/80000], d_real_loss: 0.4152, d_mnist_loss: 0.1419, d_svhn_loss: 0.2733, d_fake_loss: 0.1103, g_loss: 1.3656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [2500/80000], d_real_loss: 0.1241, d_mnist_loss: 0.0302, d_svhn_loss: 0.0939, d_fake_loss: 0.2816, g_loss: 2.2751\n",
            "saved ./samples_fashion/sample-2500-m-s.png\n",
            "saved ./samples_fashion/sample-2500-s-m.png\n",
            "Step [2510/80000], d_real_loss: 0.2967, d_mnist_loss: 0.1563, d_svhn_loss: 0.1403, d_fake_loss: 0.1006, g_loss: 1.1027\n",
            "Step [2520/80000], d_real_loss: 0.1232, d_mnist_loss: 0.0584, d_svhn_loss: 0.0648, d_fake_loss: 0.1582, g_loss: 1.2574\n",
            "Step [2530/80000], d_real_loss: 0.1013, d_mnist_loss: 0.0356, d_svhn_loss: 0.0657, d_fake_loss: 0.1077, g_loss: 1.5557\n",
            "Step [2540/80000], d_real_loss: 0.2963, d_mnist_loss: 0.1683, d_svhn_loss: 0.1280, d_fake_loss: 0.2510, g_loss: 0.8142\n",
            "Step [2550/80000], d_real_loss: 0.1417, d_mnist_loss: 0.0763, d_svhn_loss: 0.0654, d_fake_loss: 0.0895, g_loss: 1.2466\n",
            "Step [2560/80000], d_real_loss: 0.2532, d_mnist_loss: 0.1892, d_svhn_loss: 0.0640, d_fake_loss: 0.1446, g_loss: 0.9321\n",
            "Step [2570/80000], d_real_loss: 0.1429, d_mnist_loss: 0.0334, d_svhn_loss: 0.1095, d_fake_loss: 0.2661, g_loss: 0.6422\n",
            "Step [2580/80000], d_real_loss: 0.1330, d_mnist_loss: 0.0516, d_svhn_loss: 0.0814, d_fake_loss: 0.1179, g_loss: 0.8223\n",
            "Step [2590/80000], d_real_loss: 0.2918, d_mnist_loss: 0.1853, d_svhn_loss: 0.1065, d_fake_loss: 0.3417, g_loss: 0.7510\n",
            "Step [2600/80000], d_real_loss: 0.2458, d_mnist_loss: 0.2005, d_svhn_loss: 0.0452, d_fake_loss: 0.4966, g_loss: 1.3593\n",
            "Step [2610/80000], d_real_loss: 0.2408, d_mnist_loss: 0.1348, d_svhn_loss: 0.1061, d_fake_loss: 0.2873, g_loss: 1.7005\n",
            "Step [2620/80000], d_real_loss: 0.0861, d_mnist_loss: 0.0289, d_svhn_loss: 0.0572, d_fake_loss: 0.1449, g_loss: 1.4602\n",
            "Step [2630/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0372, d_svhn_loss: 0.0532, d_fake_loss: 0.0744, g_loss: 1.0248\n",
            "Step [2640/80000], d_real_loss: 0.2274, d_mnist_loss: 0.1288, d_svhn_loss: 0.0986, d_fake_loss: 0.0996, g_loss: 1.0827\n",
            "Step [2650/80000], d_real_loss: 0.2491, d_mnist_loss: 0.0547, d_svhn_loss: 0.1944, d_fake_loss: 0.1261, g_loss: 0.9916\n",
            "Step [2660/80000], d_real_loss: 0.1379, d_mnist_loss: 0.0886, d_svhn_loss: 0.0493, d_fake_loss: 0.1070, g_loss: 1.0024\n",
            "Step [2670/80000], d_real_loss: 0.1422, d_mnist_loss: 0.0258, d_svhn_loss: 0.1164, d_fake_loss: 0.1713, g_loss: 1.7461\n",
            "Step [2680/80000], d_real_loss: 0.1439, d_mnist_loss: 0.0768, d_svhn_loss: 0.0671, d_fake_loss: 0.1849, g_loss: 1.1167\n",
            "Step [2690/80000], d_real_loss: 0.0998, d_mnist_loss: 0.0266, d_svhn_loss: 0.0732, d_fake_loss: 0.0864, g_loss: 1.2629\n",
            "Step [2700/80000], d_real_loss: 0.3552, d_mnist_loss: 0.0305, d_svhn_loss: 0.3247, d_fake_loss: 0.1723, g_loss: 1.2522\n",
            "Step [2710/80000], d_real_loss: 0.3294, d_mnist_loss: 0.2283, d_svhn_loss: 0.1011, d_fake_loss: 0.3094, g_loss: 1.3464\n",
            "Step [2720/80000], d_real_loss: 0.1061, d_mnist_loss: 0.0457, d_svhn_loss: 0.0604, d_fake_loss: 0.0677, g_loss: 1.3112\n",
            "Step [2730/80000], d_real_loss: 0.2932, d_mnist_loss: 0.0651, d_svhn_loss: 0.2281, d_fake_loss: 0.1194, g_loss: 1.3147\n",
            "Step [2740/80000], d_real_loss: 0.1459, d_mnist_loss: 0.0608, d_svhn_loss: 0.0851, d_fake_loss: 0.3501, g_loss: 1.7356\n",
            "Step [2750/80000], d_real_loss: 0.4226, d_mnist_loss: 0.0840, d_svhn_loss: 0.3386, d_fake_loss: 0.1390, g_loss: 0.9956\n",
            "Step [2760/80000], d_real_loss: 0.1489, d_mnist_loss: 0.0731, d_svhn_loss: 0.0758, d_fake_loss: 0.0775, g_loss: 1.4969\n",
            "Step [2770/80000], d_real_loss: 0.1181, d_mnist_loss: 0.0675, d_svhn_loss: 0.0506, d_fake_loss: 0.2963, g_loss: 1.7991\n",
            "Step [2780/80000], d_real_loss: 0.1200, d_mnist_loss: 0.0539, d_svhn_loss: 0.0661, d_fake_loss: 0.2527, g_loss: 1.9169\n",
            "Step [2790/80000], d_real_loss: 0.1583, d_mnist_loss: 0.1077, d_svhn_loss: 0.0506, d_fake_loss: 0.2663, g_loss: 1.2914\n",
            "Step [2800/80000], d_real_loss: 0.1115, d_mnist_loss: 0.0360, d_svhn_loss: 0.0755, d_fake_loss: 0.0630, g_loss: 1.0696\n",
            "Step [2810/80000], d_real_loss: 0.1243, d_mnist_loss: 0.0693, d_svhn_loss: 0.0550, d_fake_loss: 0.1031, g_loss: 1.2430\n",
            "Step [2820/80000], d_real_loss: 0.0989, d_mnist_loss: 0.0293, d_svhn_loss: 0.0696, d_fake_loss: 0.1827, g_loss: 0.8988\n",
            "Step [2830/80000], d_real_loss: 0.1959, d_mnist_loss: 0.0498, d_svhn_loss: 0.1461, d_fake_loss: 0.2171, g_loss: 1.3873\n",
            "Step [2840/80000], d_real_loss: 0.1828, d_mnist_loss: 0.0427, d_svhn_loss: 0.1401, d_fake_loss: 0.0678, g_loss: 1.0165\n",
            "Step [2850/80000], d_real_loss: 0.3090, d_mnist_loss: 0.0363, d_svhn_loss: 0.2727, d_fake_loss: 0.4497, g_loss: 0.4622\n",
            "Step [2860/80000], d_real_loss: 0.1791, d_mnist_loss: 0.1266, d_svhn_loss: 0.0525, d_fake_loss: 0.1735, g_loss: 1.2295\n",
            "Step [2870/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0471, d_svhn_loss: 0.0421, d_fake_loss: 0.0901, g_loss: 1.4290\n",
            "Step [2880/80000], d_real_loss: 0.2758, d_mnist_loss: 0.0472, d_svhn_loss: 0.2286, d_fake_loss: 0.0782, g_loss: 0.8914\n",
            "Step [2890/80000], d_real_loss: 0.1067, d_mnist_loss: 0.0530, d_svhn_loss: 0.0537, d_fake_loss: 0.0661, g_loss: 1.0156\n",
            "Step [2900/80000], d_real_loss: 0.1927, d_mnist_loss: 0.0446, d_svhn_loss: 0.1481, d_fake_loss: 0.2888, g_loss: 0.3902\n",
            "Step [2910/80000], d_real_loss: 0.1298, d_mnist_loss: 0.0403, d_svhn_loss: 0.0895, d_fake_loss: 0.0842, g_loss: 1.0526\n",
            "Step [2920/80000], d_real_loss: 0.0907, d_mnist_loss: 0.0443, d_svhn_loss: 0.0464, d_fake_loss: 0.0861, g_loss: 1.1557\n",
            "Step [2930/80000], d_real_loss: 0.1502, d_mnist_loss: 0.0749, d_svhn_loss: 0.0753, d_fake_loss: 0.2040, g_loss: 1.5055\n",
            "Step [2940/80000], d_real_loss: 0.1452, d_mnist_loss: 0.0239, d_svhn_loss: 0.1213, d_fake_loss: 0.3674, g_loss: 1.0511\n",
            "Step [2950/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0332, d_svhn_loss: 0.0547, d_fake_loss: 0.0748, g_loss: 1.2525\n",
            "Step [2960/80000], d_real_loss: 0.3970, d_mnist_loss: 0.3351, d_svhn_loss: 0.0620, d_fake_loss: 0.1658, g_loss: 1.5242\n",
            "Step [2970/80000], d_real_loss: 0.1961, d_mnist_loss: 0.0600, d_svhn_loss: 0.1361, d_fake_loss: 0.1214, g_loss: 0.9966\n",
            "Step [2980/80000], d_real_loss: 0.1911, d_mnist_loss: 0.0660, d_svhn_loss: 0.1251, d_fake_loss: 0.0983, g_loss: 0.9977\n",
            "Step [2990/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0238, d_svhn_loss: 0.0279, d_fake_loss: 0.1896, g_loss: 1.2671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [3000/80000], d_real_loss: 0.3041, d_mnist_loss: 0.1089, d_svhn_loss: 0.1952, d_fake_loss: 0.1279, g_loss: 1.5421\n",
            "saved ./samples_fashion/sample-3000-m-s.png\n",
            "saved ./samples_fashion/sample-3000-s-m.png\n",
            "Step [3010/80000], d_real_loss: 0.2573, d_mnist_loss: 0.1850, d_svhn_loss: 0.0723, d_fake_loss: 0.1367, g_loss: 0.8814\n",
            "Step [3020/80000], d_real_loss: 0.2102, d_mnist_loss: 0.0545, d_svhn_loss: 0.1557, d_fake_loss: 0.0948, g_loss: 1.3381\n",
            "Step [3030/80000], d_real_loss: 0.2533, d_mnist_loss: 0.0345, d_svhn_loss: 0.2187, d_fake_loss: 0.2257, g_loss: 1.4822\n",
            "Step [3040/80000], d_real_loss: 0.1093, d_mnist_loss: 0.0770, d_svhn_loss: 0.0323, d_fake_loss: 0.0865, g_loss: 1.2733\n",
            "Step [3050/80000], d_real_loss: 0.1915, d_mnist_loss: 0.0849, d_svhn_loss: 0.1066, d_fake_loss: 0.3455, g_loss: 1.1876\n",
            "Step [3060/80000], d_real_loss: 0.1272, d_mnist_loss: 0.0787, d_svhn_loss: 0.0485, d_fake_loss: 0.7779, g_loss: 2.0568\n",
            "Step [3070/80000], d_real_loss: 0.1177, d_mnist_loss: 0.0514, d_svhn_loss: 0.0663, d_fake_loss: 0.1104, g_loss: 1.5545\n",
            "Step [3080/80000], d_real_loss: 0.1373, d_mnist_loss: 0.0761, d_svhn_loss: 0.0611, d_fake_loss: 0.0845, g_loss: 1.3468\n",
            "Step [3090/80000], d_real_loss: 0.6757, d_mnist_loss: 0.2571, d_svhn_loss: 0.4186, d_fake_loss: 0.5262, g_loss: 0.9172\n",
            "Step [3100/80000], d_real_loss: 0.5111, d_mnist_loss: 0.2112, d_svhn_loss: 0.2999, d_fake_loss: 0.2223, g_loss: 1.3818\n",
            "Step [3110/80000], d_real_loss: 0.1002, d_mnist_loss: 0.0234, d_svhn_loss: 0.0768, d_fake_loss: 0.3308, g_loss: 1.6190\n",
            "Step [3120/80000], d_real_loss: 0.2105, d_mnist_loss: 0.0756, d_svhn_loss: 0.1350, d_fake_loss: 0.0914, g_loss: 1.4545\n",
            "Step [3130/80000], d_real_loss: 0.4187, d_mnist_loss: 0.2738, d_svhn_loss: 0.1449, d_fake_loss: 0.0869, g_loss: 0.9782\n",
            "Step [3140/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0213, d_svhn_loss: 0.0630, d_fake_loss: 0.1036, g_loss: 1.3919\n",
            "Step [3150/80000], d_real_loss: 0.1129, d_mnist_loss: 0.0440, d_svhn_loss: 0.0690, d_fake_loss: 0.2348, g_loss: 1.4367\n",
            "Step [3160/80000], d_real_loss: 0.0828, d_mnist_loss: 0.0316, d_svhn_loss: 0.0512, d_fake_loss: 0.1595, g_loss: 1.3835\n",
            "Step [3170/80000], d_real_loss: 1.1772, d_mnist_loss: 0.1981, d_svhn_loss: 0.9791, d_fake_loss: 0.4305, g_loss: 1.0820\n",
            "Step [3180/80000], d_real_loss: 0.1284, d_mnist_loss: 0.0336, d_svhn_loss: 0.0948, d_fake_loss: 0.1056, g_loss: 1.3942\n",
            "Step [3190/80000], d_real_loss: 0.1235, d_mnist_loss: 0.0538, d_svhn_loss: 0.0698, d_fake_loss: 0.1506, g_loss: 1.0637\n",
            "Step [3200/80000], d_real_loss: 0.2690, d_mnist_loss: 0.1353, d_svhn_loss: 0.1337, d_fake_loss: 0.1085, g_loss: 0.9107\n",
            "Step [3210/80000], d_real_loss: 0.1161, d_mnist_loss: 0.0350, d_svhn_loss: 0.0811, d_fake_loss: 0.4058, g_loss: 1.3287\n",
            "Step [3220/80000], d_real_loss: 0.0832, d_mnist_loss: 0.0347, d_svhn_loss: 0.0485, d_fake_loss: 0.1235, g_loss: 1.2878\n",
            "Step [3230/80000], d_real_loss: 0.3059, d_mnist_loss: 0.1509, d_svhn_loss: 0.1550, d_fake_loss: 0.3399, g_loss: 1.6923\n",
            "Step [3240/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0297, d_svhn_loss: 0.0540, d_fake_loss: 0.1547, g_loss: 0.9329\n",
            "Step [3250/80000], d_real_loss: 0.2333, d_mnist_loss: 0.1499, d_svhn_loss: 0.0834, d_fake_loss: 0.1248, g_loss: 1.1209\n",
            "Step [3260/80000], d_real_loss: 0.0936, d_mnist_loss: 0.0247, d_svhn_loss: 0.0689, d_fake_loss: 0.0726, g_loss: 1.1936\n",
            "Step [3270/80000], d_real_loss: 0.1307, d_mnist_loss: 0.0307, d_svhn_loss: 0.1000, d_fake_loss: 0.2815, g_loss: 1.7827\n",
            "Step [3280/80000], d_real_loss: 0.1585, d_mnist_loss: 0.0683, d_svhn_loss: 0.0901, d_fake_loss: 0.1082, g_loss: 1.2713\n",
            "Step [3290/80000], d_real_loss: 0.1050, d_mnist_loss: 0.0346, d_svhn_loss: 0.0703, d_fake_loss: 0.1903, g_loss: 1.3107\n",
            "Step [3300/80000], d_real_loss: 0.1818, d_mnist_loss: 0.1115, d_svhn_loss: 0.0703, d_fake_loss: 0.5336, g_loss: 1.7245\n",
            "Step [3310/80000], d_real_loss: 0.1541, d_mnist_loss: 0.0652, d_svhn_loss: 0.0889, d_fake_loss: 0.0854, g_loss: 1.1279\n",
            "Step [3320/80000], d_real_loss: 0.2872, d_mnist_loss: 0.2093, d_svhn_loss: 0.0779, d_fake_loss: 0.1264, g_loss: 1.3974\n",
            "Step [3330/80000], d_real_loss: 0.0818, d_mnist_loss: 0.0341, d_svhn_loss: 0.0477, d_fake_loss: 0.0772, g_loss: 1.1579\n",
            "Step [3340/80000], d_real_loss: 0.4977, d_mnist_loss: 0.0919, d_svhn_loss: 0.4058, d_fake_loss: 0.2919, g_loss: 1.2993\n",
            "Step [3350/80000], d_real_loss: 0.1022, d_mnist_loss: 0.0449, d_svhn_loss: 0.0573, d_fake_loss: 0.0757, g_loss: 0.9861\n",
            "Step [3360/80000], d_real_loss: 0.1256, d_mnist_loss: 0.0583, d_svhn_loss: 0.0673, d_fake_loss: 0.2353, g_loss: 1.2882\n",
            "Step [3370/80000], d_real_loss: 0.1235, d_mnist_loss: 0.0714, d_svhn_loss: 0.0521, d_fake_loss: 0.1790, g_loss: 0.6527\n",
            "Step [3380/80000], d_real_loss: 0.0817, d_mnist_loss: 0.0342, d_svhn_loss: 0.0475, d_fake_loss: 0.2779, g_loss: 1.4411\n",
            "Step [3390/80000], d_real_loss: 0.1199, d_mnist_loss: 0.0360, d_svhn_loss: 0.0839, d_fake_loss: 0.0974, g_loss: 1.1789\n",
            "Step [3400/80000], d_real_loss: 0.1127, d_mnist_loss: 0.0386, d_svhn_loss: 0.0741, d_fake_loss: 0.0874, g_loss: 1.0091\n",
            "Step [3410/80000], d_real_loss: 0.1614, d_mnist_loss: 0.0415, d_svhn_loss: 0.1199, d_fake_loss: 0.0929, g_loss: 0.9542\n",
            "Step [3420/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0384, d_svhn_loss: 0.0495, d_fake_loss: 0.0959, g_loss: 1.0941\n",
            "Step [3430/80000], d_real_loss: 0.2013, d_mnist_loss: 0.1457, d_svhn_loss: 0.0556, d_fake_loss: 0.0621, g_loss: 1.1683\n",
            "Step [3440/80000], d_real_loss: 0.1393, d_mnist_loss: 0.0754, d_svhn_loss: 0.0640, d_fake_loss: 0.2348, g_loss: 1.3601\n",
            "Step [3450/80000], d_real_loss: 0.1663, d_mnist_loss: 0.0433, d_svhn_loss: 0.1229, d_fake_loss: 0.1746, g_loss: 1.2735\n",
            "Step [3460/80000], d_real_loss: 0.2506, d_mnist_loss: 0.0343, d_svhn_loss: 0.2163, d_fake_loss: 0.0915, g_loss: 1.2674\n",
            "Step [3470/80000], d_real_loss: 0.1543, d_mnist_loss: 0.0920, d_svhn_loss: 0.0622, d_fake_loss: 0.1081, g_loss: 0.8416\n",
            "Step [3480/80000], d_real_loss: 0.1553, d_mnist_loss: 0.0669, d_svhn_loss: 0.0885, d_fake_loss: 0.0689, g_loss: 1.0774\n",
            "Step [3490/80000], d_real_loss: 0.2075, d_mnist_loss: 0.1015, d_svhn_loss: 0.1060, d_fake_loss: 0.3621, g_loss: 1.1611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [3500/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0342, d_svhn_loss: 0.0500, d_fake_loss: 0.1598, g_loss: 0.9354\n",
            "saved ./samples_fashion/sample-3500-m-s.png\n",
            "saved ./samples_fashion/sample-3500-s-m.png\n",
            "Step [3510/80000], d_real_loss: 0.1227, d_mnist_loss: 0.0329, d_svhn_loss: 0.0898, d_fake_loss: 0.1393, g_loss: 1.1779\n",
            "Step [3520/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0340, d_svhn_loss: 0.0561, d_fake_loss: 0.3091, g_loss: 1.2458\n",
            "Step [3530/80000], d_real_loss: 0.1149, d_mnist_loss: 0.0366, d_svhn_loss: 0.0784, d_fake_loss: 0.0553, g_loss: 1.3691\n",
            "Step [3540/80000], d_real_loss: 0.1670, d_mnist_loss: 0.1109, d_svhn_loss: 0.0562, d_fake_loss: 0.1178, g_loss: 1.5947\n",
            "Step [3550/80000], d_real_loss: 0.1354, d_mnist_loss: 0.0690, d_svhn_loss: 0.0664, d_fake_loss: 0.3226, g_loss: 2.0452\n",
            "Step [3560/80000], d_real_loss: 0.2001, d_mnist_loss: 0.0788, d_svhn_loss: 0.1214, d_fake_loss: 0.1600, g_loss: 1.5318\n",
            "Step [3570/80000], d_real_loss: 0.1209, d_mnist_loss: 0.0290, d_svhn_loss: 0.0919, d_fake_loss: 0.1263, g_loss: 1.4000\n",
            "Step [3580/80000], d_real_loss: 0.2433, d_mnist_loss: 0.0789, d_svhn_loss: 0.1644, d_fake_loss: 0.1132, g_loss: 1.0794\n",
            "Step [3590/80000], d_real_loss: 0.3019, d_mnist_loss: 0.0385, d_svhn_loss: 0.2634, d_fake_loss: 0.1108, g_loss: 1.2345\n",
            "Step [3600/80000], d_real_loss: 0.0881, d_mnist_loss: 0.0248, d_svhn_loss: 0.0633, d_fake_loss: 0.0837, g_loss: 1.2396\n",
            "Step [3610/80000], d_real_loss: 0.1265, d_mnist_loss: 0.0370, d_svhn_loss: 0.0895, d_fake_loss: 0.0551, g_loss: 1.4102\n",
            "Step [3620/80000], d_real_loss: 0.1253, d_mnist_loss: 0.0306, d_svhn_loss: 0.0947, d_fake_loss: 0.0820, g_loss: 0.9816\n",
            "Step [3630/80000], d_real_loss: 0.1023, d_mnist_loss: 0.0409, d_svhn_loss: 0.0614, d_fake_loss: 0.2894, g_loss: 1.8191\n",
            "Step [3640/80000], d_real_loss: 0.1337, d_mnist_loss: 0.0294, d_svhn_loss: 0.1043, d_fake_loss: 0.1066, g_loss: 0.9345\n",
            "Step [3650/80000], d_real_loss: 0.2591, d_mnist_loss: 0.0608, d_svhn_loss: 0.1983, d_fake_loss: 0.2648, g_loss: 1.9648\n",
            "Step [3660/80000], d_real_loss: 0.0821, d_mnist_loss: 0.0284, d_svhn_loss: 0.0537, d_fake_loss: 0.0870, g_loss: 1.5868\n",
            "Step [3670/80000], d_real_loss: 0.2980, d_mnist_loss: 0.1872, d_svhn_loss: 0.1108, d_fake_loss: 0.2145, g_loss: 2.1461\n",
            "Step [3680/80000], d_real_loss: 0.1174, d_mnist_loss: 0.0705, d_svhn_loss: 0.0469, d_fake_loss: 0.1002, g_loss: 1.2394\n",
            "Step [3690/80000], d_real_loss: 0.1638, d_mnist_loss: 0.0502, d_svhn_loss: 0.1136, d_fake_loss: 0.1250, g_loss: 0.9053\n",
            "Step [3700/80000], d_real_loss: 0.1847, d_mnist_loss: 0.0439, d_svhn_loss: 0.1408, d_fake_loss: 0.0767, g_loss: 1.4718\n",
            "Step [3710/80000], d_real_loss: 0.1830, d_mnist_loss: 0.0359, d_svhn_loss: 0.1471, d_fake_loss: 0.0754, g_loss: 1.4164\n",
            "Step [3720/80000], d_real_loss: 0.1751, d_mnist_loss: 0.0484, d_svhn_loss: 0.1267, d_fake_loss: 0.1395, g_loss: 1.2721\n",
            "Step [3730/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0283, d_svhn_loss: 0.0372, d_fake_loss: 0.0709, g_loss: 0.9613\n",
            "Step [3740/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0287, d_svhn_loss: 0.0580, d_fake_loss: 0.1079, g_loss: 1.6505\n",
            "Step [3750/80000], d_real_loss: 0.0961, d_mnist_loss: 0.0647, d_svhn_loss: 0.0314, d_fake_loss: 0.1832, g_loss: 1.3883\n",
            "Step [3760/80000], d_real_loss: 0.2021, d_mnist_loss: 0.0376, d_svhn_loss: 0.1645, d_fake_loss: 0.1062, g_loss: 0.7197\n",
            "Step [3770/80000], d_real_loss: 0.3531, d_mnist_loss: 0.2908, d_svhn_loss: 0.0622, d_fake_loss: 0.1432, g_loss: 1.2686\n",
            "Step [3780/80000], d_real_loss: 0.1036, d_mnist_loss: 0.0396, d_svhn_loss: 0.0640, d_fake_loss: 0.2053, g_loss: 1.5155\n",
            "Step [3790/80000], d_real_loss: 0.0894, d_mnist_loss: 0.0483, d_svhn_loss: 0.0410, d_fake_loss: 0.1813, g_loss: 1.1790\n",
            "Step [3800/80000], d_real_loss: 0.1060, d_mnist_loss: 0.0263, d_svhn_loss: 0.0798, d_fake_loss: 0.0849, g_loss: 1.1067\n",
            "Step [3810/80000], d_real_loss: 0.2804, d_mnist_loss: 0.0345, d_svhn_loss: 0.2459, d_fake_loss: 0.2013, g_loss: 1.2342\n",
            "Step [3820/80000], d_real_loss: 0.0828, d_mnist_loss: 0.0348, d_svhn_loss: 0.0480, d_fake_loss: 0.2086, g_loss: 1.4445\n",
            "Step [3830/80000], d_real_loss: 0.1868, d_mnist_loss: 0.1197, d_svhn_loss: 0.0671, d_fake_loss: 0.1837, g_loss: 1.2174\n",
            "Step [3840/80000], d_real_loss: 0.1683, d_mnist_loss: 0.0603, d_svhn_loss: 0.1080, d_fake_loss: 0.1445, g_loss: 0.9808\n",
            "Step [3850/80000], d_real_loss: 0.1378, d_mnist_loss: 0.0343, d_svhn_loss: 0.1035, d_fake_loss: 0.1070, g_loss: 0.9791\n",
            "Step [3860/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0314, d_svhn_loss: 0.0326, d_fake_loss: 0.1758, g_loss: 0.7946\n",
            "Step [3870/80000], d_real_loss: 0.2103, d_mnist_loss: 0.0304, d_svhn_loss: 0.1799, d_fake_loss: 0.2029, g_loss: 1.1189\n",
            "Step [3880/80000], d_real_loss: 0.3450, d_mnist_loss: 0.1710, d_svhn_loss: 0.1740, d_fake_loss: 0.1678, g_loss: 1.5560\n",
            "Step [3890/80000], d_real_loss: 0.1029, d_mnist_loss: 0.0520, d_svhn_loss: 0.0509, d_fake_loss: 0.0690, g_loss: 1.3294\n",
            "Step [3900/80000], d_real_loss: 0.4269, d_mnist_loss: 0.1082, d_svhn_loss: 0.3187, d_fake_loss: 0.1568, g_loss: 1.3141\n",
            "Step [3910/80000], d_real_loss: 0.1861, d_mnist_loss: 0.0677, d_svhn_loss: 0.1184, d_fake_loss: 0.2795, g_loss: 0.8433\n",
            "Step [3920/80000], d_real_loss: 0.1254, d_mnist_loss: 0.0385, d_svhn_loss: 0.0870, d_fake_loss: 0.1297, g_loss: 1.4504\n",
            "Step [3930/80000], d_real_loss: 0.2547, d_mnist_loss: 0.2142, d_svhn_loss: 0.0405, d_fake_loss: 0.1933, g_loss: 1.2162\n",
            "Step [3940/80000], d_real_loss: 0.1103, d_mnist_loss: 0.0304, d_svhn_loss: 0.0799, d_fake_loss: 0.0736, g_loss: 1.1354\n",
            "Step [3950/80000], d_real_loss: 0.1088, d_mnist_loss: 0.0386, d_svhn_loss: 0.0702, d_fake_loss: 0.0575, g_loss: 1.0998\n",
            "Step [3960/80000], d_real_loss: 0.1009, d_mnist_loss: 0.0327, d_svhn_loss: 0.0682, d_fake_loss: 0.0900, g_loss: 1.0798\n",
            "Step [3970/80000], d_real_loss: 0.0873, d_mnist_loss: 0.0361, d_svhn_loss: 0.0512, d_fake_loss: 0.0908, g_loss: 1.1848\n",
            "Step [3980/80000], d_real_loss: 0.2403, d_mnist_loss: 0.0363, d_svhn_loss: 0.2041, d_fake_loss: 0.1805, g_loss: 1.3765\n",
            "Step [3990/80000], d_real_loss: 0.1999, d_mnist_loss: 0.1477, d_svhn_loss: 0.0521, d_fake_loss: 0.1519, g_loss: 2.0269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [4000/80000], d_real_loss: 0.0976, d_mnist_loss: 0.0355, d_svhn_loss: 0.0621, d_fake_loss: 0.0536, g_loss: 1.1650\n",
            "saved ./samples_fashion/sample-4000-m-s.png\n",
            "saved ./samples_fashion/sample-4000-s-m.png\n",
            "Step [4010/80000], d_real_loss: 0.2260, d_mnist_loss: 0.0334, d_svhn_loss: 0.1926, d_fake_loss: 0.1834, g_loss: 1.4610\n",
            "Step [4020/80000], d_real_loss: 0.1448, d_mnist_loss: 0.0804, d_svhn_loss: 0.0644, d_fake_loss: 0.1792, g_loss: 1.5738\n",
            "Step [4030/80000], d_real_loss: 0.1873, d_mnist_loss: 0.0436, d_svhn_loss: 0.1437, d_fake_loss: 0.2779, g_loss: 1.3394\n",
            "Step [4040/80000], d_real_loss: 0.1028, d_mnist_loss: 0.0424, d_svhn_loss: 0.0604, d_fake_loss: 0.1133, g_loss: 1.5392\n",
            "Step [4050/80000], d_real_loss: 0.2046, d_mnist_loss: 0.0973, d_svhn_loss: 0.1073, d_fake_loss: 0.1709, g_loss: 1.4192\n",
            "Step [4060/80000], d_real_loss: 0.1853, d_mnist_loss: 0.0340, d_svhn_loss: 0.1513, d_fake_loss: 0.2977, g_loss: 0.9481\n",
            "Step [4070/80000], d_real_loss: 0.0828, d_mnist_loss: 0.0378, d_svhn_loss: 0.0450, d_fake_loss: 0.0664, g_loss: 1.1973\n",
            "Step [4080/80000], d_real_loss: 0.4356, d_mnist_loss: 0.0235, d_svhn_loss: 0.4121, d_fake_loss: 0.1125, g_loss: 1.0339\n",
            "Step [4090/80000], d_real_loss: 0.1388, d_mnist_loss: 0.0372, d_svhn_loss: 0.1017, d_fake_loss: 0.4431, g_loss: 1.5417\n",
            "Step [4100/80000], d_real_loss: 0.0818, d_mnist_loss: 0.0446, d_svhn_loss: 0.0372, d_fake_loss: 0.0699, g_loss: 1.4610\n",
            "Step [4110/80000], d_real_loss: 0.0886, d_mnist_loss: 0.0344, d_svhn_loss: 0.0542, d_fake_loss: 0.1154, g_loss: 1.2981\n",
            "Step [4120/80000], d_real_loss: 0.1391, d_mnist_loss: 0.0664, d_svhn_loss: 0.0727, d_fake_loss: 0.1546, g_loss: 0.9135\n",
            "Step [4130/80000], d_real_loss: 0.1084, d_mnist_loss: 0.0426, d_svhn_loss: 0.0658, d_fake_loss: 0.1242, g_loss: 1.1618\n",
            "Step [4140/80000], d_real_loss: 0.1067, d_mnist_loss: 0.0254, d_svhn_loss: 0.0814, d_fake_loss: 0.1501, g_loss: 1.1107\n",
            "Step [4150/80000], d_real_loss: 0.2181, d_mnist_loss: 0.0651, d_svhn_loss: 0.1530, d_fake_loss: 0.1219, g_loss: 1.4967\n",
            "Step [4160/80000], d_real_loss: 0.1739, d_mnist_loss: 0.0760, d_svhn_loss: 0.0979, d_fake_loss: 0.1489, g_loss: 0.9153\n",
            "Step [4170/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0193, d_svhn_loss: 0.0565, d_fake_loss: 0.0693, g_loss: 1.3617\n",
            "Step [4180/80000], d_real_loss: 0.0869, d_mnist_loss: 0.0263, d_svhn_loss: 0.0607, d_fake_loss: 0.1385, g_loss: 0.7186\n",
            "Step [4190/80000], d_real_loss: 0.8030, d_mnist_loss: 0.1120, d_svhn_loss: 0.6910, d_fake_loss: 0.6273, g_loss: 1.2017\n",
            "Step [4200/80000], d_real_loss: 0.1030, d_mnist_loss: 0.0315, d_svhn_loss: 0.0715, d_fake_loss: 0.0677, g_loss: 1.2196\n",
            "Step [4210/80000], d_real_loss: 0.1831, d_mnist_loss: 0.0266, d_svhn_loss: 0.1565, d_fake_loss: 0.1097, g_loss: 1.3298\n",
            "Step [4220/80000], d_real_loss: 0.2269, d_mnist_loss: 0.1141, d_svhn_loss: 0.1127, d_fake_loss: 0.0860, g_loss: 1.1036\n",
            "Step [4230/80000], d_real_loss: 0.1322, d_mnist_loss: 0.0411, d_svhn_loss: 0.0911, d_fake_loss: 0.0949, g_loss: 1.1064\n",
            "Step [4240/80000], d_real_loss: 0.2472, d_mnist_loss: 0.0258, d_svhn_loss: 0.2214, d_fake_loss: 0.1250, g_loss: 1.4743\n",
            "Step [4250/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0369, d_svhn_loss: 0.0464, d_fake_loss: 0.0947, g_loss: 1.1662\n",
            "Step [4260/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0283, d_svhn_loss: 0.0482, d_fake_loss: 0.1156, g_loss: 0.8899\n",
            "Step [4270/80000], d_real_loss: 0.1653, d_mnist_loss: 0.0612, d_svhn_loss: 0.1042, d_fake_loss: 0.1141, g_loss: 1.3980\n",
            "Step [4280/80000], d_real_loss: 0.0832, d_mnist_loss: 0.0467, d_svhn_loss: 0.0365, d_fake_loss: 0.7047, g_loss: 2.1932\n",
            "Step [4290/80000], d_real_loss: 0.1641, d_mnist_loss: 0.0446, d_svhn_loss: 0.1194, d_fake_loss: 0.0673, g_loss: 1.2093\n",
            "Step [4300/80000], d_real_loss: 0.1652, d_mnist_loss: 0.0710, d_svhn_loss: 0.0942, d_fake_loss: 0.1414, g_loss: 1.1229\n",
            "Step [4310/80000], d_real_loss: 0.1819, d_mnist_loss: 0.0929, d_svhn_loss: 0.0891, d_fake_loss: 0.2373, g_loss: 1.2000\n",
            "Step [4320/80000], d_real_loss: 0.1118, d_mnist_loss: 0.0309, d_svhn_loss: 0.0810, d_fake_loss: 0.1278, g_loss: 1.6933\n",
            "Step [4330/80000], d_real_loss: 0.2163, d_mnist_loss: 0.0680, d_svhn_loss: 0.1483, d_fake_loss: 0.0853, g_loss: 1.0633\n",
            "Step [4340/80000], d_real_loss: 0.1203, d_mnist_loss: 0.0313, d_svhn_loss: 0.0890, d_fake_loss: 0.0982, g_loss: 1.5001\n",
            "Step [4350/80000], d_real_loss: 0.0853, d_mnist_loss: 0.0369, d_svhn_loss: 0.0485, d_fake_loss: 0.1369, g_loss: 1.1685\n",
            "Step [4360/80000], d_real_loss: 0.1041, d_mnist_loss: 0.0432, d_svhn_loss: 0.0609, d_fake_loss: 0.1080, g_loss: 1.0001\n",
            "Step [4370/80000], d_real_loss: 0.2054, d_mnist_loss: 0.1168, d_svhn_loss: 0.0886, d_fake_loss: 0.1008, g_loss: 1.2448\n",
            "Step [4380/80000], d_real_loss: 0.1167, d_mnist_loss: 0.0538, d_svhn_loss: 0.0628, d_fake_loss: 0.0866, g_loss: 1.2310\n",
            "Step [4390/80000], d_real_loss: 0.1825, d_mnist_loss: 0.0560, d_svhn_loss: 0.1265, d_fake_loss: 0.1649, g_loss: 1.1851\n",
            "Step [4400/80000], d_real_loss: 0.1720, d_mnist_loss: 0.0999, d_svhn_loss: 0.0721, d_fake_loss: 0.0996, g_loss: 1.0050\n",
            "Step [4410/80000], d_real_loss: 0.0978, d_mnist_loss: 0.0326, d_svhn_loss: 0.0653, d_fake_loss: 0.1485, g_loss: 1.2084\n",
            "Step [4420/80000], d_real_loss: 0.1358, d_mnist_loss: 0.0854, d_svhn_loss: 0.0504, d_fake_loss: 0.2657, g_loss: 1.4763\n",
            "Step [4430/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0270, d_svhn_loss: 0.0467, d_fake_loss: 0.0650, g_loss: 1.1116\n",
            "Step [4440/80000], d_real_loss: 0.1019, d_mnist_loss: 0.0402, d_svhn_loss: 0.0617, d_fake_loss: 0.0979, g_loss: 1.3527\n",
            "Step [4450/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0245, d_svhn_loss: 0.0423, d_fake_loss: 0.1369, g_loss: 1.4203\n",
            "Step [4460/80000], d_real_loss: 0.1464, d_mnist_loss: 0.0304, d_svhn_loss: 0.1160, d_fake_loss: 0.1469, g_loss: 0.7071\n",
            "Step [4470/80000], d_real_loss: 0.1792, d_mnist_loss: 0.0173, d_svhn_loss: 0.1619, d_fake_loss: 0.4227, g_loss: 1.2171\n",
            "Step [4480/80000], d_real_loss: 0.1084, d_mnist_loss: 0.0199, d_svhn_loss: 0.0885, d_fake_loss: 0.0602, g_loss: 1.2730\n",
            "Step [4490/80000], d_real_loss: 0.1990, d_mnist_loss: 0.1085, d_svhn_loss: 0.0905, d_fake_loss: 0.2589, g_loss: 1.3715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [4500/80000], d_real_loss: 0.1129, d_mnist_loss: 0.0277, d_svhn_loss: 0.0852, d_fake_loss: 0.1500, g_loss: 1.0602\n",
            "saved ./samples_fashion/sample-4500-m-s.png\n",
            "saved ./samples_fashion/sample-4500-s-m.png\n",
            "Step [4510/80000], d_real_loss: 0.1083, d_mnist_loss: 0.0630, d_svhn_loss: 0.0452, d_fake_loss: 0.2026, g_loss: 1.6456\n",
            "Step [4520/80000], d_real_loss: 0.1423, d_mnist_loss: 0.0938, d_svhn_loss: 0.0485, d_fake_loss: 0.1509, g_loss: 1.3744\n",
            "Step [4530/80000], d_real_loss: 0.3548, d_mnist_loss: 0.0258, d_svhn_loss: 0.3289, d_fake_loss: 0.0730, g_loss: 1.0275\n",
            "Step [4540/80000], d_real_loss: 0.1933, d_mnist_loss: 0.0799, d_svhn_loss: 0.1135, d_fake_loss: 0.1500, g_loss: 1.6179\n",
            "Step [4550/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0236, d_svhn_loss: 0.0396, d_fake_loss: 0.0546, g_loss: 1.4241\n",
            "Step [4560/80000], d_real_loss: 0.2587, d_mnist_loss: 0.2017, d_svhn_loss: 0.0570, d_fake_loss: 0.1957, g_loss: 1.4106\n",
            "Step [4570/80000], d_real_loss: 0.1381, d_mnist_loss: 0.0363, d_svhn_loss: 0.1018, d_fake_loss: 0.1022, g_loss: 0.8740\n",
            "Step [4580/80000], d_real_loss: 0.1185, d_mnist_loss: 0.0680, d_svhn_loss: 0.0504, d_fake_loss: 0.2497, g_loss: 1.4006\n",
            "Step [4590/80000], d_real_loss: 0.1370, d_mnist_loss: 0.0789, d_svhn_loss: 0.0581, d_fake_loss: 0.1560, g_loss: 0.9570\n",
            "Step [4600/80000], d_real_loss: 0.2299, d_mnist_loss: 0.1422, d_svhn_loss: 0.0877, d_fake_loss: 0.1642, g_loss: 1.0994\n",
            "Step [4610/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0189, d_svhn_loss: 0.0441, d_fake_loss: 0.0713, g_loss: 1.3371\n",
            "Step [4620/80000], d_real_loss: 0.2478, d_mnist_loss: 0.0400, d_svhn_loss: 0.2078, d_fake_loss: 0.1173, g_loss: 1.1959\n",
            "Step [4630/80000], d_real_loss: 0.1629, d_mnist_loss: 0.0490, d_svhn_loss: 0.1139, d_fake_loss: 0.0853, g_loss: 0.9246\n",
            "Step [4640/80000], d_real_loss: 0.1091, d_mnist_loss: 0.0291, d_svhn_loss: 0.0800, d_fake_loss: 0.0745, g_loss: 1.3446\n",
            "Step [4650/80000], d_real_loss: 0.1283, d_mnist_loss: 0.0821, d_svhn_loss: 0.0463, d_fake_loss: 0.1105, g_loss: 1.3673\n",
            "Step [4660/80000], d_real_loss: 0.3092, d_mnist_loss: 0.1065, d_svhn_loss: 0.2027, d_fake_loss: 0.0890, g_loss: 1.3523\n",
            "Step [4670/80000], d_real_loss: 0.0872, d_mnist_loss: 0.0210, d_svhn_loss: 0.0662, d_fake_loss: 0.0648, g_loss: 0.9746\n",
            "Step [4680/80000], d_real_loss: 0.1500, d_mnist_loss: 0.0276, d_svhn_loss: 0.1224, d_fake_loss: 0.2326, g_loss: 1.3410\n",
            "Step [4690/80000], d_real_loss: 0.1474, d_mnist_loss: 0.0206, d_svhn_loss: 0.1268, d_fake_loss: 0.0869, g_loss: 1.4972\n",
            "Step [4700/80000], d_real_loss: 0.1249, d_mnist_loss: 0.0669, d_svhn_loss: 0.0580, d_fake_loss: 0.1337, g_loss: 1.4952\n",
            "Step [4710/80000], d_real_loss: 0.1031, d_mnist_loss: 0.0605, d_svhn_loss: 0.0425, d_fake_loss: 0.1194, g_loss: 0.9214\n",
            "Step [4720/80000], d_real_loss: 0.0957, d_mnist_loss: 0.0336, d_svhn_loss: 0.0621, d_fake_loss: 0.1629, g_loss: 1.8309\n",
            "Step [4730/80000], d_real_loss: 0.0809, d_mnist_loss: 0.0176, d_svhn_loss: 0.0633, d_fake_loss: 0.2109, g_loss: 1.3810\n",
            "Step [4740/80000], d_real_loss: 0.2175, d_mnist_loss: 0.0375, d_svhn_loss: 0.1800, d_fake_loss: 0.2397, g_loss: 1.5955\n",
            "Step [4750/80000], d_real_loss: 0.1099, d_mnist_loss: 0.0401, d_svhn_loss: 0.0698, d_fake_loss: 0.0820, g_loss: 1.3531\n",
            "Step [4760/80000], d_real_loss: 0.3879, d_mnist_loss: 0.0321, d_svhn_loss: 0.3558, d_fake_loss: 0.2488, g_loss: 1.2725\n",
            "Step [4770/80000], d_real_loss: 0.1183, d_mnist_loss: 0.0661, d_svhn_loss: 0.0522, d_fake_loss: 0.2446, g_loss: 0.7524\n",
            "Step [4780/80000], d_real_loss: 0.1347, d_mnist_loss: 0.0291, d_svhn_loss: 0.1056, d_fake_loss: 0.1178, g_loss: 1.0916\n",
            "Step [4790/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0254, d_svhn_loss: 0.0592, d_fake_loss: 0.0764, g_loss: 1.4650\n",
            "Step [4800/80000], d_real_loss: 0.2574, d_mnist_loss: 0.1990, d_svhn_loss: 0.0584, d_fake_loss: 0.1201, g_loss: 1.6004\n",
            "Step [4810/80000], d_real_loss: 0.0828, d_mnist_loss: 0.0208, d_svhn_loss: 0.0620, d_fake_loss: 0.1564, g_loss: 0.8099\n",
            "Step [4820/80000], d_real_loss: 0.3798, d_mnist_loss: 0.0518, d_svhn_loss: 0.3280, d_fake_loss: 0.0666, g_loss: 1.3747\n",
            "Step [4830/80000], d_real_loss: 0.1066, d_mnist_loss: 0.0424, d_svhn_loss: 0.0641, d_fake_loss: 0.1418, g_loss: 1.1585\n",
            "Step [4840/80000], d_real_loss: 0.1282, d_mnist_loss: 0.0695, d_svhn_loss: 0.0587, d_fake_loss: 0.1088, g_loss: 1.1164\n",
            "Step [4850/80000], d_real_loss: 0.3021, d_mnist_loss: 0.0719, d_svhn_loss: 0.2302, d_fake_loss: 0.2218, g_loss: 1.2887\n",
            "Step [4860/80000], d_real_loss: 0.0816, d_mnist_loss: 0.0346, d_svhn_loss: 0.0469, d_fake_loss: 0.1243, g_loss: 0.8112\n",
            "Step [4870/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0212, d_svhn_loss: 0.0583, d_fake_loss: 0.0960, g_loss: 1.1396\n",
            "Step [4880/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0435, d_svhn_loss: 0.0414, d_fake_loss: 0.1208, g_loss: 1.1815\n",
            "Step [4890/80000], d_real_loss: 0.1128, d_mnist_loss: 0.0639, d_svhn_loss: 0.0489, d_fake_loss: 0.4099, g_loss: 2.0103\n",
            "Step [4900/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0332, d_svhn_loss: 0.0480, d_fake_loss: 0.3304, g_loss: 1.6967\n",
            "Step [4910/80000], d_real_loss: 0.1569, d_mnist_loss: 0.0773, d_svhn_loss: 0.0796, d_fake_loss: 0.1894, g_loss: 1.4836\n",
            "Step [4920/80000], d_real_loss: 0.1679, d_mnist_loss: 0.0220, d_svhn_loss: 0.1458, d_fake_loss: 0.1107, g_loss: 1.6089\n",
            "Step [4930/80000], d_real_loss: 0.1954, d_mnist_loss: 0.0621, d_svhn_loss: 0.1333, d_fake_loss: 0.3222, g_loss: 1.5569\n",
            "Step [4940/80000], d_real_loss: 0.0895, d_mnist_loss: 0.0329, d_svhn_loss: 0.0566, d_fake_loss: 0.0866, g_loss: 1.1399\n",
            "Step [4950/80000], d_real_loss: 0.1981, d_mnist_loss: 0.0275, d_svhn_loss: 0.1706, d_fake_loss: 0.1572, g_loss: 1.0905\n",
            "Step [4960/80000], d_real_loss: 0.1549, d_mnist_loss: 0.0640, d_svhn_loss: 0.0910, d_fake_loss: 0.0591, g_loss: 1.2225\n",
            "Step [4970/80000], d_real_loss: 0.2433, d_mnist_loss: 0.2028, d_svhn_loss: 0.0404, d_fake_loss: 0.0784, g_loss: 1.0220\n",
            "Step [4980/80000], d_real_loss: 0.1603, d_mnist_loss: 0.0456, d_svhn_loss: 0.1147, d_fake_loss: 0.2913, g_loss: 1.6123\n",
            "Step [4990/80000], d_real_loss: 0.0931, d_mnist_loss: 0.0262, d_svhn_loss: 0.0669, d_fake_loss: 0.0781, g_loss: 1.4149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [5000/80000], d_real_loss: 0.1128, d_mnist_loss: 0.0451, d_svhn_loss: 0.0677, d_fake_loss: 0.0959, g_loss: 0.9991\n",
            "saved ./samples_fashion/sample-5000-m-s.png\n",
            "saved ./samples_fashion/sample-5000-s-m.png\n",
            "Step [5010/80000], d_real_loss: 0.2061, d_mnist_loss: 0.0336, d_svhn_loss: 0.1725, d_fake_loss: 0.2115, g_loss: 1.3569\n",
            "Step [5020/80000], d_real_loss: 0.1757, d_mnist_loss: 0.0169, d_svhn_loss: 0.1589, d_fake_loss: 0.0899, g_loss: 1.3000\n",
            "Step [5030/80000], d_real_loss: 0.2318, d_mnist_loss: 0.1118, d_svhn_loss: 0.1201, d_fake_loss: 0.1030, g_loss: 1.2044\n",
            "Step [5040/80000], d_real_loss: 0.0998, d_mnist_loss: 0.0211, d_svhn_loss: 0.0787, d_fake_loss: 0.1034, g_loss: 1.1883\n",
            "Step [5050/80000], d_real_loss: 0.1600, d_mnist_loss: 0.0937, d_svhn_loss: 0.0663, d_fake_loss: 0.0699, g_loss: 1.4127\n",
            "Step [5060/80000], d_real_loss: 0.0852, d_mnist_loss: 0.0285, d_svhn_loss: 0.0567, d_fake_loss: 0.3078, g_loss: 1.7774\n",
            "Step [5070/80000], d_real_loss: 0.1448, d_mnist_loss: 0.0216, d_svhn_loss: 0.1231, d_fake_loss: 0.0757, g_loss: 1.1561\n",
            "Step [5080/80000], d_real_loss: 0.1334, d_mnist_loss: 0.0705, d_svhn_loss: 0.0629, d_fake_loss: 0.1552, g_loss: 1.5311\n",
            "Step [5090/80000], d_real_loss: 0.1760, d_mnist_loss: 0.0873, d_svhn_loss: 0.0887, d_fake_loss: 0.1015, g_loss: 1.4234\n",
            "Step [5100/80000], d_real_loss: 0.0759, d_mnist_loss: 0.0295, d_svhn_loss: 0.0464, d_fake_loss: 0.0669, g_loss: 1.2039\n",
            "Step [5110/80000], d_real_loss: 0.2268, d_mnist_loss: 0.0671, d_svhn_loss: 0.1597, d_fake_loss: 0.1009, g_loss: 1.3667\n",
            "Step [5120/80000], d_real_loss: 0.1033, d_mnist_loss: 0.0269, d_svhn_loss: 0.0764, d_fake_loss: 0.1049, g_loss: 1.1002\n",
            "Step [5130/80000], d_real_loss: 0.1810, d_mnist_loss: 0.1317, d_svhn_loss: 0.0493, d_fake_loss: 0.1374, g_loss: 1.5786\n",
            "Step [5140/80000], d_real_loss: 0.3338, d_mnist_loss: 0.1421, d_svhn_loss: 0.1917, d_fake_loss: 0.4737, g_loss: 1.1977\n",
            "Step [5150/80000], d_real_loss: 0.1281, d_mnist_loss: 0.0307, d_svhn_loss: 0.0974, d_fake_loss: 0.1032, g_loss: 1.2268\n",
            "Step [5160/80000], d_real_loss: 0.1195, d_mnist_loss: 0.0308, d_svhn_loss: 0.0887, d_fake_loss: 0.3471, g_loss: 1.1008\n",
            "Step [5170/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0256, d_svhn_loss: 0.0458, d_fake_loss: 0.0921, g_loss: 1.2383\n",
            "Step [5180/80000], d_real_loss: 0.1130, d_mnist_loss: 0.0368, d_svhn_loss: 0.0762, d_fake_loss: 0.0908, g_loss: 0.9842\n",
            "Step [5190/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0334, d_svhn_loss: 0.0443, d_fake_loss: 0.1418, g_loss: 1.1387\n",
            "Step [5200/80000], d_real_loss: 0.0929, d_mnist_loss: 0.0155, d_svhn_loss: 0.0775, d_fake_loss: 0.2331, g_loss: 1.4878\n",
            "Step [5210/80000], d_real_loss: 0.0789, d_mnist_loss: 0.0246, d_svhn_loss: 0.0544, d_fake_loss: 0.1109, g_loss: 1.6017\n",
            "Step [5220/80000], d_real_loss: 0.1180, d_mnist_loss: 0.0253, d_svhn_loss: 0.0928, d_fake_loss: 0.1235, g_loss: 1.2898\n",
            "Step [5230/80000], d_real_loss: 0.2316, d_mnist_loss: 0.1404, d_svhn_loss: 0.0912, d_fake_loss: 0.1522, g_loss: 1.3773\n",
            "Step [5240/80000], d_real_loss: 0.1687, d_mnist_loss: 0.0284, d_svhn_loss: 0.1403, d_fake_loss: 0.0648, g_loss: 1.0787\n",
            "Step [5250/80000], d_real_loss: 0.1401, d_mnist_loss: 0.0283, d_svhn_loss: 0.1118, d_fake_loss: 0.2802, g_loss: 1.4481\n",
            "Step [5260/80000], d_real_loss: 0.1749, d_mnist_loss: 0.0828, d_svhn_loss: 0.0921, d_fake_loss: 0.1959, g_loss: 1.5269\n",
            "Step [5270/80000], d_real_loss: 0.1395, d_mnist_loss: 0.0684, d_svhn_loss: 0.0711, d_fake_loss: 0.1701, g_loss: 1.4803\n",
            "Step [5280/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0168, d_svhn_loss: 0.0582, d_fake_loss: 0.0692, g_loss: 1.3635\n",
            "Step [5290/80000], d_real_loss: 0.1522, d_mnist_loss: 0.0274, d_svhn_loss: 0.1248, d_fake_loss: 0.2938, g_loss: 1.3768\n",
            "Step [5300/80000], d_real_loss: 0.2068, d_mnist_loss: 0.0495, d_svhn_loss: 0.1573, d_fake_loss: 0.1381, g_loss: 1.0886\n",
            "Step [5310/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0313, d_svhn_loss: 0.0470, d_fake_loss: 0.0875, g_loss: 0.8570\n",
            "Step [5320/80000], d_real_loss: 0.1097, d_mnist_loss: 0.0620, d_svhn_loss: 0.0478, d_fake_loss: 0.0826, g_loss: 1.2051\n",
            "Step [5330/80000], d_real_loss: 0.1020, d_mnist_loss: 0.0490, d_svhn_loss: 0.0530, d_fake_loss: 0.0573, g_loss: 0.9981\n",
            "Step [5340/80000], d_real_loss: 0.0705, d_mnist_loss: 0.0301, d_svhn_loss: 0.0404, d_fake_loss: 0.0832, g_loss: 1.2417\n",
            "Step [5350/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0450, d_svhn_loss: 0.0465, d_fake_loss: 0.1014, g_loss: 0.7950\n",
            "Step [5360/80000], d_real_loss: 0.1081, d_mnist_loss: 0.0644, d_svhn_loss: 0.0437, d_fake_loss: 0.0894, g_loss: 0.9771\n",
            "Step [5370/80000], d_real_loss: 0.1329, d_mnist_loss: 0.0752, d_svhn_loss: 0.0577, d_fake_loss: 0.1803, g_loss: 1.3598\n",
            "Step [5380/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0224, d_svhn_loss: 0.0492, d_fake_loss: 0.0810, g_loss: 1.1609\n",
            "Step [5390/80000], d_real_loss: 0.1096, d_mnist_loss: 0.0437, d_svhn_loss: 0.0659, d_fake_loss: 0.1454, g_loss: 1.0169\n",
            "Step [5400/80000], d_real_loss: 0.1033, d_mnist_loss: 0.0335, d_svhn_loss: 0.0699, d_fake_loss: 0.0843, g_loss: 1.4281\n",
            "Step [5410/80000], d_real_loss: 0.2731, d_mnist_loss: 0.0230, d_svhn_loss: 0.2501, d_fake_loss: 0.9940, g_loss: 1.5267\n",
            "Step [5420/80000], d_real_loss: 0.1976, d_mnist_loss: 0.1450, d_svhn_loss: 0.0526, d_fake_loss: 0.3442, g_loss: 1.3085\n",
            "Step [5430/80000], d_real_loss: 0.2089, d_mnist_loss: 0.0291, d_svhn_loss: 0.1798, d_fake_loss: 0.1240, g_loss: 1.0736\n",
            "Step [5440/80000], d_real_loss: 0.1188, d_mnist_loss: 0.0627, d_svhn_loss: 0.0561, d_fake_loss: 0.1328, g_loss: 1.2538\n",
            "Step [5450/80000], d_real_loss: 0.0962, d_mnist_loss: 0.0440, d_svhn_loss: 0.0522, d_fake_loss: 0.1066, g_loss: 1.1802\n",
            "Step [5460/80000], d_real_loss: 0.2219, d_mnist_loss: 0.1067, d_svhn_loss: 0.1152, d_fake_loss: 0.0866, g_loss: 0.9942\n",
            "Step [5470/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0209, d_svhn_loss: 0.0439, d_fake_loss: 0.1083, g_loss: 1.2672\n",
            "Step [5480/80000], d_real_loss: 0.2120, d_mnist_loss: 0.1429, d_svhn_loss: 0.0691, d_fake_loss: 0.1548, g_loss: 1.8470\n",
            "Step [5490/80000], d_real_loss: 0.1413, d_mnist_loss: 0.0704, d_svhn_loss: 0.0708, d_fake_loss: 0.1515, g_loss: 1.0515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [5500/80000], d_real_loss: 0.2044, d_mnist_loss: 0.0955, d_svhn_loss: 0.1089, d_fake_loss: 0.1634, g_loss: 1.6575\n",
            "saved ./samples_fashion/sample-5500-m-s.png\n",
            "saved ./samples_fashion/sample-5500-s-m.png\n",
            "Step [5510/80000], d_real_loss: 0.1468, d_mnist_loss: 0.0275, d_svhn_loss: 0.1193, d_fake_loss: 0.2985, g_loss: 1.2079\n",
            "Step [5520/80000], d_real_loss: 0.1379, d_mnist_loss: 0.0444, d_svhn_loss: 0.0934, d_fake_loss: 0.1385, g_loss: 0.8486\n",
            "Step [5530/80000], d_real_loss: 0.1478, d_mnist_loss: 0.0402, d_svhn_loss: 0.1077, d_fake_loss: 0.1263, g_loss: 0.9267\n",
            "Step [5540/80000], d_real_loss: 0.1893, d_mnist_loss: 0.1525, d_svhn_loss: 0.0367, d_fake_loss: 0.1790, g_loss: 1.6483\n",
            "Step [5550/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0294, d_svhn_loss: 0.0402, d_fake_loss: 0.1274, g_loss: 1.5309\n",
            "Step [5560/80000], d_real_loss: 0.1620, d_mnist_loss: 0.0452, d_svhn_loss: 0.1168, d_fake_loss: 0.0810, g_loss: 1.2763\n",
            "Step [5570/80000], d_real_loss: 0.1004, d_mnist_loss: 0.0262, d_svhn_loss: 0.0742, d_fake_loss: 0.0880, g_loss: 1.3225\n",
            "Step [5580/80000], d_real_loss: 0.1760, d_mnist_loss: 0.0401, d_svhn_loss: 0.1359, d_fake_loss: 0.2290, g_loss: 0.8836\n",
            "Step [5590/80000], d_real_loss: 0.2032, d_mnist_loss: 0.0459, d_svhn_loss: 0.1573, d_fake_loss: 0.0994, g_loss: 0.9897\n",
            "Step [5600/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0203, d_svhn_loss: 0.0370, d_fake_loss: 0.0638, g_loss: 1.0302\n",
            "Step [5610/80000], d_real_loss: 0.1216, d_mnist_loss: 0.0448, d_svhn_loss: 0.0768, d_fake_loss: 0.1665, g_loss: 1.3278\n",
            "Step [5620/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0302, d_svhn_loss: 0.0354, d_fake_loss: 0.1152, g_loss: 1.1465\n",
            "Step [5630/80000], d_real_loss: 0.0757, d_mnist_loss: 0.0252, d_svhn_loss: 0.0505, d_fake_loss: 0.0576, g_loss: 1.0832\n",
            "Step [5640/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0414, d_svhn_loss: 0.0286, d_fake_loss: 0.1135, g_loss: 1.3647\n",
            "Step [5650/80000], d_real_loss: 0.2742, d_mnist_loss: 0.0247, d_svhn_loss: 0.2495, d_fake_loss: 0.1129, g_loss: 1.1669\n",
            "Step [5660/80000], d_real_loss: 0.6642, d_mnist_loss: 0.0260, d_svhn_loss: 0.6382, d_fake_loss: 0.4708, g_loss: 1.2692\n",
            "Step [5670/80000], d_real_loss: 0.1260, d_mnist_loss: 0.0536, d_svhn_loss: 0.0724, d_fake_loss: 0.1030, g_loss: 1.2368\n",
            "Step [5680/80000], d_real_loss: 0.1175, d_mnist_loss: 0.0302, d_svhn_loss: 0.0873, d_fake_loss: 0.0516, g_loss: 1.1753\n",
            "Step [5690/80000], d_real_loss: 0.3501, d_mnist_loss: 0.0384, d_svhn_loss: 0.3117, d_fake_loss: 0.0897, g_loss: 1.1552\n",
            "Step [5700/80000], d_real_loss: 0.0821, d_mnist_loss: 0.0326, d_svhn_loss: 0.0495, d_fake_loss: 0.0814, g_loss: 1.1646\n",
            "Step [5710/80000], d_real_loss: 0.2846, d_mnist_loss: 0.2224, d_svhn_loss: 0.0622, d_fake_loss: 0.1330, g_loss: 1.3041\n",
            "Step [5720/80000], d_real_loss: 0.1028, d_mnist_loss: 0.0579, d_svhn_loss: 0.0449, d_fake_loss: 0.0936, g_loss: 1.5879\n",
            "Step [5730/80000], d_real_loss: 0.0968, d_mnist_loss: 0.0211, d_svhn_loss: 0.0757, d_fake_loss: 0.0856, g_loss: 1.1466\n",
            "Step [5740/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0244, d_svhn_loss: 0.0526, d_fake_loss: 0.0685, g_loss: 1.2119\n",
            "Step [5750/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0204, d_svhn_loss: 0.0609, d_fake_loss: 0.0918, g_loss: 1.4916\n",
            "Step [5760/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0208, d_svhn_loss: 0.0451, d_fake_loss: 0.0851, g_loss: 1.3868\n",
            "Step [5770/80000], d_real_loss: 0.0687, d_mnist_loss: 0.0234, d_svhn_loss: 0.0453, d_fake_loss: 0.4308, g_loss: 2.2112\n",
            "Step [5780/80000], d_real_loss: 0.0894, d_mnist_loss: 0.0224, d_svhn_loss: 0.0670, d_fake_loss: 0.0955, g_loss: 1.0102\n",
            "Step [5790/80000], d_real_loss: 0.1622, d_mnist_loss: 0.1099, d_svhn_loss: 0.0523, d_fake_loss: 0.3295, g_loss: 1.9660\n",
            "Step [5800/80000], d_real_loss: 0.1276, d_mnist_loss: 0.0426, d_svhn_loss: 0.0850, d_fake_loss: 0.0651, g_loss: 1.0094\n",
            "Step [5810/80000], d_real_loss: 0.1071, d_mnist_loss: 0.0247, d_svhn_loss: 0.0825, d_fake_loss: 0.1250, g_loss: 1.2811\n",
            "Step [5820/80000], d_real_loss: 0.0970, d_mnist_loss: 0.0523, d_svhn_loss: 0.0447, d_fake_loss: 0.0570, g_loss: 1.1589\n",
            "Step [5830/80000], d_real_loss: 0.1081, d_mnist_loss: 0.0718, d_svhn_loss: 0.0363, d_fake_loss: 0.1005, g_loss: 1.4682\n",
            "Step [5840/80000], d_real_loss: 0.2029, d_mnist_loss: 0.0471, d_svhn_loss: 0.1558, d_fake_loss: 0.1423, g_loss: 1.3395\n",
            "Step [5850/80000], d_real_loss: 0.0986, d_mnist_loss: 0.0456, d_svhn_loss: 0.0530, d_fake_loss: 0.0718, g_loss: 1.4567\n",
            "Step [5860/80000], d_real_loss: 0.0891, d_mnist_loss: 0.0309, d_svhn_loss: 0.0581, d_fake_loss: 0.1689, g_loss: 1.3482\n",
            "Step [5870/80000], d_real_loss: 0.1350, d_mnist_loss: 0.0508, d_svhn_loss: 0.0842, d_fake_loss: 0.0509, g_loss: 1.0406\n",
            "Step [5880/80000], d_real_loss: 0.0930, d_mnist_loss: 0.0487, d_svhn_loss: 0.0443, d_fake_loss: 0.0882, g_loss: 1.3423\n",
            "Step [5890/80000], d_real_loss: 0.1626, d_mnist_loss: 0.1043, d_svhn_loss: 0.0583, d_fake_loss: 0.3479, g_loss: 1.8979\n",
            "Step [5900/80000], d_real_loss: 0.1118, d_mnist_loss: 0.0589, d_svhn_loss: 0.0529, d_fake_loss: 0.1580, g_loss: 1.0684\n",
            "Step [5910/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0354, d_svhn_loss: 0.0198, d_fake_loss: 0.1710, g_loss: 1.0136\n",
            "Step [5920/80000], d_real_loss: 0.1746, d_mnist_loss: 0.1127, d_svhn_loss: 0.0619, d_fake_loss: 0.0537, g_loss: 1.1251\n",
            "Step [5930/80000], d_real_loss: 0.1022, d_mnist_loss: 0.0263, d_svhn_loss: 0.0759, d_fake_loss: 0.0989, g_loss: 1.1325\n",
            "Step [5940/80000], d_real_loss: 0.0882, d_mnist_loss: 0.0285, d_svhn_loss: 0.0596, d_fake_loss: 0.0480, g_loss: 1.3139\n",
            "Step [5950/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0223, d_svhn_loss: 0.0394, d_fake_loss: 0.2288, g_loss: 1.0913\n",
            "Step [5960/80000], d_real_loss: 0.2087, d_mnist_loss: 0.1486, d_svhn_loss: 0.0600, d_fake_loss: 0.0615, g_loss: 1.3077\n",
            "Step [5970/80000], d_real_loss: 0.1723, d_mnist_loss: 0.1280, d_svhn_loss: 0.0443, d_fake_loss: 0.1440, g_loss: 1.2249\n",
            "Step [5980/80000], d_real_loss: 0.1569, d_mnist_loss: 0.0366, d_svhn_loss: 0.1203, d_fake_loss: 0.0920, g_loss: 1.3237\n",
            "Step [5990/80000], d_real_loss: 0.2917, d_mnist_loss: 0.0285, d_svhn_loss: 0.2632, d_fake_loss: 0.1452, g_loss: 1.1385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [6000/80000], d_real_loss: 0.0701, d_mnist_loss: 0.0256, d_svhn_loss: 0.0444, d_fake_loss: 0.0622, g_loss: 1.2774\n",
            "saved ./samples_fashion/sample-6000-m-s.png\n",
            "saved ./samples_fashion/sample-6000-s-m.png\n",
            "Step [6010/80000], d_real_loss: 0.1261, d_mnist_loss: 0.0480, d_svhn_loss: 0.0781, d_fake_loss: 0.0644, g_loss: 1.0901\n",
            "Step [6020/80000], d_real_loss: 0.1150, d_mnist_loss: 0.0480, d_svhn_loss: 0.0671, d_fake_loss: 0.0590, g_loss: 1.0007\n",
            "Step [6030/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0204, d_svhn_loss: 0.0392, d_fake_loss: 0.0628, g_loss: 1.3152\n",
            "Step [6040/80000], d_real_loss: 0.2125, d_mnist_loss: 0.0700, d_svhn_loss: 0.1426, d_fake_loss: 0.1284, g_loss: 1.2971\n",
            "Step [6050/80000], d_real_loss: 0.2826, d_mnist_loss: 0.0807, d_svhn_loss: 0.2019, d_fake_loss: 0.1674, g_loss: 0.7115\n",
            "Step [6060/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0277, d_svhn_loss: 0.0406, d_fake_loss: 0.0641, g_loss: 1.1431\n",
            "Step [6070/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0503, d_svhn_loss: 0.0330, d_fake_loss: 0.1251, g_loss: 1.3954\n",
            "Step [6080/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0214, d_svhn_loss: 0.0418, d_fake_loss: 0.0704, g_loss: 1.4589\n",
            "Step [6090/80000], d_real_loss: 0.1180, d_mnist_loss: 0.0153, d_svhn_loss: 0.1027, d_fake_loss: 0.0433, g_loss: 1.1672\n",
            "Step [6100/80000], d_real_loss: 0.1005, d_mnist_loss: 0.0170, d_svhn_loss: 0.0835, d_fake_loss: 0.0547, g_loss: 1.3105\n",
            "Step [6110/80000], d_real_loss: 0.1326, d_mnist_loss: 0.0559, d_svhn_loss: 0.0767, d_fake_loss: 0.1223, g_loss: 1.1265\n",
            "Step [6120/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0357, d_svhn_loss: 0.0456, d_fake_loss: 0.0931, g_loss: 0.9435\n",
            "Step [6130/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0259, d_svhn_loss: 0.0651, d_fake_loss: 0.0926, g_loss: 0.7889\n",
            "Step [6140/80000], d_real_loss: 0.0852, d_mnist_loss: 0.0281, d_svhn_loss: 0.0571, d_fake_loss: 0.0754, g_loss: 1.3401\n",
            "Step [6150/80000], d_real_loss: 0.3241, d_mnist_loss: 0.2525, d_svhn_loss: 0.0716, d_fake_loss: 0.1398, g_loss: 1.0796\n",
            "Step [6160/80000], d_real_loss: 0.1716, d_mnist_loss: 0.0342, d_svhn_loss: 0.1374, d_fake_loss: 0.1276, g_loss: 0.8654\n",
            "Step [6170/80000], d_real_loss: 0.0850, d_mnist_loss: 0.0476, d_svhn_loss: 0.0374, d_fake_loss: 0.0580, g_loss: 1.2608\n",
            "Step [6180/80000], d_real_loss: 0.2036, d_mnist_loss: 0.0764, d_svhn_loss: 0.1272, d_fake_loss: 0.1305, g_loss: 1.0995\n",
            "Step [6190/80000], d_real_loss: 0.1210, d_mnist_loss: 0.0370, d_svhn_loss: 0.0839, d_fake_loss: 0.2902, g_loss: 1.2969\n",
            "Step [6200/80000], d_real_loss: 0.0949, d_mnist_loss: 0.0272, d_svhn_loss: 0.0676, d_fake_loss: 0.1062, g_loss: 1.0486\n",
            "Step [6210/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0238, d_svhn_loss: 0.0398, d_fake_loss: 0.2085, g_loss: 1.6356\n",
            "Step [6220/80000], d_real_loss: 0.1091, d_mnist_loss: 0.0683, d_svhn_loss: 0.0408, d_fake_loss: 0.1263, g_loss: 1.4020\n",
            "Step [6230/80000], d_real_loss: 0.1345, d_mnist_loss: 0.0710, d_svhn_loss: 0.0635, d_fake_loss: 0.0794, g_loss: 1.1379\n",
            "Step [6240/80000], d_real_loss: 0.0967, d_mnist_loss: 0.0252, d_svhn_loss: 0.0714, d_fake_loss: 0.0824, g_loss: 1.3439\n",
            "Step [6250/80000], d_real_loss: 0.0887, d_mnist_loss: 0.0596, d_svhn_loss: 0.0291, d_fake_loss: 0.0580, g_loss: 1.0377\n",
            "Step [6260/80000], d_real_loss: 0.1495, d_mnist_loss: 0.0242, d_svhn_loss: 0.1253, d_fake_loss: 0.0458, g_loss: 1.2943\n",
            "Step [6270/80000], d_real_loss: 0.1040, d_mnist_loss: 0.0601, d_svhn_loss: 0.0439, d_fake_loss: 0.1059, g_loss: 1.2300\n",
            "Step [6280/80000], d_real_loss: 0.1195, d_mnist_loss: 0.0179, d_svhn_loss: 0.1016, d_fake_loss: 0.0687, g_loss: 1.3525\n",
            "Step [6290/80000], d_real_loss: 0.0682, d_mnist_loss: 0.0262, d_svhn_loss: 0.0420, d_fake_loss: 0.0825, g_loss: 1.1847\n",
            "Step [6300/80000], d_real_loss: 0.2004, d_mnist_loss: 0.1567, d_svhn_loss: 0.0437, d_fake_loss: 0.6443, g_loss: 2.6410\n",
            "Step [6310/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0239, d_svhn_loss: 0.0564, d_fake_loss: 0.1110, g_loss: 1.5036\n",
            "Step [6320/80000], d_real_loss: 0.1245, d_mnist_loss: 0.0201, d_svhn_loss: 0.1044, d_fake_loss: 0.0784, g_loss: 1.3294\n",
            "Step [6330/80000], d_real_loss: 0.1498, d_mnist_loss: 0.0479, d_svhn_loss: 0.1020, d_fake_loss: 0.2080, g_loss: 1.8168\n",
            "Step [6340/80000], d_real_loss: 0.1645, d_mnist_loss: 0.0831, d_svhn_loss: 0.0814, d_fake_loss: 0.1033, g_loss: 0.8909\n",
            "Step [6350/80000], d_real_loss: 0.1118, d_mnist_loss: 0.0462, d_svhn_loss: 0.0655, d_fake_loss: 0.0471, g_loss: 1.0332\n",
            "Step [6360/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0177, d_svhn_loss: 0.0401, d_fake_loss: 0.0860, g_loss: 1.3349\n",
            "Step [6370/80000], d_real_loss: 0.1090, d_mnist_loss: 0.0237, d_svhn_loss: 0.0853, d_fake_loss: 0.1073, g_loss: 1.8313\n",
            "Step [6380/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0390, d_svhn_loss: 0.0334, d_fake_loss: 0.1709, g_loss: 1.2576\n",
            "Step [6390/80000], d_real_loss: 0.0986, d_mnist_loss: 0.0167, d_svhn_loss: 0.0820, d_fake_loss: 0.0894, g_loss: 0.9801\n",
            "Step [6400/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0241, d_svhn_loss: 0.0371, d_fake_loss: 0.1291, g_loss: 0.9520\n",
            "Step [6410/80000], d_real_loss: 0.1259, d_mnist_loss: 0.0851, d_svhn_loss: 0.0408, d_fake_loss: 0.2151, g_loss: 0.7891\n",
            "Step [6420/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0317, d_svhn_loss: 0.0529, d_fake_loss: 0.0720, g_loss: 1.2694\n",
            "Step [6430/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0319, d_svhn_loss: 0.0574, d_fake_loss: 0.1068, g_loss: 1.0890\n",
            "Step [6440/80000], d_real_loss: 0.1760, d_mnist_loss: 0.0629, d_svhn_loss: 0.1131, d_fake_loss: 0.0948, g_loss: 0.9979\n",
            "Step [6450/80000], d_real_loss: 0.1458, d_mnist_loss: 0.0609, d_svhn_loss: 0.0849, d_fake_loss: 0.0750, g_loss: 1.2013\n",
            "Step [6460/80000], d_real_loss: 0.2143, d_mnist_loss: 0.0537, d_svhn_loss: 0.1606, d_fake_loss: 0.1994, g_loss: 1.4529\n",
            "Step [6470/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0252, d_svhn_loss: 0.0396, d_fake_loss: 0.1258, g_loss: 1.4552\n",
            "Step [6480/80000], d_real_loss: 0.0983, d_mnist_loss: 0.0284, d_svhn_loss: 0.0700, d_fake_loss: 0.0720, g_loss: 1.3435\n",
            "Step [6490/80000], d_real_loss: 0.0751, d_mnist_loss: 0.0439, d_svhn_loss: 0.0312, d_fake_loss: 0.2062, g_loss: 1.4437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [6500/80000], d_real_loss: 0.1275, d_mnist_loss: 0.0715, d_svhn_loss: 0.0560, d_fake_loss: 0.0511, g_loss: 1.0302\n",
            "saved ./samples_fashion/sample-6500-m-s.png\n",
            "saved ./samples_fashion/sample-6500-s-m.png\n",
            "Step [6510/80000], d_real_loss: 0.0832, d_mnist_loss: 0.0245, d_svhn_loss: 0.0587, d_fake_loss: 0.1015, g_loss: 1.3973\n",
            "Step [6520/80000], d_real_loss: 0.2462, d_mnist_loss: 0.0185, d_svhn_loss: 0.2277, d_fake_loss: 0.0951, g_loss: 1.2514\n",
            "Step [6530/80000], d_real_loss: 0.7486, d_mnist_loss: 0.5632, d_svhn_loss: 0.1854, d_fake_loss: 0.5379, g_loss: 2.5321\n",
            "Step [6540/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0294, d_svhn_loss: 0.0309, d_fake_loss: 0.1717, g_loss: 1.1337\n",
            "Step [6550/80000], d_real_loss: 0.2858, d_mnist_loss: 0.0185, d_svhn_loss: 0.2672, d_fake_loss: 0.0832, g_loss: 1.2966\n",
            "Step [6560/80000], d_real_loss: 0.0797, d_mnist_loss: 0.0461, d_svhn_loss: 0.0335, d_fake_loss: 0.0906, g_loss: 1.0318\n",
            "Step [6570/80000], d_real_loss: 0.1658, d_mnist_loss: 0.0306, d_svhn_loss: 0.1352, d_fake_loss: 0.1394, g_loss: 1.2761\n",
            "Step [6580/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0372, d_svhn_loss: 0.0474, d_fake_loss: 0.1034, g_loss: 0.7186\n",
            "Step [6590/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0290, d_svhn_loss: 0.0286, d_fake_loss: 0.1281, g_loss: 1.4854\n",
            "Step [6600/80000], d_real_loss: 0.1571, d_mnist_loss: 0.0187, d_svhn_loss: 0.1384, d_fake_loss: 0.2598, g_loss: 1.4396\n",
            "Step [6610/80000], d_real_loss: 0.1041, d_mnist_loss: 0.0222, d_svhn_loss: 0.0819, d_fake_loss: 0.1353, g_loss: 1.2020\n",
            "Step [6620/80000], d_real_loss: 0.1418, d_mnist_loss: 0.0787, d_svhn_loss: 0.0631, d_fake_loss: 0.0945, g_loss: 1.4902\n",
            "Step [6630/80000], d_real_loss: 0.1993, d_mnist_loss: 0.0167, d_svhn_loss: 0.1826, d_fake_loss: 0.1482, g_loss: 1.2464\n",
            "Step [6640/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0206, d_svhn_loss: 0.0512, d_fake_loss: 0.1048, g_loss: 1.5527\n",
            "Step [6650/80000], d_real_loss: 0.1098, d_mnist_loss: 0.0454, d_svhn_loss: 0.0644, d_fake_loss: 0.1186, g_loss: 1.0873\n",
            "Step [6660/80000], d_real_loss: 0.0923, d_mnist_loss: 0.0522, d_svhn_loss: 0.0400, d_fake_loss: 0.0999, g_loss: 1.0093\n",
            "Step [6670/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0232, d_svhn_loss: 0.0431, d_fake_loss: 0.0842, g_loss: 1.2532\n",
            "Step [6680/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0476, d_svhn_loss: 0.0604, d_fake_loss: 0.0925, g_loss: 1.4043\n",
            "Step [6690/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0228, d_svhn_loss: 0.0353, d_fake_loss: 0.1900, g_loss: 1.2742\n",
            "Step [6700/80000], d_real_loss: 0.1155, d_mnist_loss: 0.0212, d_svhn_loss: 0.0942, d_fake_loss: 0.0438, g_loss: 1.1655\n",
            "Step [6710/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0226, d_svhn_loss: 0.0501, d_fake_loss: 0.0566, g_loss: 1.1344\n",
            "Step [6720/80000], d_real_loss: 0.1045, d_mnist_loss: 0.0362, d_svhn_loss: 0.0683, d_fake_loss: 0.1164, g_loss: 1.0518\n",
            "Step [6730/80000], d_real_loss: 0.4238, d_mnist_loss: 0.3049, d_svhn_loss: 0.1189, d_fake_loss: 0.1287, g_loss: 1.5170\n",
            "Step [6740/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0395, d_svhn_loss: 0.0293, d_fake_loss: 0.1290, g_loss: 1.4267\n",
            "Step [6750/80000], d_real_loss: 0.1525, d_mnist_loss: 0.0500, d_svhn_loss: 0.1025, d_fake_loss: 0.0948, g_loss: 1.1383\n",
            "Step [6760/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0276, d_svhn_loss: 0.0488, d_fake_loss: 0.0483, g_loss: 1.2344\n",
            "Step [6770/80000], d_real_loss: 0.0746, d_mnist_loss: 0.0343, d_svhn_loss: 0.0403, d_fake_loss: 0.1996, g_loss: 1.4102\n",
            "Step [6780/80000], d_real_loss: 0.1812, d_mnist_loss: 0.1320, d_svhn_loss: 0.0492, d_fake_loss: 0.1293, g_loss: 1.6538\n",
            "Step [6790/80000], d_real_loss: 0.1466, d_mnist_loss: 0.0274, d_svhn_loss: 0.1192, d_fake_loss: 0.1192, g_loss: 1.1082\n",
            "Step [6800/80000], d_real_loss: 0.0915, d_mnist_loss: 0.0278, d_svhn_loss: 0.0637, d_fake_loss: 0.0608, g_loss: 1.0105\n",
            "Step [6810/80000], d_real_loss: 0.5107, d_mnist_loss: 0.4670, d_svhn_loss: 0.0437, d_fake_loss: 0.2450, g_loss: 1.3420\n",
            "Step [6820/80000], d_real_loss: 0.2887, d_mnist_loss: 0.0397, d_svhn_loss: 0.2490, d_fake_loss: 0.1208, g_loss: 1.2606\n",
            "Step [6830/80000], d_real_loss: 0.1747, d_mnist_loss: 0.0273, d_svhn_loss: 0.1474, d_fake_loss: 0.1378, g_loss: 1.8588\n",
            "Step [6840/80000], d_real_loss: 0.1856, d_mnist_loss: 0.0914, d_svhn_loss: 0.0943, d_fake_loss: 0.0628, g_loss: 1.0261\n",
            "Step [6850/80000], d_real_loss: 0.0852, d_mnist_loss: 0.0375, d_svhn_loss: 0.0477, d_fake_loss: 0.0602, g_loss: 1.0872\n",
            "Step [6860/80000], d_real_loss: 0.1275, d_mnist_loss: 0.0624, d_svhn_loss: 0.0651, d_fake_loss: 0.4006, g_loss: 1.2976\n",
            "Step [6870/80000], d_real_loss: 0.1980, d_mnist_loss: 0.1208, d_svhn_loss: 0.0771, d_fake_loss: 0.0571, g_loss: 1.1966\n",
            "Step [6880/80000], d_real_loss: 0.0957, d_mnist_loss: 0.0199, d_svhn_loss: 0.0758, d_fake_loss: 0.0874, g_loss: 1.2864\n",
            "Step [6890/80000], d_real_loss: 0.3122, d_mnist_loss: 0.0362, d_svhn_loss: 0.2761, d_fake_loss: 0.4538, g_loss: 1.1810\n",
            "Step [6900/80000], d_real_loss: 0.2106, d_mnist_loss: 0.0185, d_svhn_loss: 0.1921, d_fake_loss: 0.1254, g_loss: 1.5182\n",
            "Step [6910/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0152, d_svhn_loss: 0.0477, d_fake_loss: 0.2088, g_loss: 1.3355\n",
            "Step [6920/80000], d_real_loss: 0.1651, d_mnist_loss: 0.0257, d_svhn_loss: 0.1394, d_fake_loss: 0.1155, g_loss: 1.0281\n",
            "Step [6930/80000], d_real_loss: 0.1676, d_mnist_loss: 0.0372, d_svhn_loss: 0.1305, d_fake_loss: 0.2179, g_loss: 1.3690\n",
            "Step [6940/80000], d_real_loss: 0.0987, d_mnist_loss: 0.0363, d_svhn_loss: 0.0624, d_fake_loss: 0.5538, g_loss: 2.0515\n",
            "Step [6950/80000], d_real_loss: 0.1571, d_mnist_loss: 0.0512, d_svhn_loss: 0.1058, d_fake_loss: 0.1209, g_loss: 1.0982\n",
            "Step [6960/80000], d_real_loss: 0.1070, d_mnist_loss: 0.0412, d_svhn_loss: 0.0657, d_fake_loss: 0.0953, g_loss: 1.3335\n",
            "Step [6970/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0402, d_svhn_loss: 0.0427, d_fake_loss: 0.0508, g_loss: 1.1646\n",
            "Step [6980/80000], d_real_loss: 0.0947, d_mnist_loss: 0.0251, d_svhn_loss: 0.0695, d_fake_loss: 0.2916, g_loss: 1.1120\n",
            "Step [6990/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0234, d_svhn_loss: 0.0439, d_fake_loss: 0.0535, g_loss: 1.1775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [7000/80000], d_real_loss: 0.1185, d_mnist_loss: 0.0209, d_svhn_loss: 0.0976, d_fake_loss: 0.0735, g_loss: 1.1610\n",
            "saved ./samples_fashion/sample-7000-m-s.png\n",
            "saved ./samples_fashion/sample-7000-s-m.png\n",
            "Step [7010/80000], d_real_loss: 0.1564, d_mnist_loss: 0.0283, d_svhn_loss: 0.1280, d_fake_loss: 0.0928, g_loss: 0.9534\n",
            "Step [7020/80000], d_real_loss: 0.0857, d_mnist_loss: 0.0226, d_svhn_loss: 0.0631, d_fake_loss: 0.0813, g_loss: 0.9834\n",
            "Step [7030/80000], d_real_loss: 0.1206, d_mnist_loss: 0.0427, d_svhn_loss: 0.0778, d_fake_loss: 0.0779, g_loss: 1.0299\n",
            "Step [7040/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0245, d_svhn_loss: 0.0362, d_fake_loss: 0.0438, g_loss: 0.9287\n",
            "Step [7050/80000], d_real_loss: 0.1856, d_mnist_loss: 0.1330, d_svhn_loss: 0.0526, d_fake_loss: 0.3443, g_loss: 1.6930\n",
            "Step [7060/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0252, d_svhn_loss: 0.0464, d_fake_loss: 0.0590, g_loss: 1.1986\n",
            "Step [7070/80000], d_real_loss: 0.0880, d_mnist_loss: 0.0291, d_svhn_loss: 0.0589, d_fake_loss: 0.2146, g_loss: 1.0609\n",
            "Step [7080/80000], d_real_loss: 0.1736, d_mnist_loss: 0.0629, d_svhn_loss: 0.1108, d_fake_loss: 0.1028, g_loss: 1.0049\n",
            "Step [7090/80000], d_real_loss: 0.1635, d_mnist_loss: 0.0274, d_svhn_loss: 0.1362, d_fake_loss: 0.2105, g_loss: 1.1572\n",
            "Step [7100/80000], d_real_loss: 0.0976, d_mnist_loss: 0.0501, d_svhn_loss: 0.0475, d_fake_loss: 0.0543, g_loss: 1.1245\n",
            "Step [7110/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0235, d_svhn_loss: 0.0543, d_fake_loss: 0.0631, g_loss: 1.1782\n",
            "Step [7120/80000], d_real_loss: 0.0789, d_mnist_loss: 0.0358, d_svhn_loss: 0.0431, d_fake_loss: 0.0656, g_loss: 1.0438\n",
            "Step [7130/80000], d_real_loss: 0.0973, d_mnist_loss: 0.0267, d_svhn_loss: 0.0706, d_fake_loss: 0.0748, g_loss: 1.0315\n",
            "Step [7140/80000], d_real_loss: 0.1016, d_mnist_loss: 0.0336, d_svhn_loss: 0.0680, d_fake_loss: 0.1062, g_loss: 1.2973\n",
            "Step [7150/80000], d_real_loss: 0.1066, d_mnist_loss: 0.0639, d_svhn_loss: 0.0427, d_fake_loss: 0.0871, g_loss: 1.1133\n",
            "Step [7160/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0281, d_svhn_loss: 0.0464, d_fake_loss: 0.1453, g_loss: 1.5673\n",
            "Step [7170/80000], d_real_loss: 0.1795, d_mnist_loss: 0.0473, d_svhn_loss: 0.1322, d_fake_loss: 0.0682, g_loss: 1.2393\n",
            "Step [7180/80000], d_real_loss: 0.2323, d_mnist_loss: 0.0859, d_svhn_loss: 0.1464, d_fake_loss: 0.1448, g_loss: 1.3188\n",
            "Step [7190/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0248, d_svhn_loss: 0.0429, d_fake_loss: 0.1003, g_loss: 1.2123\n",
            "Step [7200/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0278, d_svhn_loss: 0.0485, d_fake_loss: 0.2320, g_loss: 1.2838\n",
            "Step [7210/80000], d_real_loss: 0.0906, d_mnist_loss: 0.0332, d_svhn_loss: 0.0575, d_fake_loss: 0.0599, g_loss: 1.0866\n",
            "Step [7220/80000], d_real_loss: 0.2359, d_mnist_loss: 0.0210, d_svhn_loss: 0.2149, d_fake_loss: 0.0909, g_loss: 0.8503\n",
            "Step [7230/80000], d_real_loss: 0.0955, d_mnist_loss: 0.0161, d_svhn_loss: 0.0794, d_fake_loss: 0.1040, g_loss: 1.4972\n",
            "Step [7240/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0174, d_svhn_loss: 0.0527, d_fake_loss: 0.0481, g_loss: 1.2738\n",
            "Step [7250/80000], d_real_loss: 0.1421, d_mnist_loss: 0.0594, d_svhn_loss: 0.0827, d_fake_loss: 0.1199, g_loss: 1.3322\n",
            "Step [7260/80000], d_real_loss: 0.1002, d_mnist_loss: 0.0453, d_svhn_loss: 0.0549, d_fake_loss: 0.1310, g_loss: 0.9306\n",
            "Step [7270/80000], d_real_loss: 0.1780, d_mnist_loss: 0.0224, d_svhn_loss: 0.1556, d_fake_loss: 0.1503, g_loss: 1.6141\n",
            "Step [7280/80000], d_real_loss: 0.1378, d_mnist_loss: 0.0336, d_svhn_loss: 0.1042, d_fake_loss: 0.0671, g_loss: 1.3870\n",
            "Step [7290/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0252, d_svhn_loss: 0.0372, d_fake_loss: 0.0816, g_loss: 1.3103\n",
            "Step [7300/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0216, d_svhn_loss: 0.0497, d_fake_loss: 0.0539, g_loss: 1.3079\n",
            "Step [7310/80000], d_real_loss: 0.2867, d_mnist_loss: 0.0277, d_svhn_loss: 0.2589, d_fake_loss: 0.1802, g_loss: 1.1502\n",
            "Step [7320/80000], d_real_loss: 0.0992, d_mnist_loss: 0.0143, d_svhn_loss: 0.0850, d_fake_loss: 0.1036, g_loss: 1.0777\n",
            "Step [7330/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0174, d_svhn_loss: 0.0761, d_fake_loss: 0.1423, g_loss: 0.8523\n",
            "Step [7340/80000], d_real_loss: 0.1159, d_mnist_loss: 0.0560, d_svhn_loss: 0.0598, d_fake_loss: 0.0789, g_loss: 1.4278\n",
            "Step [7350/80000], d_real_loss: 0.0701, d_mnist_loss: 0.0276, d_svhn_loss: 0.0425, d_fake_loss: 0.1074, g_loss: 1.5025\n",
            "Step [7360/80000], d_real_loss: 0.1118, d_mnist_loss: 0.0493, d_svhn_loss: 0.0625, d_fake_loss: 0.1717, g_loss: 1.2130\n",
            "Step [7370/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0187, d_svhn_loss: 0.0399, d_fake_loss: 0.0498, g_loss: 1.3041\n",
            "Step [7380/80000], d_real_loss: 0.0989, d_mnist_loss: 0.0592, d_svhn_loss: 0.0397, d_fake_loss: 0.1126, g_loss: 1.4125\n",
            "Step [7390/80000], d_real_loss: 0.1192, d_mnist_loss: 0.0756, d_svhn_loss: 0.0436, d_fake_loss: 0.1414, g_loss: 1.5924\n",
            "Step [7400/80000], d_real_loss: 0.1665, d_mnist_loss: 0.0735, d_svhn_loss: 0.0929, d_fake_loss: 0.2869, g_loss: 1.3326\n",
            "Step [7410/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0184, d_svhn_loss: 0.0602, d_fake_loss: 0.0467, g_loss: 1.1019\n",
            "Step [7420/80000], d_real_loss: 0.0903, d_mnist_loss: 0.0298, d_svhn_loss: 0.0605, d_fake_loss: 0.2928, g_loss: 1.6783\n",
            "Step [7430/80000], d_real_loss: 0.1408, d_mnist_loss: 0.0461, d_svhn_loss: 0.0947, d_fake_loss: 0.0813, g_loss: 1.2827\n",
            "Step [7440/80000], d_real_loss: 0.0920, d_mnist_loss: 0.0211, d_svhn_loss: 0.0709, d_fake_loss: 0.1452, g_loss: 1.6328\n",
            "Step [7450/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0451, d_svhn_loss: 0.0627, d_fake_loss: 0.0742, g_loss: 0.6586\n",
            "Step [7460/80000], d_real_loss: 0.0986, d_mnist_loss: 0.0627, d_svhn_loss: 0.0359, d_fake_loss: 0.1166, g_loss: 1.3859\n",
            "Step [7470/80000], d_real_loss: 0.1612, d_mnist_loss: 0.0412, d_svhn_loss: 0.1200, d_fake_loss: 0.2097, g_loss: 1.2551\n",
            "Step [7480/80000], d_real_loss: 0.1304, d_mnist_loss: 0.0954, d_svhn_loss: 0.0351, d_fake_loss: 0.2513, g_loss: 1.3781\n",
            "Step [7490/80000], d_real_loss: 0.1473, d_mnist_loss: 0.0394, d_svhn_loss: 0.1079, d_fake_loss: 0.1017, g_loss: 1.1035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [7500/80000], d_real_loss: 0.1600, d_mnist_loss: 0.1004, d_svhn_loss: 0.0596, d_fake_loss: 0.1437, g_loss: 1.1128\n",
            "saved ./samples_fashion/sample-7500-m-s.png\n",
            "saved ./samples_fashion/sample-7500-s-m.png\n",
            "Step [7510/80000], d_real_loss: 0.2451, d_mnist_loss: 0.0402, d_svhn_loss: 0.2049, d_fake_loss: 0.2372, g_loss: 1.5485\n",
            "Step [7520/80000], d_real_loss: 0.1386, d_mnist_loss: 0.0510, d_svhn_loss: 0.0876, d_fake_loss: 0.1417, g_loss: 1.3935\n",
            "Step [7530/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0160, d_svhn_loss: 0.0476, d_fake_loss: 0.0719, g_loss: 1.1942\n",
            "Step [7540/80000], d_real_loss: 0.4911, d_mnist_loss: 0.0191, d_svhn_loss: 0.4721, d_fake_loss: 0.2747, g_loss: 0.8475\n",
            "Step [7550/80000], d_real_loss: 0.1122, d_mnist_loss: 0.0168, d_svhn_loss: 0.0954, d_fake_loss: 0.1659, g_loss: 1.3100\n",
            "Step [7560/80000], d_real_loss: 0.1961, d_mnist_loss: 0.0230, d_svhn_loss: 0.1732, d_fake_loss: 0.1076, g_loss: 1.1805\n",
            "Step [7570/80000], d_real_loss: 0.0834, d_mnist_loss: 0.0182, d_svhn_loss: 0.0653, d_fake_loss: 0.0791, g_loss: 1.3930\n",
            "Step [7580/80000], d_real_loss: 0.1225, d_mnist_loss: 0.0712, d_svhn_loss: 0.0513, d_fake_loss: 0.0950, g_loss: 0.8600\n",
            "Step [7590/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0173, d_svhn_loss: 0.0639, d_fake_loss: 0.0595, g_loss: 1.2657\n",
            "Step [7600/80000], d_real_loss: 0.1376, d_mnist_loss: 0.0225, d_svhn_loss: 0.1151, d_fake_loss: 0.1407, g_loss: 0.8479\n",
            "Step [7610/80000], d_real_loss: 0.2978, d_mnist_loss: 0.1731, d_svhn_loss: 0.1247, d_fake_loss: 0.1774, g_loss: 1.3066\n",
            "Step [7620/80000], d_real_loss: 0.1243, d_mnist_loss: 0.0365, d_svhn_loss: 0.0878, d_fake_loss: 0.0742, g_loss: 1.2287\n",
            "Step [7630/80000], d_real_loss: 0.1571, d_mnist_loss: 0.0963, d_svhn_loss: 0.0608, d_fake_loss: 0.0936, g_loss: 1.2045\n",
            "Step [7640/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0256, d_svhn_loss: 0.0329, d_fake_loss: 0.0582, g_loss: 1.3794\n",
            "Step [7650/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0196, d_svhn_loss: 0.0359, d_fake_loss: 0.0448, g_loss: 1.0952\n",
            "Step [7660/80000], d_real_loss: 0.1280, d_mnist_loss: 0.0228, d_svhn_loss: 0.1052, d_fake_loss: 0.1435, g_loss: 0.8022\n",
            "Step [7670/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0251, d_svhn_loss: 0.0359, d_fake_loss: 0.2264, g_loss: 1.3583\n",
            "Step [7680/80000], d_real_loss: 0.0983, d_mnist_loss: 0.0342, d_svhn_loss: 0.0641, d_fake_loss: 0.0998, g_loss: 1.1148\n",
            "Step [7690/80000], d_real_loss: 0.1177, d_mnist_loss: 0.0338, d_svhn_loss: 0.0839, d_fake_loss: 0.1701, g_loss: 1.0076\n",
            "Step [7700/80000], d_real_loss: 0.1368, d_mnist_loss: 0.0966, d_svhn_loss: 0.0402, d_fake_loss: 0.0466, g_loss: 1.1680\n",
            "Step [7710/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0232, d_svhn_loss: 0.0376, d_fake_loss: 0.0644, g_loss: 1.2615\n",
            "Step [7720/80000], d_real_loss: 0.0919, d_mnist_loss: 0.0312, d_svhn_loss: 0.0607, d_fake_loss: 0.0772, g_loss: 1.1677\n",
            "Step [7730/80000], d_real_loss: 0.1090, d_mnist_loss: 0.0541, d_svhn_loss: 0.0549, d_fake_loss: 0.0556, g_loss: 0.9907\n",
            "Step [7740/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0186, d_svhn_loss: 0.0429, d_fake_loss: 0.0628, g_loss: 0.9754\n",
            "Step [7750/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0476, d_svhn_loss: 0.0425, d_fake_loss: 0.1570, g_loss: 1.2394\n",
            "Step [7760/80000], d_real_loss: 0.0874, d_mnist_loss: 0.0181, d_svhn_loss: 0.0693, d_fake_loss: 0.0442, g_loss: 1.0383\n",
            "Step [7770/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0232, d_svhn_loss: 0.0574, d_fake_loss: 0.0939, g_loss: 1.2353\n",
            "Step [7780/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0323, d_svhn_loss: 0.0502, d_fake_loss: 0.0561, g_loss: 1.2716\n",
            "Step [7790/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0173, d_svhn_loss: 0.0489, d_fake_loss: 0.0663, g_loss: 1.0374\n",
            "Step [7800/80000], d_real_loss: 0.2141, d_mnist_loss: 0.1547, d_svhn_loss: 0.0594, d_fake_loss: 0.1717, g_loss: 1.4459\n",
            "Step [7810/80000], d_real_loss: 0.0911, d_mnist_loss: 0.0472, d_svhn_loss: 0.0439, d_fake_loss: 0.0651, g_loss: 1.0311\n",
            "Step [7820/80000], d_real_loss: 0.1001, d_mnist_loss: 0.0256, d_svhn_loss: 0.0745, d_fake_loss: 0.0567, g_loss: 1.0260\n",
            "Step [7830/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0146, d_svhn_loss: 0.0444, d_fake_loss: 0.2085, g_loss: 1.4103\n",
            "Step [7840/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0188, d_svhn_loss: 0.0398, d_fake_loss: 0.2413, g_loss: 1.3417\n",
            "Step [7850/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0280, d_svhn_loss: 0.0546, d_fake_loss: 0.0965, g_loss: 1.2729\n",
            "Step [7860/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0229, d_svhn_loss: 0.0417, d_fake_loss: 0.0618, g_loss: 1.1955\n",
            "Step [7870/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0294, d_svhn_loss: 0.0323, d_fake_loss: 0.0735, g_loss: 1.3767\n",
            "Step [7880/80000], d_real_loss: 0.1838, d_mnist_loss: 0.0297, d_svhn_loss: 0.1542, d_fake_loss: 0.0771, g_loss: 1.2667\n",
            "Step [7890/80000], d_real_loss: 0.1869, d_mnist_loss: 0.0422, d_svhn_loss: 0.1447, d_fake_loss: 0.2139, g_loss: 1.2009\n",
            "Step [7900/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0293, d_svhn_loss: 0.0425, d_fake_loss: 0.0571, g_loss: 1.1686\n",
            "Step [7910/80000], d_real_loss: 0.2315, d_mnist_loss: 0.1115, d_svhn_loss: 0.1200, d_fake_loss: 0.2096, g_loss: 1.3739\n",
            "Step [7920/80000], d_real_loss: 0.1662, d_mnist_loss: 0.1264, d_svhn_loss: 0.0399, d_fake_loss: 0.1568, g_loss: 1.4621\n",
            "Step [7930/80000], d_real_loss: 0.1074, d_mnist_loss: 0.0191, d_svhn_loss: 0.0883, d_fake_loss: 0.0725, g_loss: 1.2505\n",
            "Step [7940/80000], d_real_loss: 0.2268, d_mnist_loss: 0.0517, d_svhn_loss: 0.1751, d_fake_loss: 0.0619, g_loss: 1.2740\n",
            "Step [7950/80000], d_real_loss: 0.2666, d_mnist_loss: 0.1375, d_svhn_loss: 0.1291, d_fake_loss: 0.0806, g_loss: 1.2494\n",
            "Step [7960/80000], d_real_loss: 0.1702, d_mnist_loss: 0.0246, d_svhn_loss: 0.1456, d_fake_loss: 0.0782, g_loss: 1.1141\n",
            "Step [7970/80000], d_real_loss: 0.1875, d_mnist_loss: 0.0152, d_svhn_loss: 0.1723, d_fake_loss: 0.0986, g_loss: 1.4089\n",
            "Step [7980/80000], d_real_loss: 0.1412, d_mnist_loss: 0.0393, d_svhn_loss: 0.1018, d_fake_loss: 0.0494, g_loss: 1.2574\n",
            "Step [7990/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0198, d_svhn_loss: 0.0567, d_fake_loss: 0.0715, g_loss: 1.0527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [8000/80000], d_real_loss: 0.1165, d_mnist_loss: 0.0185, d_svhn_loss: 0.0981, d_fake_loss: 0.1430, g_loss: 1.1960\n",
            "saved ./samples_fashion/sample-8000-m-s.png\n",
            "saved ./samples_fashion/sample-8000-s-m.png\n",
            "Step [8010/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0280, d_svhn_loss: 0.0404, d_fake_loss: 0.0518, g_loss: 1.1733\n",
            "Step [8020/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0223, d_svhn_loss: 0.0367, d_fake_loss: 0.0404, g_loss: 1.1517\n",
            "Step [8030/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0163, d_svhn_loss: 0.0552, d_fake_loss: 0.0876, g_loss: 1.4166\n",
            "Step [8040/80000], d_real_loss: 0.1277, d_mnist_loss: 0.0750, d_svhn_loss: 0.0526, d_fake_loss: 0.1097, g_loss: 1.1935\n",
            "Step [8050/80000], d_real_loss: 0.1982, d_mnist_loss: 0.0888, d_svhn_loss: 0.1094, d_fake_loss: 0.4873, g_loss: 1.5642\n",
            "Step [8060/80000], d_real_loss: 0.1353, d_mnist_loss: 0.0316, d_svhn_loss: 0.1036, d_fake_loss: 0.0955, g_loss: 1.0888\n",
            "Step [8070/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0291, d_svhn_loss: 0.0520, d_fake_loss: 0.1895, g_loss: 0.9535\n",
            "Step [8080/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0160, d_svhn_loss: 0.0482, d_fake_loss: 0.0864, g_loss: 1.3303\n",
            "Step [8090/80000], d_real_loss: 0.0928, d_mnist_loss: 0.0216, d_svhn_loss: 0.0712, d_fake_loss: 0.0741, g_loss: 1.1624\n",
            "Step [8100/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0229, d_svhn_loss: 0.0509, d_fake_loss: 0.0912, g_loss: 1.3175\n",
            "Step [8110/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0267, d_svhn_loss: 0.0377, d_fake_loss: 0.0837, g_loss: 1.2671\n",
            "Step [8120/80000], d_real_loss: 0.1018, d_mnist_loss: 0.0496, d_svhn_loss: 0.0522, d_fake_loss: 0.1205, g_loss: 1.6807\n",
            "Step [8130/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0334, d_svhn_loss: 0.0430, d_fake_loss: 0.0802, g_loss: 1.2057\n",
            "Step [8140/80000], d_real_loss: 0.2117, d_mnist_loss: 0.1586, d_svhn_loss: 0.0531, d_fake_loss: 0.0873, g_loss: 0.8974\n",
            "Step [8150/80000], d_real_loss: 0.1727, d_mnist_loss: 0.0569, d_svhn_loss: 0.1158, d_fake_loss: 0.2002, g_loss: 1.3928\n",
            "Step [8160/80000], d_real_loss: 0.1198, d_mnist_loss: 0.0630, d_svhn_loss: 0.0568, d_fake_loss: 0.1003, g_loss: 1.2207\n",
            "Step [8170/80000], d_real_loss: 0.1258, d_mnist_loss: 0.0464, d_svhn_loss: 0.0794, d_fake_loss: 0.1761, g_loss: 1.0248\n",
            "Step [8180/80000], d_real_loss: 0.6283, d_mnist_loss: 0.0385, d_svhn_loss: 0.5898, d_fake_loss: 0.3006, g_loss: 1.1456\n",
            "Step [8190/80000], d_real_loss: 0.1113, d_mnist_loss: 0.0408, d_svhn_loss: 0.0705, d_fake_loss: 0.1696, g_loss: 1.2222\n",
            "Step [8200/80000], d_real_loss: 0.1322, d_mnist_loss: 0.0269, d_svhn_loss: 0.1053, d_fake_loss: 0.0910, g_loss: 1.0307\n",
            "Step [8210/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0164, d_svhn_loss: 0.0662, d_fake_loss: 0.1069, g_loss: 1.1237\n",
            "Step [8220/80000], d_real_loss: 0.1005, d_mnist_loss: 0.0242, d_svhn_loss: 0.0763, d_fake_loss: 0.0790, g_loss: 1.2932\n",
            "Step [8230/80000], d_real_loss: 0.0951, d_mnist_loss: 0.0420, d_svhn_loss: 0.0531, d_fake_loss: 0.1783, g_loss: 1.3020\n",
            "Step [8240/80000], d_real_loss: 0.0905, d_mnist_loss: 0.0425, d_svhn_loss: 0.0481, d_fake_loss: 0.2068, g_loss: 0.5703\n",
            "Step [8250/80000], d_real_loss: 0.2303, d_mnist_loss: 0.0892, d_svhn_loss: 0.1412, d_fake_loss: 0.1136, g_loss: 1.0882\n",
            "Step [8260/80000], d_real_loss: 0.0967, d_mnist_loss: 0.0277, d_svhn_loss: 0.0690, d_fake_loss: 0.0941, g_loss: 1.1373\n",
            "Step [8270/80000], d_real_loss: 0.1396, d_mnist_loss: 0.0504, d_svhn_loss: 0.0892, d_fake_loss: 0.1800, g_loss: 1.4785\n",
            "Step [8280/80000], d_real_loss: 0.0902, d_mnist_loss: 0.0210, d_svhn_loss: 0.0693, d_fake_loss: 0.1541, g_loss: 1.2256\n",
            "Step [8290/80000], d_real_loss: 0.0914, d_mnist_loss: 0.0524, d_svhn_loss: 0.0390, d_fake_loss: 0.0998, g_loss: 1.0012\n",
            "Step [8300/80000], d_real_loss: 0.0880, d_mnist_loss: 0.0385, d_svhn_loss: 0.0495, d_fake_loss: 0.1430, g_loss: 1.6889\n",
            "Step [8310/80000], d_real_loss: 0.1192, d_mnist_loss: 0.0483, d_svhn_loss: 0.0709, d_fake_loss: 0.0711, g_loss: 0.9393\n",
            "Step [8320/80000], d_real_loss: 0.0961, d_mnist_loss: 0.0512, d_svhn_loss: 0.0449, d_fake_loss: 0.0582, g_loss: 1.2791\n",
            "Step [8330/80000], d_real_loss: 0.0978, d_mnist_loss: 0.0449, d_svhn_loss: 0.0529, d_fake_loss: 0.0593, g_loss: 1.0287\n",
            "Step [8340/80000], d_real_loss: 0.0947, d_mnist_loss: 0.0142, d_svhn_loss: 0.0805, d_fake_loss: 0.0906, g_loss: 1.4440\n",
            "Step [8350/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0298, d_svhn_loss: 0.0254, d_fake_loss: 0.1615, g_loss: 0.9960\n",
            "Step [8360/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0324, d_svhn_loss: 0.0438, d_fake_loss: 0.0814, g_loss: 1.4120\n",
            "Step [8370/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0412, d_svhn_loss: 0.0417, d_fake_loss: 0.1292, g_loss: 1.8584\n",
            "Step [8380/80000], d_real_loss: 0.1301, d_mnist_loss: 0.0194, d_svhn_loss: 0.1107, d_fake_loss: 0.0824, g_loss: 1.2880\n",
            "Step [8390/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0186, d_svhn_loss: 0.0434, d_fake_loss: 0.0613, g_loss: 1.1583\n",
            "Step [8400/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0232, d_svhn_loss: 0.0393, d_fake_loss: 0.1069, g_loss: 1.1986\n",
            "Step [8410/80000], d_real_loss: 0.0726, d_mnist_loss: 0.0272, d_svhn_loss: 0.0454, d_fake_loss: 0.0847, g_loss: 1.0151\n",
            "Step [8420/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0182, d_svhn_loss: 0.0590, d_fake_loss: 0.1437, g_loss: 1.1887\n",
            "Step [8430/80000], d_real_loss: 0.1115, d_mnist_loss: 0.0236, d_svhn_loss: 0.0879, d_fake_loss: 0.1704, g_loss: 1.1275\n",
            "Step [8440/80000], d_real_loss: 0.2010, d_mnist_loss: 0.0234, d_svhn_loss: 0.1776, d_fake_loss: 0.1630, g_loss: 1.2076\n",
            "Step [8450/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0184, d_svhn_loss: 0.0324, d_fake_loss: 0.0675, g_loss: 1.2734\n",
            "Step [8460/80000], d_real_loss: 0.1302, d_mnist_loss: 0.0535, d_svhn_loss: 0.0767, d_fake_loss: 0.0548, g_loss: 1.2499\n",
            "Step [8470/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0168, d_svhn_loss: 0.0309, d_fake_loss: 0.0640, g_loss: 1.3224\n",
            "Step [8480/80000], d_real_loss: 0.0808, d_mnist_loss: 0.0357, d_svhn_loss: 0.0451, d_fake_loss: 0.0780, g_loss: 1.2478\n",
            "Step [8490/80000], d_real_loss: 0.1429, d_mnist_loss: 0.1041, d_svhn_loss: 0.0389, d_fake_loss: 0.0655, g_loss: 1.1051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [8500/80000], d_real_loss: 0.0751, d_mnist_loss: 0.0259, d_svhn_loss: 0.0492, d_fake_loss: 0.5593, g_loss: 1.4454\n",
            "saved ./samples_fashion/sample-8500-m-s.png\n",
            "saved ./samples_fashion/sample-8500-s-m.png\n",
            "Step [8510/80000], d_real_loss: 0.1690, d_mnist_loss: 0.0235, d_svhn_loss: 0.1455, d_fake_loss: 0.0667, g_loss: 1.1479\n",
            "Step [8520/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0487, d_svhn_loss: 0.0355, d_fake_loss: 0.1536, g_loss: 1.4868\n",
            "Step [8530/80000], d_real_loss: 0.1763, d_mnist_loss: 0.0694, d_svhn_loss: 0.1069, d_fake_loss: 0.2125, g_loss: 0.6231\n",
            "Step [8540/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0265, d_svhn_loss: 0.0386, d_fake_loss: 0.0602, g_loss: 1.0076\n",
            "Step [8550/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0270, d_svhn_loss: 0.0352, d_fake_loss: 0.0635, g_loss: 1.2286\n",
            "Step [8560/80000], d_real_loss: 0.1418, d_mnist_loss: 0.1011, d_svhn_loss: 0.0407, d_fake_loss: 0.1057, g_loss: 1.1795\n",
            "Step [8570/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0345, d_svhn_loss: 0.0735, d_fake_loss: 0.0580, g_loss: 1.1443\n",
            "Step [8580/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0198, d_svhn_loss: 0.0447, d_fake_loss: 0.1633, g_loss: 1.2388\n",
            "Step [8590/80000], d_real_loss: 0.1306, d_mnist_loss: 0.0233, d_svhn_loss: 0.1072, d_fake_loss: 0.0788, g_loss: 1.0549\n",
            "Step [8600/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0181, d_svhn_loss: 0.0432, d_fake_loss: 0.0842, g_loss: 1.4832\n",
            "Step [8610/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0225, d_svhn_loss: 0.0502, d_fake_loss: 0.0618, g_loss: 1.2789\n",
            "Step [8620/80000], d_real_loss: 0.3617, d_mnist_loss: 0.0660, d_svhn_loss: 0.2957, d_fake_loss: 0.5452, g_loss: 1.1176\n",
            "Step [8630/80000], d_real_loss: 0.1111, d_mnist_loss: 0.0210, d_svhn_loss: 0.0901, d_fake_loss: 0.0446, g_loss: 1.0534\n",
            "Step [8640/80000], d_real_loss: 0.0880, d_mnist_loss: 0.0310, d_svhn_loss: 0.0570, d_fake_loss: 0.0752, g_loss: 1.1990\n",
            "Step [8650/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0196, d_svhn_loss: 0.0574, d_fake_loss: 0.0644, g_loss: 1.3074\n",
            "Step [8660/80000], d_real_loss: 0.0996, d_mnist_loss: 0.0241, d_svhn_loss: 0.0755, d_fake_loss: 0.1183, g_loss: 1.3515\n",
            "Step [8670/80000], d_real_loss: 0.1671, d_mnist_loss: 0.0169, d_svhn_loss: 0.1503, d_fake_loss: 0.1573, g_loss: 0.9572\n",
            "Step [8680/80000], d_real_loss: 0.1020, d_mnist_loss: 0.0207, d_svhn_loss: 0.0813, d_fake_loss: 0.1426, g_loss: 1.4245\n",
            "Step [8690/80000], d_real_loss: 0.1748, d_mnist_loss: 0.0330, d_svhn_loss: 0.1418, d_fake_loss: 0.1636, g_loss: 0.9248\n",
            "Step [8700/80000], d_real_loss: 0.3075, d_mnist_loss: 0.0573, d_svhn_loss: 0.2503, d_fake_loss: 0.2197, g_loss: 0.9193\n",
            "Step [8710/80000], d_real_loss: 0.1210, d_mnist_loss: 0.0306, d_svhn_loss: 0.0904, d_fake_loss: 0.1170, g_loss: 1.3802\n",
            "Step [8720/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0121, d_svhn_loss: 0.0394, d_fake_loss: 0.0706, g_loss: 0.8828\n",
            "Step [8730/80000], d_real_loss: 0.1438, d_mnist_loss: 0.1042, d_svhn_loss: 0.0396, d_fake_loss: 0.1366, g_loss: 1.7291\n",
            "Step [8740/80000], d_real_loss: 0.1134, d_mnist_loss: 0.0456, d_svhn_loss: 0.0678, d_fake_loss: 0.2106, g_loss: 1.3605\n",
            "Step [8750/80000], d_real_loss: 0.1730, d_mnist_loss: 0.0209, d_svhn_loss: 0.1520, d_fake_loss: 0.2663, g_loss: 0.9263\n",
            "Step [8760/80000], d_real_loss: 0.1073, d_mnist_loss: 0.0300, d_svhn_loss: 0.0773, d_fake_loss: 0.0586, g_loss: 1.1333\n",
            "Step [8770/80000], d_real_loss: 0.1050, d_mnist_loss: 0.0304, d_svhn_loss: 0.0747, d_fake_loss: 0.0732, g_loss: 1.1446\n",
            "Step [8780/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0218, d_svhn_loss: 0.0347, d_fake_loss: 0.0731, g_loss: 1.0901\n",
            "Step [8790/80000], d_real_loss: 0.2729, d_mnist_loss: 0.0994, d_svhn_loss: 0.1735, d_fake_loss: 0.2014, g_loss: 0.6958\n",
            "Step [8800/80000], d_real_loss: 0.0884, d_mnist_loss: 0.0272, d_svhn_loss: 0.0612, d_fake_loss: 0.2963, g_loss: 1.2181\n",
            "Step [8810/80000], d_real_loss: 0.1163, d_mnist_loss: 0.0218, d_svhn_loss: 0.0946, d_fake_loss: 0.0755, g_loss: 1.1134\n",
            "Step [8820/80000], d_real_loss: 0.2387, d_mnist_loss: 0.0256, d_svhn_loss: 0.2131, d_fake_loss: 0.1294, g_loss: 0.8304\n",
            "Step [8830/80000], d_real_loss: 0.1398, d_mnist_loss: 0.0283, d_svhn_loss: 0.1116, d_fake_loss: 0.0608, g_loss: 0.9509\n",
            "Step [8840/80000], d_real_loss: 0.1139, d_mnist_loss: 0.0384, d_svhn_loss: 0.0756, d_fake_loss: 0.0846, g_loss: 1.2751\n",
            "Step [8850/80000], d_real_loss: 0.2003, d_mnist_loss: 0.0194, d_svhn_loss: 0.1809, d_fake_loss: 0.2292, g_loss: 1.4420\n",
            "Step [8860/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0507, d_svhn_loss: 0.0282, d_fake_loss: 0.0680, g_loss: 1.0509\n",
            "Step [8870/80000], d_real_loss: 0.0894, d_mnist_loss: 0.0354, d_svhn_loss: 0.0540, d_fake_loss: 0.0537, g_loss: 1.0568\n",
            "Step [8880/80000], d_real_loss: 0.2541, d_mnist_loss: 0.0177, d_svhn_loss: 0.2364, d_fake_loss: 0.1009, g_loss: 0.9162\n",
            "Step [8890/80000], d_real_loss: 0.0856, d_mnist_loss: 0.0386, d_svhn_loss: 0.0470, d_fake_loss: 0.0501, g_loss: 1.2866\n",
            "Step [8900/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0240, d_svhn_loss: 0.0571, d_fake_loss: 0.1446, g_loss: 1.3255\n",
            "Step [8910/80000], d_real_loss: 0.1072, d_mnist_loss: 0.0191, d_svhn_loss: 0.0881, d_fake_loss: 0.1752, g_loss: 1.9474\n",
            "Step [8920/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0252, d_svhn_loss: 0.0432, d_fake_loss: 0.2392, g_loss: 1.5160\n",
            "Step [8930/80000], d_real_loss: 0.1922, d_mnist_loss: 0.1092, d_svhn_loss: 0.0830, d_fake_loss: 0.0655, g_loss: 1.1351\n",
            "Step [8940/80000], d_real_loss: 0.0897, d_mnist_loss: 0.0340, d_svhn_loss: 0.0557, d_fake_loss: 0.1130, g_loss: 0.9203\n",
            "Step [8950/80000], d_real_loss: 0.1842, d_mnist_loss: 0.1369, d_svhn_loss: 0.0473, d_fake_loss: 0.1494, g_loss: 1.1521\n",
            "Step [8960/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0175, d_svhn_loss: 0.0334, d_fake_loss: 0.0682, g_loss: 1.1924\n",
            "Step [8970/80000], d_real_loss: 0.2108, d_mnist_loss: 0.0366, d_svhn_loss: 0.1742, d_fake_loss: 0.0879, g_loss: 1.1221\n",
            "Step [8980/80000], d_real_loss: 0.1257, d_mnist_loss: 0.0528, d_svhn_loss: 0.0729, d_fake_loss: 0.1165, g_loss: 1.5192\n",
            "Step [8990/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0361, d_svhn_loss: 0.0330, d_fake_loss: 0.1658, g_loss: 1.6930\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [9000/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0286, d_svhn_loss: 0.0455, d_fake_loss: 0.1708, g_loss: 1.1014\n",
            "saved ./samples_fashion/sample-9000-m-s.png\n",
            "saved ./samples_fashion/sample-9000-s-m.png\n",
            "Step [9010/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0251, d_svhn_loss: 0.0282, d_fake_loss: 0.0420, g_loss: 1.1008\n",
            "Step [9020/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0355, d_svhn_loss: 0.0312, d_fake_loss: 0.1659, g_loss: 1.2348\n",
            "Step [9030/80000], d_real_loss: 0.1828, d_mnist_loss: 0.0160, d_svhn_loss: 0.1667, d_fake_loss: 0.3031, g_loss: 1.4413\n",
            "Step [9040/80000], d_real_loss: 0.2815, d_mnist_loss: 0.2400, d_svhn_loss: 0.0414, d_fake_loss: 0.1812, g_loss: 1.9051\n",
            "Step [9050/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0361, d_svhn_loss: 0.0280, d_fake_loss: 0.0453, g_loss: 1.1164\n",
            "Step [9060/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0192, d_svhn_loss: 0.0250, d_fake_loss: 0.1060, g_loss: 1.3550\n",
            "Step [9070/80000], d_real_loss: 0.0925, d_mnist_loss: 0.0167, d_svhn_loss: 0.0758, d_fake_loss: 0.0469, g_loss: 0.9276\n",
            "Step [9080/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0177, d_svhn_loss: 0.0556, d_fake_loss: 0.0482, g_loss: 1.2941\n",
            "Step [9090/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0216, d_svhn_loss: 0.0270, d_fake_loss: 0.1211, g_loss: 1.1321\n",
            "Step [9100/80000], d_real_loss: 0.0920, d_mnist_loss: 0.0372, d_svhn_loss: 0.0548, d_fake_loss: 0.2175, g_loss: 1.1054\n",
            "Step [9110/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0140, d_svhn_loss: 0.0405, d_fake_loss: 0.1237, g_loss: 0.9743\n",
            "Step [9120/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0284, d_svhn_loss: 0.0400, d_fake_loss: 0.0593, g_loss: 1.2279\n",
            "Step [9130/80000], d_real_loss: 0.2129, d_mnist_loss: 0.0294, d_svhn_loss: 0.1834, d_fake_loss: 0.0556, g_loss: 1.0087\n",
            "Step [9140/80000], d_real_loss: 0.2214, d_mnist_loss: 0.0163, d_svhn_loss: 0.2051, d_fake_loss: 0.1236, g_loss: 1.3105\n",
            "Step [9150/80000], d_real_loss: 0.0863, d_mnist_loss: 0.0401, d_svhn_loss: 0.0463, d_fake_loss: 0.0856, g_loss: 1.2529\n",
            "Step [9160/80000], d_real_loss: 0.1837, d_mnist_loss: 0.1509, d_svhn_loss: 0.0329, d_fake_loss: 0.2601, g_loss: 0.6266\n",
            "Step [9170/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0315, d_svhn_loss: 0.0446, d_fake_loss: 0.1270, g_loss: 1.2881\n",
            "Step [9180/80000], d_real_loss: 0.0665, d_mnist_loss: 0.0215, d_svhn_loss: 0.0450, d_fake_loss: 0.0617, g_loss: 0.9144\n",
            "Step [9190/80000], d_real_loss: 0.2023, d_mnist_loss: 0.0224, d_svhn_loss: 0.1799, d_fake_loss: 0.3675, g_loss: 1.1139\n",
            "Step [9200/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0204, d_svhn_loss: 0.0606, d_fake_loss: 0.0823, g_loss: 1.0711\n",
            "Step [9210/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0197, d_svhn_loss: 0.0351, d_fake_loss: 0.0726, g_loss: 0.9994\n",
            "Step [9220/80000], d_real_loss: 0.0769, d_mnist_loss: 0.0414, d_svhn_loss: 0.0355, d_fake_loss: 0.1348, g_loss: 1.0204\n",
            "Step [9230/80000], d_real_loss: 0.1958, d_mnist_loss: 0.1471, d_svhn_loss: 0.0487, d_fake_loss: 0.0578, g_loss: 1.1956\n",
            "Step [9240/80000], d_real_loss: 0.0822, d_mnist_loss: 0.0492, d_svhn_loss: 0.0331, d_fake_loss: 0.0739, g_loss: 1.2023\n",
            "Step [9250/80000], d_real_loss: 0.1327, d_mnist_loss: 0.0672, d_svhn_loss: 0.0656, d_fake_loss: 0.1385, g_loss: 1.5762\n",
            "Step [9260/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0213, d_svhn_loss: 0.0449, d_fake_loss: 0.0982, g_loss: 1.3284\n",
            "Step [9270/80000], d_real_loss: 0.2358, d_mnist_loss: 0.0572, d_svhn_loss: 0.1786, d_fake_loss: 0.2011, g_loss: 1.1421\n",
            "Step [9280/80000], d_real_loss: 0.2681, d_mnist_loss: 0.1924, d_svhn_loss: 0.0757, d_fake_loss: 0.1162, g_loss: 1.0629\n",
            "Step [9290/80000], d_real_loss: 0.1610, d_mnist_loss: 0.0188, d_svhn_loss: 0.1423, d_fake_loss: 0.0991, g_loss: 1.1420\n",
            "Step [9300/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0224, d_svhn_loss: 0.0380, d_fake_loss: 0.0768, g_loss: 1.4170\n",
            "Step [9310/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0214, d_svhn_loss: 0.0691, d_fake_loss: 0.0931, g_loss: 1.2897\n",
            "Step [9320/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0246, d_svhn_loss: 0.0428, d_fake_loss: 0.1076, g_loss: 1.3253\n",
            "Step [9330/80000], d_real_loss: 0.0883, d_mnist_loss: 0.0170, d_svhn_loss: 0.0713, d_fake_loss: 0.1168, g_loss: 1.4490\n",
            "Step [9340/80000], d_real_loss: 0.1072, d_mnist_loss: 0.0246, d_svhn_loss: 0.0826, d_fake_loss: 0.0779, g_loss: 0.7187\n",
            "Step [9350/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0280, d_svhn_loss: 0.0507, d_fake_loss: 0.0956, g_loss: 1.0882\n",
            "Step [9360/80000], d_real_loss: 0.0654, d_mnist_loss: 0.0246, d_svhn_loss: 0.0408, d_fake_loss: 0.0676, g_loss: 1.0937\n",
            "Step [9370/80000], d_real_loss: 0.1024, d_mnist_loss: 0.0278, d_svhn_loss: 0.0745, d_fake_loss: 0.1532, g_loss: 1.2758\n",
            "Step [9380/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0246, d_svhn_loss: 0.0493, d_fake_loss: 0.1244, g_loss: 1.3894\n",
            "Step [9390/80000], d_real_loss: 0.1250, d_mnist_loss: 0.0241, d_svhn_loss: 0.1009, d_fake_loss: 0.1317, g_loss: 1.5405\n",
            "Step [9400/80000], d_real_loss: 0.1156, d_mnist_loss: 0.0793, d_svhn_loss: 0.0363, d_fake_loss: 0.0582, g_loss: 0.9884\n",
            "Step [9410/80000], d_real_loss: 0.0754, d_mnist_loss: 0.0228, d_svhn_loss: 0.0526, d_fake_loss: 0.0744, g_loss: 1.0982\n",
            "Step [9420/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0163, d_svhn_loss: 0.0429, d_fake_loss: 0.0671, g_loss: 1.0934\n",
            "Step [9430/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0354, d_svhn_loss: 0.0483, d_fake_loss: 0.0515, g_loss: 1.1135\n",
            "Step [9440/80000], d_real_loss: 0.1780, d_mnist_loss: 0.0685, d_svhn_loss: 0.1095, d_fake_loss: 0.1003, g_loss: 1.2752\n",
            "Step [9450/80000], d_real_loss: 0.0981, d_mnist_loss: 0.0188, d_svhn_loss: 0.0793, d_fake_loss: 0.0636, g_loss: 1.2760\n",
            "Step [9460/80000], d_real_loss: 0.1455, d_mnist_loss: 0.0755, d_svhn_loss: 0.0699, d_fake_loss: 0.0938, g_loss: 1.2681\n",
            "Step [9470/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0147, d_svhn_loss: 0.0369, d_fake_loss: 0.0635, g_loss: 1.0945\n",
            "Step [9480/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0186, d_svhn_loss: 0.0397, d_fake_loss: 0.0882, g_loss: 1.4671\n",
            "Step [9490/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0236, d_svhn_loss: 0.0411, d_fake_loss: 0.0630, g_loss: 1.2056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [9500/80000], d_real_loss: 0.4007, d_mnist_loss: 0.3527, d_svhn_loss: 0.0479, d_fake_loss: 0.3320, g_loss: 1.9383\n",
            "saved ./samples_fashion/sample-9500-m-s.png\n",
            "saved ./samples_fashion/sample-9500-s-m.png\n",
            "Step [9510/80000], d_real_loss: 0.1231, d_mnist_loss: 0.0351, d_svhn_loss: 0.0880, d_fake_loss: 0.0503, g_loss: 1.0798\n",
            "Step [9520/80000], d_real_loss: 0.1310, d_mnist_loss: 0.0755, d_svhn_loss: 0.0555, d_fake_loss: 0.1315, g_loss: 1.6108\n",
            "Step [9530/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0302, d_svhn_loss: 0.0502, d_fake_loss: 0.0558, g_loss: 1.0103\n",
            "Step [9540/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0209, d_svhn_loss: 0.0363, d_fake_loss: 0.1089, g_loss: 1.0602\n",
            "Step [9550/80000], d_real_loss: 0.1477, d_mnist_loss: 0.0400, d_svhn_loss: 0.1076, d_fake_loss: 0.0558, g_loss: 1.1187\n",
            "Step [9560/80000], d_real_loss: 0.1054, d_mnist_loss: 0.0162, d_svhn_loss: 0.0892, d_fake_loss: 0.1209, g_loss: 1.3724\n",
            "Step [9570/80000], d_real_loss: 0.0970, d_mnist_loss: 0.0330, d_svhn_loss: 0.0639, d_fake_loss: 0.0657, g_loss: 0.9889\n",
            "Step [9580/80000], d_real_loss: 0.1122, d_mnist_loss: 0.0281, d_svhn_loss: 0.0841, d_fake_loss: 0.0875, g_loss: 1.0756\n",
            "Step [9590/80000], d_real_loss: 0.0746, d_mnist_loss: 0.0132, d_svhn_loss: 0.0614, d_fake_loss: 0.0800, g_loss: 1.0731\n",
            "Step [9600/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0282, d_svhn_loss: 0.0483, d_fake_loss: 0.0737, g_loss: 1.2608\n",
            "Step [9610/80000], d_real_loss: 0.1127, d_mnist_loss: 0.0828, d_svhn_loss: 0.0298, d_fake_loss: 0.1052, g_loss: 1.0940\n",
            "Step [9620/80000], d_real_loss: 0.1841, d_mnist_loss: 0.0818, d_svhn_loss: 0.1024, d_fake_loss: 0.1656, g_loss: 1.2982\n",
            "Step [9630/80000], d_real_loss: 0.1419, d_mnist_loss: 0.0474, d_svhn_loss: 0.0944, d_fake_loss: 0.0551, g_loss: 1.0116\n",
            "Step [9640/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0205, d_svhn_loss: 0.0349, d_fake_loss: 0.1275, g_loss: 1.2440\n",
            "Step [9650/80000], d_real_loss: 0.2355, d_mnist_loss: 0.0172, d_svhn_loss: 0.2183, d_fake_loss: 1.1143, g_loss: 1.3255\n",
            "Step [9660/80000], d_real_loss: 0.0928, d_mnist_loss: 0.0289, d_svhn_loss: 0.0639, d_fake_loss: 0.0602, g_loss: 1.0125\n",
            "Step [9670/80000], d_real_loss: 0.1199, d_mnist_loss: 0.0367, d_svhn_loss: 0.0831, d_fake_loss: 0.1068, g_loss: 1.0355\n",
            "Step [9680/80000], d_real_loss: 0.1097, d_mnist_loss: 0.0173, d_svhn_loss: 0.0925, d_fake_loss: 0.1659, g_loss: 1.3881\n",
            "Step [9690/80000], d_real_loss: 0.1640, d_mnist_loss: 0.1256, d_svhn_loss: 0.0384, d_fake_loss: 0.0704, g_loss: 1.3294\n",
            "Step [9700/80000], d_real_loss: 0.1241, d_mnist_loss: 0.0672, d_svhn_loss: 0.0569, d_fake_loss: 0.0914, g_loss: 1.3323\n",
            "Step [9710/80000], d_real_loss: 0.1322, d_mnist_loss: 0.0633, d_svhn_loss: 0.0689, d_fake_loss: 0.0821, g_loss: 1.1598\n",
            "Step [9720/80000], d_real_loss: 0.1651, d_mnist_loss: 0.0193, d_svhn_loss: 0.1459, d_fake_loss: 0.3878, g_loss: 1.1887\n",
            "Step [9730/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0167, d_svhn_loss: 0.0420, d_fake_loss: 0.0835, g_loss: 1.1787\n",
            "Step [9740/80000], d_real_loss: 0.0915, d_mnist_loss: 0.0277, d_svhn_loss: 0.0638, d_fake_loss: 0.0680, g_loss: 1.1165\n",
            "Step [9750/80000], d_real_loss: 0.0854, d_mnist_loss: 0.0426, d_svhn_loss: 0.0428, d_fake_loss: 0.3226, g_loss: 0.5418\n",
            "Step [9760/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0233, d_svhn_loss: 0.0302, d_fake_loss: 0.1609, g_loss: 1.4393\n",
            "Step [9770/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0218, d_svhn_loss: 0.0331, d_fake_loss: 0.0816, g_loss: 1.3584\n",
            "Step [9780/80000], d_real_loss: 0.0760, d_mnist_loss: 0.0285, d_svhn_loss: 0.0475, d_fake_loss: 0.0761, g_loss: 0.8422\n",
            "Step [9790/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0244, d_svhn_loss: 0.0383, d_fake_loss: 0.0631, g_loss: 1.2403\n",
            "Step [9800/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0229, d_svhn_loss: 0.0372, d_fake_loss: 0.1160, g_loss: 1.5571\n",
            "Step [9810/80000], d_real_loss: 0.0767, d_mnist_loss: 0.0188, d_svhn_loss: 0.0579, d_fake_loss: 0.1828, g_loss: 1.1474\n",
            "Step [9820/80000], d_real_loss: 0.1499, d_mnist_loss: 0.1075, d_svhn_loss: 0.0423, d_fake_loss: 0.3563, g_loss: 2.0195\n",
            "Step [9830/80000], d_real_loss: 0.2297, d_mnist_loss: 0.1581, d_svhn_loss: 0.0716, d_fake_loss: 0.1014, g_loss: 1.1250\n",
            "Step [9840/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0131, d_svhn_loss: 0.0375, d_fake_loss: 0.1709, g_loss: 0.6125\n",
            "Step [9850/80000], d_real_loss: 0.0626, d_mnist_loss: 0.0206, d_svhn_loss: 0.0420, d_fake_loss: 0.0867, g_loss: 1.0097\n",
            "Step [9860/80000], d_real_loss: 0.1839, d_mnist_loss: 0.0212, d_svhn_loss: 0.1627, d_fake_loss: 0.1181, g_loss: 1.1924\n",
            "Step [9870/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0275, d_svhn_loss: 0.0414, d_fake_loss: 0.0869, g_loss: 1.1438\n",
            "Step [9880/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0384, d_svhn_loss: 0.0342, d_fake_loss: 0.0899, g_loss: 1.1180\n",
            "Step [9890/80000], d_real_loss: 0.2635, d_mnist_loss: 0.0158, d_svhn_loss: 0.2477, d_fake_loss: 0.4412, g_loss: 1.1723\n",
            "Step [9900/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0307, d_svhn_loss: 0.0354, d_fake_loss: 0.0522, g_loss: 1.0894\n",
            "Step [9910/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0518, d_svhn_loss: 0.0383, d_fake_loss: 0.3050, g_loss: 1.6864\n",
            "Step [9920/80000], d_real_loss: 0.1468, d_mnist_loss: 0.0191, d_svhn_loss: 0.1278, d_fake_loss: 0.0534, g_loss: 1.1483\n",
            "Step [9930/80000], d_real_loss: 0.1318, d_mnist_loss: 0.0668, d_svhn_loss: 0.0650, d_fake_loss: 0.2453, g_loss: 1.1142\n",
            "Step [9940/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0195, d_svhn_loss: 0.0488, d_fake_loss: 0.0855, g_loss: 0.8811\n",
            "Step [9950/80000], d_real_loss: 0.0817, d_mnist_loss: 0.0413, d_svhn_loss: 0.0404, d_fake_loss: 0.0789, g_loss: 1.3031\n",
            "Step [9960/80000], d_real_loss: 0.1196, d_mnist_loss: 0.0777, d_svhn_loss: 0.0419, d_fake_loss: 0.0859, g_loss: 1.2316\n",
            "Step [9970/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0113, d_svhn_loss: 0.0528, d_fake_loss: 0.0461, g_loss: 1.2024\n",
            "Step [9980/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0241, d_svhn_loss: 0.0269, d_fake_loss: 0.1104, g_loss: 0.7709\n",
            "Step [9990/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0280, d_svhn_loss: 0.0621, d_fake_loss: 0.0715, g_loss: 1.3789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999986290931702]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [10000/80000], d_real_loss: 0.1202, d_mnist_loss: 0.0332, d_svhn_loss: 0.0870, d_fake_loss: 0.1475, g_loss: 1.0848\n",
            "saved ./samples_fashion/sample-10000-m-s.png\n",
            "saved ./samples_fashion/sample-10000-s-m.png\n",
            "Step [10010/80000], d_real_loss: 0.0940, d_mnist_loss: 0.0130, d_svhn_loss: 0.0810, d_fake_loss: 0.0770, g_loss: 0.8130\n",
            "Step [10020/80000], d_real_loss: 0.1992, d_mnist_loss: 0.0188, d_svhn_loss: 0.1804, d_fake_loss: 0.0603, g_loss: 0.9908\n",
            "Step [10030/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0187, d_svhn_loss: 0.0487, d_fake_loss: 0.0894, g_loss: 1.1513\n",
            "Step [10040/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0249, d_svhn_loss: 0.0415, d_fake_loss: 0.0522, g_loss: 1.1991\n",
            "Step [10050/80000], d_real_loss: 0.0808, d_mnist_loss: 0.0156, d_svhn_loss: 0.0652, d_fake_loss: 0.1024, g_loss: 1.2437\n",
            "Step [10060/80000], d_real_loss: 0.2016, d_mnist_loss: 0.0202, d_svhn_loss: 0.1814, d_fake_loss: 0.0952, g_loss: 1.2537\n",
            "Step [10070/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0196, d_svhn_loss: 0.0795, d_fake_loss: 0.0531, g_loss: 1.1900\n",
            "Step [10080/80000], d_real_loss: 0.0917, d_mnist_loss: 0.0162, d_svhn_loss: 0.0755, d_fake_loss: 0.0812, g_loss: 1.2815\n",
            "Step [10090/80000], d_real_loss: 0.1755, d_mnist_loss: 0.0706, d_svhn_loss: 0.1049, d_fake_loss: 0.2551, g_loss: 0.8770\n",
            "Step [10100/80000], d_real_loss: 0.4095, d_mnist_loss: 0.3278, d_svhn_loss: 0.0816, d_fake_loss: 0.1956, g_loss: 1.3500\n",
            "Step [10110/80000], d_real_loss: 0.1312, d_mnist_loss: 0.0191, d_svhn_loss: 0.1121, d_fake_loss: 0.2730, g_loss: 1.1527\n",
            "Step [10120/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0180, d_svhn_loss: 0.0699, d_fake_loss: 0.0723, g_loss: 1.0854\n",
            "Step [10130/80000], d_real_loss: 0.1956, d_mnist_loss: 0.0171, d_svhn_loss: 0.1785, d_fake_loss: 0.0879, g_loss: 1.3551\n",
            "Step [10140/80000], d_real_loss: 0.2146, d_mnist_loss: 0.0565, d_svhn_loss: 0.1581, d_fake_loss: 0.3517, g_loss: 1.0163\n",
            "Step [10150/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0190, d_svhn_loss: 0.0424, d_fake_loss: 0.0740, g_loss: 1.0465\n",
            "Step [10160/80000], d_real_loss: 0.0994, d_mnist_loss: 0.0435, d_svhn_loss: 0.0558, d_fake_loss: 0.0686, g_loss: 0.8521\n",
            "Step [10170/80000], d_real_loss: 0.1744, d_mnist_loss: 0.1138, d_svhn_loss: 0.0606, d_fake_loss: 0.0824, g_loss: 1.1495\n",
            "Step [10180/80000], d_real_loss: 0.2429, d_mnist_loss: 0.0396, d_svhn_loss: 0.2032, d_fake_loss: 0.1476, g_loss: 1.0347\n",
            "Step [10190/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0217, d_svhn_loss: 0.0420, d_fake_loss: 0.0702, g_loss: 1.2719\n",
            "Step [10200/80000], d_real_loss: 0.2880, d_mnist_loss: 0.0198, d_svhn_loss: 0.2681, d_fake_loss: 0.2478, g_loss: 0.8115\n",
            "Step [10210/80000], d_real_loss: 0.2321, d_mnist_loss: 0.0190, d_svhn_loss: 0.2130, d_fake_loss: 0.2949, g_loss: 1.1728\n",
            "Step [10220/80000], d_real_loss: 0.1076, d_mnist_loss: 0.0353, d_svhn_loss: 0.0723, d_fake_loss: 0.1178, g_loss: 1.3716\n",
            "Step [10230/80000], d_real_loss: 0.2706, d_mnist_loss: 0.0598, d_svhn_loss: 0.2108, d_fake_loss: 0.3148, g_loss: 1.3417\n",
            "Step [10240/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0181, d_svhn_loss: 0.0541, d_fake_loss: 0.1183, g_loss: 1.4039\n",
            "Step [10250/80000], d_real_loss: 0.0759, d_mnist_loss: 0.0159, d_svhn_loss: 0.0600, d_fake_loss: 0.0410, g_loss: 1.2769\n",
            "Step [10260/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0306, d_svhn_loss: 0.0377, d_fake_loss: 0.1291, g_loss: 1.0847\n",
            "Step [10270/80000], d_real_loss: 0.0966, d_mnist_loss: 0.0156, d_svhn_loss: 0.0810, d_fake_loss: 0.1465, g_loss: 0.8836\n",
            "Step [10280/80000], d_real_loss: 0.1263, d_mnist_loss: 0.0170, d_svhn_loss: 0.1093, d_fake_loss: 0.1335, g_loss: 1.0109\n",
            "Step [10290/80000], d_real_loss: 0.1198, d_mnist_loss: 0.0554, d_svhn_loss: 0.0643, d_fake_loss: 0.0867, g_loss: 1.3009\n",
            "Step [10300/80000], d_real_loss: 0.1211, d_mnist_loss: 0.0362, d_svhn_loss: 0.0849, d_fake_loss: 0.5106, g_loss: 1.6994\n",
            "Step [10310/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0223, d_svhn_loss: 0.0514, d_fake_loss: 0.0533, g_loss: 1.1387\n",
            "Step [10320/80000], d_real_loss: 0.0994, d_mnist_loss: 0.0200, d_svhn_loss: 0.0795, d_fake_loss: 0.0562, g_loss: 1.0511\n",
            "Step [10330/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0127, d_svhn_loss: 0.0534, d_fake_loss: 0.1599, g_loss: 1.2903\n",
            "Step [10340/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0253, d_svhn_loss: 0.0430, d_fake_loss: 0.1402, g_loss: 0.8758\n",
            "Step [10350/80000], d_real_loss: 0.1544, d_mnist_loss: 0.0762, d_svhn_loss: 0.0782, d_fake_loss: 0.0669, g_loss: 0.9910\n",
            "Step [10360/80000], d_real_loss: 0.0903, d_mnist_loss: 0.0157, d_svhn_loss: 0.0745, d_fake_loss: 0.1728, g_loss: 1.0046\n",
            "Step [10370/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0136, d_svhn_loss: 0.0484, d_fake_loss: 0.0863, g_loss: 1.3762\n",
            "Step [10380/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0231, d_svhn_loss: 0.0569, d_fake_loss: 0.1617, g_loss: 1.3798\n",
            "Step [10390/80000], d_real_loss: 0.0865, d_mnist_loss: 0.0265, d_svhn_loss: 0.0600, d_fake_loss: 0.0930, g_loss: 1.5015\n",
            "Step [10400/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0185, d_svhn_loss: 0.0620, d_fake_loss: 0.0860, g_loss: 1.3218\n",
            "Step [10410/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0503, d_svhn_loss: 0.0577, d_fake_loss: 0.0522, g_loss: 0.9887\n",
            "Step [10420/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0153, d_svhn_loss: 0.0546, d_fake_loss: 0.2166, g_loss: 1.5163\n",
            "Step [10430/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0215, d_svhn_loss: 0.0435, d_fake_loss: 0.1428, g_loss: 0.9133\n",
            "Step [10440/80000], d_real_loss: 0.0936, d_mnist_loss: 0.0267, d_svhn_loss: 0.0668, d_fake_loss: 0.1807, g_loss: 1.2830\n",
            "Step [10450/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0115, d_svhn_loss: 0.0364, d_fake_loss: 0.0322, g_loss: 1.1007\n",
            "Step [10460/80000], d_real_loss: 0.1431, d_mnist_loss: 0.0496, d_svhn_loss: 0.0935, d_fake_loss: 0.1099, g_loss: 1.3390\n",
            "Step [10470/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0249, d_svhn_loss: 0.0254, d_fake_loss: 0.0701, g_loss: 1.1200\n",
            "Step [10480/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0175, d_svhn_loss: 0.0345, d_fake_loss: 0.0886, g_loss: 1.0862\n",
            "Step [10490/80000], d_real_loss: 0.0931, d_mnist_loss: 0.0403, d_svhn_loss: 0.0528, d_fake_loss: 0.0558, g_loss: 1.1284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999663829803467]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [10500/80000], d_real_loss: 0.1023, d_mnist_loss: 0.0670, d_svhn_loss: 0.0353, d_fake_loss: 0.0851, g_loss: 1.2403\n",
            "saved ./samples_fashion/sample-10500-m-s.png\n",
            "saved ./samples_fashion/sample-10500-s-m.png\n",
            "Step [10510/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0160, d_svhn_loss: 0.0708, d_fake_loss: 0.0264, g_loss: 1.0081\n",
            "Step [10520/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0199, d_svhn_loss: 0.0487, d_fake_loss: 0.1872, g_loss: 0.7085\n",
            "Step [10530/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0146, d_svhn_loss: 0.0282, d_fake_loss: 0.1041, g_loss: 1.3538\n",
            "Step [10540/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0178, d_svhn_loss: 0.0454, d_fake_loss: 0.0476, g_loss: 1.0904\n",
            "Step [10550/80000], d_real_loss: 0.0889, d_mnist_loss: 0.0200, d_svhn_loss: 0.0689, d_fake_loss: 0.0912, g_loss: 1.1413\n",
            "Step [10560/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0277, d_svhn_loss: 0.0379, d_fake_loss: 0.0943, g_loss: 1.0954\n",
            "Step [10570/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0141, d_svhn_loss: 0.0301, d_fake_loss: 0.0689, g_loss: 0.9351\n",
            "Step [10580/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0181, d_svhn_loss: 0.0374, d_fake_loss: 0.0899, g_loss: 0.9868\n",
            "Step [10590/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0398, d_svhn_loss: 0.0477, d_fake_loss: 0.0851, g_loss: 1.1339\n",
            "Step [10600/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0139, d_svhn_loss: 0.0423, d_fake_loss: 0.2378, g_loss: 0.6752\n",
            "Step [10610/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0406, d_svhn_loss: 0.0471, d_fake_loss: 0.0599, g_loss: 1.0785\n",
            "Step [10620/80000], d_real_loss: 0.1206, d_mnist_loss: 0.0224, d_svhn_loss: 0.0981, d_fake_loss: 0.0320, g_loss: 1.2685\n",
            "Step [10630/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0164, d_svhn_loss: 0.0518, d_fake_loss: 0.0586, g_loss: 1.1638\n",
            "Step [10640/80000], d_real_loss: 0.0735, d_mnist_loss: 0.0269, d_svhn_loss: 0.0466, d_fake_loss: 0.0767, g_loss: 1.1767\n",
            "Step [10650/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0391, d_svhn_loss: 0.0420, d_fake_loss: 0.0506, g_loss: 0.9748\n",
            "Step [10660/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0233, d_svhn_loss: 0.0365, d_fake_loss: 0.0527, g_loss: 1.1890\n",
            "Step [10670/80000], d_real_loss: 0.1747, d_mnist_loss: 0.0206, d_svhn_loss: 0.1541, d_fake_loss: 0.0523, g_loss: 1.0269\n",
            "Step [10680/80000], d_real_loss: 0.0946, d_mnist_loss: 0.0179, d_svhn_loss: 0.0767, d_fake_loss: 0.0681, g_loss: 1.2424\n",
            "Step [10690/80000], d_real_loss: 0.1409, d_mnist_loss: 0.0244, d_svhn_loss: 0.1164, d_fake_loss: 0.1265, g_loss: 1.2736\n",
            "Step [10700/80000], d_real_loss: 0.1602, d_mnist_loss: 0.0154, d_svhn_loss: 0.1448, d_fake_loss: 0.0900, g_loss: 1.3979\n",
            "Step [10710/80000], d_real_loss: 0.0905, d_mnist_loss: 0.0352, d_svhn_loss: 0.0554, d_fake_loss: 0.2107, g_loss: 0.9758\n",
            "Step [10720/80000], d_real_loss: 0.2338, d_mnist_loss: 0.0650, d_svhn_loss: 0.1688, d_fake_loss: 0.0982, g_loss: 1.4760\n",
            "Step [10730/80000], d_real_loss: 0.1070, d_mnist_loss: 0.0200, d_svhn_loss: 0.0869, d_fake_loss: 0.0781, g_loss: 1.2116\n",
            "Step [10740/80000], d_real_loss: 0.1387, d_mnist_loss: 0.0351, d_svhn_loss: 0.1035, d_fake_loss: 0.0682, g_loss: 1.3525\n",
            "Step [10750/80000], d_real_loss: 0.1517, d_mnist_loss: 0.0227, d_svhn_loss: 0.1290, d_fake_loss: 0.1657, g_loss: 1.3175\n",
            "Step [10760/80000], d_real_loss: 0.1143, d_mnist_loss: 0.0481, d_svhn_loss: 0.0663, d_fake_loss: 0.1145, g_loss: 1.2595\n",
            "Step [10770/80000], d_real_loss: 0.1585, d_mnist_loss: 0.0352, d_svhn_loss: 0.1233, d_fake_loss: 0.2826, g_loss: 1.3463\n",
            "Step [10780/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0116, d_svhn_loss: 0.0558, d_fake_loss: 0.0706, g_loss: 1.5919\n",
            "Step [10790/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0174, d_svhn_loss: 0.0436, d_fake_loss: 0.0577, g_loss: 0.9487\n",
            "Step [10800/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0259, d_svhn_loss: 0.0353, d_fake_loss: 0.0977, g_loss: 1.1598\n",
            "Step [10810/80000], d_real_loss: 0.1513, d_mnist_loss: 0.0114, d_svhn_loss: 0.1399, d_fake_loss: 0.0907, g_loss: 1.3218\n",
            "Step [10820/80000], d_real_loss: 0.0732, d_mnist_loss: 0.0142, d_svhn_loss: 0.0591, d_fake_loss: 0.1231, g_loss: 1.5296\n",
            "Step [10830/80000], d_real_loss: 0.1305, d_mnist_loss: 0.0392, d_svhn_loss: 0.0913, d_fake_loss: 0.1535, g_loss: 1.0859\n",
            "Step [10840/80000], d_real_loss: 0.0934, d_mnist_loss: 0.0282, d_svhn_loss: 0.0652, d_fake_loss: 0.1231, g_loss: 1.0237\n",
            "Step [10850/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0205, d_svhn_loss: 0.0495, d_fake_loss: 0.1391, g_loss: 1.3958\n",
            "Step [10860/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0268, d_svhn_loss: 0.0455, d_fake_loss: 0.1818, g_loss: 1.4304\n",
            "Step [10870/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0214, d_svhn_loss: 0.0678, d_fake_loss: 0.0386, g_loss: 1.0860\n",
            "Step [10880/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0232, d_svhn_loss: 0.0501, d_fake_loss: 0.1177, g_loss: 1.5087\n",
            "Step [10890/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0130, d_svhn_loss: 0.0358, d_fake_loss: 0.0751, g_loss: 1.2861\n",
            "Step [10900/80000], d_real_loss: 0.1836, d_mnist_loss: 0.0660, d_svhn_loss: 0.1176, d_fake_loss: 0.1061, g_loss: 1.4789\n",
            "Step [10910/80000], d_real_loss: 0.1234, d_mnist_loss: 0.0405, d_svhn_loss: 0.0829, d_fake_loss: 0.1230, g_loss: 1.2893\n",
            "Step [10920/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0321, d_svhn_loss: 0.0334, d_fake_loss: 0.0391, g_loss: 1.2451\n",
            "Step [10930/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0152, d_svhn_loss: 0.0584, d_fake_loss: 0.1101, g_loss: 1.3036\n",
            "Step [10940/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0155, d_svhn_loss: 0.0456, d_fake_loss: 0.0694, g_loss: 1.1880\n",
            "Step [10950/80000], d_real_loss: 0.1479, d_mnist_loss: 0.0844, d_svhn_loss: 0.0636, d_fake_loss: 0.1399, g_loss: 1.4250\n",
            "Step [10960/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0343, d_svhn_loss: 0.0549, d_fake_loss: 0.3476, g_loss: 1.3204\n",
            "Step [10970/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0185, d_svhn_loss: 0.0499, d_fake_loss: 0.0516, g_loss: 1.1442\n",
            "Step [10980/80000], d_real_loss: 0.1257, d_mnist_loss: 0.0300, d_svhn_loss: 0.0957, d_fake_loss: 0.1091, g_loss: 1.2575\n",
            "Step [10990/80000], d_real_loss: 0.1358, d_mnist_loss: 0.0633, d_svhn_loss: 0.0725, d_fake_loss: 0.1062, g_loss: 1.3443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9997965693473816]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [11000/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0475, d_svhn_loss: 0.0363, d_fake_loss: 0.0585, g_loss: 1.0983\n",
            "saved ./samples_fashion/sample-11000-m-s.png\n",
            "saved ./samples_fashion/sample-11000-s-m.png\n",
            "Step [11010/80000], d_real_loss: 0.1765, d_mnist_loss: 0.0116, d_svhn_loss: 0.1649, d_fake_loss: 0.0855, g_loss: 1.1765\n",
            "Step [11020/80000], d_real_loss: 0.1073, d_mnist_loss: 0.0164, d_svhn_loss: 0.0909, d_fake_loss: 0.1032, g_loss: 1.1338\n",
            "Step [11030/80000], d_real_loss: 0.0857, d_mnist_loss: 0.0455, d_svhn_loss: 0.0402, d_fake_loss: 0.0962, g_loss: 1.0918\n",
            "Step [11040/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0190, d_svhn_loss: 0.0476, d_fake_loss: 0.0589, g_loss: 1.1894\n",
            "Step [11050/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0147, d_svhn_loss: 0.0384, d_fake_loss: 0.0693, g_loss: 1.1219\n",
            "Step [11060/80000], d_real_loss: 0.1136, d_mnist_loss: 0.0754, d_svhn_loss: 0.0382, d_fake_loss: 0.0817, g_loss: 1.4028\n",
            "Step [11070/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0363, d_svhn_loss: 0.0537, d_fake_loss: 0.1768, g_loss: 1.3217\n",
            "Step [11080/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0202, d_svhn_loss: 0.0612, d_fake_loss: 0.1695, g_loss: 1.1996\n",
            "Step [11090/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0187, d_svhn_loss: 0.0415, d_fake_loss: 0.0608, g_loss: 1.0725\n",
            "Step [11100/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0166, d_svhn_loss: 0.0629, d_fake_loss: 0.0826, g_loss: 1.1346\n",
            "Step [11110/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0282, d_svhn_loss: 0.0380, d_fake_loss: 0.0695, g_loss: 1.1910\n",
            "Step [11120/80000], d_real_loss: 0.1108, d_mnist_loss: 0.0630, d_svhn_loss: 0.0477, d_fake_loss: 0.0796, g_loss: 1.1669\n",
            "Step [11130/80000], d_real_loss: 0.2996, d_mnist_loss: 0.2184, d_svhn_loss: 0.0812, d_fake_loss: 0.1578, g_loss: 1.6246\n",
            "Step [11140/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0226, d_svhn_loss: 0.0325, d_fake_loss: 0.0649, g_loss: 1.0619\n",
            "Step [11150/80000], d_real_loss: 0.0915, d_mnist_loss: 0.0184, d_svhn_loss: 0.0731, d_fake_loss: 0.0620, g_loss: 1.2061\n",
            "Step [11160/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0138, d_svhn_loss: 0.0462, d_fake_loss: 0.0437, g_loss: 1.1315\n",
            "Step [11170/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0405, d_svhn_loss: 0.0255, d_fake_loss: 0.0478, g_loss: 1.1291\n",
            "Step [11180/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0212, d_svhn_loss: 0.0341, d_fake_loss: 0.0367, g_loss: 1.2452\n",
            "Step [11190/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0171, d_svhn_loss: 0.0463, d_fake_loss: 0.1703, g_loss: 1.2887\n",
            "Step [11200/80000], d_real_loss: 0.1202, d_mnist_loss: 0.0175, d_svhn_loss: 0.1027, d_fake_loss: 0.1097, g_loss: 1.5473\n",
            "Step [11210/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0166, d_svhn_loss: 0.0453, d_fake_loss: 0.0468, g_loss: 1.0063\n",
            "Step [11220/80000], d_real_loss: 0.1831, d_mnist_loss: 0.1544, d_svhn_loss: 0.0286, d_fake_loss: 0.0813, g_loss: 1.1672\n",
            "Step [11230/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0151, d_svhn_loss: 0.0230, d_fake_loss: 0.1785, g_loss: 1.0472\n",
            "Step [11240/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0145, d_svhn_loss: 0.0333, d_fake_loss: 0.1387, g_loss: 1.2165\n",
            "Step [11250/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0291, d_svhn_loss: 0.0540, d_fake_loss: 0.0781, g_loss: 1.4976\n",
            "Step [11260/80000], d_real_loss: 0.1867, d_mnist_loss: 0.0732, d_svhn_loss: 0.1134, d_fake_loss: 0.2455, g_loss: 1.1097\n",
            "Step [11270/80000], d_real_loss: 0.0793, d_mnist_loss: 0.0195, d_svhn_loss: 0.0598, d_fake_loss: 0.0457, g_loss: 1.1007\n",
            "Step [11280/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0147, d_svhn_loss: 0.0443, d_fake_loss: 0.0554, g_loss: 1.0699\n",
            "Step [11290/80000], d_real_loss: 0.1969, d_mnist_loss: 0.0325, d_svhn_loss: 0.1644, d_fake_loss: 0.1249, g_loss: 1.0709\n",
            "Step [11300/80000], d_real_loss: 0.1504, d_mnist_loss: 0.0794, d_svhn_loss: 0.0709, d_fake_loss: 0.0517, g_loss: 1.0624\n",
            "Step [11310/80000], d_real_loss: 0.1382, d_mnist_loss: 0.0221, d_svhn_loss: 0.1162, d_fake_loss: 0.0769, g_loss: 0.9442\n",
            "Step [11320/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0191, d_svhn_loss: 0.0507, d_fake_loss: 0.0481, g_loss: 1.1758\n",
            "Step [11330/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0176, d_svhn_loss: 0.0386, d_fake_loss: 0.0473, g_loss: 1.2982\n",
            "Step [11340/80000], d_real_loss: 0.1806, d_mnist_loss: 0.0217, d_svhn_loss: 0.1588, d_fake_loss: 0.2192, g_loss: 0.9209\n",
            "Step [11350/80000], d_real_loss: 0.1061, d_mnist_loss: 0.0223, d_svhn_loss: 0.0839, d_fake_loss: 0.1413, g_loss: 0.7647\n",
            "Step [11360/80000], d_real_loss: 0.1092, d_mnist_loss: 0.0321, d_svhn_loss: 0.0771, d_fake_loss: 0.0518, g_loss: 1.1467\n",
            "Step [11370/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0171, d_svhn_loss: 0.0351, d_fake_loss: 0.0712, g_loss: 1.2858\n",
            "Step [11380/80000], d_real_loss: 0.1064, d_mnist_loss: 0.0157, d_svhn_loss: 0.0907, d_fake_loss: 0.1995, g_loss: 1.3530\n",
            "Step [11390/80000], d_real_loss: 0.1165, d_mnist_loss: 0.0261, d_svhn_loss: 0.0904, d_fake_loss: 0.1109, g_loss: 0.8735\n",
            "Step [11400/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0173, d_svhn_loss: 0.0487, d_fake_loss: 0.0909, g_loss: 1.2478\n",
            "Step [11410/80000], d_real_loss: 0.0709, d_mnist_loss: 0.0151, d_svhn_loss: 0.0558, d_fake_loss: 0.0648, g_loss: 1.1052\n",
            "Step [11420/80000], d_real_loss: 0.1837, d_mnist_loss: 0.0530, d_svhn_loss: 0.1307, d_fake_loss: 0.0882, g_loss: 0.7421\n",
            "Step [11430/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0305, d_svhn_loss: 0.0362, d_fake_loss: 0.0597, g_loss: 1.2890\n",
            "Step [11440/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0170, d_svhn_loss: 0.0466, d_fake_loss: 0.0567, g_loss: 1.1646\n",
            "Step [11450/80000], d_real_loss: 0.1131, d_mnist_loss: 0.0187, d_svhn_loss: 0.0944, d_fake_loss: 0.2089, g_loss: 1.1188\n",
            "Step [11460/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0181, d_svhn_loss: 0.0277, d_fake_loss: 0.0764, g_loss: 1.2548\n",
            "Step [11470/80000], d_real_loss: 0.1813, d_mnist_loss: 0.1200, d_svhn_loss: 0.0612, d_fake_loss: 0.4101, g_loss: 1.7415\n",
            "Step [11480/80000], d_real_loss: 0.1257, d_mnist_loss: 0.0415, d_svhn_loss: 0.0843, d_fake_loss: 0.0926, g_loss: 1.1345\n",
            "Step [11490/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0212, d_svhn_loss: 0.0457, d_fake_loss: 0.0524, g_loss: 1.2475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9996870160102844]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [11500/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0404, d_svhn_loss: 0.0587, d_fake_loss: 0.2934, g_loss: 1.7747\n",
            "saved ./samples_fashion/sample-11500-m-s.png\n",
            "saved ./samples_fashion/sample-11500-s-m.png\n",
            "Step [11510/80000], d_real_loss: 0.0963, d_mnist_loss: 0.0197, d_svhn_loss: 0.0766, d_fake_loss: 0.1111, g_loss: 1.2373\n",
            "Step [11520/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0169, d_svhn_loss: 0.0408, d_fake_loss: 0.0461, g_loss: 1.1052\n",
            "Step [11530/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0375, d_svhn_loss: 0.0440, d_fake_loss: 0.0534, g_loss: 1.2677\n",
            "Step [11540/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0163, d_svhn_loss: 0.0341, d_fake_loss: 0.0862, g_loss: 1.1911\n",
            "Step [11550/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0321, d_svhn_loss: 0.0420, d_fake_loss: 0.1243, g_loss: 1.1862\n",
            "Step [11560/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0189, d_svhn_loss: 0.0190, d_fake_loss: 0.0600, g_loss: 1.1357\n",
            "Step [11570/80000], d_real_loss: 0.1409, d_mnist_loss: 0.0623, d_svhn_loss: 0.0786, d_fake_loss: 0.1993, g_loss: 1.5527\n",
            "Step [11580/80000], d_real_loss: 0.1152, d_mnist_loss: 0.0274, d_svhn_loss: 0.0878, d_fake_loss: 0.0729, g_loss: 1.0206\n",
            "Step [11590/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0124, d_svhn_loss: 0.0457, d_fake_loss: 0.0698, g_loss: 1.0921\n",
            "Step [11600/80000], d_real_loss: 0.0665, d_mnist_loss: 0.0213, d_svhn_loss: 0.0453, d_fake_loss: 0.0796, g_loss: 1.1101\n",
            "Step [11610/80000], d_real_loss: 0.2076, d_mnist_loss: 0.0507, d_svhn_loss: 0.1570, d_fake_loss: 0.2787, g_loss: 1.3619\n",
            "Step [11620/80000], d_real_loss: 0.1171, d_mnist_loss: 0.0117, d_svhn_loss: 0.1054, d_fake_loss: 0.0809, g_loss: 1.3256\n",
            "Step [11630/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0288, d_svhn_loss: 0.0313, d_fake_loss: 0.1496, g_loss: 1.5431\n",
            "Step [11640/80000], d_real_loss: 0.2047, d_mnist_loss: 0.0621, d_svhn_loss: 0.1426, d_fake_loss: 0.3405, g_loss: 1.5562\n",
            "Step [11650/80000], d_real_loss: 0.1016, d_mnist_loss: 0.0190, d_svhn_loss: 0.0827, d_fake_loss: 0.0779, g_loss: 1.1167\n",
            "Step [11660/80000], d_real_loss: 0.0936, d_mnist_loss: 0.0600, d_svhn_loss: 0.0337, d_fake_loss: 0.0568, g_loss: 1.1475\n",
            "Step [11670/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0198, d_svhn_loss: 0.0475, d_fake_loss: 0.1697, g_loss: 1.3298\n",
            "Step [11680/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0123, d_svhn_loss: 0.0489, d_fake_loss: 0.0404, g_loss: 1.2465\n",
            "Step [11690/80000], d_real_loss: 0.1555, d_mnist_loss: 0.1110, d_svhn_loss: 0.0445, d_fake_loss: 0.0448, g_loss: 1.0992\n",
            "Step [11700/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0146, d_svhn_loss: 0.0366, d_fake_loss: 0.2143, g_loss: 1.2019\n",
            "Step [11710/80000], d_real_loss: 0.0871, d_mnist_loss: 0.0106, d_svhn_loss: 0.0765, d_fake_loss: 0.0633, g_loss: 1.0762\n",
            "Step [11720/80000], d_real_loss: 0.1109, d_mnist_loss: 0.0549, d_svhn_loss: 0.0560, d_fake_loss: 0.1433, g_loss: 1.5146\n",
            "Step [11730/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0103, d_svhn_loss: 0.0500, d_fake_loss: 0.0497, g_loss: 1.1519\n",
            "Step [11740/80000], d_real_loss: 0.2817, d_mnist_loss: 0.0132, d_svhn_loss: 0.2685, d_fake_loss: 0.1047, g_loss: 1.1106\n",
            "Step [11750/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0180, d_svhn_loss: 0.0391, d_fake_loss: 0.1473, g_loss: 1.3070\n",
            "Step [11760/80000], d_real_loss: 0.0928, d_mnist_loss: 0.0320, d_svhn_loss: 0.0608, d_fake_loss: 0.0865, g_loss: 0.9826\n",
            "Step [11770/80000], d_real_loss: 0.0855, d_mnist_loss: 0.0637, d_svhn_loss: 0.0217, d_fake_loss: 0.0912, g_loss: 1.6765\n",
            "Step [11780/80000], d_real_loss: 0.0966, d_mnist_loss: 0.0571, d_svhn_loss: 0.0396, d_fake_loss: 0.0537, g_loss: 1.2521\n",
            "Step [11790/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0242, d_svhn_loss: 0.0478, d_fake_loss: 0.0954, g_loss: 1.1972\n",
            "Step [11800/80000], d_real_loss: 0.0775, d_mnist_loss: 0.0223, d_svhn_loss: 0.0552, d_fake_loss: 0.0825, g_loss: 0.9303\n",
            "Step [11810/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0236, d_svhn_loss: 0.0260, d_fake_loss: 0.0548, g_loss: 1.2132\n",
            "Step [11820/80000], d_real_loss: 0.1215, d_mnist_loss: 0.0450, d_svhn_loss: 0.0765, d_fake_loss: 0.0397, g_loss: 1.1517\n",
            "Step [11830/80000], d_real_loss: 0.2066, d_mnist_loss: 0.0252, d_svhn_loss: 0.1814, d_fake_loss: 0.1259, g_loss: 1.0593\n",
            "Step [11840/80000], d_real_loss: 0.1143, d_mnist_loss: 0.0401, d_svhn_loss: 0.0742, d_fake_loss: 0.0438, g_loss: 1.1321\n",
            "Step [11850/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0180, d_svhn_loss: 0.0458, d_fake_loss: 0.0527, g_loss: 1.2353\n",
            "Step [11860/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0164, d_svhn_loss: 0.0532, d_fake_loss: 0.0439, g_loss: 1.1056\n",
            "Step [11870/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0129, d_svhn_loss: 0.0317, d_fake_loss: 0.0741, g_loss: 1.1415\n",
            "Step [11880/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0297, d_svhn_loss: 0.0464, d_fake_loss: 0.1258, g_loss: 1.2910\n",
            "Step [11890/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0109, d_svhn_loss: 0.0382, d_fake_loss: 0.0430, g_loss: 1.2796\n",
            "Step [11900/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0189, d_svhn_loss: 0.0424, d_fake_loss: 0.0543, g_loss: 1.2540\n",
            "Step [11910/80000], d_real_loss: 0.0965, d_mnist_loss: 0.0517, d_svhn_loss: 0.0449, d_fake_loss: 0.0979, g_loss: 0.7472\n",
            "Step [11920/80000], d_real_loss: 0.0888, d_mnist_loss: 0.0517, d_svhn_loss: 0.0370, d_fake_loss: 0.0632, g_loss: 1.1066\n",
            "Step [11930/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0250, d_svhn_loss: 0.0493, d_fake_loss: 0.0480, g_loss: 0.9466\n",
            "Step [11940/80000], d_real_loss: 0.1374, d_mnist_loss: 0.0194, d_svhn_loss: 0.1180, d_fake_loss: 0.0707, g_loss: 1.1106\n",
            "Step [11950/80000], d_real_loss: 0.1603, d_mnist_loss: 0.1233, d_svhn_loss: 0.0370, d_fake_loss: 0.2686, g_loss: 1.3396\n",
            "Step [11960/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0111, d_svhn_loss: 0.0350, d_fake_loss: 0.0679, g_loss: 1.1084\n",
            "Step [11970/80000], d_real_loss: 0.1597, d_mnist_loss: 0.0146, d_svhn_loss: 0.1451, d_fake_loss: 0.0718, g_loss: 1.3302\n",
            "Step [11980/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0150, d_svhn_loss: 0.0425, d_fake_loss: 0.1028, g_loss: 1.3110\n",
            "Step [11990/80000], d_real_loss: 0.1820, d_mnist_loss: 0.0219, d_svhn_loss: 0.1601, d_fake_loss: 0.1083, g_loss: 1.0666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9973586797714233]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [12000/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0180, d_svhn_loss: 0.0380, d_fake_loss: 0.0320, g_loss: 1.2188\n",
            "saved ./samples_fashion/sample-12000-m-s.png\n",
            "saved ./samples_fashion/sample-12000-s-m.png\n",
            "Step [12010/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0195, d_svhn_loss: 0.0420, d_fake_loss: 0.0468, g_loss: 1.1870\n",
            "Step [12020/80000], d_real_loss: 0.1917, d_mnist_loss: 0.0137, d_svhn_loss: 0.1780, d_fake_loss: 0.0783, g_loss: 1.3584\n",
            "Step [12030/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0091, d_svhn_loss: 0.0844, d_fake_loss: 0.0611, g_loss: 1.1331\n",
            "Step [12040/80000], d_real_loss: 0.2198, d_mnist_loss: 0.0251, d_svhn_loss: 0.1947, d_fake_loss: 0.1779, g_loss: 1.0714\n",
            "Step [12050/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0439, d_svhn_loss: 0.0363, d_fake_loss: 0.2193, g_loss: 0.4966\n",
            "Step [12060/80000], d_real_loss: 0.1460, d_mnist_loss: 0.0419, d_svhn_loss: 0.1040, d_fake_loss: 0.1354, g_loss: 1.1913\n",
            "Step [12070/80000], d_real_loss: 0.0644, d_mnist_loss: 0.0253, d_svhn_loss: 0.0390, d_fake_loss: 0.0569, g_loss: 1.2386\n",
            "Step [12080/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0284, d_svhn_loss: 0.0446, d_fake_loss: 0.3118, g_loss: 1.1452\n",
            "Step [12090/80000], d_real_loss: 0.1928, d_mnist_loss: 0.0315, d_svhn_loss: 0.1613, d_fake_loss: 0.0714, g_loss: 1.1416\n",
            "Step [12100/80000], d_real_loss: 0.0852, d_mnist_loss: 0.0233, d_svhn_loss: 0.0620, d_fake_loss: 0.0823, g_loss: 1.5410\n",
            "Step [12110/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0124, d_svhn_loss: 0.0443, d_fake_loss: 0.0639, g_loss: 1.3948\n",
            "Step [12120/80000], d_real_loss: 0.1177, d_mnist_loss: 0.0621, d_svhn_loss: 0.0556, d_fake_loss: 0.0988, g_loss: 1.3871\n",
            "Step [12130/80000], d_real_loss: 0.1346, d_mnist_loss: 0.0835, d_svhn_loss: 0.0511, d_fake_loss: 0.0511, g_loss: 1.2207\n",
            "Step [12140/80000], d_real_loss: 0.1281, d_mnist_loss: 0.0621, d_svhn_loss: 0.0659, d_fake_loss: 0.1468, g_loss: 1.5617\n",
            "Step [12150/80000], d_real_loss: 0.0949, d_mnist_loss: 0.0631, d_svhn_loss: 0.0318, d_fake_loss: 0.0438, g_loss: 1.2427\n",
            "Step [12160/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0124, d_svhn_loss: 0.0471, d_fake_loss: 0.0700, g_loss: 1.2558\n",
            "Step [12170/80000], d_real_loss: 0.3984, d_mnist_loss: 0.3222, d_svhn_loss: 0.0762, d_fake_loss: 0.1056, g_loss: 1.5628\n",
            "Step [12180/80000], d_real_loss: 0.1347, d_mnist_loss: 0.0224, d_svhn_loss: 0.1123, d_fake_loss: 0.0488, g_loss: 1.0009\n",
            "Step [12190/80000], d_real_loss: 0.1996, d_mnist_loss: 0.0140, d_svhn_loss: 0.1856, d_fake_loss: 0.1640, g_loss: 1.4927\n",
            "Step [12200/80000], d_real_loss: 0.1108, d_mnist_loss: 0.0173, d_svhn_loss: 0.0934, d_fake_loss: 0.0631, g_loss: 1.2776\n",
            "Step [12210/80000], d_real_loss: 0.1225, d_mnist_loss: 0.0196, d_svhn_loss: 0.1029, d_fake_loss: 0.0897, g_loss: 1.0664\n",
            "Step [12220/80000], d_real_loss: 0.1133, d_mnist_loss: 0.0216, d_svhn_loss: 0.0917, d_fake_loss: 0.1932, g_loss: 1.2404\n",
            "Step [12230/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0096, d_svhn_loss: 0.0262, d_fake_loss: 0.0491, g_loss: 1.2220\n",
            "Step [12240/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0134, d_svhn_loss: 0.0576, d_fake_loss: 0.0601, g_loss: 1.0550\n",
            "Step [12250/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0372, d_svhn_loss: 0.0292, d_fake_loss: 0.0783, g_loss: 1.2377\n",
            "Step [12260/80000], d_real_loss: 0.1063, d_mnist_loss: 0.0147, d_svhn_loss: 0.0916, d_fake_loss: 0.0936, g_loss: 1.2889\n",
            "Step [12270/80000], d_real_loss: 0.1224, d_mnist_loss: 0.0475, d_svhn_loss: 0.0749, d_fake_loss: 0.0537, g_loss: 1.1600\n",
            "Step [12280/80000], d_real_loss: 0.1177, d_mnist_loss: 0.0111, d_svhn_loss: 0.1067, d_fake_loss: 0.1435, g_loss: 1.1236\n",
            "Step [12290/80000], d_real_loss: 0.1106, d_mnist_loss: 0.0175, d_svhn_loss: 0.0931, d_fake_loss: 0.1287, g_loss: 1.1744\n",
            "Step [12300/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0188, d_svhn_loss: 0.0291, d_fake_loss: 0.0462, g_loss: 1.2491\n",
            "Step [12310/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0146, d_svhn_loss: 0.0392, d_fake_loss: 0.0429, g_loss: 1.0681\n",
            "Step [12320/80000], d_real_loss: 0.2099, d_mnist_loss: 0.1531, d_svhn_loss: 0.0569, d_fake_loss: 0.0734, g_loss: 1.4522\n",
            "Step [12330/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0246, d_svhn_loss: 0.0310, d_fake_loss: 0.0582, g_loss: 1.2546\n",
            "Step [12340/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0296, d_svhn_loss: 0.0305, d_fake_loss: 0.0492, g_loss: 1.0852\n",
            "Step [12350/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0323, d_svhn_loss: 0.0390, d_fake_loss: 0.0469, g_loss: 1.0772\n",
            "Step [12360/80000], d_real_loss: 0.0682, d_mnist_loss: 0.0217, d_svhn_loss: 0.0465, d_fake_loss: 0.1136, g_loss: 1.3018\n",
            "Step [12370/80000], d_real_loss: 0.1466, d_mnist_loss: 0.0191, d_svhn_loss: 0.1274, d_fake_loss: 0.3137, g_loss: 1.1276\n",
            "Step [12380/80000], d_real_loss: 0.0865, d_mnist_loss: 0.0455, d_svhn_loss: 0.0410, d_fake_loss: 0.0620, g_loss: 1.2793\n",
            "Step [12390/80000], d_real_loss: 0.4089, d_mnist_loss: 0.0633, d_svhn_loss: 0.3456, d_fake_loss: 0.2966, g_loss: 1.0041\n",
            "Step [12400/80000], d_real_loss: 0.0759, d_mnist_loss: 0.0180, d_svhn_loss: 0.0579, d_fake_loss: 0.0531, g_loss: 1.3077\n",
            "Step [12410/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0396, d_svhn_loss: 0.0444, d_fake_loss: 0.0902, g_loss: 1.3228\n",
            "Step [12420/80000], d_real_loss: 0.1143, d_mnist_loss: 0.0280, d_svhn_loss: 0.0863, d_fake_loss: 0.3076, g_loss: 1.2494\n",
            "Step [12430/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0129, d_svhn_loss: 0.0452, d_fake_loss: 0.1099, g_loss: 1.1451\n",
            "Step [12440/80000], d_real_loss: 0.0906, d_mnist_loss: 0.0206, d_svhn_loss: 0.0700, d_fake_loss: 0.0855, g_loss: 1.1847\n",
            "Step [12450/80000], d_real_loss: 0.1101, d_mnist_loss: 0.0155, d_svhn_loss: 0.0946, d_fake_loss: 0.0414, g_loss: 0.9870\n",
            "Step [12460/80000], d_real_loss: 0.0835, d_mnist_loss: 0.0206, d_svhn_loss: 0.0629, d_fake_loss: 0.1752, g_loss: 0.9586\n",
            "Step [12470/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0161, d_svhn_loss: 0.0611, d_fake_loss: 0.0630, g_loss: 1.0891\n",
            "Step [12480/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0279, d_svhn_loss: 0.0508, d_fake_loss: 0.0491, g_loss: 1.0270\n",
            "Step [12490/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0222, d_svhn_loss: 0.0462, d_fake_loss: 0.0839, g_loss: 1.3908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.995875358581543]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [12500/80000], d_real_loss: 0.0707, d_mnist_loss: 0.0323, d_svhn_loss: 0.0384, d_fake_loss: 0.0749, g_loss: 1.4304\n",
            "saved ./samples_fashion/sample-12500-m-s.png\n",
            "saved ./samples_fashion/sample-12500-s-m.png\n",
            "Step [12510/80000], d_real_loss: 0.1659, d_mnist_loss: 0.0145, d_svhn_loss: 0.1514, d_fake_loss: 0.4447, g_loss: 0.9444\n",
            "Step [12520/80000], d_real_loss: 0.1104, d_mnist_loss: 0.0239, d_svhn_loss: 0.0865, d_fake_loss: 0.0681, g_loss: 1.3403\n",
            "Step [12530/80000], d_real_loss: 0.1075, d_mnist_loss: 0.0595, d_svhn_loss: 0.0480, d_fake_loss: 0.0495, g_loss: 1.0513\n",
            "Step [12540/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0229, d_svhn_loss: 0.0332, d_fake_loss: 0.0449, g_loss: 1.1230\n",
            "Step [12550/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0302, d_svhn_loss: 0.0386, d_fake_loss: 0.1471, g_loss: 1.3232\n",
            "Step [12560/80000], d_real_loss: 0.1135, d_mnist_loss: 0.0158, d_svhn_loss: 0.0978, d_fake_loss: 0.1896, g_loss: 1.0354\n",
            "Step [12570/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0126, d_svhn_loss: 0.0675, d_fake_loss: 0.0415, g_loss: 1.0456\n",
            "Step [12580/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0129, d_svhn_loss: 0.0334, d_fake_loss: 0.0802, g_loss: 1.1204\n",
            "Step [12590/80000], d_real_loss: 0.2519, d_mnist_loss: 0.0174, d_svhn_loss: 0.2345, d_fake_loss: 0.1234, g_loss: 0.7629\n",
            "Step [12600/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0156, d_svhn_loss: 0.0430, d_fake_loss: 0.0409, g_loss: 1.2165\n",
            "Step [12610/80000], d_real_loss: 0.1782, d_mnist_loss: 0.0221, d_svhn_loss: 0.1561, d_fake_loss: 0.1987, g_loss: 1.1723\n",
            "Step [12620/80000], d_real_loss: 0.1033, d_mnist_loss: 0.0268, d_svhn_loss: 0.0765, d_fake_loss: 0.4154, g_loss: 0.9897\n",
            "Step [12630/80000], d_real_loss: 0.0760, d_mnist_loss: 0.0216, d_svhn_loss: 0.0545, d_fake_loss: 0.0665, g_loss: 1.0511\n",
            "Step [12640/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0374, d_svhn_loss: 0.0230, d_fake_loss: 0.0473, g_loss: 1.1172\n",
            "Step [12650/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0165, d_svhn_loss: 0.0575, d_fake_loss: 0.0735, g_loss: 1.0858\n",
            "Step [12660/80000], d_real_loss: 0.1439, d_mnist_loss: 0.0449, d_svhn_loss: 0.0990, d_fake_loss: 0.0580, g_loss: 1.1156\n",
            "Step [12670/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0115, d_svhn_loss: 0.0405, d_fake_loss: 0.0826, g_loss: 1.1658\n",
            "Step [12680/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0181, d_svhn_loss: 0.0754, d_fake_loss: 0.0686, g_loss: 1.0994\n",
            "Step [12690/80000], d_real_loss: 0.0917, d_mnist_loss: 0.0382, d_svhn_loss: 0.0535, d_fake_loss: 0.0602, g_loss: 0.9840\n",
            "Step [12700/80000], d_real_loss: 0.1476, d_mnist_loss: 0.0548, d_svhn_loss: 0.0928, d_fake_loss: 0.0855, g_loss: 1.2426\n",
            "Step [12710/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0148, d_svhn_loss: 0.0464, d_fake_loss: 0.1749, g_loss: 1.0822\n",
            "Step [12720/80000], d_real_loss: 0.0801, d_mnist_loss: 0.0176, d_svhn_loss: 0.0624, d_fake_loss: 0.0516, g_loss: 1.1365\n",
            "Step [12730/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0321, d_svhn_loss: 0.0368, d_fake_loss: 0.0615, g_loss: 1.0991\n",
            "Step [12740/80000], d_real_loss: 0.1363, d_mnist_loss: 0.1015, d_svhn_loss: 0.0348, d_fake_loss: 0.0883, g_loss: 1.3664\n",
            "Step [12750/80000], d_real_loss: 0.0779, d_mnist_loss: 0.0133, d_svhn_loss: 0.0647, d_fake_loss: 0.0477, g_loss: 1.2314\n",
            "Step [12760/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0159, d_svhn_loss: 0.0602, d_fake_loss: 0.0982, g_loss: 1.2149\n",
            "Step [12770/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0162, d_svhn_loss: 0.0390, d_fake_loss: 0.0807, g_loss: 1.1230\n",
            "Step [12780/80000], d_real_loss: 0.0886, d_mnist_loss: 0.0387, d_svhn_loss: 0.0499, d_fake_loss: 0.0554, g_loss: 1.3693\n",
            "Step [12790/80000], d_real_loss: 0.1359, d_mnist_loss: 0.0230, d_svhn_loss: 0.1129, d_fake_loss: 0.2211, g_loss: 1.5995\n",
            "Step [12800/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0391, d_svhn_loss: 0.0264, d_fake_loss: 0.0692, g_loss: 1.2356\n",
            "Step [12810/80000], d_real_loss: 0.1021, d_mnist_loss: 0.0168, d_svhn_loss: 0.0853, d_fake_loss: 0.1547, g_loss: 1.2163\n",
            "Step [12820/80000], d_real_loss: 0.1129, d_mnist_loss: 0.0188, d_svhn_loss: 0.0941, d_fake_loss: 0.2090, g_loss: 1.0700\n",
            "Step [12830/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0272, d_svhn_loss: 0.0346, d_fake_loss: 0.0560, g_loss: 1.1087\n",
            "Step [12840/80000], d_real_loss: 0.1455, d_mnist_loss: 0.0371, d_svhn_loss: 0.1084, d_fake_loss: 0.1031, g_loss: 1.0514\n",
            "Step [12850/80000], d_real_loss: 0.1750, d_mnist_loss: 0.0172, d_svhn_loss: 0.1578, d_fake_loss: 0.1578, g_loss: 1.3734\n",
            "Step [12860/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0239, d_svhn_loss: 0.0454, d_fake_loss: 0.0403, g_loss: 1.0263\n",
            "Step [12870/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0215, d_svhn_loss: 0.0330, d_fake_loss: 0.1030, g_loss: 1.1347\n",
            "Step [12880/80000], d_real_loss: 0.1015, d_mnist_loss: 0.0401, d_svhn_loss: 0.0613, d_fake_loss: 0.1924, g_loss: 1.5779\n",
            "Step [12890/80000], d_real_loss: 0.1279, d_mnist_loss: 0.0742, d_svhn_loss: 0.0536, d_fake_loss: 0.0573, g_loss: 1.3709\n",
            "Step [12900/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0209, d_svhn_loss: 0.0487, d_fake_loss: 0.0687, g_loss: 0.9826\n",
            "Step [12910/80000], d_real_loss: 0.1428, d_mnist_loss: 0.0672, d_svhn_loss: 0.0755, d_fake_loss: 0.0498, g_loss: 0.9529\n",
            "Step [12920/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0119, d_svhn_loss: 0.0724, d_fake_loss: 0.0691, g_loss: 0.9861\n",
            "Step [12930/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0169, d_svhn_loss: 0.0426, d_fake_loss: 0.0594, g_loss: 1.0426\n",
            "Step [12940/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0124, d_svhn_loss: 0.0539, d_fake_loss: 0.0625, g_loss: 1.1165\n",
            "Step [12950/80000], d_real_loss: 0.1000, d_mnist_loss: 0.0323, d_svhn_loss: 0.0677, d_fake_loss: 0.0488, g_loss: 0.8615\n",
            "Step [12960/80000], d_real_loss: 0.1041, d_mnist_loss: 0.0200, d_svhn_loss: 0.0840, d_fake_loss: 0.1177, g_loss: 1.2062\n",
            "Step [12970/80000], d_real_loss: 0.1056, d_mnist_loss: 0.0418, d_svhn_loss: 0.0638, d_fake_loss: 0.0594, g_loss: 1.1363\n",
            "Step [12980/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0215, d_svhn_loss: 0.0412, d_fake_loss: 0.0866, g_loss: 0.9613\n",
            "Step [12990/80000], d_real_loss: 0.1281, d_mnist_loss: 0.0407, d_svhn_loss: 0.0874, d_fake_loss: 0.0856, g_loss: 1.0168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9951729774475098]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [13000/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0174, d_svhn_loss: 0.0512, d_fake_loss: 0.0595, g_loss: 0.9779\n",
            "saved ./samples_fashion/sample-13000-m-s.png\n",
            "saved ./samples_fashion/sample-13000-s-m.png\n",
            "Step [13010/80000], d_real_loss: 0.1841, d_mnist_loss: 0.0260, d_svhn_loss: 0.1581, d_fake_loss: 0.0939, g_loss: 1.3860\n",
            "Step [13020/80000], d_real_loss: 0.1122, d_mnist_loss: 0.0569, d_svhn_loss: 0.0553, d_fake_loss: 0.1500, g_loss: 1.4495\n",
            "Step [13030/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0149, d_svhn_loss: 0.0383, d_fake_loss: 0.0613, g_loss: 1.1858\n",
            "Step [13040/80000], d_real_loss: 0.1129, d_mnist_loss: 0.0413, d_svhn_loss: 0.0717, d_fake_loss: 0.1189, g_loss: 1.0212\n",
            "Step [13050/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0141, d_svhn_loss: 0.0335, d_fake_loss: 0.0358, g_loss: 1.2497\n",
            "Step [13060/80000], d_real_loss: 0.1231, d_mnist_loss: 0.0165, d_svhn_loss: 0.1066, d_fake_loss: 0.0830, g_loss: 1.3886\n",
            "Step [13070/80000], d_real_loss: 0.1170, d_mnist_loss: 0.0448, d_svhn_loss: 0.0722, d_fake_loss: 0.0604, g_loss: 1.1170\n",
            "Step [13080/80000], d_real_loss: 0.0987, d_mnist_loss: 0.0144, d_svhn_loss: 0.0843, d_fake_loss: 0.0534, g_loss: 1.0132\n",
            "Step [13090/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0094, d_svhn_loss: 0.0325, d_fake_loss: 0.1158, g_loss: 1.1176\n",
            "Step [13100/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0103, d_svhn_loss: 0.0622, d_fake_loss: 0.2435, g_loss: 1.2974\n",
            "Step [13110/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0136, d_svhn_loss: 0.0399, d_fake_loss: 0.0683, g_loss: 0.8864\n",
            "Step [13120/80000], d_real_loss: 0.1003, d_mnist_loss: 0.0186, d_svhn_loss: 0.0817, d_fake_loss: 0.0555, g_loss: 1.1286\n",
            "Step [13130/80000], d_real_loss: 0.1613, d_mnist_loss: 0.1038, d_svhn_loss: 0.0576, d_fake_loss: 0.0794, g_loss: 1.2190\n",
            "Step [13140/80000], d_real_loss: 0.1030, d_mnist_loss: 0.0196, d_svhn_loss: 0.0833, d_fake_loss: 0.1061, g_loss: 1.6448\n",
            "Step [13150/80000], d_real_loss: 0.1331, d_mnist_loss: 0.0212, d_svhn_loss: 0.1119, d_fake_loss: 0.2849, g_loss: 0.9464\n",
            "Step [13160/80000], d_real_loss: 0.1238, d_mnist_loss: 0.0146, d_svhn_loss: 0.1092, d_fake_loss: 0.1546, g_loss: 0.8650\n",
            "Step [13170/80000], d_real_loss: 0.1047, d_mnist_loss: 0.0436, d_svhn_loss: 0.0611, d_fake_loss: 0.1747, g_loss: 1.2634\n",
            "Step [13180/80000], d_real_loss: 0.0832, d_mnist_loss: 0.0183, d_svhn_loss: 0.0649, d_fake_loss: 0.0985, g_loss: 1.1965\n",
            "Step [13190/80000], d_real_loss: 0.1898, d_mnist_loss: 0.0629, d_svhn_loss: 0.1269, d_fake_loss: 0.1503, g_loss: 1.1140\n",
            "Step [13200/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0220, d_svhn_loss: 0.0432, d_fake_loss: 0.0765, g_loss: 0.7400\n",
            "Step [13210/80000], d_real_loss: 0.0887, d_mnist_loss: 0.0408, d_svhn_loss: 0.0479, d_fake_loss: 0.0470, g_loss: 1.2331\n",
            "Step [13220/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0117, d_svhn_loss: 0.0612, d_fake_loss: 0.0410, g_loss: 1.0001\n",
            "Step [13230/80000], d_real_loss: 0.1154, d_mnist_loss: 0.0147, d_svhn_loss: 0.1007, d_fake_loss: 0.0512, g_loss: 1.0974\n",
            "Step [13240/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0178, d_svhn_loss: 0.0365, d_fake_loss: 0.0688, g_loss: 1.2798\n",
            "Step [13250/80000], d_real_loss: 0.1386, d_mnist_loss: 0.0286, d_svhn_loss: 0.1100, d_fake_loss: 0.1179, g_loss: 1.0423\n",
            "Step [13260/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0235, d_svhn_loss: 0.0378, d_fake_loss: 0.0351, g_loss: 0.9942\n",
            "Step [13270/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0124, d_svhn_loss: 0.0291, d_fake_loss: 0.0852, g_loss: 1.4580\n",
            "Step [13280/80000], d_real_loss: 0.1596, d_mnist_loss: 0.1161, d_svhn_loss: 0.0434, d_fake_loss: 0.4205, g_loss: 1.6740\n",
            "Step [13290/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0095, d_svhn_loss: 0.0227, d_fake_loss: 0.0658, g_loss: 1.2680\n",
            "Step [13300/80000], d_real_loss: 0.1554, d_mnist_loss: 0.0365, d_svhn_loss: 0.1188, d_fake_loss: 0.0469, g_loss: 1.0062\n",
            "Step [13310/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0269, d_svhn_loss: 0.0305, d_fake_loss: 0.0420, g_loss: 1.2065\n",
            "Step [13320/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0494, d_svhn_loss: 0.0307, d_fake_loss: 0.1067, g_loss: 1.3557\n",
            "Step [13330/80000], d_real_loss: 0.0760, d_mnist_loss: 0.0205, d_svhn_loss: 0.0555, d_fake_loss: 0.1157, g_loss: 1.4209\n",
            "Step [13340/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0118, d_svhn_loss: 0.0291, d_fake_loss: 0.0705, g_loss: 1.0980\n",
            "Step [13350/80000], d_real_loss: 0.2276, d_mnist_loss: 0.0278, d_svhn_loss: 0.1998, d_fake_loss: 0.0603, g_loss: 1.1860\n",
            "Step [13360/80000], d_real_loss: 0.1190, d_mnist_loss: 0.0605, d_svhn_loss: 0.0585, d_fake_loss: 0.2099, g_loss: 1.1191\n",
            "Step [13370/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0120, d_svhn_loss: 0.0411, d_fake_loss: 0.0393, g_loss: 1.0297\n",
            "Step [13380/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0420, d_svhn_loss: 0.0279, d_fake_loss: 0.0486, g_loss: 1.0260\n",
            "Step [13390/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0215, d_svhn_loss: 0.0435, d_fake_loss: 0.0322, g_loss: 1.2403\n",
            "Step [13400/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0141, d_svhn_loss: 0.0465, d_fake_loss: 0.0733, g_loss: 1.1760\n",
            "Step [13410/80000], d_real_loss: 0.4264, d_mnist_loss: 0.1266, d_svhn_loss: 0.2998, d_fake_loss: 0.2677, g_loss: 1.6000\n",
            "Step [13420/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0228, d_svhn_loss: 0.0385, d_fake_loss: 0.0558, g_loss: 1.1511\n",
            "Step [13430/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0153, d_svhn_loss: 0.0363, d_fake_loss: 0.0477, g_loss: 1.0824\n",
            "Step [13440/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0139, d_svhn_loss: 0.0590, d_fake_loss: 0.0901, g_loss: 1.1593\n",
            "Step [13450/80000], d_real_loss: 0.1305, d_mnist_loss: 0.0115, d_svhn_loss: 0.1190, d_fake_loss: 0.1508, g_loss: 1.4773\n",
            "Step [13460/80000], d_real_loss: 0.1944, d_mnist_loss: 0.0214, d_svhn_loss: 0.1729, d_fake_loss: 0.2658, g_loss: 1.3419\n",
            "Step [13470/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0450, d_svhn_loss: 0.0494, d_fake_loss: 0.0525, g_loss: 0.9961\n",
            "Step [13480/80000], d_real_loss: 0.1136, d_mnist_loss: 0.0353, d_svhn_loss: 0.0784, d_fake_loss: 0.0784, g_loss: 1.1542\n",
            "Step [13490/80000], d_real_loss: 0.1120, d_mnist_loss: 0.0136, d_svhn_loss: 0.0984, d_fake_loss: 0.1070, g_loss: 1.1989\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [13500/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0514, d_svhn_loss: 0.0366, d_fake_loss: 0.0861, g_loss: 1.3731\n",
            "saved ./samples_fashion/sample-13500-m-s.png\n",
            "saved ./samples_fashion/sample-13500-s-m.png\n",
            "Step [13510/80000], d_real_loss: 0.1245, d_mnist_loss: 0.0899, d_svhn_loss: 0.0346, d_fake_loss: 0.0816, g_loss: 1.1240\n",
            "Step [13520/80000], d_real_loss: 0.0769, d_mnist_loss: 0.0120, d_svhn_loss: 0.0649, d_fake_loss: 0.0571, g_loss: 1.0658\n",
            "Step [13530/80000], d_real_loss: 0.2261, d_mnist_loss: 0.0746, d_svhn_loss: 0.1515, d_fake_loss: 0.1324, g_loss: 1.0521\n",
            "Step [13540/80000], d_real_loss: 0.0856, d_mnist_loss: 0.0135, d_svhn_loss: 0.0721, d_fake_loss: 0.1926, g_loss: 1.3742\n",
            "Step [13550/80000], d_real_loss: 0.1418, d_mnist_loss: 0.0125, d_svhn_loss: 0.1293, d_fake_loss: 0.0562, g_loss: 1.0885\n",
            "Step [13560/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0277, d_svhn_loss: 0.0334, d_fake_loss: 0.0471, g_loss: 1.0551\n",
            "Step [13570/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0115, d_svhn_loss: 0.0469, d_fake_loss: 0.0587, g_loss: 1.1152\n",
            "Step [13580/80000], d_real_loss: 0.0715, d_mnist_loss: 0.0173, d_svhn_loss: 0.0542, d_fake_loss: 0.0618, g_loss: 1.1145\n",
            "Step [13590/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0154, d_svhn_loss: 0.0368, d_fake_loss: 0.1399, g_loss: 1.1281\n",
            "Step [13600/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0357, d_svhn_loss: 0.0368, d_fake_loss: 0.0576, g_loss: 1.0178\n",
            "Step [13610/80000], d_real_loss: 0.1547, d_mnist_loss: 0.0172, d_svhn_loss: 0.1375, d_fake_loss: 0.0625, g_loss: 1.2828\n",
            "Step [13620/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0164, d_svhn_loss: 0.0412, d_fake_loss: 0.0944, g_loss: 1.3370\n",
            "Step [13630/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0374, d_svhn_loss: 0.0325, d_fake_loss: 0.0883, g_loss: 1.1671\n",
            "Step [13640/80000], d_real_loss: 0.0749, d_mnist_loss: 0.0294, d_svhn_loss: 0.0454, d_fake_loss: 0.1135, g_loss: 1.1347\n",
            "Step [13650/80000], d_real_loss: 0.0948, d_mnist_loss: 0.0162, d_svhn_loss: 0.0786, d_fake_loss: 0.0883, g_loss: 0.9275\n",
            "Step [13660/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0115, d_svhn_loss: 0.0464, d_fake_loss: 0.0623, g_loss: 1.1234\n",
            "Step [13670/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0213, d_svhn_loss: 0.0314, d_fake_loss: 0.0760, g_loss: 1.2270\n",
            "Step [13680/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0146, d_svhn_loss: 0.0296, d_fake_loss: 0.0552, g_loss: 1.1373\n",
            "Step [13690/80000], d_real_loss: 0.2041, d_mnist_loss: 0.0302, d_svhn_loss: 0.1740, d_fake_loss: 0.2386, g_loss: 0.9284\n",
            "Step [13700/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0227, d_svhn_loss: 0.0361, d_fake_loss: 0.1271, g_loss: 1.2480\n",
            "Step [13710/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0419, d_svhn_loss: 0.0371, d_fake_loss: 0.2111, g_loss: 1.1290\n",
            "Step [13720/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0160, d_svhn_loss: 0.0432, d_fake_loss: 0.0390, g_loss: 1.0463\n",
            "Step [13730/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0134, d_svhn_loss: 0.0479, d_fake_loss: 0.1714, g_loss: 0.9625\n",
            "Step [13740/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0177, d_svhn_loss: 0.0415, d_fake_loss: 0.0418, g_loss: 1.1507\n",
            "Step [13750/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0124, d_svhn_loss: 0.0508, d_fake_loss: 0.0509, g_loss: 1.1196\n",
            "Step [13760/80000], d_real_loss: 0.3102, d_mnist_loss: 0.0340, d_svhn_loss: 0.2762, d_fake_loss: 0.3664, g_loss: 1.6402\n",
            "Step [13770/80000], d_real_loss: 0.1120, d_mnist_loss: 0.0162, d_svhn_loss: 0.0958, d_fake_loss: 0.0466, g_loss: 0.9685\n",
            "Step [13780/80000], d_real_loss: 0.0855, d_mnist_loss: 0.0213, d_svhn_loss: 0.0641, d_fake_loss: 0.0844, g_loss: 1.1523\n",
            "Step [13790/80000], d_real_loss: 0.1717, d_mnist_loss: 0.0347, d_svhn_loss: 0.1371, d_fake_loss: 0.0741, g_loss: 1.2844\n",
            "Step [13800/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0313, d_svhn_loss: 0.0451, d_fake_loss: 0.0673, g_loss: 1.1090\n",
            "Step [13810/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0251, d_svhn_loss: 0.0363, d_fake_loss: 0.0687, g_loss: 1.1893\n",
            "Step [13820/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0129, d_svhn_loss: 0.0312, d_fake_loss: 0.0565, g_loss: 1.1314\n",
            "Step [13830/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0164, d_svhn_loss: 0.0461, d_fake_loss: 0.0586, g_loss: 1.1967\n",
            "Step [13840/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0356, d_svhn_loss: 0.0414, d_fake_loss: 0.1169, g_loss: 0.8806\n",
            "Step [13850/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0166, d_svhn_loss: 0.0342, d_fake_loss: 0.0956, g_loss: 0.9254\n",
            "Step [13860/80000], d_real_loss: 0.0887, d_mnist_loss: 0.0169, d_svhn_loss: 0.0718, d_fake_loss: 0.0956, g_loss: 1.0245\n",
            "Step [13870/80000], d_real_loss: 0.1116, d_mnist_loss: 0.0122, d_svhn_loss: 0.0994, d_fake_loss: 0.1129, g_loss: 1.0035\n",
            "Step [13880/80000], d_real_loss: 0.1326, d_mnist_loss: 0.0627, d_svhn_loss: 0.0699, d_fake_loss: 0.1049, g_loss: 1.3144\n",
            "Step [13890/80000], d_real_loss: 0.0889, d_mnist_loss: 0.0184, d_svhn_loss: 0.0705, d_fake_loss: 0.0634, g_loss: 1.0592\n",
            "Step [13900/80000], d_real_loss: 0.1212, d_mnist_loss: 0.0854, d_svhn_loss: 0.0358, d_fake_loss: 0.1233, g_loss: 1.4342\n",
            "Step [13910/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0169, d_svhn_loss: 0.0373, d_fake_loss: 0.1050, g_loss: 1.3040\n",
            "Step [13920/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0153, d_svhn_loss: 0.0402, d_fake_loss: 0.0463, g_loss: 0.9530\n",
            "Step [13930/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0211, d_svhn_loss: 0.0301, d_fake_loss: 0.0456, g_loss: 0.9027\n",
            "Step [13940/80000], d_real_loss: 0.2329, d_mnist_loss: 0.0737, d_svhn_loss: 0.1592, d_fake_loss: 0.4106, g_loss: 0.4086\n",
            "Step [13950/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0157, d_svhn_loss: 0.0381, d_fake_loss: 0.0430, g_loss: 1.0664\n",
            "Step [13960/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0156, d_svhn_loss: 0.0315, d_fake_loss: 0.0373, g_loss: 0.9901\n",
            "Step [13970/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0175, d_svhn_loss: 0.0380, d_fake_loss: 0.0953, g_loss: 1.2470\n",
            "Step [13980/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0151, d_svhn_loss: 0.0692, d_fake_loss: 0.1059, g_loss: 1.5468\n",
            "Step [13990/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0230, d_svhn_loss: 0.0441, d_fake_loss: 0.1486, g_loss: 1.4005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9978105425834656]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [14000/80000], d_real_loss: 0.3093, d_mnist_loss: 0.0174, d_svhn_loss: 0.2918, d_fake_loss: 0.1368, g_loss: 1.1057\n",
            "saved ./samples_fashion/sample-14000-m-s.png\n",
            "saved ./samples_fashion/sample-14000-s-m.png\n",
            "Step [14010/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0219, d_svhn_loss: 0.0472, d_fake_loss: 0.0683, g_loss: 1.1226\n",
            "Step [14020/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0310, d_svhn_loss: 0.0527, d_fake_loss: 0.0537, g_loss: 1.1026\n",
            "Step [14030/80000], d_real_loss: 0.0801, d_mnist_loss: 0.0206, d_svhn_loss: 0.0595, d_fake_loss: 0.0941, g_loss: 1.1273\n",
            "Step [14040/80000], d_real_loss: 0.1207, d_mnist_loss: 0.0366, d_svhn_loss: 0.0841, d_fake_loss: 0.0699, g_loss: 1.1069\n",
            "Step [14050/80000], d_real_loss: 0.1664, d_mnist_loss: 0.1207, d_svhn_loss: 0.0457, d_fake_loss: 0.0960, g_loss: 1.1609\n",
            "Step [14060/80000], d_real_loss: 0.1636, d_mnist_loss: 0.0175, d_svhn_loss: 0.1461, d_fake_loss: 0.0979, g_loss: 1.2469\n",
            "Step [14070/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0123, d_svhn_loss: 0.0346, d_fake_loss: 0.2191, g_loss: 1.2163\n",
            "Step [14080/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0267, d_svhn_loss: 0.0313, d_fake_loss: 0.0550, g_loss: 1.2123\n",
            "Step [14090/80000], d_real_loss: 0.1075, d_mnist_loss: 0.0256, d_svhn_loss: 0.0818, d_fake_loss: 0.0856, g_loss: 1.3080\n",
            "Step [14100/80000], d_real_loss: 0.0895, d_mnist_loss: 0.0209, d_svhn_loss: 0.0686, d_fake_loss: 0.2335, g_loss: 0.9101\n",
            "Step [14110/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0246, d_svhn_loss: 0.0420, d_fake_loss: 0.1345, g_loss: 1.2142\n",
            "Step [14120/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0157, d_svhn_loss: 0.0518, d_fake_loss: 0.0432, g_loss: 1.2700\n",
            "Step [14130/80000], d_real_loss: 0.2096, d_mnist_loss: 0.0264, d_svhn_loss: 0.1832, d_fake_loss: 0.0565, g_loss: 0.9455\n",
            "Step [14140/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0190, d_svhn_loss: 0.0382, d_fake_loss: 0.0453, g_loss: 0.9752\n",
            "Step [14150/80000], d_real_loss: 0.1394, d_mnist_loss: 0.0120, d_svhn_loss: 0.1274, d_fake_loss: 0.1551, g_loss: 1.3937\n",
            "Step [14160/80000], d_real_loss: 0.2319, d_mnist_loss: 0.1783, d_svhn_loss: 0.0536, d_fake_loss: 0.1290, g_loss: 1.1531\n",
            "Step [14170/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0169, d_svhn_loss: 0.0472, d_fake_loss: 0.0563, g_loss: 1.1470\n",
            "Step [14180/80000], d_real_loss: 0.1487, d_mnist_loss: 0.0333, d_svhn_loss: 0.1153, d_fake_loss: 0.1431, g_loss: 1.4543\n",
            "Step [14190/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0126, d_svhn_loss: 0.0699, d_fake_loss: 0.0619, g_loss: 1.1741\n",
            "Step [14200/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0168, d_svhn_loss: 0.0520, d_fake_loss: 0.0450, g_loss: 1.3546\n",
            "Step [14210/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0114, d_svhn_loss: 0.0530, d_fake_loss: 0.0738, g_loss: 1.3602\n",
            "Step [14220/80000], d_real_loss: 0.1088, d_mnist_loss: 0.0105, d_svhn_loss: 0.0983, d_fake_loss: 0.0772, g_loss: 0.9276\n",
            "Step [14230/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0644, d_svhn_loss: 0.0347, d_fake_loss: 0.1317, g_loss: 0.8261\n",
            "Step [14240/80000], d_real_loss: 0.0809, d_mnist_loss: 0.0190, d_svhn_loss: 0.0619, d_fake_loss: 0.0589, g_loss: 1.1006\n",
            "Step [14250/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0287, d_svhn_loss: 0.0491, d_fake_loss: 0.0538, g_loss: 1.0239\n",
            "Step [14260/80000], d_real_loss: 0.1309, d_mnist_loss: 0.0493, d_svhn_loss: 0.0816, d_fake_loss: 0.1684, g_loss: 1.3841\n",
            "Step [14270/80000], d_real_loss: 0.0850, d_mnist_loss: 0.0189, d_svhn_loss: 0.0661, d_fake_loss: 0.1094, g_loss: 1.3919\n",
            "Step [14280/80000], d_real_loss: 0.1077, d_mnist_loss: 0.0712, d_svhn_loss: 0.0365, d_fake_loss: 0.0563, g_loss: 1.1160\n",
            "Step [14290/80000], d_real_loss: 0.1520, d_mnist_loss: 0.0210, d_svhn_loss: 0.1310, d_fake_loss: 0.1750, g_loss: 1.1544\n",
            "Step [14300/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0217, d_svhn_loss: 0.0499, d_fake_loss: 0.0288, g_loss: 1.0880\n",
            "Step [14310/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0133, d_svhn_loss: 0.0419, d_fake_loss: 0.0967, g_loss: 1.0145\n",
            "Step [14320/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0256, d_svhn_loss: 0.0379, d_fake_loss: 0.0357, g_loss: 1.0973\n",
            "Step [14330/80000], d_real_loss: 0.2083, d_mnist_loss: 0.0178, d_svhn_loss: 0.1905, d_fake_loss: 0.1263, g_loss: 1.0765\n",
            "Step [14340/80000], d_real_loss: 0.1085, d_mnist_loss: 0.0178, d_svhn_loss: 0.0907, d_fake_loss: 0.0470, g_loss: 1.2175\n",
            "Step [14350/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0216, d_svhn_loss: 0.0320, d_fake_loss: 0.0553, g_loss: 1.0350\n",
            "Step [14360/80000], d_real_loss: 0.1189, d_mnist_loss: 0.0125, d_svhn_loss: 0.1064, d_fake_loss: 0.0824, g_loss: 1.2475\n",
            "Step [14370/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0109, d_svhn_loss: 0.0615, d_fake_loss: 0.2739, g_loss: 1.6144\n",
            "Step [14380/80000], d_real_loss: 0.2241, d_mnist_loss: 0.0108, d_svhn_loss: 0.2132, d_fake_loss: 0.1906, g_loss: 1.2141\n",
            "Step [14390/80000], d_real_loss: 0.1370, d_mnist_loss: 0.0139, d_svhn_loss: 0.1232, d_fake_loss: 0.1342, g_loss: 0.8894\n",
            "Step [14400/80000], d_real_loss: 0.1075, d_mnist_loss: 0.0588, d_svhn_loss: 0.0487, d_fake_loss: 0.1123, g_loss: 1.2123\n",
            "Step [14410/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0116, d_svhn_loss: 0.0594, d_fake_loss: 0.0653, g_loss: 1.2164\n",
            "Step [14420/80000], d_real_loss: 0.1108, d_mnist_loss: 0.0152, d_svhn_loss: 0.0956, d_fake_loss: 0.0871, g_loss: 1.1540\n",
            "Step [14430/80000], d_real_loss: 0.0988, d_mnist_loss: 0.0109, d_svhn_loss: 0.0879, d_fake_loss: 0.0574, g_loss: 1.1142\n",
            "Step [14440/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0148, d_svhn_loss: 0.0508, d_fake_loss: 0.0969, g_loss: 1.5540\n",
            "Step [14450/80000], d_real_loss: 0.0792, d_mnist_loss: 0.0159, d_svhn_loss: 0.0633, d_fake_loss: 0.1408, g_loss: 1.1413\n",
            "Step [14460/80000], d_real_loss: 0.1235, d_mnist_loss: 0.0195, d_svhn_loss: 0.1040, d_fake_loss: 0.0500, g_loss: 1.1072\n",
            "Step [14470/80000], d_real_loss: 0.0949, d_mnist_loss: 0.0226, d_svhn_loss: 0.0723, d_fake_loss: 0.2198, g_loss: 1.6979\n",
            "Step [14480/80000], d_real_loss: 0.0698, d_mnist_loss: 0.0152, d_svhn_loss: 0.0547, d_fake_loss: 0.0855, g_loss: 1.3258\n",
            "Step [14490/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0283, d_svhn_loss: 0.0385, d_fake_loss: 0.0504, g_loss: 1.0861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [14500/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0131, d_svhn_loss: 0.0785, d_fake_loss: 0.1149, g_loss: 1.0681\n",
            "saved ./samples_fashion/sample-14500-m-s.png\n",
            "saved ./samples_fashion/sample-14500-s-m.png\n",
            "Step [14510/80000], d_real_loss: 0.0967, d_mnist_loss: 0.0278, d_svhn_loss: 0.0689, d_fake_loss: 0.0848, g_loss: 1.2355\n",
            "Step [14520/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0154, d_svhn_loss: 0.0454, d_fake_loss: 0.0689, g_loss: 1.2174\n",
            "Step [14530/80000], d_real_loss: 0.1238, d_mnist_loss: 0.0142, d_svhn_loss: 0.1097, d_fake_loss: 0.0658, g_loss: 1.3204\n",
            "Step [14540/80000], d_real_loss: 0.0888, d_mnist_loss: 0.0496, d_svhn_loss: 0.0392, d_fake_loss: 0.1228, g_loss: 1.2275\n",
            "Step [14550/80000], d_real_loss: 0.0701, d_mnist_loss: 0.0170, d_svhn_loss: 0.0532, d_fake_loss: 0.0602, g_loss: 1.2725\n",
            "Step [14560/80000], d_real_loss: 0.1527, d_mnist_loss: 0.0271, d_svhn_loss: 0.1257, d_fake_loss: 0.1495, g_loss: 0.7980\n",
            "Step [14570/80000], d_real_loss: 0.1387, d_mnist_loss: 0.1039, d_svhn_loss: 0.0348, d_fake_loss: 0.0777, g_loss: 1.1174\n",
            "Step [14580/80000], d_real_loss: 0.0864, d_mnist_loss: 0.0165, d_svhn_loss: 0.0699, d_fake_loss: 0.0830, g_loss: 1.2316\n",
            "Step [14590/80000], d_real_loss: 0.1989, d_mnist_loss: 0.0266, d_svhn_loss: 0.1724, d_fake_loss: 0.0796, g_loss: 0.9155\n",
            "Step [14600/80000], d_real_loss: 0.1878, d_mnist_loss: 0.0875, d_svhn_loss: 0.1003, d_fake_loss: 0.1168, g_loss: 1.0874\n",
            "Step [14610/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0149, d_svhn_loss: 0.0465, d_fake_loss: 0.0979, g_loss: 1.0702\n",
            "Step [14620/80000], d_real_loss: 0.1067, d_mnist_loss: 0.0349, d_svhn_loss: 0.0718, d_fake_loss: 0.1309, g_loss: 1.3410\n",
            "Step [14630/80000], d_real_loss: 0.0839, d_mnist_loss: 0.0398, d_svhn_loss: 0.0441, d_fake_loss: 0.0853, g_loss: 1.0850\n",
            "Step [14640/80000], d_real_loss: 0.0803, d_mnist_loss: 0.0435, d_svhn_loss: 0.0368, d_fake_loss: 0.1587, g_loss: 1.1645\n",
            "Step [14650/80000], d_real_loss: 0.3180, d_mnist_loss: 0.0277, d_svhn_loss: 0.2903, d_fake_loss: 0.2714, g_loss: 1.2310\n",
            "Step [14660/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0171, d_svhn_loss: 0.0449, d_fake_loss: 0.0532, g_loss: 1.0662\n",
            "Step [14670/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0109, d_svhn_loss: 0.0469, d_fake_loss: 0.0715, g_loss: 0.9941\n",
            "Step [14680/80000], d_real_loss: 0.1037, d_mnist_loss: 0.0525, d_svhn_loss: 0.0512, d_fake_loss: 0.1051, g_loss: 1.3756\n",
            "Step [14690/80000], d_real_loss: 0.1576, d_mnist_loss: 0.1281, d_svhn_loss: 0.0294, d_fake_loss: 0.0824, g_loss: 1.2013\n",
            "Step [14700/80000], d_real_loss: 0.1517, d_mnist_loss: 0.0334, d_svhn_loss: 0.1183, d_fake_loss: 0.1750, g_loss: 0.7991\n",
            "Step [14710/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0394, d_svhn_loss: 0.0377, d_fake_loss: 0.0572, g_loss: 1.1685\n",
            "Step [14720/80000], d_real_loss: 0.1159, d_mnist_loss: 0.0704, d_svhn_loss: 0.0455, d_fake_loss: 0.0751, g_loss: 0.9845\n",
            "Step [14730/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0171, d_svhn_loss: 0.0381, d_fake_loss: 0.0603, g_loss: 1.1777\n",
            "Step [14740/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0151, d_svhn_loss: 0.0250, d_fake_loss: 0.0645, g_loss: 1.2368\n",
            "Step [14750/80000], d_real_loss: 0.2356, d_mnist_loss: 0.1449, d_svhn_loss: 0.0907, d_fake_loss: 0.0838, g_loss: 1.4459\n",
            "Step [14760/80000], d_real_loss: 0.1296, d_mnist_loss: 0.0180, d_svhn_loss: 0.1116, d_fake_loss: 0.0891, g_loss: 1.0623\n",
            "Step [14770/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0187, d_svhn_loss: 0.0282, d_fake_loss: 0.0795, g_loss: 1.4036\n",
            "Step [14780/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0124, d_svhn_loss: 0.0364, d_fake_loss: 0.1120, g_loss: 1.2859\n",
            "Step [14790/80000], d_real_loss: 0.0626, d_mnist_loss: 0.0128, d_svhn_loss: 0.0498, d_fake_loss: 0.0769, g_loss: 1.2777\n",
            "Step [14800/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0167, d_svhn_loss: 0.0526, d_fake_loss: 0.0901, g_loss: 0.7760\n",
            "Step [14810/80000], d_real_loss: 0.1444, d_mnist_loss: 0.0947, d_svhn_loss: 0.0497, d_fake_loss: 0.0839, g_loss: 1.1791\n",
            "Step [14820/80000], d_real_loss: 0.1363, d_mnist_loss: 0.0175, d_svhn_loss: 0.1188, d_fake_loss: 0.1175, g_loss: 1.1006\n",
            "Step [14830/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0130, d_svhn_loss: 0.0423, d_fake_loss: 0.0911, g_loss: 1.1566\n",
            "Step [14840/80000], d_real_loss: 0.1404, d_mnist_loss: 0.0482, d_svhn_loss: 0.0923, d_fake_loss: 0.1689, g_loss: 1.1784\n",
            "Step [14850/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0190, d_svhn_loss: 0.0347, d_fake_loss: 0.0660, g_loss: 0.9760\n",
            "Step [14860/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0446, d_svhn_loss: 0.0364, d_fake_loss: 0.1010, g_loss: 0.9894\n",
            "Step [14870/80000], d_real_loss: 0.1129, d_mnist_loss: 0.0157, d_svhn_loss: 0.0973, d_fake_loss: 0.1100, g_loss: 1.3620\n",
            "Step [14880/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0378, d_svhn_loss: 0.0452, d_fake_loss: 0.0435, g_loss: 1.0234\n",
            "Step [14890/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0298, d_svhn_loss: 0.0316, d_fake_loss: 0.0529, g_loss: 1.1129\n",
            "Step [14900/80000], d_real_loss: 0.2109, d_mnist_loss: 0.0289, d_svhn_loss: 0.1820, d_fake_loss: 0.0677, g_loss: 1.0358\n",
            "Step [14910/80000], d_real_loss: 0.0885, d_mnist_loss: 0.0193, d_svhn_loss: 0.0692, d_fake_loss: 0.0854, g_loss: 1.3183\n",
            "Step [14920/80000], d_real_loss: 0.1102, d_mnist_loss: 0.0308, d_svhn_loss: 0.0793, d_fake_loss: 0.0671, g_loss: 1.1557\n",
            "Step [14930/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0093, d_svhn_loss: 0.0657, d_fake_loss: 0.0959, g_loss: 1.2148\n",
            "Step [14940/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0188, d_svhn_loss: 0.0290, d_fake_loss: 0.0552, g_loss: 1.3381\n",
            "Step [14950/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0204, d_svhn_loss: 0.0672, d_fake_loss: 0.1402, g_loss: 1.0698\n",
            "Step [14960/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0166, d_svhn_loss: 0.0439, d_fake_loss: 0.0515, g_loss: 1.2046\n",
            "Step [14970/80000], d_real_loss: 0.0920, d_mnist_loss: 0.0123, d_svhn_loss: 0.0797, d_fake_loss: 0.1222, g_loss: 1.2787\n",
            "Step [14980/80000], d_real_loss: 0.5012, d_mnist_loss: 0.4024, d_svhn_loss: 0.0988, d_fake_loss: 0.2723, g_loss: 1.5700\n",
            "Step [14990/80000], d_real_loss: 0.1358, d_mnist_loss: 0.0159, d_svhn_loss: 0.1199, d_fake_loss: 0.1904, g_loss: 0.9117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998807907104, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [15000/80000], d_real_loss: 0.1637, d_mnist_loss: 0.0131, d_svhn_loss: 0.1506, d_fake_loss: 0.1452, g_loss: 1.1545\n",
            "saved ./samples_fashion/sample-15000-m-s.png\n",
            "saved ./samples_fashion/sample-15000-s-m.png\n",
            "Step [15010/80000], d_real_loss: 0.0796, d_mnist_loss: 0.0114, d_svhn_loss: 0.0682, d_fake_loss: 0.0504, g_loss: 1.1835\n",
            "Step [15020/80000], d_real_loss: 0.0776, d_mnist_loss: 0.0266, d_svhn_loss: 0.0510, d_fake_loss: 0.0367, g_loss: 1.2162\n",
            "Step [15030/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0176, d_svhn_loss: 0.0441, d_fake_loss: 0.0340, g_loss: 1.1921\n",
            "Step [15040/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0181, d_svhn_loss: 0.0484, d_fake_loss: 0.0601, g_loss: 1.0913\n",
            "Step [15050/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0156, d_svhn_loss: 0.0835, d_fake_loss: 0.1086, g_loss: 1.3846\n",
            "Step [15060/80000], d_real_loss: 0.0871, d_mnist_loss: 0.0177, d_svhn_loss: 0.0694, d_fake_loss: 0.1184, g_loss: 1.2705\n",
            "Step [15070/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0130, d_svhn_loss: 0.0638, d_fake_loss: 0.0781, g_loss: 1.4255\n",
            "Step [15080/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0156, d_svhn_loss: 0.0319, d_fake_loss: 0.0414, g_loss: 1.1596\n",
            "Step [15090/80000], d_real_loss: 0.1346, d_mnist_loss: 0.0521, d_svhn_loss: 0.0825, d_fake_loss: 0.1253, g_loss: 1.0336\n",
            "Step [15100/80000], d_real_loss: 0.1012, d_mnist_loss: 0.0155, d_svhn_loss: 0.0857, d_fake_loss: 0.0942, g_loss: 1.1970\n",
            "Step [15110/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0125, d_svhn_loss: 0.0298, d_fake_loss: 0.0720, g_loss: 1.1835\n",
            "Step [15120/80000], d_real_loss: 0.1127, d_mnist_loss: 0.0130, d_svhn_loss: 0.0997, d_fake_loss: 0.0526, g_loss: 1.0766\n",
            "Step [15130/80000], d_real_loss: 0.0974, d_mnist_loss: 0.0175, d_svhn_loss: 0.0799, d_fake_loss: 0.0777, g_loss: 1.2006\n",
            "Step [15140/80000], d_real_loss: 0.1626, d_mnist_loss: 0.1155, d_svhn_loss: 0.0471, d_fake_loss: 0.0449, g_loss: 1.2901\n",
            "Step [15150/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0383, d_svhn_loss: 0.0485, d_fake_loss: 0.1225, g_loss: 0.8202\n",
            "Step [15160/80000], d_real_loss: 0.0937, d_mnist_loss: 0.0108, d_svhn_loss: 0.0829, d_fake_loss: 0.0991, g_loss: 1.1838\n",
            "Step [15170/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0116, d_svhn_loss: 0.0215, d_fake_loss: 0.0632, g_loss: 1.2786\n",
            "Step [15180/80000], d_real_loss: 0.1015, d_mnist_loss: 0.0125, d_svhn_loss: 0.0890, d_fake_loss: 0.0610, g_loss: 1.3685\n",
            "Step [15190/80000], d_real_loss: 0.0873, d_mnist_loss: 0.0157, d_svhn_loss: 0.0716, d_fake_loss: 0.0563, g_loss: 1.0684\n",
            "Step [15200/80000], d_real_loss: 0.0872, d_mnist_loss: 0.0165, d_svhn_loss: 0.0708, d_fake_loss: 0.0724, g_loss: 0.8724\n",
            "Step [15210/80000], d_real_loss: 0.1297, d_mnist_loss: 0.0857, d_svhn_loss: 0.0440, d_fake_loss: 0.0894, g_loss: 1.0804\n",
            "Step [15220/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0219, d_svhn_loss: 0.0364, d_fake_loss: 0.0557, g_loss: 1.2387\n",
            "Step [15230/80000], d_real_loss: 0.0943, d_mnist_loss: 0.0126, d_svhn_loss: 0.0817, d_fake_loss: 0.0437, g_loss: 1.1897\n",
            "Step [15240/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0328, d_svhn_loss: 0.0386, d_fake_loss: 0.0675, g_loss: 1.0585\n",
            "Step [15250/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0169, d_svhn_loss: 0.0656, d_fake_loss: 0.0631, g_loss: 1.2409\n",
            "Step [15260/80000], d_real_loss: 0.0816, d_mnist_loss: 0.0430, d_svhn_loss: 0.0386, d_fake_loss: 0.0847, g_loss: 1.0763\n",
            "Step [15270/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0087, d_svhn_loss: 0.0385, d_fake_loss: 0.0753, g_loss: 1.5374\n",
            "Step [15280/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0426, d_svhn_loss: 0.0265, d_fake_loss: 0.1038, g_loss: 1.1808\n",
            "Step [15290/80000], d_real_loss: 0.0858, d_mnist_loss: 0.0210, d_svhn_loss: 0.0648, d_fake_loss: 0.1006, g_loss: 1.1402\n",
            "Step [15300/80000], d_real_loss: 0.1264, d_mnist_loss: 0.0123, d_svhn_loss: 0.1141, d_fake_loss: 0.3880, g_loss: 1.5697\n",
            "Step [15310/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0187, d_svhn_loss: 0.0425, d_fake_loss: 0.0706, g_loss: 1.1608\n",
            "Step [15320/80000], d_real_loss: 0.1413, d_mnist_loss: 0.0251, d_svhn_loss: 0.1162, d_fake_loss: 0.0917, g_loss: 1.1342\n",
            "Step [15330/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0165, d_svhn_loss: 0.0312, d_fake_loss: 0.0634, g_loss: 0.9990\n",
            "Step [15340/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0132, d_svhn_loss: 0.0336, d_fake_loss: 0.0585, g_loss: 1.0083\n",
            "Step [15350/80000], d_real_loss: 0.1033, d_mnist_loss: 0.0691, d_svhn_loss: 0.0342, d_fake_loss: 0.1305, g_loss: 0.9331\n",
            "Step [15360/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0133, d_svhn_loss: 0.0735, d_fake_loss: 0.0635, g_loss: 1.0181\n",
            "Step [15370/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0084, d_svhn_loss: 0.0512, d_fake_loss: 0.1083, g_loss: 1.4341\n",
            "Step [15380/80000], d_real_loss: 0.0849, d_mnist_loss: 0.0488, d_svhn_loss: 0.0361, d_fake_loss: 0.0534, g_loss: 1.1279\n",
            "Step [15390/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0161, d_svhn_loss: 0.0376, d_fake_loss: 0.0579, g_loss: 1.1199\n",
            "Step [15400/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0148, d_svhn_loss: 0.0441, d_fake_loss: 0.0447, g_loss: 1.1121\n",
            "Step [15410/80000], d_real_loss: 0.1335, d_mnist_loss: 0.0153, d_svhn_loss: 0.1182, d_fake_loss: 0.1037, g_loss: 0.9501\n",
            "Step [15420/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0209, d_svhn_loss: 0.0395, d_fake_loss: 0.0535, g_loss: 1.1615\n",
            "Step [15430/80000], d_real_loss: 0.0973, d_mnist_loss: 0.0596, d_svhn_loss: 0.0377, d_fake_loss: 0.0745, g_loss: 1.1423\n",
            "Step [15440/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0199, d_svhn_loss: 0.0405, d_fake_loss: 0.0693, g_loss: 0.9641\n",
            "Step [15450/80000], d_real_loss: 0.1343, d_mnist_loss: 0.0248, d_svhn_loss: 0.1095, d_fake_loss: 0.0833, g_loss: 1.4916\n",
            "Step [15460/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0102, d_svhn_loss: 0.0349, d_fake_loss: 0.0699, g_loss: 0.8553\n",
            "Step [15470/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0134, d_svhn_loss: 0.0303, d_fake_loss: 0.0804, g_loss: 1.2469\n",
            "Step [15480/80000], d_real_loss: 0.1420, d_mnist_loss: 0.1065, d_svhn_loss: 0.0354, d_fake_loss: 0.0603, g_loss: 1.1340\n",
            "Step [15490/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0185, d_svhn_loss: 0.0364, d_fake_loss: 0.1044, g_loss: 1.1639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [15500/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0242, d_svhn_loss: 0.0418, d_fake_loss: 0.1747, g_loss: 1.3355\n",
            "saved ./samples_fashion/sample-15500-m-s.png\n",
            "saved ./samples_fashion/sample-15500-s-m.png\n",
            "Step [15510/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0181, d_svhn_loss: 0.0477, d_fake_loss: 0.0323, g_loss: 1.1142\n",
            "Step [15520/80000], d_real_loss: 0.0801, d_mnist_loss: 0.0308, d_svhn_loss: 0.0493, d_fake_loss: 0.0406, g_loss: 1.1013\n",
            "Step [15530/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0428, d_svhn_loss: 0.0346, d_fake_loss: 0.0870, g_loss: 1.1458\n",
            "Step [15540/80000], d_real_loss: 0.0995, d_mnist_loss: 0.0664, d_svhn_loss: 0.0331, d_fake_loss: 0.0649, g_loss: 1.3794\n",
            "Step [15550/80000], d_real_loss: 0.0905, d_mnist_loss: 0.0180, d_svhn_loss: 0.0725, d_fake_loss: 0.0490, g_loss: 1.1321\n",
            "Step [15560/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0176, d_svhn_loss: 0.0408, d_fake_loss: 0.0398, g_loss: 1.1601\n",
            "Step [15570/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0230, d_svhn_loss: 0.0399, d_fake_loss: 0.0634, g_loss: 0.9408\n",
            "Step [15580/80000], d_real_loss: 0.2513, d_mnist_loss: 0.2099, d_svhn_loss: 0.0413, d_fake_loss: 0.3557, g_loss: 1.3171\n",
            "Step [15590/80000], d_real_loss: 0.0809, d_mnist_loss: 0.0455, d_svhn_loss: 0.0353, d_fake_loss: 0.2752, g_loss: 0.9917\n",
            "Step [15600/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0142, d_svhn_loss: 0.0257, d_fake_loss: 0.0602, g_loss: 1.1822\n",
            "Step [15610/80000], d_real_loss: 0.1879, d_mnist_loss: 0.0192, d_svhn_loss: 0.1688, d_fake_loss: 0.2187, g_loss: 1.2051\n",
            "Step [15620/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0136, d_svhn_loss: 0.0338, d_fake_loss: 0.0799, g_loss: 1.5434\n",
            "Step [15630/80000], d_real_loss: 0.0986, d_mnist_loss: 0.0261, d_svhn_loss: 0.0725, d_fake_loss: 0.1474, g_loss: 1.1449\n",
            "Step [15640/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0210, d_svhn_loss: 0.0405, d_fake_loss: 0.0577, g_loss: 1.3986\n",
            "Step [15650/80000], d_real_loss: 0.1061, d_mnist_loss: 0.0204, d_svhn_loss: 0.0857, d_fake_loss: 0.0617, g_loss: 0.9470\n",
            "Step [15660/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0099, d_svhn_loss: 0.0279, d_fake_loss: 0.0718, g_loss: 0.8822\n",
            "Step [15670/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0217, d_svhn_loss: 0.0321, d_fake_loss: 0.0495, g_loss: 1.0366\n",
            "Step [15680/80000], d_real_loss: 0.1755, d_mnist_loss: 0.0250, d_svhn_loss: 0.1506, d_fake_loss: 0.1095, g_loss: 1.0172\n",
            "Step [15690/80000], d_real_loss: 0.1246, d_mnist_loss: 0.0119, d_svhn_loss: 0.1126, d_fake_loss: 0.0646, g_loss: 1.1356\n",
            "Step [15700/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0136, d_svhn_loss: 0.0328, d_fake_loss: 0.0451, g_loss: 1.1811\n",
            "Step [15710/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0137, d_svhn_loss: 0.0403, d_fake_loss: 0.0422, g_loss: 1.2727\n",
            "Step [15720/80000], d_real_loss: 0.0870, d_mnist_loss: 0.0157, d_svhn_loss: 0.0713, d_fake_loss: 0.1078, g_loss: 0.9560\n",
            "Step [15730/80000], d_real_loss: 0.1027, d_mnist_loss: 0.0400, d_svhn_loss: 0.0627, d_fake_loss: 0.1242, g_loss: 1.2621\n",
            "Step [15740/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0112, d_svhn_loss: 0.0526, d_fake_loss: 0.0343, g_loss: 1.0299\n",
            "Step [15750/80000], d_real_loss: 0.1707, d_mnist_loss: 0.0478, d_svhn_loss: 0.1228, d_fake_loss: 0.0404, g_loss: 1.1222\n",
            "Step [15760/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0195, d_svhn_loss: 0.0394, d_fake_loss: 0.0462, g_loss: 1.1733\n",
            "Step [15770/80000], d_real_loss: 0.0726, d_mnist_loss: 0.0339, d_svhn_loss: 0.0387, d_fake_loss: 0.0609, g_loss: 1.0901\n",
            "Step [15780/80000], d_real_loss: 0.1049, d_mnist_loss: 0.0605, d_svhn_loss: 0.0443, d_fake_loss: 0.1299, g_loss: 1.5930\n",
            "Step [15790/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0410, d_svhn_loss: 0.0251, d_fake_loss: 0.0718, g_loss: 1.1490\n",
            "Step [15800/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0135, d_svhn_loss: 0.0306, d_fake_loss: 0.0683, g_loss: 1.1301\n",
            "Step [15810/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0113, d_svhn_loss: 0.0278, d_fake_loss: 0.0345, g_loss: 1.1395\n",
            "Step [15820/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0148, d_svhn_loss: 0.0397, d_fake_loss: 0.0419, g_loss: 1.1109\n",
            "Step [15830/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0336, d_svhn_loss: 0.0367, d_fake_loss: 0.1319, g_loss: 1.1786\n",
            "Step [15840/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0198, d_svhn_loss: 0.0396, d_fake_loss: 0.0829, g_loss: 1.0144\n",
            "Step [15850/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0210, d_svhn_loss: 0.0347, d_fake_loss: 0.0602, g_loss: 1.1570\n",
            "Step [15860/80000], d_real_loss: 0.1801, d_mnist_loss: 0.0614, d_svhn_loss: 0.1187, d_fake_loss: 0.3837, g_loss: 1.6374\n",
            "Step [15870/80000], d_real_loss: 0.0870, d_mnist_loss: 0.0241, d_svhn_loss: 0.0629, d_fake_loss: 0.0563, g_loss: 1.0381\n",
            "Step [15880/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0196, d_svhn_loss: 0.0369, d_fake_loss: 0.0905, g_loss: 1.1172\n",
            "Step [15890/80000], d_real_loss: 0.0776, d_mnist_loss: 0.0249, d_svhn_loss: 0.0527, d_fake_loss: 0.1436, g_loss: 1.0343\n",
            "Step [15900/80000], d_real_loss: 0.0835, d_mnist_loss: 0.0142, d_svhn_loss: 0.0693, d_fake_loss: 0.1347, g_loss: 1.3056\n",
            "Step [15910/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0238, d_svhn_loss: 0.0486, d_fake_loss: 0.0919, g_loss: 1.2550\n",
            "Step [15920/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0239, d_svhn_loss: 0.0315, d_fake_loss: 0.0479, g_loss: 0.9118\n",
            "Step [15930/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0108, d_svhn_loss: 0.0326, d_fake_loss: 0.0503, g_loss: 1.1209\n",
            "Step [15940/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0145, d_svhn_loss: 0.0380, d_fake_loss: 0.0566, g_loss: 1.1972\n",
            "Step [15950/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0156, d_svhn_loss: 0.0544, d_fake_loss: 0.0395, g_loss: 1.1663\n",
            "Step [15960/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0242, d_svhn_loss: 0.0479, d_fake_loss: 0.0559, g_loss: 1.2692\n",
            "Step [15970/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0235, d_svhn_loss: 0.0359, d_fake_loss: 0.0856, g_loss: 1.1194\n",
            "Step [15980/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0193, d_svhn_loss: 0.0711, d_fake_loss: 0.0562, g_loss: 1.1255\n",
            "Step [15990/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0373, d_svhn_loss: 0.0571, d_fake_loss: 0.1127, g_loss: 1.0154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [16000/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0120, d_svhn_loss: 0.0421, d_fake_loss: 0.1259, g_loss: 1.1953\n",
            "saved ./samples_fashion/sample-16000-m-s.png\n",
            "saved ./samples_fashion/sample-16000-s-m.png\n",
            "Step [16010/80000], d_real_loss: 0.1152, d_mnist_loss: 0.0217, d_svhn_loss: 0.0936, d_fake_loss: 0.1191, g_loss: 0.9254\n",
            "Step [16020/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0145, d_svhn_loss: 0.0331, d_fake_loss: 0.1096, g_loss: 1.1632\n",
            "Step [16030/80000], d_real_loss: 0.0823, d_mnist_loss: 0.0125, d_svhn_loss: 0.0699, d_fake_loss: 0.0571, g_loss: 1.1827\n",
            "Step [16040/80000], d_real_loss: 0.0747, d_mnist_loss: 0.0340, d_svhn_loss: 0.0407, d_fake_loss: 0.1254, g_loss: 1.0809\n",
            "Step [16050/80000], d_real_loss: 0.1152, d_mnist_loss: 0.0339, d_svhn_loss: 0.0812, d_fake_loss: 0.0584, g_loss: 1.1206\n",
            "Step [16060/80000], d_real_loss: 0.1523, d_mnist_loss: 0.0303, d_svhn_loss: 0.1220, d_fake_loss: 0.1923, g_loss: 1.1051\n",
            "Step [16070/80000], d_real_loss: 0.1701, d_mnist_loss: 0.1285, d_svhn_loss: 0.0416, d_fake_loss: 0.0827, g_loss: 1.4541\n",
            "Step [16080/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0343, d_svhn_loss: 0.0427, d_fake_loss: 0.0926, g_loss: 0.7048\n",
            "Step [16090/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0207, d_svhn_loss: 0.0441, d_fake_loss: 0.1180, g_loss: 1.1124\n",
            "Step [16100/80000], d_real_loss: 0.2014, d_mnist_loss: 0.0130, d_svhn_loss: 0.1883, d_fake_loss: 1.0289, g_loss: 0.9947\n",
            "Step [16110/80000], d_real_loss: 0.1534, d_mnist_loss: 0.0128, d_svhn_loss: 0.1406, d_fake_loss: 0.4630, g_loss: 1.3612\n",
            "Step [16120/80000], d_real_loss: 0.1014, d_mnist_loss: 0.0199, d_svhn_loss: 0.0815, d_fake_loss: 0.1799, g_loss: 1.0382\n",
            "Step [16130/80000], d_real_loss: 0.1448, d_mnist_loss: 0.0264, d_svhn_loss: 0.1184, d_fake_loss: 0.1021, g_loss: 1.2441\n",
            "Step [16140/80000], d_real_loss: 0.0874, d_mnist_loss: 0.0361, d_svhn_loss: 0.0513, d_fake_loss: 0.0407, g_loss: 1.0235\n",
            "Step [16150/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0200, d_svhn_loss: 0.0396, d_fake_loss: 0.0902, g_loss: 1.4590\n",
            "Step [16160/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0128, d_svhn_loss: 0.0659, d_fake_loss: 0.0871, g_loss: 1.4285\n",
            "Step [16170/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0169, d_svhn_loss: 0.0476, d_fake_loss: 0.0965, g_loss: 1.5296\n",
            "Step [16180/80000], d_real_loss: 0.1942, d_mnist_loss: 0.1571, d_svhn_loss: 0.0371, d_fake_loss: 0.0895, g_loss: 0.9434\n",
            "Step [16190/80000], d_real_loss: 0.1679, d_mnist_loss: 0.1046, d_svhn_loss: 0.0634, d_fake_loss: 0.0733, g_loss: 1.0485\n",
            "Step [16200/80000], d_real_loss: 0.0937, d_mnist_loss: 0.0159, d_svhn_loss: 0.0778, d_fake_loss: 0.0839, g_loss: 1.0537\n",
            "Step [16210/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0217, d_svhn_loss: 0.0429, d_fake_loss: 0.0784, g_loss: 1.1359\n",
            "Step [16220/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0425, d_svhn_loss: 0.0348, d_fake_loss: 0.1134, g_loss: 1.3567\n",
            "Step [16230/80000], d_real_loss: 0.0767, d_mnist_loss: 0.0144, d_svhn_loss: 0.0623, d_fake_loss: 0.0503, g_loss: 0.9150\n",
            "Step [16240/80000], d_real_loss: 0.1500, d_mnist_loss: 0.0407, d_svhn_loss: 0.1093, d_fake_loss: 0.0756, g_loss: 1.1304\n",
            "Step [16250/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0125, d_svhn_loss: 0.0456, d_fake_loss: 0.0543, g_loss: 1.1974\n",
            "Step [16260/80000], d_real_loss: 0.1109, d_mnist_loss: 0.0312, d_svhn_loss: 0.0797, d_fake_loss: 0.0631, g_loss: 1.1705\n",
            "Step [16270/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0142, d_svhn_loss: 0.0580, d_fake_loss: 0.0388, g_loss: 1.0465\n",
            "Step [16280/80000], d_real_loss: 0.1318, d_mnist_loss: 0.0134, d_svhn_loss: 0.1185, d_fake_loss: 0.0710, g_loss: 1.1433\n",
            "Step [16290/80000], d_real_loss: 0.0775, d_mnist_loss: 0.0301, d_svhn_loss: 0.0474, d_fake_loss: 0.0630, g_loss: 1.2196\n",
            "Step [16300/80000], d_real_loss: 0.1191, d_mnist_loss: 0.0364, d_svhn_loss: 0.0828, d_fake_loss: 0.1719, g_loss: 1.3458\n",
            "Step [16310/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0335, d_svhn_loss: 0.0558, d_fake_loss: 0.1004, g_loss: 1.0001\n",
            "Step [16320/80000], d_real_loss: 0.1202, d_mnist_loss: 0.0206, d_svhn_loss: 0.0996, d_fake_loss: 0.0438, g_loss: 0.9580\n",
            "Step [16330/80000], d_real_loss: 0.1692, d_mnist_loss: 0.0177, d_svhn_loss: 0.1515, d_fake_loss: 0.1568, g_loss: 1.3374\n",
            "Step [16340/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0219, d_svhn_loss: 0.0326, d_fake_loss: 0.1439, g_loss: 0.5217\n",
            "Step [16350/80000], d_real_loss: 0.1071, d_mnist_loss: 0.0130, d_svhn_loss: 0.0941, d_fake_loss: 0.1648, g_loss: 1.2989\n",
            "Step [16360/80000], d_real_loss: 0.1041, d_mnist_loss: 0.0337, d_svhn_loss: 0.0703, d_fake_loss: 0.0784, g_loss: 1.0883\n",
            "Step [16370/80000], d_real_loss: 0.1161, d_mnist_loss: 0.0521, d_svhn_loss: 0.0640, d_fake_loss: 0.0683, g_loss: 1.3379\n",
            "Step [16380/80000], d_real_loss: 0.0881, d_mnist_loss: 0.0265, d_svhn_loss: 0.0616, d_fake_loss: 0.1288, g_loss: 1.0041\n",
            "Step [16390/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0140, d_svhn_loss: 0.0393, d_fake_loss: 0.1466, g_loss: 1.2781\n",
            "Step [16400/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0177, d_svhn_loss: 0.0428, d_fake_loss: 0.0450, g_loss: 0.9900\n",
            "Step [16410/80000], d_real_loss: 0.1453, d_mnist_loss: 0.0900, d_svhn_loss: 0.0553, d_fake_loss: 0.1539, g_loss: 1.2587\n",
            "Step [16420/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0244, d_svhn_loss: 0.0346, d_fake_loss: 0.0764, g_loss: 1.1459\n",
            "Step [16430/80000], d_real_loss: 0.1151, d_mnist_loss: 0.0703, d_svhn_loss: 0.0448, d_fake_loss: 0.1508, g_loss: 1.7074\n",
            "Step [16440/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0167, d_svhn_loss: 0.0576, d_fake_loss: 0.0881, g_loss: 1.0779\n",
            "Step [16450/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0109, d_svhn_loss: 0.0681, d_fake_loss: 0.0766, g_loss: 1.2072\n",
            "Step [16460/80000], d_real_loss: 0.0808, d_mnist_loss: 0.0558, d_svhn_loss: 0.0250, d_fake_loss: 0.0874, g_loss: 1.2926\n",
            "Step [16470/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0319, d_svhn_loss: 0.0529, d_fake_loss: 0.4120, g_loss: 1.9087\n",
            "Step [16480/80000], d_real_loss: 0.1076, d_mnist_loss: 0.0284, d_svhn_loss: 0.0792, d_fake_loss: 0.0755, g_loss: 1.1374\n",
            "Step [16490/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0269, d_svhn_loss: 0.0374, d_fake_loss: 0.0497, g_loss: 1.1599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999997615814209, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [16500/80000], d_real_loss: 0.0951, d_mnist_loss: 0.0310, d_svhn_loss: 0.0641, d_fake_loss: 0.1016, g_loss: 1.0816\n",
            "saved ./samples_fashion/sample-16500-m-s.png\n",
            "saved ./samples_fashion/sample-16500-s-m.png\n",
            "Step [16510/80000], d_real_loss: 0.0824, d_mnist_loss: 0.0150, d_svhn_loss: 0.0674, d_fake_loss: 0.0384, g_loss: 1.0447\n",
            "Step [16520/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0094, d_svhn_loss: 0.0310, d_fake_loss: 0.0833, g_loss: 0.8744\n",
            "Step [16530/80000], d_real_loss: 0.0726, d_mnist_loss: 0.0337, d_svhn_loss: 0.0389, d_fake_loss: 0.0507, g_loss: 1.1146\n",
            "Step [16540/80000], d_real_loss: 0.1337, d_mnist_loss: 0.0148, d_svhn_loss: 0.1189, d_fake_loss: 0.0620, g_loss: 1.0880\n",
            "Step [16550/80000], d_real_loss: 0.0757, d_mnist_loss: 0.0167, d_svhn_loss: 0.0590, d_fake_loss: 0.0994, g_loss: 0.7645\n",
            "Step [16560/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0239, d_svhn_loss: 0.0277, d_fake_loss: 0.0448, g_loss: 1.0708\n",
            "Step [16570/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0159, d_svhn_loss: 0.0573, d_fake_loss: 0.1452, g_loss: 0.9002\n",
            "Step [16580/80000], d_real_loss: 0.1346, d_mnist_loss: 0.0191, d_svhn_loss: 0.1154, d_fake_loss: 0.1532, g_loss: 0.8040\n",
            "Step [16590/80000], d_real_loss: 0.0847, d_mnist_loss: 0.0187, d_svhn_loss: 0.0659, d_fake_loss: 0.2507, g_loss: 1.5541\n",
            "Step [16600/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0330, d_svhn_loss: 0.0299, d_fake_loss: 0.0897, g_loss: 1.4243\n",
            "Step [16610/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0127, d_svhn_loss: 0.0536, d_fake_loss: 0.0787, g_loss: 1.2153\n",
            "Step [16620/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0223, d_svhn_loss: 0.0421, d_fake_loss: 0.1089, g_loss: 1.0897\n",
            "Step [16630/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0179, d_svhn_loss: 0.0354, d_fake_loss: 0.0488, g_loss: 1.1627\n",
            "Step [16640/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0215, d_svhn_loss: 0.0563, d_fake_loss: 0.0646, g_loss: 1.1265\n",
            "Step [16650/80000], d_real_loss: 0.0769, d_mnist_loss: 0.0270, d_svhn_loss: 0.0499, d_fake_loss: 0.1758, g_loss: 1.1272\n",
            "Step [16660/80000], d_real_loss: 0.1308, d_mnist_loss: 0.0159, d_svhn_loss: 0.1149, d_fake_loss: 0.1930, g_loss: 0.7252\n",
            "Step [16670/80000], d_real_loss: 0.1165, d_mnist_loss: 0.0122, d_svhn_loss: 0.1044, d_fake_loss: 0.1291, g_loss: 1.0886\n",
            "Step [16680/80000], d_real_loss: 0.0776, d_mnist_loss: 0.0520, d_svhn_loss: 0.0256, d_fake_loss: 0.0378, g_loss: 1.1484\n",
            "Step [16690/80000], d_real_loss: 0.1329, d_mnist_loss: 0.0181, d_svhn_loss: 0.1147, d_fake_loss: 0.0810, g_loss: 0.8435\n",
            "Step [16700/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0191, d_svhn_loss: 0.0195, d_fake_loss: 0.0674, g_loss: 1.1536\n",
            "Step [16710/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0143, d_svhn_loss: 0.0379, d_fake_loss: 0.0310, g_loss: 1.1673\n",
            "Step [16720/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0323, d_svhn_loss: 0.0397, d_fake_loss: 0.0328, g_loss: 1.2414\n",
            "Step [16730/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0127, d_svhn_loss: 0.0637, d_fake_loss: 0.0522, g_loss: 1.0394\n",
            "Step [16740/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0232, d_svhn_loss: 0.0319, d_fake_loss: 0.0566, g_loss: 1.1778\n",
            "Step [16750/80000], d_real_loss: 0.1151, d_mnist_loss: 0.0144, d_svhn_loss: 0.1007, d_fake_loss: 0.4091, g_loss: 1.0686\n",
            "Step [16760/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0238, d_svhn_loss: 0.0435, d_fake_loss: 0.1067, g_loss: 1.3847\n",
            "Step [16770/80000], d_real_loss: 0.1002, d_mnist_loss: 0.0613, d_svhn_loss: 0.0389, d_fake_loss: 0.0478, g_loss: 1.1500\n",
            "Step [16780/80000], d_real_loss: 0.1102, d_mnist_loss: 0.0175, d_svhn_loss: 0.0928, d_fake_loss: 0.0798, g_loss: 1.3067\n",
            "Step [16790/80000], d_real_loss: 0.1790, d_mnist_loss: 0.0835, d_svhn_loss: 0.0954, d_fake_loss: 0.1760, g_loss: 1.0350\n",
            "Step [16800/80000], d_real_loss: 0.1092, d_mnist_loss: 0.0184, d_svhn_loss: 0.0908, d_fake_loss: 0.0550, g_loss: 1.3657\n",
            "Step [16810/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0226, d_svhn_loss: 0.0367, d_fake_loss: 0.0585, g_loss: 1.0387\n",
            "Step [16820/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0161, d_svhn_loss: 0.0386, d_fake_loss: 0.0708, g_loss: 1.1191\n",
            "Step [16830/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0149, d_svhn_loss: 0.0444, d_fake_loss: 0.0381, g_loss: 1.1572\n",
            "Step [16840/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0084, d_svhn_loss: 0.0386, d_fake_loss: 0.0854, g_loss: 1.2732\n",
            "Step [16850/80000], d_real_loss: 0.0924, d_mnist_loss: 0.0422, d_svhn_loss: 0.0503, d_fake_loss: 0.0508, g_loss: 1.1322\n",
            "Step [16860/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0355, d_svhn_loss: 0.0431, d_fake_loss: 0.0710, g_loss: 0.9100\n",
            "Step [16870/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0171, d_svhn_loss: 0.0587, d_fake_loss: 0.1592, g_loss: 0.9987\n",
            "Step [16880/80000], d_real_loss: 0.0781, d_mnist_loss: 0.0230, d_svhn_loss: 0.0552, d_fake_loss: 0.1183, g_loss: 1.0499\n",
            "Step [16890/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0184, d_svhn_loss: 0.0449, d_fake_loss: 0.0576, g_loss: 0.9964\n",
            "Step [16900/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0111, d_svhn_loss: 0.0377, d_fake_loss: 0.0792, g_loss: 0.9401\n",
            "Step [16910/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0225, d_svhn_loss: 0.0265, d_fake_loss: 0.0687, g_loss: 1.0705\n",
            "Step [16920/80000], d_real_loss: 0.2101, d_mnist_loss: 0.0131, d_svhn_loss: 0.1970, d_fake_loss: 0.2154, g_loss: 1.1413\n",
            "Step [16930/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0160, d_svhn_loss: 0.0423, d_fake_loss: 0.0711, g_loss: 1.1041\n",
            "Step [16940/80000], d_real_loss: 0.1010, d_mnist_loss: 0.0138, d_svhn_loss: 0.0872, d_fake_loss: 0.0706, g_loss: 0.9174\n",
            "Step [16950/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0110, d_svhn_loss: 0.0347, d_fake_loss: 0.1210, g_loss: 1.3625\n",
            "Step [16960/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0118, d_svhn_loss: 0.0342, d_fake_loss: 0.1252, g_loss: 1.1685\n",
            "Step [16970/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0276, d_svhn_loss: 0.0454, d_fake_loss: 0.0474, g_loss: 1.3626\n",
            "Step [16980/80000], d_real_loss: 0.0823, d_mnist_loss: 0.0300, d_svhn_loss: 0.0523, d_fake_loss: 0.0987, g_loss: 1.2065\n",
            "Step [16990/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0238, d_svhn_loss: 0.0429, d_fake_loss: 0.0403, g_loss: 1.2349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999995231628418, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [17000/80000], d_real_loss: 0.1173, d_mnist_loss: 0.0168, d_svhn_loss: 0.1005, d_fake_loss: 0.2090, g_loss: 1.5557\n",
            "saved ./samples_fashion/sample-17000-m-s.png\n",
            "saved ./samples_fashion/sample-17000-s-m.png\n",
            "Step [17010/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0100, d_svhn_loss: 0.0434, d_fake_loss: 0.0523, g_loss: 0.9951\n",
            "Step [17020/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0399, d_svhn_loss: 0.0324, d_fake_loss: 0.0504, g_loss: 1.0658\n",
            "Step [17030/80000], d_real_loss: 0.0947, d_mnist_loss: 0.0197, d_svhn_loss: 0.0750, d_fake_loss: 0.1127, g_loss: 0.8882\n",
            "Step [17040/80000], d_real_loss: 0.0878, d_mnist_loss: 0.0172, d_svhn_loss: 0.0705, d_fake_loss: 0.1033, g_loss: 1.2512\n",
            "Step [17050/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0391, d_svhn_loss: 0.0525, d_fake_loss: 0.0717, g_loss: 1.4336\n",
            "Step [17060/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0182, d_svhn_loss: 0.0397, d_fake_loss: 0.0951, g_loss: 1.0623\n",
            "Step [17070/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0135, d_svhn_loss: 0.0536, d_fake_loss: 0.1006, g_loss: 1.0310\n",
            "Step [17080/80000], d_real_loss: 0.1000, d_mnist_loss: 0.0416, d_svhn_loss: 0.0584, d_fake_loss: 0.1026, g_loss: 1.3156\n",
            "Step [17090/80000], d_real_loss: 0.1308, d_mnist_loss: 0.0114, d_svhn_loss: 0.1194, d_fake_loss: 0.2338, g_loss: 0.8346\n",
            "Step [17100/80000], d_real_loss: 0.1705, d_mnist_loss: 0.0377, d_svhn_loss: 0.1328, d_fake_loss: 0.0841, g_loss: 1.1352\n",
            "Step [17110/80000], d_real_loss: 0.1134, d_mnist_loss: 0.0343, d_svhn_loss: 0.0791, d_fake_loss: 0.0384, g_loss: 1.1026\n",
            "Step [17120/80000], d_real_loss: 0.1378, d_mnist_loss: 0.0173, d_svhn_loss: 0.1205, d_fake_loss: 0.1118, g_loss: 0.9065\n",
            "Step [17130/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0196, d_svhn_loss: 0.0456, d_fake_loss: 0.0521, g_loss: 1.2952\n",
            "Step [17140/80000], d_real_loss: 0.1353, d_mnist_loss: 0.0115, d_svhn_loss: 0.1238, d_fake_loss: 0.0550, g_loss: 1.1674\n",
            "Step [17150/80000], d_real_loss: 0.3060, d_mnist_loss: 0.2484, d_svhn_loss: 0.0577, d_fake_loss: 0.0904, g_loss: 1.1352\n",
            "Step [17160/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0180, d_svhn_loss: 0.0524, d_fake_loss: 0.0585, g_loss: 1.0014\n",
            "Step [17170/80000], d_real_loss: 0.1119, d_mnist_loss: 0.0294, d_svhn_loss: 0.0825, d_fake_loss: 0.0692, g_loss: 1.0748\n",
            "Step [17180/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0123, d_svhn_loss: 0.0630, d_fake_loss: 0.0913, g_loss: 1.1710\n",
            "Step [17190/80000], d_real_loss: 0.2135, d_mnist_loss: 0.0158, d_svhn_loss: 0.1977, d_fake_loss: 0.2172, g_loss: 1.1870\n",
            "Step [17200/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0086, d_svhn_loss: 0.0468, d_fake_loss: 0.0411, g_loss: 1.0964\n",
            "Step [17210/80000], d_real_loss: 0.0626, d_mnist_loss: 0.0236, d_svhn_loss: 0.0390, d_fake_loss: 0.1137, g_loss: 1.3620\n",
            "Step [17220/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0146, d_svhn_loss: 0.0371, d_fake_loss: 0.0772, g_loss: 0.9792\n",
            "Step [17230/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0232, d_svhn_loss: 0.0616, d_fake_loss: 0.0462, g_loss: 1.0477\n",
            "Step [17240/80000], d_real_loss: 0.1002, d_mnist_loss: 0.0262, d_svhn_loss: 0.0740, d_fake_loss: 0.1213, g_loss: 1.1510\n",
            "Step [17250/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0161, d_svhn_loss: 0.0469, d_fake_loss: 0.0502, g_loss: 1.0543\n",
            "Step [17260/80000], d_real_loss: 0.1020, d_mnist_loss: 0.0250, d_svhn_loss: 0.0770, d_fake_loss: 0.0849, g_loss: 1.2100\n",
            "Step [17270/80000], d_real_loss: 0.1555, d_mnist_loss: 0.0112, d_svhn_loss: 0.1443, d_fake_loss: 0.1106, g_loss: 0.9211\n",
            "Step [17280/80000], d_real_loss: 0.0953, d_mnist_loss: 0.0108, d_svhn_loss: 0.0845, d_fake_loss: 0.0732, g_loss: 0.9685\n",
            "Step [17290/80000], d_real_loss: 0.1547, d_mnist_loss: 0.1078, d_svhn_loss: 0.0468, d_fake_loss: 0.1398, g_loss: 1.7039\n",
            "Step [17300/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0288, d_svhn_loss: 0.0432, d_fake_loss: 0.0762, g_loss: 0.9664\n",
            "Step [17310/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0147, d_svhn_loss: 0.0431, d_fake_loss: 0.0605, g_loss: 0.9313\n",
            "Step [17320/80000], d_real_loss: 0.1408, d_mnist_loss: 0.0150, d_svhn_loss: 0.1259, d_fake_loss: 0.1820, g_loss: 1.0742\n",
            "Step [17330/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0196, d_svhn_loss: 0.0478, d_fake_loss: 0.0589, g_loss: 1.0511\n",
            "Step [17340/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0250, d_svhn_loss: 0.0474, d_fake_loss: 0.0579, g_loss: 1.1611\n",
            "Step [17350/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0097, d_svhn_loss: 0.0263, d_fake_loss: 0.0487, g_loss: 1.2025\n",
            "Step [17360/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0115, d_svhn_loss: 0.0522, d_fake_loss: 0.0578, g_loss: 1.3462\n",
            "Step [17370/80000], d_real_loss: 0.1120, d_mnist_loss: 0.0627, d_svhn_loss: 0.0493, d_fake_loss: 0.0753, g_loss: 0.9944\n",
            "Step [17380/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0107, d_svhn_loss: 0.0284, d_fake_loss: 0.1385, g_loss: 1.1520\n",
            "Step [17390/80000], d_real_loss: 0.0626, d_mnist_loss: 0.0302, d_svhn_loss: 0.0324, d_fake_loss: 0.0617, g_loss: 1.2811\n",
            "Step [17400/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0182, d_svhn_loss: 0.0471, d_fake_loss: 0.0641, g_loss: 1.2781\n",
            "Step [17410/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0099, d_svhn_loss: 0.0528, d_fake_loss: 0.0623, g_loss: 1.4679\n",
            "Step [17420/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0180, d_svhn_loss: 0.0327, d_fake_loss: 0.0527, g_loss: 1.0335\n",
            "Step [17430/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0442, d_svhn_loss: 0.0404, d_fake_loss: 0.2072, g_loss: 1.3262\n",
            "Step [17440/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0191, d_svhn_loss: 0.0310, d_fake_loss: 0.0515, g_loss: 1.3574\n",
            "Step [17450/80000], d_real_loss: 0.1034, d_mnist_loss: 0.0132, d_svhn_loss: 0.0902, d_fake_loss: 0.2255, g_loss: 0.9826\n",
            "Step [17460/80000], d_real_loss: 0.1691, d_mnist_loss: 0.0732, d_svhn_loss: 0.0959, d_fake_loss: 0.1869, g_loss: 1.0146\n",
            "Step [17470/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0160, d_svhn_loss: 0.0523, d_fake_loss: 0.0787, g_loss: 1.5959\n",
            "Step [17480/80000], d_real_loss: 0.0964, d_mnist_loss: 0.0119, d_svhn_loss: 0.0845, d_fake_loss: 0.0771, g_loss: 1.1250\n",
            "Step [17490/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0131, d_svhn_loss: 0.0579, d_fake_loss: 0.0372, g_loss: 1.1590\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999996423721313, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [17500/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0261, d_svhn_loss: 0.0406, d_fake_loss: 0.1454, g_loss: 1.3437\n",
            "saved ./samples_fashion/sample-17500-m-s.png\n",
            "saved ./samples_fashion/sample-17500-s-m.png\n",
            "Step [17510/80000], d_real_loss: 0.0939, d_mnist_loss: 0.0217, d_svhn_loss: 0.0722, d_fake_loss: 0.1936, g_loss: 1.1889\n",
            "Step [17520/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0237, d_svhn_loss: 0.0415, d_fake_loss: 0.1137, g_loss: 1.5375\n",
            "Step [17530/80000], d_real_loss: 0.1626, d_mnist_loss: 0.0647, d_svhn_loss: 0.0978, d_fake_loss: 0.2092, g_loss: 1.1678\n",
            "Step [17540/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0130, d_svhn_loss: 0.0335, d_fake_loss: 0.0756, g_loss: 1.3079\n",
            "Step [17550/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0225, d_svhn_loss: 0.0693, d_fake_loss: 0.1388, g_loss: 0.9321\n",
            "Step [17560/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0106, d_svhn_loss: 0.0644, d_fake_loss: 0.0324, g_loss: 1.1381\n",
            "Step [17570/80000], d_real_loss: 0.0972, d_mnist_loss: 0.0554, d_svhn_loss: 0.0418, d_fake_loss: 0.0435, g_loss: 1.0906\n",
            "Step [17580/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0157, d_svhn_loss: 0.0579, d_fake_loss: 0.0973, g_loss: 1.1157\n",
            "Step [17590/80000], d_real_loss: 0.0936, d_mnist_loss: 0.0143, d_svhn_loss: 0.0792, d_fake_loss: 0.0482, g_loss: 1.1004\n",
            "Step [17600/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0172, d_svhn_loss: 0.0312, d_fake_loss: 0.0438, g_loss: 1.1537\n",
            "Step [17610/80000], d_real_loss: 0.1242, d_mnist_loss: 0.0337, d_svhn_loss: 0.0906, d_fake_loss: 0.2908, g_loss: 1.3994\n",
            "Step [17620/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0169, d_svhn_loss: 0.0425, d_fake_loss: 0.0983, g_loss: 1.0742\n",
            "Step [17630/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0123, d_svhn_loss: 0.0560, d_fake_loss: 0.0385, g_loss: 1.1853\n",
            "Step [17640/80000], d_real_loss: 0.0975, d_mnist_loss: 0.0156, d_svhn_loss: 0.0819, d_fake_loss: 0.0660, g_loss: 1.1529\n",
            "Step [17650/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0091, d_svhn_loss: 0.0400, d_fake_loss: 0.0588, g_loss: 1.1404\n",
            "Step [17660/80000], d_real_loss: 0.2300, d_mnist_loss: 0.0906, d_svhn_loss: 0.1394, d_fake_loss: 0.1653, g_loss: 1.2738\n",
            "Step [17670/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0310, d_svhn_loss: 0.0306, d_fake_loss: 0.1287, g_loss: 1.2824\n",
            "Step [17680/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0219, d_svhn_loss: 0.0181, d_fake_loss: 0.1522, g_loss: 1.3109\n",
            "Step [17690/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0092, d_svhn_loss: 0.0251, d_fake_loss: 0.0825, g_loss: 1.1415\n",
            "Step [17700/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0228, d_svhn_loss: 0.0381, d_fake_loss: 0.0502, g_loss: 1.0553\n",
            "Step [17710/80000], d_real_loss: 0.1431, d_mnist_loss: 0.0336, d_svhn_loss: 0.1095, d_fake_loss: 0.0787, g_loss: 1.3842\n",
            "Step [17720/80000], d_real_loss: 0.0870, d_mnist_loss: 0.0147, d_svhn_loss: 0.0724, d_fake_loss: 0.0846, g_loss: 0.9132\n",
            "Step [17730/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0384, d_svhn_loss: 0.0468, d_fake_loss: 0.1155, g_loss: 1.0788\n",
            "Step [17740/80000], d_real_loss: 0.0943, d_mnist_loss: 0.0086, d_svhn_loss: 0.0857, d_fake_loss: 0.0472, g_loss: 1.1004\n",
            "Step [17750/80000], d_real_loss: 0.0687, d_mnist_loss: 0.0227, d_svhn_loss: 0.0460, d_fake_loss: 0.0382, g_loss: 1.0378\n",
            "Step [17760/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0154, d_svhn_loss: 0.0380, d_fake_loss: 0.0481, g_loss: 0.9958\n",
            "Step [17770/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0154, d_svhn_loss: 0.0336, d_fake_loss: 0.0712, g_loss: 0.9588\n",
            "Step [17780/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0115, d_svhn_loss: 0.0286, d_fake_loss: 0.0591, g_loss: 1.1623\n",
            "Step [17790/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0201, d_svhn_loss: 0.0516, d_fake_loss: 0.0816, g_loss: 1.3969\n",
            "Step [17800/80000], d_real_loss: 0.0845, d_mnist_loss: 0.0479, d_svhn_loss: 0.0367, d_fake_loss: 0.0862, g_loss: 1.1173\n",
            "Step [17810/80000], d_real_loss: 0.0830, d_mnist_loss: 0.0139, d_svhn_loss: 0.0692, d_fake_loss: 0.1146, g_loss: 1.1816\n",
            "Step [17820/80000], d_real_loss: 0.1265, d_mnist_loss: 0.0499, d_svhn_loss: 0.0767, d_fake_loss: 0.0841, g_loss: 1.0704\n",
            "Step [17830/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0109, d_svhn_loss: 0.0641, d_fake_loss: 0.0329, g_loss: 1.0777\n",
            "Step [17840/80000], d_real_loss: 0.0869, d_mnist_loss: 0.0419, d_svhn_loss: 0.0450, d_fake_loss: 0.0833, g_loss: 1.1605\n",
            "Step [17850/80000], d_real_loss: 0.0972, d_mnist_loss: 0.0392, d_svhn_loss: 0.0579, d_fake_loss: 0.0663, g_loss: 1.2649\n",
            "Step [17860/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0133, d_svhn_loss: 0.0368, d_fake_loss: 0.1476, g_loss: 1.0858\n",
            "Step [17870/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0144, d_svhn_loss: 0.0319, d_fake_loss: 0.0570, g_loss: 1.2555\n",
            "Step [17880/80000], d_real_loss: 0.2059, d_mnist_loss: 0.0124, d_svhn_loss: 0.1935, d_fake_loss: 0.0563, g_loss: 1.2009\n",
            "Step [17890/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0208, d_svhn_loss: 0.0503, d_fake_loss: 0.0495, g_loss: 1.1917\n",
            "Step [17900/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0096, d_svhn_loss: 0.0497, d_fake_loss: 0.1254, g_loss: 1.0930\n",
            "Step [17910/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0207, d_svhn_loss: 0.0368, d_fake_loss: 0.0552, g_loss: 1.0634\n",
            "Step [17920/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0117, d_svhn_loss: 0.0654, d_fake_loss: 0.1819, g_loss: 1.5418\n",
            "Step [17930/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0163, d_svhn_loss: 0.0628, d_fake_loss: 0.1844, g_loss: 1.5211\n",
            "Step [17940/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0223, d_svhn_loss: 0.0437, d_fake_loss: 0.0441, g_loss: 1.1012\n",
            "Step [17950/80000], d_real_loss: 0.1619, d_mnist_loss: 0.0131, d_svhn_loss: 0.1488, d_fake_loss: 0.1358, g_loss: 1.1291\n",
            "Step [17960/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0159, d_svhn_loss: 0.0520, d_fake_loss: 0.0688, g_loss: 1.2631\n",
            "Step [17970/80000], d_real_loss: 0.1246, d_mnist_loss: 0.0228, d_svhn_loss: 0.1018, d_fake_loss: 0.0613, g_loss: 1.0087\n",
            "Step [17980/80000], d_real_loss: 0.1294, d_mnist_loss: 0.0440, d_svhn_loss: 0.0854, d_fake_loss: 0.0376, g_loss: 1.0394\n",
            "Step [17990/80000], d_real_loss: 0.1567, d_mnist_loss: 0.0203, d_svhn_loss: 0.1364, d_fake_loss: 0.2207, g_loss: 1.0428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [18000/80000], d_real_loss: 0.1027, d_mnist_loss: 0.0427, d_svhn_loss: 0.0600, d_fake_loss: 0.0985, g_loss: 1.0473\n",
            "saved ./samples_fashion/sample-18000-m-s.png\n",
            "saved ./samples_fashion/sample-18000-s-m.png\n",
            "Step [18010/80000], d_real_loss: 0.2097, d_mnist_loss: 0.0508, d_svhn_loss: 0.1588, d_fake_loss: 0.1106, g_loss: 1.2157\n",
            "Step [18020/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0143, d_svhn_loss: 0.0462, d_fake_loss: 0.0895, g_loss: 1.1494\n",
            "Step [18030/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0155, d_svhn_loss: 0.0339, d_fake_loss: 0.0551, g_loss: 0.9605\n",
            "Step [18040/80000], d_real_loss: 0.1125, d_mnist_loss: 0.0768, d_svhn_loss: 0.0357, d_fake_loss: 0.0739, g_loss: 1.4443\n",
            "Step [18050/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0119, d_svhn_loss: 0.0469, d_fake_loss: 0.0382, g_loss: 1.1932\n",
            "Step [18060/80000], d_real_loss: 0.1245, d_mnist_loss: 0.0139, d_svhn_loss: 0.1106, d_fake_loss: 0.0589, g_loss: 0.9648\n",
            "Step [18070/80000], d_real_loss: 0.1039, d_mnist_loss: 0.0356, d_svhn_loss: 0.0683, d_fake_loss: 0.0869, g_loss: 1.1270\n",
            "Step [18080/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0104, d_svhn_loss: 0.0530, d_fake_loss: 0.0558, g_loss: 1.0324\n",
            "Step [18090/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0096, d_svhn_loss: 0.0588, d_fake_loss: 0.0764, g_loss: 1.1076\n",
            "Step [18100/80000], d_real_loss: 0.1113, d_mnist_loss: 0.0144, d_svhn_loss: 0.0969, d_fake_loss: 0.0655, g_loss: 1.0347\n",
            "Step [18110/80000], d_real_loss: 0.0999, d_mnist_loss: 0.0705, d_svhn_loss: 0.0295, d_fake_loss: 0.0579, g_loss: 1.4272\n",
            "Step [18120/80000], d_real_loss: 0.0981, d_mnist_loss: 0.0151, d_svhn_loss: 0.0829, d_fake_loss: 0.0510, g_loss: 1.0161\n",
            "Step [18130/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0072, d_svhn_loss: 0.0391, d_fake_loss: 0.1715, g_loss: 1.1527\n",
            "Step [18140/80000], d_real_loss: 0.1303, d_mnist_loss: 0.0297, d_svhn_loss: 0.1006, d_fake_loss: 0.0865, g_loss: 1.0614\n",
            "Step [18150/80000], d_real_loss: 0.1085, d_mnist_loss: 0.0334, d_svhn_loss: 0.0752, d_fake_loss: 0.0571, g_loss: 1.0985\n",
            "Step [18160/80000], d_real_loss: 0.1310, d_mnist_loss: 0.0875, d_svhn_loss: 0.0435, d_fake_loss: 0.0781, g_loss: 0.9433\n",
            "Step [18170/80000], d_real_loss: 0.1058, d_mnist_loss: 0.0204, d_svhn_loss: 0.0854, d_fake_loss: 0.0853, g_loss: 1.1111\n",
            "Step [18180/80000], d_real_loss: 0.1294, d_mnist_loss: 0.0257, d_svhn_loss: 0.1037, d_fake_loss: 0.1111, g_loss: 1.1014\n",
            "Step [18190/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0224, d_svhn_loss: 0.0364, d_fake_loss: 0.0590, g_loss: 1.3816\n",
            "Step [18200/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0095, d_svhn_loss: 0.0305, d_fake_loss: 0.1050, g_loss: 0.9207\n",
            "Step [18210/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0179, d_svhn_loss: 0.0292, d_fake_loss: 0.1291, g_loss: 1.4138\n",
            "Step [18220/80000], d_real_loss: 0.1494, d_mnist_loss: 0.0958, d_svhn_loss: 0.0536, d_fake_loss: 0.1878, g_loss: 1.8846\n",
            "Step [18230/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0136, d_svhn_loss: 0.0408, d_fake_loss: 0.0581, g_loss: 1.0484\n",
            "Step [18240/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0140, d_svhn_loss: 0.0764, d_fake_loss: 0.0500, g_loss: 1.0663\n",
            "Step [18250/80000], d_real_loss: 0.1602, d_mnist_loss: 0.0191, d_svhn_loss: 0.1411, d_fake_loss: 0.0931, g_loss: 1.0416\n",
            "Step [18260/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0168, d_svhn_loss: 0.0495, d_fake_loss: 0.0484, g_loss: 1.0918\n",
            "Step [18270/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0105, d_svhn_loss: 0.0619, d_fake_loss: 0.0750, g_loss: 1.2147\n",
            "Step [18280/80000], d_real_loss: 0.1739, d_mnist_loss: 0.0238, d_svhn_loss: 0.1501, d_fake_loss: 0.0731, g_loss: 1.0937\n",
            "Step [18290/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0282, d_svhn_loss: 0.0261, d_fake_loss: 0.0864, g_loss: 1.2079\n",
            "Step [18300/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0233, d_svhn_loss: 0.0383, d_fake_loss: 0.0946, g_loss: 0.8107\n",
            "Step [18310/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0286, d_svhn_loss: 0.0501, d_fake_loss: 0.0528, g_loss: 0.8465\n",
            "Step [18320/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0229, d_svhn_loss: 0.0516, d_fake_loss: 0.0485, g_loss: 1.2966\n",
            "Step [18330/80000], d_real_loss: 0.1714, d_mnist_loss: 0.0587, d_svhn_loss: 0.1127, d_fake_loss: 0.0911, g_loss: 1.1246\n",
            "Step [18340/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0126, d_svhn_loss: 0.0512, d_fake_loss: 0.0509, g_loss: 1.0974\n",
            "Step [18350/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0169, d_svhn_loss: 0.0389, d_fake_loss: 0.0915, g_loss: 1.3037\n",
            "Step [18360/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0161, d_svhn_loss: 0.0344, d_fake_loss: 0.0917, g_loss: 1.0304\n",
            "Step [18370/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0177, d_svhn_loss: 0.0293, d_fake_loss: 0.0572, g_loss: 1.1627\n",
            "Step [18380/80000], d_real_loss: 0.0908, d_mnist_loss: 0.0206, d_svhn_loss: 0.0702, d_fake_loss: 0.0758, g_loss: 0.8903\n",
            "Step [18390/80000], d_real_loss: 0.4558, d_mnist_loss: 0.0302, d_svhn_loss: 0.4257, d_fake_loss: 0.0847, g_loss: 1.1930\n",
            "Step [18400/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0104, d_svhn_loss: 0.0520, d_fake_loss: 0.0521, g_loss: 0.9624\n",
            "Step [18410/80000], d_real_loss: 0.0801, d_mnist_loss: 0.0147, d_svhn_loss: 0.0654, d_fake_loss: 0.0652, g_loss: 1.1874\n",
            "Step [18420/80000], d_real_loss: 0.0912, d_mnist_loss: 0.0282, d_svhn_loss: 0.0630, d_fake_loss: 0.1155, g_loss: 0.6321\n",
            "Step [18430/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0162, d_svhn_loss: 0.0443, d_fake_loss: 0.0793, g_loss: 1.3963\n",
            "Step [18440/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0129, d_svhn_loss: 0.0414, d_fake_loss: 0.0375, g_loss: 1.1893\n",
            "Step [18450/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0092, d_svhn_loss: 0.0430, d_fake_loss: 0.0848, g_loss: 1.3641\n",
            "Step [18460/80000], d_real_loss: 0.1166, d_mnist_loss: 0.0123, d_svhn_loss: 0.1043, d_fake_loss: 0.1716, g_loss: 0.6014\n",
            "Step [18470/80000], d_real_loss: 0.0993, d_mnist_loss: 0.0170, d_svhn_loss: 0.0823, d_fake_loss: 0.1491, g_loss: 0.9536\n",
            "Step [18480/80000], d_real_loss: 0.1102, d_mnist_loss: 0.0237, d_svhn_loss: 0.0865, d_fake_loss: 0.0435, g_loss: 1.1576\n",
            "Step [18490/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0214, d_svhn_loss: 0.0313, d_fake_loss: 0.0366, g_loss: 1.0764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [18500/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0123, d_svhn_loss: 0.0381, d_fake_loss: 0.0321, g_loss: 0.9833\n",
            "saved ./samples_fashion/sample-18500-m-s.png\n",
            "saved ./samples_fashion/sample-18500-s-m.png\n",
            "Step [18510/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0240, d_svhn_loss: 0.0584, d_fake_loss: 0.0980, g_loss: 1.3078\n",
            "Step [18520/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0109, d_svhn_loss: 0.0324, d_fake_loss: 0.0428, g_loss: 1.3355\n",
            "Step [18530/80000], d_real_loss: 0.2164, d_mnist_loss: 0.0121, d_svhn_loss: 0.2043, d_fake_loss: 0.1225, g_loss: 0.6964\n",
            "Step [18540/80000], d_real_loss: 0.0796, d_mnist_loss: 0.0225, d_svhn_loss: 0.0571, d_fake_loss: 0.2328, g_loss: 1.1087\n",
            "Step [18550/80000], d_real_loss: 0.1764, d_mnist_loss: 0.0158, d_svhn_loss: 0.1606, d_fake_loss: 0.1411, g_loss: 1.2147\n",
            "Step [18560/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0149, d_svhn_loss: 0.0383, d_fake_loss: 0.0329, g_loss: 1.0679\n",
            "Step [18570/80000], d_real_loss: 0.1330, d_mnist_loss: 0.0116, d_svhn_loss: 0.1214, d_fake_loss: 0.1821, g_loss: 1.0222\n",
            "Step [18580/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0087, d_svhn_loss: 0.0335, d_fake_loss: 0.0438, g_loss: 1.2029\n",
            "Step [18590/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0329, d_svhn_loss: 0.0442, d_fake_loss: 0.0656, g_loss: 0.8799\n",
            "Step [18600/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0300, d_svhn_loss: 0.0691, d_fake_loss: 0.0621, g_loss: 0.9821\n",
            "Step [18610/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0158, d_svhn_loss: 0.0613, d_fake_loss: 0.0398, g_loss: 1.0472\n",
            "Step [18620/80000], d_real_loss: 0.1564, d_mnist_loss: 0.1154, d_svhn_loss: 0.0410, d_fake_loss: 0.0697, g_loss: 0.9684\n",
            "Step [18630/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0185, d_svhn_loss: 0.0288, d_fake_loss: 0.0601, g_loss: 0.9646\n",
            "Step [18640/80000], d_real_loss: 0.2404, d_mnist_loss: 0.1876, d_svhn_loss: 0.0528, d_fake_loss: 0.0955, g_loss: 1.3827\n",
            "Step [18650/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0141, d_svhn_loss: 0.0356, d_fake_loss: 0.0350, g_loss: 1.1054\n",
            "Step [18660/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0159, d_svhn_loss: 0.0593, d_fake_loss: 0.0515, g_loss: 1.1423\n",
            "Step [18670/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0274, d_svhn_loss: 0.0325, d_fake_loss: 0.0803, g_loss: 1.3025\n",
            "Step [18680/80000], d_real_loss: 0.1040, d_mnist_loss: 0.0162, d_svhn_loss: 0.0877, d_fake_loss: 0.0794, g_loss: 1.1776\n",
            "Step [18690/80000], d_real_loss: 0.1180, d_mnist_loss: 0.0155, d_svhn_loss: 0.1025, d_fake_loss: 0.0625, g_loss: 0.9407\n",
            "Step [18700/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0170, d_svhn_loss: 0.0301, d_fake_loss: 0.0338, g_loss: 1.1362\n",
            "Step [18710/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0212, d_svhn_loss: 0.0583, d_fake_loss: 0.1027, g_loss: 0.9455\n",
            "Step [18720/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0166, d_svhn_loss: 0.0274, d_fake_loss: 0.0750, g_loss: 1.1076\n",
            "Step [18730/80000], d_real_loss: 0.1263, d_mnist_loss: 0.0178, d_svhn_loss: 0.1085, d_fake_loss: 0.1605, g_loss: 1.2693\n",
            "Step [18740/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0111, d_svhn_loss: 0.0634, d_fake_loss: 0.0924, g_loss: 1.1122\n",
            "Step [18750/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0129, d_svhn_loss: 0.0386, d_fake_loss: 0.0696, g_loss: 1.1750\n",
            "Step [18760/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0261, d_svhn_loss: 0.0631, d_fake_loss: 0.0798, g_loss: 1.1341\n",
            "Step [18770/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0171, d_svhn_loss: 0.0620, d_fake_loss: 0.0531, g_loss: 1.1583\n",
            "Step [18780/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0277, d_svhn_loss: 0.0249, d_fake_loss: 0.0555, g_loss: 1.2221\n",
            "Step [18790/80000], d_real_loss: 0.0937, d_mnist_loss: 0.0205, d_svhn_loss: 0.0731, d_fake_loss: 0.1048, g_loss: 1.4019\n",
            "Step [18800/80000], d_real_loss: 0.1309, d_mnist_loss: 0.0122, d_svhn_loss: 0.1188, d_fake_loss: 0.0986, g_loss: 1.1372\n",
            "Step [18810/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0154, d_svhn_loss: 0.0435, d_fake_loss: 0.1231, g_loss: 1.0660\n",
            "Step [18820/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0172, d_svhn_loss: 0.0253, d_fake_loss: 0.0978, g_loss: 1.3851\n",
            "Step [18830/80000], d_real_loss: 0.1622, d_mnist_loss: 0.0439, d_svhn_loss: 0.1184, d_fake_loss: 0.0687, g_loss: 1.1448\n",
            "Step [18840/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0087, d_svhn_loss: 0.0488, d_fake_loss: 0.0587, g_loss: 1.1832\n",
            "Step [18850/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0131, d_svhn_loss: 0.0541, d_fake_loss: 0.1243, g_loss: 1.2201\n",
            "Step [18860/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0202, d_svhn_loss: 0.0379, d_fake_loss: 0.0832, g_loss: 1.2033\n",
            "Step [18870/80000], d_real_loss: 0.0817, d_mnist_loss: 0.0173, d_svhn_loss: 0.0644, d_fake_loss: 0.0829, g_loss: 0.9951\n",
            "Step [18880/80000], d_real_loss: 0.1765, d_mnist_loss: 0.0640, d_svhn_loss: 0.1124, d_fake_loss: 0.1310, g_loss: 1.4052\n",
            "Step [18890/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0164, d_svhn_loss: 0.0356, d_fake_loss: 0.0681, g_loss: 1.1204\n",
            "Step [18900/80000], d_real_loss: 0.1130, d_mnist_loss: 0.0333, d_svhn_loss: 0.0797, d_fake_loss: 0.0618, g_loss: 1.3262\n",
            "Step [18910/80000], d_real_loss: 0.0932, d_mnist_loss: 0.0114, d_svhn_loss: 0.0818, d_fake_loss: 0.1152, g_loss: 0.9445\n",
            "Step [18920/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0371, d_svhn_loss: 0.0387, d_fake_loss: 0.2173, g_loss: 1.2682\n",
            "Step [18930/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0438, d_svhn_loss: 0.0257, d_fake_loss: 0.1077, g_loss: 1.1109\n",
            "Step [18940/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0126, d_svhn_loss: 0.0362, d_fake_loss: 0.0953, g_loss: 1.1825\n",
            "Step [18950/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0129, d_svhn_loss: 0.0661, d_fake_loss: 0.0690, g_loss: 1.3267\n",
            "Step [18960/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0331, d_svhn_loss: 0.0230, d_fake_loss: 0.1320, g_loss: 0.5338\n",
            "Step [18970/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0354, d_svhn_loss: 0.0318, d_fake_loss: 0.0621, g_loss: 1.0867\n",
            "Step [18980/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0131, d_svhn_loss: 0.0720, d_fake_loss: 0.0591, g_loss: 1.2299\n",
            "Step [18990/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0137, d_svhn_loss: 0.0478, d_fake_loss: 0.1019, g_loss: 1.1121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [19000/80000], d_real_loss: 0.1169, d_mnist_loss: 0.0446, d_svhn_loss: 0.0723, d_fake_loss: 0.1415, g_loss: 1.2240\n",
            "saved ./samples_fashion/sample-19000-m-s.png\n",
            "saved ./samples_fashion/sample-19000-s-m.png\n",
            "Step [19010/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0128, d_svhn_loss: 0.0321, d_fake_loss: 0.0751, g_loss: 1.1658\n",
            "Step [19020/80000], d_real_loss: 0.1157, d_mnist_loss: 0.0401, d_svhn_loss: 0.0755, d_fake_loss: 0.0595, g_loss: 0.8980\n",
            "Step [19030/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0114, d_svhn_loss: 0.0279, d_fake_loss: 0.0823, g_loss: 1.0823\n",
            "Step [19040/80000], d_real_loss: 0.1064, d_mnist_loss: 0.0606, d_svhn_loss: 0.0458, d_fake_loss: 0.0425, g_loss: 1.0516\n",
            "Step [19050/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0125, d_svhn_loss: 0.0313, d_fake_loss: 0.0546, g_loss: 1.0159\n",
            "Step [19060/80000], d_real_loss: 0.1885, d_mnist_loss: 0.0973, d_svhn_loss: 0.0912, d_fake_loss: 0.1880, g_loss: 1.5589\n",
            "Step [19070/80000], d_real_loss: 0.1497, d_mnist_loss: 0.0181, d_svhn_loss: 0.1316, d_fake_loss: 0.1440, g_loss: 1.0727\n",
            "Step [19080/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0384, d_svhn_loss: 0.0394, d_fake_loss: 0.1282, g_loss: 1.3476\n",
            "Step [19090/80000], d_real_loss: 0.0953, d_mnist_loss: 0.0129, d_svhn_loss: 0.0825, d_fake_loss: 0.1263, g_loss: 1.0368\n",
            "Step [19100/80000], d_real_loss: 0.1068, d_mnist_loss: 0.0617, d_svhn_loss: 0.0451, d_fake_loss: 0.0708, g_loss: 1.5515\n",
            "Step [19110/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0086, d_svhn_loss: 0.0336, d_fake_loss: 0.0402, g_loss: 0.9830\n",
            "Step [19120/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0097, d_svhn_loss: 0.0353, d_fake_loss: 0.1302, g_loss: 0.7471\n",
            "Step [19130/80000], d_real_loss: 0.0914, d_mnist_loss: 0.0485, d_svhn_loss: 0.0429, d_fake_loss: 0.0480, g_loss: 1.0230\n",
            "Step [19140/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0377, d_svhn_loss: 0.0409, d_fake_loss: 0.1029, g_loss: 1.3678\n",
            "Step [19150/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0106, d_svhn_loss: 0.0382, d_fake_loss: 0.0856, g_loss: 1.1368\n",
            "Step [19160/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0240, d_svhn_loss: 0.0485, d_fake_loss: 0.0538, g_loss: 1.0482\n",
            "Step [19170/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0598, d_svhn_loss: 0.0393, d_fake_loss: 0.1812, g_loss: 0.9293\n",
            "Step [19180/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0272, d_svhn_loss: 0.0533, d_fake_loss: 0.0723, g_loss: 1.0292\n",
            "Step [19190/80000], d_real_loss: 0.1114, d_mnist_loss: 0.0179, d_svhn_loss: 0.0935, d_fake_loss: 0.0520, g_loss: 1.0382\n",
            "Step [19200/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0333, d_svhn_loss: 0.0278, d_fake_loss: 0.0790, g_loss: 1.1148\n",
            "Step [19210/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0117, d_svhn_loss: 0.0594, d_fake_loss: 0.0642, g_loss: 1.0990\n",
            "Step [19220/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0162, d_svhn_loss: 0.0359, d_fake_loss: 0.1160, g_loss: 1.0632\n",
            "Step [19230/80000], d_real_loss: 0.0808, d_mnist_loss: 0.0201, d_svhn_loss: 0.0607, d_fake_loss: 0.0587, g_loss: 1.1136\n",
            "Step [19240/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0092, d_svhn_loss: 0.0818, d_fake_loss: 0.0540, g_loss: 1.0863\n",
            "Step [19250/80000], d_real_loss: 0.1257, d_mnist_loss: 0.0136, d_svhn_loss: 0.1122, d_fake_loss: 0.0731, g_loss: 1.2386\n",
            "Step [19260/80000], d_real_loss: 0.0759, d_mnist_loss: 0.0177, d_svhn_loss: 0.0582, d_fake_loss: 0.0610, g_loss: 1.0958\n",
            "Step [19270/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0181, d_svhn_loss: 0.0900, d_fake_loss: 0.0628, g_loss: 1.3386\n",
            "Step [19280/80000], d_real_loss: 0.1307, d_mnist_loss: 0.1011, d_svhn_loss: 0.0296, d_fake_loss: 0.0516, g_loss: 1.2786\n",
            "Step [19290/80000], d_real_loss: 0.0680, d_mnist_loss: 0.0261, d_svhn_loss: 0.0418, d_fake_loss: 0.0894, g_loss: 1.1260\n",
            "Step [19300/80000], d_real_loss: 0.1560, d_mnist_loss: 0.0199, d_svhn_loss: 0.1361, d_fake_loss: 0.0686, g_loss: 1.1865\n",
            "Step [19310/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0211, d_svhn_loss: 0.0352, d_fake_loss: 0.1347, g_loss: 1.2911\n",
            "Step [19320/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0171, d_svhn_loss: 0.0301, d_fake_loss: 0.1083, g_loss: 0.8054\n",
            "Step [19330/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0146, d_svhn_loss: 0.0584, d_fake_loss: 0.0563, g_loss: 0.9439\n",
            "Step [19340/80000], d_real_loss: 0.1447, d_mnist_loss: 0.0256, d_svhn_loss: 0.1191, d_fake_loss: 0.0991, g_loss: 0.9502\n",
            "Step [19350/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0101, d_svhn_loss: 0.0412, d_fake_loss: 0.0701, g_loss: 1.2198\n",
            "Step [19360/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0327, d_svhn_loss: 0.0412, d_fake_loss: 0.0505, g_loss: 0.9368\n",
            "Step [19370/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0381, d_svhn_loss: 0.0699, d_fake_loss: 0.0855, g_loss: 0.8927\n",
            "Step [19380/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0208, d_svhn_loss: 0.0320, d_fake_loss: 0.0471, g_loss: 1.2063\n",
            "Step [19390/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0121, d_svhn_loss: 0.0459, d_fake_loss: 0.0891, g_loss: 1.2646\n",
            "Step [19400/80000], d_real_loss: 0.0767, d_mnist_loss: 0.0164, d_svhn_loss: 0.0603, d_fake_loss: 0.0696, g_loss: 1.2606\n",
            "Step [19410/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0104, d_svhn_loss: 0.0312, d_fake_loss: 0.1598, g_loss: 1.1799\n",
            "Step [19420/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0134, d_svhn_loss: 0.0770, d_fake_loss: 0.0744, g_loss: 1.2787\n",
            "Step [19430/80000], d_real_loss: 0.1418, d_mnist_loss: 0.0134, d_svhn_loss: 0.1284, d_fake_loss: 0.0458, g_loss: 1.1062\n",
            "Step [19440/80000], d_real_loss: 0.0707, d_mnist_loss: 0.0115, d_svhn_loss: 0.0592, d_fake_loss: 0.0530, g_loss: 1.0985\n",
            "Step [19450/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0284, d_svhn_loss: 0.0382, d_fake_loss: 0.0545, g_loss: 1.0488\n",
            "Step [19460/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0307, d_svhn_loss: 0.0312, d_fake_loss: 0.0864, g_loss: 1.3116\n",
            "Step [19470/80000], d_real_loss: 0.0839, d_mnist_loss: 0.0443, d_svhn_loss: 0.0396, d_fake_loss: 0.0819, g_loss: 1.0256\n",
            "Step [19480/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0238, d_svhn_loss: 0.0404, d_fake_loss: 0.0584, g_loss: 1.1003\n",
            "Step [19490/80000], d_real_loss: 0.0994, d_mnist_loss: 0.0242, d_svhn_loss: 0.0752, d_fake_loss: 0.0484, g_loss: 1.0415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [19500/80000], d_real_loss: 0.0826, d_mnist_loss: 0.0115, d_svhn_loss: 0.0711, d_fake_loss: 0.0772, g_loss: 1.0813\n",
            "saved ./samples_fashion/sample-19500-m-s.png\n",
            "saved ./samples_fashion/sample-19500-s-m.png\n",
            "Step [19510/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0162, d_svhn_loss: 0.0317, d_fake_loss: 0.0479, g_loss: 1.2925\n",
            "Step [19520/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0227, d_svhn_loss: 0.0333, d_fake_loss: 0.0401, g_loss: 1.2956\n",
            "Step [19530/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0392, d_svhn_loss: 0.0410, d_fake_loss: 0.0929, g_loss: 1.1594\n",
            "Step [19540/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0398, d_svhn_loss: 0.0313, d_fake_loss: 0.0469, g_loss: 1.1364\n",
            "Step [19550/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0099, d_svhn_loss: 0.0313, d_fake_loss: 0.0768, g_loss: 1.1251\n",
            "Step [19560/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0355, d_svhn_loss: 0.0433, d_fake_loss: 0.0588, g_loss: 1.0898\n",
            "Step [19570/80000], d_real_loss: 0.2408, d_mnist_loss: 0.0105, d_svhn_loss: 0.2302, d_fake_loss: 0.0635, g_loss: 1.2583\n",
            "Step [19580/80000], d_real_loss: 0.0644, d_mnist_loss: 0.0248, d_svhn_loss: 0.0396, d_fake_loss: 0.0470, g_loss: 1.2416\n",
            "Step [19590/80000], d_real_loss: 0.1983, d_mnist_loss: 0.0801, d_svhn_loss: 0.1182, d_fake_loss: 0.2346, g_loss: 1.2262\n",
            "Step [19600/80000], d_real_loss: 0.1353, d_mnist_loss: 0.0392, d_svhn_loss: 0.0961, d_fake_loss: 0.0797, g_loss: 1.1979\n",
            "Step [19610/80000], d_real_loss: 0.1627, d_mnist_loss: 0.0235, d_svhn_loss: 0.1392, d_fake_loss: 0.1301, g_loss: 1.0766\n",
            "Step [19620/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0133, d_svhn_loss: 0.0705, d_fake_loss: 0.0476, g_loss: 1.0163\n",
            "Step [19630/80000], d_real_loss: 0.1207, d_mnist_loss: 0.0348, d_svhn_loss: 0.0858, d_fake_loss: 0.1095, g_loss: 1.2715\n",
            "Step [19640/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0212, d_svhn_loss: 0.0402, d_fake_loss: 0.0759, g_loss: 0.9769\n",
            "Step [19650/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0143, d_svhn_loss: 0.0433, d_fake_loss: 0.1185, g_loss: 1.0204\n",
            "Step [19660/80000], d_real_loss: 0.1377, d_mnist_loss: 0.0139, d_svhn_loss: 0.1239, d_fake_loss: 0.1239, g_loss: 1.0432\n",
            "Step [19670/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0133, d_svhn_loss: 0.0365, d_fake_loss: 0.0387, g_loss: 1.0145\n",
            "Step [19680/80000], d_real_loss: 0.0945, d_mnist_loss: 0.0202, d_svhn_loss: 0.0743, d_fake_loss: 0.0941, g_loss: 1.2597\n",
            "Step [19690/80000], d_real_loss: 0.0942, d_mnist_loss: 0.0143, d_svhn_loss: 0.0799, d_fake_loss: 0.0467, g_loss: 1.1088\n",
            "Step [19700/80000], d_real_loss: 0.1075, d_mnist_loss: 0.0134, d_svhn_loss: 0.0941, d_fake_loss: 0.0533, g_loss: 1.3083\n",
            "Step [19710/80000], d_real_loss: 0.0824, d_mnist_loss: 0.0114, d_svhn_loss: 0.0711, d_fake_loss: 0.0538, g_loss: 1.1252\n",
            "Step [19720/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0235, d_svhn_loss: 0.0268, d_fake_loss: 0.0891, g_loss: 1.3792\n",
            "Step [19730/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0138, d_svhn_loss: 0.0384, d_fake_loss: 0.0332, g_loss: 1.0986\n",
            "Step [19740/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0249, d_svhn_loss: 0.0365, d_fake_loss: 0.0478, g_loss: 1.1078\n",
            "Step [19750/80000], d_real_loss: 0.1352, d_mnist_loss: 0.0456, d_svhn_loss: 0.0896, d_fake_loss: 0.0631, g_loss: 1.2910\n",
            "Step [19760/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0194, d_svhn_loss: 0.0392, d_fake_loss: 0.0868, g_loss: 1.0131\n",
            "Step [19770/80000], d_real_loss: 0.1946, d_mnist_loss: 0.0214, d_svhn_loss: 0.1731, d_fake_loss: 0.0989, g_loss: 1.1686\n",
            "Step [19780/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0062, d_svhn_loss: 0.0466, d_fake_loss: 0.1563, g_loss: 1.0823\n",
            "Step [19790/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0265, d_svhn_loss: 0.0338, d_fake_loss: 0.0341, g_loss: 0.9728\n",
            "Step [19800/80000], d_real_loss: 0.0869, d_mnist_loss: 0.0393, d_svhn_loss: 0.0475, d_fake_loss: 0.0699, g_loss: 1.3356\n",
            "Step [19810/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0153, d_svhn_loss: 0.0501, d_fake_loss: 0.0400, g_loss: 1.2251\n",
            "Step [19820/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0158, d_svhn_loss: 0.0287, d_fake_loss: 0.0416, g_loss: 1.1885\n",
            "Step [19830/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0292, d_svhn_loss: 0.0445, d_fake_loss: 0.0304, g_loss: 1.1122\n",
            "Step [19840/80000], d_real_loss: 0.1138, d_mnist_loss: 0.0950, d_svhn_loss: 0.0189, d_fake_loss: 0.0459, g_loss: 1.1142\n",
            "Step [19850/80000], d_real_loss: 0.1691, d_mnist_loss: 0.0573, d_svhn_loss: 0.1118, d_fake_loss: 0.0601, g_loss: 1.2511\n",
            "Step [19860/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0155, d_svhn_loss: 0.0476, d_fake_loss: 0.0356, g_loss: 1.0405\n",
            "Step [19870/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0292, d_svhn_loss: 0.0323, d_fake_loss: 0.0338, g_loss: 1.2510\n",
            "Step [19880/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0132, d_svhn_loss: 0.0431, d_fake_loss: 0.0534, g_loss: 1.1621\n",
            "Step [19890/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0209, d_svhn_loss: 0.0425, d_fake_loss: 0.1298, g_loss: 1.0592\n",
            "Step [19900/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0309, d_svhn_loss: 0.0272, d_fake_loss: 0.0453, g_loss: 1.3109\n",
            "Step [19910/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0254, d_svhn_loss: 0.0516, d_fake_loss: 0.0409, g_loss: 1.1109\n",
            "Step [19920/80000], d_real_loss: 0.1039, d_mnist_loss: 0.0365, d_svhn_loss: 0.0674, d_fake_loss: 0.0691, g_loss: 0.9604\n",
            "Step [19930/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0134, d_svhn_loss: 0.0362, d_fake_loss: 0.0497, g_loss: 0.9549\n",
            "Step [19940/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0138, d_svhn_loss: 0.0459, d_fake_loss: 0.0618, g_loss: 1.1848\n",
            "Step [19950/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0088, d_svhn_loss: 0.0445, d_fake_loss: 0.0550, g_loss: 1.1949\n",
            "Step [19960/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0096, d_svhn_loss: 0.0687, d_fake_loss: 0.0639, g_loss: 1.0425\n",
            "Step [19970/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0289, d_svhn_loss: 0.0363, d_fake_loss: 0.0390, g_loss: 1.0000\n",
            "Step [19980/80000], d_real_loss: 0.0751, d_mnist_loss: 0.0379, d_svhn_loss: 0.0373, d_fake_loss: 0.0932, g_loss: 1.1495\n",
            "Step [19990/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0130, d_svhn_loss: 0.0627, d_fake_loss: 0.0481, g_loss: 1.0445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999996423721313, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [20000/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0298, d_svhn_loss: 0.0453, d_fake_loss: 0.1231, g_loss: 1.3655\n",
            "saved ./samples_fashion/sample-20000-m-s.png\n",
            "saved ./samples_fashion/sample-20000-s-m.png\n",
            "Step [20010/80000], d_real_loss: 0.2307, d_mnist_loss: 0.0148, d_svhn_loss: 0.2159, d_fake_loss: 0.0453, g_loss: 1.1379\n",
            "Step [20020/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0105, d_svhn_loss: 0.0584, d_fake_loss: 0.0363, g_loss: 1.0993\n",
            "Step [20030/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0117, d_svhn_loss: 0.0631, d_fake_loss: 0.1207, g_loss: 1.2361\n",
            "Step [20040/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0131, d_svhn_loss: 0.0483, d_fake_loss: 0.0560, g_loss: 1.1649\n",
            "Step [20050/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0232, d_svhn_loss: 0.0605, d_fake_loss: 0.1650, g_loss: 1.0968\n",
            "Step [20060/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0178, d_svhn_loss: 0.0534, d_fake_loss: 0.0426, g_loss: 1.1896\n",
            "Step [20070/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0369, d_svhn_loss: 0.0444, d_fake_loss: 0.1479, g_loss: 1.2069\n",
            "Step [20080/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0102, d_svhn_loss: 0.0416, d_fake_loss: 0.0393, g_loss: 1.1418\n",
            "Step [20090/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0108, d_svhn_loss: 0.0511, d_fake_loss: 0.0421, g_loss: 1.0071\n",
            "Step [20100/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0124, d_svhn_loss: 0.0385, d_fake_loss: 0.0380, g_loss: 1.1723\n",
            "Step [20110/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0299, d_svhn_loss: 0.0244, d_fake_loss: 0.0411, g_loss: 1.0296\n",
            "Step [20120/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0200, d_svhn_loss: 0.0279, d_fake_loss: 0.0628, g_loss: 1.3248\n",
            "Step [20130/80000], d_real_loss: 0.2997, d_mnist_loss: 0.2239, d_svhn_loss: 0.0757, d_fake_loss: 0.1445, g_loss: 1.3248\n",
            "Step [20140/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0235, d_svhn_loss: 0.0223, d_fake_loss: 0.0487, g_loss: 1.1475\n",
            "Step [20150/80000], d_real_loss: 0.1047, d_mnist_loss: 0.0137, d_svhn_loss: 0.0910, d_fake_loss: 0.1218, g_loss: 1.0528\n",
            "Step [20160/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0473, d_svhn_loss: 0.0375, d_fake_loss: 0.0822, g_loss: 1.1448\n",
            "Step [20170/80000], d_real_loss: 0.1198, d_mnist_loss: 0.0132, d_svhn_loss: 0.1066, d_fake_loss: 0.1276, g_loss: 1.3178\n",
            "Step [20180/80000], d_real_loss: 0.0839, d_mnist_loss: 0.0235, d_svhn_loss: 0.0605, d_fake_loss: 0.0723, g_loss: 1.3057\n",
            "Step [20190/80000], d_real_loss: 0.0982, d_mnist_loss: 0.0215, d_svhn_loss: 0.0767, d_fake_loss: 0.0971, g_loss: 1.1355\n",
            "Step [20200/80000], d_real_loss: 0.0755, d_mnist_loss: 0.0149, d_svhn_loss: 0.0606, d_fake_loss: 0.0392, g_loss: 1.0293\n",
            "Step [20210/80000], d_real_loss: 0.1169, d_mnist_loss: 0.0172, d_svhn_loss: 0.0998, d_fake_loss: 0.1298, g_loss: 0.9747\n",
            "Step [20220/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0144, d_svhn_loss: 0.0372, d_fake_loss: 0.0406, g_loss: 1.2193\n",
            "Step [20230/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0254, d_svhn_loss: 0.0346, d_fake_loss: 0.0473, g_loss: 1.1395\n",
            "Step [20240/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0087, d_svhn_loss: 0.0463, d_fake_loss: 0.0315, g_loss: 1.0911\n",
            "Step [20250/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0125, d_svhn_loss: 0.0354, d_fake_loss: 0.1007, g_loss: 0.7713\n",
            "Step [20260/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0239, d_svhn_loss: 0.0426, d_fake_loss: 0.0556, g_loss: 1.2892\n",
            "Step [20270/80000], d_real_loss: 0.1035, d_mnist_loss: 0.0265, d_svhn_loss: 0.0770, d_fake_loss: 0.1103, g_loss: 1.2451\n",
            "Step [20280/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0184, d_svhn_loss: 0.0522, d_fake_loss: 0.0475, g_loss: 1.3111\n",
            "Step [20290/80000], d_real_loss: 0.1061, d_mnist_loss: 0.0152, d_svhn_loss: 0.0909, d_fake_loss: 0.1022, g_loss: 0.8505\n",
            "Step [20300/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0160, d_svhn_loss: 0.0370, d_fake_loss: 0.1055, g_loss: 1.3131\n",
            "Step [20310/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0261, d_svhn_loss: 0.0445, d_fake_loss: 0.0473, g_loss: 1.2361\n",
            "Step [20320/80000], d_real_loss: 0.1457, d_mnist_loss: 0.0127, d_svhn_loss: 0.1330, d_fake_loss: 0.1623, g_loss: 0.9244\n",
            "Step [20330/80000], d_real_loss: 0.0988, d_mnist_loss: 0.0336, d_svhn_loss: 0.0652, d_fake_loss: 0.0506, g_loss: 1.0481\n",
            "Step [20340/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0153, d_svhn_loss: 0.0222, d_fake_loss: 0.0627, g_loss: 1.1966\n",
            "Step [20350/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0093, d_svhn_loss: 0.0424, d_fake_loss: 0.0374, g_loss: 1.0303\n",
            "Step [20360/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0155, d_svhn_loss: 0.0492, d_fake_loss: 0.0503, g_loss: 1.1832\n",
            "Step [20370/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0084, d_svhn_loss: 0.0504, d_fake_loss: 0.0542, g_loss: 1.1311\n",
            "Step [20380/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0378, d_svhn_loss: 0.0613, d_fake_loss: 0.1195, g_loss: 1.1997\n",
            "Step [20390/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0230, d_svhn_loss: 0.0357, d_fake_loss: 0.0799, g_loss: 0.9890\n",
            "Step [20400/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0160, d_svhn_loss: 0.0459, d_fake_loss: 0.0674, g_loss: 1.2924\n",
            "Step [20410/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0079, d_svhn_loss: 0.0348, d_fake_loss: 0.0308, g_loss: 1.1534\n",
            "Step [20420/80000], d_real_loss: 0.0760, d_mnist_loss: 0.0102, d_svhn_loss: 0.0658, d_fake_loss: 0.1092, g_loss: 1.1790\n",
            "Step [20430/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0098, d_svhn_loss: 0.0421, d_fake_loss: 0.0406, g_loss: 1.2152\n",
            "Step [20440/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0128, d_svhn_loss: 0.0654, d_fake_loss: 0.0394, g_loss: 1.1826\n",
            "Step [20450/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0234, d_svhn_loss: 0.0261, d_fake_loss: 0.0377, g_loss: 1.0717\n",
            "Step [20460/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0149, d_svhn_loss: 0.0337, d_fake_loss: 0.0594, g_loss: 1.3375\n",
            "Step [20470/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0109, d_svhn_loss: 0.0304, d_fake_loss: 0.0565, g_loss: 1.0665\n",
            "Step [20480/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0192, d_svhn_loss: 0.0536, d_fake_loss: 0.0559, g_loss: 1.1376\n",
            "Step [20490/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0488, d_svhn_loss: 0.0254, d_fake_loss: 0.0916, g_loss: 1.0602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.999988317489624, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [20500/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0176, d_svhn_loss: 0.0253, d_fake_loss: 0.0573, g_loss: 1.1563\n",
            "saved ./samples_fashion/sample-20500-m-s.png\n",
            "saved ./samples_fashion/sample-20500-s-m.png\n",
            "Step [20510/80000], d_real_loss: 0.1271, d_mnist_loss: 0.0656, d_svhn_loss: 0.0616, d_fake_loss: 0.0381, g_loss: 1.2432\n",
            "Step [20520/80000], d_real_loss: 0.0726, d_mnist_loss: 0.0309, d_svhn_loss: 0.0417, d_fake_loss: 0.1494, g_loss: 0.8475\n",
            "Step [20530/80000], d_real_loss: 0.1142, d_mnist_loss: 0.0108, d_svhn_loss: 0.1034, d_fake_loss: 0.1743, g_loss: 1.4434\n",
            "Step [20540/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0292, d_svhn_loss: 0.0235, d_fake_loss: 0.0552, g_loss: 0.9957\n",
            "Step [20550/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0066, d_svhn_loss: 0.0707, d_fake_loss: 0.0978, g_loss: 0.9913\n",
            "Step [20560/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0209, d_svhn_loss: 0.0555, d_fake_loss: 0.0369, g_loss: 1.1389\n",
            "Step [20570/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0194, d_svhn_loss: 0.0294, d_fake_loss: 0.0881, g_loss: 1.3581\n",
            "Step [20580/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0113, d_svhn_loss: 0.0706, d_fake_loss: 0.1708, g_loss: 1.4386\n",
            "Step [20590/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0166, d_svhn_loss: 0.0425, d_fake_loss: 0.0845, g_loss: 1.0336\n",
            "Step [20600/80000], d_real_loss: 0.2566, d_mnist_loss: 0.1320, d_svhn_loss: 0.1246, d_fake_loss: 0.1030, g_loss: 1.1420\n",
            "Step [20610/80000], d_real_loss: 0.0644, d_mnist_loss: 0.0126, d_svhn_loss: 0.0518, d_fake_loss: 0.0516, g_loss: 1.0678\n",
            "Step [20620/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0126, d_svhn_loss: 0.0318, d_fake_loss: 0.1195, g_loss: 0.9852\n",
            "Step [20630/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0204, d_svhn_loss: 0.0367, d_fake_loss: 0.0967, g_loss: 1.2680\n",
            "Step [20640/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0155, d_svhn_loss: 0.0555, d_fake_loss: 0.0811, g_loss: 0.8287\n",
            "Step [20650/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0115, d_svhn_loss: 0.0250, d_fake_loss: 0.0632, g_loss: 1.1461\n",
            "Step [20660/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0111, d_svhn_loss: 0.0444, d_fake_loss: 0.0553, g_loss: 1.2239\n",
            "Step [20670/80000], d_real_loss: 0.1017, d_mnist_loss: 0.0161, d_svhn_loss: 0.0856, d_fake_loss: 0.0997, g_loss: 1.1879\n",
            "Step [20680/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0177, d_svhn_loss: 0.0472, d_fake_loss: 0.0403, g_loss: 1.1024\n",
            "Step [20690/80000], d_real_loss: 0.0963, d_mnist_loss: 0.0551, d_svhn_loss: 0.0412, d_fake_loss: 0.0514, g_loss: 0.9215\n",
            "Step [20700/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0145, d_svhn_loss: 0.0437, d_fake_loss: 0.0335, g_loss: 1.1231\n",
            "Step [20710/80000], d_real_loss: 0.1130, d_mnist_loss: 0.0426, d_svhn_loss: 0.0704, d_fake_loss: 0.0575, g_loss: 1.0854\n",
            "Step [20720/80000], d_real_loss: 0.0835, d_mnist_loss: 0.0156, d_svhn_loss: 0.0679, d_fake_loss: 0.1228, g_loss: 0.9087\n",
            "Step [20730/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0115, d_svhn_loss: 0.0399, d_fake_loss: 0.0400, g_loss: 1.2067\n",
            "Step [20740/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0141, d_svhn_loss: 0.0328, d_fake_loss: 0.0331, g_loss: 1.1200\n",
            "Step [20750/80000], d_real_loss: 0.1103, d_mnist_loss: 0.0282, d_svhn_loss: 0.0821, d_fake_loss: 0.0334, g_loss: 1.1323\n",
            "Step [20760/80000], d_real_loss: 0.1586, d_mnist_loss: 0.0563, d_svhn_loss: 0.1023, d_fake_loss: 0.0852, g_loss: 1.0859\n",
            "Step [20770/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0138, d_svhn_loss: 0.0355, d_fake_loss: 0.0538, g_loss: 1.0899\n",
            "Step [20780/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0123, d_svhn_loss: 0.0432, d_fake_loss: 0.0356, g_loss: 1.2084\n",
            "Step [20790/80000], d_real_loss: 0.0966, d_mnist_loss: 0.0220, d_svhn_loss: 0.0746, d_fake_loss: 0.1002, g_loss: 0.8878\n",
            "Step [20800/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0162, d_svhn_loss: 0.0681, d_fake_loss: 0.0431, g_loss: 1.1785\n",
            "Step [20810/80000], d_real_loss: 0.1206, d_mnist_loss: 0.0267, d_svhn_loss: 0.0939, d_fake_loss: 0.1266, g_loss: 1.1098\n",
            "Step [20820/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0151, d_svhn_loss: 0.0929, d_fake_loss: 0.0641, g_loss: 1.2467\n",
            "Step [20830/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0229, d_svhn_loss: 0.0346, d_fake_loss: 0.0587, g_loss: 1.0703\n",
            "Step [20840/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0091, d_svhn_loss: 0.0332, d_fake_loss: 0.0573, g_loss: 1.0851\n",
            "Step [20850/80000], d_real_loss: 0.1900, d_mnist_loss: 0.0325, d_svhn_loss: 0.1575, d_fake_loss: 0.1864, g_loss: 1.5091\n",
            "Step [20860/80000], d_real_loss: 0.1386, d_mnist_loss: 0.0158, d_svhn_loss: 0.1228, d_fake_loss: 0.0568, g_loss: 1.0957\n",
            "Step [20870/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0120, d_svhn_loss: 0.0353, d_fake_loss: 0.0363, g_loss: 1.1192\n",
            "Step [20880/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0340, d_svhn_loss: 0.0480, d_fake_loss: 0.0653, g_loss: 1.2627\n",
            "Step [20890/80000], d_real_loss: 0.1698, d_mnist_loss: 0.0126, d_svhn_loss: 0.1572, d_fake_loss: 0.1651, g_loss: 1.2889\n",
            "Step [20900/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0345, d_svhn_loss: 0.0304, d_fake_loss: 0.1492, g_loss: 1.2059\n",
            "Step [20910/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0179, d_svhn_loss: 0.0345, d_fake_loss: 0.0323, g_loss: 1.1326\n",
            "Step [20920/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0205, d_svhn_loss: 0.0435, d_fake_loss: 0.0970, g_loss: 1.3684\n",
            "Step [20930/80000], d_real_loss: 0.0744, d_mnist_loss: 0.0181, d_svhn_loss: 0.0563, d_fake_loss: 0.0625, g_loss: 1.1332\n",
            "Step [20940/80000], d_real_loss: 0.1278, d_mnist_loss: 0.0265, d_svhn_loss: 0.1013, d_fake_loss: 0.2014, g_loss: 0.9730\n",
            "Step [20950/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0207, d_svhn_loss: 0.0341, d_fake_loss: 0.0849, g_loss: 1.1000\n",
            "Step [20960/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0239, d_svhn_loss: 0.0342, d_fake_loss: 0.0607, g_loss: 1.2103\n",
            "Step [20970/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0129, d_svhn_loss: 0.0747, d_fake_loss: 0.0749, g_loss: 1.2621\n",
            "Step [20980/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0136, d_svhn_loss: 0.0318, d_fake_loss: 0.2061, g_loss: 1.6914\n",
            "Step [20990/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0170, d_svhn_loss: 0.0376, d_fake_loss: 0.0604, g_loss: 1.3013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999995827674866, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [21000/80000], d_real_loss: 0.1831, d_mnist_loss: 0.0267, d_svhn_loss: 0.1564, d_fake_loss: 0.0531, g_loss: 1.1229\n",
            "saved ./samples_fashion/sample-21000-m-s.png\n",
            "saved ./samples_fashion/sample-21000-s-m.png\n",
            "Step [21010/80000], d_real_loss: 0.0822, d_mnist_loss: 0.0173, d_svhn_loss: 0.0649, d_fake_loss: 0.2006, g_loss: 1.2681\n",
            "Step [21020/80000], d_real_loss: 0.1696, d_mnist_loss: 0.0101, d_svhn_loss: 0.1596, d_fake_loss: 0.0887, g_loss: 1.1185\n",
            "Step [21030/80000], d_real_loss: 0.1202, d_mnist_loss: 0.0097, d_svhn_loss: 0.1105, d_fake_loss: 0.1752, g_loss: 1.1534\n",
            "Step [21040/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0196, d_svhn_loss: 0.0314, d_fake_loss: 0.0663, g_loss: 1.0053\n",
            "Step [21050/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0126, d_svhn_loss: 0.0596, d_fake_loss: 0.1157, g_loss: 0.8918\n",
            "Step [21060/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0220, d_svhn_loss: 0.0421, d_fake_loss: 0.0745, g_loss: 0.9870\n",
            "Step [21070/80000], d_real_loss: 0.0980, d_mnist_loss: 0.0348, d_svhn_loss: 0.0631, d_fake_loss: 0.0500, g_loss: 0.9953\n",
            "Step [21080/80000], d_real_loss: 0.0863, d_mnist_loss: 0.0560, d_svhn_loss: 0.0303, d_fake_loss: 0.0622, g_loss: 1.0141\n",
            "Step [21090/80000], d_real_loss: 0.1037, d_mnist_loss: 0.0454, d_svhn_loss: 0.0583, d_fake_loss: 0.0960, g_loss: 1.4206\n",
            "Step [21100/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0199, d_svhn_loss: 0.0287, d_fake_loss: 0.0571, g_loss: 1.2154\n",
            "Step [21110/80000], d_real_loss: 0.1020, d_mnist_loss: 0.0110, d_svhn_loss: 0.0911, d_fake_loss: 0.0361, g_loss: 1.2619\n",
            "Step [21120/80000], d_real_loss: 0.1867, d_mnist_loss: 0.1148, d_svhn_loss: 0.0718, d_fake_loss: 0.1125, g_loss: 1.6462\n",
            "Step [21130/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0113, d_svhn_loss: 0.0175, d_fake_loss: 0.0545, g_loss: 1.1996\n",
            "Step [21140/80000], d_real_loss: 0.0701, d_mnist_loss: 0.0202, d_svhn_loss: 0.0499, d_fake_loss: 0.0429, g_loss: 1.1251\n",
            "Step [21150/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0176, d_svhn_loss: 0.0405, d_fake_loss: 0.1169, g_loss: 1.0672\n",
            "Step [21160/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0212, d_svhn_loss: 0.0486, d_fake_loss: 0.0836, g_loss: 0.9893\n",
            "Step [21170/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0128, d_svhn_loss: 0.0226, d_fake_loss: 0.0734, g_loss: 1.3419\n",
            "Step [21180/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0143, d_svhn_loss: 0.0317, d_fake_loss: 0.0595, g_loss: 1.0182\n",
            "Step [21190/80000], d_real_loss: 0.2224, d_mnist_loss: 0.0210, d_svhn_loss: 0.2013, d_fake_loss: 0.1731, g_loss: 1.1747\n",
            "Step [21200/80000], d_real_loss: 0.1266, d_mnist_loss: 0.0139, d_svhn_loss: 0.1127, d_fake_loss: 0.1120, g_loss: 1.1297\n",
            "Step [21210/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0143, d_svhn_loss: 0.0288, d_fake_loss: 0.0797, g_loss: 1.0562\n",
            "Step [21220/80000], d_real_loss: 0.0775, d_mnist_loss: 0.0488, d_svhn_loss: 0.0287, d_fake_loss: 0.0402, g_loss: 1.0939\n",
            "Step [21230/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0150, d_svhn_loss: 0.0278, d_fake_loss: 0.0741, g_loss: 1.2085\n",
            "Step [21240/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0080, d_svhn_loss: 0.0440, d_fake_loss: 0.1629, g_loss: 1.0992\n",
            "Step [21250/80000], d_real_loss: 0.1081, d_mnist_loss: 0.0113, d_svhn_loss: 0.0969, d_fake_loss: 0.0615, g_loss: 1.1997\n",
            "Step [21260/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0138, d_svhn_loss: 0.0555, d_fake_loss: 0.0500, g_loss: 1.0663\n",
            "Step [21270/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0206, d_svhn_loss: 0.0237, d_fake_loss: 0.0773, g_loss: 1.3935\n",
            "Step [21280/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0169, d_svhn_loss: 0.0373, d_fake_loss: 0.1107, g_loss: 1.2913\n",
            "Step [21290/80000], d_real_loss: 0.1205, d_mnist_loss: 0.0076, d_svhn_loss: 0.1129, d_fake_loss: 0.1186, g_loss: 1.1412\n",
            "Step [21300/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0142, d_svhn_loss: 0.0477, d_fake_loss: 0.0496, g_loss: 1.0030\n",
            "Step [21310/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0095, d_svhn_loss: 0.0391, d_fake_loss: 0.0269, g_loss: 1.3530\n",
            "Step [21320/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0152, d_svhn_loss: 0.0476, d_fake_loss: 0.0571, g_loss: 0.8612\n",
            "Step [21330/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0119, d_svhn_loss: 0.0297, d_fake_loss: 0.0420, g_loss: 0.9080\n",
            "Step [21340/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0147, d_svhn_loss: 0.0593, d_fake_loss: 0.1082, g_loss: 1.3117\n",
            "Step [21350/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0119, d_svhn_loss: 0.0416, d_fake_loss: 0.0315, g_loss: 1.1484\n",
            "Step [21360/80000], d_real_loss: 0.1540, d_mnist_loss: 0.0278, d_svhn_loss: 0.1262, d_fake_loss: 0.0740, g_loss: 1.0689\n",
            "Step [21370/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0175, d_svhn_loss: 0.0309, d_fake_loss: 0.0748, g_loss: 1.2590\n",
            "Step [21380/80000], d_real_loss: 0.1110, d_mnist_loss: 0.0126, d_svhn_loss: 0.0984, d_fake_loss: 0.0982, g_loss: 1.3562\n",
            "Step [21390/80000], d_real_loss: 0.1657, d_mnist_loss: 0.0070, d_svhn_loss: 0.1587, d_fake_loss: 0.0517, g_loss: 1.0703\n",
            "Step [21400/80000], d_real_loss: 0.2360, d_mnist_loss: 0.1744, d_svhn_loss: 0.0616, d_fake_loss: 0.0666, g_loss: 1.2572\n",
            "Step [21410/80000], d_real_loss: 0.0993, d_mnist_loss: 0.0241, d_svhn_loss: 0.0751, d_fake_loss: 0.0456, g_loss: 0.9815\n",
            "Step [21420/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0143, d_svhn_loss: 0.0392, d_fake_loss: 0.1212, g_loss: 0.9092\n",
            "Step [21430/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0175, d_svhn_loss: 0.0225, d_fake_loss: 0.0583, g_loss: 1.0594\n",
            "Step [21440/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0171, d_svhn_loss: 0.0441, d_fake_loss: 0.0682, g_loss: 1.2922\n",
            "Step [21450/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0147, d_svhn_loss: 0.0396, d_fake_loss: 0.0466, g_loss: 1.1623\n",
            "Step [21460/80000], d_real_loss: 0.0769, d_mnist_loss: 0.0147, d_svhn_loss: 0.0622, d_fake_loss: 0.0822, g_loss: 1.0152\n",
            "Step [21470/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0445, d_svhn_loss: 0.0339, d_fake_loss: 0.0577, g_loss: 1.0721\n",
            "Step [21480/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0259, d_svhn_loss: 0.0315, d_fake_loss: 0.0620, g_loss: 0.9518\n",
            "Step [21490/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0111, d_svhn_loss: 0.0412, d_fake_loss: 0.0775, g_loss: 1.1802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [21500/80000], d_real_loss: 0.0781, d_mnist_loss: 0.0216, d_svhn_loss: 0.0565, d_fake_loss: 0.0566, g_loss: 1.0902\n",
            "saved ./samples_fashion/sample-21500-m-s.png\n",
            "saved ./samples_fashion/sample-21500-s-m.png\n",
            "Step [21510/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0371, d_svhn_loss: 0.0369, d_fake_loss: 0.0907, g_loss: 1.1496\n",
            "Step [21520/80000], d_real_loss: 0.1432, d_mnist_loss: 0.0213, d_svhn_loss: 0.1220, d_fake_loss: 0.1168, g_loss: 1.1502\n",
            "Step [21530/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0266, d_svhn_loss: 0.0334, d_fake_loss: 0.0522, g_loss: 1.1513\n",
            "Step [21540/80000], d_real_loss: 0.1879, d_mnist_loss: 0.0927, d_svhn_loss: 0.0952, d_fake_loss: 0.0802, g_loss: 1.3806\n",
            "Step [21550/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0329, d_svhn_loss: 0.0514, d_fake_loss: 0.0465, g_loss: 1.1725\n",
            "Step [21560/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0244, d_svhn_loss: 0.0282, d_fake_loss: 0.0924, g_loss: 1.1335\n",
            "Step [21570/80000], d_real_loss: 0.0704, d_mnist_loss: 0.0316, d_svhn_loss: 0.0388, d_fake_loss: 0.1183, g_loss: 1.8746\n",
            "Step [21580/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0145, d_svhn_loss: 0.0453, d_fake_loss: 0.0394, g_loss: 1.1848\n",
            "Step [21590/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0120, d_svhn_loss: 0.0285, d_fake_loss: 0.0491, g_loss: 1.1267\n",
            "Step [21600/80000], d_real_loss: 0.0856, d_mnist_loss: 0.0162, d_svhn_loss: 0.0695, d_fake_loss: 0.1610, g_loss: 0.8896\n",
            "Step [21610/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0147, d_svhn_loss: 0.0362, d_fake_loss: 0.0601, g_loss: 0.9713\n",
            "Step [21620/80000], d_real_loss: 0.0872, d_mnist_loss: 0.0126, d_svhn_loss: 0.0746, d_fake_loss: 0.0742, g_loss: 1.2561\n",
            "Step [21630/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0227, d_svhn_loss: 0.0353, d_fake_loss: 0.0616, g_loss: 1.1236\n",
            "Step [21640/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0481, d_svhn_loss: 0.0419, d_fake_loss: 0.0971, g_loss: 0.9679\n",
            "Step [21650/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0097, d_svhn_loss: 0.0502, d_fake_loss: 0.0457, g_loss: 1.0935\n",
            "Step [21660/80000], d_real_loss: 0.0931, d_mnist_loss: 0.0124, d_svhn_loss: 0.0806, d_fake_loss: 0.1759, g_loss: 1.1915\n",
            "Step [21670/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0172, d_svhn_loss: 0.0317, d_fake_loss: 0.0472, g_loss: 0.8919\n",
            "Step [21680/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0145, d_svhn_loss: 0.0296, d_fake_loss: 0.0345, g_loss: 1.0278\n",
            "Step [21690/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0133, d_svhn_loss: 0.0258, d_fake_loss: 0.0512, g_loss: 1.2375\n",
            "Step [21700/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0140, d_svhn_loss: 0.0281, d_fake_loss: 0.0852, g_loss: 1.3875\n",
            "Step [21710/80000], d_real_loss: 0.1337, d_mnist_loss: 0.0106, d_svhn_loss: 0.1231, d_fake_loss: 0.1513, g_loss: 0.8902\n",
            "Step [21720/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0162, d_svhn_loss: 0.0541, d_fake_loss: 0.1255, g_loss: 1.4685\n",
            "Step [21730/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0276, d_svhn_loss: 0.0461, d_fake_loss: 0.0440, g_loss: 1.1645\n",
            "Step [21740/80000], d_real_loss: 0.1377, d_mnist_loss: 0.0094, d_svhn_loss: 0.1283, d_fake_loss: 0.0814, g_loss: 1.1645\n",
            "Step [21750/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0128, d_svhn_loss: 0.0457, d_fake_loss: 0.0609, g_loss: 1.2881\n",
            "Step [21760/80000], d_real_loss: 0.1159, d_mnist_loss: 0.0722, d_svhn_loss: 0.0438, d_fake_loss: 0.0454, g_loss: 1.1813\n",
            "Step [21770/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0113, d_svhn_loss: 0.0732, d_fake_loss: 0.1221, g_loss: 1.2629\n",
            "Step [21780/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0103, d_svhn_loss: 0.0346, d_fake_loss: 0.0336, g_loss: 1.1169\n",
            "Step [21790/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0166, d_svhn_loss: 0.0348, d_fake_loss: 0.0560, g_loss: 1.0238\n",
            "Step [21800/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0170, d_svhn_loss: 0.0635, d_fake_loss: 0.1226, g_loss: 0.8180\n",
            "Step [21810/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0105, d_svhn_loss: 0.0316, d_fake_loss: 0.0481, g_loss: 1.1301\n",
            "Step [21820/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0107, d_svhn_loss: 0.0379, d_fake_loss: 0.0857, g_loss: 0.9065\n",
            "Step [21830/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0356, d_svhn_loss: 0.0456, d_fake_loss: 0.0528, g_loss: 0.9812\n",
            "Step [21840/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0248, d_svhn_loss: 0.0355, d_fake_loss: 0.0533, g_loss: 1.2377\n",
            "Step [21850/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0073, d_svhn_loss: 0.0259, d_fake_loss: 0.0454, g_loss: 1.1634\n",
            "Step [21860/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0234, d_svhn_loss: 0.0273, d_fake_loss: 0.0749, g_loss: 0.9837\n",
            "Step [21870/80000], d_real_loss: 0.0734, d_mnist_loss: 0.0237, d_svhn_loss: 0.0497, d_fake_loss: 0.0693, g_loss: 1.2774\n",
            "Step [21880/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0119, d_svhn_loss: 0.0484, d_fake_loss: 0.1899, g_loss: 0.9571\n",
            "Step [21890/80000], d_real_loss: 0.1731, d_mnist_loss: 0.0734, d_svhn_loss: 0.0997, d_fake_loss: 0.1152, g_loss: 0.9506\n",
            "Step [21900/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0123, d_svhn_loss: 0.0538, d_fake_loss: 0.0271, g_loss: 1.0302\n",
            "Step [21910/80000], d_real_loss: 0.1303, d_mnist_loss: 0.0142, d_svhn_loss: 0.1162, d_fake_loss: 0.1651, g_loss: 0.8315\n",
            "Step [21920/80000], d_real_loss: 0.0728, d_mnist_loss: 0.0243, d_svhn_loss: 0.0485, d_fake_loss: 0.0488, g_loss: 0.9689\n",
            "Step [21930/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0195, d_svhn_loss: 0.0436, d_fake_loss: 0.0757, g_loss: 1.0713\n",
            "Step [21940/80000], d_real_loss: 0.0881, d_mnist_loss: 0.0146, d_svhn_loss: 0.0735, d_fake_loss: 0.0685, g_loss: 1.2884\n",
            "Step [21950/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0123, d_svhn_loss: 0.0281, d_fake_loss: 0.0331, g_loss: 1.0629\n",
            "Step [21960/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0198, d_svhn_loss: 0.0264, d_fake_loss: 0.0516, g_loss: 1.2131\n",
            "Step [21970/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0108, d_svhn_loss: 0.0327, d_fake_loss: 0.0725, g_loss: 1.0485\n",
            "Step [21980/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0135, d_svhn_loss: 0.0364, d_fake_loss: 0.0518, g_loss: 1.2352\n",
            "Step [21990/80000], d_real_loss: 0.1174, d_mnist_loss: 0.0158, d_svhn_loss: 0.1017, d_fake_loss: 0.0492, g_loss: 1.2580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [22000/80000], d_real_loss: 0.1828, d_mnist_loss: 0.0559, d_svhn_loss: 0.1269, d_fake_loss: 0.0461, g_loss: 1.1939\n",
            "saved ./samples_fashion/sample-22000-m-s.png\n",
            "saved ./samples_fashion/sample-22000-s-m.png\n",
            "Step [22010/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0117, d_svhn_loss: 0.0445, d_fake_loss: 0.0618, g_loss: 1.3059\n",
            "Step [22020/80000], d_real_loss: 0.1716, d_mnist_loss: 0.0389, d_svhn_loss: 0.1328, d_fake_loss: 0.1053, g_loss: 1.0558\n",
            "Step [22030/80000], d_real_loss: 0.0926, d_mnist_loss: 0.0654, d_svhn_loss: 0.0272, d_fake_loss: 0.0815, g_loss: 1.2284\n",
            "Step [22040/80000], d_real_loss: 0.1268, d_mnist_loss: 0.0779, d_svhn_loss: 0.0489, d_fake_loss: 0.1379, g_loss: 1.8404\n",
            "Step [22050/80000], d_real_loss: 0.1191, d_mnist_loss: 0.0284, d_svhn_loss: 0.0906, d_fake_loss: 0.0590, g_loss: 1.0513\n",
            "Step [22060/80000], d_real_loss: 0.0974, d_mnist_loss: 0.0131, d_svhn_loss: 0.0843, d_fake_loss: 0.0516, g_loss: 1.1594\n",
            "Step [22070/80000], d_real_loss: 0.0728, d_mnist_loss: 0.0111, d_svhn_loss: 0.0617, d_fake_loss: 0.0772, g_loss: 1.2287\n",
            "Step [22080/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0238, d_svhn_loss: 0.0303, d_fake_loss: 0.0499, g_loss: 0.9836\n",
            "Step [22090/80000], d_real_loss: 0.1559, d_mnist_loss: 0.0561, d_svhn_loss: 0.0998, d_fake_loss: 0.0428, g_loss: 1.0363\n",
            "Step [22100/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0104, d_svhn_loss: 0.0338, d_fake_loss: 0.0928, g_loss: 1.3124\n",
            "Step [22110/80000], d_real_loss: 0.0984, d_mnist_loss: 0.0595, d_svhn_loss: 0.0389, d_fake_loss: 0.0682, g_loss: 0.9527\n",
            "Step [22120/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0109, d_svhn_loss: 0.0282, d_fake_loss: 0.0659, g_loss: 1.0885\n",
            "Step [22130/80000], d_real_loss: 0.1005, d_mnist_loss: 0.0332, d_svhn_loss: 0.0673, d_fake_loss: 0.1517, g_loss: 0.8303\n",
            "Step [22140/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0297, d_svhn_loss: 0.0325, d_fake_loss: 0.0520, g_loss: 1.1650\n",
            "Step [22150/80000], d_real_loss: 0.0767, d_mnist_loss: 0.0214, d_svhn_loss: 0.0553, d_fake_loss: 0.0570, g_loss: 1.0897\n",
            "Step [22160/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0099, d_svhn_loss: 0.0247, d_fake_loss: 0.0530, g_loss: 1.1617\n",
            "Step [22170/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0085, d_svhn_loss: 0.0322, d_fake_loss: 0.0332, g_loss: 1.1450\n",
            "Step [22180/80000], d_real_loss: 0.1405, d_mnist_loss: 0.0510, d_svhn_loss: 0.0896, d_fake_loss: 0.1040, g_loss: 1.6376\n",
            "Step [22190/80000], d_real_loss: 0.0665, d_mnist_loss: 0.0261, d_svhn_loss: 0.0405, d_fake_loss: 0.1913, g_loss: 1.4308\n",
            "Step [22200/80000], d_real_loss: 0.2974, d_mnist_loss: 0.0130, d_svhn_loss: 0.2844, d_fake_loss: 0.1099, g_loss: 1.0774\n",
            "Step [22210/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0387, d_svhn_loss: 0.0399, d_fake_loss: 0.0448, g_loss: 1.1197\n",
            "Step [22220/80000], d_real_loss: 0.0726, d_mnist_loss: 0.0093, d_svhn_loss: 0.0632, d_fake_loss: 0.1411, g_loss: 1.5432\n",
            "Step [22230/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0140, d_svhn_loss: 0.0337, d_fake_loss: 0.1091, g_loss: 1.3334\n",
            "Step [22240/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0195, d_svhn_loss: 0.0363, d_fake_loss: 0.0459, g_loss: 1.1148\n",
            "Step [22250/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0099, d_svhn_loss: 0.0566, d_fake_loss: 0.1064, g_loss: 1.1723\n",
            "Step [22260/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0137, d_svhn_loss: 0.0432, d_fake_loss: 0.0530, g_loss: 0.9673\n",
            "Step [22270/80000], d_real_loss: 0.0687, d_mnist_loss: 0.0118, d_svhn_loss: 0.0569, d_fake_loss: 0.1227, g_loss: 1.2193\n",
            "Step [22280/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0093, d_svhn_loss: 0.0424, d_fake_loss: 0.0416, g_loss: 1.4185\n",
            "Step [22290/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0111, d_svhn_loss: 0.0245, d_fake_loss: 0.0428, g_loss: 1.1217\n",
            "Step [22300/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0150, d_svhn_loss: 0.0258, d_fake_loss: 0.0984, g_loss: 0.6737\n",
            "Step [22310/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0171, d_svhn_loss: 0.0546, d_fake_loss: 0.0402, g_loss: 1.0332\n",
            "Step [22320/80000], d_real_loss: 0.2609, d_mnist_loss: 0.1222, d_svhn_loss: 0.1387, d_fake_loss: 0.0859, g_loss: 1.3913\n",
            "Step [22330/80000], d_real_loss: 0.1072, d_mnist_loss: 0.0115, d_svhn_loss: 0.0957, d_fake_loss: 0.0874, g_loss: 0.9783\n",
            "Step [22340/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0138, d_svhn_loss: 0.0237, d_fake_loss: 0.1638, g_loss: 1.3706\n",
            "Step [22350/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0218, d_svhn_loss: 0.0601, d_fake_loss: 0.0524, g_loss: 1.1506\n",
            "Step [22360/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0101, d_svhn_loss: 0.0324, d_fake_loss: 0.1124, g_loss: 1.0936\n",
            "Step [22370/80000], d_real_loss: 0.1646, d_mnist_loss: 0.0090, d_svhn_loss: 0.1556, d_fake_loss: 0.1330, g_loss: 1.2371\n",
            "Step [22380/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0139, d_svhn_loss: 0.0355, d_fake_loss: 0.0536, g_loss: 1.1421\n",
            "Step [22390/80000], d_real_loss: 0.1366, d_mnist_loss: 0.0123, d_svhn_loss: 0.1243, d_fake_loss: 0.0927, g_loss: 1.1810\n",
            "Step [22400/80000], d_real_loss: 0.0896, d_mnist_loss: 0.0253, d_svhn_loss: 0.0642, d_fake_loss: 0.0815, g_loss: 0.9796\n",
            "Step [22410/80000], d_real_loss: 0.1548, d_mnist_loss: 0.0091, d_svhn_loss: 0.1457, d_fake_loss: 0.0706, g_loss: 1.1591\n",
            "Step [22420/80000], d_real_loss: 0.0990, d_mnist_loss: 0.0354, d_svhn_loss: 0.0635, d_fake_loss: 0.0430, g_loss: 1.0613\n",
            "Step [22430/80000], d_real_loss: 0.2010, d_mnist_loss: 0.0106, d_svhn_loss: 0.1904, d_fake_loss: 0.0834, g_loss: 1.1079\n",
            "Step [22440/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0114, d_svhn_loss: 0.0307, d_fake_loss: 0.0413, g_loss: 1.0905\n",
            "Step [22450/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0086, d_svhn_loss: 0.0411, d_fake_loss: 0.0524, g_loss: 1.1924\n",
            "Step [22460/80000], d_real_loss: 0.0954, d_mnist_loss: 0.0492, d_svhn_loss: 0.0462, d_fake_loss: 0.2180, g_loss: 1.0073\n",
            "Step [22470/80000], d_real_loss: 0.1015, d_mnist_loss: 0.0532, d_svhn_loss: 0.0483, d_fake_loss: 0.0343, g_loss: 1.1817\n",
            "Step [22480/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0136, d_svhn_loss: 0.0467, d_fake_loss: 0.0888, g_loss: 1.4837\n",
            "Step [22490/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0187, d_svhn_loss: 0.0473, d_fake_loss: 0.0375, g_loss: 1.0344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [22500/80000], d_real_loss: 0.1052, d_mnist_loss: 0.0178, d_svhn_loss: 0.0874, d_fake_loss: 0.0792, g_loss: 0.9587\n",
            "saved ./samples_fashion/sample-22500-m-s.png\n",
            "saved ./samples_fashion/sample-22500-s-m.png\n",
            "Step [22510/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0093, d_svhn_loss: 0.0272, d_fake_loss: 0.0496, g_loss: 0.9585\n",
            "Step [22520/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0129, d_svhn_loss: 0.0263, d_fake_loss: 0.0613, g_loss: 0.9957\n",
            "Step [22530/80000], d_real_loss: 0.0698, d_mnist_loss: 0.0105, d_svhn_loss: 0.0592, d_fake_loss: 0.0382, g_loss: 1.0583\n",
            "Step [22540/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0096, d_svhn_loss: 0.0245, d_fake_loss: 0.1560, g_loss: 1.0861\n",
            "Step [22550/80000], d_real_loss: 0.0968, d_mnist_loss: 0.0340, d_svhn_loss: 0.0628, d_fake_loss: 0.0458, g_loss: 1.1285\n",
            "Step [22560/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0061, d_svhn_loss: 0.0468, d_fake_loss: 0.0743, g_loss: 1.1086\n",
            "Step [22570/80000], d_real_loss: 0.1199, d_mnist_loss: 0.0186, d_svhn_loss: 0.1012, d_fake_loss: 0.0555, g_loss: 0.9872\n",
            "Step [22580/80000], d_real_loss: 0.1336, d_mnist_loss: 0.1036, d_svhn_loss: 0.0301, d_fake_loss: 0.0492, g_loss: 1.3945\n",
            "Step [22590/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0191, d_svhn_loss: 0.0255, d_fake_loss: 0.0466, g_loss: 1.0842\n",
            "Step [22600/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0107, d_svhn_loss: 0.0310, d_fake_loss: 0.1401, g_loss: 1.0336\n",
            "Step [22610/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0122, d_svhn_loss: 0.0430, d_fake_loss: 0.0395, g_loss: 1.0376\n",
            "Step [22620/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0164, d_svhn_loss: 0.0648, d_fake_loss: 0.1113, g_loss: 1.0565\n",
            "Step [22630/80000], d_real_loss: 0.0957, d_mnist_loss: 0.0259, d_svhn_loss: 0.0698, d_fake_loss: 0.1021, g_loss: 1.1282\n",
            "Step [22640/80000], d_real_loss: 0.1046, d_mnist_loss: 0.0325, d_svhn_loss: 0.0721, d_fake_loss: 0.0477, g_loss: 1.1299\n",
            "Step [22650/80000], d_real_loss: 0.1599, d_mnist_loss: 0.0845, d_svhn_loss: 0.0754, d_fake_loss: 0.0495, g_loss: 1.2053\n",
            "Step [22660/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0132, d_svhn_loss: 0.0537, d_fake_loss: 0.0639, g_loss: 1.1155\n",
            "Step [22670/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0151, d_svhn_loss: 0.0250, d_fake_loss: 0.0872, g_loss: 0.7685\n",
            "Step [22680/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0206, d_svhn_loss: 0.0313, d_fake_loss: 0.0755, g_loss: 1.2887\n",
            "Step [22690/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0118, d_svhn_loss: 0.0343, d_fake_loss: 0.0630, g_loss: 0.8716\n",
            "Step [22700/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0118, d_svhn_loss: 0.0336, d_fake_loss: 0.0668, g_loss: 1.1006\n",
            "Step [22710/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0064, d_svhn_loss: 0.0399, d_fake_loss: 0.0283, g_loss: 1.1111\n",
            "Step [22720/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0092, d_svhn_loss: 0.0384, d_fake_loss: 0.0559, g_loss: 1.1990\n",
            "Step [22730/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0131, d_svhn_loss: 0.0412, d_fake_loss: 0.1220, g_loss: 1.2589\n",
            "Step [22740/80000], d_real_loss: 0.1298, d_mnist_loss: 0.0681, d_svhn_loss: 0.0617, d_fake_loss: 0.1038, g_loss: 0.9921\n",
            "Step [22750/80000], d_real_loss: 0.0999, d_mnist_loss: 0.0174, d_svhn_loss: 0.0825, d_fake_loss: 0.1842, g_loss: 1.2036\n",
            "Step [22760/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0146, d_svhn_loss: 0.0579, d_fake_loss: 0.0474, g_loss: 1.0526\n",
            "Step [22770/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0118, d_svhn_loss: 0.0449, d_fake_loss: 0.0594, g_loss: 1.1516\n",
            "Step [22780/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0164, d_svhn_loss: 0.0226, d_fake_loss: 0.0449, g_loss: 1.1923\n",
            "Step [22790/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0195, d_svhn_loss: 0.0421, d_fake_loss: 0.0842, g_loss: 1.1954\n",
            "Step [22800/80000], d_real_loss: 0.1064, d_mnist_loss: 0.0694, d_svhn_loss: 0.0369, d_fake_loss: 0.0447, g_loss: 1.3678\n",
            "Step [22810/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0167, d_svhn_loss: 0.0319, d_fake_loss: 0.1668, g_loss: 1.3709\n",
            "Step [22820/80000], d_real_loss: 0.1281, d_mnist_loss: 0.0120, d_svhn_loss: 0.1160, d_fake_loss: 0.1014, g_loss: 1.3460\n",
            "Step [22830/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0252, d_svhn_loss: 0.0285, d_fake_loss: 0.1089, g_loss: 0.7598\n",
            "Step [22840/80000], d_real_loss: 0.1359, d_mnist_loss: 0.0118, d_svhn_loss: 0.1242, d_fake_loss: 0.1969, g_loss: 1.2046\n",
            "Step [22850/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0138, d_svhn_loss: 0.0209, d_fake_loss: 0.0625, g_loss: 1.1914\n",
            "Step [22860/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0211, d_svhn_loss: 0.0374, d_fake_loss: 0.0624, g_loss: 1.2762\n",
            "Step [22870/80000], d_real_loss: 0.0814, d_mnist_loss: 0.0120, d_svhn_loss: 0.0694, d_fake_loss: 0.1560, g_loss: 1.5031\n",
            "Step [22880/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0214, d_svhn_loss: 0.0423, d_fake_loss: 0.0467, g_loss: 1.0986\n",
            "Step [22890/80000], d_real_loss: 0.1427, d_mnist_loss: 0.0234, d_svhn_loss: 0.1193, d_fake_loss: 0.0967, g_loss: 1.4708\n",
            "Step [22900/80000], d_real_loss: 0.1229, d_mnist_loss: 0.0103, d_svhn_loss: 0.1126, d_fake_loss: 0.0984, g_loss: 1.1228\n",
            "Step [22910/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0211, d_svhn_loss: 0.0259, d_fake_loss: 0.0373, g_loss: 1.3027\n",
            "Step [22920/80000], d_real_loss: 0.0687, d_mnist_loss: 0.0111, d_svhn_loss: 0.0577, d_fake_loss: 0.0516, g_loss: 1.0477\n",
            "Step [22930/80000], d_real_loss: 0.1774, d_mnist_loss: 0.0145, d_svhn_loss: 0.1630, d_fake_loss: 0.0329, g_loss: 1.0959\n",
            "Step [22940/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0138, d_svhn_loss: 0.0272, d_fake_loss: 0.0453, g_loss: 1.0235\n",
            "Step [22950/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0334, d_svhn_loss: 0.0214, d_fake_loss: 0.0337, g_loss: 1.2446\n",
            "Step [22960/80000], d_real_loss: 0.1062, d_mnist_loss: 0.0746, d_svhn_loss: 0.0316, d_fake_loss: 0.0785, g_loss: 1.0980\n",
            "Step [22970/80000], d_real_loss: 0.3498, d_mnist_loss: 0.0179, d_svhn_loss: 0.3319, d_fake_loss: 0.1834, g_loss: 1.0687\n",
            "Step [22980/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0089, d_svhn_loss: 0.0242, d_fake_loss: 0.0436, g_loss: 1.1937\n",
            "Step [22990/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0229, d_svhn_loss: 0.0499, d_fake_loss: 0.1303, g_loss: 1.0378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [23000/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0082, d_svhn_loss: 0.0333, d_fake_loss: 0.0807, g_loss: 1.0470\n",
            "saved ./samples_fashion/sample-23000-m-s.png\n",
            "saved ./samples_fashion/sample-23000-s-m.png\n",
            "Step [23010/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0097, d_svhn_loss: 0.0281, d_fake_loss: 0.0442, g_loss: 1.0527\n",
            "Step [23020/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0531, d_svhn_loss: 0.0251, d_fake_loss: 0.0568, g_loss: 1.1064\n",
            "Step [23030/80000], d_real_loss: 0.1414, d_mnist_loss: 0.0282, d_svhn_loss: 0.1132, d_fake_loss: 0.0415, g_loss: 1.0960\n",
            "Step [23040/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0148, d_svhn_loss: 0.0476, d_fake_loss: 0.0730, g_loss: 1.3753\n",
            "Step [23050/80000], d_real_loss: 0.1401, d_mnist_loss: 0.0360, d_svhn_loss: 0.1041, d_fake_loss: 0.0762, g_loss: 1.1487\n",
            "Step [23060/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0084, d_svhn_loss: 0.0654, d_fake_loss: 0.0865, g_loss: 1.1345\n",
            "Step [23070/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0411, d_svhn_loss: 0.0330, d_fake_loss: 0.0318, g_loss: 1.1013\n",
            "Step [23080/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0316, d_svhn_loss: 0.0467, d_fake_loss: 0.0627, g_loss: 1.2223\n",
            "Step [23090/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0158, d_svhn_loss: 0.0258, d_fake_loss: 0.0736, g_loss: 1.4526\n",
            "Step [23100/80000], d_real_loss: 0.1020, d_mnist_loss: 0.0627, d_svhn_loss: 0.0394, d_fake_loss: 0.1372, g_loss: 1.0764\n",
            "Step [23110/80000], d_real_loss: 0.1059, d_mnist_loss: 0.0102, d_svhn_loss: 0.0956, d_fake_loss: 0.0484, g_loss: 1.0425\n",
            "Step [23120/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0143, d_svhn_loss: 0.0490, d_fake_loss: 0.0496, g_loss: 1.1407\n",
            "Step [23130/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0344, d_svhn_loss: 0.0574, d_fake_loss: 0.0779, g_loss: 1.2984\n",
            "Step [23140/80000], d_real_loss: 0.1055, d_mnist_loss: 0.0210, d_svhn_loss: 0.0845, d_fake_loss: 0.1452, g_loss: 1.2055\n",
            "Step [23150/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0091, d_svhn_loss: 0.0305, d_fake_loss: 0.0484, g_loss: 1.3160\n",
            "Step [23160/80000], d_real_loss: 0.0792, d_mnist_loss: 0.0236, d_svhn_loss: 0.0556, d_fake_loss: 0.0734, g_loss: 0.9490\n",
            "Step [23170/80000], d_real_loss: 0.0981, d_mnist_loss: 0.0327, d_svhn_loss: 0.0653, d_fake_loss: 0.1077, g_loss: 0.8533\n",
            "Step [23180/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0132, d_svhn_loss: 0.0344, d_fake_loss: 0.0686, g_loss: 1.2212\n",
            "Step [23190/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0100, d_svhn_loss: 0.0618, d_fake_loss: 0.1522, g_loss: 1.1747\n",
            "Step [23200/80000], d_real_loss: 0.0854, d_mnist_loss: 0.0117, d_svhn_loss: 0.0737, d_fake_loss: 0.0814, g_loss: 1.2629\n",
            "Step [23210/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0170, d_svhn_loss: 0.0774, d_fake_loss: 0.0454, g_loss: 1.1975\n",
            "Step [23220/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0255, d_svhn_loss: 0.0320, d_fake_loss: 0.1455, g_loss: 0.6157\n",
            "Step [23230/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0129, d_svhn_loss: 0.0557, d_fake_loss: 0.0410, g_loss: 1.1044\n",
            "Step [23240/80000], d_real_loss: 0.2183, d_mnist_loss: 0.0443, d_svhn_loss: 0.1740, d_fake_loss: 0.0539, g_loss: 1.0992\n",
            "Step [23250/80000], d_real_loss: 0.1291, d_mnist_loss: 0.0289, d_svhn_loss: 0.1003, d_fake_loss: 0.0472, g_loss: 1.2296\n",
            "Step [23260/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0087, d_svhn_loss: 0.0313, d_fake_loss: 0.0439, g_loss: 1.1898\n",
            "Step [23270/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0407, d_svhn_loss: 0.0272, d_fake_loss: 0.0469, g_loss: 1.0437\n",
            "Step [23280/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0124, d_svhn_loss: 0.0602, d_fake_loss: 0.0606, g_loss: 1.1111\n",
            "Step [23290/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0377, d_svhn_loss: 0.0280, d_fake_loss: 0.0679, g_loss: 1.2714\n",
            "Step [23300/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0140, d_svhn_loss: 0.0228, d_fake_loss: 0.0568, g_loss: 1.0994\n",
            "Step [23310/80000], d_real_loss: 0.0658, d_mnist_loss: 0.0137, d_svhn_loss: 0.0520, d_fake_loss: 0.0405, g_loss: 1.1077\n",
            "Step [23320/80000], d_real_loss: 0.1251, d_mnist_loss: 0.0260, d_svhn_loss: 0.0992, d_fake_loss: 0.0453, g_loss: 1.0769\n",
            "Step [23330/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0121, d_svhn_loss: 0.0459, d_fake_loss: 0.0426, g_loss: 1.0485\n",
            "Step [23340/80000], d_real_loss: 0.1149, d_mnist_loss: 0.0875, d_svhn_loss: 0.0274, d_fake_loss: 0.0507, g_loss: 1.1672\n",
            "Step [23350/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0103, d_svhn_loss: 0.0487, d_fake_loss: 0.0541, g_loss: 1.2716\n",
            "Step [23360/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0342, d_svhn_loss: 0.0239, d_fake_loss: 0.0413, g_loss: 1.0761\n",
            "Step [23370/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0094, d_svhn_loss: 0.0216, d_fake_loss: 0.0461, g_loss: 1.2415\n",
            "Step [23380/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0161, d_svhn_loss: 0.0362, d_fake_loss: 0.0920, g_loss: 1.2455\n",
            "Step [23390/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0093, d_svhn_loss: 0.0493, d_fake_loss: 0.0694, g_loss: 1.0470\n",
            "Step [23400/80000], d_real_loss: 0.1428, d_mnist_loss: 0.0811, d_svhn_loss: 0.0616, d_fake_loss: 0.0518, g_loss: 0.9749\n",
            "Step [23410/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0196, d_svhn_loss: 0.0426, d_fake_loss: 0.0343, g_loss: 1.1717\n",
            "Step [23420/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0407, d_svhn_loss: 0.0330, d_fake_loss: 0.0642, g_loss: 1.1311\n",
            "Step [23430/80000], d_real_loss: 0.0913, d_mnist_loss: 0.0118, d_svhn_loss: 0.0795, d_fake_loss: 0.0336, g_loss: 0.9277\n",
            "Step [23440/80000], d_real_loss: 0.0934, d_mnist_loss: 0.0218, d_svhn_loss: 0.0716, d_fake_loss: 0.1666, g_loss: 0.9280\n",
            "Step [23450/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0093, d_svhn_loss: 0.0274, d_fake_loss: 0.0716, g_loss: 1.0439\n",
            "Step [23460/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0115, d_svhn_loss: 0.0311, d_fake_loss: 0.0734, g_loss: 0.8526\n",
            "Step [23470/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0115, d_svhn_loss: 0.0468, d_fake_loss: 0.0870, g_loss: 1.1294\n",
            "Step [23480/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0664, d_svhn_loss: 0.0415, d_fake_loss: 0.1066, g_loss: 1.1792\n",
            "Step [23490/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0093, d_svhn_loss: 0.0442, d_fake_loss: 0.0974, g_loss: 1.1236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [23500/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0121, d_svhn_loss: 0.0240, d_fake_loss: 0.0950, g_loss: 1.1218\n",
            "saved ./samples_fashion/sample-23500-m-s.png\n",
            "saved ./samples_fashion/sample-23500-s-m.png\n",
            "Step [23510/80000], d_real_loss: 0.1417, d_mnist_loss: 0.0174, d_svhn_loss: 0.1242, d_fake_loss: 0.0681, g_loss: 0.8866\n",
            "Step [23520/80000], d_real_loss: 0.1533, d_mnist_loss: 0.0611, d_svhn_loss: 0.0922, d_fake_loss: 0.0339, g_loss: 0.9576\n",
            "Step [23530/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0115, d_svhn_loss: 0.0376, d_fake_loss: 0.0302, g_loss: 1.1124\n",
            "Step [23540/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0067, d_svhn_loss: 0.0336, d_fake_loss: 0.0448, g_loss: 1.1122\n",
            "Step [23550/80000], d_real_loss: 0.1894, d_mnist_loss: 0.0420, d_svhn_loss: 0.1473, d_fake_loss: 0.2994, g_loss: 1.3032\n",
            "Step [23560/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0118, d_svhn_loss: 0.0273, d_fake_loss: 0.0759, g_loss: 0.8846\n",
            "Step [23570/80000], d_real_loss: 0.0827, d_mnist_loss: 0.0323, d_svhn_loss: 0.0503, d_fake_loss: 0.0651, g_loss: 1.3271\n",
            "Step [23580/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0124, d_svhn_loss: 0.0662, d_fake_loss: 0.0348, g_loss: 1.1237\n",
            "Step [23590/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0277, d_svhn_loss: 0.0523, d_fake_loss: 0.1304, g_loss: 1.1598\n",
            "Step [23600/80000], d_real_loss: 0.1765, d_mnist_loss: 0.0222, d_svhn_loss: 0.1543, d_fake_loss: 0.0924, g_loss: 1.0789\n",
            "Step [23610/80000], d_real_loss: 0.1547, d_mnist_loss: 0.0155, d_svhn_loss: 0.1392, d_fake_loss: 0.1974, g_loss: 1.1850\n",
            "Step [23620/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0254, d_svhn_loss: 0.0406, d_fake_loss: 0.0702, g_loss: 1.2587\n",
            "Step [23630/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0235, d_svhn_loss: 0.0378, d_fake_loss: 0.1241, g_loss: 1.3712\n",
            "Step [23640/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0084, d_svhn_loss: 0.0324, d_fake_loss: 0.0456, g_loss: 0.9605\n",
            "Step [23650/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0125, d_svhn_loss: 0.0360, d_fake_loss: 0.0417, g_loss: 1.0622\n",
            "Step [23660/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0154, d_svhn_loss: 0.0435, d_fake_loss: 0.0383, g_loss: 1.2101\n",
            "Step [23670/80000], d_real_loss: 0.0779, d_mnist_loss: 0.0126, d_svhn_loss: 0.0654, d_fake_loss: 0.0555, g_loss: 1.0991\n",
            "Step [23680/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0269, d_svhn_loss: 0.0391, d_fake_loss: 0.0327, g_loss: 1.2138\n",
            "Step [23690/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0141, d_svhn_loss: 0.0604, d_fake_loss: 0.0929, g_loss: 0.9914\n",
            "Step [23700/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0111, d_svhn_loss: 0.0240, d_fake_loss: 0.0387, g_loss: 1.0814\n",
            "Step [23710/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0072, d_svhn_loss: 0.0374, d_fake_loss: 0.0372, g_loss: 1.2842\n",
            "Step [23720/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0127, d_svhn_loss: 0.0462, d_fake_loss: 0.0487, g_loss: 1.0880\n",
            "Step [23730/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0101, d_svhn_loss: 0.0262, d_fake_loss: 0.2180, g_loss: 1.3832\n",
            "Step [23740/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0156, d_svhn_loss: 0.0320, d_fake_loss: 0.0295, g_loss: 1.1390\n",
            "Step [23750/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0072, d_svhn_loss: 0.0406, d_fake_loss: 0.1421, g_loss: 1.5076\n",
            "Step [23760/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0462, d_svhn_loss: 0.0413, d_fake_loss: 0.1251, g_loss: 0.6656\n",
            "Step [23770/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0116, d_svhn_loss: 0.0547, d_fake_loss: 0.0666, g_loss: 1.0309\n",
            "Step [23780/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0120, d_svhn_loss: 0.0323, d_fake_loss: 0.0550, g_loss: 1.0320\n",
            "Step [23790/80000], d_real_loss: 0.1158, d_mnist_loss: 0.0126, d_svhn_loss: 0.1031, d_fake_loss: 0.1260, g_loss: 1.2976\n",
            "Step [23800/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0081, d_svhn_loss: 0.0377, d_fake_loss: 0.0923, g_loss: 0.9841\n",
            "Step [23810/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0138, d_svhn_loss: 0.0437, d_fake_loss: 0.0549, g_loss: 1.0556\n",
            "Step [23820/80000], d_real_loss: 0.2023, d_mnist_loss: 0.0836, d_svhn_loss: 0.1187, d_fake_loss: 0.1515, g_loss: 1.2078\n",
            "Step [23830/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0153, d_svhn_loss: 0.0273, d_fake_loss: 0.0536, g_loss: 1.0878\n",
            "Step [23840/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0174, d_svhn_loss: 0.0336, d_fake_loss: 0.0322, g_loss: 1.1432\n",
            "Step [23850/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0129, d_svhn_loss: 0.0610, d_fake_loss: 0.0603, g_loss: 1.1995\n",
            "Step [23860/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0125, d_svhn_loss: 0.0327, d_fake_loss: 0.0506, g_loss: 0.9465\n",
            "Step [23870/80000], d_real_loss: 0.1065, d_mnist_loss: 0.0098, d_svhn_loss: 0.0967, d_fake_loss: 0.1003, g_loss: 1.1128\n",
            "Step [23880/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0239, d_svhn_loss: 0.0342, d_fake_loss: 0.0670, g_loss: 1.1604\n",
            "Step [23890/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0164, d_svhn_loss: 0.0367, d_fake_loss: 0.0644, g_loss: 1.2458\n",
            "Step [23900/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0132, d_svhn_loss: 0.0606, d_fake_loss: 0.0770, g_loss: 0.9410\n",
            "Step [23910/80000], d_real_loss: 0.1697, d_mnist_loss: 0.0748, d_svhn_loss: 0.0949, d_fake_loss: 0.0709, g_loss: 1.3007\n",
            "Step [23920/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0172, d_svhn_loss: 0.0293, d_fake_loss: 0.0670, g_loss: 0.8864\n",
            "Step [23930/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0167, d_svhn_loss: 0.0402, d_fake_loss: 0.0627, g_loss: 1.1408\n",
            "Step [23940/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0291, d_svhn_loss: 0.0305, d_fake_loss: 0.0356, g_loss: 1.1493\n",
            "Step [23950/80000], d_real_loss: 0.0704, d_mnist_loss: 0.0488, d_svhn_loss: 0.0216, d_fake_loss: 0.0605, g_loss: 1.3060\n",
            "Step [23960/80000], d_real_loss: 0.1343, d_mnist_loss: 0.0387, d_svhn_loss: 0.0956, d_fake_loss: 0.0978, g_loss: 1.1341\n",
            "Step [23970/80000], d_real_loss: 0.1796, d_mnist_loss: 0.0085, d_svhn_loss: 0.1711, d_fake_loss: 0.0599, g_loss: 1.1317\n",
            "Step [23980/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0133, d_svhn_loss: 0.0307, d_fake_loss: 0.1029, g_loss: 1.0379\n",
            "Step [23990/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0252, d_svhn_loss: 0.0293, d_fake_loss: 0.1409, g_loss: 1.3472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999954104423523, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [24000/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0272, d_svhn_loss: 0.0236, d_fake_loss: 0.0517, g_loss: 1.0282\n",
            "saved ./samples_fashion/sample-24000-m-s.png\n",
            "saved ./samples_fashion/sample-24000-s-m.png\n",
            "Step [24010/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0183, d_svhn_loss: 0.0352, d_fake_loss: 0.0379, g_loss: 1.1537\n",
            "Step [24020/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0091, d_svhn_loss: 0.0228, d_fake_loss: 0.0884, g_loss: 1.0433\n",
            "Step [24030/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0134, d_svhn_loss: 0.0240, d_fake_loss: 0.0538, g_loss: 1.0320\n",
            "Step [24040/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0107, d_svhn_loss: 0.0640, d_fake_loss: 0.1142, g_loss: 0.8585\n",
            "Step [24050/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0145, d_svhn_loss: 0.0268, d_fake_loss: 0.0385, g_loss: 1.0616\n",
            "Step [24060/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0306, d_svhn_loss: 0.0232, d_fake_loss: 0.0744, g_loss: 1.2819\n",
            "Step [24070/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0108, d_svhn_loss: 0.0242, d_fake_loss: 0.0824, g_loss: 1.0916\n",
            "Step [24080/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0158, d_svhn_loss: 0.0581, d_fake_loss: 0.0638, g_loss: 1.2097\n",
            "Step [24090/80000], d_real_loss: 0.0853, d_mnist_loss: 0.0482, d_svhn_loss: 0.0372, d_fake_loss: 0.0490, g_loss: 1.0288\n",
            "Step [24100/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0064, d_svhn_loss: 0.0376, d_fake_loss: 0.0454, g_loss: 1.0174\n",
            "Step [24110/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0210, d_svhn_loss: 0.0287, d_fake_loss: 0.1176, g_loss: 1.2180\n",
            "Step [24120/80000], d_real_loss: 0.1683, d_mnist_loss: 0.0321, d_svhn_loss: 0.1363, d_fake_loss: 0.0991, g_loss: 1.2113\n",
            "Step [24130/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0097, d_svhn_loss: 0.0484, d_fake_loss: 0.1875, g_loss: 0.9782\n",
            "Step [24140/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0098, d_svhn_loss: 0.0356, d_fake_loss: 0.0914, g_loss: 1.0801\n",
            "Step [24150/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0188, d_svhn_loss: 0.0285, d_fake_loss: 0.0521, g_loss: 1.1464\n",
            "Step [24160/80000], d_real_loss: 0.0932, d_mnist_loss: 0.0194, d_svhn_loss: 0.0737, d_fake_loss: 0.1366, g_loss: 1.0835\n",
            "Step [24170/80000], d_real_loss: 0.0989, d_mnist_loss: 0.0124, d_svhn_loss: 0.0865, d_fake_loss: 0.0822, g_loss: 1.0814\n",
            "Step [24180/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0172, d_svhn_loss: 0.0312, d_fake_loss: 0.0391, g_loss: 1.0690\n",
            "Step [24190/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0116, d_svhn_loss: 0.0679, d_fake_loss: 0.0948, g_loss: 1.0278\n",
            "Step [24200/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0155, d_svhn_loss: 0.0749, d_fake_loss: 0.1180, g_loss: 1.0128\n",
            "Step [24210/80000], d_real_loss: 0.1820, d_mnist_loss: 0.0467, d_svhn_loss: 0.1352, d_fake_loss: 0.0658, g_loss: 1.2171\n",
            "Step [24220/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0266, d_svhn_loss: 0.0517, d_fake_loss: 0.0581, g_loss: 1.1783\n",
            "Step [24230/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0091, d_svhn_loss: 0.0413, d_fake_loss: 0.1869, g_loss: 0.9206\n",
            "Step [24240/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0150, d_svhn_loss: 0.0563, d_fake_loss: 0.1036, g_loss: 0.9743\n",
            "Step [24250/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0126, d_svhn_loss: 0.0211, d_fake_loss: 0.0870, g_loss: 1.3000\n",
            "Step [24260/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0121, d_svhn_loss: 0.0481, d_fake_loss: 0.3579, g_loss: 1.1326\n",
            "Step [24270/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0135, d_svhn_loss: 0.0323, d_fake_loss: 0.0301, g_loss: 1.1546\n",
            "Step [24280/80000], d_real_loss: 0.1114, d_mnist_loss: 0.0320, d_svhn_loss: 0.0794, d_fake_loss: 0.0576, g_loss: 1.3971\n",
            "Step [24290/80000], d_real_loss: 0.1392, d_mnist_loss: 0.0131, d_svhn_loss: 0.1260, d_fake_loss: 0.0473, g_loss: 1.2052\n",
            "Step [24300/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0120, d_svhn_loss: 0.0336, d_fake_loss: 0.0396, g_loss: 1.0993\n",
            "Step [24310/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0305, d_svhn_loss: 0.0238, d_fake_loss: 0.0492, g_loss: 1.3352\n",
            "Step [24320/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0140, d_svhn_loss: 0.0413, d_fake_loss: 0.0662, g_loss: 1.0711\n",
            "Step [24330/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0099, d_svhn_loss: 0.0265, d_fake_loss: 0.0409, g_loss: 1.1467\n",
            "Step [24340/80000], d_real_loss: 0.1316, d_mnist_loss: 0.0122, d_svhn_loss: 0.1193, d_fake_loss: 0.0554, g_loss: 1.1944\n",
            "Step [24350/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0129, d_svhn_loss: 0.0526, d_fake_loss: 0.0822, g_loss: 1.1447\n",
            "Step [24360/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0261, d_svhn_loss: 0.0552, d_fake_loss: 0.1306, g_loss: 1.0673\n",
            "Step [24370/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0164, d_svhn_loss: 0.0715, d_fake_loss: 0.1186, g_loss: 1.2285\n",
            "Step [24380/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0139, d_svhn_loss: 0.0338, d_fake_loss: 0.0574, g_loss: 1.1125\n",
            "Step [24390/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0155, d_svhn_loss: 0.0204, d_fake_loss: 0.0579, g_loss: 1.1301\n",
            "Step [24400/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0201, d_svhn_loss: 0.0475, d_fake_loss: 0.0787, g_loss: 1.1009\n",
            "Step [24410/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0097, d_svhn_loss: 0.0274, d_fake_loss: 0.0695, g_loss: 1.2913\n",
            "Step [24420/80000], d_real_loss: 0.0760, d_mnist_loss: 0.0156, d_svhn_loss: 0.0604, d_fake_loss: 0.0454, g_loss: 1.2365\n",
            "Step [24430/80000], d_real_loss: 0.1795, d_mnist_loss: 0.0286, d_svhn_loss: 0.1509, d_fake_loss: 0.0630, g_loss: 1.2712\n",
            "Step [24440/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0098, d_svhn_loss: 0.0284, d_fake_loss: 0.0876, g_loss: 1.2119\n",
            "Step [24450/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0251, d_svhn_loss: 0.0827, d_fake_loss: 0.2690, g_loss: 1.1402\n",
            "Step [24460/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0096, d_svhn_loss: 0.0490, d_fake_loss: 0.1035, g_loss: 1.1250\n",
            "Step [24470/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0113, d_svhn_loss: 0.0357, d_fake_loss: 0.0347, g_loss: 1.1058\n",
            "Step [24480/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0265, d_svhn_loss: 0.0296, d_fake_loss: 0.0796, g_loss: 1.3192\n",
            "Step [24490/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0098, d_svhn_loss: 0.0377, d_fake_loss: 0.0475, g_loss: 0.9739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999966025352478, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [24500/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0142, d_svhn_loss: 0.0583, d_fake_loss: 0.0557, g_loss: 1.1781\n",
            "saved ./samples_fashion/sample-24500-m-s.png\n",
            "saved ./samples_fashion/sample-24500-s-m.png\n",
            "Step [24510/80000], d_real_loss: 0.0864, d_mnist_loss: 0.0095, d_svhn_loss: 0.0769, d_fake_loss: 0.0706, g_loss: 1.1016\n",
            "Step [24520/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0068, d_svhn_loss: 0.0372, d_fake_loss: 0.0298, g_loss: 1.1682\n",
            "Step [24530/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0322, d_svhn_loss: 0.0250, d_fake_loss: 0.0835, g_loss: 1.2584\n",
            "Step [24540/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0077, d_svhn_loss: 0.0392, d_fake_loss: 0.0631, g_loss: 1.5066\n",
            "Step [24550/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0125, d_svhn_loss: 0.0267, d_fake_loss: 0.0513, g_loss: 1.0875\n",
            "Step [24560/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0145, d_svhn_loss: 0.0435, d_fake_loss: 0.0502, g_loss: 0.9434\n",
            "Step [24570/80000], d_real_loss: 0.0874, d_mnist_loss: 0.0122, d_svhn_loss: 0.0752, d_fake_loss: 0.0713, g_loss: 0.9537\n",
            "Step [24580/80000], d_real_loss: 0.1326, d_mnist_loss: 0.0822, d_svhn_loss: 0.0504, d_fake_loss: 0.0385, g_loss: 1.2400\n",
            "Step [24590/80000], d_real_loss: 0.0915, d_mnist_loss: 0.0111, d_svhn_loss: 0.0804, d_fake_loss: 0.0741, g_loss: 1.1292\n",
            "Step [24600/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0126, d_svhn_loss: 0.0266, d_fake_loss: 0.0641, g_loss: 1.0626\n",
            "Step [24610/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0163, d_svhn_loss: 0.0424, d_fake_loss: 0.0482, g_loss: 1.1338\n",
            "Step [24620/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0124, d_svhn_loss: 0.0446, d_fake_loss: 0.0529, g_loss: 1.1687\n",
            "Step [24630/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0167, d_svhn_loss: 0.0507, d_fake_loss: 0.0814, g_loss: 1.0030\n",
            "Step [24640/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0068, d_svhn_loss: 0.0304, d_fake_loss: 0.0657, g_loss: 0.8477\n",
            "Step [24650/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0147, d_svhn_loss: 0.0207, d_fake_loss: 0.0535, g_loss: 1.1562\n",
            "Step [24660/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0255, d_svhn_loss: 0.0349, d_fake_loss: 0.0462, g_loss: 1.0651\n",
            "Step [24670/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0180, d_svhn_loss: 0.0483, d_fake_loss: 0.0233, g_loss: 1.2194\n",
            "Step [24680/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0148, d_svhn_loss: 0.0441, d_fake_loss: 0.0471, g_loss: 1.0426\n",
            "Step [24690/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0158, d_svhn_loss: 0.0515, d_fake_loss: 0.0445, g_loss: 1.0199\n",
            "Step [24700/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0100, d_svhn_loss: 0.0424, d_fake_loss: 0.0483, g_loss: 1.0059\n",
            "Step [24710/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0129, d_svhn_loss: 0.0386, d_fake_loss: 0.2352, g_loss: 1.1603\n",
            "Step [24720/80000], d_real_loss: 0.0881, d_mnist_loss: 0.0131, d_svhn_loss: 0.0750, d_fake_loss: 0.0542, g_loss: 1.1606\n",
            "Step [24730/80000], d_real_loss: 0.0989, d_mnist_loss: 0.0247, d_svhn_loss: 0.0741, d_fake_loss: 0.0551, g_loss: 0.9556\n",
            "Step [24740/80000], d_real_loss: 0.0808, d_mnist_loss: 0.0382, d_svhn_loss: 0.0427, d_fake_loss: 0.0754, g_loss: 1.0852\n",
            "Step [24750/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0136, d_svhn_loss: 0.0579, d_fake_loss: 0.0759, g_loss: 0.9809\n",
            "Step [24760/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0130, d_svhn_loss: 0.0437, d_fake_loss: 0.0529, g_loss: 1.1368\n",
            "Step [24770/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0183, d_svhn_loss: 0.0270, d_fake_loss: 0.0455, g_loss: 1.1024\n",
            "Step [24780/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0262, d_svhn_loss: 0.0314, d_fake_loss: 0.0823, g_loss: 1.2090\n",
            "Step [24790/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0237, d_svhn_loss: 0.0387, d_fake_loss: 0.1427, g_loss: 1.2719\n",
            "Step [24800/80000], d_real_loss: 0.2182, d_mnist_loss: 0.0120, d_svhn_loss: 0.2062, d_fake_loss: 0.0565, g_loss: 1.0413\n",
            "Step [24810/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0164, d_svhn_loss: 0.0250, d_fake_loss: 0.0799, g_loss: 1.0355\n",
            "Step [24820/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0078, d_svhn_loss: 0.0358, d_fake_loss: 0.0959, g_loss: 0.9377\n",
            "Step [24830/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0124, d_svhn_loss: 0.0332, d_fake_loss: 0.0511, g_loss: 1.1628\n",
            "Step [24840/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0110, d_svhn_loss: 0.0412, d_fake_loss: 0.0654, g_loss: 0.8656\n",
            "Step [24850/80000], d_real_loss: 0.0905, d_mnist_loss: 0.0166, d_svhn_loss: 0.0740, d_fake_loss: 0.0458, g_loss: 1.1948\n",
            "Step [24860/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0100, d_svhn_loss: 0.0453, d_fake_loss: 0.0279, g_loss: 1.0717\n",
            "Step [24870/80000], d_real_loss: 0.1051, d_mnist_loss: 0.0242, d_svhn_loss: 0.0809, d_fake_loss: 0.1891, g_loss: 0.9163\n",
            "Step [24880/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0179, d_svhn_loss: 0.0243, d_fake_loss: 0.0620, g_loss: 1.2082\n",
            "Step [24890/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0233, d_svhn_loss: 0.0410, d_fake_loss: 0.0891, g_loss: 0.8762\n",
            "Step [24900/80000], d_real_loss: 0.1186, d_mnist_loss: 0.0673, d_svhn_loss: 0.0513, d_fake_loss: 0.1076, g_loss: 1.1785\n",
            "Step [24910/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0095, d_svhn_loss: 0.0265, d_fake_loss: 0.1161, g_loss: 1.3895\n",
            "Step [24920/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0151, d_svhn_loss: 0.0275, d_fake_loss: 0.0419, g_loss: 1.0110\n",
            "Step [24930/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0151, d_svhn_loss: 0.0242, d_fake_loss: 0.0533, g_loss: 1.1108\n",
            "Step [24940/80000], d_real_loss: 0.1052, d_mnist_loss: 0.0087, d_svhn_loss: 0.0965, d_fake_loss: 0.1321, g_loss: 1.0347\n",
            "Step [24950/80000], d_real_loss: 0.1046, d_mnist_loss: 0.0141, d_svhn_loss: 0.0905, d_fake_loss: 0.0786, g_loss: 1.0461\n",
            "Step [24960/80000], d_real_loss: 0.0979, d_mnist_loss: 0.0159, d_svhn_loss: 0.0820, d_fake_loss: 0.0982, g_loss: 1.2655\n",
            "Step [24970/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0351, d_svhn_loss: 0.0274, d_fake_loss: 0.0760, g_loss: 1.2615\n",
            "Step [24980/80000], d_real_loss: 0.1186, d_mnist_loss: 0.0785, d_svhn_loss: 0.0401, d_fake_loss: 0.1404, g_loss: 1.4038\n",
            "Step [24990/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0130, d_svhn_loss: 0.0426, d_fake_loss: 0.0639, g_loss: 1.1737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999645352363586, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [25000/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0147, d_svhn_loss: 0.0252, d_fake_loss: 0.0497, g_loss: 0.8777\n",
            "saved ./samples_fashion/sample-25000-m-s.png\n",
            "saved ./samples_fashion/sample-25000-s-m.png\n",
            "Step [25010/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0358, d_svhn_loss: 0.0460, d_fake_loss: 0.0571, g_loss: 1.4655\n",
            "Step [25020/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0227, d_svhn_loss: 0.0339, d_fake_loss: 0.0940, g_loss: 1.0801\n",
            "Step [25030/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0146, d_svhn_loss: 0.0283, d_fake_loss: 0.0466, g_loss: 1.0769\n",
            "Step [25040/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0104, d_svhn_loss: 0.0219, d_fake_loss: 0.0998, g_loss: 0.9155\n",
            "Step [25050/80000], d_real_loss: 0.2503, d_mnist_loss: 0.0330, d_svhn_loss: 0.2173, d_fake_loss: 0.0463, g_loss: 1.0496\n",
            "Step [25060/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0095, d_svhn_loss: 0.0381, d_fake_loss: 0.1563, g_loss: 1.3019\n",
            "Step [25070/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0295, d_svhn_loss: 0.0264, d_fake_loss: 0.0497, g_loss: 1.0960\n",
            "Step [25080/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0301, d_svhn_loss: 0.0437, d_fake_loss: 0.0478, g_loss: 1.0899\n",
            "Step [25090/80000], d_real_loss: 0.0917, d_mnist_loss: 0.0317, d_svhn_loss: 0.0599, d_fake_loss: 0.1619, g_loss: 1.2445\n",
            "Step [25100/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0105, d_svhn_loss: 0.0445, d_fake_loss: 0.0683, g_loss: 0.8360\n",
            "Step [25110/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0102, d_svhn_loss: 0.0282, d_fake_loss: 0.0552, g_loss: 1.0963\n",
            "Step [25120/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0133, d_svhn_loss: 0.0293, d_fake_loss: 0.0413, g_loss: 1.0765\n",
            "Step [25130/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0117, d_svhn_loss: 0.0316, d_fake_loss: 0.0420, g_loss: 1.1179\n",
            "Step [25140/80000], d_real_loss: 0.0964, d_mnist_loss: 0.0491, d_svhn_loss: 0.0473, d_fake_loss: 0.0304, g_loss: 1.0474\n",
            "Step [25150/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0248, d_svhn_loss: 0.0327, d_fake_loss: 0.0447, g_loss: 1.0288\n",
            "Step [25160/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0147, d_svhn_loss: 0.0467, d_fake_loss: 0.0327, g_loss: 1.1157\n",
            "Step [25170/80000], d_real_loss: 0.1019, d_mnist_loss: 0.0163, d_svhn_loss: 0.0857, d_fake_loss: 0.0751, g_loss: 1.0206\n",
            "Step [25180/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0174, d_svhn_loss: 0.0325, d_fake_loss: 0.0915, g_loss: 1.0289\n",
            "Step [25190/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0105, d_svhn_loss: 0.0370, d_fake_loss: 0.0561, g_loss: 0.9867\n",
            "Step [25200/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0149, d_svhn_loss: 0.0280, d_fake_loss: 0.0750, g_loss: 1.2601\n",
            "Step [25210/80000], d_real_loss: 0.0695, d_mnist_loss: 0.0203, d_svhn_loss: 0.0493, d_fake_loss: 0.0398, g_loss: 1.1341\n",
            "Step [25220/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0133, d_svhn_loss: 0.0380, d_fake_loss: 0.1473, g_loss: 1.2595\n",
            "Step [25230/80000], d_real_loss: 0.1318, d_mnist_loss: 0.0118, d_svhn_loss: 0.1200, d_fake_loss: 0.0481, g_loss: 1.0048\n",
            "Step [25240/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0110, d_svhn_loss: 0.0617, d_fake_loss: 0.0775, g_loss: 1.2137\n",
            "Step [25250/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0151, d_svhn_loss: 0.0484, d_fake_loss: 0.0332, g_loss: 1.0642\n",
            "Step [25260/80000], d_real_loss: 0.1006, d_mnist_loss: 0.0590, d_svhn_loss: 0.0416, d_fake_loss: 0.0721, g_loss: 1.0444\n",
            "Step [25270/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0232, d_svhn_loss: 0.0204, d_fake_loss: 0.0366, g_loss: 1.2128\n",
            "Step [25280/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0154, d_svhn_loss: 0.0560, d_fake_loss: 0.1796, g_loss: 0.8799\n",
            "Step [25290/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0109, d_svhn_loss: 0.0544, d_fake_loss: 0.0638, g_loss: 1.0539\n",
            "Step [25300/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0239, d_svhn_loss: 0.0260, d_fake_loss: 0.0405, g_loss: 1.0622\n",
            "Step [25310/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0119, d_svhn_loss: 0.0249, d_fake_loss: 0.0598, g_loss: 1.1889\n",
            "Step [25320/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0108, d_svhn_loss: 0.0449, d_fake_loss: 0.0384, g_loss: 1.1978\n",
            "Step [25330/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0367, d_svhn_loss: 0.0446, d_fake_loss: 0.0913, g_loss: 0.7683\n",
            "Step [25340/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0093, d_svhn_loss: 0.0347, d_fake_loss: 0.0237, g_loss: 1.1159\n",
            "Step [25350/80000], d_real_loss: 0.1175, d_mnist_loss: 0.0205, d_svhn_loss: 0.0970, d_fake_loss: 0.0717, g_loss: 0.9692\n",
            "Step [25360/80000], d_real_loss: 0.2121, d_mnist_loss: 0.0215, d_svhn_loss: 0.1906, d_fake_loss: 0.2110, g_loss: 1.1830\n",
            "Step [25370/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0249, d_svhn_loss: 0.0503, d_fake_loss: 0.0865, g_loss: 1.2339\n",
            "Step [25380/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0117, d_svhn_loss: 0.0251, d_fake_loss: 0.0833, g_loss: 1.2373\n",
            "Step [25390/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0150, d_svhn_loss: 0.0620, d_fake_loss: 0.0296, g_loss: 1.1865\n",
            "Step [25400/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0088, d_svhn_loss: 0.0514, d_fake_loss: 0.0487, g_loss: 1.1418\n",
            "Step [25410/80000], d_real_loss: 0.0827, d_mnist_loss: 0.0120, d_svhn_loss: 0.0707, d_fake_loss: 0.0788, g_loss: 1.1219\n",
            "Step [25420/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0478, d_svhn_loss: 0.0396, d_fake_loss: 0.0584, g_loss: 1.2035\n",
            "Step [25430/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0330, d_svhn_loss: 0.0362, d_fake_loss: 0.0738, g_loss: 1.0907\n",
            "Step [25440/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0092, d_svhn_loss: 0.0421, d_fake_loss: 0.1638, g_loss: 0.8062\n",
            "Step [25450/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0098, d_svhn_loss: 0.0380, d_fake_loss: 0.0547, g_loss: 1.1233\n",
            "Step [25460/80000], d_real_loss: 0.1647, d_mnist_loss: 0.0345, d_svhn_loss: 0.1302, d_fake_loss: 0.1350, g_loss: 0.8069\n",
            "Step [25470/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0092, d_svhn_loss: 0.0230, d_fake_loss: 0.0392, g_loss: 1.1474\n",
            "Step [25480/80000], d_real_loss: 0.0687, d_mnist_loss: 0.0245, d_svhn_loss: 0.0441, d_fake_loss: 0.0421, g_loss: 1.1896\n",
            "Step [25490/80000], d_real_loss: 0.0921, d_mnist_loss: 0.0154, d_svhn_loss: 0.0767, d_fake_loss: 0.0663, g_loss: 1.0852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9998681545257568, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [25500/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0094, d_svhn_loss: 0.0351, d_fake_loss: 0.0402, g_loss: 1.1407\n",
            "saved ./samples_fashion/sample-25500-m-s.png\n",
            "saved ./samples_fashion/sample-25500-s-m.png\n",
            "Step [25510/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0137, d_svhn_loss: 0.0594, d_fake_loss: 0.0736, g_loss: 1.2014\n",
            "Step [25520/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0280, d_svhn_loss: 0.0420, d_fake_loss: 0.0729, g_loss: 1.1123\n",
            "Step [25530/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0079, d_svhn_loss: 0.0216, d_fake_loss: 0.0663, g_loss: 1.0680\n",
            "Step [25540/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0110, d_svhn_loss: 0.0371, d_fake_loss: 0.1034, g_loss: 1.1296\n",
            "Step [25550/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0544, d_svhn_loss: 0.0298, d_fake_loss: 0.0620, g_loss: 1.0362\n",
            "Step [25560/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0339, d_svhn_loss: 0.0415, d_fake_loss: 0.0458, g_loss: 1.2668\n",
            "Step [25570/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0148, d_svhn_loss: 0.0176, d_fake_loss: 0.0534, g_loss: 1.2211\n",
            "Step [25580/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0154, d_svhn_loss: 0.0534, d_fake_loss: 0.0597, g_loss: 1.1590\n",
            "Step [25590/80000], d_real_loss: 0.1025, d_mnist_loss: 0.0812, d_svhn_loss: 0.0213, d_fake_loss: 0.0427, g_loss: 1.1764\n",
            "Step [25600/80000], d_real_loss: 0.1000, d_mnist_loss: 0.0088, d_svhn_loss: 0.0912, d_fake_loss: 0.0761, g_loss: 1.1280\n",
            "Step [25610/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0216, d_svhn_loss: 0.0247, d_fake_loss: 0.0698, g_loss: 1.3549\n",
            "Step [25620/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0275, d_svhn_loss: 0.0256, d_fake_loss: 0.0832, g_loss: 1.0306\n",
            "Step [25630/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0210, d_svhn_loss: 0.0521, d_fake_loss: 0.0768, g_loss: 1.2706\n",
            "Step [25640/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0100, d_svhn_loss: 0.0266, d_fake_loss: 0.1104, g_loss: 1.1893\n",
            "Step [25650/80000], d_real_loss: 0.0799, d_mnist_loss: 0.0193, d_svhn_loss: 0.0606, d_fake_loss: 0.0475, g_loss: 1.2160\n",
            "Step [25660/80000], d_real_loss: 0.1870, d_mnist_loss: 0.0140, d_svhn_loss: 0.1730, d_fake_loss: 0.0779, g_loss: 1.1089\n",
            "Step [25670/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0116, d_svhn_loss: 0.0236, d_fake_loss: 0.0317, g_loss: 1.1133\n",
            "Step [25680/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0198, d_svhn_loss: 0.0346, d_fake_loss: 0.0506, g_loss: 1.1230\n",
            "Step [25690/80000], d_real_loss: 0.1608, d_mnist_loss: 0.0132, d_svhn_loss: 0.1476, d_fake_loss: 0.2861, g_loss: 0.7790\n",
            "Step [25700/80000], d_real_loss: 0.1122, d_mnist_loss: 0.0203, d_svhn_loss: 0.0919, d_fake_loss: 0.0763, g_loss: 1.0417\n",
            "Step [25710/80000], d_real_loss: 0.0948, d_mnist_loss: 0.0095, d_svhn_loss: 0.0854, d_fake_loss: 0.0932, g_loss: 1.0659\n",
            "Step [25720/80000], d_real_loss: 0.1001, d_mnist_loss: 0.0366, d_svhn_loss: 0.0635, d_fake_loss: 0.0331, g_loss: 1.0197\n",
            "Step [25730/80000], d_real_loss: 0.1483, d_mnist_loss: 0.0145, d_svhn_loss: 0.1338, d_fake_loss: 0.1017, g_loss: 1.2509\n",
            "Step [25740/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0101, d_svhn_loss: 0.0257, d_fake_loss: 0.0334, g_loss: 1.0034\n",
            "Step [25750/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0117, d_svhn_loss: 0.0445, d_fake_loss: 0.1575, g_loss: 0.6759\n",
            "Step [25760/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0231, d_svhn_loss: 0.0291, d_fake_loss: 0.0738, g_loss: 1.0932\n",
            "Step [25770/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0128, d_svhn_loss: 0.0353, d_fake_loss: 0.0495, g_loss: 1.2556\n",
            "Step [25780/80000], d_real_loss: 0.0926, d_mnist_loss: 0.0564, d_svhn_loss: 0.0362, d_fake_loss: 0.0707, g_loss: 0.8335\n",
            "Step [25790/80000], d_real_loss: 0.0854, d_mnist_loss: 0.0171, d_svhn_loss: 0.0683, d_fake_loss: 0.0871, g_loss: 0.9622\n",
            "Step [25800/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0147, d_svhn_loss: 0.0286, d_fake_loss: 0.0737, g_loss: 1.2478\n",
            "Step [25810/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0099, d_svhn_loss: 0.0671, d_fake_loss: 0.0422, g_loss: 1.0677\n",
            "Step [25820/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0166, d_svhn_loss: 0.0621, d_fake_loss: 0.0496, g_loss: 1.1362\n",
            "Step [25830/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0080, d_svhn_loss: 0.0559, d_fake_loss: 0.0501, g_loss: 1.0478\n",
            "Step [25840/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0080, d_svhn_loss: 0.0546, d_fake_loss: 0.0770, g_loss: 1.3416\n",
            "Step [25850/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0105, d_svhn_loss: 0.0615, d_fake_loss: 0.0446, g_loss: 1.0769\n",
            "Step [25860/80000], d_real_loss: 0.1021, d_mnist_loss: 0.0126, d_svhn_loss: 0.0895, d_fake_loss: 0.1214, g_loss: 1.0552\n",
            "Step [25870/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0110, d_svhn_loss: 0.0514, d_fake_loss: 0.0622, g_loss: 1.1806\n",
            "Step [25880/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0116, d_svhn_loss: 0.0285, d_fake_loss: 0.0523, g_loss: 1.2716\n",
            "Step [25890/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0116, d_svhn_loss: 0.0224, d_fake_loss: 0.0395, g_loss: 1.2135\n",
            "Step [25900/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0118, d_svhn_loss: 0.0296, d_fake_loss: 0.0393, g_loss: 1.0285\n",
            "Step [25910/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0157, d_svhn_loss: 0.0415, d_fake_loss: 0.0646, g_loss: 1.2263\n",
            "Step [25920/80000], d_real_loss: 0.0992, d_mnist_loss: 0.0270, d_svhn_loss: 0.0722, d_fake_loss: 0.0577, g_loss: 1.0176\n",
            "Step [25930/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0089, d_svhn_loss: 0.0244, d_fake_loss: 0.0478, g_loss: 1.1270\n",
            "Step [25940/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0067, d_svhn_loss: 0.0314, d_fake_loss: 0.0499, g_loss: 1.0281\n",
            "Step [25950/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0086, d_svhn_loss: 0.0253, d_fake_loss: 0.1022, g_loss: 1.0856\n",
            "Step [25960/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0290, d_svhn_loss: 0.0259, d_fake_loss: 0.0675, g_loss: 1.3274\n",
            "Step [25970/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0263, d_svhn_loss: 0.0494, d_fake_loss: 0.2975, g_loss: 1.5401\n",
            "Step [25980/80000], d_real_loss: 0.2382, d_mnist_loss: 0.0225, d_svhn_loss: 0.2157, d_fake_loss: 0.1117, g_loss: 1.0616\n",
            "Step [25990/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0173, d_svhn_loss: 0.0447, d_fake_loss: 0.0399, g_loss: 1.1059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9998406767845154, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [26000/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0227, d_svhn_loss: 0.0281, d_fake_loss: 0.0439, g_loss: 1.1462\n",
            "saved ./samples_fashion/sample-26000-m-s.png\n",
            "saved ./samples_fashion/sample-26000-s-m.png\n",
            "Step [26010/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0344, d_svhn_loss: 0.0339, d_fake_loss: 0.0362, g_loss: 1.2151\n",
            "Step [26020/80000], d_real_loss: 0.1778, d_mnist_loss: 0.0113, d_svhn_loss: 0.1665, d_fake_loss: 0.1843, g_loss: 1.4800\n",
            "Step [26030/80000], d_real_loss: 0.1033, d_mnist_loss: 0.0122, d_svhn_loss: 0.0911, d_fake_loss: 0.0397, g_loss: 1.1166\n",
            "Step [26040/80000], d_real_loss: 0.0887, d_mnist_loss: 0.0209, d_svhn_loss: 0.0678, d_fake_loss: 0.0913, g_loss: 1.3589\n",
            "Step [26050/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0112, d_svhn_loss: 0.0426, d_fake_loss: 0.0418, g_loss: 1.0143\n",
            "Step [26060/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0200, d_svhn_loss: 0.0339, d_fake_loss: 0.0935, g_loss: 1.1767\n",
            "Step [26070/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0183, d_svhn_loss: 0.0215, d_fake_loss: 0.0510, g_loss: 0.8644\n",
            "Step [26080/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0067, d_svhn_loss: 0.0354, d_fake_loss: 0.0301, g_loss: 1.1024\n",
            "Step [26090/80000], d_real_loss: 0.1596, d_mnist_loss: 0.0546, d_svhn_loss: 0.1050, d_fake_loss: 0.1662, g_loss: 1.2656\n",
            "Step [26100/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0225, d_svhn_loss: 0.0603, d_fake_loss: 0.0348, g_loss: 0.9761\n",
            "Step [26110/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0133, d_svhn_loss: 0.0385, d_fake_loss: 0.1074, g_loss: 1.0905\n",
            "Step [26120/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0138, d_svhn_loss: 0.0623, d_fake_loss: 0.0691, g_loss: 1.1937\n",
            "Step [26130/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0190, d_svhn_loss: 0.0298, d_fake_loss: 0.0432, g_loss: 1.1147\n",
            "Step [26140/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0087, d_svhn_loss: 0.0280, d_fake_loss: 0.0805, g_loss: 1.1421\n",
            "Step [26150/80000], d_real_loss: 0.1116, d_mnist_loss: 0.0418, d_svhn_loss: 0.0698, d_fake_loss: 0.0721, g_loss: 1.7622\n",
            "Step [26160/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0093, d_svhn_loss: 0.0305, d_fake_loss: 0.1306, g_loss: 1.2256\n",
            "Step [26170/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0265, d_svhn_loss: 0.0223, d_fake_loss: 0.0901, g_loss: 1.1282\n",
            "Step [26180/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0156, d_svhn_loss: 0.0186, d_fake_loss: 0.0841, g_loss: 1.2129\n",
            "Step [26190/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0106, d_svhn_loss: 0.0254, d_fake_loss: 0.0555, g_loss: 1.1526\n",
            "Step [26200/80000], d_real_loss: 0.1029, d_mnist_loss: 0.0146, d_svhn_loss: 0.0884, d_fake_loss: 0.0567, g_loss: 1.1629\n",
            "Step [26210/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0137, d_svhn_loss: 0.0491, d_fake_loss: 0.0917, g_loss: 1.1112\n",
            "Step [26220/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0187, d_svhn_loss: 0.0307, d_fake_loss: 0.0289, g_loss: 1.1123\n",
            "Step [26230/80000], d_real_loss: 0.1050, d_mnist_loss: 0.0076, d_svhn_loss: 0.0975, d_fake_loss: 0.2478, g_loss: 1.2719\n",
            "Step [26240/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0129, d_svhn_loss: 0.0590, d_fake_loss: 0.0654, g_loss: 1.1611\n",
            "Step [26250/80000], d_real_loss: 0.1086, d_mnist_loss: 0.0141, d_svhn_loss: 0.0946, d_fake_loss: 0.0610, g_loss: 1.1853\n",
            "Step [26260/80000], d_real_loss: 0.0947, d_mnist_loss: 0.0207, d_svhn_loss: 0.0740, d_fake_loss: 0.0799, g_loss: 1.0524\n",
            "Step [26270/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0318, d_svhn_loss: 0.0375, d_fake_loss: 0.1038, g_loss: 1.1667\n",
            "Step [26280/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0171, d_svhn_loss: 0.0624, d_fake_loss: 0.0484, g_loss: 1.0547\n",
            "Step [26290/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0632, d_svhn_loss: 0.0235, d_fake_loss: 0.0841, g_loss: 0.9479\n",
            "Step [26300/80000], d_real_loss: 0.0701, d_mnist_loss: 0.0118, d_svhn_loss: 0.0582, d_fake_loss: 0.0315, g_loss: 1.1496\n",
            "Step [26310/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0098, d_svhn_loss: 0.0739, d_fake_loss: 0.1004, g_loss: 0.9598\n",
            "Step [26320/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0124, d_svhn_loss: 0.0320, d_fake_loss: 0.1399, g_loss: 1.3579\n",
            "Step [26330/80000], d_real_loss: 0.1285, d_mnist_loss: 0.0088, d_svhn_loss: 0.1197, d_fake_loss: 0.0742, g_loss: 1.1735\n",
            "Step [26340/80000], d_real_loss: 0.1334, d_mnist_loss: 0.0084, d_svhn_loss: 0.1250, d_fake_loss: 0.0913, g_loss: 1.2536\n",
            "Step [26350/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0091, d_svhn_loss: 0.0377, d_fake_loss: 0.0626, g_loss: 1.0747\n",
            "Step [26360/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0095, d_svhn_loss: 0.0581, d_fake_loss: 0.0754, g_loss: 0.9221\n",
            "Step [26370/80000], d_real_loss: 0.1178, d_mnist_loss: 0.0800, d_svhn_loss: 0.0378, d_fake_loss: 0.0695, g_loss: 1.1067\n",
            "Step [26380/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0115, d_svhn_loss: 0.0441, d_fake_loss: 0.1062, g_loss: 1.1190\n",
            "Step [26390/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0304, d_svhn_loss: 0.0401, d_fake_loss: 0.0271, g_loss: 1.0683\n",
            "Step [26400/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0099, d_svhn_loss: 0.0260, d_fake_loss: 0.0320, g_loss: 1.1059\n",
            "Step [26410/80000], d_real_loss: 0.0796, d_mnist_loss: 0.0242, d_svhn_loss: 0.0554, d_fake_loss: 0.1148, g_loss: 1.0296\n",
            "Step [26420/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0098, d_svhn_loss: 0.0257, d_fake_loss: 0.0845, g_loss: 1.1149\n",
            "Step [26430/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0201, d_svhn_loss: 0.0290, d_fake_loss: 0.0505, g_loss: 1.0918\n",
            "Step [26440/80000], d_real_loss: 0.1459, d_mnist_loss: 0.0296, d_svhn_loss: 0.1163, d_fake_loss: 0.1536, g_loss: 1.4726\n",
            "Step [26450/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0083, d_svhn_loss: 0.0307, d_fake_loss: 0.0578, g_loss: 1.1112\n",
            "Step [26460/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0127, d_svhn_loss: 0.0227, d_fake_loss: 0.0415, g_loss: 1.0270\n",
            "Step [26470/80000], d_real_loss: 0.1354, d_mnist_loss: 0.0407, d_svhn_loss: 0.0947, d_fake_loss: 0.1144, g_loss: 1.2035\n",
            "Step [26480/80000], d_real_loss: 0.1443, d_mnist_loss: 0.1124, d_svhn_loss: 0.0318, d_fake_loss: 0.1577, g_loss: 1.9773\n",
            "Step [26490/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0283, d_svhn_loss: 0.0393, d_fake_loss: 0.0559, g_loss: 1.1170\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999921321868896, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [26500/80000], d_real_loss: 0.1642, d_mnist_loss: 0.0178, d_svhn_loss: 0.1463, d_fake_loss: 0.1590, g_loss: 1.0649\n",
            "saved ./samples_fashion/sample-26500-m-s.png\n",
            "saved ./samples_fashion/sample-26500-s-m.png\n",
            "Step [26510/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0158, d_svhn_loss: 0.0333, d_fake_loss: 0.0494, g_loss: 1.1510\n",
            "Step [26520/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0093, d_svhn_loss: 0.0450, d_fake_loss: 0.0524, g_loss: 1.1028\n",
            "Step [26530/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0131, d_svhn_loss: 0.0235, d_fake_loss: 0.0333, g_loss: 1.1580\n",
            "Step [26540/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0148, d_svhn_loss: 0.0216, d_fake_loss: 0.0426, g_loss: 1.1339\n",
            "Step [26550/80000], d_real_loss: 0.0907, d_mnist_loss: 0.0459, d_svhn_loss: 0.0448, d_fake_loss: 0.0542, g_loss: 1.0710\n",
            "Step [26560/80000], d_real_loss: 0.1297, d_mnist_loss: 0.0075, d_svhn_loss: 0.1221, d_fake_loss: 0.0906, g_loss: 1.1089\n",
            "Step [26570/80000], d_real_loss: 0.0746, d_mnist_loss: 0.0100, d_svhn_loss: 0.0646, d_fake_loss: 0.0846, g_loss: 1.0509\n",
            "Step [26580/80000], d_real_loss: 0.0924, d_mnist_loss: 0.0457, d_svhn_loss: 0.0468, d_fake_loss: 0.1095, g_loss: 1.2111\n",
            "Step [26590/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0470, d_svhn_loss: 0.0222, d_fake_loss: 0.0840, g_loss: 1.2213\n",
            "Step [26600/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0076, d_svhn_loss: 0.0242, d_fake_loss: 0.0601, g_loss: 1.0606\n",
            "Step [26610/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0180, d_svhn_loss: 0.0288, d_fake_loss: 0.0516, g_loss: 1.0861\n",
            "Step [26620/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0177, d_svhn_loss: 0.0392, d_fake_loss: 0.0867, g_loss: 1.0825\n",
            "Step [26630/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0144, d_svhn_loss: 0.0343, d_fake_loss: 0.0773, g_loss: 1.2309\n",
            "Step [26640/80000], d_real_loss: 0.0757, d_mnist_loss: 0.0098, d_svhn_loss: 0.0659, d_fake_loss: 0.0593, g_loss: 1.1647\n",
            "Step [26650/80000], d_real_loss: 0.1636, d_mnist_loss: 0.0134, d_svhn_loss: 0.1501, d_fake_loss: 0.0279, g_loss: 1.1711\n",
            "Step [26660/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0071, d_svhn_loss: 0.0268, d_fake_loss: 0.0925, g_loss: 1.3766\n",
            "Step [26670/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0098, d_svhn_loss: 0.0227, d_fake_loss: 0.1121, g_loss: 1.1242\n",
            "Step [26680/80000], d_real_loss: 0.1090, d_mnist_loss: 0.0256, d_svhn_loss: 0.0834, d_fake_loss: 0.1412, g_loss: 1.1422\n",
            "Step [26690/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0113, d_svhn_loss: 0.0377, d_fake_loss: 0.1339, g_loss: 1.1800\n",
            "Step [26700/80000], d_real_loss: 0.0954, d_mnist_loss: 0.0140, d_svhn_loss: 0.0815, d_fake_loss: 0.1539, g_loss: 0.9846\n",
            "Step [26710/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0142, d_svhn_loss: 0.0451, d_fake_loss: 0.1029, g_loss: 1.1858\n",
            "Step [26720/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0110, d_svhn_loss: 0.0446, d_fake_loss: 0.1429, g_loss: 1.3641\n",
            "Step [26730/80000], d_real_loss: 0.1019, d_mnist_loss: 0.0085, d_svhn_loss: 0.0934, d_fake_loss: 0.1180, g_loss: 1.1824\n",
            "Step [26740/80000], d_real_loss: 0.0865, d_mnist_loss: 0.0391, d_svhn_loss: 0.0473, d_fake_loss: 0.1040, g_loss: 1.0919\n",
            "Step [26750/80000], d_real_loss: 0.0984, d_mnist_loss: 0.0246, d_svhn_loss: 0.0738, d_fake_loss: 0.0275, g_loss: 1.0061\n",
            "Step [26760/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0472, d_svhn_loss: 0.0227, d_fake_loss: 0.0489, g_loss: 1.2759\n",
            "Step [26770/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0158, d_svhn_loss: 0.0476, d_fake_loss: 0.0877, g_loss: 1.0370\n",
            "Step [26780/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0110, d_svhn_loss: 0.0424, d_fake_loss: 0.0415, g_loss: 1.1251\n",
            "Step [26790/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0094, d_svhn_loss: 0.0392, d_fake_loss: 0.0641, g_loss: 1.1015\n",
            "Step [26800/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0135, d_svhn_loss: 0.0595, d_fake_loss: 0.1438, g_loss: 0.9687\n",
            "Step [26810/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0289, d_svhn_loss: 0.0431, d_fake_loss: 0.0427, g_loss: 1.0169\n",
            "Step [26820/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0150, d_svhn_loss: 0.0353, d_fake_loss: 0.0789, g_loss: 1.2013\n",
            "Step [26830/80000], d_real_loss: 0.0794, d_mnist_loss: 0.0114, d_svhn_loss: 0.0680, d_fake_loss: 0.1418, g_loss: 0.9072\n",
            "Step [26840/80000], d_real_loss: 0.0288, d_mnist_loss: 0.0101, d_svhn_loss: 0.0187, d_fake_loss: 0.0433, g_loss: 1.1606\n",
            "Step [26850/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0114, d_svhn_loss: 0.0220, d_fake_loss: 0.0523, g_loss: 1.0296\n",
            "Step [26860/80000], d_real_loss: 0.1073, d_mnist_loss: 0.0805, d_svhn_loss: 0.0267, d_fake_loss: 0.0394, g_loss: 1.1874\n",
            "Step [26870/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0097, d_svhn_loss: 0.0294, d_fake_loss: 0.0429, g_loss: 1.1082\n",
            "Step [26880/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0122, d_svhn_loss: 0.0517, d_fake_loss: 0.0793, g_loss: 1.1740\n",
            "Step [26890/80000], d_real_loss: 0.0887, d_mnist_loss: 0.0128, d_svhn_loss: 0.0759, d_fake_loss: 0.0730, g_loss: 1.1174\n",
            "Step [26900/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0087, d_svhn_loss: 0.0678, d_fake_loss: 0.0927, g_loss: 1.1337\n",
            "Step [26910/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0172, d_svhn_loss: 0.0302, d_fake_loss: 0.0352, g_loss: 0.9941\n",
            "Step [26920/80000], d_real_loss: 0.6821, d_mnist_loss: 0.6489, d_svhn_loss: 0.0332, d_fake_loss: 0.1502, g_loss: 1.4479\n",
            "Step [26930/80000], d_real_loss: 0.1603, d_mnist_loss: 0.0274, d_svhn_loss: 0.1329, d_fake_loss: 0.1189, g_loss: 1.1093\n",
            "Step [26940/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0112, d_svhn_loss: 0.0503, d_fake_loss: 0.0925, g_loss: 1.0373\n",
            "Step [26950/80000], d_real_loss: 0.1160, d_mnist_loss: 0.0824, d_svhn_loss: 0.0335, d_fake_loss: 0.0663, g_loss: 1.0810\n",
            "Step [26960/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0244, d_svhn_loss: 0.0266, d_fake_loss: 0.0840, g_loss: 1.0733\n",
            "Step [26970/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0091, d_svhn_loss: 0.0330, d_fake_loss: 0.0683, g_loss: 1.1078\n",
            "Step [26980/80000], d_real_loss: 0.0908, d_mnist_loss: 0.0127, d_svhn_loss: 0.0781, d_fake_loss: 0.0527, g_loss: 0.9185\n",
            "Step [26990/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0294, d_svhn_loss: 0.0585, d_fake_loss: 0.0789, g_loss: 0.9719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [27000/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0150, d_svhn_loss: 0.0280, d_fake_loss: 0.0318, g_loss: 1.0878\n",
            "saved ./samples_fashion/sample-27000-m-s.png\n",
            "saved ./samples_fashion/sample-27000-s-m.png\n",
            "Step [27010/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0138, d_svhn_loss: 0.0331, d_fake_loss: 0.0451, g_loss: 1.1756\n",
            "Step [27020/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0226, d_svhn_loss: 0.0305, d_fake_loss: 0.0396, g_loss: 1.0399\n",
            "Step [27030/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0083, d_svhn_loss: 0.0418, d_fake_loss: 0.0713, g_loss: 1.2113\n",
            "Step [27040/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0081, d_svhn_loss: 0.0597, d_fake_loss: 0.0400, g_loss: 1.0338\n",
            "Step [27050/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0338, d_svhn_loss: 0.0289, d_fake_loss: 0.0448, g_loss: 1.1191\n",
            "Step [27060/80000], d_real_loss: 0.1016, d_mnist_loss: 0.0207, d_svhn_loss: 0.0809, d_fake_loss: 0.0439, g_loss: 1.1418\n",
            "Step [27070/80000], d_real_loss: 0.1086, d_mnist_loss: 0.0348, d_svhn_loss: 0.0737, d_fake_loss: 0.1623, g_loss: 1.2199\n",
            "Step [27080/80000], d_real_loss: 0.0826, d_mnist_loss: 0.0561, d_svhn_loss: 0.0265, d_fake_loss: 0.0556, g_loss: 1.0169\n",
            "Step [27090/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0099, d_svhn_loss: 0.0398, d_fake_loss: 0.0370, g_loss: 1.0826\n",
            "Step [27100/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0090, d_svhn_loss: 0.0236, d_fake_loss: 0.0681, g_loss: 1.2702\n",
            "Step [27110/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0416, d_svhn_loss: 0.0386, d_fake_loss: 0.0375, g_loss: 1.0437\n",
            "Step [27120/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0066, d_svhn_loss: 0.0309, d_fake_loss: 0.0387, g_loss: 1.1138\n",
            "Step [27130/80000], d_real_loss: 0.0920, d_mnist_loss: 0.0214, d_svhn_loss: 0.0706, d_fake_loss: 0.0680, g_loss: 1.0806\n",
            "Step [27140/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0170, d_svhn_loss: 0.0167, d_fake_loss: 0.0467, g_loss: 1.0213\n",
            "Step [27150/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0086, d_svhn_loss: 0.0326, d_fake_loss: 0.0458, g_loss: 1.2473\n",
            "Step [27160/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0140, d_svhn_loss: 0.0248, d_fake_loss: 0.0397, g_loss: 1.1618\n",
            "Step [27170/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0285, d_svhn_loss: 0.0351, d_fake_loss: 0.0451, g_loss: 1.0283\n",
            "Step [27180/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0201, d_svhn_loss: 0.0334, d_fake_loss: 0.0360, g_loss: 1.0252\n",
            "Step [27190/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0332, d_svhn_loss: 0.0245, d_fake_loss: 0.0435, g_loss: 1.1285\n",
            "Step [27200/80000], d_real_loss: 0.0698, d_mnist_loss: 0.0121, d_svhn_loss: 0.0577, d_fake_loss: 0.0638, g_loss: 1.1544\n",
            "Step [27210/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0137, d_svhn_loss: 0.0406, d_fake_loss: 0.0396, g_loss: 1.0715\n",
            "Step [27220/80000], d_real_loss: 0.1037, d_mnist_loss: 0.0102, d_svhn_loss: 0.0935, d_fake_loss: 0.0740, g_loss: 0.9285\n",
            "Step [27230/80000], d_real_loss: 0.1045, d_mnist_loss: 0.0467, d_svhn_loss: 0.0578, d_fake_loss: 0.0459, g_loss: 1.2553\n",
            "Step [27240/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0397, d_svhn_loss: 0.0433, d_fake_loss: 0.0695, g_loss: 1.2787\n",
            "Step [27250/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0108, d_svhn_loss: 0.0462, d_fake_loss: 0.0417, g_loss: 1.1165\n",
            "Step [27260/80000], d_real_loss: 0.1243, d_mnist_loss: 0.0941, d_svhn_loss: 0.0302, d_fake_loss: 0.0283, g_loss: 1.0429\n",
            "Step [27270/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0178, d_svhn_loss: 0.0438, d_fake_loss: 0.1082, g_loss: 1.3403\n",
            "Step [27280/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0082, d_svhn_loss: 0.0390, d_fake_loss: 0.0328, g_loss: 1.2446\n",
            "Step [27290/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0142, d_svhn_loss: 0.0382, d_fake_loss: 0.0821, g_loss: 0.8572\n",
            "Step [27300/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0371, d_svhn_loss: 0.0368, d_fake_loss: 0.1073, g_loss: 1.2023\n",
            "Step [27310/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0073, d_svhn_loss: 0.0254, d_fake_loss: 0.1023, g_loss: 1.2023\n",
            "Step [27320/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0116, d_svhn_loss: 0.0293, d_fake_loss: 0.0297, g_loss: 1.2800\n",
            "Step [27330/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0132, d_svhn_loss: 0.0471, d_fake_loss: 0.0456, g_loss: 1.0541\n",
            "Step [27340/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0251, d_svhn_loss: 0.0289, d_fake_loss: 0.0767, g_loss: 1.1809\n",
            "Step [27350/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0311, d_svhn_loss: 0.0471, d_fake_loss: 0.0774, g_loss: 1.2821\n",
            "Step [27360/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0156, d_svhn_loss: 0.0393, d_fake_loss: 0.0612, g_loss: 1.1412\n",
            "Step [27370/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0257, d_svhn_loss: 0.0432, d_fake_loss: 0.0650, g_loss: 1.0542\n",
            "Step [27380/80000], d_real_loss: 0.1594, d_mnist_loss: 0.0143, d_svhn_loss: 0.1451, d_fake_loss: 0.0620, g_loss: 1.0680\n",
            "Step [27390/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0242, d_svhn_loss: 0.0360, d_fake_loss: 0.0595, g_loss: 1.1203\n",
            "Step [27400/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0111, d_svhn_loss: 0.0412, d_fake_loss: 0.0263, g_loss: 1.1295\n",
            "Step [27410/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0127, d_svhn_loss: 0.0272, d_fake_loss: 0.0498, g_loss: 1.2227\n",
            "Step [27420/80000], d_real_loss: 0.1934, d_mnist_loss: 0.0119, d_svhn_loss: 0.1815, d_fake_loss: 0.1045, g_loss: 1.2222\n",
            "Step [27430/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0102, d_svhn_loss: 0.0485, d_fake_loss: 0.1251, g_loss: 1.2234\n",
            "Step [27440/80000], d_real_loss: 0.1422, d_mnist_loss: 0.0385, d_svhn_loss: 0.1037, d_fake_loss: 0.0638, g_loss: 0.8723\n",
            "Step [27450/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0274, d_svhn_loss: 0.0260, d_fake_loss: 0.0656, g_loss: 1.3325\n",
            "Step [27460/80000], d_real_loss: 0.0871, d_mnist_loss: 0.0528, d_svhn_loss: 0.0344, d_fake_loss: 0.0478, g_loss: 0.9995\n",
            "Step [27470/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0156, d_svhn_loss: 0.0314, d_fake_loss: 0.1059, g_loss: 1.1668\n",
            "Step [27480/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0118, d_svhn_loss: 0.0560, d_fake_loss: 0.0247, g_loss: 1.1306\n",
            "Step [27490/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0090, d_svhn_loss: 0.0640, d_fake_loss: 0.0894, g_loss: 1.0904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999916553497314, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [27500/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0301, d_svhn_loss: 0.0462, d_fake_loss: 0.0383, g_loss: 1.0566\n",
            "saved ./samples_fashion/sample-27500-m-s.png\n",
            "saved ./samples_fashion/sample-27500-s-m.png\n",
            "Step [27510/80000], d_real_loss: 0.1201, d_mnist_loss: 0.0122, d_svhn_loss: 0.1078, d_fake_loss: 0.0555, g_loss: 1.0579\n",
            "Step [27520/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0260, d_svhn_loss: 0.0183, d_fake_loss: 0.0628, g_loss: 1.1906\n",
            "Step [27530/80000], d_real_loss: 0.1830, d_mnist_loss: 0.0677, d_svhn_loss: 0.1153, d_fake_loss: 0.1071, g_loss: 1.1941\n",
            "Step [27540/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0163, d_svhn_loss: 0.0238, d_fake_loss: 0.0603, g_loss: 1.1978\n",
            "Step [27550/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0515, d_svhn_loss: 0.0296, d_fake_loss: 0.0334, g_loss: 1.0702\n",
            "Step [27560/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0365, d_svhn_loss: 0.0312, d_fake_loss: 0.0346, g_loss: 1.0210\n",
            "Step [27570/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0133, d_svhn_loss: 0.0333, d_fake_loss: 0.0432, g_loss: 1.2182\n",
            "Step [27580/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0105, d_svhn_loss: 0.0313, d_fake_loss: 0.1082, g_loss: 1.1007\n",
            "Step [27590/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0128, d_svhn_loss: 0.0313, d_fake_loss: 0.1336, g_loss: 1.3475\n",
            "Step [27600/80000], d_real_loss: 0.1587, d_mnist_loss: 0.0191, d_svhn_loss: 0.1397, d_fake_loss: 0.0937, g_loss: 0.9532\n",
            "Step [27610/80000], d_real_loss: 0.0735, d_mnist_loss: 0.0310, d_svhn_loss: 0.0425, d_fake_loss: 0.0577, g_loss: 0.9522\n",
            "Step [27620/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0371, d_svhn_loss: 0.0339, d_fake_loss: 0.0768, g_loss: 1.2299\n",
            "Step [27630/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0184, d_svhn_loss: 0.0400, d_fake_loss: 0.0636, g_loss: 0.9964\n",
            "Step [27640/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0117, d_svhn_loss: 0.0374, d_fake_loss: 0.0940, g_loss: 1.5415\n",
            "Step [27650/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0220, d_svhn_loss: 0.0228, d_fake_loss: 0.0595, g_loss: 1.0821\n",
            "Step [27660/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0106, d_svhn_loss: 0.0397, d_fake_loss: 0.0414, g_loss: 1.1248\n",
            "Step [27670/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0132, d_svhn_loss: 0.0705, d_fake_loss: 0.0632, g_loss: 1.1303\n",
            "Step [27680/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0222, d_svhn_loss: 0.0461, d_fake_loss: 0.0755, g_loss: 1.1957\n",
            "Step [27690/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0094, d_svhn_loss: 0.0555, d_fake_loss: 0.1343, g_loss: 0.8121\n",
            "Step [27700/80000], d_real_loss: 0.1680, d_mnist_loss: 0.0505, d_svhn_loss: 0.1175, d_fake_loss: 0.1113, g_loss: 1.2647\n",
            "Step [27710/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0147, d_svhn_loss: 0.0626, d_fake_loss: 0.0623, g_loss: 1.0501\n",
            "Step [27720/80000], d_real_loss: 0.0866, d_mnist_loss: 0.0141, d_svhn_loss: 0.0725, d_fake_loss: 0.0633, g_loss: 1.1910\n",
            "Step [27730/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0343, d_svhn_loss: 0.0247, d_fake_loss: 0.0676, g_loss: 1.1691\n",
            "Step [27740/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0187, d_svhn_loss: 0.0357, d_fake_loss: 0.0492, g_loss: 1.1095\n",
            "Step [27750/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0095, d_svhn_loss: 0.0561, d_fake_loss: 0.0313, g_loss: 1.1093\n",
            "Step [27760/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0152, d_svhn_loss: 0.0529, d_fake_loss: 0.0544, g_loss: 1.5297\n",
            "Step [27770/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0247, d_svhn_loss: 0.0292, d_fake_loss: 0.0826, g_loss: 1.2211\n",
            "Step [27780/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0153, d_svhn_loss: 0.0375, d_fake_loss: 0.0362, g_loss: 1.0842\n",
            "Step [27790/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0128, d_svhn_loss: 0.0212, d_fake_loss: 0.0836, g_loss: 1.0936\n",
            "Step [27800/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0077, d_svhn_loss: 0.0526, d_fake_loss: 0.1398, g_loss: 1.0541\n",
            "Step [27810/80000], d_real_loss: 0.1006, d_mnist_loss: 0.0114, d_svhn_loss: 0.0893, d_fake_loss: 0.1022, g_loss: 0.9112\n",
            "Step [27820/80000], d_real_loss: 0.0798, d_mnist_loss: 0.0101, d_svhn_loss: 0.0697, d_fake_loss: 0.0644, g_loss: 1.2700\n",
            "Step [27830/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0290, d_svhn_loss: 0.0289, d_fake_loss: 0.0533, g_loss: 1.2212\n",
            "Step [27840/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0269, d_svhn_loss: 0.0204, d_fake_loss: 0.0686, g_loss: 1.2449\n",
            "Step [27850/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0106, d_svhn_loss: 0.0193, d_fake_loss: 0.0757, g_loss: 1.3895\n",
            "Step [27860/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0261, d_svhn_loss: 0.0466, d_fake_loss: 0.0427, g_loss: 1.1770\n",
            "Step [27870/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0171, d_svhn_loss: 0.0275, d_fake_loss: 0.0352, g_loss: 0.9981\n",
            "Step [27880/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0208, d_svhn_loss: 0.0306, d_fake_loss: 0.0340, g_loss: 1.1452\n",
            "Step [27890/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0389, d_svhn_loss: 0.0179, d_fake_loss: 0.0507, g_loss: 1.1041\n",
            "Step [27900/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0096, d_svhn_loss: 0.0253, d_fake_loss: 0.0643, g_loss: 1.2526\n",
            "Step [27910/80000], d_real_loss: 0.0937, d_mnist_loss: 0.0291, d_svhn_loss: 0.0647, d_fake_loss: 0.0933, g_loss: 1.0111\n",
            "Step [27920/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0099, d_svhn_loss: 0.0730, d_fake_loss: 0.0903, g_loss: 0.8722\n",
            "Step [27930/80000], d_real_loss: 0.1462, d_mnist_loss: 0.0094, d_svhn_loss: 0.1368, d_fake_loss: 0.0791, g_loss: 1.2819\n",
            "Step [27940/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0127, d_svhn_loss: 0.0277, d_fake_loss: 0.0329, g_loss: 1.1285\n",
            "Step [27950/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0263, d_svhn_loss: 0.0271, d_fake_loss: 0.0539, g_loss: 1.2633\n",
            "Step [27960/80000], d_real_loss: 0.0897, d_mnist_loss: 0.0228, d_svhn_loss: 0.0669, d_fake_loss: 0.1377, g_loss: 0.9944\n",
            "Step [27970/80000], d_real_loss: 0.0871, d_mnist_loss: 0.0154, d_svhn_loss: 0.0718, d_fake_loss: 0.0535, g_loss: 0.9940\n",
            "Step [27980/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0154, d_svhn_loss: 0.0438, d_fake_loss: 0.0578, g_loss: 1.1982\n",
            "Step [27990/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0242, d_svhn_loss: 0.0425, d_fake_loss: 0.0376, g_loss: 1.0755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.999955952167511, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [28000/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0364, d_svhn_loss: 0.0480, d_fake_loss: 0.0508, g_loss: 1.0624\n",
            "saved ./samples_fashion/sample-28000-m-s.png\n",
            "saved ./samples_fashion/sample-28000-s-m.png\n",
            "Step [28010/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0135, d_svhn_loss: 0.0685, d_fake_loss: 0.0953, g_loss: 1.1226\n",
            "Step [28020/80000], d_real_loss: 0.1763, d_mnist_loss: 0.0092, d_svhn_loss: 0.1671, d_fake_loss: 0.0606, g_loss: 1.1459\n",
            "Step [28030/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0112, d_svhn_loss: 0.0279, d_fake_loss: 0.0906, g_loss: 1.2552\n",
            "Step [28040/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0135, d_svhn_loss: 0.0524, d_fake_loss: 0.0914, g_loss: 0.8814\n",
            "Step [28050/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0120, d_svhn_loss: 0.0406, d_fake_loss: 0.0350, g_loss: 1.1859\n",
            "Step [28060/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0170, d_svhn_loss: 0.0364, d_fake_loss: 0.0619, g_loss: 1.1078\n",
            "Step [28070/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0184, d_svhn_loss: 0.0258, d_fake_loss: 0.0891, g_loss: 1.2466\n",
            "Step [28080/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0129, d_svhn_loss: 0.0264, d_fake_loss: 0.0680, g_loss: 0.8353\n",
            "Step [28090/80000], d_real_loss: 0.1332, d_mnist_loss: 0.0230, d_svhn_loss: 0.1102, d_fake_loss: 0.1656, g_loss: 1.1189\n",
            "Step [28100/80000], d_real_loss: 0.1011, d_mnist_loss: 0.0252, d_svhn_loss: 0.0759, d_fake_loss: 0.0558, g_loss: 1.1826\n",
            "Step [28110/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0162, d_svhn_loss: 0.0506, d_fake_loss: 0.2639, g_loss: 1.2682\n",
            "Step [28120/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0092, d_svhn_loss: 0.0568, d_fake_loss: 0.1751, g_loss: 1.2087\n",
            "Step [28130/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0216, d_svhn_loss: 0.0344, d_fake_loss: 0.0321, g_loss: 1.0862\n",
            "Step [28140/80000], d_real_loss: 0.1415, d_mnist_loss: 0.0191, d_svhn_loss: 0.1224, d_fake_loss: 0.0493, g_loss: 0.9931\n",
            "Step [28150/80000], d_real_loss: 0.0821, d_mnist_loss: 0.0348, d_svhn_loss: 0.0473, d_fake_loss: 0.1180, g_loss: 1.4425\n",
            "Step [28160/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0076, d_svhn_loss: 0.0729, d_fake_loss: 0.0423, g_loss: 1.2032\n",
            "Step [28170/80000], d_real_loss: 0.1028, d_mnist_loss: 0.0310, d_svhn_loss: 0.0718, d_fake_loss: 0.1082, g_loss: 0.9734\n",
            "Step [28180/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0141, d_svhn_loss: 0.0331, d_fake_loss: 0.1253, g_loss: 1.1685\n",
            "Step [28190/80000], d_real_loss: 0.1140, d_mnist_loss: 0.0445, d_svhn_loss: 0.0695, d_fake_loss: 0.0347, g_loss: 1.1195\n",
            "Step [28200/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0176, d_svhn_loss: 0.0298, d_fake_loss: 0.0354, g_loss: 0.9707\n",
            "Step [28210/80000], d_real_loss: 0.0972, d_mnist_loss: 0.0098, d_svhn_loss: 0.0874, d_fake_loss: 0.0351, g_loss: 1.0878\n",
            "Step [28220/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0115, d_svhn_loss: 0.0524, d_fake_loss: 0.0556, g_loss: 1.0539\n",
            "Step [28230/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0077, d_svhn_loss: 0.0494, d_fake_loss: 0.0308, g_loss: 1.0810\n",
            "Step [28240/80000], d_real_loss: 0.0878, d_mnist_loss: 0.0117, d_svhn_loss: 0.0761, d_fake_loss: 0.0411, g_loss: 1.1205\n",
            "Step [28250/80000], d_real_loss: 0.0936, d_mnist_loss: 0.0198, d_svhn_loss: 0.0738, d_fake_loss: 0.1272, g_loss: 1.2328\n",
            "Step [28260/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0137, d_svhn_loss: 0.0688, d_fake_loss: 0.0641, g_loss: 1.0554\n",
            "Step [28270/80000], d_real_loss: 0.1428, d_mnist_loss: 0.1114, d_svhn_loss: 0.0314, d_fake_loss: 0.0336, g_loss: 1.2492\n",
            "Step [28280/80000], d_real_loss: 0.0947, d_mnist_loss: 0.0339, d_svhn_loss: 0.0608, d_fake_loss: 0.0305, g_loss: 1.0397\n",
            "Step [28290/80000], d_real_loss: 0.0959, d_mnist_loss: 0.0155, d_svhn_loss: 0.0804, d_fake_loss: 0.0902, g_loss: 1.1851\n",
            "Step [28300/80000], d_real_loss: 0.0881, d_mnist_loss: 0.0111, d_svhn_loss: 0.0770, d_fake_loss: 0.0773, g_loss: 1.0957\n",
            "Step [28310/80000], d_real_loss: 0.1837, d_mnist_loss: 0.0079, d_svhn_loss: 0.1758, d_fake_loss: 0.0942, g_loss: 0.9792\n",
            "Step [28320/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0144, d_svhn_loss: 0.0239, d_fake_loss: 0.0377, g_loss: 1.1899\n",
            "Step [28330/80000], d_real_loss: 0.1188, d_mnist_loss: 0.0519, d_svhn_loss: 0.0668, d_fake_loss: 0.0338, g_loss: 1.1133\n",
            "Step [28340/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0185, d_svhn_loss: 0.0363, d_fake_loss: 0.0464, g_loss: 1.0191\n",
            "Step [28350/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0238, d_svhn_loss: 0.0385, d_fake_loss: 0.0861, g_loss: 0.8643\n",
            "Step [28360/80000], d_real_loss: 0.0654, d_mnist_loss: 0.0158, d_svhn_loss: 0.0496, d_fake_loss: 0.0625, g_loss: 1.0987\n",
            "Step [28370/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0181, d_svhn_loss: 0.0355, d_fake_loss: 0.0547, g_loss: 1.1173\n",
            "Step [28380/80000], d_real_loss: 0.0735, d_mnist_loss: 0.0136, d_svhn_loss: 0.0600, d_fake_loss: 0.1058, g_loss: 1.2380\n",
            "Step [28390/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0140, d_svhn_loss: 0.0308, d_fake_loss: 0.0529, g_loss: 1.2238\n",
            "Step [28400/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0116, d_svhn_loss: 0.0246, d_fake_loss: 0.0357, g_loss: 1.0044\n",
            "Step [28410/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0110, d_svhn_loss: 0.0517, d_fake_loss: 0.0846, g_loss: 1.1347\n",
            "Step [28420/80000], d_real_loss: 0.0794, d_mnist_loss: 0.0361, d_svhn_loss: 0.0432, d_fake_loss: 0.0847, g_loss: 1.2721\n",
            "Step [28430/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0224, d_svhn_loss: 0.0306, d_fake_loss: 0.0533, g_loss: 1.0177\n",
            "Step [28440/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0208, d_svhn_loss: 0.0684, d_fake_loss: 0.0392, g_loss: 1.0525\n",
            "Step [28450/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0112, d_svhn_loss: 0.0321, d_fake_loss: 0.0477, g_loss: 1.0857\n",
            "Step [28460/80000], d_real_loss: 0.1340, d_mnist_loss: 0.0126, d_svhn_loss: 0.1214, d_fake_loss: 0.0472, g_loss: 1.1894\n",
            "Step [28470/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0103, d_svhn_loss: 0.0501, d_fake_loss: 0.0882, g_loss: 0.9129\n",
            "Step [28480/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0141, d_svhn_loss: 0.0343, d_fake_loss: 0.0588, g_loss: 1.2131\n",
            "Step [28490/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0550, d_svhn_loss: 0.0400, d_fake_loss: 0.0670, g_loss: 1.3019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999130964279175, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [28500/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0076, d_svhn_loss: 0.0238, d_fake_loss: 0.0475, g_loss: 1.0495\n",
            "saved ./samples_fashion/sample-28500-m-s.png\n",
            "saved ./samples_fashion/sample-28500-s-m.png\n",
            "Step [28510/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0176, d_svhn_loss: 0.0541, d_fake_loss: 0.0451, g_loss: 1.1454\n",
            "Step [28520/80000], d_real_loss: 0.1198, d_mnist_loss: 0.0295, d_svhn_loss: 0.0903, d_fake_loss: 0.0430, g_loss: 1.2963\n",
            "Step [28530/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0191, d_svhn_loss: 0.0270, d_fake_loss: 0.0832, g_loss: 1.1800\n",
            "Step [28540/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0133, d_svhn_loss: 0.0349, d_fake_loss: 0.1422, g_loss: 1.1561\n",
            "Step [28550/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0529, d_svhn_loss: 0.0234, d_fake_loss: 0.0359, g_loss: 1.1162\n",
            "Step [28560/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0101, d_svhn_loss: 0.0223, d_fake_loss: 0.0568, g_loss: 1.2917\n",
            "Step [28570/80000], d_real_loss: 0.4181, d_mnist_loss: 0.3467, d_svhn_loss: 0.0714, d_fake_loss: 0.0531, g_loss: 1.0591\n",
            "Step [28580/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0180, d_svhn_loss: 0.0268, d_fake_loss: 0.0826, g_loss: 0.9877\n",
            "Step [28590/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0151, d_svhn_loss: 0.0193, d_fake_loss: 0.0632, g_loss: 1.0419\n",
            "Step [28600/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0080, d_svhn_loss: 0.0190, d_fake_loss: 0.0987, g_loss: 1.0081\n",
            "Step [28610/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0111, d_svhn_loss: 0.0363, d_fake_loss: 0.0335, g_loss: 1.0931\n",
            "Step [28620/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0090, d_svhn_loss: 0.0279, d_fake_loss: 0.0971, g_loss: 1.1552\n",
            "Step [28630/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0079, d_svhn_loss: 0.0704, d_fake_loss: 0.0543, g_loss: 1.1940\n",
            "Step [28640/80000], d_real_loss: 0.0965, d_mnist_loss: 0.0106, d_svhn_loss: 0.0859, d_fake_loss: 0.0320, g_loss: 1.1233\n",
            "Step [28650/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0108, d_svhn_loss: 0.0207, d_fake_loss: 0.0273, g_loss: 0.9963\n",
            "Step [28660/80000], d_real_loss: 0.1474, d_mnist_loss: 0.0191, d_svhn_loss: 0.1283, d_fake_loss: 0.1855, g_loss: 0.9157\n",
            "Step [28670/80000], d_real_loss: 0.1371, d_mnist_loss: 0.1132, d_svhn_loss: 0.0239, d_fake_loss: 0.0523, g_loss: 1.1396\n",
            "Step [28680/80000], d_real_loss: 0.0728, d_mnist_loss: 0.0474, d_svhn_loss: 0.0253, d_fake_loss: 0.0940, g_loss: 0.9697\n",
            "Step [28690/80000], d_real_loss: 0.0695, d_mnist_loss: 0.0315, d_svhn_loss: 0.0380, d_fake_loss: 0.0316, g_loss: 1.1739\n",
            "Step [28700/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0097, d_svhn_loss: 0.0375, d_fake_loss: 0.0384, g_loss: 1.2291\n",
            "Step [28710/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0169, d_svhn_loss: 0.0268, d_fake_loss: 0.0677, g_loss: 1.3362\n",
            "Step [28720/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0112, d_svhn_loss: 0.0665, d_fake_loss: 0.0993, g_loss: 1.2372\n",
            "Step [28730/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0187, d_svhn_loss: 0.0244, d_fake_loss: 0.0526, g_loss: 1.2719\n",
            "Step [28740/80000], d_real_loss: 0.1187, d_mnist_loss: 0.0157, d_svhn_loss: 0.1030, d_fake_loss: 0.0402, g_loss: 1.0255\n",
            "Step [28750/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0101, d_svhn_loss: 0.0232, d_fake_loss: 0.0459, g_loss: 1.1289\n",
            "Step [28760/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0145, d_svhn_loss: 0.0659, d_fake_loss: 0.0591, g_loss: 1.2302\n",
            "Step [28770/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0175, d_svhn_loss: 0.0439, d_fake_loss: 0.0322, g_loss: 1.1037\n",
            "Step [28780/80000], d_real_loss: 0.1626, d_mnist_loss: 0.0370, d_svhn_loss: 0.1256, d_fake_loss: 0.0503, g_loss: 1.0501\n",
            "Step [28790/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0166, d_svhn_loss: 0.0232, d_fake_loss: 0.0318, g_loss: 1.1063\n",
            "Step [28800/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0139, d_svhn_loss: 0.0772, d_fake_loss: 0.0474, g_loss: 1.1983\n",
            "Step [28810/80000], d_real_loss: 0.0780, d_mnist_loss: 0.0365, d_svhn_loss: 0.0415, d_fake_loss: 0.0464, g_loss: 1.0961\n",
            "Step [28820/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0100, d_svhn_loss: 0.0391, d_fake_loss: 0.1040, g_loss: 1.1538\n",
            "Step [28830/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0186, d_svhn_loss: 0.0578, d_fake_loss: 0.0432, g_loss: 1.0781\n",
            "Step [28840/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0090, d_svhn_loss: 0.0269, d_fake_loss: 0.0649, g_loss: 1.2921\n",
            "Step [28850/80000], d_real_loss: 0.0884, d_mnist_loss: 0.0120, d_svhn_loss: 0.0764, d_fake_loss: 0.0424, g_loss: 1.1083\n",
            "Step [28860/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0094, d_svhn_loss: 0.0199, d_fake_loss: 0.0405, g_loss: 1.0812\n",
            "Step [28870/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0146, d_svhn_loss: 0.0349, d_fake_loss: 0.0363, g_loss: 1.1708\n",
            "Step [28880/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0141, d_svhn_loss: 0.0380, d_fake_loss: 0.0310, g_loss: 0.8883\n",
            "Step [28890/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0131, d_svhn_loss: 0.0167, d_fake_loss: 0.0871, g_loss: 1.3595\n",
            "Step [28900/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0389, d_svhn_loss: 0.0330, d_fake_loss: 0.0386, g_loss: 1.0625\n",
            "Step [28910/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0170, d_svhn_loss: 0.0269, d_fake_loss: 0.0446, g_loss: 1.2241\n",
            "Step [28920/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0557, d_svhn_loss: 0.0280, d_fake_loss: 0.0542, g_loss: 1.0733\n",
            "Step [28930/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0201, d_svhn_loss: 0.0323, d_fake_loss: 0.1650, g_loss: 1.0547\n",
            "Step [28940/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0106, d_svhn_loss: 0.0227, d_fake_loss: 0.0429, g_loss: 1.0063\n",
            "Step [28950/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0141, d_svhn_loss: 0.0445, d_fake_loss: 0.0551, g_loss: 1.0365\n",
            "Step [28960/80000], d_real_loss: 0.1013, d_mnist_loss: 0.0490, d_svhn_loss: 0.0522, d_fake_loss: 0.3161, g_loss: 1.4416\n",
            "Step [28970/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0556, d_svhn_loss: 0.0196, d_fake_loss: 0.0559, g_loss: 1.3409\n",
            "Step [28980/80000], d_real_loss: 0.1015, d_mnist_loss: 0.0774, d_svhn_loss: 0.0241, d_fake_loss: 0.0658, g_loss: 1.3240\n",
            "Step [28990/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0157, d_svhn_loss: 0.0274, d_fake_loss: 0.0541, g_loss: 0.9091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999132752418518, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [29000/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0246, d_svhn_loss: 0.0301, d_fake_loss: 0.1128, g_loss: 1.2149\n",
            "saved ./samples_fashion/sample-29000-m-s.png\n",
            "saved ./samples_fashion/sample-29000-s-m.png\n",
            "Step [29010/80000], d_real_loss: 0.0870, d_mnist_loss: 0.0120, d_svhn_loss: 0.0750, d_fake_loss: 0.0959, g_loss: 1.0244\n",
            "Step [29020/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0163, d_svhn_loss: 0.0248, d_fake_loss: 0.0420, g_loss: 1.1043\n",
            "Step [29030/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0236, d_svhn_loss: 0.0457, d_fake_loss: 0.0612, g_loss: 1.0905\n",
            "Step [29040/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0189, d_svhn_loss: 0.0365, d_fake_loss: 0.0432, g_loss: 1.0994\n",
            "Step [29050/80000], d_real_loss: 0.1036, d_mnist_loss: 0.0091, d_svhn_loss: 0.0945, d_fake_loss: 0.1317, g_loss: 1.0971\n",
            "Step [29060/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0132, d_svhn_loss: 0.0272, d_fake_loss: 0.0502, g_loss: 1.1929\n",
            "Step [29070/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0107, d_svhn_loss: 0.0340, d_fake_loss: 0.0401, g_loss: 1.0257\n",
            "Step [29080/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0089, d_svhn_loss: 0.0253, d_fake_loss: 0.0745, g_loss: 1.0314\n",
            "Step [29090/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0116, d_svhn_loss: 0.0606, d_fake_loss: 0.0304, g_loss: 1.0923\n",
            "Step [29100/80000], d_real_loss: 0.1479, d_mnist_loss: 0.0585, d_svhn_loss: 0.0894, d_fake_loss: 0.0969, g_loss: 0.9991\n",
            "Step [29110/80000], d_real_loss: 0.0626, d_mnist_loss: 0.0086, d_svhn_loss: 0.0540, d_fake_loss: 0.0765, g_loss: 1.3651\n",
            "Step [29120/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0118, d_svhn_loss: 0.0314, d_fake_loss: 0.0335, g_loss: 1.1426\n",
            "Step [29130/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0314, d_svhn_loss: 0.0356, d_fake_loss: 0.0388, g_loss: 1.1746\n",
            "Step [29140/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0101, d_svhn_loss: 0.0328, d_fake_loss: 0.0841, g_loss: 1.0749\n",
            "Step [29150/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0220, d_svhn_loss: 0.0255, d_fake_loss: 0.0330, g_loss: 0.9565\n",
            "Step [29160/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0186, d_svhn_loss: 0.0279, d_fake_loss: 0.0511, g_loss: 1.0339\n",
            "Step [29170/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0163, d_svhn_loss: 0.0276, d_fake_loss: 0.0436, g_loss: 1.1790\n",
            "Step [29180/80000], d_real_loss: 0.1155, d_mnist_loss: 0.0696, d_svhn_loss: 0.0459, d_fake_loss: 0.0715, g_loss: 1.1520\n",
            "Step [29190/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0099, d_svhn_loss: 0.0491, d_fake_loss: 0.0360, g_loss: 1.1744\n",
            "Step [29200/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0219, d_svhn_loss: 0.0396, d_fake_loss: 0.0437, g_loss: 1.0771\n",
            "Step [29210/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0194, d_svhn_loss: 0.0475, d_fake_loss: 0.0306, g_loss: 1.0703\n",
            "Step [29220/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0364, d_svhn_loss: 0.0310, d_fake_loss: 0.0482, g_loss: 0.9715\n",
            "Step [29230/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0129, d_svhn_loss: 0.0456, d_fake_loss: 0.0750, g_loss: 0.9508\n",
            "Step [29240/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0406, d_svhn_loss: 0.0294, d_fake_loss: 0.0820, g_loss: 1.3535\n",
            "Step [29250/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0062, d_svhn_loss: 0.0396, d_fake_loss: 0.0345, g_loss: 1.1786\n",
            "Step [29260/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0220, d_svhn_loss: 0.0250, d_fake_loss: 0.0498, g_loss: 1.1022\n",
            "Step [29270/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0127, d_svhn_loss: 0.0244, d_fake_loss: 0.0440, g_loss: 1.1515\n",
            "Step [29280/80000], d_real_loss: 0.1431, d_mnist_loss: 0.1080, d_svhn_loss: 0.0351, d_fake_loss: 0.0434, g_loss: 1.1563\n",
            "Step [29290/80000], d_real_loss: 0.0952, d_mnist_loss: 0.0127, d_svhn_loss: 0.0824, d_fake_loss: 0.0466, g_loss: 1.1234\n",
            "Step [29300/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0126, d_svhn_loss: 0.0420, d_fake_loss: 0.0898, g_loss: 1.3445\n",
            "Step [29310/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0148, d_svhn_loss: 0.0472, d_fake_loss: 0.0677, g_loss: 1.1839\n",
            "Step [29320/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0210, d_svhn_loss: 0.0527, d_fake_loss: 0.1812, g_loss: 1.3047\n",
            "Step [29330/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0135, d_svhn_loss: 0.0268, d_fake_loss: 0.0858, g_loss: 1.0958\n",
            "Step [29340/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0204, d_svhn_loss: 0.0333, d_fake_loss: 0.0312, g_loss: 1.0351\n",
            "Step [29350/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0254, d_svhn_loss: 0.0193, d_fake_loss: 0.0345, g_loss: 1.0263\n",
            "Step [29360/80000], d_real_loss: 0.1540, d_mnist_loss: 0.0927, d_svhn_loss: 0.0613, d_fake_loss: 0.0911, g_loss: 1.1205\n",
            "Step [29370/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0202, d_svhn_loss: 0.0445, d_fake_loss: 0.0348, g_loss: 1.1540\n",
            "Step [29380/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0090, d_svhn_loss: 0.0697, d_fake_loss: 0.0895, g_loss: 1.0316\n",
            "Step [29390/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0131, d_svhn_loss: 0.0736, d_fake_loss: 0.0832, g_loss: 1.1180\n",
            "Step [29400/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0072, d_svhn_loss: 0.0564, d_fake_loss: 0.0555, g_loss: 1.0109\n",
            "Step [29410/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0146, d_svhn_loss: 0.0216, d_fake_loss: 0.0595, g_loss: 1.2911\n",
            "Step [29420/80000], d_real_loss: 0.0962, d_mnist_loss: 0.0693, d_svhn_loss: 0.0270, d_fake_loss: 0.0616, g_loss: 1.1874\n",
            "Step [29430/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0321, d_svhn_loss: 0.0204, d_fake_loss: 0.0465, g_loss: 1.1212\n",
            "Step [29440/80000], d_real_loss: 0.1184, d_mnist_loss: 0.0906, d_svhn_loss: 0.0278, d_fake_loss: 0.0775, g_loss: 1.2464\n",
            "Step [29450/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0211, d_svhn_loss: 0.0278, d_fake_loss: 0.0747, g_loss: 1.2453\n",
            "Step [29460/80000], d_real_loss: 0.1010, d_mnist_loss: 0.0147, d_svhn_loss: 0.0863, d_fake_loss: 0.0510, g_loss: 0.9059\n",
            "Step [29470/80000], d_real_loss: 0.0959, d_mnist_loss: 0.0574, d_svhn_loss: 0.0386, d_fake_loss: 0.1152, g_loss: 1.4270\n",
            "Step [29480/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0120, d_svhn_loss: 0.0667, d_fake_loss: 0.0334, g_loss: 1.0640\n",
            "Step [29490/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0145, d_svhn_loss: 0.0460, d_fake_loss: 0.0770, g_loss: 1.1360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9994434714317322, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [29500/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0152, d_svhn_loss: 0.0281, d_fake_loss: 0.0547, g_loss: 1.2435\n",
            "saved ./samples_fashion/sample-29500-m-s.png\n",
            "saved ./samples_fashion/sample-29500-s-m.png\n",
            "Step [29510/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0124, d_svhn_loss: 0.0261, d_fake_loss: 0.0625, g_loss: 1.3265\n",
            "Step [29520/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0179, d_svhn_loss: 0.0398, d_fake_loss: 0.0599, g_loss: 1.4126\n",
            "Step [29530/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0140, d_svhn_loss: 0.0205, d_fake_loss: 0.0419, g_loss: 1.1006\n",
            "Step [29540/80000], d_real_loss: 0.0858, d_mnist_loss: 0.0110, d_svhn_loss: 0.0748, d_fake_loss: 0.0470, g_loss: 1.2013\n",
            "Step [29550/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0109, d_svhn_loss: 0.0260, d_fake_loss: 0.0513, g_loss: 1.2202\n",
            "Step [29560/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0170, d_svhn_loss: 0.0263, d_fake_loss: 0.0393, g_loss: 1.2404\n",
            "Step [29570/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0110, d_svhn_loss: 0.0498, d_fake_loss: 0.1232, g_loss: 0.9205\n",
            "Step [29580/80000], d_real_loss: 0.0830, d_mnist_loss: 0.0150, d_svhn_loss: 0.0679, d_fake_loss: 0.1976, g_loss: 1.2169\n",
            "Step [29590/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0104, d_svhn_loss: 0.0455, d_fake_loss: 0.2960, g_loss: 0.8241\n",
            "Step [29600/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0129, d_svhn_loss: 0.0198, d_fake_loss: 0.0417, g_loss: 1.1142\n",
            "Step [29610/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0159, d_svhn_loss: 0.0371, d_fake_loss: 0.0415, g_loss: 1.1750\n",
            "Step [29620/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0188, d_svhn_loss: 0.0243, d_fake_loss: 0.0534, g_loss: 1.0095\n",
            "Step [29630/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0121, d_svhn_loss: 0.0322, d_fake_loss: 0.0302, g_loss: 1.1231\n",
            "Step [29640/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0125, d_svhn_loss: 0.0203, d_fake_loss: 0.0746, g_loss: 1.0319\n",
            "Step [29650/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0114, d_svhn_loss: 0.0650, d_fake_loss: 0.0423, g_loss: 1.1015\n",
            "Step [29660/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0127, d_svhn_loss: 0.0344, d_fake_loss: 0.0516, g_loss: 1.1771\n",
            "Step [29670/80000], d_real_loss: 0.1445, d_mnist_loss: 0.0125, d_svhn_loss: 0.1320, d_fake_loss: 0.1865, g_loss: 1.2226\n",
            "Step [29680/80000], d_real_loss: 0.0999, d_mnist_loss: 0.0122, d_svhn_loss: 0.0877, d_fake_loss: 0.1579, g_loss: 1.3705\n",
            "Step [29690/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0289, d_svhn_loss: 0.0433, d_fake_loss: 0.0477, g_loss: 1.0820\n",
            "Step [29700/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0145, d_svhn_loss: 0.0294, d_fake_loss: 0.0843, g_loss: 1.3951\n",
            "Step [29710/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0101, d_svhn_loss: 0.0272, d_fake_loss: 0.0430, g_loss: 1.0278\n",
            "Step [29720/80000], d_real_loss: 0.1801, d_mnist_loss: 0.0352, d_svhn_loss: 0.1449, d_fake_loss: 0.0296, g_loss: 1.0747\n",
            "Step [29730/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0142, d_svhn_loss: 0.0308, d_fake_loss: 0.0410, g_loss: 1.1227\n",
            "Step [29740/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0092, d_svhn_loss: 0.0349, d_fake_loss: 0.0361, g_loss: 1.1220\n",
            "Step [29750/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0131, d_svhn_loss: 0.0589, d_fake_loss: 0.0633, g_loss: 1.1883\n",
            "Step [29760/80000], d_real_loss: 0.0821, d_mnist_loss: 0.0119, d_svhn_loss: 0.0702, d_fake_loss: 0.0412, g_loss: 1.2699\n",
            "Step [29770/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0114, d_svhn_loss: 0.0344, d_fake_loss: 0.0542, g_loss: 1.2048\n",
            "Step [29780/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0125, d_svhn_loss: 0.0268, d_fake_loss: 0.0412, g_loss: 0.9879\n",
            "Step [29790/80000], d_real_loss: 0.1051, d_mnist_loss: 0.0763, d_svhn_loss: 0.0288, d_fake_loss: 0.0511, g_loss: 1.1291\n",
            "Step [29800/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0092, d_svhn_loss: 0.0571, d_fake_loss: 0.0718, g_loss: 1.2332\n",
            "Step [29810/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0452, d_svhn_loss: 0.0306, d_fake_loss: 0.0428, g_loss: 1.0527\n",
            "Step [29820/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0098, d_svhn_loss: 0.0399, d_fake_loss: 0.0333, g_loss: 1.1150\n",
            "Step [29830/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0162, d_svhn_loss: 0.0577, d_fake_loss: 0.0629, g_loss: 1.3032\n",
            "Step [29840/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0254, d_svhn_loss: 0.0224, d_fake_loss: 0.0788, g_loss: 1.3517\n",
            "Step [29850/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0141, d_svhn_loss: 0.0412, d_fake_loss: 0.0362, g_loss: 1.2457\n",
            "Step [29860/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0245, d_svhn_loss: 0.0304, d_fake_loss: 0.1716, g_loss: 1.2865\n",
            "Step [29870/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0079, d_svhn_loss: 0.0585, d_fake_loss: 0.0555, g_loss: 1.1292\n",
            "Step [29880/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0188, d_svhn_loss: 0.0553, d_fake_loss: 0.0340, g_loss: 0.9918\n",
            "Step [29890/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0134, d_svhn_loss: 0.0234, d_fake_loss: 0.0379, g_loss: 1.2525\n",
            "Step [29900/80000], d_real_loss: 0.0915, d_mnist_loss: 0.0111, d_svhn_loss: 0.0803, d_fake_loss: 0.0814, g_loss: 1.1416\n",
            "Step [29910/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0072, d_svhn_loss: 0.0242, d_fake_loss: 0.0411, g_loss: 1.1413\n",
            "Step [29920/80000], d_real_loss: 0.0850, d_mnist_loss: 0.0525, d_svhn_loss: 0.0325, d_fake_loss: 0.0545, g_loss: 1.1826\n",
            "Step [29930/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0095, d_svhn_loss: 0.0433, d_fake_loss: 0.0782, g_loss: 1.3169\n",
            "Step [29940/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0130, d_svhn_loss: 0.0279, d_fake_loss: 0.0308, g_loss: 1.1052\n",
            "Step [29950/80000], d_real_loss: 0.0680, d_mnist_loss: 0.0318, d_svhn_loss: 0.0363, d_fake_loss: 0.0444, g_loss: 1.0306\n",
            "Step [29960/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0177, d_svhn_loss: 0.0286, d_fake_loss: 0.0352, g_loss: 1.1457\n",
            "Step [29970/80000], d_real_loss: 0.0747, d_mnist_loss: 0.0207, d_svhn_loss: 0.0540, d_fake_loss: 0.0464, g_loss: 1.0107\n",
            "Step [29980/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0073, d_svhn_loss: 0.0294, d_fake_loss: 0.0285, g_loss: 1.2035\n",
            "Step [29990/80000], d_real_loss: 0.0929, d_mnist_loss: 0.0123, d_svhn_loss: 0.0806, d_fake_loss: 0.0617, g_loss: 1.0545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9992005825042725, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [30000/80000], d_real_loss: 0.1060, d_mnist_loss: 0.0464, d_svhn_loss: 0.0597, d_fake_loss: 0.1082, g_loss: 1.1226\n",
            "saved ./samples_fashion/sample-30000-m-s.png\n",
            "saved ./samples_fashion/sample-30000-s-m.png\n",
            "Step [30010/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0147, d_svhn_loss: 0.0370, d_fake_loss: 0.0963, g_loss: 1.1893\n",
            "Step [30020/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0062, d_svhn_loss: 0.0694, d_fake_loss: 0.0514, g_loss: 1.0614\n",
            "Step [30030/80000], d_real_loss: 0.0887, d_mnist_loss: 0.0246, d_svhn_loss: 0.0641, d_fake_loss: 0.1002, g_loss: 1.1568\n",
            "Step [30040/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0088, d_svhn_loss: 0.0383, d_fake_loss: 0.0818, g_loss: 0.8233\n",
            "Step [30050/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0085, d_svhn_loss: 0.0574, d_fake_loss: 0.1199, g_loss: 1.0763\n",
            "Step [30060/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0107, d_svhn_loss: 0.0395, d_fake_loss: 0.0207, g_loss: 1.0627\n",
            "Step [30070/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0191, d_svhn_loss: 0.0534, d_fake_loss: 0.0908, g_loss: 1.1698\n",
            "Step [30080/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0246, d_svhn_loss: 0.0421, d_fake_loss: 0.1236, g_loss: 1.3251\n",
            "Step [30090/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0097, d_svhn_loss: 0.0301, d_fake_loss: 0.0447, g_loss: 1.1353\n",
            "Step [30100/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0198, d_svhn_loss: 0.0186, d_fake_loss: 0.0440, g_loss: 1.1816\n",
            "Step [30110/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0089, d_svhn_loss: 0.0427, d_fake_loss: 0.0591, g_loss: 1.3309\n",
            "Step [30120/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0178, d_svhn_loss: 0.0403, d_fake_loss: 0.0678, g_loss: 1.1283\n",
            "Step [30130/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0165, d_svhn_loss: 0.0462, d_fake_loss: 0.0492, g_loss: 1.1051\n",
            "Step [30140/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0262, d_svhn_loss: 0.0511, d_fake_loss: 0.1069, g_loss: 1.1815\n",
            "Step [30150/80000], d_real_loss: 0.1003, d_mnist_loss: 0.0403, d_svhn_loss: 0.0601, d_fake_loss: 0.1869, g_loss: 1.3747\n",
            "Step [30160/80000], d_real_loss: 0.1085, d_mnist_loss: 0.0432, d_svhn_loss: 0.0653, d_fake_loss: 0.0438, g_loss: 1.1369\n",
            "Step [30170/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0166, d_svhn_loss: 0.0301, d_fake_loss: 0.0948, g_loss: 0.9270\n",
            "Step [30180/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0159, d_svhn_loss: 0.0687, d_fake_loss: 0.0692, g_loss: 0.9817\n",
            "Step [30190/80000], d_real_loss: 0.1259, d_mnist_loss: 0.0184, d_svhn_loss: 0.1075, d_fake_loss: 0.0384, g_loss: 1.0847\n",
            "Step [30200/80000], d_real_loss: 0.1351, d_mnist_loss: 0.0614, d_svhn_loss: 0.0736, d_fake_loss: 0.0502, g_loss: 0.9504\n",
            "Step [30210/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0191, d_svhn_loss: 0.0299, d_fake_loss: 0.0677, g_loss: 1.1882\n",
            "Step [30220/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0099, d_svhn_loss: 0.0222, d_fake_loss: 0.1076, g_loss: 1.3769\n",
            "Step [30230/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0236, d_svhn_loss: 0.0415, d_fake_loss: 0.0393, g_loss: 0.9624\n",
            "Step [30240/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0088, d_svhn_loss: 0.0789, d_fake_loss: 0.0721, g_loss: 1.0271\n",
            "Step [30250/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0267, d_svhn_loss: 0.0364, d_fake_loss: 0.0612, g_loss: 1.1150\n",
            "Step [30260/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0463, d_svhn_loss: 0.0211, d_fake_loss: 0.0848, g_loss: 1.1204\n",
            "Step [30270/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0128, d_svhn_loss: 0.0238, d_fake_loss: 0.0938, g_loss: 1.1897\n",
            "Step [30280/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0111, d_svhn_loss: 0.0541, d_fake_loss: 0.0359, g_loss: 1.1120\n",
            "Step [30290/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0318, d_svhn_loss: 0.0342, d_fake_loss: 0.0347, g_loss: 0.9857\n",
            "Step [30300/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0089, d_svhn_loss: 0.0286, d_fake_loss: 0.0489, g_loss: 1.0093\n",
            "Step [30310/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0113, d_svhn_loss: 0.0572, d_fake_loss: 0.1776, g_loss: 1.3393\n",
            "Step [30320/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0293, d_svhn_loss: 0.0326, d_fake_loss: 0.0485, g_loss: 1.2204\n",
            "Step [30330/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0267, d_svhn_loss: 0.0284, d_fake_loss: 0.0308, g_loss: 1.0801\n",
            "Step [30340/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0213, d_svhn_loss: 0.0347, d_fake_loss: 0.1736, g_loss: 1.1348\n",
            "Step [30350/80000], d_real_loss: 0.1871, d_mnist_loss: 0.0828, d_svhn_loss: 0.1044, d_fake_loss: 0.0847, g_loss: 1.1821\n",
            "Step [30360/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0131, d_svhn_loss: 0.0462, d_fake_loss: 0.0583, g_loss: 1.2057\n",
            "Step [30370/80000], d_real_loss: 0.1037, d_mnist_loss: 0.0442, d_svhn_loss: 0.0595, d_fake_loss: 0.0793, g_loss: 1.1131\n",
            "Step [30380/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0139, d_svhn_loss: 0.0261, d_fake_loss: 0.0863, g_loss: 1.2306\n",
            "Step [30390/80000], d_real_loss: 0.1427, d_mnist_loss: 0.0108, d_svhn_loss: 0.1319, d_fake_loss: 0.0741, g_loss: 1.2162\n",
            "Step [30400/80000], d_real_loss: 0.1960, d_mnist_loss: 0.1686, d_svhn_loss: 0.0275, d_fake_loss: 0.0878, g_loss: 1.3516\n",
            "Step [30410/80000], d_real_loss: 0.0801, d_mnist_loss: 0.0285, d_svhn_loss: 0.0515, d_fake_loss: 0.0338, g_loss: 1.0657\n",
            "Step [30420/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0258, d_svhn_loss: 0.0336, d_fake_loss: 0.0524, g_loss: 0.8939\n",
            "Step [30430/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0321, d_svhn_loss: 0.0183, d_fake_loss: 0.0656, g_loss: 1.2255\n",
            "Step [30440/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0129, d_svhn_loss: 0.0303, d_fake_loss: 0.0365, g_loss: 1.1682\n",
            "Step [30450/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0185, d_svhn_loss: 0.0385, d_fake_loss: 0.0350, g_loss: 1.0995\n",
            "Step [30460/80000], d_real_loss: 0.1005, d_mnist_loss: 0.0241, d_svhn_loss: 0.0764, d_fake_loss: 0.0540, g_loss: 1.0939\n",
            "Step [30470/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0094, d_svhn_loss: 0.0229, d_fake_loss: 0.0313, g_loss: 1.0659\n",
            "Step [30480/80000], d_real_loss: 0.2486, d_mnist_loss: 0.0230, d_svhn_loss: 0.2256, d_fake_loss: 0.1340, g_loss: 0.9745\n",
            "Step [30490/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0114, d_svhn_loss: 0.0336, d_fake_loss: 0.0351, g_loss: 1.0816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999425411224365, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [30500/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0112, d_svhn_loss: 0.0343, d_fake_loss: 0.0580, g_loss: 1.1388\n",
            "saved ./samples_fashion/sample-30500-m-s.png\n",
            "saved ./samples_fashion/sample-30500-s-m.png\n",
            "Step [30510/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0123, d_svhn_loss: 0.0567, d_fake_loss: 0.0924, g_loss: 0.8472\n",
            "Step [30520/80000], d_real_loss: 0.0665, d_mnist_loss: 0.0308, d_svhn_loss: 0.0357, d_fake_loss: 0.0532, g_loss: 1.1153\n",
            "Step [30530/80000], d_real_loss: 0.0735, d_mnist_loss: 0.0133, d_svhn_loss: 0.0602, d_fake_loss: 0.0592, g_loss: 1.1315\n",
            "Step [30540/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0289, d_svhn_loss: 0.0304, d_fake_loss: 0.1107, g_loss: 1.0291\n",
            "Step [30550/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0088, d_svhn_loss: 0.0534, d_fake_loss: 0.0547, g_loss: 1.1549\n",
            "Step [30560/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0150, d_svhn_loss: 0.0393, d_fake_loss: 0.0418, g_loss: 1.0605\n",
            "Step [30570/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0134, d_svhn_loss: 0.0174, d_fake_loss: 0.0388, g_loss: 1.1900\n",
            "Step [30580/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0123, d_svhn_loss: 0.0546, d_fake_loss: 0.0987, g_loss: 1.0902\n",
            "Step [30590/80000], d_real_loss: 0.1121, d_mnist_loss: 0.0093, d_svhn_loss: 0.1028, d_fake_loss: 0.1018, g_loss: 1.2235\n",
            "Step [30600/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0114, d_svhn_loss: 0.0624, d_fake_loss: 0.0282, g_loss: 1.1877\n",
            "Step [30610/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0088, d_svhn_loss: 0.0320, d_fake_loss: 0.0601, g_loss: 1.2788\n",
            "Step [30620/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0181, d_svhn_loss: 0.0250, d_fake_loss: 0.0589, g_loss: 1.0375\n",
            "Step [30630/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0272, d_svhn_loss: 0.0321, d_fake_loss: 0.0502, g_loss: 1.0890\n",
            "Step [30640/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0222, d_svhn_loss: 0.0245, d_fake_loss: 0.0607, g_loss: 1.2601\n",
            "Step [30650/80000], d_real_loss: 0.0962, d_mnist_loss: 0.0151, d_svhn_loss: 0.0810, d_fake_loss: 0.0291, g_loss: 0.9923\n",
            "Step [30660/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0173, d_svhn_loss: 0.0364, d_fake_loss: 0.0337, g_loss: 1.1552\n",
            "Step [30670/80000], d_real_loss: 0.1019, d_mnist_loss: 0.0486, d_svhn_loss: 0.0533, d_fake_loss: 0.0633, g_loss: 0.8622\n",
            "Step [30680/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0139, d_svhn_loss: 0.0483, d_fake_loss: 0.0581, g_loss: 1.2039\n",
            "Step [30690/80000], d_real_loss: 0.1142, d_mnist_loss: 0.0112, d_svhn_loss: 0.1029, d_fake_loss: 0.1165, g_loss: 1.0959\n",
            "Step [30700/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0175, d_svhn_loss: 0.0373, d_fake_loss: 0.2109, g_loss: 1.0291\n",
            "Step [30710/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0107, d_svhn_loss: 0.0217, d_fake_loss: 0.1899, g_loss: 1.0120\n",
            "Step [30720/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0054, d_svhn_loss: 0.0316, d_fake_loss: 0.0766, g_loss: 1.0781\n",
            "Step [30730/80000], d_real_loss: 0.0962, d_mnist_loss: 0.0149, d_svhn_loss: 0.0813, d_fake_loss: 0.0329, g_loss: 1.0151\n",
            "Step [30740/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0139, d_svhn_loss: 0.0557, d_fake_loss: 0.0571, g_loss: 1.1373\n",
            "Step [30750/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0203, d_svhn_loss: 0.0579, d_fake_loss: 0.0383, g_loss: 0.9407\n",
            "Step [30760/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0139, d_svhn_loss: 0.0373, d_fake_loss: 0.0523, g_loss: 1.2784\n",
            "Step [30770/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0157, d_svhn_loss: 0.0410, d_fake_loss: 0.0327, g_loss: 1.1806\n",
            "Step [30780/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0131, d_svhn_loss: 0.0370, d_fake_loss: 0.1419, g_loss: 1.2770\n",
            "Step [30790/80000], d_real_loss: 0.1828, d_mnist_loss: 0.0507, d_svhn_loss: 0.1321, d_fake_loss: 0.0279, g_loss: 1.0801\n",
            "Step [30800/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0111, d_svhn_loss: 0.0310, d_fake_loss: 0.0658, g_loss: 1.2744\n",
            "Step [30810/80000], d_real_loss: 0.0747, d_mnist_loss: 0.0194, d_svhn_loss: 0.0553, d_fake_loss: 0.0561, g_loss: 1.1688\n",
            "Step [30820/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0076, d_svhn_loss: 0.0328, d_fake_loss: 0.0440, g_loss: 1.0619\n",
            "Step [30830/80000], d_real_loss: 0.1330, d_mnist_loss: 0.0165, d_svhn_loss: 0.1166, d_fake_loss: 0.0576, g_loss: 1.0360\n",
            "Step [30840/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0155, d_svhn_loss: 0.0597, d_fake_loss: 0.0386, g_loss: 1.1232\n",
            "Step [30850/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0115, d_svhn_loss: 0.0213, d_fake_loss: 0.0466, g_loss: 1.2209\n",
            "Step [30860/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0150, d_svhn_loss: 0.0269, d_fake_loss: 0.0386, g_loss: 1.0122\n",
            "Step [30870/80000], d_real_loss: 0.0744, d_mnist_loss: 0.0123, d_svhn_loss: 0.0621, d_fake_loss: 0.1155, g_loss: 0.9799\n",
            "Step [30880/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0098, d_svhn_loss: 0.0205, d_fake_loss: 0.0389, g_loss: 1.1726\n",
            "Step [30890/80000], d_real_loss: 0.1321, d_mnist_loss: 0.0675, d_svhn_loss: 0.0646, d_fake_loss: 0.0301, g_loss: 1.1358\n",
            "Step [30900/80000], d_real_loss: 0.2622, d_mnist_loss: 0.2295, d_svhn_loss: 0.0327, d_fake_loss: 0.0950, g_loss: 1.7837\n",
            "Step [30910/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0154, d_svhn_loss: 0.0284, d_fake_loss: 0.0572, g_loss: 1.0761\n",
            "Step [30920/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0105, d_svhn_loss: 0.0714, d_fake_loss: 0.0371, g_loss: 1.0869\n",
            "Step [30930/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0183, d_svhn_loss: 0.0426, d_fake_loss: 0.0845, g_loss: 1.2098\n",
            "Step [30940/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0113, d_svhn_loss: 0.0261, d_fake_loss: 0.0591, g_loss: 1.2187\n",
            "Step [30950/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0099, d_svhn_loss: 0.0227, d_fake_loss: 0.0593, g_loss: 1.2056\n",
            "Step [30960/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0138, d_svhn_loss: 0.0277, d_fake_loss: 0.1207, g_loss: 0.9830\n",
            "Step [30970/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0164, d_svhn_loss: 0.0396, d_fake_loss: 0.0481, g_loss: 1.2711\n",
            "Step [30980/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0171, d_svhn_loss: 0.0232, d_fake_loss: 0.0613, g_loss: 1.1159\n",
            "Step [30990/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0196, d_svhn_loss: 0.0373, d_fake_loss: 0.0441, g_loss: 1.1661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [31000/80000], d_real_loss: 0.0913, d_mnist_loss: 0.0268, d_svhn_loss: 0.0645, d_fake_loss: 0.1140, g_loss: 1.2551\n",
            "saved ./samples_fashion/sample-31000-m-s.png\n",
            "saved ./samples_fashion/sample-31000-s-m.png\n",
            "Step [31010/80000], d_real_loss: 0.1155, d_mnist_loss: 0.0092, d_svhn_loss: 0.1063, d_fake_loss: 0.0662, g_loss: 1.1102\n",
            "Step [31020/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0111, d_svhn_loss: 0.0348, d_fake_loss: 0.0304, g_loss: 1.2049\n",
            "Step [31030/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0166, d_svhn_loss: 0.0453, d_fake_loss: 0.0374, g_loss: 1.1988\n",
            "Step [31040/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0120, d_svhn_loss: 0.0958, d_fake_loss: 0.0700, g_loss: 1.1148\n",
            "Step [31050/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0374, d_svhn_loss: 0.0342, d_fake_loss: 0.0380, g_loss: 1.1091\n",
            "Step [31060/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0136, d_svhn_loss: 0.0444, d_fake_loss: 0.0553, g_loss: 1.1171\n",
            "Step [31070/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0071, d_svhn_loss: 0.0321, d_fake_loss: 0.0365, g_loss: 1.0428\n",
            "Step [31080/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0076, d_svhn_loss: 0.0549, d_fake_loss: 0.0526, g_loss: 1.0525\n",
            "Step [31090/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0269, d_svhn_loss: 0.0242, d_fake_loss: 0.0510, g_loss: 1.1566\n",
            "Step [31100/80000], d_real_loss: 0.1069, d_mnist_loss: 0.0063, d_svhn_loss: 0.1006, d_fake_loss: 0.0641, g_loss: 1.0071\n",
            "Step [31110/80000], d_real_loss: 0.1443, d_mnist_loss: 0.0886, d_svhn_loss: 0.0557, d_fake_loss: 0.1379, g_loss: 1.5044\n",
            "Step [31120/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0145, d_svhn_loss: 0.0210, d_fake_loss: 0.0602, g_loss: 1.1143\n",
            "Step [31130/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0133, d_svhn_loss: 0.0331, d_fake_loss: 0.0527, g_loss: 1.1072\n",
            "Step [31140/80000], d_real_loss: 0.1638, d_mnist_loss: 0.0112, d_svhn_loss: 0.1526, d_fake_loss: 0.0718, g_loss: 1.2101\n",
            "Step [31150/80000], d_real_loss: 0.0823, d_mnist_loss: 0.0344, d_svhn_loss: 0.0479, d_fake_loss: 0.0962, g_loss: 1.0929\n",
            "Step [31160/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0262, d_svhn_loss: 0.0292, d_fake_loss: 0.0312, g_loss: 1.1604\n",
            "Step [31170/80000], d_real_loss: 0.1578, d_mnist_loss: 0.0402, d_svhn_loss: 0.1176, d_fake_loss: 0.0782, g_loss: 1.1255\n",
            "Step [31180/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0250, d_svhn_loss: 0.0375, d_fake_loss: 0.0343, g_loss: 1.2644\n",
            "Step [31190/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0094, d_svhn_loss: 0.0324, d_fake_loss: 0.0574, g_loss: 1.0075\n",
            "Step [31200/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0098, d_svhn_loss: 0.0363, d_fake_loss: 0.0707, g_loss: 1.1352\n",
            "Step [31210/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0275, d_svhn_loss: 0.0402, d_fake_loss: 0.0611, g_loss: 1.0879\n",
            "Step [31220/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0151, d_svhn_loss: 0.0312, d_fake_loss: 0.2171, g_loss: 1.0661\n",
            "Step [31230/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0099, d_svhn_loss: 0.0401, d_fake_loss: 0.0635, g_loss: 0.9414\n",
            "Step [31240/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0104, d_svhn_loss: 0.0413, d_fake_loss: 0.0807, g_loss: 1.2200\n",
            "Step [31250/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0203, d_svhn_loss: 0.0345, d_fake_loss: 0.0359, g_loss: 1.0949\n",
            "Step [31260/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0270, d_svhn_loss: 0.0250, d_fake_loss: 0.0514, g_loss: 0.9341\n",
            "Step [31270/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0142, d_svhn_loss: 0.0314, d_fake_loss: 0.0691, g_loss: 1.1935\n",
            "Step [31280/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0566, d_svhn_loss: 0.0234, d_fake_loss: 0.0455, g_loss: 0.8990\n",
            "Step [31290/80000], d_real_loss: 0.1337, d_mnist_loss: 0.0803, d_svhn_loss: 0.0534, d_fake_loss: 0.0730, g_loss: 1.1255\n",
            "Step [31300/80000], d_real_loss: 0.1562, d_mnist_loss: 0.0087, d_svhn_loss: 0.1475, d_fake_loss: 0.0908, g_loss: 1.1154\n",
            "Step [31310/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0165, d_svhn_loss: 0.0255, d_fake_loss: 0.0933, g_loss: 1.1505\n",
            "Step [31320/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0093, d_svhn_loss: 0.0596, d_fake_loss: 0.0409, g_loss: 1.0638\n",
            "Step [31330/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0262, d_svhn_loss: 0.0348, d_fake_loss: 0.0460, g_loss: 1.0846\n",
            "Step [31340/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0113, d_svhn_loss: 0.0289, d_fake_loss: 0.0389, g_loss: 1.1861\n",
            "Step [31350/80000], d_real_loss: 0.0956, d_mnist_loss: 0.0616, d_svhn_loss: 0.0340, d_fake_loss: 0.0663, g_loss: 0.8910\n",
            "Step [31360/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0465, d_svhn_loss: 0.0176, d_fake_loss: 0.0541, g_loss: 1.1693\n",
            "Step [31370/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0104, d_svhn_loss: 0.0575, d_fake_loss: 0.0833, g_loss: 1.1714\n",
            "Step [31380/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0144, d_svhn_loss: 0.0217, d_fake_loss: 0.0866, g_loss: 1.2643\n",
            "Step [31390/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0102, d_svhn_loss: 0.0404, d_fake_loss: 0.0531, g_loss: 1.1787\n",
            "Step [31400/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0128, d_svhn_loss: 0.0402, d_fake_loss: 0.0584, g_loss: 1.1676\n",
            "Step [31410/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0104, d_svhn_loss: 0.0245, d_fake_loss: 0.0522, g_loss: 1.2437\n",
            "Step [31420/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0112, d_svhn_loss: 0.0253, d_fake_loss: 0.1062, g_loss: 0.9399\n",
            "Step [31430/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0159, d_svhn_loss: 0.0311, d_fake_loss: 0.0377, g_loss: 1.0759\n",
            "Step [31440/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0188, d_svhn_loss: 0.0230, d_fake_loss: 0.0953, g_loss: 1.2231\n",
            "Step [31450/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0352, d_svhn_loss: 0.0409, d_fake_loss: 0.0454, g_loss: 1.1020\n",
            "Step [31460/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0166, d_svhn_loss: 0.0262, d_fake_loss: 0.0406, g_loss: 1.1463\n",
            "Step [31470/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0227, d_svhn_loss: 0.0235, d_fake_loss: 0.0862, g_loss: 1.5056\n",
            "Step [31480/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0157, d_svhn_loss: 0.0241, d_fake_loss: 0.1012, g_loss: 1.0508\n",
            "Step [31490/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0109, d_svhn_loss: 0.0352, d_fake_loss: 0.0999, g_loss: 1.0876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9995229840278625, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [31500/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0148, d_svhn_loss: 0.0257, d_fake_loss: 0.1106, g_loss: 1.1599\n",
            "saved ./samples_fashion/sample-31500-m-s.png\n",
            "saved ./samples_fashion/sample-31500-s-m.png\n",
            "Step [31510/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0131, d_svhn_loss: 0.0209, d_fake_loss: 0.0525, g_loss: 1.0516\n",
            "Step [31520/80000], d_real_loss: 0.1198, d_mnist_loss: 0.0125, d_svhn_loss: 0.1074, d_fake_loss: 0.0600, g_loss: 1.1662\n",
            "Step [31530/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0292, d_svhn_loss: 0.0418, d_fake_loss: 0.0254, g_loss: 1.0411\n",
            "Step [31540/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0334, d_svhn_loss: 0.0293, d_fake_loss: 0.0343, g_loss: 0.9705\n",
            "Step [31550/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0143, d_svhn_loss: 0.0748, d_fake_loss: 0.1583, g_loss: 0.9865\n",
            "Step [31560/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0076, d_svhn_loss: 0.0304, d_fake_loss: 0.0239, g_loss: 1.0741\n",
            "Step [31570/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0178, d_svhn_loss: 0.0245, d_fake_loss: 0.0301, g_loss: 1.0391\n",
            "Step [31580/80000], d_real_loss: 0.1157, d_mnist_loss: 0.0167, d_svhn_loss: 0.0990, d_fake_loss: 0.0363, g_loss: 1.1801\n",
            "Step [31590/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0256, d_svhn_loss: 0.0229, d_fake_loss: 0.0344, g_loss: 0.9030\n",
            "Step [31600/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0362, d_svhn_loss: 0.0254, d_fake_loss: 0.0362, g_loss: 1.2798\n",
            "Step [31610/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0253, d_svhn_loss: 0.0529, d_fake_loss: 0.0357, g_loss: 1.0424\n",
            "Step [31620/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0133, d_svhn_loss: 0.0449, d_fake_loss: 0.0716, g_loss: 1.2287\n",
            "Step [31630/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0119, d_svhn_loss: 0.0302, d_fake_loss: 0.0497, g_loss: 1.0435\n",
            "Step [31640/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0148, d_svhn_loss: 0.0246, d_fake_loss: 0.1016, g_loss: 1.2411\n",
            "Step [31650/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0087, d_svhn_loss: 0.0210, d_fake_loss: 0.0379, g_loss: 1.1513\n",
            "Step [31660/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0123, d_svhn_loss: 0.0462, d_fake_loss: 0.0498, g_loss: 1.0274\n",
            "Step [31670/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0129, d_svhn_loss: 0.0272, d_fake_loss: 0.1050, g_loss: 0.9323\n",
            "Step [31680/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0122, d_svhn_loss: 0.0232, d_fake_loss: 0.0742, g_loss: 0.8639\n",
            "Step [31690/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0187, d_svhn_loss: 0.0364, d_fake_loss: 0.0301, g_loss: 1.1413\n",
            "Step [31700/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0130, d_svhn_loss: 0.0256, d_fake_loss: 0.0550, g_loss: 1.1359\n",
            "Step [31710/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0106, d_svhn_loss: 0.0285, d_fake_loss: 0.0435, g_loss: 1.1580\n",
            "Step [31720/80000], d_real_loss: 0.3014, d_mnist_loss: 0.1876, d_svhn_loss: 0.1139, d_fake_loss: 0.1061, g_loss: 0.9557\n",
            "Step [31730/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0202, d_svhn_loss: 0.0359, d_fake_loss: 0.0468, g_loss: 1.0665\n",
            "Step [31740/80000], d_real_loss: 0.0747, d_mnist_loss: 0.0284, d_svhn_loss: 0.0464, d_fake_loss: 0.1039, g_loss: 0.9423\n",
            "Step [31750/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0142, d_svhn_loss: 0.0282, d_fake_loss: 0.0532, g_loss: 1.1699\n",
            "Step [31760/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0137, d_svhn_loss: 0.0319, d_fake_loss: 0.0476, g_loss: 1.1148\n",
            "Step [31770/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0352, d_svhn_loss: 0.0275, d_fake_loss: 0.0415, g_loss: 0.9968\n",
            "Step [31780/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0131, d_svhn_loss: 0.0323, d_fake_loss: 0.0309, g_loss: 1.0715\n",
            "Step [31790/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0107, d_svhn_loss: 0.0178, d_fake_loss: 0.0470, g_loss: 1.0465\n",
            "Step [31800/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0171, d_svhn_loss: 0.0293, d_fake_loss: 0.0380, g_loss: 1.0432\n",
            "Step [31810/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0241, d_svhn_loss: 0.0220, d_fake_loss: 0.0510, g_loss: 1.0336\n",
            "Step [31820/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0080, d_svhn_loss: 0.0303, d_fake_loss: 0.0211, g_loss: 1.0224\n",
            "Step [31830/80000], d_real_loss: 0.0856, d_mnist_loss: 0.0337, d_svhn_loss: 0.0519, d_fake_loss: 0.0504, g_loss: 1.3223\n",
            "Step [31840/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0125, d_svhn_loss: 0.0228, d_fake_loss: 0.0656, g_loss: 1.2404\n",
            "Step [31850/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0085, d_svhn_loss: 0.0422, d_fake_loss: 0.0565, g_loss: 0.9179\n",
            "Step [31860/80000], d_real_loss: 0.0695, d_mnist_loss: 0.0444, d_svhn_loss: 0.0251, d_fake_loss: 0.0453, g_loss: 1.0812\n",
            "Step [31870/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0156, d_svhn_loss: 0.0266, d_fake_loss: 0.0745, g_loss: 1.2650\n",
            "Step [31880/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0106, d_svhn_loss: 0.0192, d_fake_loss: 0.0476, g_loss: 1.0832\n",
            "Step [31890/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0068, d_svhn_loss: 0.0208, d_fake_loss: 0.0357, g_loss: 1.0129\n",
            "Step [31900/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0156, d_svhn_loss: 0.0719, d_fake_loss: 0.0604, g_loss: 1.0101\n",
            "Step [31910/80000], d_real_loss: 0.0775, d_mnist_loss: 0.0531, d_svhn_loss: 0.0244, d_fake_loss: 0.0615, g_loss: 0.9537\n",
            "Step [31920/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0203, d_svhn_loss: 0.0433, d_fake_loss: 0.1041, g_loss: 1.0859\n",
            "Step [31930/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0123, d_svhn_loss: 0.0253, d_fake_loss: 0.0318, g_loss: 1.1460\n",
            "Step [31940/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0167, d_svhn_loss: 0.0248, d_fake_loss: 0.0279, g_loss: 1.0489\n",
            "Step [31950/80000], d_real_loss: 0.0882, d_mnist_loss: 0.0585, d_svhn_loss: 0.0297, d_fake_loss: 0.0387, g_loss: 1.1541\n",
            "Step [31960/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0113, d_svhn_loss: 0.0374, d_fake_loss: 0.0874, g_loss: 1.1033\n",
            "Step [31970/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0178, d_svhn_loss: 0.0303, d_fake_loss: 0.0345, g_loss: 1.2119\n",
            "Step [31980/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0103, d_svhn_loss: 0.0304, d_fake_loss: 0.0302, g_loss: 1.1393\n",
            "Step [31990/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0198, d_svhn_loss: 0.0241, d_fake_loss: 0.0306, g_loss: 1.0509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9995384812355042, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [32000/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0337, d_svhn_loss: 0.0273, d_fake_loss: 0.0603, g_loss: 1.1358\n",
            "saved ./samples_fashion/sample-32000-m-s.png\n",
            "saved ./samples_fashion/sample-32000-s-m.png\n",
            "Step [32010/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0299, d_svhn_loss: 0.0328, d_fake_loss: 0.0377, g_loss: 1.0512\n",
            "Step [32020/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0374, d_svhn_loss: 0.0302, d_fake_loss: 0.0355, g_loss: 1.1426\n",
            "Step [32030/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0388, d_svhn_loss: 0.0348, d_fake_loss: 0.0718, g_loss: 1.2226\n",
            "Step [32040/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0146, d_svhn_loss: 0.0274, d_fake_loss: 0.0655, g_loss: 1.2676\n",
            "Step [32050/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0141, d_svhn_loss: 0.0340, d_fake_loss: 0.0366, g_loss: 1.1416\n",
            "Step [32060/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0090, d_svhn_loss: 0.0164, d_fake_loss: 0.0466, g_loss: 1.0544\n",
            "Step [32070/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0183, d_svhn_loss: 0.0491, d_fake_loss: 0.0205, g_loss: 1.0087\n",
            "Step [32080/80000], d_real_loss: 0.0891, d_mnist_loss: 0.0054, d_svhn_loss: 0.0837, d_fake_loss: 0.0725, g_loss: 1.2912\n",
            "Step [32090/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0167, d_svhn_loss: 0.0546, d_fake_loss: 0.0927, g_loss: 1.4377\n",
            "Step [32100/80000], d_real_loss: 0.1143, d_mnist_loss: 0.0119, d_svhn_loss: 0.1023, d_fake_loss: 0.0935, g_loss: 0.9944\n",
            "Step [32110/80000], d_real_loss: 0.5078, d_mnist_loss: 0.4820, d_svhn_loss: 0.0258, d_fake_loss: 0.0631, g_loss: 1.5347\n",
            "Step [32120/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0112, d_svhn_loss: 0.0503, d_fake_loss: 0.0698, g_loss: 1.1690\n",
            "Step [32130/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0101, d_svhn_loss: 0.0724, d_fake_loss: 0.0786, g_loss: 1.1332\n",
            "Step [32140/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0098, d_svhn_loss: 0.0542, d_fake_loss: 0.0728, g_loss: 1.2766\n",
            "Step [32150/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0090, d_svhn_loss: 0.0311, d_fake_loss: 0.0355, g_loss: 1.0642\n",
            "Step [32160/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0250, d_svhn_loss: 0.0265, d_fake_loss: 0.0477, g_loss: 1.1446\n",
            "Step [32170/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0117, d_svhn_loss: 0.0378, d_fake_loss: 0.0575, g_loss: 1.0168\n",
            "Step [32180/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0125, d_svhn_loss: 0.0201, d_fake_loss: 0.1172, g_loss: 1.3245\n",
            "Step [32190/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0102, d_svhn_loss: 0.0373, d_fake_loss: 0.0656, g_loss: 0.9913\n",
            "Step [32200/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0431, d_svhn_loss: 0.0294, d_fake_loss: 0.0438, g_loss: 1.1102\n",
            "Step [32210/80000], d_real_loss: 0.4231, d_mnist_loss: 0.3568, d_svhn_loss: 0.0663, d_fake_loss: 0.1201, g_loss: 1.5999\n",
            "Step [32220/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0141, d_svhn_loss: 0.0382, d_fake_loss: 0.0446, g_loss: 1.1607\n",
            "Step [32230/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0151, d_svhn_loss: 0.0301, d_fake_loss: 0.0445, g_loss: 1.1440\n",
            "Step [32240/80000], d_real_loss: 0.0817, d_mnist_loss: 0.0092, d_svhn_loss: 0.0725, d_fake_loss: 0.1435, g_loss: 1.1588\n",
            "Step [32250/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0168, d_svhn_loss: 0.0237, d_fake_loss: 0.0379, g_loss: 1.0928\n",
            "Step [32260/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0159, d_svhn_loss: 0.0488, d_fake_loss: 0.0699, g_loss: 1.3317\n",
            "Step [32270/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0222, d_svhn_loss: 0.0200, d_fake_loss: 0.0452, g_loss: 1.2340\n",
            "Step [32280/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0105, d_svhn_loss: 0.0258, d_fake_loss: 0.0730, g_loss: 1.2252\n",
            "Step [32290/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0140, d_svhn_loss: 0.0220, d_fake_loss: 0.0530, g_loss: 1.1100\n",
            "Step [32300/80000], d_real_loss: 0.1300, d_mnist_loss: 0.0095, d_svhn_loss: 0.1205, d_fake_loss: 0.0691, g_loss: 1.0820\n",
            "Step [32310/80000], d_real_loss: 0.1312, d_mnist_loss: 0.0104, d_svhn_loss: 0.1209, d_fake_loss: 0.0496, g_loss: 1.1680\n",
            "Step [32320/80000], d_real_loss: 0.0874, d_mnist_loss: 0.0302, d_svhn_loss: 0.0572, d_fake_loss: 0.1038, g_loss: 1.2079\n",
            "Step [32330/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0447, d_svhn_loss: 0.0308, d_fake_loss: 0.0404, g_loss: 1.0827\n",
            "Step [32340/80000], d_real_loss: 0.0780, d_mnist_loss: 0.0212, d_svhn_loss: 0.0569, d_fake_loss: 0.0340, g_loss: 1.0045\n",
            "Step [32350/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0230, d_svhn_loss: 0.0294, d_fake_loss: 0.0685, g_loss: 1.0296\n",
            "Step [32360/80000], d_real_loss: 0.1087, d_mnist_loss: 0.0393, d_svhn_loss: 0.0695, d_fake_loss: 0.1400, g_loss: 1.2866\n",
            "Step [32370/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0202, d_svhn_loss: 0.0563, d_fake_loss: 0.0656, g_loss: 1.1856\n",
            "Step [32380/80000], d_real_loss: 0.0267, d_mnist_loss: 0.0085, d_svhn_loss: 0.0182, d_fake_loss: 0.0331, g_loss: 1.0245\n",
            "Step [32390/80000], d_real_loss: 0.0885, d_mnist_loss: 0.0156, d_svhn_loss: 0.0730, d_fake_loss: 0.0354, g_loss: 1.1643\n",
            "Step [32400/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0146, d_svhn_loss: 0.0277, d_fake_loss: 0.0319, g_loss: 0.9713\n",
            "Step [32410/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0216, d_svhn_loss: 0.0291, d_fake_loss: 0.0956, g_loss: 1.0722\n",
            "Step [32420/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0398, d_svhn_loss: 0.0318, d_fake_loss: 0.0483, g_loss: 1.3515\n",
            "Step [32430/80000], d_real_loss: 0.1894, d_mnist_loss: 0.0403, d_svhn_loss: 0.1491, d_fake_loss: 0.0422, g_loss: 1.1325\n",
            "Step [32440/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0138, d_svhn_loss: 0.0576, d_fake_loss: 0.0608, g_loss: 1.2395\n",
            "Step [32450/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0080, d_svhn_loss: 0.0299, d_fake_loss: 0.0678, g_loss: 1.3536\n",
            "Step [32460/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0122, d_svhn_loss: 0.0639, d_fake_loss: 0.0549, g_loss: 1.0820\n",
            "Step [32470/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0129, d_svhn_loss: 0.0209, d_fake_loss: 0.0373, g_loss: 1.1932\n",
            "Step [32480/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0163, d_svhn_loss: 0.0311, d_fake_loss: 0.0498, g_loss: 1.0659\n",
            "Step [32490/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0092, d_svhn_loss: 0.0602, d_fake_loss: 0.1168, g_loss: 1.1421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9993820190429688, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [32500/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0135, d_svhn_loss: 0.0310, d_fake_loss: 0.0360, g_loss: 1.2011\n",
            "saved ./samples_fashion/sample-32500-m-s.png\n",
            "saved ./samples_fashion/sample-32500-s-m.png\n",
            "Step [32510/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0342, d_svhn_loss: 0.0395, d_fake_loss: 0.0884, g_loss: 1.1541\n",
            "Step [32520/80000], d_real_loss: 0.0966, d_mnist_loss: 0.0136, d_svhn_loss: 0.0829, d_fake_loss: 0.0392, g_loss: 1.0730\n",
            "Step [32530/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0369, d_svhn_loss: 0.0434, d_fake_loss: 0.0539, g_loss: 1.3657\n",
            "Step [32540/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0091, d_svhn_loss: 0.0312, d_fake_loss: 0.0545, g_loss: 1.1857\n",
            "Step [32550/80000], d_real_loss: 0.2004, d_mnist_loss: 0.0406, d_svhn_loss: 0.1598, d_fake_loss: 0.0873, g_loss: 0.9489\n",
            "Step [32560/80000], d_real_loss: 0.0909, d_mnist_loss: 0.0480, d_svhn_loss: 0.0429, d_fake_loss: 0.0511, g_loss: 1.1295\n",
            "Step [32570/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0116, d_svhn_loss: 0.0470, d_fake_loss: 0.1008, g_loss: 1.0269\n",
            "Step [32580/80000], d_real_loss: 0.1145, d_mnist_loss: 0.0345, d_svhn_loss: 0.0800, d_fake_loss: 0.0448, g_loss: 1.1462\n",
            "Step [32590/80000], d_real_loss: 0.0951, d_mnist_loss: 0.0093, d_svhn_loss: 0.0858, d_fake_loss: 0.1103, g_loss: 1.2461\n",
            "Step [32600/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0080, d_svhn_loss: 0.0298, d_fake_loss: 0.0537, g_loss: 1.1635\n",
            "Step [32610/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0126, d_svhn_loss: 0.0483, d_fake_loss: 0.0344, g_loss: 1.1975\n",
            "Step [32620/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0118, d_svhn_loss: 0.0217, d_fake_loss: 0.0351, g_loss: 1.1453\n",
            "Step [32630/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0133, d_svhn_loss: 0.0651, d_fake_loss: 0.0722, g_loss: 1.3394\n",
            "Step [32640/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0107, d_svhn_loss: 0.0182, d_fake_loss: 0.0460, g_loss: 1.1770\n",
            "Step [32650/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0134, d_svhn_loss: 0.0583, d_fake_loss: 0.0616, g_loss: 0.9775\n",
            "Step [32660/80000], d_real_loss: 0.0751, d_mnist_loss: 0.0507, d_svhn_loss: 0.0244, d_fake_loss: 0.0328, g_loss: 1.1038\n",
            "Step [32670/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0232, d_svhn_loss: 0.0334, d_fake_loss: 0.1063, g_loss: 0.8877\n",
            "Step [32680/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0133, d_svhn_loss: 0.0413, d_fake_loss: 0.0662, g_loss: 1.2673\n",
            "Step [32690/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0074, d_svhn_loss: 0.0711, d_fake_loss: 0.0673, g_loss: 1.2899\n",
            "Step [32700/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0553, d_svhn_loss: 0.0229, d_fake_loss: 0.1347, g_loss: 1.8193\n",
            "Step [32710/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0116, d_svhn_loss: 0.0397, d_fake_loss: 0.0283, g_loss: 1.1628\n",
            "Step [32720/80000], d_real_loss: 0.1014, d_mnist_loss: 0.0629, d_svhn_loss: 0.0385, d_fake_loss: 0.0746, g_loss: 1.2581\n",
            "Step [32730/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0203, d_svhn_loss: 0.0307, d_fake_loss: 0.0686, g_loss: 1.2539\n",
            "Step [32740/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0160, d_svhn_loss: 0.0612, d_fake_loss: 0.0308, g_loss: 1.0030\n",
            "Step [32750/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0206, d_svhn_loss: 0.0336, d_fake_loss: 0.0513, g_loss: 1.1339\n",
            "Step [32760/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0189, d_svhn_loss: 0.0746, d_fake_loss: 0.0415, g_loss: 1.1762\n",
            "Step [32770/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0136, d_svhn_loss: 0.0477, d_fake_loss: 0.0386, g_loss: 1.0969\n",
            "Step [32780/80000], d_real_loss: 0.0886, d_mnist_loss: 0.0176, d_svhn_loss: 0.0710, d_fake_loss: 0.0412, g_loss: 1.0328\n",
            "Step [32790/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0308, d_svhn_loss: 0.0218, d_fake_loss: 0.0319, g_loss: 1.0889\n",
            "Step [32800/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0119, d_svhn_loss: 0.0323, d_fake_loss: 0.0898, g_loss: 1.0246\n",
            "Step [32810/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0102, d_svhn_loss: 0.0301, d_fake_loss: 0.0708, g_loss: 1.0812\n",
            "Step [32820/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0324, d_svhn_loss: 0.0301, d_fake_loss: 0.0680, g_loss: 1.2885\n",
            "Step [32830/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0173, d_svhn_loss: 0.0391, d_fake_loss: 0.1456, g_loss: 1.3480\n",
            "Step [32840/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0281, d_svhn_loss: 0.0232, d_fake_loss: 0.0957, g_loss: 1.4105\n",
            "Step [32850/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0075, d_svhn_loss: 0.0502, d_fake_loss: 0.0732, g_loss: 1.2720\n",
            "Step [32860/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0147, d_svhn_loss: 0.0182, d_fake_loss: 0.0494, g_loss: 1.1164\n",
            "Step [32870/80000], d_real_loss: 0.0798, d_mnist_loss: 0.0356, d_svhn_loss: 0.0442, d_fake_loss: 0.0807, g_loss: 1.3376\n",
            "Step [32880/80000], d_real_loss: 0.1079, d_mnist_loss: 0.0560, d_svhn_loss: 0.0519, d_fake_loss: 0.1422, g_loss: 1.3163\n",
            "Step [32890/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0143, d_svhn_loss: 0.0446, d_fake_loss: 0.0303, g_loss: 1.1343\n",
            "Step [32900/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0099, d_svhn_loss: 0.0194, d_fake_loss: 0.0358, g_loss: 1.1327\n",
            "Step [32910/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0237, d_svhn_loss: 0.0470, d_fake_loss: 0.0483, g_loss: 1.3724\n",
            "Step [32920/80000], d_real_loss: 0.0775, d_mnist_loss: 0.0228, d_svhn_loss: 0.0548, d_fake_loss: 0.0433, g_loss: 1.0909\n",
            "Step [32930/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0104, d_svhn_loss: 0.0220, d_fake_loss: 0.0493, g_loss: 1.3905\n",
            "Step [32940/80000], d_real_loss: 0.1034, d_mnist_loss: 0.0190, d_svhn_loss: 0.0843, d_fake_loss: 0.1951, g_loss: 1.1682\n",
            "Step [32950/80000], d_real_loss: 0.0735, d_mnist_loss: 0.0144, d_svhn_loss: 0.0591, d_fake_loss: 0.1262, g_loss: 1.0966\n",
            "Step [32960/80000], d_real_loss: 0.1491, d_mnist_loss: 0.0396, d_svhn_loss: 0.1095, d_fake_loss: 0.0898, g_loss: 1.1043\n",
            "Step [32970/80000], d_real_loss: 0.0852, d_mnist_loss: 0.0425, d_svhn_loss: 0.0428, d_fake_loss: 0.0827, g_loss: 1.1995\n",
            "Step [32980/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0140, d_svhn_loss: 0.0274, d_fake_loss: 0.1072, g_loss: 1.0637\n",
            "Step [32990/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0142, d_svhn_loss: 0.0365, d_fake_loss: 0.0678, g_loss: 1.0964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9990708231925964, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [33000/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0142, d_svhn_loss: 0.0452, d_fake_loss: 0.0626, g_loss: 1.2171\n",
            "saved ./samples_fashion/sample-33000-m-s.png\n",
            "saved ./samples_fashion/sample-33000-s-m.png\n",
            "Step [33010/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0122, d_svhn_loss: 0.0235, d_fake_loss: 0.1452, g_loss: 1.0159\n",
            "Step [33020/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0075, d_svhn_loss: 0.0330, d_fake_loss: 0.0373, g_loss: 1.1686\n",
            "Step [33030/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0134, d_svhn_loss: 0.0288, d_fake_loss: 0.0619, g_loss: 1.1809\n",
            "Step [33040/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0087, d_svhn_loss: 0.0439, d_fake_loss: 0.1236, g_loss: 1.0693\n",
            "Step [33050/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0095, d_svhn_loss: 0.0216, d_fake_loss: 0.0381, g_loss: 1.0918\n",
            "Step [33060/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0559, d_svhn_loss: 0.0225, d_fake_loss: 0.0681, g_loss: 1.1603\n",
            "Step [33070/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0085, d_svhn_loss: 0.0442, d_fake_loss: 0.0460, g_loss: 1.2828\n",
            "Step [33080/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0115, d_svhn_loss: 0.0493, d_fake_loss: 0.0356, g_loss: 1.1291\n",
            "Step [33090/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0473, d_svhn_loss: 0.0378, d_fake_loss: 0.0298, g_loss: 1.0247\n",
            "Step [33100/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0230, d_svhn_loss: 0.0261, d_fake_loss: 0.0404, g_loss: 1.0203\n",
            "Step [33110/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0105, d_svhn_loss: 0.0224, d_fake_loss: 0.0576, g_loss: 0.9996\n",
            "Step [33120/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0153, d_svhn_loss: 0.0485, d_fake_loss: 0.0680, g_loss: 1.1033\n",
            "Step [33130/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0329, d_svhn_loss: 0.0230, d_fake_loss: 0.0259, g_loss: 1.0538\n",
            "Step [33140/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0276, d_svhn_loss: 0.0466, d_fake_loss: 0.0407, g_loss: 1.2696\n",
            "Step [33150/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0098, d_svhn_loss: 0.0445, d_fake_loss: 0.0465, g_loss: 1.1063\n",
            "Step [33160/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0092, d_svhn_loss: 0.0431, d_fake_loss: 0.0358, g_loss: 1.1216\n",
            "Step [33170/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0183, d_svhn_loss: 0.0400, d_fake_loss: 0.0271, g_loss: 1.1017\n",
            "Step [33180/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0105, d_svhn_loss: 0.0234, d_fake_loss: 0.0318, g_loss: 1.1044\n",
            "Step [33190/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0148, d_svhn_loss: 0.0380, d_fake_loss: 0.0377, g_loss: 1.2703\n",
            "Step [33200/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0227, d_svhn_loss: 0.0373, d_fake_loss: 0.0430, g_loss: 1.0081\n",
            "Step [33210/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0139, d_svhn_loss: 0.0313, d_fake_loss: 0.0498, g_loss: 1.2152\n",
            "Step [33220/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0167, d_svhn_loss: 0.0448, d_fake_loss: 0.1998, g_loss: 1.2702\n",
            "Step [33230/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0190, d_svhn_loss: 0.0228, d_fake_loss: 0.0413, g_loss: 0.9167\n",
            "Step [33240/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0398, d_svhn_loss: 0.0392, d_fake_loss: 0.1077, g_loss: 1.1567\n",
            "Step [33250/80000], d_real_loss: 0.0908, d_mnist_loss: 0.0079, d_svhn_loss: 0.0828, d_fake_loss: 0.0454, g_loss: 1.1983\n",
            "Step [33260/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0438, d_svhn_loss: 0.0229, d_fake_loss: 0.0611, g_loss: 0.9639\n",
            "Step [33270/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0185, d_svhn_loss: 0.0195, d_fake_loss: 0.0399, g_loss: 1.0799\n",
            "Step [33280/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0093, d_svhn_loss: 0.0305, d_fake_loss: 0.0304, g_loss: 1.1539\n",
            "Step [33290/80000], d_real_loss: 0.0834, d_mnist_loss: 0.0098, d_svhn_loss: 0.0736, d_fake_loss: 0.0324, g_loss: 1.1924\n",
            "Step [33300/80000], d_real_loss: 0.1089, d_mnist_loss: 0.0197, d_svhn_loss: 0.0892, d_fake_loss: 0.0547, g_loss: 1.2295\n",
            "Step [33310/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0125, d_svhn_loss: 0.0341, d_fake_loss: 0.0447, g_loss: 1.1931\n",
            "Step [33320/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0133, d_svhn_loss: 0.0227, d_fake_loss: 0.0323, g_loss: 1.1307\n",
            "Step [33330/80000], d_real_loss: 0.2094, d_mnist_loss: 0.0775, d_svhn_loss: 0.1318, d_fake_loss: 0.0967, g_loss: 1.2689\n",
            "Step [33340/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0190, d_svhn_loss: 0.0384, d_fake_loss: 0.0905, g_loss: 1.2646\n",
            "Step [33350/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0125, d_svhn_loss: 0.0216, d_fake_loss: 0.0365, g_loss: 1.1082\n",
            "Step [33360/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0081, d_svhn_loss: 0.0282, d_fake_loss: 0.0309, g_loss: 1.2379\n",
            "Step [33370/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0121, d_svhn_loss: 0.0204, d_fake_loss: 0.0405, g_loss: 1.2292\n",
            "Step [33380/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0115, d_svhn_loss: 0.0476, d_fake_loss: 0.0374, g_loss: 1.3176\n",
            "Step [33390/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0202, d_svhn_loss: 0.0228, d_fake_loss: 0.0766, g_loss: 1.0860\n",
            "Step [33400/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0218, d_svhn_loss: 0.0228, d_fake_loss: 0.0494, g_loss: 1.1391\n",
            "Step [33410/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0184, d_svhn_loss: 0.0195, d_fake_loss: 0.0864, g_loss: 1.1697\n",
            "Step [33420/80000], d_real_loss: 0.1107, d_mnist_loss: 0.0105, d_svhn_loss: 0.1002, d_fake_loss: 0.1213, g_loss: 1.1049\n",
            "Step [33430/80000], d_real_loss: 0.2237, d_mnist_loss: 0.0922, d_svhn_loss: 0.1314, d_fake_loss: 0.1012, g_loss: 1.2869\n",
            "Step [33440/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0130, d_svhn_loss: 0.0263, d_fake_loss: 0.0835, g_loss: 1.2866\n",
            "Step [33450/80000], d_real_loss: 0.0704, d_mnist_loss: 0.0144, d_svhn_loss: 0.0560, d_fake_loss: 0.0482, g_loss: 1.1110\n",
            "Step [33460/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0184, d_svhn_loss: 0.0490, d_fake_loss: 0.0470, g_loss: 0.9901\n",
            "Step [33470/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0194, d_svhn_loss: 0.0278, d_fake_loss: 0.0781, g_loss: 1.1185\n",
            "Step [33480/80000], d_real_loss: 0.0947, d_mnist_loss: 0.0209, d_svhn_loss: 0.0737, d_fake_loss: 0.0738, g_loss: 0.9535\n",
            "Step [33490/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0130, d_svhn_loss: 0.0384, d_fake_loss: 0.0520, g_loss: 1.1243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9972704648971558, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [33500/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0070, d_svhn_loss: 0.0646, d_fake_loss: 0.0428, g_loss: 1.1401\n",
            "saved ./samples_fashion/sample-33500-m-s.png\n",
            "saved ./samples_fashion/sample-33500-s-m.png\n",
            "Step [33510/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0181, d_svhn_loss: 0.0153, d_fake_loss: 0.0941, g_loss: 0.9259\n",
            "Step [33520/80000], d_real_loss: 0.1046, d_mnist_loss: 0.0098, d_svhn_loss: 0.0948, d_fake_loss: 0.0718, g_loss: 1.0898\n",
            "Step [33530/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0129, d_svhn_loss: 0.0317, d_fake_loss: 0.0998, g_loss: 1.1208\n",
            "Step [33540/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0204, d_svhn_loss: 0.0315, d_fake_loss: 0.0394, g_loss: 1.0663\n",
            "Step [33550/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0467, d_svhn_loss: 0.0303, d_fake_loss: 0.0528, g_loss: 1.1510\n",
            "Step [33560/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0139, d_svhn_loss: 0.0284, d_fake_loss: 0.0773, g_loss: 1.4657\n",
            "Step [33570/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0129, d_svhn_loss: 0.0408, d_fake_loss: 0.0322, g_loss: 1.0515\n",
            "Step [33580/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0154, d_svhn_loss: 0.0470, d_fake_loss: 0.1226, g_loss: 1.1445\n",
            "Step [33590/80000], d_real_loss: 0.0832, d_mnist_loss: 0.0207, d_svhn_loss: 0.0625, d_fake_loss: 0.0541, g_loss: 1.1349\n",
            "Step [33600/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0150, d_svhn_loss: 0.0262, d_fake_loss: 0.0278, g_loss: 1.1233\n",
            "Step [33610/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0123, d_svhn_loss: 0.0517, d_fake_loss: 0.0693, g_loss: 1.1647\n",
            "Step [33620/80000], d_real_loss: 0.1671, d_mnist_loss: 0.0151, d_svhn_loss: 0.1520, d_fake_loss: 0.0863, g_loss: 0.9906\n",
            "Step [33630/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0102, d_svhn_loss: 0.0254, d_fake_loss: 0.0379, g_loss: 1.0526\n",
            "Step [33640/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0111, d_svhn_loss: 0.0387, d_fake_loss: 0.0627, g_loss: 1.0442\n",
            "Step [33650/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0230, d_svhn_loss: 0.0228, d_fake_loss: 0.0955, g_loss: 1.2168\n",
            "Step [33660/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0209, d_svhn_loss: 0.0233, d_fake_loss: 0.0703, g_loss: 1.3910\n",
            "Step [33670/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0103, d_svhn_loss: 0.0223, d_fake_loss: 0.0268, g_loss: 1.1811\n",
            "Step [33680/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0113, d_svhn_loss: 0.0416, d_fake_loss: 0.0620, g_loss: 1.2110\n",
            "Step [33690/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0142, d_svhn_loss: 0.0505, d_fake_loss: 0.0665, g_loss: 1.1311\n",
            "Step [33700/80000], d_real_loss: 0.1375, d_mnist_loss: 0.0240, d_svhn_loss: 0.1135, d_fake_loss: 0.0349, g_loss: 1.2859\n",
            "Step [33710/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0121, d_svhn_loss: 0.0287, d_fake_loss: 0.0289, g_loss: 1.0963\n",
            "Step [33720/80000], d_real_loss: 0.1245, d_mnist_loss: 0.0978, d_svhn_loss: 0.0267, d_fake_loss: 0.0369, g_loss: 1.2030\n",
            "Step [33730/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0126, d_svhn_loss: 0.0214, d_fake_loss: 0.0483, g_loss: 1.0207\n",
            "Step [33740/80000], d_real_loss: 0.1630, d_mnist_loss: 0.0371, d_svhn_loss: 0.1260, d_fake_loss: 0.2030, g_loss: 1.1782\n",
            "Step [33750/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0155, d_svhn_loss: 0.0524, d_fake_loss: 0.0306, g_loss: 1.0267\n",
            "Step [33760/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0309, d_svhn_loss: 0.0220, d_fake_loss: 0.0411, g_loss: 1.1836\n",
            "Step [33770/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0111, d_svhn_loss: 0.0371, d_fake_loss: 0.0719, g_loss: 1.2237\n",
            "Step [33780/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0111, d_svhn_loss: 0.0208, d_fake_loss: 0.0566, g_loss: 1.2608\n",
            "Step [33790/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0086, d_svhn_loss: 0.0227, d_fake_loss: 0.0635, g_loss: 1.1058\n",
            "Step [33800/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0085, d_svhn_loss: 0.0256, d_fake_loss: 0.0162, g_loss: 1.1359\n",
            "Step [33810/80000], d_real_loss: 0.1328, d_mnist_loss: 0.0248, d_svhn_loss: 0.1080, d_fake_loss: 0.2952, g_loss: 0.9690\n",
            "Step [33820/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0142, d_svhn_loss: 0.0439, d_fake_loss: 0.0890, g_loss: 1.1334\n",
            "Step [33830/80000], d_real_loss: 0.0789, d_mnist_loss: 0.0529, d_svhn_loss: 0.0260, d_fake_loss: 0.0883, g_loss: 1.0194\n",
            "Step [33840/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0114, d_svhn_loss: 0.0240, d_fake_loss: 0.0444, g_loss: 1.2128\n",
            "Step [33850/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0273, d_svhn_loss: 0.0239, d_fake_loss: 0.0273, g_loss: 1.1248\n",
            "Step [33860/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0115, d_svhn_loss: 0.0342, d_fake_loss: 0.0405, g_loss: 1.2383\n",
            "Step [33870/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0283, d_svhn_loss: 0.0439, d_fake_loss: 0.0466, g_loss: 1.1170\n",
            "Step [33880/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0152, d_svhn_loss: 0.0404, d_fake_loss: 0.0856, g_loss: 1.1358\n",
            "Step [33890/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0165, d_svhn_loss: 0.0310, d_fake_loss: 0.0626, g_loss: 1.1732\n",
            "Step [33900/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0135, d_svhn_loss: 0.0203, d_fake_loss: 0.1002, g_loss: 1.0909\n",
            "Step [33910/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0157, d_svhn_loss: 0.0459, d_fake_loss: 0.0554, g_loss: 0.9035\n",
            "Step [33920/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0212, d_svhn_loss: 0.0358, d_fake_loss: 0.0826, g_loss: 0.9616\n",
            "Step [33930/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0416, d_svhn_loss: 0.0293, d_fake_loss: 0.0453, g_loss: 1.2697\n",
            "Step [33940/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0113, d_svhn_loss: 0.0438, d_fake_loss: 0.0353, g_loss: 1.0653\n",
            "Step [33950/80000], d_real_loss: 0.1065, d_mnist_loss: 0.0530, d_svhn_loss: 0.0535, d_fake_loss: 0.0549, g_loss: 1.5867\n",
            "Step [33960/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0121, d_svhn_loss: 0.0217, d_fake_loss: 0.0396, g_loss: 1.0754\n",
            "Step [33970/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0121, d_svhn_loss: 0.0436, d_fake_loss: 0.1651, g_loss: 1.2346\n",
            "Step [33980/80000], d_real_loss: 0.0979, d_mnist_loss: 0.0649, d_svhn_loss: 0.0331, d_fake_loss: 0.1246, g_loss: 1.1335\n",
            "Step [33990/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0232, d_svhn_loss: 0.0261, d_fake_loss: 0.0820, g_loss: 1.2434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9882923364639282, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [34000/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0164, d_svhn_loss: 0.0260, d_fake_loss: 0.0466, g_loss: 1.2243\n",
            "saved ./samples_fashion/sample-34000-m-s.png\n",
            "saved ./samples_fashion/sample-34000-s-m.png\n",
            "Step [34010/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0131, d_svhn_loss: 0.0553, d_fake_loss: 0.0592, g_loss: 1.0325\n",
            "Step [34020/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0104, d_svhn_loss: 0.0323, d_fake_loss: 0.0356, g_loss: 1.2000\n",
            "Step [34030/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0156, d_svhn_loss: 0.0251, d_fake_loss: 0.0560, g_loss: 1.0282\n",
            "Step [34040/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0367, d_svhn_loss: 0.0583, d_fake_loss: 0.0418, g_loss: 1.0866\n",
            "Step [34050/80000], d_real_loss: 0.1009, d_mnist_loss: 0.0198, d_svhn_loss: 0.0811, d_fake_loss: 0.0664, g_loss: 0.9766\n",
            "Step [34060/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0142, d_svhn_loss: 0.0215, d_fake_loss: 0.0437, g_loss: 1.1874\n",
            "Step [34070/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0110, d_svhn_loss: 0.0490, d_fake_loss: 0.0554, g_loss: 1.3358\n",
            "Step [34080/80000], d_real_loss: 0.0845, d_mnist_loss: 0.0197, d_svhn_loss: 0.0648, d_fake_loss: 0.0395, g_loss: 1.1196\n",
            "Step [34090/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0125, d_svhn_loss: 0.0433, d_fake_loss: 0.0368, g_loss: 1.1037\n",
            "Step [34100/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0302, d_svhn_loss: 0.0278, d_fake_loss: 0.0453, g_loss: 1.1847\n",
            "Step [34110/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0117, d_svhn_loss: 0.0286, d_fake_loss: 0.0788, g_loss: 1.3983\n",
            "Step [34120/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0124, d_svhn_loss: 0.0302, d_fake_loss: 0.0797, g_loss: 1.2281\n",
            "Step [34130/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0335, d_svhn_loss: 0.0219, d_fake_loss: 0.0339, g_loss: 1.2840\n",
            "Step [34140/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0148, d_svhn_loss: 0.0482, d_fake_loss: 0.0401, g_loss: 1.1673\n",
            "Step [34150/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0176, d_svhn_loss: 0.0438, d_fake_loss: 0.0356, g_loss: 1.0182\n",
            "Step [34160/80000], d_real_loss: 0.0754, d_mnist_loss: 0.0202, d_svhn_loss: 0.0552, d_fake_loss: 0.0995, g_loss: 1.2600\n",
            "Step [34170/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0111, d_svhn_loss: 0.0218, d_fake_loss: 0.0358, g_loss: 1.1369\n",
            "Step [34180/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0201, d_svhn_loss: 0.0363, d_fake_loss: 0.0241, g_loss: 1.2081\n",
            "Step [34190/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0224, d_svhn_loss: 0.0289, d_fake_loss: 0.0475, g_loss: 1.0987\n",
            "Step [34200/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0105, d_svhn_loss: 0.0270, d_fake_loss: 0.0369, g_loss: 1.2460\n",
            "Step [34210/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0120, d_svhn_loss: 0.0422, d_fake_loss: 0.0930, g_loss: 1.3395\n",
            "Step [34220/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0127, d_svhn_loss: 0.0314, d_fake_loss: 0.0315, g_loss: 1.1560\n",
            "Step [34230/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0193, d_svhn_loss: 0.0307, d_fake_loss: 0.0733, g_loss: 1.4724\n",
            "Step [34240/80000], d_real_loss: 0.1006, d_mnist_loss: 0.0164, d_svhn_loss: 0.0842, d_fake_loss: 0.0969, g_loss: 1.1037\n",
            "Step [34250/80000], d_real_loss: 0.1240, d_mnist_loss: 0.0496, d_svhn_loss: 0.0744, d_fake_loss: 0.0314, g_loss: 0.9877\n",
            "Step [34260/80000], d_real_loss: 0.0779, d_mnist_loss: 0.0513, d_svhn_loss: 0.0266, d_fake_loss: 0.0514, g_loss: 0.9700\n",
            "Step [34270/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0096, d_svhn_loss: 0.0329, d_fake_loss: 0.1097, g_loss: 1.0326\n",
            "Step [34280/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0143, d_svhn_loss: 0.0459, d_fake_loss: 0.0645, g_loss: 0.9391\n",
            "Step [34290/80000], d_real_loss: 0.0260, d_mnist_loss: 0.0110, d_svhn_loss: 0.0150, d_fake_loss: 0.0401, g_loss: 1.2079\n",
            "Step [34300/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0128, d_svhn_loss: 0.0324, d_fake_loss: 0.0957, g_loss: 1.6117\n",
            "Step [34310/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0146, d_svhn_loss: 0.0346, d_fake_loss: 0.0723, g_loss: 1.2114\n",
            "Step [34320/80000], d_real_loss: 0.0988, d_mnist_loss: 0.0137, d_svhn_loss: 0.0850, d_fake_loss: 0.0406, g_loss: 1.1892\n",
            "Step [34330/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0166, d_svhn_loss: 0.0586, d_fake_loss: 0.1235, g_loss: 1.1324\n",
            "Step [34340/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0140, d_svhn_loss: 0.0204, d_fake_loss: 0.0506, g_loss: 1.0573\n",
            "Step [34350/80000], d_real_loss: 0.0847, d_mnist_loss: 0.0142, d_svhn_loss: 0.0704, d_fake_loss: 0.0511, g_loss: 1.0083\n",
            "Step [34360/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0112, d_svhn_loss: 0.0225, d_fake_loss: 0.0288, g_loss: 1.1034\n",
            "Step [34370/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0249, d_svhn_loss: 0.0348, d_fake_loss: 0.0548, g_loss: 1.1637\n",
            "Step [34380/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0136, d_svhn_loss: 0.0237, d_fake_loss: 0.1270, g_loss: 1.2066\n",
            "Step [34390/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0135, d_svhn_loss: 0.0331, d_fake_loss: 0.0282, g_loss: 1.0689\n",
            "Step [34400/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0120, d_svhn_loss: 0.0218, d_fake_loss: 0.0470, g_loss: 1.1841\n",
            "Step [34410/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0127, d_svhn_loss: 0.0175, d_fake_loss: 0.0646, g_loss: 1.0821\n",
            "Step [34420/80000], d_real_loss: 0.0780, d_mnist_loss: 0.0445, d_svhn_loss: 0.0336, d_fake_loss: 0.0467, g_loss: 1.1173\n",
            "Step [34430/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0290, d_svhn_loss: 0.0205, d_fake_loss: 0.0757, g_loss: 1.1705\n",
            "Step [34440/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0147, d_svhn_loss: 0.0630, d_fake_loss: 0.0717, g_loss: 0.8708\n",
            "Step [34450/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0160, d_svhn_loss: 0.0228, d_fake_loss: 0.0419, g_loss: 1.1798\n",
            "Step [34460/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0529, d_svhn_loss: 0.0406, d_fake_loss: 0.1225, g_loss: 1.0223\n",
            "Step [34470/80000], d_real_loss: 0.1865, d_mnist_loss: 0.0260, d_svhn_loss: 0.1605, d_fake_loss: 0.1166, g_loss: 1.1274\n",
            "Step [34480/80000], d_real_loss: 0.0928, d_mnist_loss: 0.0534, d_svhn_loss: 0.0394, d_fake_loss: 0.0728, g_loss: 1.2397\n",
            "Step [34490/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0299, d_svhn_loss: 0.0264, d_fake_loss: 0.0494, g_loss: 1.0579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9923617243766785, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [34500/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0226, d_svhn_loss: 0.0549, d_fake_loss: 0.0507, g_loss: 1.1953\n",
            "saved ./samples_fashion/sample-34500-m-s.png\n",
            "saved ./samples_fashion/sample-34500-s-m.png\n",
            "Step [34510/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0161, d_svhn_loss: 0.0364, d_fake_loss: 0.0434, g_loss: 1.0739\n",
            "Step [34520/80000], d_real_loss: 0.1358, d_mnist_loss: 0.0145, d_svhn_loss: 0.1213, d_fake_loss: 0.0375, g_loss: 1.0244\n",
            "Step [34530/80000], d_real_loss: 0.0991, d_mnist_loss: 0.0154, d_svhn_loss: 0.0838, d_fake_loss: 0.0392, g_loss: 1.1338\n",
            "Step [34540/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0182, d_svhn_loss: 0.0422, d_fake_loss: 0.0331, g_loss: 1.0533\n",
            "Step [34550/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0214, d_svhn_loss: 0.0241, d_fake_loss: 0.0617, g_loss: 1.2695\n",
            "Step [34560/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0131, d_svhn_loss: 0.0653, d_fake_loss: 0.0281, g_loss: 1.0509\n",
            "Step [34570/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0067, d_svhn_loss: 0.0448, d_fake_loss: 0.0456, g_loss: 1.4406\n",
            "Step [34580/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0214, d_svhn_loss: 0.0469, d_fake_loss: 0.0457, g_loss: 1.1154\n",
            "Step [34590/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0212, d_svhn_loss: 0.0241, d_fake_loss: 0.0564, g_loss: 1.1769\n",
            "Step [34600/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0202, d_svhn_loss: 0.0261, d_fake_loss: 0.0620, g_loss: 1.1464\n",
            "Step [34610/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0167, d_svhn_loss: 0.0228, d_fake_loss: 0.0652, g_loss: 1.2917\n",
            "Step [34620/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0283, d_svhn_loss: 0.0410, d_fake_loss: 0.0767, g_loss: 1.2864\n",
            "Step [34630/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0267, d_svhn_loss: 0.0419, d_fake_loss: 0.3122, g_loss: 1.1089\n",
            "Step [34640/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0188, d_svhn_loss: 0.0236, d_fake_loss: 0.0519, g_loss: 1.2610\n",
            "Step [34650/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0188, d_svhn_loss: 0.0229, d_fake_loss: 0.0450, g_loss: 1.1518\n",
            "Step [34660/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0140, d_svhn_loss: 0.0244, d_fake_loss: 0.0615, g_loss: 1.3127\n",
            "Step [34670/80000], d_real_loss: 0.0863, d_mnist_loss: 0.0145, d_svhn_loss: 0.0718, d_fake_loss: 0.0432, g_loss: 1.0702\n",
            "Step [34680/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0102, d_svhn_loss: 0.0478, d_fake_loss: 0.0480, g_loss: 0.9955\n",
            "Step [34690/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0125, d_svhn_loss: 0.0259, d_fake_loss: 0.0383, g_loss: 1.0790\n",
            "Step [34700/80000], d_real_loss: 0.1035, d_mnist_loss: 0.0141, d_svhn_loss: 0.0894, d_fake_loss: 0.1065, g_loss: 1.2062\n",
            "Step [34710/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0142, d_svhn_loss: 0.0181, d_fake_loss: 0.0370, g_loss: 1.1363\n",
            "Step [34720/80000], d_real_loss: 0.1921, d_mnist_loss: 0.1240, d_svhn_loss: 0.0681, d_fake_loss: 0.1189, g_loss: 1.6172\n",
            "Step [34730/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0188, d_svhn_loss: 0.0251, d_fake_loss: 0.0635, g_loss: 0.9004\n",
            "Step [34740/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0093, d_svhn_loss: 0.0637, d_fake_loss: 0.0751, g_loss: 1.1123\n",
            "Step [34750/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0160, d_svhn_loss: 0.0381, d_fake_loss: 0.0310, g_loss: 1.1697\n",
            "Step [34760/80000], d_real_loss: 0.0925, d_mnist_loss: 0.0371, d_svhn_loss: 0.0554, d_fake_loss: 0.0425, g_loss: 0.9159\n",
            "Step [34770/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0120, d_svhn_loss: 0.0263, d_fake_loss: 0.0832, g_loss: 1.0850\n",
            "Step [34780/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0260, d_svhn_loss: 0.0389, d_fake_loss: 0.0519, g_loss: 1.2205\n",
            "Step [34790/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0292, d_svhn_loss: 0.0165, d_fake_loss: 0.0365, g_loss: 1.2227\n",
            "Step [34800/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0400, d_svhn_loss: 0.0274, d_fake_loss: 0.0437, g_loss: 1.0566\n",
            "Step [34810/80000], d_real_loss: 0.1281, d_mnist_loss: 0.0132, d_svhn_loss: 0.1149, d_fake_loss: 0.2422, g_loss: 1.1412\n",
            "Step [34820/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0093, d_svhn_loss: 0.0359, d_fake_loss: 0.0926, g_loss: 1.1254\n",
            "Step [34830/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0191, d_svhn_loss: 0.0353, d_fake_loss: 0.0588, g_loss: 1.1892\n",
            "Step [34840/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0104, d_svhn_loss: 0.0357, d_fake_loss: 0.0695, g_loss: 1.1587\n",
            "Step [34850/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0136, d_svhn_loss: 0.0418, d_fake_loss: 0.0588, g_loss: 1.1401\n",
            "Step [34860/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0127, d_svhn_loss: 0.0490, d_fake_loss: 0.0275, g_loss: 1.1121\n",
            "Step [34870/80000], d_real_loss: 0.0385, d_mnist_loss: 0.0126, d_svhn_loss: 0.0258, d_fake_loss: 0.1088, g_loss: 1.2483\n",
            "Step [34880/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0127, d_svhn_loss: 0.0722, d_fake_loss: 0.0766, g_loss: 1.2410\n",
            "Step [34890/80000], d_real_loss: 0.1211, d_mnist_loss: 0.0334, d_svhn_loss: 0.0877, d_fake_loss: 0.1290, g_loss: 1.1181\n",
            "Step [34900/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0100, d_svhn_loss: 0.0459, d_fake_loss: 0.0934, g_loss: 1.1666\n",
            "Step [34910/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0148, d_svhn_loss: 0.0338, d_fake_loss: 0.0700, g_loss: 1.2725\n",
            "Step [34920/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0143, d_svhn_loss: 0.0237, d_fake_loss: 0.0624, g_loss: 1.2660\n",
            "Step [34930/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0126, d_svhn_loss: 0.0233, d_fake_loss: 0.0960, g_loss: 1.0733\n",
            "Step [34940/80000], d_real_loss: 0.0922, d_mnist_loss: 0.0486, d_svhn_loss: 0.0436, d_fake_loss: 0.0565, g_loss: 1.1594\n",
            "Step [34950/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0112, d_svhn_loss: 0.0167, d_fake_loss: 0.0745, g_loss: 1.1806\n",
            "Step [34960/80000], d_real_loss: 0.2132, d_mnist_loss: 0.0331, d_svhn_loss: 0.1801, d_fake_loss: 0.0710, g_loss: 1.4303\n",
            "Step [34970/80000], d_real_loss: 0.2119, d_mnist_loss: 0.0145, d_svhn_loss: 0.1974, d_fake_loss: 0.0778, g_loss: 1.2819\n",
            "Step [34980/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0231, d_svhn_loss: 0.0240, d_fake_loss: 0.0751, g_loss: 1.1499\n",
            "Step [34990/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0102, d_svhn_loss: 0.0203, d_fake_loss: 0.0485, g_loss: 0.9654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9940615892410278, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [35000/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0152, d_svhn_loss: 0.0316, d_fake_loss: 0.0710, g_loss: 1.1964\n",
            "saved ./samples_fashion/sample-35000-m-s.png\n",
            "saved ./samples_fashion/sample-35000-s-m.png\n",
            "Step [35010/80000], d_real_loss: 0.0943, d_mnist_loss: 0.0248, d_svhn_loss: 0.0695, d_fake_loss: 0.0773, g_loss: 1.2327\n",
            "Step [35020/80000], d_real_loss: 0.0779, d_mnist_loss: 0.0141, d_svhn_loss: 0.0638, d_fake_loss: 0.0697, g_loss: 1.1472\n",
            "Step [35030/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0079, d_svhn_loss: 0.0463, d_fake_loss: 0.0361, g_loss: 1.1527\n",
            "Step [35040/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0333, d_svhn_loss: 0.0178, d_fake_loss: 0.0556, g_loss: 1.2928\n",
            "Step [35050/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0128, d_svhn_loss: 0.0242, d_fake_loss: 0.0602, g_loss: 1.3888\n",
            "Step [35060/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0257, d_svhn_loss: 0.0424, d_fake_loss: 0.0411, g_loss: 1.0587\n",
            "Step [35070/80000], d_real_loss: 0.0984, d_mnist_loss: 0.0156, d_svhn_loss: 0.0828, d_fake_loss: 0.1208, g_loss: 1.0305\n",
            "Step [35080/80000], d_real_loss: 0.1241, d_mnist_loss: 0.1011, d_svhn_loss: 0.0230, d_fake_loss: 0.0441, g_loss: 1.2870\n",
            "Step [35090/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0206, d_svhn_loss: 0.0259, d_fake_loss: 0.0404, g_loss: 0.9716\n",
            "Step [35100/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0187, d_svhn_loss: 0.0386, d_fake_loss: 0.0591, g_loss: 1.1792\n",
            "Step [35110/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0129, d_svhn_loss: 0.0266, d_fake_loss: 0.0287, g_loss: 1.2053\n",
            "Step [35120/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0201, d_svhn_loss: 0.0256, d_fake_loss: 0.0401, g_loss: 1.0316\n",
            "Step [35130/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0256, d_svhn_loss: 0.0294, d_fake_loss: 0.0979, g_loss: 0.9857\n",
            "Step [35140/80000], d_real_loss: 0.0927, d_mnist_loss: 0.0406, d_svhn_loss: 0.0521, d_fake_loss: 0.0392, g_loss: 1.0839\n",
            "Step [35150/80000], d_real_loss: 0.1027, d_mnist_loss: 0.0072, d_svhn_loss: 0.0955, d_fake_loss: 0.0337, g_loss: 1.2921\n",
            "Step [35160/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0290, d_svhn_loss: 0.0242, d_fake_loss: 0.0365, g_loss: 1.0018\n",
            "Step [35170/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0362, d_svhn_loss: 0.0280, d_fake_loss: 0.0853, g_loss: 1.2299\n",
            "Step [35180/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0123, d_svhn_loss: 0.0287, d_fake_loss: 0.0698, g_loss: 1.2020\n",
            "Step [35190/80000], d_real_loss: 0.0251, d_mnist_loss: 0.0103, d_svhn_loss: 0.0148, d_fake_loss: 0.0466, g_loss: 1.3105\n",
            "Step [35200/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0399, d_svhn_loss: 0.0269, d_fake_loss: 0.0872, g_loss: 0.9506\n",
            "Step [35210/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0371, d_svhn_loss: 0.0339, d_fake_loss: 0.0982, g_loss: 1.2487\n",
            "Step [35220/80000], d_real_loss: 0.0849, d_mnist_loss: 0.0095, d_svhn_loss: 0.0753, d_fake_loss: 0.0634, g_loss: 1.2434\n",
            "Step [35230/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0253, d_svhn_loss: 0.0269, d_fake_loss: 0.0715, g_loss: 1.2046\n",
            "Step [35240/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0090, d_svhn_loss: 0.0536, d_fake_loss: 0.0611, g_loss: 1.3984\n",
            "Step [35250/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0104, d_svhn_loss: 0.0227, d_fake_loss: 0.0442, g_loss: 1.3291\n",
            "Step [35260/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0105, d_svhn_loss: 0.0297, d_fake_loss: 0.0531, g_loss: 0.9779\n",
            "Step [35270/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0169, d_svhn_loss: 0.0258, d_fake_loss: 0.0293, g_loss: 1.0583\n",
            "Step [35280/80000], d_real_loss: 0.0954, d_mnist_loss: 0.0340, d_svhn_loss: 0.0614, d_fake_loss: 0.0488, g_loss: 0.9184\n",
            "Step [35290/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0174, d_svhn_loss: 0.0355, d_fake_loss: 0.0717, g_loss: 1.1527\n",
            "Step [35300/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0254, d_svhn_loss: 0.0179, d_fake_loss: 0.0342, g_loss: 1.1419\n",
            "Step [35310/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0142, d_svhn_loss: 0.0364, d_fake_loss: 0.0752, g_loss: 1.0233\n",
            "Step [35320/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0242, d_svhn_loss: 0.0228, d_fake_loss: 0.0620, g_loss: 1.1778\n",
            "Step [35330/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0363, d_svhn_loss: 0.0299, d_fake_loss: 0.0813, g_loss: 1.2751\n",
            "Step [35340/80000], d_real_loss: 0.2500, d_mnist_loss: 0.0285, d_svhn_loss: 0.2216, d_fake_loss: 0.1977, g_loss: 1.3674\n",
            "Step [35350/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0588, d_svhn_loss: 0.0328, d_fake_loss: 0.0264, g_loss: 1.1292\n",
            "Step [35360/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0199, d_svhn_loss: 0.0377, d_fake_loss: 0.0285, g_loss: 1.1535\n",
            "Step [35370/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0133, d_svhn_loss: 0.0370, d_fake_loss: 0.0486, g_loss: 1.1662\n",
            "Step [35380/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0178, d_svhn_loss: 0.0294, d_fake_loss: 0.0276, g_loss: 1.1345\n",
            "Step [35390/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0252, d_svhn_loss: 0.0370, d_fake_loss: 0.0270, g_loss: 1.0796\n",
            "Step [35400/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0102, d_svhn_loss: 0.0566, d_fake_loss: 0.0680, g_loss: 0.8915\n",
            "Step [35410/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0473, d_svhn_loss: 0.0360, d_fake_loss: 0.0450, g_loss: 1.0391\n",
            "Step [35420/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0131, d_svhn_loss: 0.0236, d_fake_loss: 0.0677, g_loss: 1.3227\n",
            "Step [35430/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0153, d_svhn_loss: 0.0304, d_fake_loss: 0.0318, g_loss: 1.2276\n",
            "Step [35440/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0218, d_svhn_loss: 0.0325, d_fake_loss: 0.0260, g_loss: 1.0432\n",
            "Step [35450/80000], d_real_loss: 0.1194, d_mnist_loss: 0.0691, d_svhn_loss: 0.0503, d_fake_loss: 0.0743, g_loss: 0.9566\n",
            "Step [35460/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0106, d_svhn_loss: 0.0353, d_fake_loss: 0.0869, g_loss: 1.2662\n",
            "Step [35470/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0591, d_svhn_loss: 0.0257, d_fake_loss: 0.0458, g_loss: 1.1515\n",
            "Step [35480/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0249, d_svhn_loss: 0.0297, d_fake_loss: 0.0374, g_loss: 1.1494\n",
            "Step [35490/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0266, d_svhn_loss: 0.0306, d_fake_loss: 0.0389, g_loss: 1.1210\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9860337376594543, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [35500/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0182, d_svhn_loss: 0.0173, d_fake_loss: 0.0610, g_loss: 0.9233\n",
            "saved ./samples_fashion/sample-35500-m-s.png\n",
            "saved ./samples_fashion/sample-35500-s-m.png\n",
            "Step [35510/80000], d_real_loss: 0.0882, d_mnist_loss: 0.0624, d_svhn_loss: 0.0258, d_fake_loss: 0.0347, g_loss: 1.1190\n",
            "Step [35520/80000], d_real_loss: 0.0709, d_mnist_loss: 0.0113, d_svhn_loss: 0.0596, d_fake_loss: 0.0429, g_loss: 1.0982\n",
            "Step [35530/80000], d_real_loss: 0.1350, d_mnist_loss: 0.0132, d_svhn_loss: 0.1218, d_fake_loss: 0.1297, g_loss: 1.0615\n",
            "Step [35540/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0291, d_svhn_loss: 0.0212, d_fake_loss: 0.0509, g_loss: 1.2176\n",
            "Step [35550/80000], d_real_loss: 0.0732, d_mnist_loss: 0.0179, d_svhn_loss: 0.0553, d_fake_loss: 0.1152, g_loss: 1.1485\n",
            "Step [35560/80000], d_real_loss: 0.1360, d_mnist_loss: 0.1004, d_svhn_loss: 0.0356, d_fake_loss: 0.1054, g_loss: 0.7607\n",
            "Step [35570/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0160, d_svhn_loss: 0.0415, d_fake_loss: 0.0553, g_loss: 1.0475\n",
            "Step [35580/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0097, d_svhn_loss: 0.0466, d_fake_loss: 0.0506, g_loss: 1.1368\n",
            "Step [35590/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0170, d_svhn_loss: 0.0241, d_fake_loss: 0.0665, g_loss: 1.1037\n",
            "Step [35600/80000], d_real_loss: 0.1065, d_mnist_loss: 0.0118, d_svhn_loss: 0.0947, d_fake_loss: 0.0418, g_loss: 1.1471\n",
            "Step [35610/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0242, d_svhn_loss: 0.0266, d_fake_loss: 0.0899, g_loss: 1.2899\n",
            "Step [35620/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0157, d_svhn_loss: 0.0279, d_fake_loss: 0.0515, g_loss: 1.1194\n",
            "Step [35630/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0093, d_svhn_loss: 0.0657, d_fake_loss: 0.0329, g_loss: 1.0862\n",
            "Step [35640/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0126, d_svhn_loss: 0.0368, d_fake_loss: 0.0596, g_loss: 1.1082\n",
            "Step [35650/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0126, d_svhn_loss: 0.0242, d_fake_loss: 0.0456, g_loss: 1.4043\n",
            "Step [35660/80000], d_real_loss: 0.1040, d_mnist_loss: 0.0113, d_svhn_loss: 0.0927, d_fake_loss: 0.0326, g_loss: 1.2233\n",
            "Step [35670/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0119, d_svhn_loss: 0.0485, d_fake_loss: 0.0921, g_loss: 1.2712\n",
            "Step [35680/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0090, d_svhn_loss: 0.0491, d_fake_loss: 0.0554, g_loss: 1.2684\n",
            "Step [35690/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0171, d_svhn_loss: 0.0352, d_fake_loss: 0.0483, g_loss: 1.2657\n",
            "Step [35700/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0139, d_svhn_loss: 0.0369, d_fake_loss: 0.0331, g_loss: 1.0526\n",
            "Step [35710/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0165, d_svhn_loss: 0.0513, d_fake_loss: 0.0465, g_loss: 0.9509\n",
            "Step [35720/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0174, d_svhn_loss: 0.0296, d_fake_loss: 0.0939, g_loss: 1.2874\n",
            "Step [35730/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0302, d_svhn_loss: 0.0265, d_fake_loss: 0.0891, g_loss: 0.8310\n",
            "Step [35740/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0274, d_svhn_loss: 0.0266, d_fake_loss: 0.0731, g_loss: 1.0650\n",
            "Step [35750/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0136, d_svhn_loss: 0.0265, d_fake_loss: 0.0303, g_loss: 1.1001\n",
            "Step [35760/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0291, d_svhn_loss: 0.0423, d_fake_loss: 0.1006, g_loss: 1.2954\n",
            "Step [35770/80000], d_real_loss: 0.1399, d_mnist_loss: 0.0157, d_svhn_loss: 0.1242, d_fake_loss: 0.0267, g_loss: 1.2169\n",
            "Step [35780/80000], d_real_loss: 0.1280, d_mnist_loss: 0.0743, d_svhn_loss: 0.0537, d_fake_loss: 0.1621, g_loss: 1.0335\n",
            "Step [35790/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0197, d_svhn_loss: 0.0260, d_fake_loss: 0.0327, g_loss: 1.0262\n",
            "Step [35800/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0209, d_svhn_loss: 0.0314, d_fake_loss: 0.0833, g_loss: 1.2258\n",
            "Step [35810/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0164, d_svhn_loss: 0.0260, d_fake_loss: 0.0463, g_loss: 1.2944\n",
            "Step [35820/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0432, d_svhn_loss: 0.0503, d_fake_loss: 0.0378, g_loss: 0.9985\n",
            "Step [35830/80000], d_real_loss: 0.1701, d_mnist_loss: 0.0358, d_svhn_loss: 0.1343, d_fake_loss: 0.0857, g_loss: 1.1214\n",
            "Step [35840/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0223, d_svhn_loss: 0.0306, d_fake_loss: 0.0374, g_loss: 1.1473\n",
            "Step [35850/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0168, d_svhn_loss: 0.0280, d_fake_loss: 0.0461, g_loss: 0.9451\n",
            "Step [35860/80000], d_real_loss: 0.0912, d_mnist_loss: 0.0092, d_svhn_loss: 0.0820, d_fake_loss: 0.0822, g_loss: 1.0796\n",
            "Step [35870/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0143, d_svhn_loss: 0.0426, d_fake_loss: 0.1181, g_loss: 1.3441\n",
            "Step [35880/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0298, d_svhn_loss: 0.0224, d_fake_loss: 0.0284, g_loss: 1.0916\n",
            "Step [35890/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0169, d_svhn_loss: 0.0309, d_fake_loss: 0.0584, g_loss: 0.8401\n",
            "Step [35900/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0135, d_svhn_loss: 0.0660, d_fake_loss: 0.0496, g_loss: 1.1916\n",
            "Step [35910/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0122, d_svhn_loss: 0.0495, d_fake_loss: 0.0553, g_loss: 1.0979\n",
            "Step [35920/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0366, d_svhn_loss: 0.0290, d_fake_loss: 0.1539, g_loss: 1.7509\n",
            "Step [35930/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0352, d_svhn_loss: 0.0379, d_fake_loss: 0.0440, g_loss: 1.1429\n",
            "Step [35940/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0175, d_svhn_loss: 0.0243, d_fake_loss: 0.0443, g_loss: 1.0588\n",
            "Step [35950/80000], d_real_loss: 0.1879, d_mnist_loss: 0.0132, d_svhn_loss: 0.1747, d_fake_loss: 0.2961, g_loss: 1.2898\n",
            "Step [35960/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0151, d_svhn_loss: 0.0461, d_fake_loss: 0.0354, g_loss: 1.0987\n",
            "Step [35970/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0139, d_svhn_loss: 0.0155, d_fake_loss: 0.1435, g_loss: 0.9704\n",
            "Step [35980/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0125, d_svhn_loss: 0.0392, d_fake_loss: 0.0500, g_loss: 1.1377\n",
            "Step [35990/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0255, d_svhn_loss: 0.0318, d_fake_loss: 0.1533, g_loss: 1.1691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.992719292640686, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [36000/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0151, d_svhn_loss: 0.0339, d_fake_loss: 0.0623, g_loss: 1.2207\n",
            "saved ./samples_fashion/sample-36000-m-s.png\n",
            "saved ./samples_fashion/sample-36000-s-m.png\n",
            "Step [36010/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0205, d_svhn_loss: 0.0163, d_fake_loss: 0.0307, g_loss: 1.1038\n",
            "Step [36020/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0448, d_svhn_loss: 0.0281, d_fake_loss: 0.0504, g_loss: 1.1788\n",
            "Step [36030/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0097, d_svhn_loss: 0.0294, d_fake_loss: 0.2778, g_loss: 1.1229\n",
            "Step [36040/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0136, d_svhn_loss: 0.0554, d_fake_loss: 0.0397, g_loss: 1.1855\n",
            "Step [36050/80000], d_real_loss: 0.0934, d_mnist_loss: 0.0145, d_svhn_loss: 0.0789, d_fake_loss: 0.0344, g_loss: 1.1969\n",
            "Step [36060/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0145, d_svhn_loss: 0.0220, d_fake_loss: 0.0403, g_loss: 1.0308\n",
            "Step [36070/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0142, d_svhn_loss: 0.0178, d_fake_loss: 0.0625, g_loss: 1.1569\n",
            "Step [36080/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0356, d_svhn_loss: 0.0249, d_fake_loss: 0.0459, g_loss: 1.1009\n",
            "Step [36090/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0269, d_svhn_loss: 0.0452, d_fake_loss: 0.0564, g_loss: 1.2215\n",
            "Step [36100/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0159, d_svhn_loss: 0.0316, d_fake_loss: 0.0447, g_loss: 1.1568\n",
            "Step [36110/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0127, d_svhn_loss: 0.0453, d_fake_loss: 0.0782, g_loss: 1.1607\n",
            "Step [36120/80000], d_real_loss: 0.0878, d_mnist_loss: 0.0160, d_svhn_loss: 0.0718, d_fake_loss: 0.0988, g_loss: 1.1124\n",
            "Step [36130/80000], d_real_loss: 0.0862, d_mnist_loss: 0.0287, d_svhn_loss: 0.0575, d_fake_loss: 0.0594, g_loss: 1.0837\n",
            "Step [36140/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0111, d_svhn_loss: 0.0559, d_fake_loss: 0.1191, g_loss: 1.0798\n",
            "Step [36150/80000], d_real_loss: 0.0922, d_mnist_loss: 0.0462, d_svhn_loss: 0.0459, d_fake_loss: 0.0418, g_loss: 0.9427\n",
            "Step [36160/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0109, d_svhn_loss: 0.0330, d_fake_loss: 0.0340, g_loss: 1.1179\n",
            "Step [36170/80000], d_real_loss: 0.0828, d_mnist_loss: 0.0356, d_svhn_loss: 0.0472, d_fake_loss: 0.0486, g_loss: 1.2877\n",
            "Step [36180/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0166, d_svhn_loss: 0.0264, d_fake_loss: 0.0591, g_loss: 0.9397\n",
            "Step [36190/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0135, d_svhn_loss: 0.0395, d_fake_loss: 0.0463, g_loss: 1.3725\n",
            "Step [36200/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0206, d_svhn_loss: 0.0380, d_fake_loss: 0.0988, g_loss: 1.2666\n",
            "Step [36210/80000], d_real_loss: 0.1141, d_mnist_loss: 0.0454, d_svhn_loss: 0.0686, d_fake_loss: 0.0872, g_loss: 1.1259\n",
            "Step [36220/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0142, d_svhn_loss: 0.0308, d_fake_loss: 0.0448, g_loss: 1.1958\n",
            "Step [36230/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0202, d_svhn_loss: 0.0193, d_fake_loss: 0.0329, g_loss: 1.1292\n",
            "Step [36240/80000], d_real_loss: 0.1322, d_mnist_loss: 0.0293, d_svhn_loss: 0.1029, d_fake_loss: 0.0773, g_loss: 0.9475\n",
            "Step [36250/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0163, d_svhn_loss: 0.0247, d_fake_loss: 0.0272, g_loss: 1.0623\n",
            "Step [36260/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0231, d_svhn_loss: 0.0280, d_fake_loss: 0.0647, g_loss: 1.1242\n",
            "Step [36270/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0108, d_svhn_loss: 0.0513, d_fake_loss: 0.0491, g_loss: 0.9703\n",
            "Step [36280/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0199, d_svhn_loss: 0.0365, d_fake_loss: 0.0330, g_loss: 1.1942\n",
            "Step [36290/80000], d_real_loss: 0.1669, d_mnist_loss: 0.0959, d_svhn_loss: 0.0710, d_fake_loss: 0.0565, g_loss: 1.2447\n",
            "Step [36300/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0134, d_svhn_loss: 0.0242, d_fake_loss: 0.0505, g_loss: 1.0158\n",
            "Step [36310/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0281, d_svhn_loss: 0.0372, d_fake_loss: 0.0666, g_loss: 1.1121\n",
            "Step [36320/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0222, d_svhn_loss: 0.0300, d_fake_loss: 0.1322, g_loss: 1.4556\n",
            "Step [36330/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0132, d_svhn_loss: 0.0187, d_fake_loss: 0.0506, g_loss: 1.2822\n",
            "Step [36340/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0188, d_svhn_loss: 0.0313, d_fake_loss: 0.0313, g_loss: 1.0460\n",
            "Step [36350/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0299, d_svhn_loss: 0.0331, d_fake_loss: 0.0508, g_loss: 1.2286\n",
            "Step [36360/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0140, d_svhn_loss: 0.0363, d_fake_loss: 0.0319, g_loss: 1.2600\n",
            "Step [36370/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0279, d_svhn_loss: 0.0346, d_fake_loss: 0.1740, g_loss: 1.3268\n",
            "Step [36380/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0127, d_svhn_loss: 0.0512, d_fake_loss: 0.0497, g_loss: 1.1795\n",
            "Step [36390/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0140, d_svhn_loss: 0.0366, d_fake_loss: 0.1495, g_loss: 1.2634\n",
            "Step [36400/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0169, d_svhn_loss: 0.0479, d_fake_loss: 0.0403, g_loss: 1.2379\n",
            "Step [36410/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0357, d_svhn_loss: 0.0214, d_fake_loss: 0.0657, g_loss: 1.1691\n",
            "Step [36420/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0094, d_svhn_loss: 0.0206, d_fake_loss: 0.0307, g_loss: 1.1769\n",
            "Step [36430/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0153, d_svhn_loss: 0.0448, d_fake_loss: 0.0441, g_loss: 1.3188\n",
            "Step [36440/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0158, d_svhn_loss: 0.0182, d_fake_loss: 0.0417, g_loss: 1.2493\n",
            "Step [36450/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0164, d_svhn_loss: 0.0442, d_fake_loss: 0.0524, g_loss: 1.1447\n",
            "Step [36460/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0101, d_svhn_loss: 0.0224, d_fake_loss: 0.0410, g_loss: 1.1538\n",
            "Step [36470/80000], d_real_loss: 0.1007, d_mnist_loss: 0.0306, d_svhn_loss: 0.0701, d_fake_loss: 0.0502, g_loss: 1.3651\n",
            "Step [36480/80000], d_real_loss: 0.0913, d_mnist_loss: 0.0603, d_svhn_loss: 0.0310, d_fake_loss: 0.0651, g_loss: 0.9339\n",
            "Step [36490/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0169, d_svhn_loss: 0.0219, d_fake_loss: 0.0299, g_loss: 1.0897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9940456748008728, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [36500/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0147, d_svhn_loss: 0.0236, d_fake_loss: 0.0583, g_loss: 1.1343\n",
            "saved ./samples_fashion/sample-36500-m-s.png\n",
            "saved ./samples_fashion/sample-36500-s-m.png\n",
            "Step [36510/80000], d_real_loss: 0.1243, d_mnist_loss: 0.0250, d_svhn_loss: 0.0992, d_fake_loss: 0.0642, g_loss: 1.0806\n",
            "Step [36520/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0176, d_svhn_loss: 0.0225, d_fake_loss: 0.0875, g_loss: 1.2022\n",
            "Step [36530/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0253, d_svhn_loss: 0.0295, d_fake_loss: 0.0498, g_loss: 1.0289\n",
            "Step [36540/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0136, d_svhn_loss: 0.0226, d_fake_loss: 0.0821, g_loss: 1.3238\n",
            "Step [36550/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0346, d_svhn_loss: 0.0315, d_fake_loss: 0.0422, g_loss: 1.0463\n",
            "Step [36560/80000], d_real_loss: 0.0704, d_mnist_loss: 0.0375, d_svhn_loss: 0.0329, d_fake_loss: 0.0745, g_loss: 0.9397\n",
            "Step [36570/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0160, d_svhn_loss: 0.0295, d_fake_loss: 0.0482, g_loss: 1.1740\n",
            "Step [36580/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0191, d_svhn_loss: 0.0262, d_fake_loss: 0.0328, g_loss: 1.1420\n",
            "Step [36590/80000], d_real_loss: 0.0654, d_mnist_loss: 0.0512, d_svhn_loss: 0.0142, d_fake_loss: 0.0483, g_loss: 1.0786\n",
            "Step [36600/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0111, d_svhn_loss: 0.0270, d_fake_loss: 0.0435, g_loss: 1.2360\n",
            "Step [36610/80000], d_real_loss: 0.1204, d_mnist_loss: 0.0167, d_svhn_loss: 0.1037, d_fake_loss: 0.1576, g_loss: 1.0333\n",
            "Step [36620/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0114, d_svhn_loss: 0.0338, d_fake_loss: 0.0356, g_loss: 1.2113\n",
            "Step [36630/80000], d_real_loss: 0.0928, d_mnist_loss: 0.0658, d_svhn_loss: 0.0270, d_fake_loss: 0.0340, g_loss: 1.0318\n",
            "Step [36640/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0158, d_svhn_loss: 0.0174, d_fake_loss: 0.0423, g_loss: 1.0775\n",
            "Step [36650/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0141, d_svhn_loss: 0.0598, d_fake_loss: 0.0534, g_loss: 1.1385\n",
            "Step [36660/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0148, d_svhn_loss: 0.0269, d_fake_loss: 0.0555, g_loss: 1.1386\n",
            "Step [36670/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0143, d_svhn_loss: 0.0271, d_fake_loss: 0.1908, g_loss: 1.3121\n",
            "Step [36680/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0155, d_svhn_loss: 0.0335, d_fake_loss: 0.0820, g_loss: 1.2644\n",
            "Step [36690/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0122, d_svhn_loss: 0.0402, d_fake_loss: 0.0466, g_loss: 1.1508\n",
            "Step [36700/80000], d_real_loss: 0.1324, d_mnist_loss: 0.0525, d_svhn_loss: 0.0798, d_fake_loss: 0.0881, g_loss: 1.0836\n",
            "Step [36710/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0172, d_svhn_loss: 0.0295, d_fake_loss: 0.0630, g_loss: 1.1570\n",
            "Step [36720/80000], d_real_loss: 0.0957, d_mnist_loss: 0.0713, d_svhn_loss: 0.0244, d_fake_loss: 0.1156, g_loss: 1.4555\n",
            "Step [36730/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0198, d_svhn_loss: 0.0271, d_fake_loss: 0.0419, g_loss: 1.0038\n",
            "Step [36740/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0226, d_svhn_loss: 0.0260, d_fake_loss: 0.0608, g_loss: 1.1245\n",
            "Step [36750/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0243, d_svhn_loss: 0.0305, d_fake_loss: 0.0497, g_loss: 1.2530\n",
            "Step [36760/80000], d_real_loss: 0.1309, d_mnist_loss: 0.0152, d_svhn_loss: 0.1157, d_fake_loss: 0.0764, g_loss: 1.1083\n",
            "Step [36770/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0341, d_svhn_loss: 0.0381, d_fake_loss: 0.0581, g_loss: 0.9498\n",
            "Step [36780/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0246, d_svhn_loss: 0.0338, d_fake_loss: 0.0546, g_loss: 1.1360\n",
            "Step [36790/80000], d_real_loss: 0.0898, d_mnist_loss: 0.0447, d_svhn_loss: 0.0450, d_fake_loss: 0.0376, g_loss: 1.1601\n",
            "Step [36800/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0666, d_svhn_loss: 0.0202, d_fake_loss: 0.1110, g_loss: 1.5141\n",
            "Step [36810/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0164, d_svhn_loss: 0.0305, d_fake_loss: 0.0736, g_loss: 1.2198\n",
            "Step [36820/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0325, d_svhn_loss: 0.0449, d_fake_loss: 0.0330, g_loss: 1.1001\n",
            "Step [36830/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0139, d_svhn_loss: 0.0159, d_fake_loss: 0.0303, g_loss: 1.1927\n",
            "Step [36840/80000], d_real_loss: 0.1474, d_mnist_loss: 0.0128, d_svhn_loss: 0.1346, d_fake_loss: 0.0608, g_loss: 1.1855\n",
            "Step [36850/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0166, d_svhn_loss: 0.0735, d_fake_loss: 0.0347, g_loss: 1.1313\n",
            "Step [36860/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0170, d_svhn_loss: 0.0242, d_fake_loss: 0.0824, g_loss: 1.0043\n",
            "Step [36870/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0263, d_svhn_loss: 0.0520, d_fake_loss: 0.0706, g_loss: 1.0739\n",
            "Step [36880/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0138, d_svhn_loss: 0.0389, d_fake_loss: 0.0345, g_loss: 1.0818\n",
            "Step [36890/80000], d_real_loss: 0.1391, d_mnist_loss: 0.0113, d_svhn_loss: 0.1278, d_fake_loss: 0.0539, g_loss: 1.2112\n",
            "Step [36900/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0170, d_svhn_loss: 0.0314, d_fake_loss: 0.1109, g_loss: 1.2856\n",
            "Step [36910/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0161, d_svhn_loss: 0.0610, d_fake_loss: 0.0990, g_loss: 1.3073\n",
            "Step [36920/80000], d_real_loss: 0.0946, d_mnist_loss: 0.0590, d_svhn_loss: 0.0356, d_fake_loss: 0.1050, g_loss: 1.4300\n",
            "Step [36930/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0188, d_svhn_loss: 0.0293, d_fake_loss: 0.0511, g_loss: 1.1888\n",
            "Step [36940/80000], d_real_loss: 0.1343, d_mnist_loss: 0.0134, d_svhn_loss: 0.1209, d_fake_loss: 0.1088, g_loss: 1.2071\n",
            "Step [36950/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0402, d_svhn_loss: 0.0385, d_fake_loss: 0.0373, g_loss: 1.0204\n",
            "Step [36960/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0156, d_svhn_loss: 0.0628, d_fake_loss: 0.0577, g_loss: 1.2743\n",
            "Step [36970/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0317, d_svhn_loss: 0.0264, d_fake_loss: 0.1265, g_loss: 1.0545\n",
            "Step [36980/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0168, d_svhn_loss: 0.0179, d_fake_loss: 0.0452, g_loss: 1.1214\n",
            "Step [36990/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0137, d_svhn_loss: 0.0366, d_fake_loss: 0.0575, g_loss: 1.2068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9807934165000916, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [37000/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0161, d_svhn_loss: 0.0245, d_fake_loss: 0.0654, g_loss: 1.1021\n",
            "saved ./samples_fashion/sample-37000-m-s.png\n",
            "saved ./samples_fashion/sample-37000-s-m.png\n",
            "Step [37010/80000], d_real_loss: 0.1410, d_mnist_loss: 0.1198, d_svhn_loss: 0.0212, d_fake_loss: 0.0380, g_loss: 0.9118\n",
            "Step [37020/80000], d_real_loss: 0.0993, d_mnist_loss: 0.0194, d_svhn_loss: 0.0799, d_fake_loss: 0.1091, g_loss: 1.0597\n",
            "Step [37030/80000], d_real_loss: 0.1127, d_mnist_loss: 0.0201, d_svhn_loss: 0.0925, d_fake_loss: 0.0932, g_loss: 1.3117\n",
            "Step [37040/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0131, d_svhn_loss: 0.0167, d_fake_loss: 0.0918, g_loss: 0.9732\n",
            "Step [37050/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0349, d_svhn_loss: 0.0359, d_fake_loss: 0.0380, g_loss: 1.2517\n",
            "Step [37060/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0200, d_svhn_loss: 0.0506, d_fake_loss: 0.1648, g_loss: 1.1173\n",
            "Step [37070/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0326, d_svhn_loss: 0.0236, d_fake_loss: 0.0345, g_loss: 1.0670\n",
            "Step [37080/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0201, d_svhn_loss: 0.0428, d_fake_loss: 0.0776, g_loss: 1.1293\n",
            "Step [37090/80000], d_real_loss: 0.0927, d_mnist_loss: 0.0148, d_svhn_loss: 0.0779, d_fake_loss: 0.0653, g_loss: 1.0002\n",
            "Step [37100/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0520, d_svhn_loss: 0.0390, d_fake_loss: 0.0393, g_loss: 1.2019\n",
            "Step [37110/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0128, d_svhn_loss: 0.0423, d_fake_loss: 0.0744, g_loss: 1.3871\n",
            "Step [37120/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0104, d_svhn_loss: 0.0333, d_fake_loss: 0.0412, g_loss: 1.0655\n",
            "Step [37130/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0136, d_svhn_loss: 0.0330, d_fake_loss: 0.0728, g_loss: 0.9442\n",
            "Step [37140/80000], d_real_loss: 0.0857, d_mnist_loss: 0.0459, d_svhn_loss: 0.0398, d_fake_loss: 0.0584, g_loss: 1.1880\n",
            "Step [37150/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0230, d_svhn_loss: 0.0187, d_fake_loss: 0.0512, g_loss: 1.1234\n",
            "Step [37160/80000], d_real_loss: 0.0769, d_mnist_loss: 0.0259, d_svhn_loss: 0.0510, d_fake_loss: 0.0658, g_loss: 1.0894\n",
            "Step [37170/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0155, d_svhn_loss: 0.0483, d_fake_loss: 0.0603, g_loss: 1.0980\n",
            "Step [37180/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0189, d_svhn_loss: 0.0312, d_fake_loss: 0.0813, g_loss: 1.0316\n",
            "Step [37190/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0161, d_svhn_loss: 0.0357, d_fake_loss: 0.0756, g_loss: 1.0571\n",
            "Step [37200/80000], d_real_loss: 0.0907, d_mnist_loss: 0.0256, d_svhn_loss: 0.0651, d_fake_loss: 0.1277, g_loss: 1.1602\n",
            "Step [37210/80000], d_real_loss: 0.1074, d_mnist_loss: 0.0168, d_svhn_loss: 0.0906, d_fake_loss: 0.0490, g_loss: 1.1377\n",
            "Step [37220/80000], d_real_loss: 0.1168, d_mnist_loss: 0.0733, d_svhn_loss: 0.0435, d_fake_loss: 0.0597, g_loss: 0.9468\n",
            "Step [37230/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0155, d_svhn_loss: 0.0280, d_fake_loss: 0.0502, g_loss: 1.0388\n",
            "Step [37240/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0146, d_svhn_loss: 0.0315, d_fake_loss: 0.0342, g_loss: 1.0242\n",
            "Step [37250/80000], d_real_loss: 0.1491, d_mnist_loss: 0.0129, d_svhn_loss: 0.1362, d_fake_loss: 0.1058, g_loss: 1.1118\n",
            "Step [37260/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0101, d_svhn_loss: 0.0651, d_fake_loss: 0.0406, g_loss: 1.1627\n",
            "Step [37270/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0191, d_svhn_loss: 0.0213, d_fake_loss: 0.0701, g_loss: 1.2667\n",
            "Step [37280/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0440, d_svhn_loss: 0.0460, d_fake_loss: 0.0460, g_loss: 0.9460\n",
            "Step [37290/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0210, d_svhn_loss: 0.0329, d_fake_loss: 0.0770, g_loss: 1.2201\n",
            "Step [37300/80000], d_real_loss: 0.0943, d_mnist_loss: 0.0558, d_svhn_loss: 0.0385, d_fake_loss: 0.0539, g_loss: 0.9371\n",
            "Step [37310/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0155, d_svhn_loss: 0.0259, d_fake_loss: 0.0584, g_loss: 1.0123\n",
            "Step [37320/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0180, d_svhn_loss: 0.0196, d_fake_loss: 0.0842, g_loss: 1.2156\n",
            "Step [37330/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0283, d_svhn_loss: 0.0216, d_fake_loss: 0.0343, g_loss: 1.1892\n",
            "Step [37340/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0181, d_svhn_loss: 0.0454, d_fake_loss: 0.0375, g_loss: 1.1834\n",
            "Step [37350/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0163, d_svhn_loss: 0.0253, d_fake_loss: 0.0373, g_loss: 1.0582\n",
            "Step [37360/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0118, d_svhn_loss: 0.0256, d_fake_loss: 0.0266, g_loss: 1.0050\n",
            "Step [37370/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0193, d_svhn_loss: 0.0423, d_fake_loss: 0.0408, g_loss: 1.1133\n",
            "Step [37380/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0375, d_svhn_loss: 0.0328, d_fake_loss: 0.0337, g_loss: 1.1071\n",
            "Step [37390/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0175, d_svhn_loss: 0.0439, d_fake_loss: 0.0709, g_loss: 1.2873\n",
            "Step [37400/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0177, d_svhn_loss: 0.0332, d_fake_loss: 0.0578, g_loss: 1.1180\n",
            "Step [37410/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0152, d_svhn_loss: 0.0337, d_fake_loss: 0.0660, g_loss: 1.2455\n",
            "Step [37420/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0135, d_svhn_loss: 0.0387, d_fake_loss: 0.0703, g_loss: 1.2554\n",
            "Step [37430/80000], d_real_loss: 0.1776, d_mnist_loss: 0.0153, d_svhn_loss: 0.1623, d_fake_loss: 0.0415, g_loss: 1.1762\n",
            "Step [37440/80000], d_real_loss: 0.1126, d_mnist_loss: 0.0155, d_svhn_loss: 0.0971, d_fake_loss: 0.0338, g_loss: 1.0440\n",
            "Step [37450/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0213, d_svhn_loss: 0.0347, d_fake_loss: 0.0354, g_loss: 1.1148\n",
            "Step [37460/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0191, d_svhn_loss: 0.0173, d_fake_loss: 0.1153, g_loss: 1.3899\n",
            "Step [37470/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0270, d_svhn_loss: 0.0305, d_fake_loss: 0.0552, g_loss: 1.3865\n",
            "Step [37480/80000], d_real_loss: 0.1849, d_mnist_loss: 0.1445, d_svhn_loss: 0.0404, d_fake_loss: 0.0393, g_loss: 1.1375\n",
            "Step [37490/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0199, d_svhn_loss: 0.0451, d_fake_loss: 0.0719, g_loss: 1.2011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9860205054283142, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [37500/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0318, d_svhn_loss: 0.0309, d_fake_loss: 0.0530, g_loss: 1.1415\n",
            "saved ./samples_fashion/sample-37500-m-s.png\n",
            "saved ./samples_fashion/sample-37500-s-m.png\n",
            "Step [37510/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0186, d_svhn_loss: 0.0643, d_fake_loss: 0.0782, g_loss: 1.2883\n",
            "Step [37520/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0149, d_svhn_loss: 0.0283, d_fake_loss: 0.0866, g_loss: 1.1233\n",
            "Step [37530/80000], d_real_loss: 0.0894, d_mnist_loss: 0.0613, d_svhn_loss: 0.0281, d_fake_loss: 0.1174, g_loss: 1.2329\n",
            "Step [37540/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0126, d_svhn_loss: 0.0298, d_fake_loss: 0.0397, g_loss: 1.0493\n",
            "Step [37550/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0086, d_svhn_loss: 0.0486, d_fake_loss: 0.1299, g_loss: 1.3077\n",
            "Step [37560/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0138, d_svhn_loss: 0.0390, d_fake_loss: 0.0742, g_loss: 1.2335\n",
            "Step [37570/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0148, d_svhn_loss: 0.0511, d_fake_loss: 0.0469, g_loss: 1.1235\n",
            "Step [37580/80000], d_real_loss: 0.0809, d_mnist_loss: 0.0332, d_svhn_loss: 0.0476, d_fake_loss: 0.0458, g_loss: 0.9315\n",
            "Step [37590/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0163, d_svhn_loss: 0.0252, d_fake_loss: 0.0348, g_loss: 1.1117\n",
            "Step [37600/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0121, d_svhn_loss: 0.0344, d_fake_loss: 0.0830, g_loss: 1.0085\n",
            "Step [37610/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0092, d_svhn_loss: 0.0467, d_fake_loss: 0.0399, g_loss: 1.2286\n",
            "Step [37620/80000], d_real_loss: 0.1207, d_mnist_loss: 0.0205, d_svhn_loss: 0.1002, d_fake_loss: 0.0468, g_loss: 1.3062\n",
            "Step [37630/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0412, d_svhn_loss: 0.0271, d_fake_loss: 0.0581, g_loss: 1.4114\n",
            "Step [37640/80000], d_real_loss: 0.0715, d_mnist_loss: 0.0156, d_svhn_loss: 0.0559, d_fake_loss: 0.0525, g_loss: 1.0057\n",
            "Step [37650/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0159, d_svhn_loss: 0.0360, d_fake_loss: 0.0490, g_loss: 1.3179\n",
            "Step [37660/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0135, d_svhn_loss: 0.0629, d_fake_loss: 0.0671, g_loss: 1.3684\n",
            "Step [37670/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0168, d_svhn_loss: 0.0220, d_fake_loss: 0.0889, g_loss: 0.9435\n",
            "Step [37680/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0111, d_svhn_loss: 0.0235, d_fake_loss: 0.0669, g_loss: 1.2014\n",
            "Step [37690/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0239, d_svhn_loss: 0.0352, d_fake_loss: 0.1760, g_loss: 0.9114\n",
            "Step [37700/80000], d_real_loss: 0.0869, d_mnist_loss: 0.0574, d_svhn_loss: 0.0294, d_fake_loss: 0.0474, g_loss: 1.3876\n",
            "Step [37710/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0156, d_svhn_loss: 0.0366, d_fake_loss: 0.0541, g_loss: 1.1544\n",
            "Step [37720/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0100, d_svhn_loss: 0.0523, d_fake_loss: 0.0798, g_loss: 1.0995\n",
            "Step [37730/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0338, d_svhn_loss: 0.0314, d_fake_loss: 0.0897, g_loss: 1.2426\n",
            "Step [37740/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0142, d_svhn_loss: 0.0287, d_fake_loss: 0.0641, g_loss: 1.2540\n",
            "Step [37750/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0135, d_svhn_loss: 0.0394, d_fake_loss: 0.0374, g_loss: 1.1577\n",
            "Step [37760/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0219, d_svhn_loss: 0.0288, d_fake_loss: 0.0636, g_loss: 1.1282\n",
            "Step [37770/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0208, d_svhn_loss: 0.0209, d_fake_loss: 0.0592, g_loss: 1.3143\n",
            "Step [37780/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0250, d_svhn_loss: 0.0312, d_fake_loss: 0.1739, g_loss: 1.3747\n",
            "Step [37790/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0158, d_svhn_loss: 0.0276, d_fake_loss: 0.0216, g_loss: 1.2424\n",
            "Step [37800/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0162, d_svhn_loss: 0.0544, d_fake_loss: 0.0416, g_loss: 1.2526\n",
            "Step [37810/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0360, d_svhn_loss: 0.0408, d_fake_loss: 0.0867, g_loss: 1.2810\n",
            "Step [37820/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0136, d_svhn_loss: 0.0144, d_fake_loss: 0.0340, g_loss: 1.3388\n",
            "Step [37830/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0306, d_svhn_loss: 0.0354, d_fake_loss: 0.0381, g_loss: 1.0843\n",
            "Step [37840/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0220, d_svhn_loss: 0.0422, d_fake_loss: 0.0588, g_loss: 1.2489\n",
            "Step [37850/80000], d_real_loss: 0.1126, d_mnist_loss: 0.0686, d_svhn_loss: 0.0441, d_fake_loss: 0.0623, g_loss: 1.1492\n",
            "Step [37860/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0217, d_svhn_loss: 0.0433, d_fake_loss: 0.0421, g_loss: 1.0289\n",
            "Step [37870/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0202, d_svhn_loss: 0.0461, d_fake_loss: 0.0666, g_loss: 1.3470\n",
            "Step [37880/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0335, d_svhn_loss: 0.0239, d_fake_loss: 0.0756, g_loss: 1.3021\n",
            "Step [37890/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0149, d_svhn_loss: 0.0535, d_fake_loss: 0.0459, g_loss: 1.0587\n",
            "Step [37900/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0124, d_svhn_loss: 0.0613, d_fake_loss: 0.0259, g_loss: 1.1385\n",
            "Step [37910/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0135, d_svhn_loss: 0.0234, d_fake_loss: 0.0320, g_loss: 1.1635\n",
            "Step [37920/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0114, d_svhn_loss: 0.0352, d_fake_loss: 0.0265, g_loss: 1.1531\n",
            "Step [37930/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0144, d_svhn_loss: 0.0221, d_fake_loss: 0.0734, g_loss: 1.0097\n",
            "Step [37940/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0183, d_svhn_loss: 0.0372, d_fake_loss: 0.0477, g_loss: 1.0542\n",
            "Step [37950/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0168, d_svhn_loss: 0.0244, d_fake_loss: 0.0262, g_loss: 1.2225\n",
            "Step [37960/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0141, d_svhn_loss: 0.0156, d_fake_loss: 0.0512, g_loss: 1.0840\n",
            "Step [37970/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0137, d_svhn_loss: 0.0673, d_fake_loss: 0.0446, g_loss: 1.1134\n",
            "Step [37980/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0172, d_svhn_loss: 0.0778, d_fake_loss: 0.1310, g_loss: 0.9323\n",
            "Step [37990/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0142, d_svhn_loss: 0.0258, d_fake_loss: 0.0680, g_loss: 1.1111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9413143396377563, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [38000/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0380, d_svhn_loss: 0.0391, d_fake_loss: 0.0379, g_loss: 0.9524\n",
            "saved ./samples_fashion/sample-38000-m-s.png\n",
            "saved ./samples_fashion/sample-38000-s-m.png\n",
            "Step [38010/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0187, d_svhn_loss: 0.0162, d_fake_loss: 0.0358, g_loss: 1.0139\n",
            "Step [38020/80000], d_real_loss: 0.0385, d_mnist_loss: 0.0139, d_svhn_loss: 0.0246, d_fake_loss: 0.0837, g_loss: 1.3069\n",
            "Step [38030/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0137, d_svhn_loss: 0.0217, d_fake_loss: 0.0421, g_loss: 1.2685\n",
            "Step [38040/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0482, d_svhn_loss: 0.0191, d_fake_loss: 0.0248, g_loss: 1.0958\n",
            "Step [38050/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0115, d_svhn_loss: 0.0571, d_fake_loss: 0.0633, g_loss: 1.1635\n",
            "Step [38060/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0176, d_svhn_loss: 0.0289, d_fake_loss: 0.0463, g_loss: 1.1881\n",
            "Step [38070/80000], d_real_loss: 0.1413, d_mnist_loss: 0.1144, d_svhn_loss: 0.0270, d_fake_loss: 0.0675, g_loss: 1.8321\n",
            "Step [38080/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0415, d_svhn_loss: 0.0174, d_fake_loss: 0.0387, g_loss: 1.2100\n",
            "Step [38090/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0133, d_svhn_loss: 0.0137, d_fake_loss: 0.0594, g_loss: 1.1157\n",
            "Step [38100/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0152, d_svhn_loss: 0.0327, d_fake_loss: 0.0322, g_loss: 1.1108\n",
            "Step [38110/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0202, d_svhn_loss: 0.0249, d_fake_loss: 0.0430, g_loss: 1.1436\n",
            "Step [38120/80000], d_real_loss: 0.0889, d_mnist_loss: 0.0437, d_svhn_loss: 0.0452, d_fake_loss: 0.0281, g_loss: 1.0929\n",
            "Step [38130/80000], d_real_loss: 0.1255, d_mnist_loss: 0.0647, d_svhn_loss: 0.0608, d_fake_loss: 0.1163, g_loss: 1.2123\n",
            "Step [38140/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0142, d_svhn_loss: 0.0390, d_fake_loss: 0.0409, g_loss: 1.2635\n",
            "Step [38150/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0368, d_svhn_loss: 0.0235, d_fake_loss: 0.0717, g_loss: 1.1645\n",
            "Step [38160/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0541, d_svhn_loss: 0.0201, d_fake_loss: 0.0572, g_loss: 1.1252\n",
            "Step [38170/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0144, d_svhn_loss: 0.0261, d_fake_loss: 0.0358, g_loss: 1.0999\n",
            "Step [38180/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0135, d_svhn_loss: 0.0221, d_fake_loss: 0.1061, g_loss: 1.0963\n",
            "Step [38190/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0163, d_svhn_loss: 0.0291, d_fake_loss: 0.0656, g_loss: 1.4050\n",
            "Step [38200/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0138, d_svhn_loss: 0.1034, d_fake_loss: 0.0655, g_loss: 1.0553\n",
            "Step [38210/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0109, d_svhn_loss: 0.0288, d_fake_loss: 0.0478, g_loss: 1.2444\n",
            "Step [38220/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0239, d_svhn_loss: 0.0205, d_fake_loss: 0.0519, g_loss: 0.9320\n",
            "Step [38230/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0131, d_svhn_loss: 0.0210, d_fake_loss: 0.0376, g_loss: 1.2556\n",
            "Step [38240/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0091, d_svhn_loss: 0.0257, d_fake_loss: 0.0424, g_loss: 1.0734\n",
            "Step [38250/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0159, d_svhn_loss: 0.0203, d_fake_loss: 0.0464, g_loss: 1.3532\n",
            "Step [38260/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0452, d_svhn_loss: 0.0187, d_fake_loss: 0.1823, g_loss: 1.2856\n",
            "Step [38270/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0443, d_svhn_loss: 0.0281, d_fake_loss: 0.0518, g_loss: 1.2190\n",
            "Step [38280/80000], d_real_loss: 0.1007, d_mnist_loss: 0.0450, d_svhn_loss: 0.0557, d_fake_loss: 0.1266, g_loss: 1.1230\n",
            "Step [38290/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0280, d_svhn_loss: 0.0258, d_fake_loss: 0.0874, g_loss: 1.4597\n",
            "Step [38300/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0181, d_svhn_loss: 0.0153, d_fake_loss: 0.0704, g_loss: 1.2649\n",
            "Step [38310/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0174, d_svhn_loss: 0.0424, d_fake_loss: 0.0362, g_loss: 1.1245\n",
            "Step [38320/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0181, d_svhn_loss: 0.0355, d_fake_loss: 0.0817, g_loss: 1.0125\n",
            "Step [38330/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0190, d_svhn_loss: 0.0242, d_fake_loss: 0.0667, g_loss: 1.2270\n",
            "Step [38340/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0242, d_svhn_loss: 0.0352, d_fake_loss: 0.0520, g_loss: 1.2732\n",
            "Step [38350/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0139, d_svhn_loss: 0.0236, d_fake_loss: 0.0302, g_loss: 1.0485\n",
            "Step [38360/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0520, d_svhn_loss: 0.0201, d_fake_loss: 0.0441, g_loss: 1.2212\n",
            "Step [38370/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0159, d_svhn_loss: 0.0342, d_fake_loss: 0.0922, g_loss: 1.4217\n",
            "Step [38380/80000], d_real_loss: 0.0855, d_mnist_loss: 0.0305, d_svhn_loss: 0.0551, d_fake_loss: 0.0630, g_loss: 0.9552\n",
            "Step [38390/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0504, d_svhn_loss: 0.0213, d_fake_loss: 0.0552, g_loss: 1.2405\n",
            "Step [38400/80000], d_real_loss: 0.2100, d_mnist_loss: 0.1940, d_svhn_loss: 0.0159, d_fake_loss: 0.1216, g_loss: 1.2297\n",
            "Step [38410/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0128, d_svhn_loss: 0.0301, d_fake_loss: 0.0687, g_loss: 1.0852\n",
            "Step [38420/80000], d_real_loss: 0.1232, d_mnist_loss: 0.0195, d_svhn_loss: 0.1038, d_fake_loss: 0.0740, g_loss: 1.0511\n",
            "Step [38430/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0212, d_svhn_loss: 0.0197, d_fake_loss: 0.0603, g_loss: 1.1210\n",
            "Step [38440/80000], d_real_loss: 0.1707, d_mnist_loss: 0.0258, d_svhn_loss: 0.1450, d_fake_loss: 0.0803, g_loss: 0.9588\n",
            "Step [38450/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0290, d_svhn_loss: 0.0191, d_fake_loss: 0.0442, g_loss: 1.0376\n",
            "Step [38460/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0238, d_svhn_loss: 0.0317, d_fake_loss: 0.0420, g_loss: 1.0200\n",
            "Step [38470/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0192, d_svhn_loss: 0.0211, d_fake_loss: 0.0576, g_loss: 1.0996\n",
            "Step [38480/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0137, d_svhn_loss: 0.0479, d_fake_loss: 0.0603, g_loss: 1.2511\n",
            "Step [38490/80000], d_real_loss: 0.0984, d_mnist_loss: 0.0164, d_svhn_loss: 0.0821, d_fake_loss: 0.0325, g_loss: 1.0999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9572089910507202, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [38500/80000], d_real_loss: 0.1094, d_mnist_loss: 0.0276, d_svhn_loss: 0.0818, d_fake_loss: 0.0602, g_loss: 1.2699\n",
            "saved ./samples_fashion/sample-38500-m-s.png\n",
            "saved ./samples_fashion/sample-38500-s-m.png\n",
            "Step [38510/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0294, d_svhn_loss: 0.0394, d_fake_loss: 0.0390, g_loss: 1.1135\n",
            "Step [38520/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0195, d_svhn_loss: 0.0476, d_fake_loss: 0.0461, g_loss: 1.0735\n",
            "Step [38530/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0346, d_svhn_loss: 0.0372, d_fake_loss: 0.1180, g_loss: 1.2250\n",
            "Step [38540/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0139, d_svhn_loss: 0.0536, d_fake_loss: 0.0835, g_loss: 1.2137\n",
            "Step [38550/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0192, d_svhn_loss: 0.0232, d_fake_loss: 0.0380, g_loss: 1.2435\n",
            "Step [38560/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0298, d_svhn_loss: 0.0268, d_fake_loss: 0.0565, g_loss: 1.1630\n",
            "Step [38570/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0116, d_svhn_loss: 0.0213, d_fake_loss: 0.0596, g_loss: 1.2179\n",
            "Step [38580/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0199, d_svhn_loss: 0.0348, d_fake_loss: 0.0816, g_loss: 1.2106\n",
            "Step [38590/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0146, d_svhn_loss: 0.0462, d_fake_loss: 0.0319, g_loss: 1.2322\n",
            "Step [38600/80000], d_real_loss: 0.1115, d_mnist_loss: 0.0620, d_svhn_loss: 0.0495, d_fake_loss: 0.1299, g_loss: 1.0410\n",
            "Step [38610/80000], d_real_loss: 0.0975, d_mnist_loss: 0.0164, d_svhn_loss: 0.0811, d_fake_loss: 0.1051, g_loss: 1.1060\n",
            "Step [38620/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0107, d_svhn_loss: 0.0136, d_fake_loss: 0.0815, g_loss: 0.8045\n",
            "Step [38630/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0352, d_svhn_loss: 0.0252, d_fake_loss: 0.0646, g_loss: 1.1448\n",
            "Step [38640/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0308, d_svhn_loss: 0.0326, d_fake_loss: 0.0385, g_loss: 1.0232\n",
            "Step [38650/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0315, d_svhn_loss: 0.0285, d_fake_loss: 0.0741, g_loss: 1.0423\n",
            "Step [38660/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0215, d_svhn_loss: 0.0247, d_fake_loss: 0.0738, g_loss: 1.2165\n",
            "Step [38670/80000], d_real_loss: 0.0882, d_mnist_loss: 0.0224, d_svhn_loss: 0.0657, d_fake_loss: 0.0583, g_loss: 1.1532\n",
            "Step [38680/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0118, d_svhn_loss: 0.0305, d_fake_loss: 0.0413, g_loss: 1.3508\n",
            "Step [38690/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0186, d_svhn_loss: 0.0499, d_fake_loss: 0.0375, g_loss: 1.1656\n",
            "Step [38700/80000], d_real_loss: 0.1398, d_mnist_loss: 0.0165, d_svhn_loss: 0.1233, d_fake_loss: 0.0594, g_loss: 1.2412\n",
            "Step [38710/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0139, d_svhn_loss: 0.0255, d_fake_loss: 0.0667, g_loss: 1.1705\n",
            "Step [38720/80000], d_real_loss: 0.0759, d_mnist_loss: 0.0386, d_svhn_loss: 0.0374, d_fake_loss: 0.0764, g_loss: 1.2425\n",
            "Step [38730/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0124, d_svhn_loss: 0.0353, d_fake_loss: 0.0474, g_loss: 1.1797\n",
            "Step [38740/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0421, d_svhn_loss: 0.0235, d_fake_loss: 0.0536, g_loss: 1.2051\n",
            "Step [38750/80000], d_real_loss: 0.1830, d_mnist_loss: 0.0156, d_svhn_loss: 0.1674, d_fake_loss: 0.0666, g_loss: 1.3668\n",
            "Step [38760/80000], d_real_loss: 0.0766, d_mnist_loss: 0.0230, d_svhn_loss: 0.0536, d_fake_loss: 0.0935, g_loss: 1.3470\n",
            "Step [38770/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0221, d_svhn_loss: 0.0458, d_fake_loss: 0.0474, g_loss: 1.0385\n",
            "Step [38780/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0180, d_svhn_loss: 0.0422, d_fake_loss: 0.0430, g_loss: 1.2019\n",
            "Step [38790/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0201, d_svhn_loss: 0.0435, d_fake_loss: 0.0976, g_loss: 1.4072\n",
            "Step [38800/80000], d_real_loss: 0.1147, d_mnist_loss: 0.0207, d_svhn_loss: 0.0940, d_fake_loss: 0.0302, g_loss: 1.0530\n",
            "Step [38810/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0161, d_svhn_loss: 0.0539, d_fake_loss: 0.0582, g_loss: 1.0295\n",
            "Step [38820/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0149, d_svhn_loss: 0.0434, d_fake_loss: 0.0638, g_loss: 1.2406\n",
            "Step [38830/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0313, d_svhn_loss: 0.0275, d_fake_loss: 0.0365, g_loss: 1.2596\n",
            "Step [38840/80000], d_real_loss: 0.1275, d_mnist_loss: 0.0172, d_svhn_loss: 0.1103, d_fake_loss: 0.0563, g_loss: 1.2676\n",
            "Step [38850/80000], d_real_loss: 0.0841, d_mnist_loss: 0.0323, d_svhn_loss: 0.0518, d_fake_loss: 0.0752, g_loss: 1.1704\n",
            "Step [38860/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0309, d_svhn_loss: 0.0374, d_fake_loss: 0.0403, g_loss: 1.0358\n",
            "Step [38870/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0282, d_svhn_loss: 0.0311, d_fake_loss: 0.1022, g_loss: 1.1544\n",
            "Step [38880/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0199, d_svhn_loss: 0.0342, d_fake_loss: 0.0519, g_loss: 1.0542\n",
            "Step [38890/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0148, d_svhn_loss: 0.0325, d_fake_loss: 0.0536, g_loss: 1.2290\n",
            "Step [38900/80000], d_real_loss: 0.0680, d_mnist_loss: 0.0172, d_svhn_loss: 0.0508, d_fake_loss: 0.1065, g_loss: 1.1760\n",
            "Step [38910/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0136, d_svhn_loss: 0.0475, d_fake_loss: 0.0859, g_loss: 1.0808\n",
            "Step [38920/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0123, d_svhn_loss: 0.0627, d_fake_loss: 0.0332, g_loss: 1.0421\n",
            "Step [38930/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0310, d_svhn_loss: 0.0201, d_fake_loss: 0.1004, g_loss: 1.1851\n",
            "Step [38940/80000], d_real_loss: 0.1946, d_mnist_loss: 0.0313, d_svhn_loss: 0.1634, d_fake_loss: 0.1541, g_loss: 1.0304\n",
            "Step [38950/80000], d_real_loss: 0.0654, d_mnist_loss: 0.0203, d_svhn_loss: 0.0452, d_fake_loss: 0.1368, g_loss: 1.3848\n",
            "Step [38960/80000], d_real_loss: 0.0989, d_mnist_loss: 0.0105, d_svhn_loss: 0.0884, d_fake_loss: 0.1284, g_loss: 1.0793\n",
            "Step [38970/80000], d_real_loss: 0.1104, d_mnist_loss: 0.0200, d_svhn_loss: 0.0905, d_fake_loss: 0.0510, g_loss: 1.1247\n",
            "Step [38980/80000], d_real_loss: 0.1322, d_mnist_loss: 0.0565, d_svhn_loss: 0.0757, d_fake_loss: 0.1768, g_loss: 0.8675\n",
            "Step [38990/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0199, d_svhn_loss: 0.0307, d_fake_loss: 0.0238, g_loss: 0.9780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9704100489616394, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [39000/80000], d_real_loss: 0.1211, d_mnist_loss: 0.0210, d_svhn_loss: 0.1001, d_fake_loss: 0.0317, g_loss: 1.0911\n",
            "saved ./samples_fashion/sample-39000-m-s.png\n",
            "saved ./samples_fashion/sample-39000-s-m.png\n",
            "Step [39010/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0142, d_svhn_loss: 0.0321, d_fake_loss: 0.0468, g_loss: 1.2259\n",
            "Step [39020/80000], d_real_loss: 0.0878, d_mnist_loss: 0.0535, d_svhn_loss: 0.0343, d_fake_loss: 0.0859, g_loss: 1.1144\n",
            "Step [39030/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0139, d_svhn_loss: 0.0161, d_fake_loss: 0.0716, g_loss: 1.0524\n",
            "Step [39040/80000], d_real_loss: 0.1236, d_mnist_loss: 0.0353, d_svhn_loss: 0.0883, d_fake_loss: 0.1076, g_loss: 1.0268\n",
            "Step [39050/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0442, d_svhn_loss: 0.0301, d_fake_loss: 0.0641, g_loss: 1.1130\n",
            "Step [39060/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0150, d_svhn_loss: 0.0237, d_fake_loss: 0.0848, g_loss: 1.0837\n",
            "Step [39070/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0123, d_svhn_loss: 0.0246, d_fake_loss: 0.0543, g_loss: 1.0893\n",
            "Step [39080/80000], d_real_loss: 0.0751, d_mnist_loss: 0.0313, d_svhn_loss: 0.0438, d_fake_loss: 0.0768, g_loss: 1.3605\n",
            "Step [39090/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0276, d_svhn_loss: 0.0288, d_fake_loss: 0.0344, g_loss: 1.1943\n",
            "Step [39100/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0112, d_svhn_loss: 0.0342, d_fake_loss: 0.0467, g_loss: 1.2220\n",
            "Step [39110/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0274, d_svhn_loss: 0.0422, d_fake_loss: 0.0404, g_loss: 1.1255\n",
            "Step [39120/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0126, d_svhn_loss: 0.0409, d_fake_loss: 0.0764, g_loss: 0.8751\n",
            "Step [39130/80000], d_real_loss: 0.1068, d_mnist_loss: 0.0775, d_svhn_loss: 0.0293, d_fake_loss: 0.0632, g_loss: 1.2845\n",
            "Step [39140/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0178, d_svhn_loss: 0.0259, d_fake_loss: 0.0697, g_loss: 1.3953\n",
            "Step [39150/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0643, d_svhn_loss: 0.0169, d_fake_loss: 0.0320, g_loss: 1.1862\n",
            "Step [39160/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0272, d_svhn_loss: 0.0225, d_fake_loss: 0.1058, g_loss: 1.2503\n",
            "Step [39170/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0192, d_svhn_loss: 0.0195, d_fake_loss: 0.0452, g_loss: 1.3599\n",
            "Step [39180/80000], d_real_loss: 0.0927, d_mnist_loss: 0.0137, d_svhn_loss: 0.0790, d_fake_loss: 0.0927, g_loss: 1.1485\n",
            "Step [39190/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0277, d_svhn_loss: 0.0269, d_fake_loss: 0.1155, g_loss: 1.4243\n",
            "Step [39200/80000], d_real_loss: 0.1325, d_mnist_loss: 0.0129, d_svhn_loss: 0.1197, d_fake_loss: 0.1165, g_loss: 1.2229\n",
            "Step [39210/80000], d_real_loss: 0.0658, d_mnist_loss: 0.0183, d_svhn_loss: 0.0475, d_fake_loss: 0.0508, g_loss: 1.2613\n",
            "Step [39220/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0191, d_svhn_loss: 0.0372, d_fake_loss: 0.0452, g_loss: 1.0297\n",
            "Step [39230/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0129, d_svhn_loss: 0.0502, d_fake_loss: 0.0534, g_loss: 1.0669\n",
            "Step [39240/80000], d_real_loss: 0.0803, d_mnist_loss: 0.0137, d_svhn_loss: 0.0666, d_fake_loss: 0.0400, g_loss: 1.0873\n",
            "Step [39250/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0152, d_svhn_loss: 0.0435, d_fake_loss: 0.1364, g_loss: 1.6495\n",
            "Step [39260/80000], d_real_loss: 0.1298, d_mnist_loss: 0.0279, d_svhn_loss: 0.1019, d_fake_loss: 0.0936, g_loss: 1.4208\n",
            "Step [39270/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0379, d_svhn_loss: 0.0188, d_fake_loss: 0.0710, g_loss: 1.4933\n",
            "Step [39280/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0153, d_svhn_loss: 0.0225, d_fake_loss: 0.1368, g_loss: 0.9520\n",
            "Step [39290/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0291, d_svhn_loss: 0.0221, d_fake_loss: 0.0254, g_loss: 1.1189\n",
            "Step [39300/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0125, d_svhn_loss: 0.0426, d_fake_loss: 0.0815, g_loss: 1.2211\n",
            "Step [39310/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0289, d_svhn_loss: 0.0230, d_fake_loss: 0.0341, g_loss: 1.1254\n",
            "Step [39320/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0156, d_svhn_loss: 0.0334, d_fake_loss: 0.0563, g_loss: 0.9753\n",
            "Step [39330/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0200, d_svhn_loss: 0.0197, d_fake_loss: 0.0522, g_loss: 1.1135\n",
            "Step [39340/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0152, d_svhn_loss: 0.0219, d_fake_loss: 0.0391, g_loss: 1.1901\n",
            "Step [39350/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0183, d_svhn_loss: 0.0243, d_fake_loss: 0.0370, g_loss: 1.2292\n",
            "Step [39360/80000], d_real_loss: 0.1482, d_mnist_loss: 0.0145, d_svhn_loss: 0.1337, d_fake_loss: 0.0773, g_loss: 1.1158\n",
            "Step [39370/80000], d_real_loss: 0.1021, d_mnist_loss: 0.0629, d_svhn_loss: 0.0393, d_fake_loss: 0.0555, g_loss: 1.1473\n",
            "Step [39380/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0186, d_svhn_loss: 0.0456, d_fake_loss: 0.2786, g_loss: 1.3169\n",
            "Step [39390/80000], d_real_loss: 0.1860, d_mnist_loss: 0.0190, d_svhn_loss: 0.1670, d_fake_loss: 0.2094, g_loss: 1.2510\n",
            "Step [39400/80000], d_real_loss: 0.1192, d_mnist_loss: 0.0204, d_svhn_loss: 0.0988, d_fake_loss: 0.0698, g_loss: 1.2095\n",
            "Step [39410/80000], d_real_loss: 0.1137, d_mnist_loss: 0.0225, d_svhn_loss: 0.0912, d_fake_loss: 0.0300, g_loss: 1.1275\n",
            "Step [39420/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0200, d_svhn_loss: 0.0215, d_fake_loss: 0.0423, g_loss: 1.1690\n",
            "Step [39430/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0347, d_svhn_loss: 0.0486, d_fake_loss: 0.0348, g_loss: 1.2251\n",
            "Step [39440/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0687, d_svhn_loss: 0.0213, d_fake_loss: 0.0367, g_loss: 1.0320\n",
            "Step [39450/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0185, d_svhn_loss: 0.0195, d_fake_loss: 0.0289, g_loss: 1.1511\n",
            "Step [39460/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0187, d_svhn_loss: 0.0501, d_fake_loss: 0.0613, g_loss: 1.3452\n",
            "Step [39470/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0367, d_svhn_loss: 0.0295, d_fake_loss: 0.0824, g_loss: 1.1734\n",
            "Step [39480/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0269, d_svhn_loss: 0.0213, d_fake_loss: 0.0322, g_loss: 1.2135\n",
            "Step [39490/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0139, d_svhn_loss: 0.0266, d_fake_loss: 0.0499, g_loss: 1.1369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9157991409301758, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [39500/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0098, d_svhn_loss: 0.0230, d_fake_loss: 0.0500, g_loss: 1.0090\n",
            "saved ./samples_fashion/sample-39500-m-s.png\n",
            "saved ./samples_fashion/sample-39500-s-m.png\n",
            "Step [39510/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0248, d_svhn_loss: 0.0319, d_fake_loss: 0.0554, g_loss: 1.3069\n",
            "Step [39520/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0190, d_svhn_loss: 0.0270, d_fake_loss: 0.0755, g_loss: 0.7953\n",
            "Step [39530/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0150, d_svhn_loss: 0.0295, d_fake_loss: 0.0787, g_loss: 1.3658\n",
            "Step [39540/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0134, d_svhn_loss: 0.0268, d_fake_loss: 0.1026, g_loss: 0.8538\n",
            "Step [39550/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0197, d_svhn_loss: 0.0215, d_fake_loss: 0.1462, g_loss: 0.8550\n",
            "Step [39560/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0143, d_svhn_loss: 0.0476, d_fake_loss: 0.1378, g_loss: 0.9975\n",
            "Step [39570/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0443, d_svhn_loss: 0.0729, d_fake_loss: 0.0961, g_loss: 1.1535\n",
            "Step [39580/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0220, d_svhn_loss: 0.0345, d_fake_loss: 0.0579, g_loss: 1.1966\n",
            "Step [39590/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0352, d_svhn_loss: 0.0344, d_fake_loss: 0.0367, g_loss: 1.1616\n",
            "Step [39600/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0138, d_svhn_loss: 0.0257, d_fake_loss: 0.0525, g_loss: 1.1239\n",
            "Step [39610/80000], d_real_loss: 0.0977, d_mnist_loss: 0.0506, d_svhn_loss: 0.0472, d_fake_loss: 0.0450, g_loss: 1.0933\n",
            "Step [39620/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0153, d_svhn_loss: 0.0322, d_fake_loss: 0.0412, g_loss: 1.2260\n",
            "Step [39630/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0465, d_svhn_loss: 0.0350, d_fake_loss: 0.0327, g_loss: 1.2644\n",
            "Step [39640/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0313, d_svhn_loss: 0.0309, d_fake_loss: 0.1200, g_loss: 1.1862\n",
            "Step [39650/80000], d_real_loss: 0.0827, d_mnist_loss: 0.0091, d_svhn_loss: 0.0736, d_fake_loss: 0.0850, g_loss: 1.1945\n",
            "Step [39660/80000], d_real_loss: 0.1019, d_mnist_loss: 0.0737, d_svhn_loss: 0.0282, d_fake_loss: 0.0394, g_loss: 1.1495\n",
            "Step [39670/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0255, d_svhn_loss: 0.0222, d_fake_loss: 0.0469, g_loss: 1.2517\n",
            "Step [39680/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0150, d_svhn_loss: 0.0342, d_fake_loss: 0.1198, g_loss: 1.4968\n",
            "Step [39690/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0294, d_svhn_loss: 0.0270, d_fake_loss: 0.1017, g_loss: 1.1461\n",
            "Step [39700/80000], d_real_loss: 0.1528, d_mnist_loss: 0.0146, d_svhn_loss: 0.1382, d_fake_loss: 0.0381, g_loss: 1.2346\n",
            "Step [39710/80000], d_real_loss: 0.0941, d_mnist_loss: 0.0207, d_svhn_loss: 0.0734, d_fake_loss: 0.0408, g_loss: 0.9417\n",
            "Step [39720/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0229, d_svhn_loss: 0.0163, d_fake_loss: 0.0360, g_loss: 1.0875\n",
            "Step [39730/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0175, d_svhn_loss: 0.0274, d_fake_loss: 0.0516, g_loss: 1.2261\n",
            "Step [39740/80000], d_real_loss: 0.1971, d_mnist_loss: 0.0310, d_svhn_loss: 0.1661, d_fake_loss: 0.2394, g_loss: 1.1666\n",
            "Step [39750/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0494, d_svhn_loss: 0.0177, d_fake_loss: 0.0545, g_loss: 1.2325\n",
            "Step [39760/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0251, d_svhn_loss: 0.0280, d_fake_loss: 0.0445, g_loss: 1.0618\n",
            "Step [39770/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0107, d_svhn_loss: 0.0739, d_fake_loss: 0.0384, g_loss: 1.1655\n",
            "Step [39780/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0171, d_svhn_loss: 0.0247, d_fake_loss: 0.0362, g_loss: 1.2235\n",
            "Step [39790/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0173, d_svhn_loss: 0.0361, d_fake_loss: 0.0399, g_loss: 1.0921\n",
            "Step [39800/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0185, d_svhn_loss: 0.0132, d_fake_loss: 0.0350, g_loss: 1.2376\n",
            "Step [39810/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0354, d_svhn_loss: 0.0338, d_fake_loss: 0.0808, g_loss: 0.8730\n",
            "Step [39820/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0309, d_svhn_loss: 0.0270, d_fake_loss: 0.0657, g_loss: 1.1255\n",
            "Step [39830/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0135, d_svhn_loss: 0.0222, d_fake_loss: 0.0400, g_loss: 1.1076\n",
            "Step [39840/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0147, d_svhn_loss: 0.0217, d_fake_loss: 0.0724, g_loss: 1.2603\n",
            "Step [39850/80000], d_real_loss: 0.0976, d_mnist_loss: 0.0136, d_svhn_loss: 0.0841, d_fake_loss: 0.0337, g_loss: 1.1624\n",
            "Step [39860/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0205, d_svhn_loss: 0.0223, d_fake_loss: 0.0787, g_loss: 1.2286\n",
            "Step [39870/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0197, d_svhn_loss: 0.0203, d_fake_loss: 0.0632, g_loss: 1.3034\n",
            "Step [39880/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0145, d_svhn_loss: 0.0275, d_fake_loss: 0.0469, g_loss: 1.2120\n",
            "Step [39890/80000], d_real_loss: 0.0909, d_mnist_loss: 0.0537, d_svhn_loss: 0.0371, d_fake_loss: 0.0767, g_loss: 1.1172\n",
            "Step [39900/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0279, d_svhn_loss: 0.0396, d_fake_loss: 0.0349, g_loss: 1.1934\n",
            "Step [39910/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0120, d_svhn_loss: 0.0298, d_fake_loss: 0.0539, g_loss: 1.1832\n",
            "Step [39920/80000], d_real_loss: 0.1570, d_mnist_loss: 0.0513, d_svhn_loss: 0.1057, d_fake_loss: 0.0597, g_loss: 1.0307\n",
            "Step [39930/80000], d_real_loss: 0.1937, d_mnist_loss: 0.0580, d_svhn_loss: 0.1356, d_fake_loss: 0.0711, g_loss: 1.0281\n",
            "Step [39940/80000], d_real_loss: 0.0952, d_mnist_loss: 0.0186, d_svhn_loss: 0.0766, d_fake_loss: 0.0906, g_loss: 1.2353\n",
            "Step [39950/80000], d_real_loss: 0.1083, d_mnist_loss: 0.0421, d_svhn_loss: 0.0662, d_fake_loss: 0.0419, g_loss: 1.2179\n",
            "Step [39960/80000], d_real_loss: 0.1440, d_mnist_loss: 0.0617, d_svhn_loss: 0.0822, d_fake_loss: 0.0419, g_loss: 1.1042\n",
            "Step [39970/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0175, d_svhn_loss: 0.0278, d_fake_loss: 0.0460, g_loss: 1.2150\n",
            "Step [39980/80000], d_real_loss: 0.0862, d_mnist_loss: 0.0488, d_svhn_loss: 0.0374, d_fake_loss: 0.0256, g_loss: 1.0745\n",
            "Step [39990/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0162, d_svhn_loss: 0.0438, d_fake_loss: 0.0770, g_loss: 1.2042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9073728322982788, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [40000/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0160, d_svhn_loss: 0.0311, d_fake_loss: 0.0387, g_loss: 1.1823\n",
            "saved ./samples_fashion/sample-40000-m-s.png\n",
            "saved ./samples_fashion/sample-40000-s-m.png\n",
            "Step [40010/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0229, d_svhn_loss: 0.0326, d_fake_loss: 0.0496, g_loss: 1.3319\n",
            "Step [40020/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0282, d_svhn_loss: 0.0204, d_fake_loss: 0.0687, g_loss: 1.3408\n",
            "Step [40030/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0272, d_svhn_loss: 0.0181, d_fake_loss: 0.0951, g_loss: 1.2220\n",
            "Step [40040/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0249, d_svhn_loss: 0.0265, d_fake_loss: 0.0509, g_loss: 1.0722\n",
            "Step [40050/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0219, d_svhn_loss: 0.0469, d_fake_loss: 0.0707, g_loss: 0.9750\n",
            "Step [40060/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0214, d_svhn_loss: 0.0241, d_fake_loss: 0.0797, g_loss: 1.3996\n",
            "Step [40070/80000], d_real_loss: 0.0942, d_mnist_loss: 0.0219, d_svhn_loss: 0.0723, d_fake_loss: 0.0526, g_loss: 1.0325\n",
            "Step [40080/80000], d_real_loss: 0.1112, d_mnist_loss: 0.0182, d_svhn_loss: 0.0930, d_fake_loss: 0.0268, g_loss: 1.1085\n",
            "Step [40090/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0107, d_svhn_loss: 0.0269, d_fake_loss: 0.1109, g_loss: 1.3504\n",
            "Step [40100/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0103, d_svhn_loss: 0.0299, d_fake_loss: 0.0873, g_loss: 1.1799\n",
            "Step [40110/80000], d_real_loss: 0.0701, d_mnist_loss: 0.0381, d_svhn_loss: 0.0320, d_fake_loss: 0.0414, g_loss: 1.1267\n",
            "Step [40120/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0203, d_svhn_loss: 0.0465, d_fake_loss: 0.0343, g_loss: 1.0784\n",
            "Step [40130/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0154, d_svhn_loss: 0.0300, d_fake_loss: 0.0635, g_loss: 1.0496\n",
            "Step [40140/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0208, d_svhn_loss: 0.0315, d_fake_loss: 0.0468, g_loss: 1.0917\n",
            "Step [40150/80000], d_real_loss: 0.1297, d_mnist_loss: 0.0484, d_svhn_loss: 0.0813, d_fake_loss: 0.0614, g_loss: 1.1226\n",
            "Step [40160/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0295, d_svhn_loss: 0.0441, d_fake_loss: 0.0913, g_loss: 1.0376\n",
            "Step [40170/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0209, d_svhn_loss: 0.0292, d_fake_loss: 0.0497, g_loss: 1.2761\n",
            "Step [40180/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0188, d_svhn_loss: 0.0217, d_fake_loss: 0.0457, g_loss: 1.1597\n",
            "Step [40190/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0227, d_svhn_loss: 0.0250, d_fake_loss: 0.0545, g_loss: 1.1179\n",
            "Step [40200/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0146, d_svhn_loss: 0.0347, d_fake_loss: 0.0448, g_loss: 1.0336\n",
            "Step [40210/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0256, d_svhn_loss: 0.0248, d_fake_loss: 0.0331, g_loss: 0.9985\n",
            "Step [40220/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0176, d_svhn_loss: 0.0251, d_fake_loss: 0.0489, g_loss: 1.0613\n",
            "Step [40230/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0175, d_svhn_loss: 0.0186, d_fake_loss: 0.0732, g_loss: 1.1442\n",
            "Step [40240/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0288, d_svhn_loss: 0.0233, d_fake_loss: 0.0767, g_loss: 1.2591\n",
            "Step [40250/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0273, d_svhn_loss: 0.0237, d_fake_loss: 0.1439, g_loss: 0.9020\n",
            "Step [40260/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0415, d_svhn_loss: 0.0215, d_fake_loss: 0.0368, g_loss: 1.1613\n",
            "Step [40270/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0094, d_svhn_loss: 0.0254, d_fake_loss: 0.0461, g_loss: 1.1889\n",
            "Step [40280/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0158, d_svhn_loss: 0.0533, d_fake_loss: 0.0550, g_loss: 1.0247\n",
            "Step [40290/80000], d_real_loss: 0.1246, d_mnist_loss: 0.0634, d_svhn_loss: 0.0612, d_fake_loss: 0.1005, g_loss: 1.4046\n",
            "Step [40300/80000], d_real_loss: 0.1118, d_mnist_loss: 0.0148, d_svhn_loss: 0.0970, d_fake_loss: 0.0592, g_loss: 1.1273\n",
            "Step [40310/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0253, d_svhn_loss: 0.0469, d_fake_loss: 0.1343, g_loss: 1.1169\n",
            "Step [40320/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0131, d_svhn_loss: 0.0285, d_fake_loss: 0.0425, g_loss: 1.2014\n",
            "Step [40330/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0157, d_svhn_loss: 0.0347, d_fake_loss: 0.0652, g_loss: 1.3236\n",
            "Step [40340/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0147, d_svhn_loss: 0.0704, d_fake_loss: 0.0753, g_loss: 1.0575\n",
            "Step [40350/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0370, d_svhn_loss: 0.0241, d_fake_loss: 0.0370, g_loss: 1.1609\n",
            "Step [40360/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0150, d_svhn_loss: 0.0301, d_fake_loss: 0.0611, g_loss: 1.3747\n",
            "Step [40370/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0222, d_svhn_loss: 0.0159, d_fake_loss: 0.0398, g_loss: 1.1712\n",
            "Step [40380/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0208, d_svhn_loss: 0.0331, d_fake_loss: 0.1121, g_loss: 1.4294\n",
            "Step [40390/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0225, d_svhn_loss: 0.0239, d_fake_loss: 0.1280, g_loss: 1.2699\n",
            "Step [40400/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0096, d_svhn_loss: 0.0184, d_fake_loss: 0.0373, g_loss: 1.2988\n",
            "Step [40410/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0121, d_svhn_loss: 0.0323, d_fake_loss: 0.0489, g_loss: 1.2904\n",
            "Step [40420/80000], d_real_loss: 0.1148, d_mnist_loss: 0.0392, d_svhn_loss: 0.0757, d_fake_loss: 0.0961, g_loss: 1.2302\n",
            "Step [40430/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0227, d_svhn_loss: 0.0333, d_fake_loss: 0.0495, g_loss: 1.3718\n",
            "Step [40440/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0265, d_svhn_loss: 0.0220, d_fake_loss: 0.0420, g_loss: 1.2121\n",
            "Step [40450/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0153, d_svhn_loss: 0.0201, d_fake_loss: 0.0689, g_loss: 1.2711\n",
            "Step [40460/80000], d_real_loss: 0.1155, d_mnist_loss: 0.0435, d_svhn_loss: 0.0720, d_fake_loss: 0.0582, g_loss: 1.0008\n",
            "Step [40470/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0279, d_svhn_loss: 0.0228, d_fake_loss: 0.1077, g_loss: 1.3250\n",
            "Step [40480/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0312, d_svhn_loss: 0.0228, d_fake_loss: 0.0416, g_loss: 1.0601\n",
            "Step [40490/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0179, d_svhn_loss: 0.0419, d_fake_loss: 0.0297, g_loss: 0.9760\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9277162551879883, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [40500/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0188, d_svhn_loss: 0.0350, d_fake_loss: 0.0377, g_loss: 1.0777\n",
            "saved ./samples_fashion/sample-40500-m-s.png\n",
            "saved ./samples_fashion/sample-40500-s-m.png\n",
            "Step [40510/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0343, d_svhn_loss: 0.0198, d_fake_loss: 0.0295, g_loss: 1.0277\n",
            "Step [40520/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0137, d_svhn_loss: 0.0286, d_fake_loss: 0.0461, g_loss: 1.2844\n",
            "Step [40530/80000], d_real_loss: 0.1594, d_mnist_loss: 0.1207, d_svhn_loss: 0.0387, d_fake_loss: 0.1656, g_loss: 1.6178\n",
            "Step [40540/80000], d_real_loss: 0.1535, d_mnist_loss: 0.0264, d_svhn_loss: 0.1271, d_fake_loss: 0.1834, g_loss: 0.9777\n",
            "Step [40550/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0328, d_svhn_loss: 0.0238, d_fake_loss: 0.0353, g_loss: 1.0409\n",
            "Step [40560/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0135, d_svhn_loss: 0.0783, d_fake_loss: 0.0346, g_loss: 1.1528\n",
            "Step [40570/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0119, d_svhn_loss: 0.0445, d_fake_loss: 0.0700, g_loss: 1.1649\n",
            "Step [40580/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0130, d_svhn_loss: 0.0354, d_fake_loss: 0.0658, g_loss: 0.9783\n",
            "Step [40590/80000], d_real_loss: 0.1153, d_mnist_loss: 0.0170, d_svhn_loss: 0.0983, d_fake_loss: 0.0413, g_loss: 1.1301\n",
            "Step [40600/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0204, d_svhn_loss: 0.0183, d_fake_loss: 0.0356, g_loss: 1.2074\n",
            "Step [40610/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0099, d_svhn_loss: 0.0294, d_fake_loss: 0.0625, g_loss: 1.2458\n",
            "Step [40620/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0218, d_svhn_loss: 0.0247, d_fake_loss: 0.0503, g_loss: 1.2397\n",
            "Step [40630/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0117, d_svhn_loss: 0.0321, d_fake_loss: 0.0828, g_loss: 1.1711\n",
            "Step [40640/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0193, d_svhn_loss: 0.0166, d_fake_loss: 0.0443, g_loss: 0.8375\n",
            "Step [40650/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0155, d_svhn_loss: 0.0256, d_fake_loss: 0.0443, g_loss: 1.2015\n",
            "Step [40660/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0108, d_svhn_loss: 0.0433, d_fake_loss: 0.0512, g_loss: 1.3054\n",
            "Step [40670/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0121, d_svhn_loss: 0.0304, d_fake_loss: 0.0847, g_loss: 1.3997\n",
            "Step [40680/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0445, d_svhn_loss: 0.0210, d_fake_loss: 0.0688, g_loss: 1.2892\n",
            "Step [40690/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0199, d_svhn_loss: 0.0262, d_fake_loss: 0.0339, g_loss: 0.9980\n",
            "Step [40700/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0123, d_svhn_loss: 0.0577, d_fake_loss: 0.0943, g_loss: 1.1011\n",
            "Step [40710/80000], d_real_loss: 0.0907, d_mnist_loss: 0.0430, d_svhn_loss: 0.0476, d_fake_loss: 0.0486, g_loss: 1.1465\n",
            "Step [40720/80000], d_real_loss: 0.0698, d_mnist_loss: 0.0179, d_svhn_loss: 0.0519, d_fake_loss: 0.0424, g_loss: 0.9846\n",
            "Step [40730/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0131, d_svhn_loss: 0.0321, d_fake_loss: 0.0325, g_loss: 1.0992\n",
            "Step [40740/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0220, d_svhn_loss: 0.0152, d_fake_loss: 0.0846, g_loss: 1.4020\n",
            "Step [40750/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0357, d_svhn_loss: 0.0247, d_fake_loss: 0.0376, g_loss: 1.1253\n",
            "Step [40760/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0148, d_svhn_loss: 0.0233, d_fake_loss: 0.0713, g_loss: 1.1902\n",
            "Step [40770/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0130, d_svhn_loss: 0.0260, d_fake_loss: 0.0992, g_loss: 1.3341\n",
            "Step [40780/80000], d_real_loss: 0.0907, d_mnist_loss: 0.0480, d_svhn_loss: 0.0427, d_fake_loss: 0.0969, g_loss: 1.3508\n",
            "Step [40790/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0137, d_svhn_loss: 0.0348, d_fake_loss: 0.0561, g_loss: 1.2586\n",
            "Step [40800/80000], d_real_loss: 0.1097, d_mnist_loss: 0.0191, d_svhn_loss: 0.0906, d_fake_loss: 0.0433, g_loss: 1.2548\n",
            "Step [40810/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0146, d_svhn_loss: 0.0162, d_fake_loss: 0.0271, g_loss: 1.0976\n",
            "Step [40820/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0222, d_svhn_loss: 0.0273, d_fake_loss: 0.1079, g_loss: 1.2180\n",
            "Step [40830/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0183, d_svhn_loss: 0.0353, d_fake_loss: 0.0420, g_loss: 1.0451\n",
            "Step [40840/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0339, d_svhn_loss: 0.0151, d_fake_loss: 0.0686, g_loss: 1.1436\n",
            "Step [40850/80000], d_real_loss: 0.1000, d_mnist_loss: 0.0639, d_svhn_loss: 0.0361, d_fake_loss: 0.0381, g_loss: 1.0542\n",
            "Step [40860/80000], d_real_loss: 0.0997, d_mnist_loss: 0.0554, d_svhn_loss: 0.0443, d_fake_loss: 0.0482, g_loss: 1.2401\n",
            "Step [40870/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0305, d_svhn_loss: 0.0279, d_fake_loss: 0.0542, g_loss: 1.0523\n",
            "Step [40880/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0217, d_svhn_loss: 0.0733, d_fake_loss: 0.1115, g_loss: 1.0570\n",
            "Step [40890/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0163, d_svhn_loss: 0.0353, d_fake_loss: 0.0423, g_loss: 1.1481\n",
            "Step [40900/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0437, d_svhn_loss: 0.0442, d_fake_loss: 0.0419, g_loss: 0.9600\n",
            "Step [40910/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0195, d_svhn_loss: 0.0497, d_fake_loss: 0.0485, g_loss: 0.9680\n",
            "Step [40920/80000], d_real_loss: 0.0881, d_mnist_loss: 0.0551, d_svhn_loss: 0.0330, d_fake_loss: 0.0542, g_loss: 1.0993\n",
            "Step [40930/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0324, d_svhn_loss: 0.0279, d_fake_loss: 0.0454, g_loss: 1.0516\n",
            "Step [40940/80000], d_real_loss: 0.1116, d_mnist_loss: 0.0459, d_svhn_loss: 0.0657, d_fake_loss: 0.0426, g_loss: 1.0967\n",
            "Step [40950/80000], d_real_loss: 0.0814, d_mnist_loss: 0.0352, d_svhn_loss: 0.0462, d_fake_loss: 0.1012, g_loss: 1.3358\n",
            "Step [40960/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0149, d_svhn_loss: 0.0128, d_fake_loss: 0.0338, g_loss: 1.0340\n",
            "Step [40970/80000], d_real_loss: 0.1019, d_mnist_loss: 0.0791, d_svhn_loss: 0.0228, d_fake_loss: 0.0428, g_loss: 1.1089\n",
            "Step [40980/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0152, d_svhn_loss: 0.0233, d_fake_loss: 0.0568, g_loss: 1.1121\n",
            "Step [40990/80000], d_real_loss: 0.0749, d_mnist_loss: 0.0205, d_svhn_loss: 0.0544, d_fake_loss: 0.0920, g_loss: 1.2392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8526262044906616, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [41000/80000], d_real_loss: 0.0836, d_mnist_loss: 0.0464, d_svhn_loss: 0.0372, d_fake_loss: 0.0338, g_loss: 1.2599\n",
            "saved ./samples_fashion/sample-41000-m-s.png\n",
            "saved ./samples_fashion/sample-41000-s-m.png\n",
            "Step [41010/80000], d_real_loss: 0.1737, d_mnist_loss: 0.1544, d_svhn_loss: 0.0193, d_fake_loss: 0.0664, g_loss: 1.7840\n",
            "Step [41020/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0298, d_svhn_loss: 0.0335, d_fake_loss: 0.1498, g_loss: 1.1368\n",
            "Step [41030/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0116, d_svhn_loss: 0.0293, d_fake_loss: 0.0355, g_loss: 1.3039\n",
            "Step [41040/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0154, d_svhn_loss: 0.0312, d_fake_loss: 0.0735, g_loss: 1.2900\n",
            "Step [41050/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0207, d_svhn_loss: 0.0213, d_fake_loss: 0.0474, g_loss: 1.2761\n",
            "Step [41060/80000], d_real_loss: 0.1191, d_mnist_loss: 0.0657, d_svhn_loss: 0.0533, d_fake_loss: 0.0679, g_loss: 0.9910\n",
            "Step [41070/80000], d_real_loss: 0.0928, d_mnist_loss: 0.0652, d_svhn_loss: 0.0276, d_fake_loss: 0.0489, g_loss: 1.1787\n",
            "Step [41080/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0153, d_svhn_loss: 0.0212, d_fake_loss: 0.0494, g_loss: 1.0274\n",
            "Step [41090/80000], d_real_loss: 0.0912, d_mnist_loss: 0.0145, d_svhn_loss: 0.0767, d_fake_loss: 0.0570, g_loss: 1.0633\n",
            "Step [41100/80000], d_real_loss: 0.0238, d_mnist_loss: 0.0100, d_svhn_loss: 0.0138, d_fake_loss: 0.0491, g_loss: 1.3057\n",
            "Step [41110/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0119, d_svhn_loss: 0.0189, d_fake_loss: 0.0265, g_loss: 1.2570\n",
            "Step [41120/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0281, d_svhn_loss: 0.0492, d_fake_loss: 0.0953, g_loss: 1.2099\n",
            "Step [41130/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0119, d_svhn_loss: 0.0429, d_fake_loss: 0.0338, g_loss: 1.1622\n",
            "Step [41140/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0171, d_svhn_loss: 0.0153, d_fake_loss: 0.0322, g_loss: 1.1675\n",
            "Step [41150/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0152, d_svhn_loss: 0.0302, d_fake_loss: 0.0485, g_loss: 1.0919\n",
            "Step [41160/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0137, d_svhn_loss: 0.0223, d_fake_loss: 0.0694, g_loss: 1.1111\n",
            "Step [41170/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0194, d_svhn_loss: 0.0330, d_fake_loss: 0.0289, g_loss: 1.0409\n",
            "Step [41180/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0135, d_svhn_loss: 0.0195, d_fake_loss: 0.0651, g_loss: 1.3969\n",
            "Step [41190/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0184, d_svhn_loss: 0.0343, d_fake_loss: 0.0505, g_loss: 1.1294\n",
            "Step [41200/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0151, d_svhn_loss: 0.0526, d_fake_loss: 0.0307, g_loss: 1.1992\n",
            "Step [41210/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0432, d_svhn_loss: 0.0214, d_fake_loss: 0.0279, g_loss: 0.8943\n",
            "Step [41220/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0143, d_svhn_loss: 0.0167, d_fake_loss: 0.1091, g_loss: 1.0734\n",
            "Step [41230/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0362, d_svhn_loss: 0.0453, d_fake_loss: 0.0877, g_loss: 1.0424\n",
            "Step [41240/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0406, d_svhn_loss: 0.0195, d_fake_loss: 0.0549, g_loss: 1.2030\n",
            "Step [41250/80000], d_real_loss: 0.1963, d_mnist_loss: 0.0791, d_svhn_loss: 0.1171, d_fake_loss: 0.0422, g_loss: 0.9651\n",
            "Step [41260/80000], d_real_loss: 0.3263, d_mnist_loss: 0.2760, d_svhn_loss: 0.0503, d_fake_loss: 0.1242, g_loss: 1.7668\n",
            "Step [41270/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0405, d_svhn_loss: 0.0158, d_fake_loss: 0.0555, g_loss: 0.8480\n",
            "Step [41280/80000], d_real_loss: 0.1452, d_mnist_loss: 0.1180, d_svhn_loss: 0.0272, d_fake_loss: 0.1093, g_loss: 1.0638\n",
            "Step [41290/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0162, d_svhn_loss: 0.0334, d_fake_loss: 0.0821, g_loss: 1.0777\n",
            "Step [41300/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0153, d_svhn_loss: 0.0685, d_fake_loss: 0.0323, g_loss: 1.1386\n",
            "Step [41310/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0335, d_svhn_loss: 0.0373, d_fake_loss: 0.0714, g_loss: 1.1834\n",
            "Step [41320/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0132, d_svhn_loss: 0.0294, d_fake_loss: 0.0425, g_loss: 1.2302\n",
            "Step [41330/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0540, d_svhn_loss: 0.0172, d_fake_loss: 0.0968, g_loss: 1.2970\n",
            "Step [41340/80000], d_real_loss: 0.1426, d_mnist_loss: 0.0312, d_svhn_loss: 0.1113, d_fake_loss: 0.1137, g_loss: 1.1150\n",
            "Step [41350/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0199, d_svhn_loss: 0.0139, d_fake_loss: 0.0325, g_loss: 1.2150\n",
            "Step [41360/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0185, d_svhn_loss: 0.0195, d_fake_loss: 0.0445, g_loss: 1.1060\n",
            "Step [41370/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0473, d_svhn_loss: 0.0443, d_fake_loss: 0.1257, g_loss: 1.0455\n",
            "Step [41380/80000], d_real_loss: 0.1915, d_mnist_loss: 0.1611, d_svhn_loss: 0.0304, d_fake_loss: 0.0357, g_loss: 1.2041\n",
            "Step [41390/80000], d_real_loss: 0.0776, d_mnist_loss: 0.0141, d_svhn_loss: 0.0634, d_fake_loss: 0.1375, g_loss: 1.4136\n",
            "Step [41400/80000], d_real_loss: 0.1161, d_mnist_loss: 0.0202, d_svhn_loss: 0.0959, d_fake_loss: 0.1438, g_loss: 0.9018\n",
            "Step [41410/80000], d_real_loss: 0.1979, d_mnist_loss: 0.0159, d_svhn_loss: 0.1820, d_fake_loss: 0.0452, g_loss: 1.1384\n",
            "Step [41420/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0248, d_svhn_loss: 0.0336, d_fake_loss: 0.0513, g_loss: 1.2614\n",
            "Step [41430/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0298, d_svhn_loss: 0.0270, d_fake_loss: 0.0347, g_loss: 1.1653\n",
            "Step [41440/80000], d_real_loss: 0.1275, d_mnist_loss: 0.0588, d_svhn_loss: 0.0687, d_fake_loss: 0.0299, g_loss: 1.0733\n",
            "Step [41450/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0226, d_svhn_loss: 0.0213, d_fake_loss: 0.0452, g_loss: 1.2255\n",
            "Step [41460/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0257, d_svhn_loss: 0.0446, d_fake_loss: 0.0356, g_loss: 1.1826\n",
            "Step [41470/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0169, d_svhn_loss: 0.0375, d_fake_loss: 0.0435, g_loss: 1.2253\n",
            "Step [41480/80000], d_real_loss: 0.1274, d_mnist_loss: 0.0480, d_svhn_loss: 0.0794, d_fake_loss: 0.0616, g_loss: 1.0057\n",
            "Step [41490/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0146, d_svhn_loss: 0.0193, d_fake_loss: 0.1028, g_loss: 1.0334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9609273672103882, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [41500/80000], d_real_loss: 0.0878, d_mnist_loss: 0.0121, d_svhn_loss: 0.0756, d_fake_loss: 0.0657, g_loss: 1.0293\n",
            "saved ./samples_fashion/sample-41500-m-s.png\n",
            "saved ./samples_fashion/sample-41500-s-m.png\n",
            "Step [41510/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0283, d_svhn_loss: 0.0375, d_fake_loss: 0.0398, g_loss: 1.0560\n",
            "Step [41520/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0148, d_svhn_loss: 0.0218, d_fake_loss: 0.0459, g_loss: 1.0179\n",
            "Step [41530/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0178, d_svhn_loss: 0.0256, d_fake_loss: 0.0261, g_loss: 1.1225\n",
            "Step [41540/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0132, d_svhn_loss: 0.0528, d_fake_loss: 0.0299, g_loss: 1.1739\n",
            "Step [41550/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0338, d_svhn_loss: 0.0380, d_fake_loss: 0.0447, g_loss: 1.2390\n",
            "Step [41560/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0142, d_svhn_loss: 0.0349, d_fake_loss: 0.0460, g_loss: 1.2925\n",
            "Step [41570/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0145, d_svhn_loss: 0.0300, d_fake_loss: 0.0390, g_loss: 1.2529\n",
            "Step [41580/80000], d_real_loss: 0.0709, d_mnist_loss: 0.0449, d_svhn_loss: 0.0260, d_fake_loss: 0.0480, g_loss: 1.3292\n",
            "Step [41590/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0441, d_svhn_loss: 0.0235, d_fake_loss: 0.0379, g_loss: 1.1393\n",
            "Step [41600/80000], d_real_loss: 0.1352, d_mnist_loss: 0.0702, d_svhn_loss: 0.0650, d_fake_loss: 0.1462, g_loss: 1.4404\n",
            "Step [41610/80000], d_real_loss: 0.0955, d_mnist_loss: 0.0200, d_svhn_loss: 0.0755, d_fake_loss: 0.0484, g_loss: 1.1965\n",
            "Step [41620/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0191, d_svhn_loss: 0.0326, d_fake_loss: 0.0477, g_loss: 1.1823\n",
            "Step [41630/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0129, d_svhn_loss: 0.0720, d_fake_loss: 0.0361, g_loss: 1.2362\n",
            "Step [41640/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0146, d_svhn_loss: 0.0531, d_fake_loss: 0.0281, g_loss: 1.0858\n",
            "Step [41650/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0278, d_svhn_loss: 0.0185, d_fake_loss: 0.0288, g_loss: 1.0432\n",
            "Step [41660/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0247, d_svhn_loss: 0.0222, d_fake_loss: 0.0394, g_loss: 1.1084\n",
            "Step [41670/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0155, d_svhn_loss: 0.0516, d_fake_loss: 0.0920, g_loss: 1.1294\n",
            "Step [41680/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0274, d_svhn_loss: 0.0348, d_fake_loss: 0.0682, g_loss: 1.0875\n",
            "Step [41690/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0112, d_svhn_loss: 0.0279, d_fake_loss: 0.0641, g_loss: 1.2377\n",
            "Step [41700/80000], d_real_loss: 0.1030, d_mnist_loss: 0.0238, d_svhn_loss: 0.0792, d_fake_loss: 0.0531, g_loss: 1.0881\n",
            "Step [41710/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0172, d_svhn_loss: 0.0383, d_fake_loss: 0.0404, g_loss: 0.9899\n",
            "Step [41720/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0115, d_svhn_loss: 0.0318, d_fake_loss: 0.0967, g_loss: 1.2803\n",
            "Step [41730/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0129, d_svhn_loss: 0.0214, d_fake_loss: 0.0350, g_loss: 1.1704\n",
            "Step [41740/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0111, d_svhn_loss: 0.0214, d_fake_loss: 0.0825, g_loss: 1.2673\n",
            "Step [41750/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0124, d_svhn_loss: 0.0649, d_fake_loss: 0.0706, g_loss: 1.2283\n",
            "Step [41760/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0196, d_svhn_loss: 0.0362, d_fake_loss: 0.0248, g_loss: 1.1416\n",
            "Step [41770/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0170, d_svhn_loss: 0.0175, d_fake_loss: 0.1038, g_loss: 1.2072\n",
            "Step [41780/80000], d_real_loss: 0.0917, d_mnist_loss: 0.0196, d_svhn_loss: 0.0721, d_fake_loss: 0.0688, g_loss: 1.2269\n",
            "Step [41790/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0161, d_svhn_loss: 0.0288, d_fake_loss: 0.0736, g_loss: 1.2680\n",
            "Step [41800/80000], d_real_loss: 0.0992, d_mnist_loss: 0.0716, d_svhn_loss: 0.0276, d_fake_loss: 0.0564, g_loss: 1.3234\n",
            "Step [41810/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0305, d_svhn_loss: 0.0478, d_fake_loss: 0.0700, g_loss: 1.1867\n",
            "Step [41820/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0093, d_svhn_loss: 0.0163, d_fake_loss: 0.0587, g_loss: 1.0699\n",
            "Step [41830/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0142, d_svhn_loss: 0.0384, d_fake_loss: 0.0334, g_loss: 1.0458\n",
            "Step [41840/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0512, d_svhn_loss: 0.0205, d_fake_loss: 0.0458, g_loss: 1.1417\n",
            "Step [41850/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0210, d_svhn_loss: 0.0395, d_fake_loss: 0.1162, g_loss: 1.1788\n",
            "Step [41860/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0302, d_svhn_loss: 0.0279, d_fake_loss: 0.0915, g_loss: 1.1787\n",
            "Step [41870/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0189, d_svhn_loss: 0.0195, d_fake_loss: 0.0302, g_loss: 1.0201\n",
            "Step [41880/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0127, d_svhn_loss: 0.0293, d_fake_loss: 0.0741, g_loss: 1.2116\n",
            "Step [41890/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0113, d_svhn_loss: 0.0324, d_fake_loss: 0.0628, g_loss: 1.1112\n",
            "Step [41900/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0124, d_svhn_loss: 0.0369, d_fake_loss: 0.1190, g_loss: 1.0897\n",
            "Step [41910/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0103, d_svhn_loss: 0.0332, d_fake_loss: 0.0703, g_loss: 1.2950\n",
            "Step [41920/80000], d_real_loss: 0.0797, d_mnist_loss: 0.0346, d_svhn_loss: 0.0451, d_fake_loss: 0.0795, g_loss: 1.1673\n",
            "Step [41930/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0190, d_svhn_loss: 0.0293, d_fake_loss: 0.2405, g_loss: 1.3275\n",
            "Step [41940/80000], d_real_loss: 0.1131, d_mnist_loss: 0.0612, d_svhn_loss: 0.0519, d_fake_loss: 0.0379, g_loss: 0.9926\n",
            "Step [41950/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0148, d_svhn_loss: 0.0378, d_fake_loss: 0.0305, g_loss: 1.1382\n",
            "Step [41960/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0270, d_svhn_loss: 0.0221, d_fake_loss: 0.0349, g_loss: 1.1753\n",
            "Step [41970/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0159, d_svhn_loss: 0.0256, d_fake_loss: 0.0927, g_loss: 1.2116\n",
            "Step [41980/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0397, d_svhn_loss: 0.0341, d_fake_loss: 0.0536, g_loss: 1.2252\n",
            "Step [41990/80000], d_real_loss: 0.1103, d_mnist_loss: 0.0223, d_svhn_loss: 0.0880, d_fake_loss: 0.0874, g_loss: 1.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9023445248603821, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [42000/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0125, d_svhn_loss: 0.0299, d_fake_loss: 0.0574, g_loss: 1.0848\n",
            "saved ./samples_fashion/sample-42000-m-s.png\n",
            "saved ./samples_fashion/sample-42000-s-m.png\n",
            "Step [42010/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0189, d_svhn_loss: 0.0255, d_fake_loss: 0.0570, g_loss: 1.3329\n",
            "Step [42020/80000], d_real_loss: 0.1762, d_mnist_loss: 0.1281, d_svhn_loss: 0.0481, d_fake_loss: 0.1065, g_loss: 1.1744\n",
            "Step [42030/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0235, d_svhn_loss: 0.0215, d_fake_loss: 0.0700, g_loss: 1.2267\n",
            "Step [42040/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0142, d_svhn_loss: 0.0268, d_fake_loss: 0.0521, g_loss: 1.2166\n",
            "Step [42050/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0242, d_svhn_loss: 0.0231, d_fake_loss: 0.0376, g_loss: 1.1905\n",
            "Step [42060/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0148, d_svhn_loss: 0.0308, d_fake_loss: 0.1655, g_loss: 1.2490\n",
            "Step [42070/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0203, d_svhn_loss: 0.0185, d_fake_loss: 0.0472, g_loss: 1.2490\n",
            "Step [42080/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0199, d_svhn_loss: 0.0186, d_fake_loss: 0.0581, g_loss: 1.0010\n",
            "Step [42090/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0276, d_svhn_loss: 0.0169, d_fake_loss: 0.0548, g_loss: 1.1308\n",
            "Step [42100/80000], d_real_loss: 0.1656, d_mnist_loss: 0.1303, d_svhn_loss: 0.0353, d_fake_loss: 0.1335, g_loss: 1.2740\n",
            "Step [42110/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0113, d_svhn_loss: 0.0307, d_fake_loss: 0.0516, g_loss: 1.1122\n",
            "Step [42120/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0242, d_svhn_loss: 0.0347, d_fake_loss: 0.0959, g_loss: 1.1278\n",
            "Step [42130/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0199, d_svhn_loss: 0.0208, d_fake_loss: 0.0519, g_loss: 1.1300\n",
            "Step [42140/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0155, d_svhn_loss: 0.0278, d_fake_loss: 0.0297, g_loss: 1.0800\n",
            "Step [42150/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0504, d_svhn_loss: 0.0220, d_fake_loss: 0.0622, g_loss: 1.0540\n",
            "Step [42160/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0130, d_svhn_loss: 0.0388, d_fake_loss: 0.0459, g_loss: 1.1869\n",
            "Step [42170/80000], d_real_loss: 0.0826, d_mnist_loss: 0.0274, d_svhn_loss: 0.0552, d_fake_loss: 0.0287, g_loss: 0.9836\n",
            "Step [42180/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0113, d_svhn_loss: 0.0227, d_fake_loss: 0.0417, g_loss: 1.2676\n",
            "Step [42190/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0369, d_svhn_loss: 0.0301, d_fake_loss: 0.0465, g_loss: 1.1323\n",
            "Step [42200/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0210, d_svhn_loss: 0.0272, d_fake_loss: 0.0965, g_loss: 1.2239\n",
            "Step [42210/80000], d_real_loss: 0.1374, d_mnist_loss: 0.1074, d_svhn_loss: 0.0300, d_fake_loss: 0.0736, g_loss: 1.0516\n",
            "Step [42220/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0208, d_svhn_loss: 0.0336, d_fake_loss: 0.0561, g_loss: 1.0736\n",
            "Step [42230/80000], d_real_loss: 0.1056, d_mnist_loss: 0.0469, d_svhn_loss: 0.0586, d_fake_loss: 0.0528, g_loss: 1.0266\n",
            "Step [42240/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0102, d_svhn_loss: 0.0453, d_fake_loss: 0.0490, g_loss: 1.1337\n",
            "Step [42250/80000], d_real_loss: 0.0942, d_mnist_loss: 0.0447, d_svhn_loss: 0.0496, d_fake_loss: 0.0457, g_loss: 1.0151\n",
            "Step [42260/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0211, d_svhn_loss: 0.0327, d_fake_loss: 0.0535, g_loss: 1.0988\n",
            "Step [42270/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0209, d_svhn_loss: 0.0410, d_fake_loss: 0.2340, g_loss: 1.1577\n",
            "Step [42280/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0623, d_svhn_loss: 0.0277, d_fake_loss: 0.0561, g_loss: 1.2021\n",
            "Step [42290/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0140, d_svhn_loss: 0.0462, d_fake_loss: 0.0587, g_loss: 1.0712\n",
            "Step [42300/80000], d_real_loss: 0.0789, d_mnist_loss: 0.0509, d_svhn_loss: 0.0280, d_fake_loss: 0.0586, g_loss: 1.1254\n",
            "Step [42310/80000], d_real_loss: 0.0845, d_mnist_loss: 0.0195, d_svhn_loss: 0.0650, d_fake_loss: 0.0616, g_loss: 1.1807\n",
            "Step [42320/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0335, d_svhn_loss: 0.0212, d_fake_loss: 0.0981, g_loss: 1.3046\n",
            "Step [42330/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0436, d_svhn_loss: 0.0312, d_fake_loss: 0.1021, g_loss: 1.1936\n",
            "Step [42340/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0186, d_svhn_loss: 0.0352, d_fake_loss: 0.1144, g_loss: 1.3184\n",
            "Step [42350/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0507, d_svhn_loss: 0.0443, d_fake_loss: 0.0503, g_loss: 1.0951\n",
            "Step [42360/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0222, d_svhn_loss: 0.0126, d_fake_loss: 0.0390, g_loss: 1.1926\n",
            "Step [42370/80000], d_real_loss: 0.1333, d_mnist_loss: 0.1129, d_svhn_loss: 0.0204, d_fake_loss: 0.0573, g_loss: 1.2650\n",
            "Step [42380/80000], d_real_loss: 0.1173, d_mnist_loss: 0.0861, d_svhn_loss: 0.0312, d_fake_loss: 0.0486, g_loss: 1.0202\n",
            "Step [42390/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0187, d_svhn_loss: 0.0285, d_fake_loss: 0.0370, g_loss: 1.2214\n",
            "Step [42400/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0134, d_svhn_loss: 0.0395, d_fake_loss: 0.0560, g_loss: 1.1745\n",
            "Step [42410/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0224, d_svhn_loss: 0.0246, d_fake_loss: 0.0808, g_loss: 1.3212\n",
            "Step [42420/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0175, d_svhn_loss: 0.0184, d_fake_loss: 0.0359, g_loss: 1.1533\n",
            "Step [42430/80000], d_real_loss: 0.1051, d_mnist_loss: 0.0826, d_svhn_loss: 0.0225, d_fake_loss: 0.1734, g_loss: 1.4171\n",
            "Step [42440/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0297, d_svhn_loss: 0.0229, d_fake_loss: 0.0659, g_loss: 1.2228\n",
            "Step [42450/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0227, d_svhn_loss: 0.0194, d_fake_loss: 0.0494, g_loss: 1.2002\n",
            "Step [42460/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0157, d_svhn_loss: 0.0230, d_fake_loss: 0.0377, g_loss: 1.2445\n",
            "Step [42470/80000], d_real_loss: 0.1000, d_mnist_loss: 0.0703, d_svhn_loss: 0.0297, d_fake_loss: 0.0633, g_loss: 1.2317\n",
            "Step [42480/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0129, d_svhn_loss: 0.0232, d_fake_loss: 0.0467, g_loss: 1.2086\n",
            "Step [42490/80000], d_real_loss: 0.0890, d_mnist_loss: 0.0422, d_svhn_loss: 0.0468, d_fake_loss: 0.0750, g_loss: 1.1425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.86313796043396, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [42500/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0251, d_svhn_loss: 0.0320, d_fake_loss: 0.0260, g_loss: 1.2472\n",
            "saved ./samples_fashion/sample-42500-m-s.png\n",
            "saved ./samples_fashion/sample-42500-s-m.png\n",
            "Step [42510/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0297, d_svhn_loss: 0.0298, d_fake_loss: 0.0773, g_loss: 1.1470\n",
            "Step [42520/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0183, d_svhn_loss: 0.0208, d_fake_loss: 0.0698, g_loss: 1.1828\n",
            "Step [42530/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0181, d_svhn_loss: 0.0210, d_fake_loss: 0.0492, g_loss: 1.1962\n",
            "Step [42540/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0145, d_svhn_loss: 0.0557, d_fake_loss: 0.0437, g_loss: 1.0817\n",
            "Step [42550/80000], d_real_loss: 0.0899, d_mnist_loss: 0.0187, d_svhn_loss: 0.0712, d_fake_loss: 0.1263, g_loss: 1.2367\n",
            "Step [42560/80000], d_real_loss: 0.1158, d_mnist_loss: 0.0153, d_svhn_loss: 0.1005, d_fake_loss: 0.0665, g_loss: 1.0826\n",
            "Step [42570/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0171, d_svhn_loss: 0.0286, d_fake_loss: 0.0338, g_loss: 1.1397\n",
            "Step [42580/80000], d_real_loss: 0.1083, d_mnist_loss: 0.0285, d_svhn_loss: 0.0798, d_fake_loss: 0.0316, g_loss: 1.0529\n",
            "Step [42590/80000], d_real_loss: 0.1372, d_mnist_loss: 0.0370, d_svhn_loss: 0.1002, d_fake_loss: 0.0323, g_loss: 1.0983\n",
            "Step [42600/80000], d_real_loss: 0.1579, d_mnist_loss: 0.0655, d_svhn_loss: 0.0924, d_fake_loss: 0.0771, g_loss: 1.1925\n",
            "Step [42610/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0126, d_svhn_loss: 0.0383, d_fake_loss: 0.0780, g_loss: 1.1840\n",
            "Step [42620/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0203, d_svhn_loss: 0.0406, d_fake_loss: 0.0273, g_loss: 1.0448\n",
            "Step [42630/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0166, d_svhn_loss: 0.0312, d_fake_loss: 0.0741, g_loss: 1.1434\n",
            "Step [42640/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0109, d_svhn_loss: 0.0194, d_fake_loss: 0.0804, g_loss: 1.0045\n",
            "Step [42650/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0185, d_svhn_loss: 0.0182, d_fake_loss: 0.0550, g_loss: 1.1439\n",
            "Step [42660/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0183, d_svhn_loss: 0.0339, d_fake_loss: 0.0394, g_loss: 1.0809\n",
            "Step [42670/80000], d_real_loss: 0.2193, d_mnist_loss: 0.0273, d_svhn_loss: 0.1920, d_fake_loss: 0.0743, g_loss: 1.2338\n",
            "Step [42680/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0201, d_svhn_loss: 0.0140, d_fake_loss: 0.0589, g_loss: 1.3227\n",
            "Step [42690/80000], d_real_loss: 0.1118, d_mnist_loss: 0.0726, d_svhn_loss: 0.0392, d_fake_loss: 0.0413, g_loss: 1.2164\n",
            "Step [42700/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0322, d_svhn_loss: 0.0144, d_fake_loss: 0.0868, g_loss: 1.2939\n",
            "Step [42710/80000], d_real_loss: 0.1057, d_mnist_loss: 0.0719, d_svhn_loss: 0.0337, d_fake_loss: 0.0559, g_loss: 1.0759\n",
            "Step [42720/80000], d_real_loss: 0.1158, d_mnist_loss: 0.0903, d_svhn_loss: 0.0254, d_fake_loss: 0.0429, g_loss: 0.9888\n",
            "Step [42730/80000], d_real_loss: 0.1182, d_mnist_loss: 0.0534, d_svhn_loss: 0.0648, d_fake_loss: 0.0579, g_loss: 1.1052\n",
            "Step [42740/80000], d_real_loss: 0.0626, d_mnist_loss: 0.0170, d_svhn_loss: 0.0456, d_fake_loss: 0.1049, g_loss: 1.2751\n",
            "Step [42750/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0341, d_svhn_loss: 0.0177, d_fake_loss: 0.0878, g_loss: 0.9847\n",
            "Step [42760/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0120, d_svhn_loss: 0.0416, d_fake_loss: 0.0389, g_loss: 1.2073\n",
            "Step [42770/80000], d_real_loss: 0.1011, d_mnist_loss: 0.0355, d_svhn_loss: 0.0655, d_fake_loss: 0.0797, g_loss: 1.1895\n",
            "Step [42780/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0145, d_svhn_loss: 0.0452, d_fake_loss: 0.1014, g_loss: 0.9415\n",
            "Step [42790/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0149, d_svhn_loss: 0.0242, d_fake_loss: 0.0487, g_loss: 1.1278\n",
            "Step [42800/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0220, d_svhn_loss: 0.0428, d_fake_loss: 0.0687, g_loss: 0.9776\n",
            "Step [42810/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0275, d_svhn_loss: 0.0298, d_fake_loss: 0.0533, g_loss: 1.2311\n",
            "Step [42820/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0124, d_svhn_loss: 0.0316, d_fake_loss: 0.0373, g_loss: 1.0887\n",
            "Step [42830/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0619, d_svhn_loss: 0.0248, d_fake_loss: 0.0409, g_loss: 0.9788\n",
            "Step [42840/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0373, d_svhn_loss: 0.0224, d_fake_loss: 0.0460, g_loss: 1.0161\n",
            "Step [42850/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0134, d_svhn_loss: 0.0512, d_fake_loss: 0.0391, g_loss: 1.4062\n",
            "Step [42860/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0188, d_svhn_loss: 0.0522, d_fake_loss: 0.1056, g_loss: 1.3943\n",
            "Step [42870/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0134, d_svhn_loss: 0.0335, d_fake_loss: 0.0375, g_loss: 1.0532\n",
            "Step [42880/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0168, d_svhn_loss: 0.0460, d_fake_loss: 0.0623, g_loss: 1.1887\n",
            "Step [42890/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0183, d_svhn_loss: 0.0735, d_fake_loss: 0.0297, g_loss: 1.2415\n",
            "Step [42900/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0244, d_svhn_loss: 0.0253, d_fake_loss: 0.0472, g_loss: 0.8905\n",
            "Step [42910/80000], d_real_loss: 0.0933, d_mnist_loss: 0.0232, d_svhn_loss: 0.0701, d_fake_loss: 0.0697, g_loss: 1.2350\n",
            "Step [42920/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0300, d_svhn_loss: 0.0221, d_fake_loss: 0.0591, g_loss: 1.1255\n",
            "Step [42930/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0135, d_svhn_loss: 0.0504, d_fake_loss: 0.0643, g_loss: 1.1529\n",
            "Step [42940/80000], d_real_loss: 0.0658, d_mnist_loss: 0.0314, d_svhn_loss: 0.0344, d_fake_loss: 0.0676, g_loss: 0.9738\n",
            "Step [42950/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0141, d_svhn_loss: 0.0440, d_fake_loss: 0.1286, g_loss: 1.2718\n",
            "Step [42960/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0203, d_svhn_loss: 0.0374, d_fake_loss: 0.0650, g_loss: 0.9755\n",
            "Step [42970/80000], d_real_loss: 0.1233, d_mnist_loss: 0.0760, d_svhn_loss: 0.0473, d_fake_loss: 0.0882, g_loss: 1.3761\n",
            "Step [42980/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0426, d_svhn_loss: 0.0184, d_fake_loss: 0.1427, g_loss: 1.0942\n",
            "Step [42990/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0224, d_svhn_loss: 0.0276, d_fake_loss: 0.0337, g_loss: 1.0803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8947545289993286, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [43000/80000], d_real_loss: 0.1529, d_mnist_loss: 0.0489, d_svhn_loss: 0.1040, d_fake_loss: 0.0758, g_loss: 1.1277\n",
            "saved ./samples_fashion/sample-43000-m-s.png\n",
            "saved ./samples_fashion/sample-43000-s-m.png\n",
            "Step [43010/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0256, d_svhn_loss: 0.0145, d_fake_loss: 0.0671, g_loss: 0.8929\n",
            "Step [43020/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0193, d_svhn_loss: 0.0155, d_fake_loss: 0.0391, g_loss: 1.0814\n",
            "Step [43030/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0163, d_svhn_loss: 0.0227, d_fake_loss: 0.0519, g_loss: 1.2077\n",
            "Step [43040/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0124, d_svhn_loss: 0.0606, d_fake_loss: 0.0838, g_loss: 1.2756\n",
            "Step [43050/80000], d_real_loss: 0.1291, d_mnist_loss: 0.0489, d_svhn_loss: 0.0802, d_fake_loss: 0.0329, g_loss: 1.0487\n",
            "Step [43060/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0258, d_svhn_loss: 0.0190, d_fake_loss: 0.0880, g_loss: 1.0494\n",
            "Step [43070/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0229, d_svhn_loss: 0.0188, d_fake_loss: 0.1191, g_loss: 1.1909\n",
            "Step [43080/80000], d_real_loss: 0.0803, d_mnist_loss: 0.0212, d_svhn_loss: 0.0591, d_fake_loss: 0.1099, g_loss: 1.1564\n",
            "Step [43090/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0158, d_svhn_loss: 0.0329, d_fake_loss: 0.0365, g_loss: 1.1637\n",
            "Step [43100/80000], d_real_loss: 0.0939, d_mnist_loss: 0.0419, d_svhn_loss: 0.0520, d_fake_loss: 0.0545, g_loss: 1.1124\n",
            "Step [43110/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0191, d_svhn_loss: 0.0147, d_fake_loss: 0.0261, g_loss: 1.3701\n",
            "Step [43120/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0277, d_svhn_loss: 0.0184, d_fake_loss: 0.0337, g_loss: 1.1650\n",
            "Step [43130/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0555, d_svhn_loss: 0.0199, d_fake_loss: 0.0835, g_loss: 1.1645\n",
            "Step [43140/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0336, d_svhn_loss: 0.0167, d_fake_loss: 0.0276, g_loss: 1.1525\n",
            "Step [43150/80000], d_real_loss: 0.0929, d_mnist_loss: 0.0725, d_svhn_loss: 0.0204, d_fake_loss: 0.1863, g_loss: 1.1852\n",
            "Step [43160/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0183, d_svhn_loss: 0.0214, d_fake_loss: 0.0639, g_loss: 1.2155\n",
            "Step [43170/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0159, d_svhn_loss: 0.0309, d_fake_loss: 0.0405, g_loss: 1.0530\n",
            "Step [43180/80000], d_real_loss: 0.1017, d_mnist_loss: 0.0610, d_svhn_loss: 0.0408, d_fake_loss: 0.0800, g_loss: 1.3046\n",
            "Step [43190/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0181, d_svhn_loss: 0.0238, d_fake_loss: 0.0627, g_loss: 1.3177\n",
            "Step [43200/80000], d_real_loss: 0.0895, d_mnist_loss: 0.0217, d_svhn_loss: 0.0678, d_fake_loss: 0.0367, g_loss: 1.1207\n",
            "Step [43210/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0528, d_svhn_loss: 0.0263, d_fake_loss: 0.0431, g_loss: 1.1145\n",
            "Step [43220/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0132, d_svhn_loss: 0.0231, d_fake_loss: 0.0895, g_loss: 0.8440\n",
            "Step [43230/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0249, d_svhn_loss: 0.0168, d_fake_loss: 0.0997, g_loss: 1.2905\n",
            "Step [43240/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0149, d_svhn_loss: 0.0245, d_fake_loss: 0.0701, g_loss: 1.2066\n",
            "Step [43250/80000], d_real_loss: 0.0695, d_mnist_loss: 0.0508, d_svhn_loss: 0.0187, d_fake_loss: 0.0538, g_loss: 1.0462\n",
            "Step [43260/80000], d_real_loss: 0.0925, d_mnist_loss: 0.0421, d_svhn_loss: 0.0505, d_fake_loss: 0.0478, g_loss: 1.0850\n",
            "Step [43270/80000], d_real_loss: 0.0226, d_mnist_loss: 0.0107, d_svhn_loss: 0.0119, d_fake_loss: 0.0262, g_loss: 1.1489\n",
            "Step [43280/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0245, d_svhn_loss: 0.0327, d_fake_loss: 0.0464, g_loss: 1.0357\n",
            "Step [43290/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0199, d_svhn_loss: 0.0569, d_fake_loss: 0.0881, g_loss: 1.1266\n",
            "Step [43300/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0163, d_svhn_loss: 0.0147, d_fake_loss: 0.0439, g_loss: 1.1182\n",
            "Step [43310/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0407, d_svhn_loss: 0.0232, d_fake_loss: 0.0506, g_loss: 1.2033\n",
            "Step [43320/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0166, d_svhn_loss: 0.0592, d_fake_loss: 0.0645, g_loss: 1.1802\n",
            "Step [43330/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0133, d_svhn_loss: 0.0205, d_fake_loss: 0.0677, g_loss: 1.2454\n",
            "Step [43340/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0186, d_svhn_loss: 0.0427, d_fake_loss: 0.0336, g_loss: 1.1067\n",
            "Step [43350/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0311, d_svhn_loss: 0.0348, d_fake_loss: 0.0764, g_loss: 1.1019\n",
            "Step [43360/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0099, d_svhn_loss: 0.0306, d_fake_loss: 0.0279, g_loss: 1.1988\n",
            "Step [43370/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0187, d_svhn_loss: 0.0409, d_fake_loss: 0.0406, g_loss: 1.1530\n",
            "Step [43380/80000], d_real_loss: 0.0797, d_mnist_loss: 0.0184, d_svhn_loss: 0.0612, d_fake_loss: 0.0543, g_loss: 1.2398\n",
            "Step [43390/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0167, d_svhn_loss: 0.0168, d_fake_loss: 0.0310, g_loss: 1.1556\n",
            "Step [43400/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0273, d_svhn_loss: 0.0361, d_fake_loss: 0.0637, g_loss: 0.9468\n",
            "Step [43410/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0144, d_svhn_loss: 0.0271, d_fake_loss: 0.0467, g_loss: 1.2691\n",
            "Step [43420/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0133, d_svhn_loss: 0.0160, d_fake_loss: 0.1284, g_loss: 1.3918\n",
            "Step [43430/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0181, d_svhn_loss: 0.0359, d_fake_loss: 0.0541, g_loss: 1.2432\n",
            "Step [43440/80000], d_real_loss: 0.1448, d_mnist_loss: 0.0170, d_svhn_loss: 0.1279, d_fake_loss: 0.2416, g_loss: 1.1220\n",
            "Step [43450/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0187, d_svhn_loss: 0.0185, d_fake_loss: 0.0338, g_loss: 1.1323\n",
            "Step [43460/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0167, d_svhn_loss: 0.0265, d_fake_loss: 0.0549, g_loss: 1.0270\n",
            "Step [43470/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0135, d_svhn_loss: 0.0308, d_fake_loss: 0.0501, g_loss: 1.2181\n",
            "Step [43480/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0201, d_svhn_loss: 0.0226, d_fake_loss: 0.0560, g_loss: 1.1256\n",
            "Step [43490/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0203, d_svhn_loss: 0.0241, d_fake_loss: 0.0763, g_loss: 1.2406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8488049507141113, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [43500/80000], d_real_loss: 0.0856, d_mnist_loss: 0.0129, d_svhn_loss: 0.0727, d_fake_loss: 0.0485, g_loss: 1.0864\n",
            "saved ./samples_fashion/sample-43500-m-s.png\n",
            "saved ./samples_fashion/sample-43500-s-m.png\n",
            "Step [43510/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0135, d_svhn_loss: 0.0213, d_fake_loss: 0.0437, g_loss: 1.3544\n",
            "Step [43520/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0331, d_svhn_loss: 0.0238, d_fake_loss: 0.0509, g_loss: 1.2147\n",
            "Step [43530/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0315, d_svhn_loss: 0.0152, d_fake_loss: 0.0495, g_loss: 1.2623\n",
            "Step [43540/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0205, d_svhn_loss: 0.0395, d_fake_loss: 0.0638, g_loss: 1.0970\n",
            "Step [43550/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0371, d_svhn_loss: 0.0188, d_fake_loss: 0.0443, g_loss: 1.0182\n",
            "Step [43560/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0204, d_svhn_loss: 0.0465, d_fake_loss: 0.0609, g_loss: 1.2234\n",
            "Step [43570/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0191, d_svhn_loss: 0.0209, d_fake_loss: 0.0557, g_loss: 1.1825\n",
            "Step [43580/80000], d_real_loss: 0.1014, d_mnist_loss: 0.0742, d_svhn_loss: 0.0272, d_fake_loss: 0.0750, g_loss: 1.2973\n",
            "Step [43590/80000], d_real_loss: 0.0791, d_mnist_loss: 0.0534, d_svhn_loss: 0.0257, d_fake_loss: 0.0395, g_loss: 1.1418\n",
            "Step [43600/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0226, d_svhn_loss: 0.0204, d_fake_loss: 0.0773, g_loss: 1.2111\n",
            "Step [43610/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0193, d_svhn_loss: 0.0291, d_fake_loss: 0.0397, g_loss: 1.0544\n",
            "Step [43620/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0565, d_svhn_loss: 0.0255, d_fake_loss: 0.0808, g_loss: 1.1702\n",
            "Step [43630/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0199, d_svhn_loss: 0.0519, d_fake_loss: 0.0521, g_loss: 1.1949\n",
            "Step [43640/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0167, d_svhn_loss: 0.0192, d_fake_loss: 0.0431, g_loss: 1.1127\n",
            "Step [43650/80000], d_real_loss: 0.2064, d_mnist_loss: 0.0775, d_svhn_loss: 0.1288, d_fake_loss: 0.0313, g_loss: 1.1016\n",
            "Step [43660/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0215, d_svhn_loss: 0.0311, d_fake_loss: 0.0464, g_loss: 1.0962\n",
            "Step [43670/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0174, d_svhn_loss: 0.0425, d_fake_loss: 0.0710, g_loss: 1.2052\n",
            "Step [43680/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0131, d_svhn_loss: 0.0241, d_fake_loss: 0.0283, g_loss: 1.1268\n",
            "Step [43690/80000], d_real_loss: 0.1497, d_mnist_loss: 0.0285, d_svhn_loss: 0.1212, d_fake_loss: 0.0750, g_loss: 1.1666\n",
            "Step [43700/80000], d_real_loss: 0.0836, d_mnist_loss: 0.0182, d_svhn_loss: 0.0654, d_fake_loss: 0.0558, g_loss: 1.1295\n",
            "Step [43710/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0128, d_svhn_loss: 0.0317, d_fake_loss: 0.0532, g_loss: 1.1521\n",
            "Step [43720/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0131, d_svhn_loss: 0.0141, d_fake_loss: 0.0451, g_loss: 1.3141\n",
            "Step [43730/80000], d_real_loss: 0.1210, d_mnist_loss: 0.1033, d_svhn_loss: 0.0177, d_fake_loss: 0.0754, g_loss: 1.0879\n",
            "Step [43740/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0212, d_svhn_loss: 0.0293, d_fake_loss: 0.0446, g_loss: 1.2517\n",
            "Step [43750/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0243, d_svhn_loss: 0.0475, d_fake_loss: 0.0384, g_loss: 1.4262\n",
            "Step [43760/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0230, d_svhn_loss: 0.0299, d_fake_loss: 0.0296, g_loss: 1.2110\n",
            "Step [43770/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0192, d_svhn_loss: 0.0365, d_fake_loss: 0.0455, g_loss: 1.0567\n",
            "Step [43780/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0219, d_svhn_loss: 0.0384, d_fake_loss: 0.0763, g_loss: 1.1810\n",
            "Step [43790/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0150, d_svhn_loss: 0.0286, d_fake_loss: 0.0784, g_loss: 1.1193\n",
            "Step [43800/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0135, d_svhn_loss: 0.0295, d_fake_loss: 0.0649, g_loss: 1.0331\n",
            "Step [43810/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0161, d_svhn_loss: 0.0210, d_fake_loss: 0.0477, g_loss: 1.1079\n",
            "Step [43820/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0121, d_svhn_loss: 0.0698, d_fake_loss: 0.0553, g_loss: 1.0925\n",
            "Step [43830/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0158, d_svhn_loss: 0.0149, d_fake_loss: 0.0465, g_loss: 1.1169\n",
            "Step [43840/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0499, d_svhn_loss: 0.0275, d_fake_loss: 0.0985, g_loss: 1.5378\n",
            "Step [43850/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0202, d_svhn_loss: 0.0352, d_fake_loss: 0.0388, g_loss: 1.2078\n",
            "Step [43860/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0185, d_svhn_loss: 0.0225, d_fake_loss: 0.0701, g_loss: 0.8362\n",
            "Step [43870/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0466, d_svhn_loss: 0.0224, d_fake_loss: 0.0279, g_loss: 1.0089\n",
            "Step [43880/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0304, d_svhn_loss: 0.0270, d_fake_loss: 0.0595, g_loss: 1.3536\n",
            "Step [43890/80000], d_real_loss: 0.1212, d_mnist_loss: 0.0225, d_svhn_loss: 0.0986, d_fake_loss: 0.0508, g_loss: 1.0499\n",
            "Step [43900/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0175, d_svhn_loss: 0.0427, d_fake_loss: 0.0699, g_loss: 1.1626\n",
            "Step [43910/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0196, d_svhn_loss: 0.0196, d_fake_loss: 0.0726, g_loss: 0.9136\n",
            "Step [43920/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0144, d_svhn_loss: 0.0164, d_fake_loss: 0.0598, g_loss: 1.1980\n",
            "Step [43930/80000], d_real_loss: 0.0705, d_mnist_loss: 0.0245, d_svhn_loss: 0.0460, d_fake_loss: 0.0533, g_loss: 1.0612\n",
            "Step [43940/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0560, d_svhn_loss: 0.0204, d_fake_loss: 0.0677, g_loss: 1.1155\n",
            "Step [43950/80000], d_real_loss: 0.1088, d_mnist_loss: 0.0512, d_svhn_loss: 0.0576, d_fake_loss: 0.0293, g_loss: 1.0376\n",
            "Step [43960/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0145, d_svhn_loss: 0.0358, d_fake_loss: 0.0721, g_loss: 1.1413\n",
            "Step [43970/80000], d_real_loss: 0.0945, d_mnist_loss: 0.0470, d_svhn_loss: 0.0475, d_fake_loss: 0.0861, g_loss: 0.8016\n",
            "Step [43980/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0185, d_svhn_loss: 0.0646, d_fake_loss: 0.1125, g_loss: 1.2240\n",
            "Step [43990/80000], d_real_loss: 0.1309, d_mnist_loss: 0.0870, d_svhn_loss: 0.0439, d_fake_loss: 0.2114, g_loss: 1.4802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8161693811416626, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [44000/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0293, d_svhn_loss: 0.0260, d_fake_loss: 0.0842, g_loss: 1.1900\n",
            "saved ./samples_fashion/sample-44000-m-s.png\n",
            "saved ./samples_fashion/sample-44000-s-m.png\n",
            "Step [44010/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0169, d_svhn_loss: 0.0428, d_fake_loss: 0.0924, g_loss: 1.0789\n",
            "Step [44020/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0336, d_svhn_loss: 0.0238, d_fake_loss: 0.0694, g_loss: 1.3287\n",
            "Step [44030/80000], d_real_loss: 0.0769, d_mnist_loss: 0.0373, d_svhn_loss: 0.0395, d_fake_loss: 0.0533, g_loss: 1.0352\n",
            "Step [44040/80000], d_real_loss: 0.1567, d_mnist_loss: 0.0167, d_svhn_loss: 0.1400, d_fake_loss: 0.0724, g_loss: 1.0466\n",
            "Step [44050/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0217, d_svhn_loss: 0.0267, d_fake_loss: 0.0668, g_loss: 1.4518\n",
            "Step [44060/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0318, d_svhn_loss: 0.0328, d_fake_loss: 0.0635, g_loss: 1.1179\n",
            "Step [44070/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0405, d_svhn_loss: 0.0198, d_fake_loss: 0.0855, g_loss: 1.3257\n",
            "Step [44080/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0255, d_svhn_loss: 0.0278, d_fake_loss: 0.0281, g_loss: 1.1249\n",
            "Step [44090/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0200, d_svhn_loss: 0.0283, d_fake_loss: 0.0750, g_loss: 1.3315\n",
            "Step [44100/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0106, d_svhn_loss: 0.0419, d_fake_loss: 0.0416, g_loss: 1.1310\n",
            "Step [44110/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0170, d_svhn_loss: 0.0267, d_fake_loss: 0.0334, g_loss: 1.1250\n",
            "Step [44120/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0123, d_svhn_loss: 0.0207, d_fake_loss: 0.0384, g_loss: 1.3114\n",
            "Step [44130/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0221, d_svhn_loss: 0.0260, d_fake_loss: 0.0287, g_loss: 1.0208\n",
            "Step [44140/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0154, d_svhn_loss: 0.0342, d_fake_loss: 0.0358, g_loss: 1.1921\n",
            "Step [44150/80000], d_real_loss: 0.1076, d_mnist_loss: 0.0154, d_svhn_loss: 0.0922, d_fake_loss: 0.0388, g_loss: 1.3233\n",
            "Step [44160/80000], d_real_loss: 0.1279, d_mnist_loss: 0.1074, d_svhn_loss: 0.0205, d_fake_loss: 0.0822, g_loss: 1.5204\n",
            "Step [44170/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0161, d_svhn_loss: 0.0186, d_fake_loss: 0.0773, g_loss: 0.9362\n",
            "Step [44180/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0209, d_svhn_loss: 0.0208, d_fake_loss: 0.0915, g_loss: 1.1404\n",
            "Step [44190/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0188, d_svhn_loss: 0.0201, d_fake_loss: 0.0703, g_loss: 1.2155\n",
            "Step [44200/80000], d_real_loss: 0.0849, d_mnist_loss: 0.0179, d_svhn_loss: 0.0671, d_fake_loss: 0.0510, g_loss: 1.1781\n",
            "Step [44210/80000], d_real_loss: 0.0972, d_mnist_loss: 0.0140, d_svhn_loss: 0.0832, d_fake_loss: 0.0592, g_loss: 1.0939\n",
            "Step [44220/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0188, d_svhn_loss: 0.0229, d_fake_loss: 0.0336, g_loss: 1.1777\n",
            "Step [44230/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0175, d_svhn_loss: 0.0378, d_fake_loss: 0.1340, g_loss: 0.9571\n",
            "Step [44240/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0179, d_svhn_loss: 0.0415, d_fake_loss: 0.0383, g_loss: 1.1821\n",
            "Step [44250/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0194, d_svhn_loss: 0.0536, d_fake_loss: 0.0559, g_loss: 1.2243\n",
            "Step [44260/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0252, d_svhn_loss: 0.0250, d_fake_loss: 0.0343, g_loss: 1.0898\n",
            "Step [44270/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0144, d_svhn_loss: 0.0281, d_fake_loss: 0.1299, g_loss: 1.3752\n",
            "Step [44280/80000], d_real_loss: 0.1775, d_mnist_loss: 0.0138, d_svhn_loss: 0.1637, d_fake_loss: 0.0680, g_loss: 1.1575\n",
            "Step [44290/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0112, d_svhn_loss: 0.0369, d_fake_loss: 0.0440, g_loss: 1.2834\n",
            "Step [44300/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0223, d_svhn_loss: 0.0243, d_fake_loss: 0.0439, g_loss: 1.1481\n",
            "Step [44310/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0137, d_svhn_loss: 0.0182, d_fake_loss: 0.0342, g_loss: 1.2029\n",
            "Step [44320/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0188, d_svhn_loss: 0.0360, d_fake_loss: 0.0716, g_loss: 1.4399\n",
            "Step [44330/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0245, d_svhn_loss: 0.0495, d_fake_loss: 0.0626, g_loss: 1.2939\n",
            "Step [44340/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0282, d_svhn_loss: 0.0182, d_fake_loss: 0.1790, g_loss: 1.3808\n",
            "Step [44350/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0250, d_svhn_loss: 0.0364, d_fake_loss: 0.1445, g_loss: 1.3071\n",
            "Step [44360/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0200, d_svhn_loss: 0.0296, d_fake_loss: 0.0336, g_loss: 1.2908\n",
            "Step [44370/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0104, d_svhn_loss: 0.0468, d_fake_loss: 0.0307, g_loss: 1.0397\n",
            "Step [44380/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0286, d_svhn_loss: 0.0427, d_fake_loss: 0.0567, g_loss: 1.2614\n",
            "Step [44390/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0413, d_svhn_loss: 0.0423, d_fake_loss: 0.1193, g_loss: 1.1322\n",
            "Step [44400/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0178, d_svhn_loss: 0.0140, d_fake_loss: 0.0427, g_loss: 1.0478\n",
            "Step [44410/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0338, d_svhn_loss: 0.0156, d_fake_loss: 0.0807, g_loss: 1.2177\n",
            "Step [44420/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0370, d_svhn_loss: 0.0182, d_fake_loss: 0.0360, g_loss: 1.2384\n",
            "Step [44430/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0378, d_svhn_loss: 0.0394, d_fake_loss: 0.0361, g_loss: 1.2460\n",
            "Step [44440/80000], d_real_loss: 0.0735, d_mnist_loss: 0.0325, d_svhn_loss: 0.0410, d_fake_loss: 0.0482, g_loss: 0.9640\n",
            "Step [44450/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0324, d_svhn_loss: 0.0179, d_fake_loss: 0.0371, g_loss: 1.1413\n",
            "Step [44460/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0176, d_svhn_loss: 0.0434, d_fake_loss: 0.0357, g_loss: 1.2271\n",
            "Step [44470/80000], d_real_loss: 0.1023, d_mnist_loss: 0.0245, d_svhn_loss: 0.0778, d_fake_loss: 0.0836, g_loss: 1.0879\n",
            "Step [44480/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0158, d_svhn_loss: 0.0259, d_fake_loss: 0.0567, g_loss: 1.3929\n",
            "Step [44490/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0162, d_svhn_loss: 0.0419, d_fake_loss: 0.0438, g_loss: 1.1162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8806028366088867, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [44500/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0124, d_svhn_loss: 0.0304, d_fake_loss: 0.0495, g_loss: 1.1102\n",
            "saved ./samples_fashion/sample-44500-m-s.png\n",
            "saved ./samples_fashion/sample-44500-s-m.png\n",
            "Step [44510/80000], d_real_loss: 0.1252, d_mnist_loss: 0.0554, d_svhn_loss: 0.0698, d_fake_loss: 0.0535, g_loss: 1.0192\n",
            "Step [44520/80000], d_real_loss: 0.0876, d_mnist_loss: 0.0431, d_svhn_loss: 0.0445, d_fake_loss: 0.0560, g_loss: 1.0954\n",
            "Step [44530/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0124, d_svhn_loss: 0.0285, d_fake_loss: 0.1308, g_loss: 1.1776\n",
            "Step [44540/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0211, d_svhn_loss: 0.0411, d_fake_loss: 0.0826, g_loss: 1.1666\n",
            "Step [44550/80000], d_real_loss: 0.0604, d_mnist_loss: 0.0415, d_svhn_loss: 0.0189, d_fake_loss: 0.0641, g_loss: 1.2497\n",
            "Step [44560/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0150, d_svhn_loss: 0.0220, d_fake_loss: 0.0639, g_loss: 1.2409\n",
            "Step [44570/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0161, d_svhn_loss: 0.0257, d_fake_loss: 0.0309, g_loss: 1.0469\n",
            "Step [44580/80000], d_real_loss: 0.1365, d_mnist_loss: 0.0879, d_svhn_loss: 0.0486, d_fake_loss: 0.0866, g_loss: 1.2358\n",
            "Step [44590/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0173, d_svhn_loss: 0.0335, d_fake_loss: 0.0974, g_loss: 1.0397\n",
            "Step [44600/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0107, d_svhn_loss: 0.0497, d_fake_loss: 0.0699, g_loss: 1.1077\n",
            "Step [44610/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0169, d_svhn_loss: 0.0252, d_fake_loss: 0.0251, g_loss: 1.0564\n",
            "Step [44620/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0132, d_svhn_loss: 0.0274, d_fake_loss: 0.0318, g_loss: 1.2302\n",
            "Step [44630/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0160, d_svhn_loss: 0.0530, d_fake_loss: 0.0266, g_loss: 1.1714\n",
            "Step [44640/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0262, d_svhn_loss: 0.0186, d_fake_loss: 0.0283, g_loss: 1.1912\n",
            "Step [44650/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0446, d_svhn_loss: 0.0272, d_fake_loss: 0.0552, g_loss: 0.8573\n",
            "Step [44660/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0095, d_svhn_loss: 0.0298, d_fake_loss: 0.0827, g_loss: 1.1870\n",
            "Step [44670/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0123, d_svhn_loss: 0.0302, d_fake_loss: 0.0491, g_loss: 1.1040\n",
            "Step [44680/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0185, d_svhn_loss: 0.0206, d_fake_loss: 0.0678, g_loss: 1.1371\n",
            "Step [44690/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0454, d_svhn_loss: 0.0207, d_fake_loss: 0.0344, g_loss: 1.1007\n",
            "Step [44700/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0180, d_svhn_loss: 0.0217, d_fake_loss: 0.0320, g_loss: 1.2350\n",
            "Step [44710/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0608, d_svhn_loss: 0.0180, d_fake_loss: 0.0589, g_loss: 1.0692\n",
            "Step [44720/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0169, d_svhn_loss: 0.0226, d_fake_loss: 0.0250, g_loss: 1.0265\n",
            "Step [44730/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0322, d_svhn_loss: 0.0192, d_fake_loss: 0.0275, g_loss: 1.2988\n",
            "Step [44740/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0208, d_svhn_loss: 0.0293, d_fake_loss: 0.1278, g_loss: 1.3528\n",
            "Step [44750/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0363, d_svhn_loss: 0.0169, d_fake_loss: 0.0361, g_loss: 1.0387\n",
            "Step [44760/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0194, d_svhn_loss: 0.0567, d_fake_loss: 0.0501, g_loss: 1.1528\n",
            "Step [44770/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0173, d_svhn_loss: 0.0294, d_fake_loss: 0.0504, g_loss: 1.3273\n",
            "Step [44780/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0186, d_svhn_loss: 0.0255, d_fake_loss: 0.0566, g_loss: 1.1430\n",
            "Step [44790/80000], d_real_loss: 0.1467, d_mnist_loss: 0.0699, d_svhn_loss: 0.0768, d_fake_loss: 0.1663, g_loss: 0.9591\n",
            "Step [44800/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0347, d_svhn_loss: 0.0361, d_fake_loss: 0.0489, g_loss: 1.0705\n",
            "Step [44810/80000], d_real_loss: 0.0898, d_mnist_loss: 0.0160, d_svhn_loss: 0.0738, d_fake_loss: 0.0328, g_loss: 1.0771\n",
            "Step [44820/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0163, d_svhn_loss: 0.0264, d_fake_loss: 0.0410, g_loss: 1.1210\n",
            "Step [44830/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0325, d_svhn_loss: 0.0449, d_fake_loss: 0.0523, g_loss: 1.0225\n",
            "Step [44840/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0303, d_svhn_loss: 0.0237, d_fake_loss: 0.0416, g_loss: 1.1289\n",
            "Step [44850/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0246, d_svhn_loss: 0.0276, d_fake_loss: 0.0897, g_loss: 1.1500\n",
            "Step [44860/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0136, d_svhn_loss: 0.0226, d_fake_loss: 0.0515, g_loss: 1.3370\n",
            "Step [44870/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0108, d_svhn_loss: 0.0182, d_fake_loss: 0.1177, g_loss: 1.1606\n",
            "Step [44880/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0157, d_svhn_loss: 0.0451, d_fake_loss: 0.0391, g_loss: 1.2369\n",
            "Step [44890/80000], d_real_loss: 0.0932, d_mnist_loss: 0.0580, d_svhn_loss: 0.0352, d_fake_loss: 0.0988, g_loss: 1.2012\n",
            "Step [44900/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0204, d_svhn_loss: 0.0216, d_fake_loss: 0.0897, g_loss: 0.7299\n",
            "Step [44910/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0315, d_svhn_loss: 0.0203, d_fake_loss: 0.0788, g_loss: 0.9879\n",
            "Step [44920/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0426, d_svhn_loss: 0.0206, d_fake_loss: 0.0572, g_loss: 1.0109\n",
            "Step [44930/80000], d_real_loss: 0.1724, d_mnist_loss: 0.1373, d_svhn_loss: 0.0351, d_fake_loss: 0.0464, g_loss: 1.0542\n",
            "Step [44940/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0199, d_svhn_loss: 0.0586, d_fake_loss: 0.1160, g_loss: 1.1101\n",
            "Step [44950/80000], d_real_loss: 0.0855, d_mnist_loss: 0.0535, d_svhn_loss: 0.0320, d_fake_loss: 0.2389, g_loss: 1.4912\n",
            "Step [44960/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0127, d_svhn_loss: 0.0220, d_fake_loss: 0.0418, g_loss: 1.0254\n",
            "Step [44970/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0463, d_svhn_loss: 0.0274, d_fake_loss: 0.0300, g_loss: 1.0632\n",
            "Step [44980/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0176, d_svhn_loss: 0.0188, d_fake_loss: 0.0846, g_loss: 1.1517\n",
            "Step [44990/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0217, d_svhn_loss: 0.0250, d_fake_loss: 0.0234, g_loss: 1.1415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.832707941532135, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [45000/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0238, d_svhn_loss: 0.0279, d_fake_loss: 0.0865, g_loss: 1.4056\n",
            "saved ./samples_fashion/sample-45000-m-s.png\n",
            "saved ./samples_fashion/sample-45000-s-m.png\n",
            "Step [45010/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0253, d_svhn_loss: 0.0354, d_fake_loss: 0.0578, g_loss: 1.2329\n",
            "Step [45020/80000], d_real_loss: 0.1121, d_mnist_loss: 0.0155, d_svhn_loss: 0.0966, d_fake_loss: 0.0466, g_loss: 1.0952\n",
            "Step [45030/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0188, d_svhn_loss: 0.0189, d_fake_loss: 0.0305, g_loss: 1.1186\n",
            "Step [45040/80000], d_real_loss: 0.3776, d_mnist_loss: 0.0484, d_svhn_loss: 0.3292, d_fake_loss: 0.1312, g_loss: 1.2214\n",
            "Step [45050/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0314, d_svhn_loss: 0.0388, d_fake_loss: 0.0425, g_loss: 1.0657\n",
            "Step [45060/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0146, d_svhn_loss: 0.0258, d_fake_loss: 0.0480, g_loss: 1.2176\n",
            "Step [45070/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0159, d_svhn_loss: 0.0195, d_fake_loss: 0.0254, g_loss: 1.1552\n",
            "Step [45080/80000], d_real_loss: 0.0797, d_mnist_loss: 0.0570, d_svhn_loss: 0.0227, d_fake_loss: 0.0313, g_loss: 1.0866\n",
            "Step [45090/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0175, d_svhn_loss: 0.0238, d_fake_loss: 0.0472, g_loss: 1.0898\n",
            "Step [45100/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0215, d_svhn_loss: 0.0415, d_fake_loss: 0.1032, g_loss: 1.1300\n",
            "Step [45110/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0669, d_svhn_loss: 0.0231, d_fake_loss: 0.0653, g_loss: 1.0487\n",
            "Step [45120/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0114, d_svhn_loss: 0.0274, d_fake_loss: 0.0294, g_loss: 1.0818\n",
            "Step [45130/80000], d_real_loss: 0.0906, d_mnist_loss: 0.0356, d_svhn_loss: 0.0550, d_fake_loss: 0.0826, g_loss: 1.1288\n",
            "Step [45140/80000], d_real_loss: 0.0794, d_mnist_loss: 0.0174, d_svhn_loss: 0.0620, d_fake_loss: 0.0802, g_loss: 1.1278\n",
            "Step [45150/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0196, d_svhn_loss: 0.0204, d_fake_loss: 0.0637, g_loss: 1.2814\n",
            "Step [45160/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0208, d_svhn_loss: 0.0441, d_fake_loss: 0.0331, g_loss: 0.9910\n",
            "Step [45170/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0148, d_svhn_loss: 0.0212, d_fake_loss: 0.0320, g_loss: 1.1341\n",
            "Step [45180/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0253, d_svhn_loss: 0.0382, d_fake_loss: 0.0735, g_loss: 1.3957\n",
            "Step [45190/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0212, d_svhn_loss: 0.0195, d_fake_loss: 0.0359, g_loss: 1.1545\n",
            "Step [45200/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0142, d_svhn_loss: 0.0245, d_fake_loss: 0.0364, g_loss: 1.3611\n",
            "Step [45210/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0397, d_svhn_loss: 0.0447, d_fake_loss: 0.0928, g_loss: 0.7963\n",
            "Step [45220/80000], d_real_loss: 0.0871, d_mnist_loss: 0.0259, d_svhn_loss: 0.0612, d_fake_loss: 0.0474, g_loss: 0.9647\n",
            "Step [45230/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0203, d_svhn_loss: 0.0437, d_fake_loss: 0.1034, g_loss: 1.1618\n",
            "Step [45240/80000], d_real_loss: 0.1074, d_mnist_loss: 0.0595, d_svhn_loss: 0.0479, d_fake_loss: 0.0897, g_loss: 1.1705\n",
            "Step [45250/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0129, d_svhn_loss: 0.0269, d_fake_loss: 0.0415, g_loss: 1.2443\n",
            "Step [45260/80000], d_real_loss: 0.2201, d_mnist_loss: 0.1827, d_svhn_loss: 0.0374, d_fake_loss: 0.0378, g_loss: 1.2330\n",
            "Step [45270/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0223, d_svhn_loss: 0.0170, d_fake_loss: 0.0909, g_loss: 1.1714\n",
            "Step [45280/80000], d_real_loss: 0.0719, d_mnist_loss: 0.0123, d_svhn_loss: 0.0596, d_fake_loss: 0.0629, g_loss: 1.1702\n",
            "Step [45290/80000], d_real_loss: 0.0908, d_mnist_loss: 0.0531, d_svhn_loss: 0.0377, d_fake_loss: 0.0620, g_loss: 1.2779\n",
            "Step [45300/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0165, d_svhn_loss: 0.0325, d_fake_loss: 0.0380, g_loss: 1.1854\n",
            "Step [45310/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0314, d_svhn_loss: 0.0263, d_fake_loss: 0.2005, g_loss: 1.4462\n",
            "Step [45320/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0220, d_svhn_loss: 0.0177, d_fake_loss: 0.0249, g_loss: 1.2072\n",
            "Step [45330/80000], d_real_loss: 0.0839, d_mnist_loss: 0.0535, d_svhn_loss: 0.0304, d_fake_loss: 0.0669, g_loss: 1.0305\n",
            "Step [45340/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0416, d_svhn_loss: 0.0259, d_fake_loss: 0.0620, g_loss: 1.0706\n",
            "Step [45350/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0165, d_svhn_loss: 0.0303, d_fake_loss: 0.0544, g_loss: 1.0116\n",
            "Step [45360/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0339, d_svhn_loss: 0.0404, d_fake_loss: 0.0404, g_loss: 1.0305\n",
            "Step [45370/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0404, d_svhn_loss: 0.0191, d_fake_loss: 0.0516, g_loss: 1.0174\n",
            "Step [45380/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0290, d_svhn_loss: 0.0220, d_fake_loss: 0.0435, g_loss: 1.2294\n",
            "Step [45390/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0224, d_svhn_loss: 0.0187, d_fake_loss: 0.0337, g_loss: 1.2075\n",
            "Step [45400/80000], d_real_loss: 0.1100, d_mnist_loss: 0.0677, d_svhn_loss: 0.0423, d_fake_loss: 0.0721, g_loss: 1.1131\n",
            "Step [45410/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0206, d_svhn_loss: 0.0269, d_fake_loss: 0.0548, g_loss: 1.3068\n",
            "Step [45420/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0270, d_svhn_loss: 0.0368, d_fake_loss: 0.0692, g_loss: 1.2017\n",
            "Step [45430/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0138, d_svhn_loss: 0.0499, d_fake_loss: 0.0394, g_loss: 1.1168\n",
            "Step [45440/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0213, d_svhn_loss: 0.0212, d_fake_loss: 0.0717, g_loss: 1.2823\n",
            "Step [45450/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0238, d_svhn_loss: 0.0260, d_fake_loss: 0.0305, g_loss: 1.1182\n",
            "Step [45460/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0100, d_svhn_loss: 0.0237, d_fake_loss: 0.0722, g_loss: 0.9429\n",
            "Step [45470/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0130, d_svhn_loss: 0.0269, d_fake_loss: 0.0422, g_loss: 1.1929\n",
            "Step [45480/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0347, d_svhn_loss: 0.0398, d_fake_loss: 0.0558, g_loss: 1.1218\n",
            "Step [45490/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0166, d_svhn_loss: 0.0237, d_fake_loss: 0.1064, g_loss: 1.1689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8952792882919312, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [45500/80000], d_real_loss: 0.1201, d_mnist_loss: 0.0223, d_svhn_loss: 0.0978, d_fake_loss: 0.0877, g_loss: 1.1645\n",
            "saved ./samples_fashion/sample-45500-m-s.png\n",
            "saved ./samples_fashion/sample-45500-s-m.png\n",
            "Step [45510/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0094, d_svhn_loss: 0.0262, d_fake_loss: 0.1297, g_loss: 1.2244\n",
            "Step [45520/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0135, d_svhn_loss: 0.0328, d_fake_loss: 0.0393, g_loss: 1.1309\n",
            "Step [45530/80000], d_real_loss: 0.0988, d_mnist_loss: 0.0667, d_svhn_loss: 0.0321, d_fake_loss: 0.0916, g_loss: 1.1792\n",
            "Step [45540/80000], d_real_loss: 0.0817, d_mnist_loss: 0.0254, d_svhn_loss: 0.0563, d_fake_loss: 0.0333, g_loss: 1.1334\n",
            "Step [45550/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0716, d_svhn_loss: 0.0220, d_fake_loss: 0.0411, g_loss: 1.1983\n",
            "Step [45560/80000], d_real_loss: 0.0856, d_mnist_loss: 0.0314, d_svhn_loss: 0.0542, d_fake_loss: 0.0550, g_loss: 1.0082\n",
            "Step [45570/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0249, d_svhn_loss: 0.0397, d_fake_loss: 0.0689, g_loss: 1.2933\n",
            "Step [45580/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0259, d_svhn_loss: 0.0349, d_fake_loss: 0.0412, g_loss: 1.1721\n",
            "Step [45590/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0240, d_svhn_loss: 0.0354, d_fake_loss: 0.0705, g_loss: 0.8140\n",
            "Step [45600/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0180, d_svhn_loss: 0.0289, d_fake_loss: 0.1657, g_loss: 1.1100\n",
            "Step [45610/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0279, d_svhn_loss: 0.0398, d_fake_loss: 0.0418, g_loss: 1.1165\n",
            "Step [45620/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0255, d_svhn_loss: 0.0232, d_fake_loss: 0.0623, g_loss: 1.1402\n",
            "Step [45630/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0229, d_svhn_loss: 0.0184, d_fake_loss: 0.0478, g_loss: 1.1449\n",
            "Step [45640/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0223, d_svhn_loss: 0.0224, d_fake_loss: 0.0406, g_loss: 1.1292\n",
            "Step [45650/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0170, d_svhn_loss: 0.0237, d_fake_loss: 0.0387, g_loss: 1.1291\n",
            "Step [45660/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0293, d_svhn_loss: 0.0232, d_fake_loss: 0.0633, g_loss: 1.2064\n",
            "Step [45670/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0244, d_svhn_loss: 0.0350, d_fake_loss: 0.0377, g_loss: 1.1361\n",
            "Step [45680/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0329, d_svhn_loss: 0.0204, d_fake_loss: 0.0710, g_loss: 1.1151\n",
            "Step [45690/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0204, d_svhn_loss: 0.0151, d_fake_loss: 0.0674, g_loss: 1.0285\n",
            "Step [45700/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0189, d_svhn_loss: 0.0172, d_fake_loss: 0.0532, g_loss: 1.0378\n",
            "Step [45710/80000], d_real_loss: 0.0822, d_mnist_loss: 0.0371, d_svhn_loss: 0.0451, d_fake_loss: 0.0302, g_loss: 1.0033\n",
            "Step [45720/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0258, d_svhn_loss: 0.0293, d_fake_loss: 0.0487, g_loss: 1.2054\n",
            "Step [45730/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0193, d_svhn_loss: 0.0135, d_fake_loss: 0.0422, g_loss: 1.1033\n",
            "Step [45740/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0216, d_svhn_loss: 0.0343, d_fake_loss: 0.0927, g_loss: 1.3467\n",
            "Step [45750/80000], d_real_loss: 0.1162, d_mnist_loss: 0.0713, d_svhn_loss: 0.0449, d_fake_loss: 0.2640, g_loss: 1.4294\n",
            "Step [45760/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0190, d_svhn_loss: 0.0338, d_fake_loss: 0.0517, g_loss: 1.2434\n",
            "Step [45770/80000], d_real_loss: 0.1062, d_mnist_loss: 0.0848, d_svhn_loss: 0.0214, d_fake_loss: 0.1005, g_loss: 1.1734\n",
            "Step [45780/80000], d_real_loss: 0.1091, d_mnist_loss: 0.0223, d_svhn_loss: 0.0868, d_fake_loss: 0.2303, g_loss: 1.0649\n",
            "Step [45790/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0210, d_svhn_loss: 0.0530, d_fake_loss: 0.0781, g_loss: 1.2536\n",
            "Step [45800/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0145, d_svhn_loss: 0.0353, d_fake_loss: 0.0788, g_loss: 1.3583\n",
            "Step [45810/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0189, d_svhn_loss: 0.0412, d_fake_loss: 0.0753, g_loss: 1.2594\n",
            "Step [45820/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0138, d_svhn_loss: 0.0416, d_fake_loss: 0.0344, g_loss: 1.0336\n",
            "Step [45830/80000], d_real_loss: 0.0753, d_mnist_loss: 0.0173, d_svhn_loss: 0.0580, d_fake_loss: 0.0363, g_loss: 1.1535\n",
            "Step [45840/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0143, d_svhn_loss: 0.0212, d_fake_loss: 0.1757, g_loss: 1.3409\n",
            "Step [45850/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0327, d_svhn_loss: 0.0239, d_fake_loss: 0.0934, g_loss: 1.1208\n",
            "Step [45860/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0183, d_svhn_loss: 0.0224, d_fake_loss: 0.0550, g_loss: 1.2835\n",
            "Step [45870/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0236, d_svhn_loss: 0.0203, d_fake_loss: 0.1715, g_loss: 1.6543\n",
            "Step [45880/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0341, d_svhn_loss: 0.0354, d_fake_loss: 0.2008, g_loss: 1.5126\n",
            "Step [45890/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0398, d_svhn_loss: 0.0316, d_fake_loss: 0.1086, g_loss: 1.2839\n",
            "Step [45900/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0272, d_svhn_loss: 0.0249, d_fake_loss: 0.0309, g_loss: 1.1182\n",
            "Step [45910/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0259, d_svhn_loss: 0.0210, d_fake_loss: 0.0308, g_loss: 1.0680\n",
            "Step [45920/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0221, d_svhn_loss: 0.0324, d_fake_loss: 0.0549, g_loss: 1.2116\n",
            "Step [45930/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0223, d_svhn_loss: 0.0321, d_fake_loss: 0.0308, g_loss: 1.2012\n",
            "Step [45940/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0179, d_svhn_loss: 0.0165, d_fake_loss: 0.0480, g_loss: 1.1371\n",
            "Step [45950/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0267, d_svhn_loss: 0.0332, d_fake_loss: 0.0522, g_loss: 1.2956\n",
            "Step [45960/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0198, d_svhn_loss: 0.0633, d_fake_loss: 0.0620, g_loss: 1.0910\n",
            "Step [45970/80000], d_real_loss: 0.0896, d_mnist_loss: 0.0730, d_svhn_loss: 0.0166, d_fake_loss: 0.1622, g_loss: 1.0908\n",
            "Step [45980/80000], d_real_loss: 0.0825, d_mnist_loss: 0.0606, d_svhn_loss: 0.0219, d_fake_loss: 0.1726, g_loss: 1.4059\n",
            "Step [45990/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0170, d_svhn_loss: 0.0262, d_fake_loss: 0.0380, g_loss: 1.2163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8113721013069153, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [46000/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0178, d_svhn_loss: 0.0284, d_fake_loss: 0.0637, g_loss: 1.0211\n",
            "saved ./samples_fashion/sample-46000-m-s.png\n",
            "saved ./samples_fashion/sample-46000-s-m.png\n",
            "Step [46010/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0214, d_svhn_loss: 0.0547, d_fake_loss: 0.0337, g_loss: 1.1211\n",
            "Step [46020/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0100, d_svhn_loss: 0.0385, d_fake_loss: 0.0490, g_loss: 1.2549\n",
            "Step [46030/80000], d_real_loss: 0.1729, d_mnist_loss: 0.0215, d_svhn_loss: 0.1514, d_fake_loss: 0.1207, g_loss: 1.0349\n",
            "Step [46040/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0406, d_svhn_loss: 0.0224, d_fake_loss: 0.0387, g_loss: 1.2796\n",
            "Step [46050/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0168, d_svhn_loss: 0.0446, d_fake_loss: 0.0544, g_loss: 1.3177\n",
            "Step [46060/80000], d_real_loss: 0.0803, d_mnist_loss: 0.0326, d_svhn_loss: 0.0477, d_fake_loss: 0.0324, g_loss: 1.2155\n",
            "Step [46070/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0143, d_svhn_loss: 0.0469, d_fake_loss: 0.0391, g_loss: 1.1353\n",
            "Step [46080/80000], d_real_loss: 0.1076, d_mnist_loss: 0.0166, d_svhn_loss: 0.0910, d_fake_loss: 0.0931, g_loss: 1.1787\n",
            "Step [46090/80000], d_real_loss: 0.1650, d_mnist_loss: 0.0299, d_svhn_loss: 0.1351, d_fake_loss: 0.1137, g_loss: 1.0913\n",
            "Step [46100/80000], d_real_loss: 0.1267, d_mnist_loss: 0.0266, d_svhn_loss: 0.1001, d_fake_loss: 0.0716, g_loss: 1.3319\n",
            "Step [46110/80000], d_real_loss: 0.1859, d_mnist_loss: 0.0242, d_svhn_loss: 0.1617, d_fake_loss: 0.1820, g_loss: 1.1307\n",
            "Step [46120/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0169, d_svhn_loss: 0.0212, d_fake_loss: 0.0297, g_loss: 1.1890\n",
            "Step [46130/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0184, d_svhn_loss: 0.0342, d_fake_loss: 0.0557, g_loss: 1.2636\n",
            "Step [46140/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0430, d_svhn_loss: 0.0191, d_fake_loss: 0.0575, g_loss: 1.1751\n",
            "Step [46150/80000], d_real_loss: 0.1120, d_mnist_loss: 0.0803, d_svhn_loss: 0.0317, d_fake_loss: 0.0242, g_loss: 0.9657\n",
            "Step [46160/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0193, d_svhn_loss: 0.0571, d_fake_loss: 0.0778, g_loss: 1.4395\n",
            "Step [46170/80000], d_real_loss: 0.0975, d_mnist_loss: 0.0210, d_svhn_loss: 0.0765, d_fake_loss: 0.1248, g_loss: 1.1680\n",
            "Step [46180/80000], d_real_loss: 0.0898, d_mnist_loss: 0.0299, d_svhn_loss: 0.0598, d_fake_loss: 0.0670, g_loss: 1.0805\n",
            "Step [46190/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0135, d_svhn_loss: 0.0258, d_fake_loss: 0.0777, g_loss: 1.5752\n",
            "Step [46200/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0176, d_svhn_loss: 0.0243, d_fake_loss: 0.0560, g_loss: 1.1613\n",
            "Step [46210/80000], d_real_loss: 0.0966, d_mnist_loss: 0.0312, d_svhn_loss: 0.0654, d_fake_loss: 0.0312, g_loss: 1.2793\n",
            "Step [46220/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0158, d_svhn_loss: 0.0182, d_fake_loss: 0.0798, g_loss: 1.2087\n",
            "Step [46230/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0369, d_svhn_loss: 0.0267, d_fake_loss: 0.0521, g_loss: 1.3258\n",
            "Step [46240/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0300, d_svhn_loss: 0.0297, d_fake_loss: 0.0562, g_loss: 1.0123\n",
            "Step [46250/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0166, d_svhn_loss: 0.0448, d_fake_loss: 0.0251, g_loss: 1.1353\n",
            "Step [46260/80000], d_real_loss: 0.0826, d_mnist_loss: 0.0570, d_svhn_loss: 0.0256, d_fake_loss: 0.0873, g_loss: 1.1323\n",
            "Step [46270/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0419, d_svhn_loss: 0.0223, d_fake_loss: 0.0266, g_loss: 1.1483\n",
            "Step [46280/80000], d_real_loss: 0.0982, d_mnist_loss: 0.0548, d_svhn_loss: 0.0434, d_fake_loss: 0.0475, g_loss: 1.0516\n",
            "Step [46290/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0329, d_svhn_loss: 0.0266, d_fake_loss: 0.1422, g_loss: 1.3790\n",
            "Step [46300/80000], d_real_loss: 0.1151, d_mnist_loss: 0.0966, d_svhn_loss: 0.0185, d_fake_loss: 0.0712, g_loss: 1.4309\n",
            "Step [46310/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0215, d_svhn_loss: 0.0263, d_fake_loss: 0.0440, g_loss: 1.1119\n",
            "Step [46320/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0211, d_svhn_loss: 0.0216, d_fake_loss: 0.0973, g_loss: 1.0911\n",
            "Step [46330/80000], d_real_loss: 0.0958, d_mnist_loss: 0.0467, d_svhn_loss: 0.0490, d_fake_loss: 0.0273, g_loss: 0.9986\n",
            "Step [46340/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0116, d_svhn_loss: 0.0263, d_fake_loss: 0.0289, g_loss: 1.2026\n",
            "Step [46350/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0146, d_svhn_loss: 0.0356, d_fake_loss: 0.1435, g_loss: 1.4040\n",
            "Step [46360/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0167, d_svhn_loss: 0.0390, d_fake_loss: 0.1305, g_loss: 1.1070\n",
            "Step [46370/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0308, d_svhn_loss: 0.0608, d_fake_loss: 0.0816, g_loss: 1.2029\n",
            "Step [46380/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0161, d_svhn_loss: 0.0239, d_fake_loss: 0.0300, g_loss: 1.1756\n",
            "Step [46390/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0107, d_svhn_loss: 0.0708, d_fake_loss: 0.0480, g_loss: 1.2498\n",
            "Step [46400/80000], d_real_loss: 0.1052, d_mnist_loss: 0.0148, d_svhn_loss: 0.0905, d_fake_loss: 0.1429, g_loss: 1.2690\n",
            "Step [46410/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0206, d_svhn_loss: 0.0245, d_fake_loss: 0.0238, g_loss: 1.1320\n",
            "Step [46420/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0200, d_svhn_loss: 0.0257, d_fake_loss: 0.0696, g_loss: 1.1496\n",
            "Step [46430/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0179, d_svhn_loss: 0.0209, d_fake_loss: 0.1142, g_loss: 1.3253\n",
            "Step [46440/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0265, d_svhn_loss: 0.0320, d_fake_loss: 0.0397, g_loss: 1.0333\n",
            "Step [46450/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0383, d_svhn_loss: 0.0257, d_fake_loss: 0.0347, g_loss: 1.3150\n",
            "Step [46460/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0140, d_svhn_loss: 0.0251, d_fake_loss: 0.0854, g_loss: 0.9053\n",
            "Step [46470/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0214, d_svhn_loss: 0.0184, d_fake_loss: 0.0373, g_loss: 1.1322\n",
            "Step [46480/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0187, d_svhn_loss: 0.0218, d_fake_loss: 0.0397, g_loss: 1.1783\n",
            "Step [46490/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0208, d_svhn_loss: 0.0218, d_fake_loss: 0.0341, g_loss: 1.0379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8415880799293518, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [46500/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0390, d_svhn_loss: 0.0201, d_fake_loss: 0.0686, g_loss: 1.1548\n",
            "saved ./samples_fashion/sample-46500-m-s.png\n",
            "saved ./samples_fashion/sample-46500-s-m.png\n",
            "Step [46510/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0211, d_svhn_loss: 0.0605, d_fake_loss: 0.0363, g_loss: 1.0674\n",
            "Step [46520/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0251, d_svhn_loss: 0.0289, d_fake_loss: 0.0515, g_loss: 1.0575\n",
            "Step [46530/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0245, d_svhn_loss: 0.0221, d_fake_loss: 0.0399, g_loss: 1.0204\n",
            "Step [46540/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0383, d_svhn_loss: 0.0191, d_fake_loss: 0.0265, g_loss: 1.1486\n",
            "Step [46550/80000], d_real_loss: 0.0746, d_mnist_loss: 0.0205, d_svhn_loss: 0.0540, d_fake_loss: 0.1284, g_loss: 1.2102\n",
            "Step [46560/80000], d_real_loss: 0.1110, d_mnist_loss: 0.0574, d_svhn_loss: 0.0537, d_fake_loss: 0.1048, g_loss: 1.5860\n",
            "Step [46570/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0174, d_svhn_loss: 0.0397, d_fake_loss: 0.0638, g_loss: 1.0726\n",
            "Step [46580/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0130, d_svhn_loss: 0.0364, d_fake_loss: 0.0273, g_loss: 1.3229\n",
            "Step [46590/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0134, d_svhn_loss: 0.0303, d_fake_loss: 0.0508, g_loss: 1.2558\n",
            "Step [46600/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0256, d_svhn_loss: 0.0445, d_fake_loss: 0.0444, g_loss: 1.1105\n",
            "Step [46610/80000], d_real_loss: 0.0849, d_mnist_loss: 0.0518, d_svhn_loss: 0.0331, d_fake_loss: 0.0434, g_loss: 1.1989\n",
            "Step [46620/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0197, d_svhn_loss: 0.0555, d_fake_loss: 0.0930, g_loss: 1.2743\n",
            "Step [46630/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0250, d_svhn_loss: 0.0339, d_fake_loss: 0.0433, g_loss: 1.0045\n",
            "Step [46640/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0370, d_svhn_loss: 0.0319, d_fake_loss: 0.0346, g_loss: 1.0335\n",
            "Step [46650/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0198, d_svhn_loss: 0.0238, d_fake_loss: 0.0382, g_loss: 1.1502\n",
            "Step [46660/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0163, d_svhn_loss: 0.0196, d_fake_loss: 0.0353, g_loss: 1.1325\n",
            "Step [46670/80000], d_real_loss: 0.0715, d_mnist_loss: 0.0344, d_svhn_loss: 0.0371, d_fake_loss: 0.1015, g_loss: 1.2045\n",
            "Step [46680/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0118, d_svhn_loss: 0.0448, d_fake_loss: 0.0429, g_loss: 0.9422\n",
            "Step [46690/80000], d_real_loss: 0.1365, d_mnist_loss: 0.1015, d_svhn_loss: 0.0349, d_fake_loss: 0.0997, g_loss: 1.0195\n",
            "Step [46700/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0189, d_svhn_loss: 0.0179, d_fake_loss: 0.0390, g_loss: 1.1671\n",
            "Step [46710/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0129, d_svhn_loss: 0.0285, d_fake_loss: 0.0305, g_loss: 1.1544\n",
            "Step [46720/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0299, d_svhn_loss: 0.0158, d_fake_loss: 0.0287, g_loss: 1.0968\n",
            "Step [46730/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0143, d_svhn_loss: 0.0557, d_fake_loss: 0.0410, g_loss: 1.1749\n",
            "Step [46740/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0181, d_svhn_loss: 0.0458, d_fake_loss: 0.0643, g_loss: 1.1193\n",
            "Step [46750/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0088, d_svhn_loss: 0.0227, d_fake_loss: 0.0521, g_loss: 0.9876\n",
            "Step [46760/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0159, d_svhn_loss: 0.0189, d_fake_loss: 0.0366, g_loss: 1.1288\n",
            "Step [46770/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0199, d_svhn_loss: 0.0206, d_fake_loss: 0.0487, g_loss: 1.1862\n",
            "Step [46780/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0355, d_svhn_loss: 0.0302, d_fake_loss: 0.0867, g_loss: 1.0499\n",
            "Step [46790/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0233, d_svhn_loss: 0.0302, d_fake_loss: 0.0633, g_loss: 1.2230\n",
            "Step [46800/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0242, d_svhn_loss: 0.0156, d_fake_loss: 0.0335, g_loss: 1.0357\n",
            "Step [46810/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0699, d_svhn_loss: 0.0206, d_fake_loss: 0.0911, g_loss: 1.1635\n",
            "Step [46820/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0280, d_svhn_loss: 0.0183, d_fake_loss: 0.0404, g_loss: 1.0538\n",
            "Step [46830/80000], d_real_loss: 0.0709, d_mnist_loss: 0.0224, d_svhn_loss: 0.0485, d_fake_loss: 0.1068, g_loss: 1.0302\n",
            "Step [46840/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0222, d_svhn_loss: 0.0258, d_fake_loss: 0.0656, g_loss: 1.1902\n",
            "Step [46850/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0113, d_svhn_loss: 0.0260, d_fake_loss: 0.0659, g_loss: 1.0045\n",
            "Step [46860/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0302, d_svhn_loss: 0.0214, d_fake_loss: 0.0297, g_loss: 1.1106\n",
            "Step [46870/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0260, d_svhn_loss: 0.0417, d_fake_loss: 0.0481, g_loss: 1.1575\n",
            "Step [46880/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0174, d_svhn_loss: 0.0263, d_fake_loss: 0.0598, g_loss: 1.1687\n",
            "Step [46890/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0125, d_svhn_loss: 0.0396, d_fake_loss: 0.1605, g_loss: 1.3087\n",
            "Step [46900/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0282, d_svhn_loss: 0.0190, d_fake_loss: 0.0784, g_loss: 1.1653\n",
            "Step [46910/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0455, d_svhn_loss: 0.0252, d_fake_loss: 0.0331, g_loss: 1.0744\n",
            "Step [46920/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0163, d_svhn_loss: 0.0231, d_fake_loss: 0.1484, g_loss: 1.0932\n",
            "Step [46930/80000], d_real_loss: 0.1386, d_mnist_loss: 0.0991, d_svhn_loss: 0.0395, d_fake_loss: 0.1131, g_loss: 1.1304\n",
            "Step [46940/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0262, d_svhn_loss: 0.0198, d_fake_loss: 0.0333, g_loss: 1.1391\n",
            "Step [46950/80000], d_real_loss: 0.0986, d_mnist_loss: 0.0211, d_svhn_loss: 0.0774, d_fake_loss: 0.0436, g_loss: 1.1529\n",
            "Step [46960/80000], d_real_loss: 0.0835, d_mnist_loss: 0.0302, d_svhn_loss: 0.0533, d_fake_loss: 0.0519, g_loss: 1.2268\n",
            "Step [46970/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0185, d_svhn_loss: 0.0260, d_fake_loss: 0.0603, g_loss: 1.1942\n",
            "Step [46980/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0134, d_svhn_loss: 0.0455, d_fake_loss: 0.1071, g_loss: 1.1277\n",
            "Step [46990/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0192, d_svhn_loss: 0.0686, d_fake_loss: 0.0485, g_loss: 1.0556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7907276749610901, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [47000/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0330, d_svhn_loss: 0.0386, d_fake_loss: 0.0595, g_loss: 1.3025\n",
            "saved ./samples_fashion/sample-47000-m-s.png\n",
            "saved ./samples_fashion/sample-47000-s-m.png\n",
            "Step [47010/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0134, d_svhn_loss: 0.0557, d_fake_loss: 0.1061, g_loss: 1.2632\n",
            "Step [47020/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0147, d_svhn_loss: 0.0631, d_fake_loss: 0.0372, g_loss: 1.1585\n",
            "Step [47030/80000], d_real_loss: 0.0872, d_mnist_loss: 0.0335, d_svhn_loss: 0.0538, d_fake_loss: 0.1476, g_loss: 1.1419\n",
            "Step [47040/80000], d_real_loss: 0.0755, d_mnist_loss: 0.0157, d_svhn_loss: 0.0598, d_fake_loss: 0.0544, g_loss: 1.0605\n",
            "Step [47050/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0234, d_svhn_loss: 0.0265, d_fake_loss: 0.0273, g_loss: 1.1873\n",
            "Step [47060/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0172, d_svhn_loss: 0.0392, d_fake_loss: 0.0451, g_loss: 1.3204\n",
            "Step [47070/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0261, d_svhn_loss: 0.0259, d_fake_loss: 0.0295, g_loss: 1.1262\n",
            "Step [47080/80000], d_real_loss: 0.1387, d_mnist_loss: 0.1079, d_svhn_loss: 0.0307, d_fake_loss: 0.0724, g_loss: 1.1607\n",
            "Step [47090/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0235, d_svhn_loss: 0.0281, d_fake_loss: 0.0273, g_loss: 1.0605\n",
            "Step [47100/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0265, d_svhn_loss: 0.0337, d_fake_loss: 0.1260, g_loss: 1.1798\n",
            "Step [47110/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0238, d_svhn_loss: 0.0253, d_fake_loss: 0.0533, g_loss: 1.1444\n",
            "Step [47120/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0264, d_svhn_loss: 0.0378, d_fake_loss: 0.0375, g_loss: 1.1029\n",
            "Step [47130/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0119, d_svhn_loss: 0.0356, d_fake_loss: 0.0474, g_loss: 1.2107\n",
            "Step [47140/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0251, d_svhn_loss: 0.0219, d_fake_loss: 0.0952, g_loss: 1.3341\n",
            "Step [47150/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0174, d_svhn_loss: 0.0457, d_fake_loss: 0.0835, g_loss: 1.0989\n",
            "Step [47160/80000], d_real_loss: 0.0897, d_mnist_loss: 0.0271, d_svhn_loss: 0.0626, d_fake_loss: 0.0548, g_loss: 1.1803\n",
            "Step [47170/80000], d_real_loss: 0.1201, d_mnist_loss: 0.0548, d_svhn_loss: 0.0653, d_fake_loss: 0.0824, g_loss: 1.4973\n",
            "Step [47180/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0239, d_svhn_loss: 0.0165, d_fake_loss: 0.0490, g_loss: 1.0186\n",
            "Step [47190/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0124, d_svhn_loss: 0.0264, d_fake_loss: 0.0706, g_loss: 1.1877\n",
            "Step [47200/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0330, d_svhn_loss: 0.0337, d_fake_loss: 0.0800, g_loss: 1.0859\n",
            "Step [47210/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0385, d_svhn_loss: 0.0400, d_fake_loss: 0.0279, g_loss: 1.0817\n",
            "Step [47220/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0374, d_svhn_loss: 0.0164, d_fake_loss: 0.0460, g_loss: 1.1503\n",
            "Step [47230/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0204, d_svhn_loss: 0.0175, d_fake_loss: 0.0404, g_loss: 1.3183\n",
            "Step [47240/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0134, d_svhn_loss: 0.0173, d_fake_loss: 0.0630, g_loss: 1.2845\n",
            "Step [47250/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0284, d_svhn_loss: 0.0367, d_fake_loss: 0.0423, g_loss: 1.0220\n",
            "Step [47260/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0397, d_svhn_loss: 0.0240, d_fake_loss: 0.0655, g_loss: 1.0254\n",
            "Step [47270/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0169, d_svhn_loss: 0.0385, d_fake_loss: 0.0506, g_loss: 1.0323\n",
            "Step [47280/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0234, d_svhn_loss: 0.0308, d_fake_loss: 0.0490, g_loss: 1.1459\n",
            "Step [47290/80000], d_real_loss: 0.0896, d_mnist_loss: 0.0201, d_svhn_loss: 0.0695, d_fake_loss: 0.0514, g_loss: 1.2726\n",
            "Step [47300/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0254, d_svhn_loss: 0.0298, d_fake_loss: 0.0336, g_loss: 1.1228\n",
            "Step [47310/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0364, d_svhn_loss: 0.0151, d_fake_loss: 0.0591, g_loss: 1.1817\n",
            "Step [47320/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0489, d_svhn_loss: 0.0299, d_fake_loss: 0.0461, g_loss: 1.1994\n",
            "Step [47330/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0266, d_svhn_loss: 0.0198, d_fake_loss: 0.0460, g_loss: 0.9559\n",
            "Step [47340/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0198, d_svhn_loss: 0.0198, d_fake_loss: 0.0341, g_loss: 1.0635\n",
            "Step [47350/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0266, d_svhn_loss: 0.0130, d_fake_loss: 0.0491, g_loss: 1.1667\n",
            "Step [47360/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0154, d_svhn_loss: 0.0159, d_fake_loss: 0.0742, g_loss: 1.2771\n",
            "Step [47370/80000], d_real_loss: 0.1039, d_mnist_loss: 0.0545, d_svhn_loss: 0.0494, d_fake_loss: 0.1169, g_loss: 1.1322\n",
            "Step [47380/80000], d_real_loss: 0.0254, d_mnist_loss: 0.0148, d_svhn_loss: 0.0106, d_fake_loss: 0.0436, g_loss: 1.0893\n",
            "Step [47390/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0154, d_svhn_loss: 0.0588, d_fake_loss: 0.1129, g_loss: 1.4007\n",
            "Step [47400/80000], d_real_loss: 0.1039, d_mnist_loss: 0.0250, d_svhn_loss: 0.0789, d_fake_loss: 0.0679, g_loss: 1.1777\n",
            "Step [47410/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0163, d_svhn_loss: 0.0507, d_fake_loss: 0.1069, g_loss: 1.3697\n",
            "Step [47420/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0187, d_svhn_loss: 0.0224, d_fake_loss: 0.0268, g_loss: 1.0451\n",
            "Step [47430/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0270, d_svhn_loss: 0.0234, d_fake_loss: 0.0671, g_loss: 1.0836\n",
            "Step [47440/80000], d_real_loss: 0.1193, d_mnist_loss: 0.0207, d_svhn_loss: 0.0987, d_fake_loss: 0.0842, g_loss: 1.2296\n",
            "Step [47450/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0129, d_svhn_loss: 0.0263, d_fake_loss: 0.0726, g_loss: 1.2595\n",
            "Step [47460/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0422, d_svhn_loss: 0.0214, d_fake_loss: 0.0435, g_loss: 1.2868\n",
            "Step [47470/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0140, d_svhn_loss: 0.0193, d_fake_loss: 0.0309, g_loss: 1.1084\n",
            "Step [47480/80000], d_real_loss: 0.0923, d_mnist_loss: 0.0338, d_svhn_loss: 0.0585, d_fake_loss: 0.0749, g_loss: 1.1405\n",
            "Step [47490/80000], d_real_loss: 0.1455, d_mnist_loss: 0.0988, d_svhn_loss: 0.0466, d_fake_loss: 0.0694, g_loss: 1.2478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8516091704368591, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [47500/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0384, d_svhn_loss: 0.0212, d_fake_loss: 0.0539, g_loss: 1.1477\n",
            "saved ./samples_fashion/sample-47500-m-s.png\n",
            "saved ./samples_fashion/sample-47500-s-m.png\n",
            "Step [47510/80000], d_real_loss: 0.1676, d_mnist_loss: 0.1390, d_svhn_loss: 0.0285, d_fake_loss: 0.0666, g_loss: 1.0822\n",
            "Step [47520/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0198, d_svhn_loss: 0.0388, d_fake_loss: 0.0894, g_loss: 1.3957\n",
            "Step [47530/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0175, d_svhn_loss: 0.0239, d_fake_loss: 0.0982, g_loss: 1.0764\n",
            "Step [47540/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0501, d_svhn_loss: 0.0228, d_fake_loss: 0.0743, g_loss: 1.1309\n",
            "Step [47550/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0252, d_svhn_loss: 0.0212, d_fake_loss: 0.0818, g_loss: 1.2864\n",
            "Step [47560/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0195, d_svhn_loss: 0.0359, d_fake_loss: 0.0547, g_loss: 0.9994\n",
            "Step [47570/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0148, d_svhn_loss: 0.0435, d_fake_loss: 0.0527, g_loss: 1.0892\n",
            "Step [47580/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0346, d_svhn_loss: 0.0259, d_fake_loss: 0.0716, g_loss: 1.1936\n",
            "Step [47590/80000], d_real_loss: 0.0789, d_mnist_loss: 0.0413, d_svhn_loss: 0.0376, d_fake_loss: 0.0378, g_loss: 1.0289\n",
            "Step [47600/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0262, d_svhn_loss: 0.0221, d_fake_loss: 0.0408, g_loss: 1.1715\n",
            "Step [47610/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0286, d_svhn_loss: 0.0255, d_fake_loss: 0.0772, g_loss: 1.4486\n",
            "Step [47620/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0184, d_svhn_loss: 0.0191, d_fake_loss: 0.0580, g_loss: 1.1363\n",
            "Step [47630/80000], d_real_loss: 0.1002, d_mnist_loss: 0.0367, d_svhn_loss: 0.0635, d_fake_loss: 0.0499, g_loss: 1.1293\n",
            "Step [47640/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0178, d_svhn_loss: 0.0197, d_fake_loss: 0.0565, g_loss: 1.0928\n",
            "Step [47650/80000], d_real_loss: 0.1099, d_mnist_loss: 0.0194, d_svhn_loss: 0.0905, d_fake_loss: 0.0277, g_loss: 1.1849\n",
            "Step [47660/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0143, d_svhn_loss: 0.0174, d_fake_loss: 0.0398, g_loss: 1.1440\n",
            "Step [47670/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0323, d_svhn_loss: 0.0205, d_fake_loss: 0.0392, g_loss: 1.3251\n",
            "Step [47680/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0167, d_svhn_loss: 0.0296, d_fake_loss: 0.0619, g_loss: 1.3303\n",
            "Step [47690/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0550, d_svhn_loss: 0.0234, d_fake_loss: 0.0606, g_loss: 1.1809\n",
            "Step [47700/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0408, d_svhn_loss: 0.0308, d_fake_loss: 0.0541, g_loss: 1.1381\n",
            "Step [47710/80000], d_real_loss: 0.0809, d_mnist_loss: 0.0529, d_svhn_loss: 0.0281, d_fake_loss: 0.0522, g_loss: 1.1005\n",
            "Step [47720/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0330, d_svhn_loss: 0.0298, d_fake_loss: 0.0771, g_loss: 1.2694\n",
            "Step [47730/80000], d_real_loss: 0.0835, d_mnist_loss: 0.0232, d_svhn_loss: 0.0603, d_fake_loss: 0.0699, g_loss: 1.2043\n",
            "Step [47740/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0195, d_svhn_loss: 0.0268, d_fake_loss: 0.0494, g_loss: 1.2416\n",
            "Step [47750/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0197, d_svhn_loss: 0.0209, d_fake_loss: 0.0632, g_loss: 1.1751\n",
            "Step [47760/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0626, d_svhn_loss: 0.0164, d_fake_loss: 0.0467, g_loss: 1.1852\n",
            "Step [47770/80000], d_real_loss: 0.1412, d_mnist_loss: 0.0445, d_svhn_loss: 0.0967, d_fake_loss: 0.0633, g_loss: 1.0789\n",
            "Step [47780/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0304, d_svhn_loss: 0.0284, d_fake_loss: 0.0346, g_loss: 1.3692\n",
            "Step [47790/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0271, d_svhn_loss: 0.0233, d_fake_loss: 0.0474, g_loss: 1.2696\n",
            "Step [47800/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0271, d_svhn_loss: 0.0246, d_fake_loss: 0.0452, g_loss: 1.1344\n",
            "Step [47810/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0181, d_svhn_loss: 0.0522, d_fake_loss: 0.0672, g_loss: 1.2864\n",
            "Step [47820/80000], d_real_loss: 0.1424, d_mnist_loss: 0.0667, d_svhn_loss: 0.0757, d_fake_loss: 0.1322, g_loss: 1.1377\n",
            "Step [47830/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0165, d_svhn_loss: 0.0237, d_fake_loss: 0.0406, g_loss: 1.1855\n",
            "Step [47840/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0518, d_svhn_loss: 0.0195, d_fake_loss: 0.0690, g_loss: 1.7693\n",
            "Step [47850/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0192, d_svhn_loss: 0.0230, d_fake_loss: 0.1792, g_loss: 1.1242\n",
            "Step [47860/80000], d_real_loss: 0.0705, d_mnist_loss: 0.0282, d_svhn_loss: 0.0423, d_fake_loss: 0.0422, g_loss: 1.3604\n",
            "Step [47870/80000], d_real_loss: 0.1164, d_mnist_loss: 0.0887, d_svhn_loss: 0.0277, d_fake_loss: 0.0445, g_loss: 1.2874\n",
            "Step [47880/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0182, d_svhn_loss: 0.0172, d_fake_loss: 0.0620, g_loss: 1.1861\n",
            "Step [47890/80000], d_real_loss: 0.0896, d_mnist_loss: 0.0660, d_svhn_loss: 0.0236, d_fake_loss: 0.0564, g_loss: 1.1340\n",
            "Step [47900/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0135, d_svhn_loss: 0.0254, d_fake_loss: 0.0842, g_loss: 1.2818\n",
            "Step [47910/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0141, d_svhn_loss: 0.0268, d_fake_loss: 0.1216, g_loss: 1.4185\n",
            "Step [47920/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0198, d_svhn_loss: 0.0522, d_fake_loss: 0.0454, g_loss: 1.1712\n",
            "Step [47930/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0574, d_svhn_loss: 0.0228, d_fake_loss: 0.1042, g_loss: 0.9654\n",
            "Step [47940/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0216, d_svhn_loss: 0.0218, d_fake_loss: 0.0792, g_loss: 1.3375\n",
            "Step [47950/80000], d_real_loss: 0.1611, d_mnist_loss: 0.1173, d_svhn_loss: 0.0438, d_fake_loss: 0.0408, g_loss: 1.1464\n",
            "Step [47960/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0334, d_svhn_loss: 0.0220, d_fake_loss: 0.0644, g_loss: 1.1787\n",
            "Step [47970/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0261, d_svhn_loss: 0.0133, d_fake_loss: 0.1211, g_loss: 1.3396\n",
            "Step [47980/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0191, d_svhn_loss: 0.0360, d_fake_loss: 0.0336, g_loss: 1.1736\n",
            "Step [47990/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0200, d_svhn_loss: 0.0164, d_fake_loss: 0.0412, g_loss: 1.1414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8010073304176331, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [48000/80000], d_real_loss: 0.1106, d_mnist_loss: 0.0863, d_svhn_loss: 0.0243, d_fake_loss: 0.0791, g_loss: 1.0517\n",
            "saved ./samples_fashion/sample-48000-m-s.png\n",
            "saved ./samples_fashion/sample-48000-s-m.png\n",
            "Step [48010/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0286, d_svhn_loss: 0.0406, d_fake_loss: 0.1140, g_loss: 1.1065\n",
            "Step [48020/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0568, d_svhn_loss: 0.0222, d_fake_loss: 0.0513, g_loss: 1.1089\n",
            "Step [48030/80000], d_real_loss: 0.0712, d_mnist_loss: 0.0327, d_svhn_loss: 0.0386, d_fake_loss: 0.0506, g_loss: 1.1784\n",
            "Step [48040/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0707, d_svhn_loss: 0.0194, d_fake_loss: 0.0506, g_loss: 0.8757\n",
            "Step [48050/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0200, d_svhn_loss: 0.0194, d_fake_loss: 0.0781, g_loss: 1.3164\n",
            "Step [48060/80000], d_real_loss: 0.0757, d_mnist_loss: 0.0148, d_svhn_loss: 0.0609, d_fake_loss: 0.0860, g_loss: 1.2175\n",
            "Step [48070/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0228, d_svhn_loss: 0.0181, d_fake_loss: 0.0522, g_loss: 1.0898\n",
            "Step [48080/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0483, d_svhn_loss: 0.0233, d_fake_loss: 0.0408, g_loss: 1.1308\n",
            "Step [48090/80000], d_real_loss: 0.1085, d_mnist_loss: 0.0881, d_svhn_loss: 0.0204, d_fake_loss: 0.0407, g_loss: 1.1554\n",
            "Step [48100/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0213, d_svhn_loss: 0.0245, d_fake_loss: 0.0750, g_loss: 1.3521\n",
            "Step [48110/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0146, d_svhn_loss: 0.0334, d_fake_loss: 0.0616, g_loss: 1.1312\n",
            "Step [48120/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0177, d_svhn_loss: 0.0593, d_fake_loss: 0.0420, g_loss: 1.1584\n",
            "Step [48130/80000], d_real_loss: 0.1458, d_mnist_loss: 0.0258, d_svhn_loss: 0.1199, d_fake_loss: 0.0955, g_loss: 1.0902\n",
            "Step [48140/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0149, d_svhn_loss: 0.0203, d_fake_loss: 0.0532, g_loss: 1.1825\n",
            "Step [48150/80000], d_real_loss: 0.0240, d_mnist_loss: 0.0098, d_svhn_loss: 0.0141, d_fake_loss: 0.0425, g_loss: 1.2295\n",
            "Step [48160/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0169, d_svhn_loss: 0.0210, d_fake_loss: 0.0858, g_loss: 1.2735\n",
            "Step [48170/80000], d_real_loss: 0.0897, d_mnist_loss: 0.0446, d_svhn_loss: 0.0451, d_fake_loss: 0.0410, g_loss: 1.1137\n",
            "Step [48180/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0324, d_svhn_loss: 0.0166, d_fake_loss: 0.0462, g_loss: 1.1374\n",
            "Step [48190/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0173, d_svhn_loss: 0.0240, d_fake_loss: 0.0334, g_loss: 1.1075\n",
            "Step [48200/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0180, d_svhn_loss: 0.0219, d_fake_loss: 0.0425, g_loss: 1.1577\n",
            "Step [48210/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0221, d_svhn_loss: 0.0195, d_fake_loss: 0.0467, g_loss: 1.0702\n",
            "Step [48220/80000], d_real_loss: 0.0929, d_mnist_loss: 0.0352, d_svhn_loss: 0.0577, d_fake_loss: 0.0613, g_loss: 1.1043\n",
            "Step [48230/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0287, d_svhn_loss: 0.0427, d_fake_loss: 0.1411, g_loss: 1.1947\n",
            "Step [48240/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0246, d_svhn_loss: 0.0267, d_fake_loss: 0.0622, g_loss: 1.1349\n",
            "Step [48250/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0288, d_svhn_loss: 0.0272, d_fake_loss: 0.1264, g_loss: 1.1123\n",
            "Step [48260/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0390, d_svhn_loss: 0.0163, d_fake_loss: 0.0493, g_loss: 1.1937\n",
            "Step [48270/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0293, d_svhn_loss: 0.0470, d_fake_loss: 0.0431, g_loss: 1.0787\n",
            "Step [48280/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0455, d_svhn_loss: 0.0262, d_fake_loss: 0.0423, g_loss: 1.3014\n",
            "Step [48290/80000], d_real_loss: 0.1356, d_mnist_loss: 0.0217, d_svhn_loss: 0.1139, d_fake_loss: 0.0358, g_loss: 1.2220\n",
            "Step [48300/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0137, d_svhn_loss: 0.0333, d_fake_loss: 0.0418, g_loss: 1.1576\n",
            "Step [48310/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0200, d_svhn_loss: 0.0140, d_fake_loss: 0.0333, g_loss: 1.2183\n",
            "Step [48320/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0275, d_svhn_loss: 0.0257, d_fake_loss: 0.0438, g_loss: 1.1896\n",
            "Step [48330/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0356, d_svhn_loss: 0.0252, d_fake_loss: 0.0295, g_loss: 1.0581\n",
            "Step [48340/80000], d_real_loss: 0.0941, d_mnist_loss: 0.0238, d_svhn_loss: 0.0704, d_fake_loss: 0.0629, g_loss: 0.9821\n",
            "Step [48350/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0169, d_svhn_loss: 0.0381, d_fake_loss: 0.0828, g_loss: 1.0037\n",
            "Step [48360/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0275, d_svhn_loss: 0.0135, d_fake_loss: 0.0377, g_loss: 1.1627\n",
            "Step [48370/80000], d_real_loss: 0.1027, d_mnist_loss: 0.0725, d_svhn_loss: 0.0302, d_fake_loss: 0.0567, g_loss: 1.1589\n",
            "Step [48380/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0431, d_svhn_loss: 0.0179, d_fake_loss: 0.0643, g_loss: 1.0476\n",
            "Step [48390/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0357, d_svhn_loss: 0.0250, d_fake_loss: 0.0463, g_loss: 1.1427\n",
            "Step [48400/80000], d_real_loss: 0.0766, d_mnist_loss: 0.0273, d_svhn_loss: 0.0493, d_fake_loss: 0.0995, g_loss: 1.0385\n",
            "Step [48410/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0285, d_svhn_loss: 0.0329, d_fake_loss: 0.0780, g_loss: 1.1800\n",
            "Step [48420/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0208, d_svhn_loss: 0.0610, d_fake_loss: 0.0352, g_loss: 1.3125\n",
            "Step [48430/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0183, d_svhn_loss: 0.0333, d_fake_loss: 0.0632, g_loss: 1.3391\n",
            "Step [48440/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0439, d_svhn_loss: 0.0390, d_fake_loss: 0.0443, g_loss: 1.0482\n",
            "Step [48450/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0177, d_svhn_loss: 0.0302, d_fake_loss: 0.1175, g_loss: 1.0735\n",
            "Step [48460/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0244, d_svhn_loss: 0.0395, d_fake_loss: 0.1654, g_loss: 0.9319\n",
            "Step [48470/80000], d_real_loss: 0.0916, d_mnist_loss: 0.0485, d_svhn_loss: 0.0431, d_fake_loss: 0.1067, g_loss: 1.4225\n",
            "Step [48480/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0316, d_svhn_loss: 0.0234, d_fake_loss: 0.0310, g_loss: 1.2002\n",
            "Step [48490/80000], d_real_loss: 0.1206, d_mnist_loss: 0.0482, d_svhn_loss: 0.0724, d_fake_loss: 0.0629, g_loss: 0.9819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8845763802528381, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [48500/80000], d_real_loss: 0.1920, d_mnist_loss: 0.0116, d_svhn_loss: 0.1804, d_fake_loss: 0.0861, g_loss: 1.0988\n",
            "saved ./samples_fashion/sample-48500-m-s.png\n",
            "saved ./samples_fashion/sample-48500-s-m.png\n",
            "Step [48510/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0173, d_svhn_loss: 0.0289, d_fake_loss: 0.0471, g_loss: 1.2744\n",
            "Step [48520/80000], d_real_loss: 0.0864, d_mnist_loss: 0.0173, d_svhn_loss: 0.0690, d_fake_loss: 0.0415, g_loss: 0.9363\n",
            "Step [48530/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0202, d_svhn_loss: 0.0147, d_fake_loss: 0.0385, g_loss: 1.1769\n",
            "Step [48540/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0230, d_svhn_loss: 0.0187, d_fake_loss: 0.0360, g_loss: 1.2444\n",
            "Step [48550/80000], d_real_loss: 0.1084, d_mnist_loss: 0.0255, d_svhn_loss: 0.0830, d_fake_loss: 0.0337, g_loss: 1.2961\n",
            "Step [48560/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0160, d_svhn_loss: 0.0304, d_fake_loss: 0.0488, g_loss: 1.2041\n",
            "Step [48570/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0245, d_svhn_loss: 0.0221, d_fake_loss: 0.0685, g_loss: 0.9146\n",
            "Step [48580/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0271, d_svhn_loss: 0.0250, d_fake_loss: 0.0726, g_loss: 1.1790\n",
            "Step [48590/80000], d_real_loss: 0.0938, d_mnist_loss: 0.0345, d_svhn_loss: 0.0593, d_fake_loss: 0.0379, g_loss: 1.2475\n",
            "Step [48600/80000], d_real_loss: 0.1821, d_mnist_loss: 0.0179, d_svhn_loss: 0.1642, d_fake_loss: 0.0917, g_loss: 1.0592\n",
            "Step [48610/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0146, d_svhn_loss: 0.0490, d_fake_loss: 0.0707, g_loss: 1.1456\n",
            "Step [48620/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0142, d_svhn_loss: 0.0185, d_fake_loss: 0.0258, g_loss: 1.1091\n",
            "Step [48630/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0254, d_svhn_loss: 0.0209, d_fake_loss: 0.0727, g_loss: 1.2323\n",
            "Step [48640/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0187, d_svhn_loss: 0.0184, d_fake_loss: 0.0736, g_loss: 1.0732\n",
            "Step [48650/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0379, d_svhn_loss: 0.0218, d_fake_loss: 0.0505, g_loss: 1.1624\n",
            "Step [48660/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0380, d_svhn_loss: 0.0337, d_fake_loss: 0.0561, g_loss: 1.2100\n",
            "Step [48670/80000], d_real_loss: 0.0943, d_mnist_loss: 0.0148, d_svhn_loss: 0.0795, d_fake_loss: 0.1039, g_loss: 1.3597\n",
            "Step [48680/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0505, d_svhn_loss: 0.0152, d_fake_loss: 0.0444, g_loss: 1.2368\n",
            "Step [48690/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0151, d_svhn_loss: 0.0196, d_fake_loss: 0.0513, g_loss: 1.1686\n",
            "Step [48700/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0187, d_svhn_loss: 0.0216, d_fake_loss: 0.0563, g_loss: 1.1670\n",
            "Step [48710/80000], d_real_loss: 0.0940, d_mnist_loss: 0.0277, d_svhn_loss: 0.0663, d_fake_loss: 0.0538, g_loss: 1.2270\n",
            "Step [48720/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0474, d_svhn_loss: 0.0341, d_fake_loss: 0.0646, g_loss: 1.3106\n",
            "Step [48730/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0179, d_svhn_loss: 0.0251, d_fake_loss: 0.0755, g_loss: 1.1262\n",
            "Step [48740/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0231, d_svhn_loss: 0.0461, d_fake_loss: 0.1788, g_loss: 0.9476\n",
            "Step [48750/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0176, d_svhn_loss: 0.0278, d_fake_loss: 0.1482, g_loss: 1.1780\n",
            "Step [48760/80000], d_real_loss: 0.1289, d_mnist_loss: 0.0560, d_svhn_loss: 0.0729, d_fake_loss: 0.0431, g_loss: 1.0901\n",
            "Step [48770/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0141, d_svhn_loss: 0.0317, d_fake_loss: 0.1049, g_loss: 1.1845\n",
            "Step [48780/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0340, d_svhn_loss: 0.0260, d_fake_loss: 0.0513, g_loss: 1.0501\n",
            "Step [48790/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0234, d_svhn_loss: 0.0225, d_fake_loss: 0.0546, g_loss: 1.0585\n",
            "Step [48800/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0194, d_svhn_loss: 0.0259, d_fake_loss: 0.0713, g_loss: 1.1785\n",
            "Step [48810/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0167, d_svhn_loss: 0.0240, d_fake_loss: 0.0535, g_loss: 1.1341\n",
            "Step [48820/80000], d_real_loss: 0.0785, d_mnist_loss: 0.0480, d_svhn_loss: 0.0305, d_fake_loss: 0.0632, g_loss: 1.1222\n",
            "Step [48830/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0517, d_svhn_loss: 0.0302, d_fake_loss: 0.0473, g_loss: 1.1427\n",
            "Step [48840/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0224, d_svhn_loss: 0.0159, d_fake_loss: 0.0398, g_loss: 1.0442\n",
            "Step [48850/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0294, d_svhn_loss: 0.0376, d_fake_loss: 0.0344, g_loss: 1.1243\n",
            "Step [48860/80000], d_real_loss: 0.1091, d_mnist_loss: 0.0236, d_svhn_loss: 0.0855, d_fake_loss: 0.0552, g_loss: 1.1127\n",
            "Step [48870/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0353, d_svhn_loss: 0.0193, d_fake_loss: 0.0500, g_loss: 1.0540\n",
            "Step [48880/80000], d_real_loss: 0.0898, d_mnist_loss: 0.0209, d_svhn_loss: 0.0689, d_fake_loss: 0.0948, g_loss: 1.1886\n",
            "Step [48890/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0176, d_svhn_loss: 0.0409, d_fake_loss: 0.1349, g_loss: 1.2449\n",
            "Step [48900/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0279, d_svhn_loss: 0.0167, d_fake_loss: 0.0352, g_loss: 1.1532\n",
            "Step [48910/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0426, d_svhn_loss: 0.0225, d_fake_loss: 0.0569, g_loss: 1.1569\n",
            "Step [48920/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0302, d_svhn_loss: 0.0249, d_fake_loss: 0.0697, g_loss: 1.2545\n",
            "Step [48930/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0388, d_svhn_loss: 0.0276, d_fake_loss: 0.0468, g_loss: 1.0338\n",
            "Step [48940/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0217, d_svhn_loss: 0.0200, d_fake_loss: 0.0510, g_loss: 1.2529\n",
            "Step [48950/80000], d_real_loss: 0.1155, d_mnist_loss: 0.0654, d_svhn_loss: 0.0501, d_fake_loss: 0.0584, g_loss: 1.3031\n",
            "Step [48960/80000], d_real_loss: 0.1029, d_mnist_loss: 0.0766, d_svhn_loss: 0.0263, d_fake_loss: 0.0358, g_loss: 1.2294\n",
            "Step [48970/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0328, d_svhn_loss: 0.0244, d_fake_loss: 0.0733, g_loss: 1.2535\n",
            "Step [48980/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0321, d_svhn_loss: 0.0221, d_fake_loss: 0.0644, g_loss: 1.2456\n",
            "Step [48990/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0207, d_svhn_loss: 0.0247, d_fake_loss: 0.0480, g_loss: 1.3564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.811679482460022, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [49000/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0252, d_svhn_loss: 0.0216, d_fake_loss: 0.0710, g_loss: 1.2455\n",
            "saved ./samples_fashion/sample-49000-m-s.png\n",
            "saved ./samples_fashion/sample-49000-s-m.png\n",
            "Step [49010/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0227, d_svhn_loss: 0.0538, d_fake_loss: 0.0328, g_loss: 1.1070\n",
            "Step [49020/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0166, d_svhn_loss: 0.0494, d_fake_loss: 0.0499, g_loss: 1.3004\n",
            "Step [49030/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0276, d_svhn_loss: 0.0409, d_fake_loss: 0.0834, g_loss: 1.1660\n",
            "Step [49040/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0346, d_svhn_loss: 0.0474, d_fake_loss: 0.0674, g_loss: 1.1029\n",
            "Step [49050/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0233, d_svhn_loss: 0.0374, d_fake_loss: 0.0551, g_loss: 1.2577\n",
            "Step [49060/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0205, d_svhn_loss: 0.0334, d_fake_loss: 0.0574, g_loss: 1.1096\n",
            "Step [49070/80000], d_real_loss: 0.1863, d_mnist_loss: 0.0177, d_svhn_loss: 0.1686, d_fake_loss: 0.1153, g_loss: 1.1319\n",
            "Step [49080/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0507, d_svhn_loss: 0.0201, d_fake_loss: 0.0751, g_loss: 1.3616\n",
            "Step [49090/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0231, d_svhn_loss: 0.0439, d_fake_loss: 0.0841, g_loss: 1.1571\n",
            "Step [49100/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0411, d_svhn_loss: 0.0265, d_fake_loss: 0.0312, g_loss: 1.0600\n",
            "Step [49110/80000], d_real_loss: 0.0385, d_mnist_loss: 0.0162, d_svhn_loss: 0.0223, d_fake_loss: 0.0942, g_loss: 1.1930\n",
            "Step [49120/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0268, d_svhn_loss: 0.0380, d_fake_loss: 0.0415, g_loss: 1.1474\n",
            "Step [49130/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0226, d_svhn_loss: 0.0392, d_fake_loss: 0.0333, g_loss: 1.0698\n",
            "Step [49140/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0177, d_svhn_loss: 0.0249, d_fake_loss: 0.0970, g_loss: 1.2447\n",
            "Step [49150/80000], d_real_loss: 0.1158, d_mnist_loss: 0.0145, d_svhn_loss: 0.1013, d_fake_loss: 0.0428, g_loss: 1.0952\n",
            "Step [49160/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0331, d_svhn_loss: 0.0194, d_fake_loss: 0.1011, g_loss: 1.1769\n",
            "Step [49170/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0232, d_svhn_loss: 0.0363, d_fake_loss: 0.0644, g_loss: 1.1398\n",
            "Step [49180/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0330, d_svhn_loss: 0.0181, d_fake_loss: 0.0477, g_loss: 1.1986\n",
            "Step [49190/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0298, d_svhn_loss: 0.0321, d_fake_loss: 0.1266, g_loss: 1.2003\n",
            "Step [49200/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0194, d_svhn_loss: 0.0270, d_fake_loss: 0.0431, g_loss: 1.0861\n",
            "Step [49210/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0284, d_svhn_loss: 0.0238, d_fake_loss: 0.0430, g_loss: 1.1895\n",
            "Step [49220/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0398, d_svhn_loss: 0.0170, d_fake_loss: 0.1001, g_loss: 1.1651\n",
            "Step [49230/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0200, d_svhn_loss: 0.0206, d_fake_loss: 0.0276, g_loss: 1.1369\n",
            "Step [49240/80000], d_real_loss: 0.0878, d_mnist_loss: 0.0654, d_svhn_loss: 0.0224, d_fake_loss: 0.0393, g_loss: 1.0823\n",
            "Step [49250/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0231, d_svhn_loss: 0.0344, d_fake_loss: 0.0404, g_loss: 1.1230\n",
            "Step [49260/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0466, d_svhn_loss: 0.0296, d_fake_loss: 0.0767, g_loss: 1.3903\n",
            "Step [49270/80000], d_real_loss: 0.0693, d_mnist_loss: 0.0351, d_svhn_loss: 0.0342, d_fake_loss: 0.0551, g_loss: 1.1202\n",
            "Step [49280/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0323, d_svhn_loss: 0.0178, d_fake_loss: 0.0368, g_loss: 1.0184\n",
            "Step [49290/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0142, d_svhn_loss: 0.0595, d_fake_loss: 0.0672, g_loss: 1.3454\n",
            "Step [49300/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0150, d_svhn_loss: 0.0525, d_fake_loss: 0.0333, g_loss: 1.1964\n",
            "Step [49310/80000], d_real_loss: 0.0789, d_mnist_loss: 0.0204, d_svhn_loss: 0.0585, d_fake_loss: 0.0310, g_loss: 1.0199\n",
            "Step [49320/80000], d_real_loss: 0.0899, d_mnist_loss: 0.0649, d_svhn_loss: 0.0250, d_fake_loss: 0.0700, g_loss: 0.8768\n",
            "Step [49330/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0315, d_svhn_loss: 0.0131, d_fake_loss: 0.0351, g_loss: 1.0104\n",
            "Step [49340/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0180, d_svhn_loss: 0.0181, d_fake_loss: 0.0342, g_loss: 1.3469\n",
            "Step [49350/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0715, d_svhn_loss: 0.0164, d_fake_loss: 0.0610, g_loss: 1.1333\n",
            "Step [49360/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0183, d_svhn_loss: 0.0464, d_fake_loss: 0.0799, g_loss: 0.9265\n",
            "Step [49370/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0163, d_svhn_loss: 0.0377, d_fake_loss: 0.0551, g_loss: 1.2889\n",
            "Step [49380/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0486, d_svhn_loss: 0.0292, d_fake_loss: 0.0292, g_loss: 1.0483\n",
            "Step [49390/80000], d_real_loss: 0.1071, d_mnist_loss: 0.0799, d_svhn_loss: 0.0272, d_fake_loss: 0.0461, g_loss: 1.2266\n",
            "Step [49400/80000], d_real_loss: 0.1057, d_mnist_loss: 0.0404, d_svhn_loss: 0.0654, d_fake_loss: 0.0760, g_loss: 1.3218\n",
            "Step [49410/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0140, d_svhn_loss: 0.0244, d_fake_loss: 0.0763, g_loss: 1.1159\n",
            "Step [49420/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0156, d_svhn_loss: 0.0274, d_fake_loss: 0.1070, g_loss: 1.4513\n",
            "Step [49430/80000], d_real_loss: 0.1157, d_mnist_loss: 0.0148, d_svhn_loss: 0.1008, d_fake_loss: 0.0745, g_loss: 0.8924\n",
            "Step [49440/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0238, d_svhn_loss: 0.0486, d_fake_loss: 0.1429, g_loss: 1.2182\n",
            "Step [49450/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0166, d_svhn_loss: 0.0318, d_fake_loss: 0.0453, g_loss: 1.1091\n",
            "Step [49460/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0220, d_svhn_loss: 0.0232, d_fake_loss: 0.0769, g_loss: 1.1827\n",
            "Step [49470/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0238, d_svhn_loss: 0.0225, d_fake_loss: 0.0250, g_loss: 1.0561\n",
            "Step [49480/80000], d_real_loss: 0.0857, d_mnist_loss: 0.0167, d_svhn_loss: 0.0690, d_fake_loss: 0.0363, g_loss: 1.0383\n",
            "Step [49490/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0178, d_svhn_loss: 0.0181, d_fake_loss: 0.0703, g_loss: 1.2155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8202986121177673, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [49500/80000], d_real_loss: 0.1177, d_mnist_loss: 0.0708, d_svhn_loss: 0.0469, d_fake_loss: 0.0355, g_loss: 1.1067\n",
            "saved ./samples_fashion/sample-49500-m-s.png\n",
            "saved ./samples_fashion/sample-49500-s-m.png\n",
            "Step [49510/80000], d_real_loss: 0.1028, d_mnist_loss: 0.0414, d_svhn_loss: 0.0614, d_fake_loss: 0.0518, g_loss: 0.9853\n",
            "Step [49520/80000], d_real_loss: 0.0834, d_mnist_loss: 0.0437, d_svhn_loss: 0.0397, d_fake_loss: 0.0336, g_loss: 1.1095\n",
            "Step [49530/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0253, d_svhn_loss: 0.0263, d_fake_loss: 0.0258, g_loss: 1.2692\n",
            "Step [49540/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0265, d_svhn_loss: 0.0317, d_fake_loss: 0.0815, g_loss: 1.2585\n",
            "Step [49550/80000], d_real_loss: 0.1032, d_mnist_loss: 0.0179, d_svhn_loss: 0.0853, d_fake_loss: 0.0955, g_loss: 1.2070\n",
            "Step [49560/80000], d_real_loss: 0.1504, d_mnist_loss: 0.0949, d_svhn_loss: 0.0555, d_fake_loss: 0.0820, g_loss: 1.2300\n",
            "Step [49570/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0494, d_svhn_loss: 0.0236, d_fake_loss: 0.0678, g_loss: 1.0985\n",
            "Step [49580/80000], d_real_loss: 0.1556, d_mnist_loss: 0.0287, d_svhn_loss: 0.1269, d_fake_loss: 0.0367, g_loss: 1.0677\n",
            "Step [49590/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0198, d_svhn_loss: 0.0171, d_fake_loss: 0.0598, g_loss: 1.0262\n",
            "Step [49600/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0209, d_svhn_loss: 0.0194, d_fake_loss: 0.0422, g_loss: 1.1360\n",
            "Step [49610/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0254, d_svhn_loss: 0.0236, d_fake_loss: 0.0480, g_loss: 1.1901\n",
            "Step [49620/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0164, d_svhn_loss: 0.0399, d_fake_loss: 0.0598, g_loss: 1.2343\n",
            "Step [49630/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0196, d_svhn_loss: 0.0276, d_fake_loss: 0.1072, g_loss: 1.3129\n",
            "Step [49640/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0313, d_svhn_loss: 0.0422, d_fake_loss: 0.0367, g_loss: 1.3089\n",
            "Step [49650/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0256, d_svhn_loss: 0.0277, d_fake_loss: 0.0318, g_loss: 1.0459\n",
            "Step [49660/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0353, d_svhn_loss: 0.0204, d_fake_loss: 0.0541, g_loss: 1.2268\n",
            "Step [49670/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0461, d_svhn_loss: 0.0172, d_fake_loss: 0.0656, g_loss: 0.9608\n",
            "Step [49680/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0232, d_svhn_loss: 0.0212, d_fake_loss: 0.0488, g_loss: 1.0409\n",
            "Step [49690/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0161, d_svhn_loss: 0.0183, d_fake_loss: 0.0335, g_loss: 1.1552\n",
            "Step [49700/80000], d_real_loss: 0.0948, d_mnist_loss: 0.0316, d_svhn_loss: 0.0632, d_fake_loss: 0.0823, g_loss: 1.2059\n",
            "Step [49710/80000], d_real_loss: 0.0534, d_mnist_loss: 0.0144, d_svhn_loss: 0.0390, d_fake_loss: 0.1172, g_loss: 1.3282\n",
            "Step [49720/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0409, d_svhn_loss: 0.0255, d_fake_loss: 0.0397, g_loss: 1.0979\n",
            "Step [49730/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0339, d_svhn_loss: 0.0207, d_fake_loss: 0.0470, g_loss: 1.4532\n",
            "Step [49740/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0358, d_svhn_loss: 0.0266, d_fake_loss: 0.0461, g_loss: 1.1348\n",
            "Step [49750/80000], d_real_loss: 0.0949, d_mnist_loss: 0.0759, d_svhn_loss: 0.0190, d_fake_loss: 0.0460, g_loss: 1.1224\n",
            "Step [49760/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0360, d_svhn_loss: 0.0158, d_fake_loss: 0.1144, g_loss: 1.3854\n",
            "Step [49770/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0267, d_svhn_loss: 0.0322, d_fake_loss: 0.0641, g_loss: 1.1889\n",
            "Step [49780/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0172, d_svhn_loss: 0.0228, d_fake_loss: 0.0799, g_loss: 1.2457\n",
            "Step [49790/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0464, d_svhn_loss: 0.0210, d_fake_loss: 0.0821, g_loss: 1.3045\n",
            "Step [49800/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0270, d_svhn_loss: 0.0189, d_fake_loss: 0.0270, g_loss: 0.9862\n",
            "Step [49810/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0245, d_svhn_loss: 0.0164, d_fake_loss: 0.0244, g_loss: 1.3782\n",
            "Step [49820/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0292, d_svhn_loss: 0.0394, d_fake_loss: 0.1516, g_loss: 1.3585\n",
            "Step [49830/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0316, d_svhn_loss: 0.0271, d_fake_loss: 0.0506, g_loss: 1.1171\n",
            "Step [49840/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0210, d_svhn_loss: 0.0246, d_fake_loss: 0.0904, g_loss: 1.0280\n",
            "Step [49850/80000], d_real_loss: 0.0508, d_mnist_loss: 0.0179, d_svhn_loss: 0.0330, d_fake_loss: 0.0548, g_loss: 1.1729\n",
            "Step [49860/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0261, d_svhn_loss: 0.0290, d_fake_loss: 0.0404, g_loss: 1.0313\n",
            "Step [49870/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0248, d_svhn_loss: 0.0202, d_fake_loss: 0.0603, g_loss: 1.2723\n",
            "Step [49880/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0195, d_svhn_loss: 0.0458, d_fake_loss: 0.0511, g_loss: 1.1785\n",
            "Step [49890/80000], d_real_loss: 0.0682, d_mnist_loss: 0.0541, d_svhn_loss: 0.0140, d_fake_loss: 0.0436, g_loss: 1.1667\n",
            "Step [49900/80000], d_real_loss: 0.1004, d_mnist_loss: 0.0195, d_svhn_loss: 0.0808, d_fake_loss: 0.0498, g_loss: 1.2326\n",
            "Step [49910/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0394, d_svhn_loss: 0.0242, d_fake_loss: 0.0453, g_loss: 1.2044\n",
            "Step [49920/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0263, d_svhn_loss: 0.0251, d_fake_loss: 0.0757, g_loss: 1.0783\n",
            "Step [49930/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0144, d_svhn_loss: 0.0352, d_fake_loss: 0.0478, g_loss: 1.1050\n",
            "Step [49940/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0229, d_svhn_loss: 0.0138, d_fake_loss: 0.0394, g_loss: 1.2637\n",
            "Step [49950/80000], d_real_loss: 0.1204, d_mnist_loss: 0.0629, d_svhn_loss: 0.0575, d_fake_loss: 0.0518, g_loss: 1.1148\n",
            "Step [49960/80000], d_real_loss: 0.0845, d_mnist_loss: 0.0536, d_svhn_loss: 0.0308, d_fake_loss: 0.1267, g_loss: 1.4884\n",
            "Step [49970/80000], d_real_loss: 0.1576, d_mnist_loss: 0.0760, d_svhn_loss: 0.0816, d_fake_loss: 0.0633, g_loss: 1.0789\n",
            "Step [49980/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0157, d_svhn_loss: 0.0178, d_fake_loss: 0.0628, g_loss: 1.4278\n",
            "Step [49990/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0188, d_svhn_loss: 0.0302, d_fake_loss: 0.0486, g_loss: 1.2731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8640266060829163, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [50000/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0439, d_svhn_loss: 0.0251, d_fake_loss: 0.1092, g_loss: 1.1608\n",
            "saved ./samples_fashion/sample-50000-m-s.png\n",
            "saved ./samples_fashion/sample-50000-s-m.png\n",
            "Step [50010/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0192, d_svhn_loss: 0.0231, d_fake_loss: 0.0445, g_loss: 1.0078\n",
            "Step [50020/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0143, d_svhn_loss: 0.0172, d_fake_loss: 0.0317, g_loss: 1.3250\n",
            "Step [50030/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0157, d_svhn_loss: 0.0368, d_fake_loss: 0.0806, g_loss: 1.2645\n",
            "Step [50040/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0187, d_svhn_loss: 0.0464, d_fake_loss: 0.0651, g_loss: 1.3292\n",
            "Step [50050/80000], d_real_loss: 0.1064, d_mnist_loss: 0.0185, d_svhn_loss: 0.0879, d_fake_loss: 0.1123, g_loss: 0.8918\n",
            "Step [50060/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0158, d_svhn_loss: 0.0181, d_fake_loss: 0.0651, g_loss: 0.9872\n",
            "Step [50070/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0165, d_svhn_loss: 0.0169, d_fake_loss: 0.0509, g_loss: 1.3215\n",
            "Step [50080/80000], d_real_loss: 0.1065, d_mnist_loss: 0.0875, d_svhn_loss: 0.0190, d_fake_loss: 0.0438, g_loss: 1.0621\n",
            "Step [50090/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0175, d_svhn_loss: 0.0292, d_fake_loss: 0.0271, g_loss: 1.0706\n",
            "Step [50100/80000], d_real_loss: 0.1112, d_mnist_loss: 0.0868, d_svhn_loss: 0.0244, d_fake_loss: 0.0630, g_loss: 1.2629\n",
            "Step [50110/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0291, d_svhn_loss: 0.0293, d_fake_loss: 0.0831, g_loss: 1.3085\n",
            "Step [50120/80000], d_real_loss: 0.0828, d_mnist_loss: 0.0136, d_svhn_loss: 0.0691, d_fake_loss: 0.0407, g_loss: 1.2593\n",
            "Step [50130/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0201, d_svhn_loss: 0.0231, d_fake_loss: 0.0529, g_loss: 1.2777\n",
            "Step [50140/80000], d_real_loss: 0.2296, d_mnist_loss: 0.1112, d_svhn_loss: 0.1184, d_fake_loss: 0.0881, g_loss: 1.3144\n",
            "Step [50150/80000], d_real_loss: 0.0928, d_mnist_loss: 0.0231, d_svhn_loss: 0.0697, d_fake_loss: 0.0359, g_loss: 1.1737\n",
            "Step [50160/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0133, d_svhn_loss: 0.0174, d_fake_loss: 0.0413, g_loss: 1.0542\n",
            "Step [50170/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0353, d_svhn_loss: 0.0179, d_fake_loss: 0.0535, g_loss: 1.1320\n",
            "Step [50180/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0372, d_svhn_loss: 0.0280, d_fake_loss: 0.0457, g_loss: 1.1129\n",
            "Step [50190/80000], d_real_loss: 0.1543, d_mnist_loss: 0.1269, d_svhn_loss: 0.0274, d_fake_loss: 0.0713, g_loss: 1.1803\n",
            "Step [50200/80000], d_real_loss: 0.1411, d_mnist_loss: 0.0944, d_svhn_loss: 0.0467, d_fake_loss: 0.0586, g_loss: 1.2793\n",
            "Step [50210/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0180, d_svhn_loss: 0.0499, d_fake_loss: 0.0730, g_loss: 1.2211\n",
            "Step [50220/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0410, d_svhn_loss: 0.0212, d_fake_loss: 0.0352, g_loss: 1.0389\n",
            "Step [50230/80000], d_real_loss: 0.1200, d_mnist_loss: 0.0970, d_svhn_loss: 0.0230, d_fake_loss: 0.0717, g_loss: 1.1170\n",
            "Step [50240/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0229, d_svhn_loss: 0.0413, d_fake_loss: 0.0573, g_loss: 1.1955\n",
            "Step [50250/80000], d_real_loss: 0.1679, d_mnist_loss: 0.0724, d_svhn_loss: 0.0955, d_fake_loss: 0.0750, g_loss: 1.1932\n",
            "Step [50260/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0131, d_svhn_loss: 0.0236, d_fake_loss: 0.0874, g_loss: 1.2425\n",
            "Step [50270/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0185, d_svhn_loss: 0.0284, d_fake_loss: 0.0415, g_loss: 1.1763\n",
            "Step [50280/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0413, d_svhn_loss: 0.0173, d_fake_loss: 0.0467, g_loss: 1.2517\n",
            "Step [50290/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0166, d_svhn_loss: 0.0586, d_fake_loss: 0.0574, g_loss: 1.0944\n",
            "Step [50300/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0438, d_svhn_loss: 0.0222, d_fake_loss: 0.0432, g_loss: 1.1420\n",
            "Step [50310/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0333, d_svhn_loss: 0.0233, d_fake_loss: 0.0647, g_loss: 1.3857\n",
            "Step [50320/80000], d_real_loss: 0.1055, d_mnist_loss: 0.0380, d_svhn_loss: 0.0675, d_fake_loss: 0.0557, g_loss: 1.1028\n",
            "Step [50330/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0199, d_svhn_loss: 0.0343, d_fake_loss: 0.0398, g_loss: 1.0971\n",
            "Step [50340/80000], d_real_loss: 0.0266, d_mnist_loss: 0.0136, d_svhn_loss: 0.0130, d_fake_loss: 0.0435, g_loss: 1.6770\n",
            "Step [50350/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0229, d_svhn_loss: 0.0265, d_fake_loss: 0.0378, g_loss: 1.1692\n",
            "Step [50360/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0570, d_svhn_loss: 0.0236, d_fake_loss: 0.0391, g_loss: 1.1275\n",
            "Step [50370/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0285, d_svhn_loss: 0.0168, d_fake_loss: 0.0559, g_loss: 1.1573\n",
            "Step [50380/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0193, d_svhn_loss: 0.0192, d_fake_loss: 0.0481, g_loss: 1.3238\n",
            "Step [50390/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0148, d_svhn_loss: 0.0269, d_fake_loss: 0.0410, g_loss: 1.2993\n",
            "Step [50400/80000], d_real_loss: 0.1217, d_mnist_loss: 0.1033, d_svhn_loss: 0.0185, d_fake_loss: 0.0989, g_loss: 1.0211\n",
            "Step [50410/80000], d_real_loss: 0.1216, d_mnist_loss: 0.0874, d_svhn_loss: 0.0342, d_fake_loss: 0.0563, g_loss: 1.0345\n",
            "Step [50420/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0164, d_svhn_loss: 0.0158, d_fake_loss: 0.0267, g_loss: 1.0525\n",
            "Step [50430/80000], d_real_loss: 0.0680, d_mnist_loss: 0.0493, d_svhn_loss: 0.0188, d_fake_loss: 0.0341, g_loss: 1.0906\n",
            "Step [50440/80000], d_real_loss: 0.0797, d_mnist_loss: 0.0631, d_svhn_loss: 0.0166, d_fake_loss: 0.0298, g_loss: 1.0657\n",
            "Step [50450/80000], d_real_loss: 0.0885, d_mnist_loss: 0.0680, d_svhn_loss: 0.0205, d_fake_loss: 0.0338, g_loss: 1.2079\n",
            "Step [50460/80000], d_real_loss: 0.0860, d_mnist_loss: 0.0659, d_svhn_loss: 0.0201, d_fake_loss: 0.0486, g_loss: 1.1092\n",
            "Step [50470/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0307, d_svhn_loss: 0.0174, d_fake_loss: 0.0554, g_loss: 1.1817\n",
            "Step [50480/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0170, d_svhn_loss: 0.0207, d_fake_loss: 0.0769, g_loss: 1.0806\n",
            "Step [50490/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0256, d_svhn_loss: 0.0304, d_fake_loss: 0.0387, g_loss: 1.1976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7903162240982056, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [50500/80000], d_real_loss: 0.1270, d_mnist_loss: 0.0176, d_svhn_loss: 0.1094, d_fake_loss: 0.0504, g_loss: 1.1656\n",
            "saved ./samples_fashion/sample-50500-m-s.png\n",
            "saved ./samples_fashion/sample-50500-s-m.png\n",
            "Step [50510/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0646, d_svhn_loss: 0.0304, d_fake_loss: 0.0602, g_loss: 1.2035\n",
            "Step [50520/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0423, d_svhn_loss: 0.0162, d_fake_loss: 0.0874, g_loss: 0.9298\n",
            "Step [50530/80000], d_real_loss: 0.0902, d_mnist_loss: 0.0696, d_svhn_loss: 0.0206, d_fake_loss: 0.0279, g_loss: 1.0382\n",
            "Step [50540/80000], d_real_loss: 0.1221, d_mnist_loss: 0.0739, d_svhn_loss: 0.0482, d_fake_loss: 0.2244, g_loss: 1.2131\n",
            "Step [50550/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0183, d_svhn_loss: 0.0222, d_fake_loss: 0.0485, g_loss: 1.1758\n",
            "Step [50560/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0353, d_svhn_loss: 0.0188, d_fake_loss: 0.0469, g_loss: 1.0388\n",
            "Step [50570/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0164, d_svhn_loss: 0.0254, d_fake_loss: 0.0417, g_loss: 1.1643\n",
            "Step [50580/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0164, d_svhn_loss: 0.0203, d_fake_loss: 0.0453, g_loss: 1.1004\n",
            "Step [50590/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0471, d_svhn_loss: 0.0184, d_fake_loss: 0.0536, g_loss: 1.1205\n",
            "Step [50600/80000], d_real_loss: 0.1779, d_mnist_loss: 0.0287, d_svhn_loss: 0.1492, d_fake_loss: 0.0392, g_loss: 1.0778\n",
            "Step [50610/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0417, d_svhn_loss: 0.0164, d_fake_loss: 0.0400, g_loss: 1.2430\n",
            "Step [50620/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0295, d_svhn_loss: 0.0296, d_fake_loss: 0.0385, g_loss: 1.0205\n",
            "Step [50630/80000], d_real_loss: 0.0971, d_mnist_loss: 0.0680, d_svhn_loss: 0.0291, d_fake_loss: 0.0815, g_loss: 1.0367\n",
            "Step [50640/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0170, d_svhn_loss: 0.0258, d_fake_loss: 0.0474, g_loss: 1.1969\n",
            "Step [50650/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0241, d_svhn_loss: 0.0230, d_fake_loss: 0.0290, g_loss: 1.0290\n",
            "Step [50660/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0159, d_svhn_loss: 0.0470, d_fake_loss: 0.1127, g_loss: 1.1944\n",
            "Step [50670/80000], d_real_loss: 0.0235, d_mnist_loss: 0.0113, d_svhn_loss: 0.0122, d_fake_loss: 0.0478, g_loss: 1.1618\n",
            "Step [50680/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0318, d_svhn_loss: 0.0356, d_fake_loss: 0.0632, g_loss: 1.1569\n",
            "Step [50690/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0331, d_svhn_loss: 0.0200, d_fake_loss: 0.0354, g_loss: 1.0135\n",
            "Step [50700/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0248, d_svhn_loss: 0.0186, d_fake_loss: 0.0274, g_loss: 1.0627\n",
            "Step [50710/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0505, d_svhn_loss: 0.0213, d_fake_loss: 0.0423, g_loss: 1.1293\n",
            "Step [50720/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0139, d_svhn_loss: 0.0651, d_fake_loss: 0.0748, g_loss: 1.0428\n",
            "Step [50730/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0167, d_svhn_loss: 0.0200, d_fake_loss: 0.0565, g_loss: 1.2654\n",
            "Step [50740/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0181, d_svhn_loss: 0.0257, d_fake_loss: 0.0550, g_loss: 1.2584\n",
            "Step [50750/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0328, d_svhn_loss: 0.0488, d_fake_loss: 0.0827, g_loss: 1.0959\n",
            "Step [50760/80000], d_real_loss: 0.1129, d_mnist_loss: 0.0219, d_svhn_loss: 0.0910, d_fake_loss: 0.0630, g_loss: 1.0862\n",
            "Step [50770/80000], d_real_loss: 0.1186, d_mnist_loss: 0.0962, d_svhn_loss: 0.0224, d_fake_loss: 0.1150, g_loss: 1.1318\n",
            "Step [50780/80000], d_real_loss: 0.1229, d_mnist_loss: 0.1019, d_svhn_loss: 0.0209, d_fake_loss: 0.0572, g_loss: 1.2152\n",
            "Step [50790/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0192, d_svhn_loss: 0.0241, d_fake_loss: 0.0729, g_loss: 1.0779\n",
            "Step [50800/80000], d_real_loss: 0.1439, d_mnist_loss: 0.0312, d_svhn_loss: 0.1127, d_fake_loss: 0.0467, g_loss: 1.0437\n",
            "Step [50810/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0225, d_svhn_loss: 0.0220, d_fake_loss: 0.0516, g_loss: 1.1440\n",
            "Step [50820/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0171, d_svhn_loss: 0.0265, d_fake_loss: 0.0597, g_loss: 1.2220\n",
            "Step [50830/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0373, d_svhn_loss: 0.0191, d_fake_loss: 0.0616, g_loss: 1.3482\n",
            "Step [50840/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0160, d_svhn_loss: 0.0732, d_fake_loss: 0.0307, g_loss: 1.1022\n",
            "Step [50850/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0167, d_svhn_loss: 0.0310, d_fake_loss: 0.0290, g_loss: 1.1473\n",
            "Step [50860/80000], d_real_loss: 0.1194, d_mnist_loss: 0.0982, d_svhn_loss: 0.0212, d_fake_loss: 0.0584, g_loss: 1.2712\n",
            "Step [50870/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0207, d_svhn_loss: 0.0501, d_fake_loss: 0.0631, g_loss: 1.3265\n",
            "Step [50880/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0192, d_svhn_loss: 0.0263, d_fake_loss: 0.0536, g_loss: 1.2136\n",
            "Step [50890/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0264, d_svhn_loss: 0.0556, d_fake_loss: 0.0250, g_loss: 1.1624\n",
            "Step [50900/80000], d_real_loss: 0.2676, d_mnist_loss: 0.2481, d_svhn_loss: 0.0195, d_fake_loss: 0.1103, g_loss: 1.3038\n",
            "Step [50910/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0246, d_svhn_loss: 0.0597, d_fake_loss: 0.0602, g_loss: 1.0972\n",
            "Step [50920/80000], d_real_loss: 0.1005, d_mnist_loss: 0.0782, d_svhn_loss: 0.0223, d_fake_loss: 0.0529, g_loss: 1.0860\n",
            "Step [50930/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0354, d_svhn_loss: 0.0153, d_fake_loss: 0.0427, g_loss: 1.2557\n",
            "Step [50940/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0175, d_svhn_loss: 0.0197, d_fake_loss: 0.0911, g_loss: 1.0408\n",
            "Step [50950/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0289, d_svhn_loss: 0.0162, d_fake_loss: 0.0836, g_loss: 0.9988\n",
            "Step [50960/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0353, d_svhn_loss: 0.0159, d_fake_loss: 0.0343, g_loss: 1.2122\n",
            "Step [50970/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0251, d_svhn_loss: 0.0209, d_fake_loss: 0.0309, g_loss: 1.0577\n",
            "Step [50980/80000], d_real_loss: 0.1504, d_mnist_loss: 0.0322, d_svhn_loss: 0.1182, d_fake_loss: 0.0401, g_loss: 1.1329\n",
            "Step [50990/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0127, d_svhn_loss: 0.0254, d_fake_loss: 0.0422, g_loss: 1.1384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7762730717658997, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [51000/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0148, d_svhn_loss: 0.0292, d_fake_loss: 0.1059, g_loss: 1.1177\n",
            "saved ./samples_fashion/sample-51000-m-s.png\n",
            "saved ./samples_fashion/sample-51000-s-m.png\n",
            "Step [51010/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0268, d_svhn_loss: 0.0330, d_fake_loss: 0.0545, g_loss: 1.0184\n",
            "Step [51020/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0129, d_svhn_loss: 0.0178, d_fake_loss: 0.0391, g_loss: 1.1848\n",
            "Step [51030/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0147, d_svhn_loss: 0.0729, d_fake_loss: 0.1499, g_loss: 1.2701\n",
            "Step [51040/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0201, d_svhn_loss: 0.0361, d_fake_loss: 0.0520, g_loss: 1.2930\n",
            "Step [51050/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0568, d_svhn_loss: 0.0208, d_fake_loss: 0.0483, g_loss: 1.4011\n",
            "Step [51060/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0400, d_svhn_loss: 0.0217, d_fake_loss: 0.0241, g_loss: 1.1838\n",
            "Step [51070/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0287, d_svhn_loss: 0.0498, d_fake_loss: 0.0775, g_loss: 1.2506\n",
            "Step [51080/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0168, d_svhn_loss: 0.0221, d_fake_loss: 0.0755, g_loss: 1.2142\n",
            "Step [51090/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0283, d_svhn_loss: 0.0362, d_fake_loss: 0.0671, g_loss: 1.0030\n",
            "Step [51100/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0159, d_svhn_loss: 0.0282, d_fake_loss: 0.0921, g_loss: 1.2822\n",
            "Step [51110/80000], d_real_loss: 0.1306, d_mnist_loss: 0.0637, d_svhn_loss: 0.0669, d_fake_loss: 0.0571, g_loss: 1.0433\n",
            "Step [51120/80000], d_real_loss: 0.1678, d_mnist_loss: 0.0737, d_svhn_loss: 0.0941, d_fake_loss: 0.0854, g_loss: 1.1282\n",
            "Step [51130/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0200, d_svhn_loss: 0.0194, d_fake_loss: 0.0641, g_loss: 1.2701\n",
            "Step [51140/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0226, d_svhn_loss: 0.0278, d_fake_loss: 0.0760, g_loss: 1.2187\n",
            "Step [51150/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0200, d_svhn_loss: 0.0475, d_fake_loss: 0.0727, g_loss: 1.2838\n",
            "Step [51160/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0336, d_svhn_loss: 0.0288, d_fake_loss: 0.1338, g_loss: 0.8330\n",
            "Step [51170/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0198, d_svhn_loss: 0.0236, d_fake_loss: 0.0309, g_loss: 1.0934\n",
            "Step [51180/80000], d_real_loss: 0.0862, d_mnist_loss: 0.0199, d_svhn_loss: 0.0663, d_fake_loss: 0.0357, g_loss: 1.2254\n",
            "Step [51190/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0134, d_svhn_loss: 0.0351, d_fake_loss: 0.0514, g_loss: 1.1692\n",
            "Step [51200/80000], d_real_loss: 0.1310, d_mnist_loss: 0.0996, d_svhn_loss: 0.0314, d_fake_loss: 0.0679, g_loss: 1.1688\n",
            "Step [51210/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0233, d_svhn_loss: 0.0391, d_fake_loss: 0.0356, g_loss: 1.2063\n",
            "Step [51220/80000], d_real_loss: 0.1389, d_mnist_loss: 0.0187, d_svhn_loss: 0.1201, d_fake_loss: 0.0722, g_loss: 1.2720\n",
            "Step [51230/80000], d_real_loss: 0.1460, d_mnist_loss: 0.0720, d_svhn_loss: 0.0740, d_fake_loss: 0.0288, g_loss: 0.9705\n",
            "Step [51240/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0216, d_svhn_loss: 0.0204, d_fake_loss: 0.0647, g_loss: 1.0413\n",
            "Step [51250/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0221, d_svhn_loss: 0.0156, d_fake_loss: 0.0570, g_loss: 1.0437\n",
            "Step [51260/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0152, d_svhn_loss: 0.0281, d_fake_loss: 0.0275, g_loss: 1.2170\n",
            "Step [51270/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0186, d_svhn_loss: 0.0230, d_fake_loss: 0.0616, g_loss: 1.0909\n",
            "Step [51280/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0365, d_svhn_loss: 0.0306, d_fake_loss: 0.0574, g_loss: 1.1361\n",
            "Step [51290/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0140, d_svhn_loss: 0.0241, d_fake_loss: 0.0439, g_loss: 1.1466\n",
            "Step [51300/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0281, d_svhn_loss: 0.0256, d_fake_loss: 0.0535, g_loss: 1.1801\n",
            "Step [51310/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0179, d_svhn_loss: 0.0186, d_fake_loss: 0.0480, g_loss: 1.0618\n",
            "Step [51320/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0161, d_svhn_loss: 0.0188, d_fake_loss: 0.0580, g_loss: 1.3585\n",
            "Step [51330/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0197, d_svhn_loss: 0.0202, d_fake_loss: 0.1843, g_loss: 1.1286\n",
            "Step [51340/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0321, d_svhn_loss: 0.0310, d_fake_loss: 0.0622, g_loss: 1.2375\n",
            "Step [51350/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0277, d_svhn_loss: 0.0234, d_fake_loss: 0.0888, g_loss: 1.2811\n",
            "Step [51360/80000], d_real_loss: 0.2069, d_mnist_loss: 0.1909, d_svhn_loss: 0.0160, d_fake_loss: 0.0604, g_loss: 1.1080\n",
            "Step [51370/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0358, d_svhn_loss: 0.0194, d_fake_loss: 0.1596, g_loss: 1.2351\n",
            "Step [51380/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0220, d_svhn_loss: 0.0211, d_fake_loss: 0.0781, g_loss: 1.1044\n",
            "Step [51390/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0404, d_svhn_loss: 0.0259, d_fake_loss: 0.0338, g_loss: 1.1629\n",
            "Step [51400/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0111, d_svhn_loss: 0.0365, d_fake_loss: 0.0280, g_loss: 1.1508\n",
            "Step [51410/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0186, d_svhn_loss: 0.0296, d_fake_loss: 0.0663, g_loss: 1.0707\n",
            "Step [51420/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0184, d_svhn_loss: 0.0154, d_fake_loss: 0.0371, g_loss: 1.2752\n",
            "Step [51430/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0160, d_svhn_loss: 0.0411, d_fake_loss: 0.0694, g_loss: 1.0848\n",
            "Step [51440/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0205, d_svhn_loss: 0.0279, d_fake_loss: 0.0291, g_loss: 1.0529\n",
            "Step [51450/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0175, d_svhn_loss: 0.0182, d_fake_loss: 0.0442, g_loss: 1.2645\n",
            "Step [51460/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0196, d_svhn_loss: 0.0525, d_fake_loss: 0.0669, g_loss: 1.2000\n",
            "Step [51470/80000], d_real_loss: 0.1150, d_mnist_loss: 0.0277, d_svhn_loss: 0.0872, d_fake_loss: 0.0242, g_loss: 1.0826\n",
            "Step [51480/80000], d_real_loss: 0.0261, d_mnist_loss: 0.0127, d_svhn_loss: 0.0134, d_fake_loss: 0.0245, g_loss: 1.1941\n",
            "Step [51490/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0148, d_svhn_loss: 0.0357, d_fake_loss: 0.0287, g_loss: 1.1167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7653409838676453, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [51500/80000], d_real_loss: 0.0968, d_mnist_loss: 0.0128, d_svhn_loss: 0.0840, d_fake_loss: 0.1354, g_loss: 1.1889\n",
            "saved ./samples_fashion/sample-51500-m-s.png\n",
            "saved ./samples_fashion/sample-51500-s-m.png\n",
            "Step [51510/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0296, d_svhn_loss: 0.0548, d_fake_loss: 0.0460, g_loss: 1.0226\n",
            "Step [51520/80000], d_real_loss: 0.1073, d_mnist_loss: 0.0582, d_svhn_loss: 0.0490, d_fake_loss: 0.0567, g_loss: 1.0550\n",
            "Step [51530/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0385, d_svhn_loss: 0.0193, d_fake_loss: 0.0343, g_loss: 1.2961\n",
            "Step [51540/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0155, d_svhn_loss: 0.0187, d_fake_loss: 0.0509, g_loss: 1.0245\n",
            "Step [51550/80000], d_real_loss: 0.0894, d_mnist_loss: 0.0623, d_svhn_loss: 0.0271, d_fake_loss: 0.0750, g_loss: 1.4104\n",
            "Step [51560/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0181, d_svhn_loss: 0.0399, d_fake_loss: 0.0751, g_loss: 0.9401\n",
            "Step [51570/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0193, d_svhn_loss: 0.0202, d_fake_loss: 0.0427, g_loss: 1.1937\n",
            "Step [51580/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0157, d_svhn_loss: 0.0184, d_fake_loss: 0.0389, g_loss: 1.2536\n",
            "Step [51590/80000], d_real_loss: 0.0978, d_mnist_loss: 0.0764, d_svhn_loss: 0.0215, d_fake_loss: 0.0336, g_loss: 1.0528\n",
            "Step [51600/80000], d_real_loss: 0.0929, d_mnist_loss: 0.0511, d_svhn_loss: 0.0418, d_fake_loss: 0.0318, g_loss: 1.2157\n",
            "Step [51610/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0176, d_svhn_loss: 0.0235, d_fake_loss: 0.0494, g_loss: 1.2125\n",
            "Step [51620/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0232, d_svhn_loss: 0.0531, d_fake_loss: 0.0314, g_loss: 1.2265\n",
            "Step [51630/80000], d_real_loss: 0.1258, d_mnist_loss: 0.1125, d_svhn_loss: 0.0133, d_fake_loss: 0.0540, g_loss: 1.1573\n",
            "Step [51640/80000], d_real_loss: 0.0661, d_mnist_loss: 0.0486, d_svhn_loss: 0.0175, d_fake_loss: 0.0603, g_loss: 1.1395\n",
            "Step [51650/80000], d_real_loss: 0.1352, d_mnist_loss: 0.0379, d_svhn_loss: 0.0973, d_fake_loss: 0.0598, g_loss: 1.0388\n",
            "Step [51660/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0206, d_svhn_loss: 0.0197, d_fake_loss: 0.0486, g_loss: 1.2061\n",
            "Step [51670/80000], d_real_loss: 0.1001, d_mnist_loss: 0.0407, d_svhn_loss: 0.0594, d_fake_loss: 0.0300, g_loss: 0.9609\n",
            "Step [51680/80000], d_real_loss: 0.1176, d_mnist_loss: 0.0966, d_svhn_loss: 0.0210, d_fake_loss: 0.0445, g_loss: 1.2532\n",
            "Step [51690/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0260, d_svhn_loss: 0.0308, d_fake_loss: 0.0264, g_loss: 1.1425\n",
            "Step [51700/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0249, d_svhn_loss: 0.0273, d_fake_loss: 0.0357, g_loss: 0.9778\n",
            "Step [51710/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0215, d_svhn_loss: 0.0336, d_fake_loss: 0.0343, g_loss: 1.0793\n",
            "Step [51720/80000], d_real_loss: 0.1191, d_mnist_loss: 0.0203, d_svhn_loss: 0.0987, d_fake_loss: 0.1511, g_loss: 1.2050\n",
            "Step [51730/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0423, d_svhn_loss: 0.0172, d_fake_loss: 0.0649, g_loss: 1.0653\n",
            "Step [51740/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0186, d_svhn_loss: 0.0306, d_fake_loss: 0.0877, g_loss: 1.3231\n",
            "Step [51750/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0123, d_svhn_loss: 0.0192, d_fake_loss: 0.0430, g_loss: 1.2011\n",
            "Step [51760/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0354, d_svhn_loss: 0.0182, d_fake_loss: 0.0335, g_loss: 1.0210\n",
            "Step [51770/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0180, d_svhn_loss: 0.0332, d_fake_loss: 0.0434, g_loss: 1.0792\n",
            "Step [51780/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0226, d_svhn_loss: 0.0158, d_fake_loss: 0.0305, g_loss: 1.1399\n",
            "Step [51790/80000], d_real_loss: 0.1116, d_mnist_loss: 0.0181, d_svhn_loss: 0.0936, d_fake_loss: 0.0920, g_loss: 1.0201\n",
            "Step [51800/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0274, d_svhn_loss: 0.0145, d_fake_loss: 0.0376, g_loss: 1.2183\n",
            "Step [51810/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0247, d_svhn_loss: 0.0191, d_fake_loss: 0.0392, g_loss: 1.1930\n",
            "Step [51820/80000], d_real_loss: 0.0972, d_mnist_loss: 0.0301, d_svhn_loss: 0.0671, d_fake_loss: 0.1843, g_loss: 1.3038\n",
            "Step [51830/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0234, d_svhn_loss: 0.0189, d_fake_loss: 0.0364, g_loss: 1.0740\n",
            "Step [51840/80000], d_real_loss: 0.0848, d_mnist_loss: 0.0179, d_svhn_loss: 0.0670, d_fake_loss: 0.0397, g_loss: 1.1093\n",
            "Step [51850/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0211, d_svhn_loss: 0.0120, d_fake_loss: 0.0370, g_loss: 1.1610\n",
            "Step [51860/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0297, d_svhn_loss: 0.0161, d_fake_loss: 0.0323, g_loss: 1.1161\n",
            "Step [51870/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0281, d_svhn_loss: 0.0321, d_fake_loss: 0.0839, g_loss: 1.1655\n",
            "Step [51880/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0203, d_svhn_loss: 0.0379, d_fake_loss: 0.0290, g_loss: 1.2237\n",
            "Step [51890/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0176, d_svhn_loss: 0.0199, d_fake_loss: 0.0387, g_loss: 1.0863\n",
            "Step [51900/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0269, d_svhn_loss: 0.0272, d_fake_loss: 0.1934, g_loss: 0.9010\n",
            "Step [51910/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0226, d_svhn_loss: 0.0130, d_fake_loss: 0.0371, g_loss: 1.1083\n",
            "Step [51920/80000], d_real_loss: 0.0807, d_mnist_loss: 0.0164, d_svhn_loss: 0.0642, d_fake_loss: 0.0295, g_loss: 1.0821\n",
            "Step [51930/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0313, d_svhn_loss: 0.0256, d_fake_loss: 0.0666, g_loss: 1.2039\n",
            "Step [51940/80000], d_real_loss: 0.0836, d_mnist_loss: 0.0472, d_svhn_loss: 0.0364, d_fake_loss: 0.0586, g_loss: 1.1859\n",
            "Step [51950/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0158, d_svhn_loss: 0.0237, d_fake_loss: 0.1013, g_loss: 1.2070\n",
            "Step [51960/80000], d_real_loss: 0.1213, d_mnist_loss: 0.0378, d_svhn_loss: 0.0835, d_fake_loss: 0.0386, g_loss: 0.9857\n",
            "Step [51970/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0509, d_svhn_loss: 0.0187, d_fake_loss: 0.0331, g_loss: 1.0485\n",
            "Step [51980/80000], d_real_loss: 0.0796, d_mnist_loss: 0.0547, d_svhn_loss: 0.0249, d_fake_loss: 0.0703, g_loss: 1.0727\n",
            "Step [51990/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0169, d_svhn_loss: 0.0434, d_fake_loss: 0.0473, g_loss: 1.0925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8343881368637085, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [52000/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0176, d_svhn_loss: 0.0168, d_fake_loss: 0.0616, g_loss: 1.1035\n",
            "saved ./samples_fashion/sample-52000-m-s.png\n",
            "saved ./samples_fashion/sample-52000-s-m.png\n",
            "Step [52010/80000], d_real_loss: 0.0971, d_mnist_loss: 0.0559, d_svhn_loss: 0.0412, d_fake_loss: 0.0292, g_loss: 0.9844\n",
            "Step [52020/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0194, d_svhn_loss: 0.0237, d_fake_loss: 0.0375, g_loss: 1.1685\n",
            "Step [52030/80000], d_real_loss: 0.1074, d_mnist_loss: 0.0678, d_svhn_loss: 0.0396, d_fake_loss: 0.0484, g_loss: 1.0514\n",
            "Step [52040/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0204, d_svhn_loss: 0.0204, d_fake_loss: 0.0579, g_loss: 1.1771\n",
            "Step [52050/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0284, d_svhn_loss: 0.0220, d_fake_loss: 0.0526, g_loss: 1.1995\n",
            "Step [52060/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0140, d_svhn_loss: 0.0189, d_fake_loss: 0.0726, g_loss: 1.0027\n",
            "Step [52070/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0367, d_svhn_loss: 0.0215, d_fake_loss: 0.0490, g_loss: 1.1638\n",
            "Step [52080/80000], d_real_loss: 0.1550, d_mnist_loss: 0.0754, d_svhn_loss: 0.0796, d_fake_loss: 0.0296, g_loss: 1.1075\n",
            "Step [52090/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0252, d_svhn_loss: 0.0201, d_fake_loss: 0.0359, g_loss: 1.2681\n",
            "Step [52100/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0140, d_svhn_loss: 0.0150, d_fake_loss: 0.0605, g_loss: 1.1906\n",
            "Step [52110/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0278, d_svhn_loss: 0.0202, d_fake_loss: 0.0378, g_loss: 0.9879\n",
            "Step [52120/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0163, d_svhn_loss: 0.0227, d_fake_loss: 0.0429, g_loss: 1.2608\n",
            "Step [52130/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0306, d_svhn_loss: 0.0255, d_fake_loss: 0.0498, g_loss: 1.0766\n",
            "Step [52140/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0282, d_svhn_loss: 0.0196, d_fake_loss: 0.0593, g_loss: 1.2824\n",
            "Step [52150/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0224, d_svhn_loss: 0.0145, d_fake_loss: 0.0612, g_loss: 1.0400\n",
            "Step [52160/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0237, d_svhn_loss: 0.0179, d_fake_loss: 0.1108, g_loss: 1.2751\n",
            "Step [52170/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0148, d_svhn_loss: 0.0258, d_fake_loss: 0.0638, g_loss: 1.2311\n",
            "Step [52180/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0295, d_svhn_loss: 0.0136, d_fake_loss: 0.0503, g_loss: 1.3036\n",
            "Step [52190/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0225, d_svhn_loss: 0.0192, d_fake_loss: 0.0353, g_loss: 1.0881\n",
            "Step [52200/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0140, d_svhn_loss: 0.0209, d_fake_loss: 0.0657, g_loss: 1.0928\n",
            "Step [52210/80000], d_real_loss: 0.0749, d_mnist_loss: 0.0225, d_svhn_loss: 0.0524, d_fake_loss: 0.0518, g_loss: 1.1670\n",
            "Step [52220/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0230, d_svhn_loss: 0.0201, d_fake_loss: 0.0485, g_loss: 1.1628\n",
            "Step [52230/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0177, d_svhn_loss: 0.0351, d_fake_loss: 0.0395, g_loss: 1.2474\n",
            "Step [52240/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0145, d_svhn_loss: 0.0176, d_fake_loss: 0.0990, g_loss: 1.1239\n",
            "Step [52250/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0191, d_svhn_loss: 0.0166, d_fake_loss: 0.0511, g_loss: 1.1491\n",
            "Step [52260/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0221, d_svhn_loss: 0.0350, d_fake_loss: 0.0285, g_loss: 1.0444\n",
            "Step [52270/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0227, d_svhn_loss: 0.0159, d_fake_loss: 0.0833, g_loss: 1.1624\n",
            "Step [52280/80000], d_real_loss: 0.1056, d_mnist_loss: 0.0176, d_svhn_loss: 0.0880, d_fake_loss: 0.0425, g_loss: 1.2282\n",
            "Step [52290/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0167, d_svhn_loss: 0.0397, d_fake_loss: 0.0743, g_loss: 1.1427\n",
            "Step [52300/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0221, d_svhn_loss: 0.0401, d_fake_loss: 0.1063, g_loss: 1.1719\n",
            "Step [52310/80000], d_real_loss: 0.0803, d_mnist_loss: 0.0168, d_svhn_loss: 0.0636, d_fake_loss: 0.0372, g_loss: 1.1762\n",
            "Step [52320/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0204, d_svhn_loss: 0.0263, d_fake_loss: 0.0405, g_loss: 1.1250\n",
            "Step [52330/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0387, d_svhn_loss: 0.0149, d_fake_loss: 0.0352, g_loss: 1.0267\n",
            "Step [52340/80000], d_real_loss: 0.0258, d_mnist_loss: 0.0128, d_svhn_loss: 0.0130, d_fake_loss: 0.0260, g_loss: 1.1455\n",
            "Step [52350/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0134, d_svhn_loss: 0.0204, d_fake_loss: 0.0267, g_loss: 1.0996\n",
            "Step [52360/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0208, d_svhn_loss: 0.0414, d_fake_loss: 0.0364, g_loss: 1.3262\n",
            "Step [52370/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0681, d_svhn_loss: 0.0196, d_fake_loss: 0.0399, g_loss: 1.1202\n",
            "Step [52380/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0304, d_svhn_loss: 0.0287, d_fake_loss: 0.0459, g_loss: 1.2363\n",
            "Step [52390/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0174, d_svhn_loss: 0.0502, d_fake_loss: 0.1109, g_loss: 1.0407\n",
            "Step [52400/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0334, d_svhn_loss: 0.0221, d_fake_loss: 0.0730, g_loss: 1.2247\n",
            "Step [52410/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0164, d_svhn_loss: 0.0417, d_fake_loss: 0.0281, g_loss: 1.1173\n",
            "Step [52420/80000], d_real_loss: 0.0780, d_mnist_loss: 0.0488, d_svhn_loss: 0.0291, d_fake_loss: 0.0795, g_loss: 1.1953\n",
            "Step [52430/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0161, d_svhn_loss: 0.0382, d_fake_loss: 0.0878, g_loss: 1.1977\n",
            "Step [52440/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0154, d_svhn_loss: 0.0230, d_fake_loss: 0.0273, g_loss: 1.1184\n",
            "Step [52450/80000], d_real_loss: 0.1266, d_mnist_loss: 0.0198, d_svhn_loss: 0.1068, d_fake_loss: 0.0494, g_loss: 1.0949\n",
            "Step [52460/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0180, d_svhn_loss: 0.0279, d_fake_loss: 0.0647, g_loss: 1.1150\n",
            "Step [52470/80000], d_real_loss: 0.1093, d_mnist_loss: 0.0541, d_svhn_loss: 0.0552, d_fake_loss: 0.0575, g_loss: 1.2111\n",
            "Step [52480/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0394, d_svhn_loss: 0.0331, d_fake_loss: 0.1043, g_loss: 1.4737\n",
            "Step [52490/80000], d_real_loss: 0.0930, d_mnist_loss: 0.0594, d_svhn_loss: 0.0335, d_fake_loss: 0.0357, g_loss: 1.0433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8582578897476196, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [52500/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0320, d_svhn_loss: 0.0367, d_fake_loss: 0.0594, g_loss: 1.0561\n",
            "saved ./samples_fashion/sample-52500-m-s.png\n",
            "saved ./samples_fashion/sample-52500-s-m.png\n",
            "Step [52510/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0292, d_svhn_loss: 0.0222, d_fake_loss: 0.0500, g_loss: 1.0149\n",
            "Step [52520/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0372, d_svhn_loss: 0.0276, d_fake_loss: 0.0450, g_loss: 1.0756\n",
            "Step [52530/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0163, d_svhn_loss: 0.0393, d_fake_loss: 0.0318, g_loss: 1.0776\n",
            "Step [52540/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0196, d_svhn_loss: 0.0341, d_fake_loss: 0.0334, g_loss: 1.2168\n",
            "Step [52550/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0709, d_svhn_loss: 0.0201, d_fake_loss: 0.0696, g_loss: 1.0304\n",
            "Step [52560/80000], d_real_loss: 0.1405, d_mnist_loss: 0.1020, d_svhn_loss: 0.0385, d_fake_loss: 0.0338, g_loss: 0.8913\n",
            "Step [52570/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0175, d_svhn_loss: 0.0189, d_fake_loss: 0.0443, g_loss: 1.2855\n",
            "Step [52580/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0242, d_svhn_loss: 0.0159, d_fake_loss: 0.0383, g_loss: 1.2457\n",
            "Step [52590/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0205, d_svhn_loss: 0.0222, d_fake_loss: 0.0923, g_loss: 1.2985\n",
            "Step [52600/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0207, d_svhn_loss: 0.0349, d_fake_loss: 0.0408, g_loss: 1.1430\n",
            "Step [52610/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0437, d_svhn_loss: 0.0215, d_fake_loss: 0.0659, g_loss: 1.1057\n",
            "Step [52620/80000], d_real_loss: 0.0816, d_mnist_loss: 0.0104, d_svhn_loss: 0.0712, d_fake_loss: 0.0338, g_loss: 1.0625\n",
            "Step [52630/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0150, d_svhn_loss: 0.0371, d_fake_loss: 0.0234, g_loss: 1.1262\n",
            "Step [52640/80000], d_real_loss: 0.0824, d_mnist_loss: 0.0587, d_svhn_loss: 0.0237, d_fake_loss: 0.0465, g_loss: 1.0676\n",
            "Step [52650/80000], d_real_loss: 0.0798, d_mnist_loss: 0.0120, d_svhn_loss: 0.0678, d_fake_loss: 0.0771, g_loss: 1.2361\n",
            "Step [52660/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0281, d_svhn_loss: 0.0204, d_fake_loss: 0.0835, g_loss: 0.9746\n",
            "Step [52670/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0213, d_svhn_loss: 0.0169, d_fake_loss: 0.0719, g_loss: 1.2158\n",
            "Step [52680/80000], d_real_loss: 0.0707, d_mnist_loss: 0.0257, d_svhn_loss: 0.0450, d_fake_loss: 0.1147, g_loss: 1.1056\n",
            "Step [52690/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0361, d_svhn_loss: 0.0261, d_fake_loss: 0.0323, g_loss: 1.0544\n",
            "Step [52700/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0233, d_svhn_loss: 0.0316, d_fake_loss: 0.1100, g_loss: 1.2118\n",
            "Step [52710/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0125, d_svhn_loss: 0.0561, d_fake_loss: 0.0300, g_loss: 1.0992\n",
            "Step [52720/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0279, d_svhn_loss: 0.0147, d_fake_loss: 0.0386, g_loss: 1.3252\n",
            "Step [52730/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0177, d_svhn_loss: 0.0507, d_fake_loss: 0.0634, g_loss: 1.0907\n",
            "Step [52740/80000], d_real_loss: 0.0862, d_mnist_loss: 0.0686, d_svhn_loss: 0.0175, d_fake_loss: 0.0763, g_loss: 1.1831\n",
            "Step [52750/80000], d_real_loss: 0.0860, d_mnist_loss: 0.0203, d_svhn_loss: 0.0657, d_fake_loss: 0.0318, g_loss: 1.2040\n",
            "Step [52760/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0434, d_svhn_loss: 0.0178, d_fake_loss: 0.0359, g_loss: 1.0339\n",
            "Step [52770/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0193, d_svhn_loss: 0.0291, d_fake_loss: 0.0278, g_loss: 1.0203\n",
            "Step [52780/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0204, d_svhn_loss: 0.0201, d_fake_loss: 0.0483, g_loss: 1.1755\n",
            "Step [52790/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0159, d_svhn_loss: 0.0572, d_fake_loss: 0.0643, g_loss: 1.0302\n",
            "Step [52800/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0148, d_svhn_loss: 0.0200, d_fake_loss: 0.0432, g_loss: 1.0428\n",
            "Step [52810/80000], d_real_loss: 0.0862, d_mnist_loss: 0.0415, d_svhn_loss: 0.0447, d_fake_loss: 0.0873, g_loss: 1.4318\n",
            "Step [52820/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0231, d_svhn_loss: 0.0350, d_fake_loss: 0.0860, g_loss: 1.2686\n",
            "Step [52830/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0490, d_svhn_loss: 0.0210, d_fake_loss: 0.0347, g_loss: 1.2613\n",
            "Step [52840/80000], d_real_loss: 0.1238, d_mnist_loss: 0.0786, d_svhn_loss: 0.0452, d_fake_loss: 0.1125, g_loss: 1.1574\n",
            "Step [52850/80000], d_real_loss: 0.1365, d_mnist_loss: 0.1185, d_svhn_loss: 0.0179, d_fake_loss: 0.0404, g_loss: 1.1492\n",
            "Step [52860/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0226, d_svhn_loss: 0.0280, d_fake_loss: 0.1143, g_loss: 0.8525\n",
            "Step [52870/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0184, d_svhn_loss: 0.0144, d_fake_loss: 0.0484, g_loss: 1.1926\n",
            "Step [52880/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0152, d_svhn_loss: 0.0125, d_fake_loss: 0.0222, g_loss: 1.0925\n",
            "Step [52890/80000], d_real_loss: 0.0913, d_mnist_loss: 0.0257, d_svhn_loss: 0.0656, d_fake_loss: 0.0365, g_loss: 1.2408\n",
            "Step [52900/80000], d_real_loss: 0.1046, d_mnist_loss: 0.0864, d_svhn_loss: 0.0182, d_fake_loss: 0.0259, g_loss: 1.0495\n",
            "Step [52910/80000], d_real_loss: 0.1005, d_mnist_loss: 0.0485, d_svhn_loss: 0.0520, d_fake_loss: 0.0740, g_loss: 1.0390\n",
            "Step [52920/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0342, d_svhn_loss: 0.0153, d_fake_loss: 0.0633, g_loss: 1.2044\n",
            "Step [52930/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0140, d_svhn_loss: 0.0176, d_fake_loss: 0.0427, g_loss: 1.1594\n",
            "Step [52940/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0140, d_svhn_loss: 0.0197, d_fake_loss: 0.0328, g_loss: 1.1485\n",
            "Step [52950/80000], d_real_loss: 0.1047, d_mnist_loss: 0.0124, d_svhn_loss: 0.0923, d_fake_loss: 0.0626, g_loss: 1.1362\n",
            "Step [52960/80000], d_real_loss: 0.1132, d_mnist_loss: 0.0811, d_svhn_loss: 0.0320, d_fake_loss: 0.1098, g_loss: 1.3183\n",
            "Step [52970/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0286, d_svhn_loss: 0.0163, d_fake_loss: 0.0250, g_loss: 1.2167\n",
            "Step [52980/80000], d_real_loss: 0.0746, d_mnist_loss: 0.0600, d_svhn_loss: 0.0146, d_fake_loss: 0.0370, g_loss: 1.2806\n",
            "Step [52990/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0200, d_svhn_loss: 0.0193, d_fake_loss: 0.0330, g_loss: 1.1694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7521764039993286, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [53000/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0267, d_svhn_loss: 0.0196, d_fake_loss: 0.0373, g_loss: 1.3623\n",
            "saved ./samples_fashion/sample-53000-m-s.png\n",
            "saved ./samples_fashion/sample-53000-s-m.png\n",
            "Step [53010/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0229, d_svhn_loss: 0.0166, d_fake_loss: 0.0344, g_loss: 1.2552\n",
            "Step [53020/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0150, d_svhn_loss: 0.0670, d_fake_loss: 0.1043, g_loss: 1.2351\n",
            "Step [53030/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0228, d_svhn_loss: 0.0262, d_fake_loss: 0.0281, g_loss: 1.2005\n",
            "Step [53040/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0309, d_svhn_loss: 0.0123, d_fake_loss: 0.0970, g_loss: 1.4730\n",
            "Step [53050/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0357, d_svhn_loss: 0.0170, d_fake_loss: 0.1184, g_loss: 1.1202\n",
            "Step [53060/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0194, d_svhn_loss: 0.0205, d_fake_loss: 0.0531, g_loss: 1.2558\n",
            "Step [53070/80000], d_real_loss: 0.1183, d_mnist_loss: 0.0657, d_svhn_loss: 0.0526, d_fake_loss: 0.0980, g_loss: 1.3121\n",
            "Step [53080/80000], d_real_loss: 0.0819, d_mnist_loss: 0.0576, d_svhn_loss: 0.0243, d_fake_loss: 0.0401, g_loss: 0.9870\n",
            "Step [53090/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0236, d_svhn_loss: 0.0193, d_fake_loss: 0.1585, g_loss: 1.0771\n",
            "Step [53100/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0274, d_svhn_loss: 0.0172, d_fake_loss: 0.1602, g_loss: 1.3067\n",
            "Step [53110/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0160, d_svhn_loss: 0.0466, d_fake_loss: 0.0600, g_loss: 1.1348\n",
            "Step [53120/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0139, d_svhn_loss: 0.0298, d_fake_loss: 0.0529, g_loss: 1.3271\n",
            "Step [53130/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0390, d_svhn_loss: 0.0206, d_fake_loss: 0.0219, g_loss: 1.1413\n",
            "Step [53140/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0226, d_svhn_loss: 0.0207, d_fake_loss: 0.0316, g_loss: 1.2691\n",
            "Step [53150/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0169, d_svhn_loss: 0.0402, d_fake_loss: 0.0543, g_loss: 1.3938\n",
            "Step [53160/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0224, d_svhn_loss: 0.0112, d_fake_loss: 0.0439, g_loss: 1.0601\n",
            "Step [53170/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0246, d_svhn_loss: 0.0165, d_fake_loss: 0.0307, g_loss: 1.1429\n",
            "Step [53180/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0509, d_svhn_loss: 0.0392, d_fake_loss: 0.0406, g_loss: 0.9985\n",
            "Step [53190/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0613, d_svhn_loss: 0.0230, d_fake_loss: 0.0264, g_loss: 0.9963\n",
            "Step [53200/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0203, d_svhn_loss: 0.0227, d_fake_loss: 0.0637, g_loss: 1.0489\n",
            "Step [53210/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0326, d_svhn_loss: 0.0254, d_fake_loss: 0.0472, g_loss: 1.2058\n",
            "Step [53220/80000], d_real_loss: 0.0933, d_mnist_loss: 0.0187, d_svhn_loss: 0.0745, d_fake_loss: 0.0301, g_loss: 1.2152\n",
            "Step [53230/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0273, d_svhn_loss: 0.0332, d_fake_loss: 0.0416, g_loss: 1.1043\n",
            "Step [53240/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0495, d_svhn_loss: 0.0230, d_fake_loss: 0.0575, g_loss: 1.1459\n",
            "Step [53250/80000], d_real_loss: 0.1012, d_mnist_loss: 0.0589, d_svhn_loss: 0.0423, d_fake_loss: 0.0652, g_loss: 1.0698\n",
            "Step [53260/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0543, d_svhn_loss: 0.0147, d_fake_loss: 0.0908, g_loss: 1.0598\n",
            "Step [53270/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0299, d_svhn_loss: 0.0223, d_fake_loss: 0.0234, g_loss: 1.0237\n",
            "Step [53280/80000], d_real_loss: 0.1158, d_mnist_loss: 0.0867, d_svhn_loss: 0.0291, d_fake_loss: 0.0315, g_loss: 1.1148\n",
            "Step [53290/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0286, d_svhn_loss: 0.0187, d_fake_loss: 0.0242, g_loss: 1.0639\n",
            "Step [53300/80000], d_real_loss: 0.0942, d_mnist_loss: 0.0157, d_svhn_loss: 0.0785, d_fake_loss: 0.0673, g_loss: 1.2298\n",
            "Step [53310/80000], d_real_loss: 0.0746, d_mnist_loss: 0.0564, d_svhn_loss: 0.0182, d_fake_loss: 0.0291, g_loss: 1.1057\n",
            "Step [53320/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0267, d_svhn_loss: 0.0507, d_fake_loss: 0.0795, g_loss: 1.3674\n",
            "Step [53330/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0512, d_svhn_loss: 0.0140, d_fake_loss: 0.0846, g_loss: 1.0836\n",
            "Step [53340/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0409, d_svhn_loss: 0.0189, d_fake_loss: 0.0610, g_loss: 1.0697\n",
            "Step [53350/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0258, d_svhn_loss: 0.0183, d_fake_loss: 0.0264, g_loss: 1.1099\n",
            "Step [53360/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0203, d_svhn_loss: 0.0160, d_fake_loss: 0.0451, g_loss: 1.1260\n",
            "Step [53370/80000], d_real_loss: 0.0932, d_mnist_loss: 0.0616, d_svhn_loss: 0.0316, d_fake_loss: 0.0529, g_loss: 1.0815\n",
            "Step [53380/80000], d_real_loss: 0.0990, d_mnist_loss: 0.0383, d_svhn_loss: 0.0607, d_fake_loss: 0.0963, g_loss: 1.2157\n",
            "Step [53390/80000], d_real_loss: 0.1180, d_mnist_loss: 0.0236, d_svhn_loss: 0.0944, d_fake_loss: 0.0919, g_loss: 1.0727\n",
            "Step [53400/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0207, d_svhn_loss: 0.0154, d_fake_loss: 0.0921, g_loss: 1.2227\n",
            "Step [53410/80000], d_real_loss: 0.1194, d_mnist_loss: 0.0362, d_svhn_loss: 0.0832, d_fake_loss: 0.0341, g_loss: 1.1184\n",
            "Step [53420/80000], d_real_loss: 0.0972, d_mnist_loss: 0.0256, d_svhn_loss: 0.0716, d_fake_loss: 0.0651, g_loss: 1.2116\n",
            "Step [53430/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0257, d_svhn_loss: 0.0239, d_fake_loss: 0.0613, g_loss: 1.0360\n",
            "Step [53440/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0191, d_svhn_loss: 0.0451, d_fake_loss: 0.0309, g_loss: 1.2451\n",
            "Step [53450/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0284, d_svhn_loss: 0.0170, d_fake_loss: 0.0309, g_loss: 1.0840\n",
            "Step [53460/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0176, d_svhn_loss: 0.0266, d_fake_loss: 0.0451, g_loss: 1.0805\n",
            "Step [53470/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0203, d_svhn_loss: 0.0199, d_fake_loss: 0.0260, g_loss: 1.1548\n",
            "Step [53480/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0333, d_svhn_loss: 0.0196, d_fake_loss: 0.0376, g_loss: 1.2302\n",
            "Step [53490/80000], d_real_loss: 0.0857, d_mnist_loss: 0.0290, d_svhn_loss: 0.0567, d_fake_loss: 0.0453, g_loss: 1.0710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.786596953868866, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [53500/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0413, d_svhn_loss: 0.0152, d_fake_loss: 0.0287, g_loss: 1.1004\n",
            "saved ./samples_fashion/sample-53500-m-s.png\n",
            "saved ./samples_fashion/sample-53500-s-m.png\n",
            "Step [53510/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0180, d_svhn_loss: 0.0365, d_fake_loss: 0.0361, g_loss: 1.0044\n",
            "Step [53520/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0258, d_svhn_loss: 0.0582, d_fake_loss: 0.0266, g_loss: 1.0466\n",
            "Step [53530/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0181, d_svhn_loss: 0.0391, d_fake_loss: 0.0847, g_loss: 1.2202\n",
            "Step [53540/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0262, d_svhn_loss: 0.0149, d_fake_loss: 0.0312, g_loss: 1.0959\n",
            "Step [53550/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0363, d_svhn_loss: 0.0162, d_fake_loss: 0.0385, g_loss: 1.3105\n",
            "Step [53560/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0333, d_svhn_loss: 0.0137, d_fake_loss: 0.0568, g_loss: 1.1544\n",
            "Step [53570/80000], d_real_loss: 0.1542, d_mnist_loss: 0.0569, d_svhn_loss: 0.0973, d_fake_loss: 0.2163, g_loss: 0.8557\n",
            "Step [53580/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0208, d_svhn_loss: 0.0236, d_fake_loss: 0.0940, g_loss: 0.8762\n",
            "Step [53590/80000], d_real_loss: 0.0955, d_mnist_loss: 0.0664, d_svhn_loss: 0.0291, d_fake_loss: 0.0689, g_loss: 1.5767\n",
            "Step [53600/80000], d_real_loss: 0.1340, d_mnist_loss: 0.0981, d_svhn_loss: 0.0359, d_fake_loss: 0.0354, g_loss: 0.9603\n",
            "Step [53610/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0201, d_svhn_loss: 0.0167, d_fake_loss: 0.0549, g_loss: 1.1926\n",
            "Step [53620/80000], d_real_loss: 0.1442, d_mnist_loss: 0.0201, d_svhn_loss: 0.1241, d_fake_loss: 0.1288, g_loss: 1.2096\n",
            "Step [53630/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0207, d_svhn_loss: 0.0235, d_fake_loss: 0.0682, g_loss: 1.2173\n",
            "Step [53640/80000], d_real_loss: 0.0983, d_mnist_loss: 0.0194, d_svhn_loss: 0.0790, d_fake_loss: 0.0933, g_loss: 1.2468\n",
            "Step [53650/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0432, d_svhn_loss: 0.0374, d_fake_loss: 0.0303, g_loss: 1.1812\n",
            "Step [53660/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0437, d_svhn_loss: 0.0290, d_fake_loss: 0.0382, g_loss: 1.0391\n",
            "Step [53670/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0121, d_svhn_loss: 0.0248, d_fake_loss: 0.0555, g_loss: 1.2282\n",
            "Step [53680/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0194, d_svhn_loss: 0.0332, d_fake_loss: 0.1047, g_loss: 1.2598\n",
            "Step [53690/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0177, d_svhn_loss: 0.0412, d_fake_loss: 0.0370, g_loss: 1.2067\n",
            "Step [53700/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0185, d_svhn_loss: 0.0288, d_fake_loss: 0.0284, g_loss: 1.2072\n",
            "Step [53710/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0242, d_svhn_loss: 0.0253, d_fake_loss: 0.0356, g_loss: 1.0847\n",
            "Step [53720/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0208, d_svhn_loss: 0.0269, d_fake_loss: 0.0369, g_loss: 1.1620\n",
            "Step [53730/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0471, d_svhn_loss: 0.0212, d_fake_loss: 0.1440, g_loss: 1.2692\n",
            "Step [53740/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0238, d_svhn_loss: 0.0168, d_fake_loss: 0.0450, g_loss: 1.1436\n",
            "Step [53750/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0139, d_svhn_loss: 0.0155, d_fake_loss: 0.0328, g_loss: 1.1062\n",
            "Step [53760/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0256, d_svhn_loss: 0.0329, d_fake_loss: 0.0275, g_loss: 1.2341\n",
            "Step [53770/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0266, d_svhn_loss: 0.0162, d_fake_loss: 0.0639, g_loss: 1.3191\n",
            "Step [53780/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0185, d_svhn_loss: 0.0277, d_fake_loss: 0.1589, g_loss: 1.2986\n",
            "Step [53790/80000], d_real_loss: 0.0746, d_mnist_loss: 0.0384, d_svhn_loss: 0.0362, d_fake_loss: 0.0511, g_loss: 1.0089\n",
            "Step [53800/80000], d_real_loss: 0.0995, d_mnist_loss: 0.0551, d_svhn_loss: 0.0444, d_fake_loss: 0.0593, g_loss: 1.3524\n",
            "Step [53810/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0133, d_svhn_loss: 0.0371, d_fake_loss: 0.0361, g_loss: 1.0100\n",
            "Step [53820/80000], d_real_loss: 0.1399, d_mnist_loss: 0.0402, d_svhn_loss: 0.0998, d_fake_loss: 0.1340, g_loss: 1.0708\n",
            "Step [53830/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0354, d_svhn_loss: 0.0197, d_fake_loss: 0.0211, g_loss: 1.0520\n",
            "Step [53840/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0200, d_svhn_loss: 0.0167, d_fake_loss: 0.0270, g_loss: 1.1547\n",
            "Step [53850/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0371, d_svhn_loss: 0.0278, d_fake_loss: 0.0628, g_loss: 1.3161\n",
            "Step [53860/80000], d_real_loss: 0.0925, d_mnist_loss: 0.0674, d_svhn_loss: 0.0251, d_fake_loss: 0.0729, g_loss: 1.1401\n",
            "Step [53870/80000], d_real_loss: 0.1498, d_mnist_loss: 0.0323, d_svhn_loss: 0.1175, d_fake_loss: 0.0564, g_loss: 0.8794\n",
            "Step [53880/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0179, d_svhn_loss: 0.0366, d_fake_loss: 0.0556, g_loss: 1.0499\n",
            "Step [53890/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0215, d_svhn_loss: 0.0210, d_fake_loss: 0.0215, g_loss: 1.1195\n",
            "Step [53900/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0240, d_svhn_loss: 0.0216, d_fake_loss: 0.0257, g_loss: 1.0276\n",
            "Step [53910/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0233, d_svhn_loss: 0.0330, d_fake_loss: 0.1118, g_loss: 1.1581\n",
            "Step [53920/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0257, d_svhn_loss: 0.0271, d_fake_loss: 0.0277, g_loss: 1.1579\n",
            "Step [53930/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0230, d_svhn_loss: 0.0337, d_fake_loss: 0.0940, g_loss: 1.2571\n",
            "Step [53940/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0169, d_svhn_loss: 0.0175, d_fake_loss: 0.0453, g_loss: 1.0749\n",
            "Step [53950/80000], d_real_loss: 0.0951, d_mnist_loss: 0.0735, d_svhn_loss: 0.0216, d_fake_loss: 0.0243, g_loss: 1.0994\n",
            "Step [53960/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0147, d_svhn_loss: 0.0210, d_fake_loss: 0.0323, g_loss: 1.1067\n",
            "Step [53970/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0448, d_svhn_loss: 0.0243, d_fake_loss: 0.0324, g_loss: 1.0454\n",
            "Step [53980/80000], d_real_loss: 0.0749, d_mnist_loss: 0.0285, d_svhn_loss: 0.0464, d_fake_loss: 0.0397, g_loss: 0.9500\n",
            "Step [53990/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0124, d_svhn_loss: 0.0272, d_fake_loss: 0.1509, g_loss: 1.0261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8337343335151672, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [54000/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0210, d_svhn_loss: 0.0197, d_fake_loss: 0.0552, g_loss: 1.0294\n",
            "saved ./samples_fashion/sample-54000-m-s.png\n",
            "saved ./samples_fashion/sample-54000-s-m.png\n",
            "Step [54010/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0310, d_svhn_loss: 0.0230, d_fake_loss: 0.1181, g_loss: 1.3410\n",
            "Step [54020/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0206, d_svhn_loss: 0.0334, d_fake_loss: 0.0310, g_loss: 1.1473\n",
            "Step [54030/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0207, d_svhn_loss: 0.0287, d_fake_loss: 0.0474, g_loss: 1.1353\n",
            "Step [54040/80000], d_real_loss: 0.0847, d_mnist_loss: 0.0304, d_svhn_loss: 0.0543, d_fake_loss: 0.0634, g_loss: 0.8537\n",
            "Step [54050/80000], d_real_loss: 0.1143, d_mnist_loss: 0.0195, d_svhn_loss: 0.0948, d_fake_loss: 0.0491, g_loss: 1.1076\n",
            "Step [54060/80000], d_real_loss: 0.1288, d_mnist_loss: 0.0434, d_svhn_loss: 0.0854, d_fake_loss: 0.0350, g_loss: 1.0335\n",
            "Step [54070/80000], d_real_loss: 0.0798, d_mnist_loss: 0.0208, d_svhn_loss: 0.0590, d_fake_loss: 0.0580, g_loss: 1.1339\n",
            "Step [54080/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0152, d_svhn_loss: 0.0272, d_fake_loss: 0.0459, g_loss: 1.0441\n",
            "Step [54090/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0348, d_svhn_loss: 0.0185, d_fake_loss: 0.0730, g_loss: 1.2661\n",
            "Step [54100/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0195, d_svhn_loss: 0.0271, d_fake_loss: 0.0345, g_loss: 1.3417\n",
            "Step [54110/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0528, d_svhn_loss: 0.0249, d_fake_loss: 0.0943, g_loss: 1.1185\n",
            "Step [54120/80000], d_real_loss: 0.1090, d_mnist_loss: 0.0383, d_svhn_loss: 0.0707, d_fake_loss: 0.0319, g_loss: 1.2790\n",
            "Step [54130/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0317, d_svhn_loss: 0.0277, d_fake_loss: 0.0479, g_loss: 1.3008\n",
            "Step [54140/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0173, d_svhn_loss: 0.0219, d_fake_loss: 0.0509, g_loss: 1.1591\n",
            "Step [54150/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0393, d_svhn_loss: 0.0349, d_fake_loss: 0.0702, g_loss: 1.3022\n",
            "Step [54160/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0166, d_svhn_loss: 0.0282, d_fake_loss: 0.0413, g_loss: 1.0790\n",
            "Step [54170/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0188, d_svhn_loss: 0.0228, d_fake_loss: 0.0536, g_loss: 0.9668\n",
            "Step [54180/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0262, d_svhn_loss: 0.0192, d_fake_loss: 0.0606, g_loss: 1.3168\n",
            "Step [54190/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0165, d_svhn_loss: 0.0428, d_fake_loss: 0.0225, g_loss: 1.1950\n",
            "Step [54200/80000], d_real_loss: 0.0826, d_mnist_loss: 0.0592, d_svhn_loss: 0.0235, d_fake_loss: 0.0285, g_loss: 1.0954\n",
            "Step [54210/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0194, d_svhn_loss: 0.0312, d_fake_loss: 0.0484, g_loss: 1.1951\n",
            "Step [54220/80000], d_real_loss: 0.1219, d_mnist_loss: 0.0293, d_svhn_loss: 0.0926, d_fake_loss: 0.0372, g_loss: 1.0927\n",
            "Step [54230/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0120, d_svhn_loss: 0.0429, d_fake_loss: 0.0713, g_loss: 1.1459\n",
            "Step [54240/80000], d_real_loss: 0.0940, d_mnist_loss: 0.0406, d_svhn_loss: 0.0534, d_fake_loss: 0.0808, g_loss: 1.1385\n",
            "Step [54250/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0112, d_svhn_loss: 0.0569, d_fake_loss: 0.1020, g_loss: 1.1292\n",
            "Step [54260/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0420, d_svhn_loss: 0.0230, d_fake_loss: 0.0211, g_loss: 1.0721\n",
            "Step [54270/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0319, d_svhn_loss: 0.0284, d_fake_loss: 0.0315, g_loss: 1.2848\n",
            "Step [54280/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0172, d_svhn_loss: 0.0191, d_fake_loss: 0.0384, g_loss: 1.1689\n",
            "Step [54290/80000], d_real_loss: 0.2252, d_mnist_loss: 0.0265, d_svhn_loss: 0.1988, d_fake_loss: 0.0450, g_loss: 1.1040\n",
            "Step [54300/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0417, d_svhn_loss: 0.0123, d_fake_loss: 0.0485, g_loss: 0.9780\n",
            "Step [54310/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0309, d_svhn_loss: 0.0223, d_fake_loss: 0.0648, g_loss: 1.0538\n",
            "Step [54320/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0135, d_svhn_loss: 0.0173, d_fake_loss: 0.0397, g_loss: 1.0121\n",
            "Step [54330/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0278, d_svhn_loss: 0.0230, d_fake_loss: 0.0487, g_loss: 0.9853\n",
            "Step [54340/80000], d_real_loss: 0.2060, d_mnist_loss: 0.1852, d_svhn_loss: 0.0208, d_fake_loss: 0.0421, g_loss: 1.3576\n",
            "Step [54350/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0190, d_svhn_loss: 0.0202, d_fake_loss: 0.0698, g_loss: 1.3061\n",
            "Step [54360/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0120, d_svhn_loss: 0.0164, d_fake_loss: 0.0871, g_loss: 1.2170\n",
            "Step [54370/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0220, d_svhn_loss: 0.0144, d_fake_loss: 0.0351, g_loss: 1.2788\n",
            "Step [54380/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0353, d_svhn_loss: 0.0272, d_fake_loss: 0.0378, g_loss: 1.2052\n",
            "Step [54390/80000], d_real_loss: 0.0908, d_mnist_loss: 0.0636, d_svhn_loss: 0.0271, d_fake_loss: 0.0439, g_loss: 1.0923\n",
            "Step [54400/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0224, d_svhn_loss: 0.0356, d_fake_loss: 0.0349, g_loss: 1.0496\n",
            "Step [54410/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0195, d_svhn_loss: 0.0175, d_fake_loss: 0.0975, g_loss: 1.3276\n",
            "Step [54420/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0230, d_svhn_loss: 0.0250, d_fake_loss: 0.0505, g_loss: 1.0922\n",
            "Step [54430/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0236, d_svhn_loss: 0.0291, d_fake_loss: 0.0309, g_loss: 1.2041\n",
            "Step [54440/80000], d_real_loss: 0.0712, d_mnist_loss: 0.0274, d_svhn_loss: 0.0438, d_fake_loss: 0.1337, g_loss: 1.1455\n",
            "Step [54450/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0237, d_svhn_loss: 0.0460, d_fake_loss: 0.0296, g_loss: 1.0466\n",
            "Step [54460/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0180, d_svhn_loss: 0.0168, d_fake_loss: 0.0411, g_loss: 1.1645\n",
            "Step [54470/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0160, d_svhn_loss: 0.0183, d_fake_loss: 0.0484, g_loss: 1.2597\n",
            "Step [54480/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0168, d_svhn_loss: 0.0411, d_fake_loss: 0.0583, g_loss: 1.3536\n",
            "Step [54490/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0285, d_svhn_loss: 0.0417, d_fake_loss: 0.0397, g_loss: 1.1443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7742003202438354, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [54500/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0289, d_svhn_loss: 0.0440, d_fake_loss: 0.2645, g_loss: 1.4200\n",
            "saved ./samples_fashion/sample-54500-m-s.png\n",
            "saved ./samples_fashion/sample-54500-s-m.png\n",
            "Step [54510/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0169, d_svhn_loss: 0.0272, d_fake_loss: 0.0424, g_loss: 1.3251\n",
            "Step [54520/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0482, d_svhn_loss: 0.0191, d_fake_loss: 0.0804, g_loss: 1.0650\n",
            "Step [54530/80000], d_real_loss: 0.0878, d_mnist_loss: 0.0562, d_svhn_loss: 0.0316, d_fake_loss: 0.0456, g_loss: 1.1200\n",
            "Step [54540/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0294, d_svhn_loss: 0.0512, d_fake_loss: 0.0349, g_loss: 0.9247\n",
            "Step [54550/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0170, d_svhn_loss: 0.0196, d_fake_loss: 0.0333, g_loss: 1.0194\n",
            "Step [54560/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0354, d_svhn_loss: 0.0340, d_fake_loss: 0.0349, g_loss: 1.2128\n",
            "Step [54570/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0231, d_svhn_loss: 0.0263, d_fake_loss: 0.0527, g_loss: 1.0548\n",
            "Step [54580/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0136, d_svhn_loss: 0.0149, d_fake_loss: 0.0361, g_loss: 1.1134\n",
            "Step [54590/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0228, d_svhn_loss: 0.0243, d_fake_loss: 0.0591, g_loss: 1.2208\n",
            "Step [54600/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0192, d_svhn_loss: 0.0233, d_fake_loss: 0.0400, g_loss: 1.0763\n",
            "Step [54610/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0166, d_svhn_loss: 0.0227, d_fake_loss: 0.0346, g_loss: 1.1628\n",
            "Step [54620/80000], d_real_loss: 0.1056, d_mnist_loss: 0.0611, d_svhn_loss: 0.0445, d_fake_loss: 0.1036, g_loss: 1.0537\n",
            "Step [54630/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0302, d_svhn_loss: 0.0221, d_fake_loss: 0.0256, g_loss: 1.2201\n",
            "Step [54640/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0560, d_svhn_loss: 0.0317, d_fake_loss: 0.0432, g_loss: 1.0145\n",
            "Step [54650/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0205, d_svhn_loss: 0.0414, d_fake_loss: 0.0795, g_loss: 1.0693\n",
            "Step [54660/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0300, d_svhn_loss: 0.0243, d_fake_loss: 0.0455, g_loss: 0.9788\n",
            "Step [54670/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0135, d_svhn_loss: 0.0215, d_fake_loss: 0.0266, g_loss: 1.0869\n",
            "Step [54680/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0192, d_svhn_loss: 0.0213, d_fake_loss: 0.1011, g_loss: 1.2921\n",
            "Step [54690/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0192, d_svhn_loss: 0.0180, d_fake_loss: 0.0249, g_loss: 1.2037\n",
            "Step [54700/80000], d_real_loss: 0.1028, d_mnist_loss: 0.0121, d_svhn_loss: 0.0907, d_fake_loss: 0.0411, g_loss: 1.0933\n",
            "Step [54710/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0208, d_svhn_loss: 0.0238, d_fake_loss: 0.0219, g_loss: 1.1159\n",
            "Step [54720/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0206, d_svhn_loss: 0.0136, d_fake_loss: 0.0355, g_loss: 1.1207\n",
            "Step [54730/80000], d_real_loss: 0.0385, d_mnist_loss: 0.0142, d_svhn_loss: 0.0242, d_fake_loss: 0.0290, g_loss: 1.1373\n",
            "Step [54740/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0738, d_svhn_loss: 0.0162, d_fake_loss: 0.0320, g_loss: 1.2319\n",
            "Step [54750/80000], d_real_loss: 0.0715, d_mnist_loss: 0.0454, d_svhn_loss: 0.0261, d_fake_loss: 0.0332, g_loss: 1.1772\n",
            "Step [54760/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0227, d_svhn_loss: 0.0216, d_fake_loss: 0.0235, g_loss: 1.1724\n",
            "Step [54770/80000], d_real_loss: 0.0990, d_mnist_loss: 0.0818, d_svhn_loss: 0.0172, d_fake_loss: 0.0719, g_loss: 1.0872\n",
            "Step [54780/80000], d_real_loss: 0.1200, d_mnist_loss: 0.0388, d_svhn_loss: 0.0813, d_fake_loss: 0.0358, g_loss: 1.1355\n",
            "Step [54790/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0168, d_svhn_loss: 0.0287, d_fake_loss: 0.0615, g_loss: 1.3404\n",
            "Step [54800/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0193, d_svhn_loss: 0.0457, d_fake_loss: 0.0380, g_loss: 1.2883\n",
            "Step [54810/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0170, d_svhn_loss: 0.0182, d_fake_loss: 0.0505, g_loss: 1.2010\n",
            "Step [54820/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0130, d_svhn_loss: 0.0241, d_fake_loss: 0.0385, g_loss: 1.2138\n",
            "Step [54830/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0111, d_svhn_loss: 0.0184, d_fake_loss: 0.1260, g_loss: 1.2743\n",
            "Step [54840/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0185, d_svhn_loss: 0.0218, d_fake_loss: 0.0211, g_loss: 1.1524\n",
            "Step [54850/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0140, d_svhn_loss: 0.0188, d_fake_loss: 0.0613, g_loss: 1.1518\n",
            "Step [54860/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0105, d_svhn_loss: 0.0258, d_fake_loss: 0.0266, g_loss: 1.1017\n",
            "Step [54870/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0248, d_svhn_loss: 0.0151, d_fake_loss: 0.0761, g_loss: 1.2027\n",
            "Step [54880/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0181, d_svhn_loss: 0.0357, d_fake_loss: 0.0576, g_loss: 1.1866\n",
            "Step [54890/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0268, d_svhn_loss: 0.0181, d_fake_loss: 0.0557, g_loss: 1.2141\n",
            "Step [54900/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0158, d_svhn_loss: 0.0204, d_fake_loss: 0.0434, g_loss: 1.2353\n",
            "Step [54910/80000], d_real_loss: 0.1260, d_mnist_loss: 0.0281, d_svhn_loss: 0.0979, d_fake_loss: 0.0417, g_loss: 1.1962\n",
            "Step [54920/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0149, d_svhn_loss: 0.0459, d_fake_loss: 0.0562, g_loss: 1.1493\n",
            "Step [54930/80000], d_real_loss: 0.0997, d_mnist_loss: 0.0772, d_svhn_loss: 0.0224, d_fake_loss: 0.0385, g_loss: 1.1000\n",
            "Step [54940/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0194, d_svhn_loss: 0.0225, d_fake_loss: 0.0241, g_loss: 1.0406\n",
            "Step [54950/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0139, d_svhn_loss: 0.0196, d_fake_loss: 0.0600, g_loss: 1.0450\n",
            "Step [54960/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0210, d_svhn_loss: 0.0565, d_fake_loss: 0.0469, g_loss: 1.1825\n",
            "Step [54970/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0208, d_svhn_loss: 0.0444, d_fake_loss: 0.0963, g_loss: 1.1807\n",
            "Step [54980/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0265, d_svhn_loss: 0.0265, d_fake_loss: 0.1089, g_loss: 1.2541\n",
            "Step [54990/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0465, d_svhn_loss: 0.0181, d_fake_loss: 0.0604, g_loss: 1.2161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7868863344192505, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [55000/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0204, d_svhn_loss: 0.0184, d_fake_loss: 0.1682, g_loss: 1.1931\n",
            "saved ./samples_fashion/sample-55000-m-s.png\n",
            "saved ./samples_fashion/sample-55000-s-m.png\n",
            "Step [55010/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0174, d_svhn_loss: 0.0179, d_fake_loss: 0.0499, g_loss: 1.2843\n",
            "Step [55020/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0217, d_svhn_loss: 0.0162, d_fake_loss: 0.0384, g_loss: 1.2870\n",
            "Step [55030/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0143, d_svhn_loss: 0.0484, d_fake_loss: 0.0360, g_loss: 1.1003\n",
            "Step [55040/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0205, d_svhn_loss: 0.0277, d_fake_loss: 0.0703, g_loss: 1.0750\n",
            "Step [55050/80000], d_real_loss: 0.1487, d_mnist_loss: 0.0484, d_svhn_loss: 0.1003, d_fake_loss: 0.1000, g_loss: 0.9682\n",
            "Step [55060/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0325, d_svhn_loss: 0.0484, d_fake_loss: 0.0279, g_loss: 1.1155\n",
            "Step [55070/80000], d_real_loss: 0.0849, d_mnist_loss: 0.0660, d_svhn_loss: 0.0189, d_fake_loss: 0.1043, g_loss: 1.1695\n",
            "Step [55080/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0149, d_svhn_loss: 0.0719, d_fake_loss: 0.0922, g_loss: 1.0987\n",
            "Step [55090/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0384, d_svhn_loss: 0.0135, d_fake_loss: 0.0461, g_loss: 1.0985\n",
            "Step [55100/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0151, d_svhn_loss: 0.0341, d_fake_loss: 0.0508, g_loss: 1.1302\n",
            "Step [55110/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0251, d_svhn_loss: 0.0227, d_fake_loss: 0.0455, g_loss: 1.2459\n",
            "Step [55120/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0198, d_svhn_loss: 0.0217, d_fake_loss: 0.0334, g_loss: 1.1054\n",
            "Step [55130/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0316, d_svhn_loss: 0.0168, d_fake_loss: 0.0748, g_loss: 0.9947\n",
            "Step [55140/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0258, d_svhn_loss: 0.0221, d_fake_loss: 0.1663, g_loss: 1.3380\n",
            "Step [55150/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0187, d_svhn_loss: 0.0314, d_fake_loss: 0.0585, g_loss: 1.3570\n",
            "Step [55160/80000], d_real_loss: 0.0626, d_mnist_loss: 0.0463, d_svhn_loss: 0.0162, d_fake_loss: 0.0508, g_loss: 1.1609\n",
            "Step [55170/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0230, d_svhn_loss: 0.0175, d_fake_loss: 0.0384, g_loss: 1.0528\n",
            "Step [55180/80000], d_real_loss: 0.0980, d_mnist_loss: 0.0769, d_svhn_loss: 0.0211, d_fake_loss: 0.0628, g_loss: 1.1995\n",
            "Step [55190/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0213, d_svhn_loss: 0.0174, d_fake_loss: 0.0723, g_loss: 1.2748\n",
            "Step [55200/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0182, d_svhn_loss: 0.0438, d_fake_loss: 0.0460, g_loss: 1.2235\n",
            "Step [55210/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0220, d_svhn_loss: 0.0223, d_fake_loss: 0.0268, g_loss: 1.2305\n",
            "Step [55220/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0305, d_svhn_loss: 0.0144, d_fake_loss: 0.0431, g_loss: 1.3199\n",
            "Step [55230/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0265, d_svhn_loss: 0.0486, d_fake_loss: 0.0662, g_loss: 0.9647\n",
            "Step [55240/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0191, d_svhn_loss: 0.0552, d_fake_loss: 0.0843, g_loss: 1.0757\n",
            "Step [55250/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0178, d_svhn_loss: 0.0552, d_fake_loss: 0.0702, g_loss: 1.5458\n",
            "Step [55260/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0147, d_svhn_loss: 0.0133, d_fake_loss: 0.0868, g_loss: 1.2979\n",
            "Step [55270/80000], d_real_loss: 0.0816, d_mnist_loss: 0.0152, d_svhn_loss: 0.0664, d_fake_loss: 0.0408, g_loss: 1.2432\n",
            "Step [55280/80000], d_real_loss: 0.0979, d_mnist_loss: 0.0470, d_svhn_loss: 0.0509, d_fake_loss: 0.1968, g_loss: 1.3253\n",
            "Step [55290/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0237, d_svhn_loss: 0.0385, d_fake_loss: 0.0349, g_loss: 0.9760\n",
            "Step [55300/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0213, d_svhn_loss: 0.0262, d_fake_loss: 0.0478, g_loss: 1.1801\n",
            "Step [55310/80000], d_real_loss: 0.0870, d_mnist_loss: 0.0674, d_svhn_loss: 0.0196, d_fake_loss: 0.0578, g_loss: 1.1420\n",
            "Step [55320/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0125, d_svhn_loss: 0.0231, d_fake_loss: 0.0855, g_loss: 1.2492\n",
            "Step [55330/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0325, d_svhn_loss: 0.0188, d_fake_loss: 0.0470, g_loss: 1.2772\n",
            "Step [55340/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0158, d_svhn_loss: 0.0218, d_fake_loss: 0.0423, g_loss: 1.1465\n",
            "Step [55350/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0147, d_svhn_loss: 0.0179, d_fake_loss: 0.0495, g_loss: 1.2453\n",
            "Step [55360/80000], d_real_loss: 0.1510, d_mnist_loss: 0.0292, d_svhn_loss: 0.1218, d_fake_loss: 0.0433, g_loss: 1.0586\n",
            "Step [55370/80000], d_real_loss: 0.0243, d_mnist_loss: 0.0117, d_svhn_loss: 0.0126, d_fake_loss: 0.0315, g_loss: 1.2018\n",
            "Step [55380/80000], d_real_loss: 0.1027, d_mnist_loss: 0.0857, d_svhn_loss: 0.0170, d_fake_loss: 0.0288, g_loss: 0.9376\n",
            "Step [55390/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0161, d_svhn_loss: 0.0147, d_fake_loss: 0.0264, g_loss: 1.1376\n",
            "Step [55400/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0145, d_svhn_loss: 0.0425, d_fake_loss: 0.0605, g_loss: 1.1378\n",
            "Step [55410/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0201, d_svhn_loss: 0.0318, d_fake_loss: 0.0304, g_loss: 1.1281\n",
            "Step [55420/80000], d_real_loss: 0.1107, d_mnist_loss: 0.0924, d_svhn_loss: 0.0183, d_fake_loss: 0.0647, g_loss: 1.2453\n",
            "Step [55430/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0359, d_svhn_loss: 0.0154, d_fake_loss: 0.0274, g_loss: 1.0890\n",
            "Step [55440/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0397, d_svhn_loss: 0.0269, d_fake_loss: 0.0964, g_loss: 1.2097\n",
            "Step [55450/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0308, d_svhn_loss: 0.0214, d_fake_loss: 0.0248, g_loss: 1.2074\n",
            "Step [55460/80000], d_real_loss: 0.1065, d_mnist_loss: 0.0131, d_svhn_loss: 0.0934, d_fake_loss: 0.0479, g_loss: 1.2092\n",
            "Step [55470/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0154, d_svhn_loss: 0.0185, d_fake_loss: 0.1523, g_loss: 1.3649\n",
            "Step [55480/80000], d_real_loss: 0.1089, d_mnist_loss: 0.0915, d_svhn_loss: 0.0173, d_fake_loss: 0.0258, g_loss: 1.1130\n",
            "Step [55490/80000], d_real_loss: 0.1485, d_mnist_loss: 0.0523, d_svhn_loss: 0.0962, d_fake_loss: 0.0545, g_loss: 1.4219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7593050599098206, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [55500/80000], d_real_loss: 0.0924, d_mnist_loss: 0.0194, d_svhn_loss: 0.0730, d_fake_loss: 0.0385, g_loss: 1.1217\n",
            "saved ./samples_fashion/sample-55500-m-s.png\n",
            "saved ./samples_fashion/sample-55500-s-m.png\n",
            "Step [55510/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0196, d_svhn_loss: 0.0589, d_fake_loss: 0.0421, g_loss: 1.0884\n",
            "Step [55520/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0385, d_svhn_loss: 0.0168, d_fake_loss: 0.0478, g_loss: 1.1799\n",
            "Step [55530/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0167, d_svhn_loss: 0.0484, d_fake_loss: 0.0345, g_loss: 1.1358\n",
            "Step [55540/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0619, d_svhn_loss: 0.0225, d_fake_loss: 0.1554, g_loss: 1.3793\n",
            "Step [55550/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0228, d_svhn_loss: 0.0199, d_fake_loss: 0.0392, g_loss: 1.0983\n",
            "Step [55560/80000], d_real_loss: 0.0904, d_mnist_loss: 0.0613, d_svhn_loss: 0.0290, d_fake_loss: 0.0458, g_loss: 1.0685\n",
            "Step [55570/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0296, d_svhn_loss: 0.0363, d_fake_loss: 0.1258, g_loss: 1.0693\n",
            "Step [55580/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0174, d_svhn_loss: 0.0447, d_fake_loss: 0.0402, g_loss: 1.1748\n",
            "Step [55590/80000], d_real_loss: 0.1446, d_mnist_loss: 0.1250, d_svhn_loss: 0.0196, d_fake_loss: 0.0875, g_loss: 1.6771\n",
            "Step [55600/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0197, d_svhn_loss: 0.0284, d_fake_loss: 0.0381, g_loss: 1.1065\n",
            "Step [55610/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0233, d_svhn_loss: 0.0175, d_fake_loss: 0.0529, g_loss: 1.1031\n",
            "Step [55620/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0263, d_svhn_loss: 0.0274, d_fake_loss: 0.0754, g_loss: 1.1610\n",
            "Step [55630/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0380, d_svhn_loss: 0.0342, d_fake_loss: 0.0623, g_loss: 1.1993\n",
            "Step [55640/80000], d_real_loss: 0.0712, d_mnist_loss: 0.0380, d_svhn_loss: 0.0333, d_fake_loss: 0.0452, g_loss: 1.0016\n",
            "Step [55650/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0254, d_svhn_loss: 0.0340, d_fake_loss: 0.0351, g_loss: 1.2440\n",
            "Step [55660/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0199, d_svhn_loss: 0.0305, d_fake_loss: 0.0536, g_loss: 1.0036\n",
            "Step [55670/80000], d_real_loss: 0.0914, d_mnist_loss: 0.0348, d_svhn_loss: 0.0566, d_fake_loss: 0.0440, g_loss: 1.1186\n",
            "Step [55680/80000], d_real_loss: 0.0942, d_mnist_loss: 0.0794, d_svhn_loss: 0.0147, d_fake_loss: 0.0369, g_loss: 1.0122\n",
            "Step [55690/80000], d_real_loss: 0.0839, d_mnist_loss: 0.0597, d_svhn_loss: 0.0241, d_fake_loss: 0.0408, g_loss: 1.2698\n",
            "Step [55700/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0200, d_svhn_loss: 0.0282, d_fake_loss: 0.0389, g_loss: 1.1847\n",
            "Step [55710/80000], d_real_loss: 0.0822, d_mnist_loss: 0.0621, d_svhn_loss: 0.0201, d_fake_loss: 0.0369, g_loss: 1.1836\n",
            "Step [55720/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0260, d_svhn_loss: 0.0424, d_fake_loss: 0.0299, g_loss: 1.1159\n",
            "Step [55730/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0272, d_svhn_loss: 0.0171, d_fake_loss: 0.0770, g_loss: 1.1611\n",
            "Step [55740/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0489, d_svhn_loss: 0.0162, d_fake_loss: 0.0718, g_loss: 0.8923\n",
            "Step [55750/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0450, d_svhn_loss: 0.0180, d_fake_loss: 0.0432, g_loss: 1.1369\n",
            "Step [55760/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0264, d_svhn_loss: 0.0150, d_fake_loss: 0.0726, g_loss: 1.2926\n",
            "Step [55770/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0183, d_svhn_loss: 0.0328, d_fake_loss: 0.0476, g_loss: 1.2429\n",
            "Step [55780/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0164, d_svhn_loss: 0.0162, d_fake_loss: 0.0221, g_loss: 1.2014\n",
            "Step [55790/80000], d_real_loss: 0.1665, d_mnist_loss: 0.0766, d_svhn_loss: 0.0900, d_fake_loss: 0.0542, g_loss: 1.0181\n",
            "Step [55800/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0225, d_svhn_loss: 0.0155, d_fake_loss: 0.0221, g_loss: 1.1319\n",
            "Step [55810/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0185, d_svhn_loss: 0.0231, d_fake_loss: 0.0490, g_loss: 1.1839\n",
            "Step [55820/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0216, d_svhn_loss: 0.0241, d_fake_loss: 0.0489, g_loss: 1.0579\n",
            "Step [55830/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0239, d_svhn_loss: 0.0197, d_fake_loss: 0.0833, g_loss: 1.1905\n",
            "Step [55840/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0188, d_svhn_loss: 0.0446, d_fake_loss: 0.0491, g_loss: 1.2009\n",
            "Step [55850/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0411, d_svhn_loss: 0.0167, d_fake_loss: 0.1540, g_loss: 1.4555\n",
            "Step [55860/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0264, d_svhn_loss: 0.0212, d_fake_loss: 0.0405, g_loss: 1.0989\n",
            "Step [55870/80000], d_real_loss: 0.1374, d_mnist_loss: 0.1109, d_svhn_loss: 0.0265, d_fake_loss: 0.0459, g_loss: 1.1818\n",
            "Step [55880/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0124, d_svhn_loss: 0.0171, d_fake_loss: 0.0257, g_loss: 1.1336\n",
            "Step [55890/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0178, d_svhn_loss: 0.0313, d_fake_loss: 0.0612, g_loss: 1.2642\n",
            "Step [55900/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0330, d_svhn_loss: 0.0263, d_fake_loss: 0.0471, g_loss: 1.1731\n",
            "Step [55910/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0156, d_svhn_loss: 0.0224, d_fake_loss: 0.0229, g_loss: 1.0635\n",
            "Step [55920/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0346, d_svhn_loss: 0.0256, d_fake_loss: 0.0405, g_loss: 1.4394\n",
            "Step [55930/80000], d_real_loss: 0.0772, d_mnist_loss: 0.0325, d_svhn_loss: 0.0447, d_fake_loss: 0.0453, g_loss: 1.1247\n",
            "Step [55940/80000], d_real_loss: 0.1450, d_mnist_loss: 0.0356, d_svhn_loss: 0.1094, d_fake_loss: 0.0343, g_loss: 1.1038\n",
            "Step [55950/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0172, d_svhn_loss: 0.0222, d_fake_loss: 0.0610, g_loss: 1.2281\n",
            "Step [55960/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0518, d_svhn_loss: 0.0165, d_fake_loss: 0.0421, g_loss: 1.1591\n",
            "Step [55970/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0331, d_svhn_loss: 0.0262, d_fake_loss: 0.0474, g_loss: 1.0613\n",
            "Step [55980/80000], d_real_loss: 0.0909, d_mnist_loss: 0.0294, d_svhn_loss: 0.0616, d_fake_loss: 0.0831, g_loss: 1.1817\n",
            "Step [55990/80000], d_real_loss: 0.1096, d_mnist_loss: 0.0755, d_svhn_loss: 0.0341, d_fake_loss: 0.0770, g_loss: 1.2960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.771722674369812, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [56000/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0219, d_svhn_loss: 0.0268, d_fake_loss: 0.0401, g_loss: 1.2805\n",
            "saved ./samples_fashion/sample-56000-m-s.png\n",
            "saved ./samples_fashion/sample-56000-s-m.png\n",
            "Step [56010/80000], d_real_loss: 0.1195, d_mnist_loss: 0.0849, d_svhn_loss: 0.0346, d_fake_loss: 0.1330, g_loss: 1.1407\n",
            "Step [56020/80000], d_real_loss: 0.1390, d_mnist_loss: 0.0676, d_svhn_loss: 0.0714, d_fake_loss: 0.0514, g_loss: 0.9600\n",
            "Step [56030/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0434, d_svhn_loss: 0.0195, d_fake_loss: 0.0440, g_loss: 1.0662\n",
            "Step [56040/80000], d_real_loss: 0.0970, d_mnist_loss: 0.0248, d_svhn_loss: 0.0722, d_fake_loss: 0.0592, g_loss: 1.1855\n",
            "Step [56050/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0458, d_svhn_loss: 0.0118, d_fake_loss: 0.0276, g_loss: 1.1302\n",
            "Step [56060/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0208, d_svhn_loss: 0.0199, d_fake_loss: 0.0716, g_loss: 1.2478\n",
            "Step [56070/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0123, d_svhn_loss: 0.0190, d_fake_loss: 0.0330, g_loss: 1.1508\n",
            "Step [56080/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0503, d_svhn_loss: 0.0259, d_fake_loss: 0.0541, g_loss: 1.0181\n",
            "Step [56090/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0147, d_svhn_loss: 0.0236, d_fake_loss: 0.0856, g_loss: 1.2827\n",
            "Step [56100/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0305, d_svhn_loss: 0.0336, d_fake_loss: 0.0602, g_loss: 1.2629\n",
            "Step [56110/80000], d_real_loss: 0.2101, d_mnist_loss: 0.1711, d_svhn_loss: 0.0390, d_fake_loss: 0.0594, g_loss: 1.0482\n",
            "Step [56120/80000], d_real_loss: 0.0776, d_mnist_loss: 0.0268, d_svhn_loss: 0.0508, d_fake_loss: 0.0716, g_loss: 1.0881\n",
            "Step [56130/80000], d_real_loss: 0.1334, d_mnist_loss: 0.0169, d_svhn_loss: 0.1164, d_fake_loss: 0.0704, g_loss: 1.1414\n",
            "Step [56140/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0178, d_svhn_loss: 0.0194, d_fake_loss: 0.0702, g_loss: 0.9783\n",
            "Step [56150/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0191, d_svhn_loss: 0.0161, d_fake_loss: 0.0370, g_loss: 1.1666\n",
            "Step [56160/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0168, d_svhn_loss: 0.0224, d_fake_loss: 0.0724, g_loss: 1.1305\n",
            "Step [56170/80000], d_real_loss: 0.1106, d_mnist_loss: 0.0328, d_svhn_loss: 0.0778, d_fake_loss: 0.0903, g_loss: 1.1024\n",
            "Step [56180/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0286, d_svhn_loss: 0.0649, d_fake_loss: 0.0400, g_loss: 1.0767\n",
            "Step [56190/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0156, d_svhn_loss: 0.0630, d_fake_loss: 0.0530, g_loss: 1.2783\n",
            "Step [56200/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0204, d_svhn_loss: 0.0355, d_fake_loss: 0.0445, g_loss: 1.3302\n",
            "Step [56210/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0194, d_svhn_loss: 0.0306, d_fake_loss: 0.0376, g_loss: 1.1618\n",
            "Step [56220/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0267, d_svhn_loss: 0.0169, d_fake_loss: 0.0920, g_loss: 1.1379\n",
            "Step [56230/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0173, d_svhn_loss: 0.0231, d_fake_loss: 0.0738, g_loss: 1.0267\n",
            "Step [56240/80000], d_real_loss: 0.0757, d_mnist_loss: 0.0298, d_svhn_loss: 0.0459, d_fake_loss: 0.0315, g_loss: 1.0973\n",
            "Step [56250/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0180, d_svhn_loss: 0.0210, d_fake_loss: 0.0394, g_loss: 1.1507\n",
            "Step [56260/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0363, d_svhn_loss: 0.0240, d_fake_loss: 0.0486, g_loss: 1.3039\n",
            "Step [56270/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0121, d_svhn_loss: 0.0612, d_fake_loss: 0.0440, g_loss: 1.0779\n",
            "Step [56280/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0291, d_svhn_loss: 0.0232, d_fake_loss: 0.0659, g_loss: 1.0511\n",
            "Step [56290/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0245, d_svhn_loss: 0.0211, d_fake_loss: 0.0439, g_loss: 1.2016\n",
            "Step [56300/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0276, d_svhn_loss: 0.0310, d_fake_loss: 0.0757, g_loss: 1.1945\n",
            "Step [56310/80000], d_real_loss: 0.1131, d_mnist_loss: 0.0459, d_svhn_loss: 0.0672, d_fake_loss: 0.0862, g_loss: 1.1019\n",
            "Step [56320/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0240, d_svhn_loss: 0.0254, d_fake_loss: 0.0547, g_loss: 1.2369\n",
            "Step [56330/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0138, d_svhn_loss: 0.0157, d_fake_loss: 0.0321, g_loss: 1.2253\n",
            "Step [56340/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0259, d_svhn_loss: 0.0239, d_fake_loss: 0.0404, g_loss: 0.9919\n",
            "Step [56350/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0381, d_svhn_loss: 0.0182, d_fake_loss: 0.0582, g_loss: 1.0796\n",
            "Step [56360/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0140, d_svhn_loss: 0.0761, d_fake_loss: 0.0266, g_loss: 1.1054\n",
            "Step [56370/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0286, d_svhn_loss: 0.0190, d_fake_loss: 0.1401, g_loss: 1.4074\n",
            "Step [56380/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0316, d_svhn_loss: 0.0181, d_fake_loss: 0.0674, g_loss: 1.3385\n",
            "Step [56390/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0137, d_svhn_loss: 0.0168, d_fake_loss: 0.0994, g_loss: 1.2045\n",
            "Step [56400/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0146, d_svhn_loss: 0.0145, d_fake_loss: 0.0576, g_loss: 1.1588\n",
            "Step [56410/80000], d_real_loss: 0.0971, d_mnist_loss: 0.0273, d_svhn_loss: 0.0698, d_fake_loss: 0.0314, g_loss: 1.1164\n",
            "Step [56420/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0181, d_svhn_loss: 0.0296, d_fake_loss: 0.0334, g_loss: 1.0997\n",
            "Step [56430/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0366, d_svhn_loss: 0.0128, d_fake_loss: 0.0457, g_loss: 1.0467\n",
            "Step [56440/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0280, d_svhn_loss: 0.0161, d_fake_loss: 0.0315, g_loss: 1.1000\n",
            "Step [56450/80000], d_real_loss: 0.0951, d_mnist_loss: 0.0344, d_svhn_loss: 0.0607, d_fake_loss: 0.1028, g_loss: 0.9563\n",
            "Step [56460/80000], d_real_loss: 0.0939, d_mnist_loss: 0.0602, d_svhn_loss: 0.0337, d_fake_loss: 0.0543, g_loss: 1.1540\n",
            "Step [56470/80000], d_real_loss: 0.0860, d_mnist_loss: 0.0490, d_svhn_loss: 0.0370, d_fake_loss: 0.0880, g_loss: 1.1565\n",
            "Step [56480/80000], d_real_loss: 0.0822, d_mnist_loss: 0.0227, d_svhn_loss: 0.0595, d_fake_loss: 0.0564, g_loss: 1.1590\n",
            "Step [56490/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0241, d_svhn_loss: 0.0221, d_fake_loss: 0.0488, g_loss: 1.4623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7487226128578186, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [56500/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0139, d_svhn_loss: 0.0644, d_fake_loss: 0.0380, g_loss: 1.0433\n",
            "saved ./samples_fashion/sample-56500-m-s.png\n",
            "saved ./samples_fashion/sample-56500-s-m.png\n",
            "Step [56510/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0306, d_svhn_loss: 0.0304, d_fake_loss: 0.0873, g_loss: 1.1138\n",
            "Step [56520/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0165, d_svhn_loss: 0.0289, d_fake_loss: 0.1663, g_loss: 0.9472\n",
            "Step [56530/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0376, d_svhn_loss: 0.0362, d_fake_loss: 0.0349, g_loss: 1.1142\n",
            "Step [56540/80000], d_real_loss: 0.1526, d_mnist_loss: 0.0355, d_svhn_loss: 0.1171, d_fake_loss: 0.1666, g_loss: 0.9547\n",
            "Step [56550/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0462, d_svhn_loss: 0.0204, d_fake_loss: 0.1403, g_loss: 1.1936\n",
            "Step [56560/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0250, d_svhn_loss: 0.0234, d_fake_loss: 0.0565, g_loss: 0.9286\n",
            "Step [56570/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0280, d_svhn_loss: 0.0224, d_fake_loss: 0.0332, g_loss: 1.2214\n",
            "Step [56580/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0200, d_svhn_loss: 0.0218, d_fake_loss: 0.0289, g_loss: 1.0654\n",
            "Step [56590/80000], d_real_loss: 0.2125, d_mnist_loss: 0.1038, d_svhn_loss: 0.1088, d_fake_loss: 0.0451, g_loss: 1.2518\n",
            "Step [56600/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0250, d_svhn_loss: 0.0224, d_fake_loss: 0.0520, g_loss: 1.0650\n",
            "Step [56610/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0153, d_svhn_loss: 0.0148, d_fake_loss: 0.0214, g_loss: 1.1541\n",
            "Step [56620/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0145, d_svhn_loss: 0.0215, d_fake_loss: 0.1220, g_loss: 1.0325\n",
            "Step [56630/80000], d_real_loss: 0.1114, d_mnist_loss: 0.0796, d_svhn_loss: 0.0318, d_fake_loss: 0.0976, g_loss: 1.0406\n",
            "Step [56640/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0337, d_svhn_loss: 0.0195, d_fake_loss: 0.0569, g_loss: 1.0327\n",
            "Step [56650/80000], d_real_loss: 0.1617, d_mnist_loss: 0.1202, d_svhn_loss: 0.0415, d_fake_loss: 0.1122, g_loss: 1.1213\n",
            "Step [56660/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0185, d_svhn_loss: 0.0363, d_fake_loss: 0.0333, g_loss: 1.0162\n",
            "Step [56670/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0268, d_svhn_loss: 0.0483, d_fake_loss: 0.0286, g_loss: 1.2874\n",
            "Step [56680/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0151, d_svhn_loss: 0.0144, d_fake_loss: 0.0464, g_loss: 1.1138\n",
            "Step [56690/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0151, d_svhn_loss: 0.0124, d_fake_loss: 0.0452, g_loss: 1.0362\n",
            "Step [56700/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0637, d_svhn_loss: 0.0298, d_fake_loss: 0.0573, g_loss: 1.1290\n",
            "Step [56710/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0157, d_svhn_loss: 0.0460, d_fake_loss: 0.0736, g_loss: 1.2326\n",
            "Step [56720/80000], d_real_loss: 0.1237, d_mnist_loss: 0.0990, d_svhn_loss: 0.0247, d_fake_loss: 0.0311, g_loss: 1.2110\n",
            "Step [56730/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0399, d_svhn_loss: 0.0338, d_fake_loss: 0.0618, g_loss: 1.0292\n",
            "Step [56740/80000], d_real_loss: 0.0861, d_mnist_loss: 0.0346, d_svhn_loss: 0.0516, d_fake_loss: 0.0841, g_loss: 1.0654\n",
            "Step [56750/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0452, d_svhn_loss: 0.0199, d_fake_loss: 0.0226, g_loss: 1.3093\n",
            "Step [56760/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0162, d_svhn_loss: 0.0544, d_fake_loss: 0.0380, g_loss: 1.0275\n",
            "Step [56770/80000], d_real_loss: 0.0704, d_mnist_loss: 0.0203, d_svhn_loss: 0.0501, d_fake_loss: 0.0882, g_loss: 1.3443\n",
            "Step [56780/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0318, d_svhn_loss: 0.0211, d_fake_loss: 0.0397, g_loss: 1.1339\n",
            "Step [56790/80000], d_real_loss: 0.0860, d_mnist_loss: 0.0122, d_svhn_loss: 0.0738, d_fake_loss: 0.0504, g_loss: 1.0971\n",
            "Step [56800/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0179, d_svhn_loss: 0.0636, d_fake_loss: 0.0723, g_loss: 1.0737\n",
            "Step [56810/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0312, d_svhn_loss: 0.0311, d_fake_loss: 0.0382, g_loss: 1.2023\n",
            "Step [56820/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0208, d_svhn_loss: 0.0152, d_fake_loss: 0.0826, g_loss: 1.2949\n",
            "Step [56830/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0334, d_svhn_loss: 0.0161, d_fake_loss: 0.0419, g_loss: 1.0986\n",
            "Step [56840/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0373, d_svhn_loss: 0.0199, d_fake_loss: 0.0543, g_loss: 1.1910\n",
            "Step [56850/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0294, d_svhn_loss: 0.0263, d_fake_loss: 0.0608, g_loss: 1.3333\n",
            "Step [56860/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0361, d_svhn_loss: 0.0177, d_fake_loss: 0.0596, g_loss: 1.2170\n",
            "Step [56870/80000], d_real_loss: 0.0792, d_mnist_loss: 0.0298, d_svhn_loss: 0.0494, d_fake_loss: 0.0363, g_loss: 1.2730\n",
            "Step [56880/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0237, d_svhn_loss: 0.0222, d_fake_loss: 0.0383, g_loss: 1.0877\n",
            "Step [56890/80000], d_real_loss: 0.0860, d_mnist_loss: 0.0299, d_svhn_loss: 0.0560, d_fake_loss: 0.0866, g_loss: 1.1117\n",
            "Step [56900/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0400, d_svhn_loss: 0.0140, d_fake_loss: 0.0345, g_loss: 1.0416\n",
            "Step [56910/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0376, d_svhn_loss: 0.0455, d_fake_loss: 0.0726, g_loss: 1.0942\n",
            "Step [56920/80000], d_real_loss: 0.1005, d_mnist_loss: 0.0706, d_svhn_loss: 0.0298, d_fake_loss: 0.0672, g_loss: 1.0632\n",
            "Step [56930/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0251, d_svhn_loss: 0.0187, d_fake_loss: 0.0546, g_loss: 1.0315\n",
            "Step [56940/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0257, d_svhn_loss: 0.0195, d_fake_loss: 0.0655, g_loss: 1.1814\n",
            "Step [56950/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0416, d_svhn_loss: 0.0181, d_fake_loss: 0.0449, g_loss: 1.1196\n",
            "Step [56960/80000], d_real_loss: 0.1327, d_mnist_loss: 0.0459, d_svhn_loss: 0.0868, d_fake_loss: 0.0293, g_loss: 1.0819\n",
            "Step [56970/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0238, d_svhn_loss: 0.0145, d_fake_loss: 0.0514, g_loss: 1.2409\n",
            "Step [56980/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0162, d_svhn_loss: 0.0406, d_fake_loss: 0.0275, g_loss: 1.1137\n",
            "Step [56990/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0139, d_svhn_loss: 0.0264, d_fake_loss: 0.0235, g_loss: 1.1779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7763990163803101, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [57000/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0211, d_svhn_loss: 0.0408, d_fake_loss: 0.0281, g_loss: 1.0629\n",
            "saved ./samples_fashion/sample-57000-m-s.png\n",
            "saved ./samples_fashion/sample-57000-s-m.png\n",
            "Step [57010/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0222, d_svhn_loss: 0.0160, d_fake_loss: 0.1583, g_loss: 1.3050\n",
            "Step [57020/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0242, d_svhn_loss: 0.0325, d_fake_loss: 0.0441, g_loss: 0.9952\n",
            "Step [57030/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0222, d_svhn_loss: 0.0319, d_fake_loss: 0.0396, g_loss: 1.0475\n",
            "Step [57040/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0196, d_svhn_loss: 0.0322, d_fake_loss: 0.0260, g_loss: 1.0885\n",
            "Step [57050/80000], d_real_loss: 0.0981, d_mnist_loss: 0.0830, d_svhn_loss: 0.0151, d_fake_loss: 0.0614, g_loss: 1.0909\n",
            "Step [57060/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0284, d_svhn_loss: 0.0188, d_fake_loss: 0.0963, g_loss: 1.2402\n",
            "Step [57070/80000], d_real_loss: 0.1214, d_mnist_loss: 0.0200, d_svhn_loss: 0.1014, d_fake_loss: 0.0522, g_loss: 1.1357\n",
            "Step [57080/80000], d_real_loss: 0.1866, d_mnist_loss: 0.0216, d_svhn_loss: 0.1651, d_fake_loss: 0.0365, g_loss: 1.1122\n",
            "Step [57090/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0354, d_svhn_loss: 0.0158, d_fake_loss: 0.0710, g_loss: 1.2482\n",
            "Step [57100/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0299, d_svhn_loss: 0.0117, d_fake_loss: 0.1005, g_loss: 0.9984\n",
            "Step [57110/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0599, d_svhn_loss: 0.0179, d_fake_loss: 0.1412, g_loss: 1.1791\n",
            "Step [57120/80000], d_real_loss: 0.1467, d_mnist_loss: 0.1006, d_svhn_loss: 0.0461, d_fake_loss: 0.0420, g_loss: 1.1349\n",
            "Step [57130/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0128, d_svhn_loss: 0.0303, d_fake_loss: 0.0329, g_loss: 1.1237\n",
            "Step [57140/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0448, d_svhn_loss: 0.0372, d_fake_loss: 0.0313, g_loss: 1.1478\n",
            "Step [57150/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0273, d_svhn_loss: 0.0178, d_fake_loss: 0.0345, g_loss: 1.0987\n",
            "Step [57160/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0193, d_svhn_loss: 0.0304, d_fake_loss: 0.0640, g_loss: 1.0899\n",
            "Step [57170/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0119, d_svhn_loss: 0.0271, d_fake_loss: 0.0263, g_loss: 1.1106\n",
            "Step [57180/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0110, d_svhn_loss: 0.0482, d_fake_loss: 0.0798, g_loss: 1.1336\n",
            "Step [57190/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0137, d_svhn_loss: 0.0297, d_fake_loss: 0.0492, g_loss: 1.2303\n",
            "Step [57200/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0424, d_svhn_loss: 0.0216, d_fake_loss: 0.0265, g_loss: 1.0913\n",
            "Step [57210/80000], d_real_loss: 0.0948, d_mnist_loss: 0.0359, d_svhn_loss: 0.0589, d_fake_loss: 0.0632, g_loss: 1.1237\n",
            "Step [57220/80000], d_real_loss: 0.0870, d_mnist_loss: 0.0673, d_svhn_loss: 0.0197, d_fake_loss: 0.0328, g_loss: 1.0588\n",
            "Step [57230/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0268, d_svhn_loss: 0.0355, d_fake_loss: 0.0922, g_loss: 1.1357\n",
            "Step [57240/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0206, d_svhn_loss: 0.0319, d_fake_loss: 0.0700, g_loss: 1.2539\n",
            "Step [57250/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0137, d_svhn_loss: 0.0276, d_fake_loss: 0.1065, g_loss: 1.2790\n",
            "Step [57260/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0219, d_svhn_loss: 0.0218, d_fake_loss: 0.1097, g_loss: 1.2017\n",
            "Step [57270/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0502, d_svhn_loss: 0.0132, d_fake_loss: 0.0348, g_loss: 1.0647\n",
            "Step [57280/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0159, d_svhn_loss: 0.0249, d_fake_loss: 0.0353, g_loss: 1.2147\n",
            "Step [57290/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0256, d_svhn_loss: 0.0430, d_fake_loss: 0.0500, g_loss: 1.1059\n",
            "Step [57300/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0291, d_svhn_loss: 0.0160, d_fake_loss: 0.0450, g_loss: 1.1774\n",
            "Step [57310/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0198, d_svhn_loss: 0.0185, d_fake_loss: 0.0403, g_loss: 1.1513\n",
            "Step [57320/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0351, d_svhn_loss: 0.0239, d_fake_loss: 0.0658, g_loss: 1.4216\n",
            "Step [57330/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0176, d_svhn_loss: 0.0222, d_fake_loss: 0.0489, g_loss: 1.2723\n",
            "Step [57340/80000], d_real_loss: 0.0909, d_mnist_loss: 0.0687, d_svhn_loss: 0.0222, d_fake_loss: 0.0304, g_loss: 1.1449\n",
            "Step [57350/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0237, d_svhn_loss: 0.0203, d_fake_loss: 0.0955, g_loss: 0.9864\n",
            "Step [57360/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0372, d_svhn_loss: 0.0225, d_fake_loss: 0.0320, g_loss: 1.1052\n",
            "Step [57370/80000], d_real_loss: 0.0968, d_mnist_loss: 0.0784, d_svhn_loss: 0.0184, d_fake_loss: 0.1524, g_loss: 1.4345\n",
            "Step [57380/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0488, d_svhn_loss: 0.0171, d_fake_loss: 0.1222, g_loss: 1.1367\n",
            "Step [57390/80000], d_real_loss: 0.0842, d_mnist_loss: 0.0342, d_svhn_loss: 0.0500, d_fake_loss: 0.0388, g_loss: 1.1767\n",
            "Step [57400/80000], d_real_loss: 0.0951, d_mnist_loss: 0.0412, d_svhn_loss: 0.0540, d_fake_loss: 0.1811, g_loss: 1.2379\n",
            "Step [57410/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0255, d_svhn_loss: 0.0184, d_fake_loss: 0.0501, g_loss: 1.3426\n",
            "Step [57420/80000], d_real_loss: 0.0847, d_mnist_loss: 0.0219, d_svhn_loss: 0.0629, d_fake_loss: 0.0411, g_loss: 1.0537\n",
            "Step [57430/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0253, d_svhn_loss: 0.0329, d_fake_loss: 0.0240, g_loss: 1.1918\n",
            "Step [57440/80000], d_real_loss: 0.0658, d_mnist_loss: 0.0428, d_svhn_loss: 0.0231, d_fake_loss: 0.0294, g_loss: 1.0635\n",
            "Step [57450/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0147, d_svhn_loss: 0.0230, d_fake_loss: 0.0320, g_loss: 1.2181\n",
            "Step [57460/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0261, d_svhn_loss: 0.0275, d_fake_loss: 0.0766, g_loss: 1.1229\n",
            "Step [57470/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0292, d_svhn_loss: 0.0284, d_fake_loss: 0.0573, g_loss: 1.3930\n",
            "Step [57480/80000], d_real_loss: 0.0948, d_mnist_loss: 0.0127, d_svhn_loss: 0.0821, d_fake_loss: 0.0731, g_loss: 0.9454\n",
            "Step [57490/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0143, d_svhn_loss: 0.0191, d_fake_loss: 0.0434, g_loss: 1.1649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8449327349662781, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [57500/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0211, d_svhn_loss: 0.0491, d_fake_loss: 0.0371, g_loss: 1.1646\n",
            "saved ./samples_fashion/sample-57500-m-s.png\n",
            "saved ./samples_fashion/sample-57500-s-m.png\n",
            "Step [57510/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0199, d_svhn_loss: 0.0411, d_fake_loss: 0.0412, g_loss: 1.0497\n",
            "Step [57520/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0229, d_svhn_loss: 0.0324, d_fake_loss: 0.0638, g_loss: 1.1191\n",
            "Step [57530/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0186, d_svhn_loss: 0.0229, d_fake_loss: 0.0435, g_loss: 1.0882\n",
            "Step [57540/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0254, d_svhn_loss: 0.0201, d_fake_loss: 0.0423, g_loss: 1.0787\n",
            "Step [57550/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0136, d_svhn_loss: 0.0191, d_fake_loss: 0.0752, g_loss: 1.1944\n",
            "Step [57560/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0180, d_svhn_loss: 0.0420, d_fake_loss: 0.0238, g_loss: 1.1390\n",
            "Step [57570/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0176, d_svhn_loss: 0.0165, d_fake_loss: 0.0339, g_loss: 1.1618\n",
            "Step [57580/80000], d_real_loss: 0.0849, d_mnist_loss: 0.0716, d_svhn_loss: 0.0133, d_fake_loss: 0.0549, g_loss: 1.0170\n",
            "Step [57590/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0345, d_svhn_loss: 0.0203, d_fake_loss: 0.0708, g_loss: 1.3893\n",
            "Step [57600/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0187, d_svhn_loss: 0.0453, d_fake_loss: 0.0498, g_loss: 1.3180\n",
            "Step [57610/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0201, d_svhn_loss: 0.0169, d_fake_loss: 0.0906, g_loss: 1.1152\n",
            "Step [57620/80000], d_real_loss: 0.0324, d_mnist_loss: 0.0118, d_svhn_loss: 0.0206, d_fake_loss: 0.0459, g_loss: 1.1635\n",
            "Step [57630/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0162, d_svhn_loss: 0.0323, d_fake_loss: 0.0867, g_loss: 1.2978\n",
            "Step [57640/80000], d_real_loss: 0.0871, d_mnist_loss: 0.0606, d_svhn_loss: 0.0265, d_fake_loss: 0.0755, g_loss: 1.1196\n",
            "Step [57650/80000], d_real_loss: 0.0771, d_mnist_loss: 0.0405, d_svhn_loss: 0.0366, d_fake_loss: 0.0349, g_loss: 0.9769\n",
            "Step [57660/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0295, d_svhn_loss: 0.0221, d_fake_loss: 0.0379, g_loss: 1.1120\n",
            "Step [57670/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0159, d_svhn_loss: 0.0340, d_fake_loss: 0.0458, g_loss: 1.0755\n",
            "Step [57680/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0125, d_svhn_loss: 0.0354, d_fake_loss: 0.0455, g_loss: 1.2354\n",
            "Step [57690/80000], d_real_loss: 0.0754, d_mnist_loss: 0.0395, d_svhn_loss: 0.0359, d_fake_loss: 0.0912, g_loss: 1.1037\n",
            "Step [57700/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0142, d_svhn_loss: 0.0491, d_fake_loss: 0.0456, g_loss: 1.1836\n",
            "Step [57710/80000], d_real_loss: 0.1107, d_mnist_loss: 0.0723, d_svhn_loss: 0.0384, d_fake_loss: 0.0522, g_loss: 1.0353\n",
            "Step [57720/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0186, d_svhn_loss: 0.0275, d_fake_loss: 0.0777, g_loss: 1.1948\n",
            "Step [57730/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0187, d_svhn_loss: 0.0293, d_fake_loss: 0.0171, g_loss: 1.0718\n",
            "Step [57740/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0214, d_svhn_loss: 0.0208, d_fake_loss: 0.0406, g_loss: 1.1319\n",
            "Step [57750/80000], d_real_loss: 0.1346, d_mnist_loss: 0.0766, d_svhn_loss: 0.0581, d_fake_loss: 0.0734, g_loss: 1.0674\n",
            "Step [57760/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0282, d_svhn_loss: 0.0304, d_fake_loss: 0.0667, g_loss: 1.2609\n",
            "Step [57770/80000], d_real_loss: 0.1287, d_mnist_loss: 0.1074, d_svhn_loss: 0.0213, d_fake_loss: 0.0611, g_loss: 1.1071\n",
            "Step [57780/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0293, d_svhn_loss: 0.0198, d_fake_loss: 0.0276, g_loss: 1.1578\n",
            "Step [57790/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0201, d_svhn_loss: 0.0258, d_fake_loss: 0.0310, g_loss: 1.1726\n",
            "Step [57800/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0214, d_svhn_loss: 0.0178, d_fake_loss: 0.0475, g_loss: 1.1212\n",
            "Step [57810/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0150, d_svhn_loss: 0.0182, d_fake_loss: 0.0767, g_loss: 1.2077\n",
            "Step [57820/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0238, d_svhn_loss: 0.0213, d_fake_loss: 0.0435, g_loss: 1.0823\n",
            "Step [57830/80000], d_real_loss: 0.1502, d_mnist_loss: 0.0569, d_svhn_loss: 0.0933, d_fake_loss: 0.0317, g_loss: 1.1753\n",
            "Step [57840/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0283, d_svhn_loss: 0.0411, d_fake_loss: 0.0269, g_loss: 1.1834\n",
            "Step [57850/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0365, d_svhn_loss: 0.0185, d_fake_loss: 0.0289, g_loss: 1.1375\n",
            "Step [57860/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0297, d_svhn_loss: 0.0301, d_fake_loss: 0.0536, g_loss: 1.0644\n",
            "Step [57870/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0318, d_svhn_loss: 0.0324, d_fake_loss: 0.0898, g_loss: 1.2213\n",
            "Step [57880/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0146, d_svhn_loss: 0.0443, d_fake_loss: 0.0622, g_loss: 1.0639\n",
            "Step [57890/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0184, d_svhn_loss: 0.0524, d_fake_loss: 0.0508, g_loss: 1.0619\n",
            "Step [57900/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0130, d_svhn_loss: 0.0487, d_fake_loss: 0.1023, g_loss: 1.1886\n",
            "Step [57910/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0359, d_svhn_loss: 0.0229, d_fake_loss: 0.0522, g_loss: 1.1304\n",
            "Step [57920/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0515, d_svhn_loss: 0.0182, d_fake_loss: 0.0381, g_loss: 1.1878\n",
            "Step [57930/80000], d_real_loss: 0.0786, d_mnist_loss: 0.0188, d_svhn_loss: 0.0598, d_fake_loss: 0.0495, g_loss: 1.0428\n",
            "Step [57940/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0223, d_svhn_loss: 0.0231, d_fake_loss: 0.0561, g_loss: 1.3059\n",
            "Step [57950/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0206, d_svhn_loss: 0.0510, d_fake_loss: 0.0373, g_loss: 1.1336\n",
            "Step [57960/80000], d_real_loss: 0.0940, d_mnist_loss: 0.0727, d_svhn_loss: 0.0213, d_fake_loss: 0.0630, g_loss: 1.1382\n",
            "Step [57970/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0200, d_svhn_loss: 0.0416, d_fake_loss: 0.0280, g_loss: 1.1944\n",
            "Step [57980/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0220, d_svhn_loss: 0.0151, d_fake_loss: 0.0269, g_loss: 1.1122\n",
            "Step [57990/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0236, d_svhn_loss: 0.0438, d_fake_loss: 0.0548, g_loss: 1.1263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7137782573699951, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [58000/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0147, d_svhn_loss: 0.0539, d_fake_loss: 0.0419, g_loss: 1.1658\n",
            "saved ./samples_fashion/sample-58000-m-s.png\n",
            "saved ./samples_fashion/sample-58000-s-m.png\n",
            "Step [58010/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0415, d_svhn_loss: 0.0187, d_fake_loss: 0.0389, g_loss: 1.0544\n",
            "Step [58020/80000], d_real_loss: 0.0860, d_mnist_loss: 0.0445, d_svhn_loss: 0.0415, d_fake_loss: 0.0795, g_loss: 1.0469\n",
            "Step [58030/80000], d_real_loss: 0.1163, d_mnist_loss: 0.0231, d_svhn_loss: 0.0932, d_fake_loss: 0.1003, g_loss: 1.0534\n",
            "Step [58040/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0240, d_svhn_loss: 0.0209, d_fake_loss: 0.0385, g_loss: 1.1816\n",
            "Step [58050/80000], d_real_loss: 0.0775, d_mnist_loss: 0.0173, d_svhn_loss: 0.0603, d_fake_loss: 0.1020, g_loss: 1.0064\n",
            "Step [58060/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0292, d_svhn_loss: 0.0308, d_fake_loss: 0.0567, g_loss: 1.1318\n",
            "Step [58070/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0457, d_svhn_loss: 0.0196, d_fake_loss: 0.0403, g_loss: 1.1155\n",
            "Step [58080/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0244, d_svhn_loss: 0.0339, d_fake_loss: 0.0408, g_loss: 1.0686\n",
            "Step [58090/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0237, d_svhn_loss: 0.0240, d_fake_loss: 0.0226, g_loss: 1.0506\n",
            "Step [58100/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0156, d_svhn_loss: 0.0171, d_fake_loss: 0.0379, g_loss: 1.1093\n",
            "Step [58110/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0134, d_svhn_loss: 0.0189, d_fake_loss: 0.0540, g_loss: 1.2177\n",
            "Step [58120/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0187, d_svhn_loss: 0.0266, d_fake_loss: 0.0506, g_loss: 1.1557\n",
            "Step [58130/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0211, d_svhn_loss: 0.0285, d_fake_loss: 0.0337, g_loss: 1.0554\n",
            "Step [58140/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0225, d_svhn_loss: 0.0351, d_fake_loss: 0.1059, g_loss: 1.1928\n",
            "Step [58150/80000], d_real_loss: 0.1739, d_mnist_loss: 0.0291, d_svhn_loss: 0.1448, d_fake_loss: 0.1580, g_loss: 1.1873\n",
            "Step [58160/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0168, d_svhn_loss: 0.0243, d_fake_loss: 0.0397, g_loss: 1.1488\n",
            "Step [58170/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0179, d_svhn_loss: 0.0385, d_fake_loss: 0.0310, g_loss: 1.1776\n",
            "Step [58180/80000], d_real_loss: 0.1767, d_mnist_loss: 0.0994, d_svhn_loss: 0.0773, d_fake_loss: 0.0653, g_loss: 1.0985\n",
            "Step [58190/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0174, d_svhn_loss: 0.0246, d_fake_loss: 0.0334, g_loss: 1.2308\n",
            "Step [58200/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0187, d_svhn_loss: 0.0242, d_fake_loss: 0.0465, g_loss: 0.9395\n",
            "Step [58210/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0092, d_svhn_loss: 0.0801, d_fake_loss: 0.0666, g_loss: 1.2514\n",
            "Step [58220/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0131, d_svhn_loss: 0.0399, d_fake_loss: 0.0688, g_loss: 1.2664\n",
            "Step [58230/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0108, d_svhn_loss: 0.0332, d_fake_loss: 0.0390, g_loss: 1.1333\n",
            "Step [58240/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0128, d_svhn_loss: 0.0229, d_fake_loss: 0.0308, g_loss: 1.0795\n",
            "Step [58250/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0243, d_svhn_loss: 0.0193, d_fake_loss: 0.0798, g_loss: 1.2421\n",
            "Step [58260/80000], d_real_loss: 0.0860, d_mnist_loss: 0.0677, d_svhn_loss: 0.0183, d_fake_loss: 0.0964, g_loss: 1.1209\n",
            "Step [58270/80000], d_real_loss: 0.1334, d_mnist_loss: 0.0608, d_svhn_loss: 0.0726, d_fake_loss: 0.0402, g_loss: 1.0850\n",
            "Step [58280/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0486, d_svhn_loss: 0.0230, d_fake_loss: 0.0466, g_loss: 1.0535\n",
            "Step [58290/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0222, d_svhn_loss: 0.0401, d_fake_loss: 0.0323, g_loss: 1.1430\n",
            "Step [58300/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0290, d_svhn_loss: 0.0317, d_fake_loss: 0.0408, g_loss: 1.0993\n",
            "Step [58310/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0132, d_svhn_loss: 0.0497, d_fake_loss: 0.0484, g_loss: 1.0957\n",
            "Step [58320/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0289, d_svhn_loss: 0.0238, d_fake_loss: 0.1641, g_loss: 1.1391\n",
            "Step [58330/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0112, d_svhn_loss: 0.0321, d_fake_loss: 0.0517, g_loss: 1.1484\n",
            "Step [58340/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0177, d_svhn_loss: 0.0232, d_fake_loss: 0.0599, g_loss: 1.1253\n",
            "Step [58350/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0218, d_svhn_loss: 0.0363, d_fake_loss: 0.0713, g_loss: 1.2681\n",
            "Step [58360/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0303, d_svhn_loss: 0.0184, d_fake_loss: 0.0404, g_loss: 1.0790\n",
            "Step [58370/80000], d_real_loss: 0.1242, d_mnist_loss: 0.1037, d_svhn_loss: 0.0205, d_fake_loss: 0.0429, g_loss: 1.1621\n",
            "Step [58380/80000], d_real_loss: 0.1090, d_mnist_loss: 0.0877, d_svhn_loss: 0.0213, d_fake_loss: 0.0680, g_loss: 1.1022\n",
            "Step [58390/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0252, d_svhn_loss: 0.0135, d_fake_loss: 0.0345, g_loss: 1.1474\n",
            "Step [58400/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0676, d_svhn_loss: 0.0191, d_fake_loss: 0.0749, g_loss: 0.9542\n",
            "Step [58410/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0164, d_svhn_loss: 0.0225, d_fake_loss: 0.0313, g_loss: 1.2030\n",
            "Step [58420/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0082, d_svhn_loss: 0.0231, d_fake_loss: 0.0662, g_loss: 1.2070\n",
            "Step [58430/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0349, d_svhn_loss: 0.0456, d_fake_loss: 0.0742, g_loss: 1.1999\n",
            "Step [58440/80000], d_real_loss: 0.0895, d_mnist_loss: 0.0146, d_svhn_loss: 0.0749, d_fake_loss: 0.0355, g_loss: 1.2268\n",
            "Step [58450/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0200, d_svhn_loss: 0.0416, d_fake_loss: 0.0380, g_loss: 1.3973\n",
            "Step [58460/80000], d_real_loss: 0.0773, d_mnist_loss: 0.0413, d_svhn_loss: 0.0360, d_fake_loss: 0.0457, g_loss: 1.0739\n",
            "Step [58470/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0233, d_svhn_loss: 0.0427, d_fake_loss: 0.0549, g_loss: 1.1672\n",
            "Step [58480/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0199, d_svhn_loss: 0.0163, d_fake_loss: 0.0420, g_loss: 1.1445\n",
            "Step [58490/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0230, d_svhn_loss: 0.0237, d_fake_loss: 0.0306, g_loss: 1.1695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7826448082923889, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [58500/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0148, d_svhn_loss: 0.0155, d_fake_loss: 0.0328, g_loss: 1.2237\n",
            "saved ./samples_fashion/sample-58500-m-s.png\n",
            "saved ./samples_fashion/sample-58500-s-m.png\n",
            "Step [58510/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0402, d_svhn_loss: 0.0210, d_fake_loss: 0.0403, g_loss: 1.0918\n",
            "Step [58520/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0191, d_svhn_loss: 0.0239, d_fake_loss: 0.0449, g_loss: 1.2655\n",
            "Step [58530/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0273, d_svhn_loss: 0.0197, d_fake_loss: 0.0374, g_loss: 1.2161\n",
            "Step [58540/80000], d_real_loss: 0.2626, d_mnist_loss: 0.2131, d_svhn_loss: 0.0495, d_fake_loss: 0.0505, g_loss: 1.6179\n",
            "Step [58550/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0368, d_svhn_loss: 0.0300, d_fake_loss: 0.0391, g_loss: 1.1584\n",
            "Step [58560/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0189, d_svhn_loss: 0.0274, d_fake_loss: 0.0310, g_loss: 1.1342\n",
            "Step [58570/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0146, d_svhn_loss: 0.0256, d_fake_loss: 0.0339, g_loss: 1.2482\n",
            "Step [58580/80000], d_real_loss: 0.0969, d_mnist_loss: 0.0212, d_svhn_loss: 0.0758, d_fake_loss: 0.0591, g_loss: 1.0463\n",
            "Step [58590/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0123, d_svhn_loss: 0.0394, d_fake_loss: 0.0455, g_loss: 1.1671\n",
            "Step [58600/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0241, d_svhn_loss: 0.0159, d_fake_loss: 0.0285, g_loss: 1.0437\n",
            "Step [58610/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0201, d_svhn_loss: 0.0126, d_fake_loss: 0.0688, g_loss: 1.1265\n",
            "Step [58620/80000], d_real_loss: 0.1355, d_mnist_loss: 0.0332, d_svhn_loss: 0.1023, d_fake_loss: 0.0350, g_loss: 1.0121\n",
            "Step [58630/80000], d_real_loss: 0.1031, d_mnist_loss: 0.0137, d_svhn_loss: 0.0894, d_fake_loss: 0.0892, g_loss: 1.1361\n",
            "Step [58640/80000], d_real_loss: 0.1291, d_mnist_loss: 0.0959, d_svhn_loss: 0.0331, d_fake_loss: 0.1082, g_loss: 1.2933\n",
            "Step [58650/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0228, d_svhn_loss: 0.0191, d_fake_loss: 0.0346, g_loss: 1.1153\n",
            "Step [58660/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0410, d_svhn_loss: 0.0191, d_fake_loss: 0.0393, g_loss: 1.0783\n",
            "Step [58670/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0231, d_svhn_loss: 0.0197, d_fake_loss: 0.0404, g_loss: 1.1097\n",
            "Step [58680/80000], d_real_loss: 0.0982, d_mnist_loss: 0.0358, d_svhn_loss: 0.0624, d_fake_loss: 0.0835, g_loss: 1.1687\n",
            "Step [58690/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0135, d_svhn_loss: 0.0160, d_fake_loss: 0.0302, g_loss: 1.1592\n",
            "Step [58700/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0200, d_svhn_loss: 0.0172, d_fake_loss: 0.0625, g_loss: 1.4124\n",
            "Step [58710/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0228, d_svhn_loss: 0.0213, d_fake_loss: 0.0571, g_loss: 1.4188\n",
            "Step [58720/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0193, d_svhn_loss: 0.0169, d_fake_loss: 0.0767, g_loss: 1.2601\n",
            "Step [58730/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0128, d_svhn_loss: 0.0215, d_fake_loss: 0.0330, g_loss: 1.1618\n",
            "Step [58740/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0178, d_svhn_loss: 0.0635, d_fake_loss: 0.0248, g_loss: 1.1605\n",
            "Step [58750/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0135, d_svhn_loss: 0.0260, d_fake_loss: 0.0350, g_loss: 1.2291\n",
            "Step [58760/80000], d_real_loss: 0.0883, d_mnist_loss: 0.0220, d_svhn_loss: 0.0663, d_fake_loss: 0.0775, g_loss: 1.2587\n",
            "Step [58770/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0152, d_svhn_loss: 0.0218, d_fake_loss: 0.0387, g_loss: 1.1246\n",
            "Step [58780/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0243, d_svhn_loss: 0.0536, d_fake_loss: 0.0708, g_loss: 1.0357\n",
            "Step [58790/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0258, d_svhn_loss: 0.0310, d_fake_loss: 0.0453, g_loss: 1.2481\n",
            "Step [58800/80000], d_real_loss: 0.0874, d_mnist_loss: 0.0557, d_svhn_loss: 0.0317, d_fake_loss: 0.0898, g_loss: 1.1249\n",
            "Step [58810/80000], d_real_loss: 0.0502, d_mnist_loss: 0.0360, d_svhn_loss: 0.0142, d_fake_loss: 0.0465, g_loss: 1.0304\n",
            "Step [58820/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0258, d_svhn_loss: 0.0224, d_fake_loss: 0.0226, g_loss: 1.0635\n",
            "Step [58830/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0175, d_svhn_loss: 0.0230, d_fake_loss: 0.0789, g_loss: 1.0646\n",
            "Step [58840/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0137, d_svhn_loss: 0.0142, d_fake_loss: 0.0390, g_loss: 1.2378\n",
            "Step [58850/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0202, d_svhn_loss: 0.0336, d_fake_loss: 0.0415, g_loss: 1.1879\n",
            "Step [58860/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0113, d_svhn_loss: 0.0229, d_fake_loss: 0.0412, g_loss: 1.1339\n",
            "Step [58870/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0174, d_svhn_loss: 0.0235, d_fake_loss: 0.1103, g_loss: 1.2336\n",
            "Step [58880/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0260, d_svhn_loss: 0.0431, d_fake_loss: 0.1426, g_loss: 1.1987\n",
            "Step [58890/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0200, d_svhn_loss: 0.0169, d_fake_loss: 0.0487, g_loss: 1.4034\n",
            "Step [58900/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0419, d_svhn_loss: 0.0201, d_fake_loss: 0.0555, g_loss: 1.0514\n",
            "Step [58910/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0321, d_svhn_loss: 0.0255, d_fake_loss: 0.0930, g_loss: 1.1561\n",
            "Step [58920/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0206, d_svhn_loss: 0.0198, d_fake_loss: 0.0434, g_loss: 1.1568\n",
            "Step [58930/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0265, d_svhn_loss: 0.0236, d_fake_loss: 0.0331, g_loss: 1.2788\n",
            "Step [58940/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0572, d_svhn_loss: 0.0241, d_fake_loss: 0.0900, g_loss: 1.0593\n",
            "Step [58950/80000], d_real_loss: 0.0976, d_mnist_loss: 0.0296, d_svhn_loss: 0.0680, d_fake_loss: 0.0318, g_loss: 1.1172\n",
            "Step [58960/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0384, d_svhn_loss: 0.0219, d_fake_loss: 0.0557, g_loss: 1.2866\n",
            "Step [58970/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0220, d_svhn_loss: 0.0164, d_fake_loss: 0.0570, g_loss: 1.2223\n",
            "Step [58980/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0240, d_svhn_loss: 0.0333, d_fake_loss: 0.0980, g_loss: 1.3337\n",
            "Step [58990/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0263, d_svhn_loss: 0.0331, d_fake_loss: 0.0279, g_loss: 1.0467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7370757460594177, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [59000/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0161, d_svhn_loss: 0.0333, d_fake_loss: 0.0586, g_loss: 1.1957\n",
            "saved ./samples_fashion/sample-59000-m-s.png\n",
            "saved ./samples_fashion/sample-59000-s-m.png\n",
            "Step [59010/80000], d_real_loss: 0.1096, d_mnist_loss: 0.0726, d_svhn_loss: 0.0369, d_fake_loss: 0.1651, g_loss: 1.3101\n",
            "Step [59020/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0290, d_svhn_loss: 0.0283, d_fake_loss: 0.0249, g_loss: 1.2310\n",
            "Step [59030/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0218, d_svhn_loss: 0.0159, d_fake_loss: 0.0259, g_loss: 1.1098\n",
            "Step [59040/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0177, d_svhn_loss: 0.0265, d_fake_loss: 0.0298, g_loss: 1.1686\n",
            "Step [59050/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0184, d_svhn_loss: 0.0579, d_fake_loss: 0.0315, g_loss: 1.1548\n",
            "Step [59060/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0322, d_svhn_loss: 0.0250, d_fake_loss: 0.0467, g_loss: 1.1557\n",
            "Step [59070/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0217, d_svhn_loss: 0.0225, d_fake_loss: 0.0428, g_loss: 1.1347\n",
            "Step [59080/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0251, d_svhn_loss: 0.0231, d_fake_loss: 0.0335, g_loss: 1.1416\n",
            "Step [59090/80000], d_real_loss: 0.0861, d_mnist_loss: 0.0419, d_svhn_loss: 0.0442, d_fake_loss: 0.0594, g_loss: 1.4034\n",
            "Step [59100/80000], d_real_loss: 0.0730, d_mnist_loss: 0.0260, d_svhn_loss: 0.0471, d_fake_loss: 0.0918, g_loss: 1.1260\n",
            "Step [59110/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0168, d_svhn_loss: 0.0141, d_fake_loss: 0.0646, g_loss: 1.1637\n",
            "Step [59120/80000], d_real_loss: 0.1009, d_mnist_loss: 0.0266, d_svhn_loss: 0.0743, d_fake_loss: 0.1613, g_loss: 1.1713\n",
            "Step [59130/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0168, d_svhn_loss: 0.0391, d_fake_loss: 0.0807, g_loss: 1.0493\n",
            "Step [59140/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0204, d_svhn_loss: 0.0232, d_fake_loss: 0.0918, g_loss: 1.1440\n",
            "Step [59150/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0191, d_svhn_loss: 0.0441, d_fake_loss: 0.0282, g_loss: 1.1526\n",
            "Step [59160/80000], d_real_loss: 0.1051, d_mnist_loss: 0.0298, d_svhn_loss: 0.0754, d_fake_loss: 0.0596, g_loss: 1.1190\n",
            "Step [59170/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0467, d_svhn_loss: 0.0244, d_fake_loss: 0.0291, g_loss: 1.1196\n",
            "Step [59180/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0293, d_svhn_loss: 0.0149, d_fake_loss: 0.0495, g_loss: 1.2484\n",
            "Step [59190/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0197, d_svhn_loss: 0.0198, d_fake_loss: 0.0480, g_loss: 1.3218\n",
            "Step [59200/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0319, d_svhn_loss: 0.0245, d_fake_loss: 0.0416, g_loss: 1.0739\n",
            "Step [59210/80000], d_real_loss: 0.0585, d_mnist_loss: 0.0172, d_svhn_loss: 0.0413, d_fake_loss: 0.0493, g_loss: 1.0680\n",
            "Step [59220/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0293, d_svhn_loss: 0.0250, d_fake_loss: 0.0308, g_loss: 1.2194\n",
            "Step [59230/80000], d_real_loss: 0.0979, d_mnist_loss: 0.0781, d_svhn_loss: 0.0198, d_fake_loss: 0.0438, g_loss: 1.1214\n",
            "Step [59240/80000], d_real_loss: 0.0926, d_mnist_loss: 0.0519, d_svhn_loss: 0.0407, d_fake_loss: 0.0263, g_loss: 1.1758\n",
            "Step [59250/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0370, d_svhn_loss: 0.0305, d_fake_loss: 0.0441, g_loss: 1.0821\n",
            "Step [59260/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0140, d_svhn_loss: 0.0362, d_fake_loss: 0.0963, g_loss: 1.2341\n",
            "Step [59270/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0266, d_svhn_loss: 0.0362, d_fake_loss: 0.0274, g_loss: 1.2506\n",
            "Step [59280/80000], d_real_loss: 0.0313, d_mnist_loss: 0.0115, d_svhn_loss: 0.0197, d_fake_loss: 0.0411, g_loss: 1.0371\n",
            "Step [59290/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0271, d_svhn_loss: 0.0195, d_fake_loss: 0.0277, g_loss: 1.2255\n",
            "Step [59300/80000], d_real_loss: 0.1126, d_mnist_loss: 0.0494, d_svhn_loss: 0.0632, d_fake_loss: 0.0316, g_loss: 1.1057\n",
            "Step [59310/80000], d_real_loss: 0.0385, d_mnist_loss: 0.0227, d_svhn_loss: 0.0158, d_fake_loss: 0.0285, g_loss: 1.1072\n",
            "Step [59320/80000], d_real_loss: 0.0993, d_mnist_loss: 0.0169, d_svhn_loss: 0.0824, d_fake_loss: 0.0356, g_loss: 1.1727\n",
            "Step [59330/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0155, d_svhn_loss: 0.0200, d_fake_loss: 0.0424, g_loss: 1.1018\n",
            "Step [59340/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0419, d_svhn_loss: 0.0236, d_fake_loss: 0.0632, g_loss: 1.0603\n",
            "Step [59350/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0288, d_svhn_loss: 0.0317, d_fake_loss: 0.1111, g_loss: 1.2094\n",
            "Step [59360/80000], d_real_loss: 0.0294, d_mnist_loss: 0.0113, d_svhn_loss: 0.0182, d_fake_loss: 0.0512, g_loss: 1.0759\n",
            "Step [59370/80000], d_real_loss: 0.0909, d_mnist_loss: 0.0720, d_svhn_loss: 0.0189, d_fake_loss: 0.0299, g_loss: 1.0767\n",
            "Step [59380/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0176, d_svhn_loss: 0.0201, d_fake_loss: 0.0408, g_loss: 1.1849\n",
            "Step [59390/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0310, d_svhn_loss: 0.0207, d_fake_loss: 0.0331, g_loss: 1.0561\n",
            "Step [59400/80000], d_real_loss: 0.1615, d_mnist_loss: 0.0379, d_svhn_loss: 0.1235, d_fake_loss: 0.1020, g_loss: 0.9373\n",
            "Step [59410/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0146, d_svhn_loss: 0.0171, d_fake_loss: 0.0694, g_loss: 0.9653\n",
            "Step [59420/80000], d_real_loss: 0.0510, d_mnist_loss: 0.0168, d_svhn_loss: 0.0341, d_fake_loss: 0.0321, g_loss: 1.1959\n",
            "Step [59430/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0631, d_svhn_loss: 0.0542, d_fake_loss: 0.1606, g_loss: 0.9206\n",
            "Step [59440/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0181, d_svhn_loss: 0.0329, d_fake_loss: 0.0407, g_loss: 1.2066\n",
            "Step [59450/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0510, d_svhn_loss: 0.0134, d_fake_loss: 0.0686, g_loss: 1.3703\n",
            "Step [59460/80000], d_real_loss: 0.0818, d_mnist_loss: 0.0516, d_svhn_loss: 0.0301, d_fake_loss: 0.0231, g_loss: 1.0034\n",
            "Step [59470/80000], d_real_loss: 0.2056, d_mnist_loss: 0.0225, d_svhn_loss: 0.1831, d_fake_loss: 0.0556, g_loss: 1.0155\n",
            "Step [59480/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0138, d_svhn_loss: 0.0240, d_fake_loss: 0.0480, g_loss: 1.0706\n",
            "Step [59490/80000], d_real_loss: 0.0765, d_mnist_loss: 0.0507, d_svhn_loss: 0.0258, d_fake_loss: 0.0443, g_loss: 0.9910\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8000129461288452, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [59500/80000], d_real_loss: 0.0963, d_mnist_loss: 0.0505, d_svhn_loss: 0.0458, d_fake_loss: 0.0415, g_loss: 1.0386\n",
            "saved ./samples_fashion/sample-59500-m-s.png\n",
            "saved ./samples_fashion/sample-59500-s-m.png\n",
            "Step [59510/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0434, d_svhn_loss: 0.0191, d_fake_loss: 0.0896, g_loss: 1.0367\n",
            "Step [59520/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0165, d_svhn_loss: 0.0238, d_fake_loss: 0.1155, g_loss: 1.0798\n",
            "Step [59530/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0216, d_svhn_loss: 0.0216, d_fake_loss: 0.0243, g_loss: 1.1755\n",
            "Step [59540/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0397, d_svhn_loss: 0.0156, d_fake_loss: 0.0600, g_loss: 1.1094\n",
            "Step [59550/80000], d_real_loss: 0.1021, d_mnist_loss: 0.0824, d_svhn_loss: 0.0197, d_fake_loss: 0.0353, g_loss: 1.0627\n",
            "Step [59560/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0198, d_svhn_loss: 0.0238, d_fake_loss: 0.0340, g_loss: 1.0593\n",
            "Step [59570/80000], d_real_loss: 0.1581, d_mnist_loss: 0.0250, d_svhn_loss: 0.1331, d_fake_loss: 0.0921, g_loss: 1.1999\n",
            "Step [59580/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0326, d_svhn_loss: 0.0150, d_fake_loss: 0.0423, g_loss: 1.0637\n",
            "Step [59590/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0196, d_svhn_loss: 0.0201, d_fake_loss: 0.0809, g_loss: 1.2358\n",
            "Step [59600/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0131, d_svhn_loss: 0.0406, d_fake_loss: 0.0348, g_loss: 1.1203\n",
            "Step [59610/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0225, d_svhn_loss: 0.0549, d_fake_loss: 0.1268, g_loss: 0.9870\n",
            "Step [59620/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0331, d_svhn_loss: 0.0282, d_fake_loss: 0.0528, g_loss: 1.0253\n",
            "Step [59630/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0269, d_svhn_loss: 0.0209, d_fake_loss: 0.0455, g_loss: 1.1820\n",
            "Step [59640/80000], d_real_loss: 0.2510, d_mnist_loss: 0.1497, d_svhn_loss: 0.1013, d_fake_loss: 0.1160, g_loss: 1.2527\n",
            "Step [59650/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0135, d_svhn_loss: 0.0366, d_fake_loss: 0.0930, g_loss: 0.9985\n",
            "Step [59660/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0210, d_svhn_loss: 0.0372, d_fake_loss: 0.0531, g_loss: 1.3222\n",
            "Step [59670/80000], d_real_loss: 0.1038, d_mnist_loss: 0.0163, d_svhn_loss: 0.0875, d_fake_loss: 0.0690, g_loss: 1.0965\n",
            "Step [59680/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0251, d_svhn_loss: 0.0278, d_fake_loss: 0.0302, g_loss: 1.1816\n",
            "Step [59690/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0143, d_svhn_loss: 0.0167, d_fake_loss: 0.0429, g_loss: 1.2321\n",
            "Step [59700/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0175, d_svhn_loss: 0.0194, d_fake_loss: 0.0641, g_loss: 1.1534\n",
            "Step [59710/80000], d_real_loss: 0.0676, d_mnist_loss: 0.0285, d_svhn_loss: 0.0390, d_fake_loss: 0.0348, g_loss: 1.0777\n",
            "Step [59720/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0135, d_svhn_loss: 0.0378, d_fake_loss: 0.0742, g_loss: 1.0987\n",
            "Step [59730/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0405, d_svhn_loss: 0.0232, d_fake_loss: 0.0489, g_loss: 1.0724\n",
            "Step [59740/80000], d_real_loss: 0.0246, d_mnist_loss: 0.0127, d_svhn_loss: 0.0119, d_fake_loss: 0.1271, g_loss: 1.1849\n",
            "Step [59750/80000], d_real_loss: 0.0605, d_mnist_loss: 0.0320, d_svhn_loss: 0.0286, d_fake_loss: 0.0256, g_loss: 1.0622\n",
            "Step [59760/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0316, d_svhn_loss: 0.0140, d_fake_loss: 0.0297, g_loss: 1.0930\n",
            "Step [59770/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0214, d_svhn_loss: 0.0287, d_fake_loss: 0.0485, g_loss: 1.1456\n",
            "Step [59780/80000], d_real_loss: 0.0811, d_mnist_loss: 0.0209, d_svhn_loss: 0.0602, d_fake_loss: 0.0287, g_loss: 1.2352\n",
            "Step [59790/80000], d_real_loss: 0.0696, d_mnist_loss: 0.0475, d_svhn_loss: 0.0221, d_fake_loss: 0.0443, g_loss: 0.8742\n",
            "Step [59800/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0227, d_svhn_loss: 0.0189, d_fake_loss: 0.0323, g_loss: 1.1386\n",
            "Step [59810/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0129, d_svhn_loss: 0.0462, d_fake_loss: 0.0454, g_loss: 1.2104\n",
            "Step [59820/80000], d_real_loss: 0.0975, d_mnist_loss: 0.0230, d_svhn_loss: 0.0744, d_fake_loss: 0.1241, g_loss: 1.1104\n",
            "Step [59830/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0216, d_svhn_loss: 0.0268, d_fake_loss: 0.0598, g_loss: 1.5220\n",
            "Step [59840/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0231, d_svhn_loss: 0.0263, d_fake_loss: 0.1131, g_loss: 1.1483\n",
            "Step [59850/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0180, d_svhn_loss: 0.0377, d_fake_loss: 0.0471, g_loss: 1.2075\n",
            "Step [59860/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0130, d_svhn_loss: 0.0430, d_fake_loss: 0.0630, g_loss: 1.1872\n",
            "Step [59870/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0147, d_svhn_loss: 0.0454, d_fake_loss: 0.0359, g_loss: 1.1831\n",
            "Step [59880/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0190, d_svhn_loss: 0.0614, d_fake_loss: 0.0582, g_loss: 1.0854\n",
            "Step [59890/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0237, d_svhn_loss: 0.0205, d_fake_loss: 0.0620, g_loss: 1.1167\n",
            "Step [59900/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0192, d_svhn_loss: 0.0266, d_fake_loss: 0.0607, g_loss: 1.3649\n",
            "Step [59910/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0185, d_svhn_loss: 0.0211, d_fake_loss: 0.0321, g_loss: 1.0797\n",
            "Step [59920/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0201, d_svhn_loss: 0.0370, d_fake_loss: 0.0996, g_loss: 1.2403\n",
            "Step [59930/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0164, d_svhn_loss: 0.0268, d_fake_loss: 0.0484, g_loss: 1.2450\n",
            "Step [59940/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0277, d_svhn_loss: 0.0203, d_fake_loss: 0.1205, g_loss: 1.2499\n",
            "Step [59950/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0159, d_svhn_loss: 0.0169, d_fake_loss: 0.0402, g_loss: 1.2182\n",
            "Step [59960/80000], d_real_loss: 0.1019, d_mnist_loss: 0.0764, d_svhn_loss: 0.0254, d_fake_loss: 0.0385, g_loss: 1.0059\n",
            "Step [59970/80000], d_real_loss: 0.0982, d_mnist_loss: 0.0207, d_svhn_loss: 0.0775, d_fake_loss: 0.0263, g_loss: 1.1585\n",
            "Step [59980/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0232, d_svhn_loss: 0.0350, d_fake_loss: 0.0635, g_loss: 1.1953\n",
            "Step [59990/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0263, d_svhn_loss: 0.0260, d_fake_loss: 0.0234, g_loss: 1.1110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8214937448501587, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [60000/80000], d_real_loss: 0.0930, d_mnist_loss: 0.0238, d_svhn_loss: 0.0691, d_fake_loss: 0.0682, g_loss: 1.1373\n",
            "saved ./samples_fashion/sample-60000-m-s.png\n",
            "saved ./samples_fashion/sample-60000-s-m.png\n",
            "Step [60010/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0196, d_svhn_loss: 0.0265, d_fake_loss: 0.0309, g_loss: 1.1783\n",
            "Step [60020/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0196, d_svhn_loss: 0.0272, d_fake_loss: 0.0776, g_loss: 1.1466\n",
            "Step [60030/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0145, d_svhn_loss: 0.0382, d_fake_loss: 0.0279, g_loss: 1.0793\n",
            "Step [60040/80000], d_real_loss: 0.0898, d_mnist_loss: 0.0319, d_svhn_loss: 0.0579, d_fake_loss: 0.0596, g_loss: 1.2215\n",
            "Step [60050/80000], d_real_loss: 0.0569, d_mnist_loss: 0.0248, d_svhn_loss: 0.0320, d_fake_loss: 0.0369, g_loss: 1.1079\n",
            "Step [60060/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0222, d_svhn_loss: 0.0178, d_fake_loss: 0.0312, g_loss: 1.1241\n",
            "Step [60070/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0269, d_svhn_loss: 0.0213, d_fake_loss: 0.0510, g_loss: 1.2598\n",
            "Step [60080/80000], d_real_loss: 0.0809, d_mnist_loss: 0.0170, d_svhn_loss: 0.0639, d_fake_loss: 0.1131, g_loss: 1.0372\n",
            "Step [60090/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0151, d_svhn_loss: 0.0265, d_fake_loss: 0.0557, g_loss: 1.1864\n",
            "Step [60100/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0216, d_svhn_loss: 0.0241, d_fake_loss: 0.0451, g_loss: 1.1465\n",
            "Step [60110/80000], d_real_loss: 0.1033, d_mnist_loss: 0.0350, d_svhn_loss: 0.0683, d_fake_loss: 0.0353, g_loss: 1.1756\n",
            "Step [60120/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0271, d_svhn_loss: 0.0148, d_fake_loss: 0.0230, g_loss: 1.2294\n",
            "Step [60130/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0200, d_svhn_loss: 0.0411, d_fake_loss: 0.1425, g_loss: 1.2561\n",
            "Step [60140/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0239, d_svhn_loss: 0.0449, d_fake_loss: 0.0293, g_loss: 1.1539\n",
            "Step [60150/80000], d_real_loss: 0.0727, d_mnist_loss: 0.0530, d_svhn_loss: 0.0198, d_fake_loss: 0.0444, g_loss: 1.1092\n",
            "Step [60160/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0187, d_svhn_loss: 0.0156, d_fake_loss: 0.1359, g_loss: 1.5001\n",
            "Step [60170/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0379, d_svhn_loss: 0.0181, d_fake_loss: 0.0421, g_loss: 1.0271\n",
            "Step [60180/80000], d_real_loss: 0.1870, d_mnist_loss: 0.0506, d_svhn_loss: 0.1363, d_fake_loss: 0.0819, g_loss: 1.2903\n",
            "Step [60190/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0145, d_svhn_loss: 0.0466, d_fake_loss: 0.0677, g_loss: 1.3261\n",
            "Step [60200/80000], d_real_loss: 0.1001, d_mnist_loss: 0.0312, d_svhn_loss: 0.0689, d_fake_loss: 0.0912, g_loss: 1.2045\n",
            "Step [60210/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0157, d_svhn_loss: 0.0414, d_fake_loss: 0.0358, g_loss: 1.1083\n",
            "Step [60220/80000], d_real_loss: 0.0814, d_mnist_loss: 0.0348, d_svhn_loss: 0.0466, d_fake_loss: 0.0530, g_loss: 1.1903\n",
            "Step [60230/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0133, d_svhn_loss: 0.0496, d_fake_loss: 0.0544, g_loss: 1.1429\n",
            "Step [60240/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0216, d_svhn_loss: 0.0275, d_fake_loss: 0.0427, g_loss: 1.0853\n",
            "Step [60250/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0222, d_svhn_loss: 0.0174, d_fake_loss: 0.0462, g_loss: 1.1284\n",
            "Step [60260/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0157, d_svhn_loss: 0.0537, d_fake_loss: 0.0688, g_loss: 1.0113\n",
            "Step [60270/80000], d_real_loss: 0.0691, d_mnist_loss: 0.0493, d_svhn_loss: 0.0198, d_fake_loss: 0.0571, g_loss: 1.0605\n",
            "Step [60280/80000], d_real_loss: 0.0698, d_mnist_loss: 0.0466, d_svhn_loss: 0.0232, d_fake_loss: 0.0511, g_loss: 0.9220\n",
            "Step [60290/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0133, d_svhn_loss: 0.0254, d_fake_loss: 0.0232, g_loss: 1.1135\n",
            "Step [60300/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0301, d_svhn_loss: 0.0259, d_fake_loss: 0.0282, g_loss: 1.2713\n",
            "Step [60310/80000], d_real_loss: 0.1213, d_mnist_loss: 0.0961, d_svhn_loss: 0.0253, d_fake_loss: 0.0411, g_loss: 1.1160\n",
            "Step [60320/80000], d_real_loss: 0.0882, d_mnist_loss: 0.0556, d_svhn_loss: 0.0326, d_fake_loss: 0.0627, g_loss: 1.1887\n",
            "Step [60330/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0218, d_svhn_loss: 0.0307, d_fake_loss: 0.1078, g_loss: 1.0534\n",
            "Step [60340/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0148, d_svhn_loss: 0.0662, d_fake_loss: 0.0649, g_loss: 1.1142\n",
            "Step [60350/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0118, d_svhn_loss: 0.0215, d_fake_loss: 0.0865, g_loss: 1.2311\n",
            "Step [60360/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0252, d_svhn_loss: 0.0233, d_fake_loss: 0.0453, g_loss: 1.1376\n",
            "Step [60370/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0215, d_svhn_loss: 0.0184, d_fake_loss: 0.0398, g_loss: 1.1740\n",
            "Step [60380/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0151, d_svhn_loss: 0.0200, d_fake_loss: 0.0375, g_loss: 1.2484\n",
            "Step [60390/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0426, d_svhn_loss: 0.0136, d_fake_loss: 0.0746, g_loss: 1.2271\n",
            "Step [60400/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0198, d_svhn_loss: 0.0197, d_fake_loss: 0.0505, g_loss: 1.2714\n",
            "Step [60410/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0171, d_svhn_loss: 0.0407, d_fake_loss: 0.0400, g_loss: 1.2213\n",
            "Step [60420/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0187, d_svhn_loss: 0.0313, d_fake_loss: 0.0309, g_loss: 1.1008\n",
            "Step [60430/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0215, d_svhn_loss: 0.0261, d_fake_loss: 0.0595, g_loss: 1.1609\n",
            "Step [60440/80000], d_real_loss: 0.0770, d_mnist_loss: 0.0619, d_svhn_loss: 0.0151, d_fake_loss: 0.0650, g_loss: 0.8579\n",
            "Step [60450/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0259, d_svhn_loss: 0.0209, d_fake_loss: 0.0385, g_loss: 1.2204\n",
            "Step [60460/80000], d_real_loss: 0.0941, d_mnist_loss: 0.0614, d_svhn_loss: 0.0327, d_fake_loss: 0.0379, g_loss: 1.2310\n",
            "Step [60470/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0359, d_svhn_loss: 0.0249, d_fake_loss: 0.0279, g_loss: 1.2563\n",
            "Step [60480/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0339, d_svhn_loss: 0.0135, d_fake_loss: 0.1492, g_loss: 0.9742\n",
            "Step [60490/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0252, d_svhn_loss: 0.0169, d_fake_loss: 0.0719, g_loss: 1.1981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7711763381958008, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [60500/80000], d_real_loss: 0.0766, d_mnist_loss: 0.0237, d_svhn_loss: 0.0530, d_fake_loss: 0.0611, g_loss: 1.1931\n",
            "saved ./samples_fashion/sample-60500-m-s.png\n",
            "saved ./samples_fashion/sample-60500-s-m.png\n",
            "Step [60510/80000], d_real_loss: 0.0938, d_mnist_loss: 0.0104, d_svhn_loss: 0.0834, d_fake_loss: 0.0809, g_loss: 1.2576\n",
            "Step [60520/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0287, d_svhn_loss: 0.0208, d_fake_loss: 0.0306, g_loss: 1.1639\n",
            "Step [60530/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0308, d_svhn_loss: 0.0206, d_fake_loss: 0.0413, g_loss: 1.1777\n",
            "Step [60540/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0228, d_svhn_loss: 0.0179, d_fake_loss: 0.0301, g_loss: 1.1361\n",
            "Step [60550/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0508, d_svhn_loss: 0.0202, d_fake_loss: 0.0350, g_loss: 0.9811\n",
            "Step [60560/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0392, d_svhn_loss: 0.0260, d_fake_loss: 0.0504, g_loss: 1.2242\n",
            "Step [60570/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0133, d_svhn_loss: 0.0173, d_fake_loss: 0.0513, g_loss: 1.1591\n",
            "Step [60580/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0193, d_svhn_loss: 0.0251, d_fake_loss: 0.0834, g_loss: 1.2307\n",
            "Step [60590/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0192, d_svhn_loss: 0.0126, d_fake_loss: 0.0213, g_loss: 1.1650\n",
            "Step [60600/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0127, d_svhn_loss: 0.0215, d_fake_loss: 0.0516, g_loss: 1.1425\n",
            "Step [60610/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0191, d_svhn_loss: 0.0232, d_fake_loss: 0.0680, g_loss: 1.1419\n",
            "Step [60620/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0199, d_svhn_loss: 0.0187, d_fake_loss: 0.0381, g_loss: 1.1411\n",
            "Step [60630/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0252, d_svhn_loss: 0.0182, d_fake_loss: 0.1078, g_loss: 1.1139\n",
            "Step [60640/80000], d_real_loss: 0.0276, d_mnist_loss: 0.0127, d_svhn_loss: 0.0149, d_fake_loss: 0.0150, g_loss: 1.0664\n",
            "Step [60650/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0275, d_svhn_loss: 0.0136, d_fake_loss: 0.0255, g_loss: 1.0718\n",
            "Step [60660/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0176, d_svhn_loss: 0.0291, d_fake_loss: 0.1341, g_loss: 1.1915\n",
            "Step [60670/80000], d_real_loss: 0.1163, d_mnist_loss: 0.0422, d_svhn_loss: 0.0740, d_fake_loss: 0.0440, g_loss: 1.0815\n",
            "Step [60680/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0226, d_svhn_loss: 0.0301, d_fake_loss: 0.1128, g_loss: 1.1138\n",
            "Step [60690/80000], d_real_loss: 0.0264, d_mnist_loss: 0.0139, d_svhn_loss: 0.0125, d_fake_loss: 0.0851, g_loss: 1.1492\n",
            "Step [60700/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0232, d_svhn_loss: 0.0253, d_fake_loss: 0.0956, g_loss: 1.1837\n",
            "Step [60710/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0178, d_svhn_loss: 0.0522, d_fake_loss: 0.0292, g_loss: 1.2102\n",
            "Step [60720/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0232, d_svhn_loss: 0.0236, d_fake_loss: 0.0291, g_loss: 1.1603\n",
            "Step [60730/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0199, d_svhn_loss: 0.0199, d_fake_loss: 0.0405, g_loss: 1.0613\n",
            "Step [60740/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0209, d_svhn_loss: 0.0200, d_fake_loss: 0.0459, g_loss: 1.2651\n",
            "Step [60750/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0196, d_svhn_loss: 0.0202, d_fake_loss: 0.0358, g_loss: 1.1532\n",
            "Step [60760/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0426, d_svhn_loss: 0.0211, d_fake_loss: 0.1298, g_loss: 1.2547\n",
            "Step [60770/80000], d_real_loss: 0.1261, d_mnist_loss: 0.0618, d_svhn_loss: 0.0643, d_fake_loss: 0.0808, g_loss: 1.0279\n",
            "Step [60780/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0358, d_svhn_loss: 0.0270, d_fake_loss: 0.0768, g_loss: 1.0407\n",
            "Step [60790/80000], d_real_loss: 0.0823, d_mnist_loss: 0.0171, d_svhn_loss: 0.0652, d_fake_loss: 0.0664, g_loss: 1.0828\n",
            "Step [60800/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0281, d_svhn_loss: 0.0503, d_fake_loss: 0.0396, g_loss: 1.0992\n",
            "Step [60810/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0772, d_svhn_loss: 0.0401, d_fake_loss: 0.0432, g_loss: 1.0476\n",
            "Step [60820/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0184, d_svhn_loss: 0.0218, d_fake_loss: 0.0413, g_loss: 1.1484\n",
            "Step [60830/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0259, d_svhn_loss: 0.0276, d_fake_loss: 0.0487, g_loss: 1.1736\n",
            "Step [60840/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0144, d_svhn_loss: 0.0215, d_fake_loss: 0.0392, g_loss: 1.1126\n",
            "Step [60850/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0193, d_svhn_loss: 0.0221, d_fake_loss: 0.0714, g_loss: 1.1236\n",
            "Step [60860/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0176, d_svhn_loss: 0.0564, d_fake_loss: 0.0509, g_loss: 1.0793\n",
            "Step [60870/80000], d_real_loss: 0.0814, d_mnist_loss: 0.0249, d_svhn_loss: 0.0565, d_fake_loss: 0.1436, g_loss: 1.5089\n",
            "Step [60880/80000], d_real_loss: 0.0756, d_mnist_loss: 0.0163, d_svhn_loss: 0.0592, d_fake_loss: 0.0785, g_loss: 1.1913\n",
            "Step [60890/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0350, d_svhn_loss: 0.0147, d_fake_loss: 0.0421, g_loss: 1.0646\n",
            "Step [60900/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0195, d_svhn_loss: 0.0399, d_fake_loss: 0.1065, g_loss: 1.1429\n",
            "Step [60910/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0179, d_svhn_loss: 0.0193, d_fake_loss: 0.0504, g_loss: 1.3312\n",
            "Step [60920/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0294, d_svhn_loss: 0.0244, d_fake_loss: 0.0379, g_loss: 1.1494\n",
            "Step [60930/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0455, d_svhn_loss: 0.0226, d_fake_loss: 0.1596, g_loss: 1.1798\n",
            "Step [60940/80000], d_real_loss: 0.1195, d_mnist_loss: 0.0197, d_svhn_loss: 0.0998, d_fake_loss: 0.0270, g_loss: 1.1256\n",
            "Step [60950/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0170, d_svhn_loss: 0.0300, d_fake_loss: 0.0284, g_loss: 1.1566\n",
            "Step [60960/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0179, d_svhn_loss: 0.0207, d_fake_loss: 0.0432, g_loss: 1.3108\n",
            "Step [60970/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0114, d_svhn_loss: 0.0186, d_fake_loss: 0.0746, g_loss: 1.2226\n",
            "Step [60980/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0173, d_svhn_loss: 0.0232, d_fake_loss: 0.0275, g_loss: 1.1370\n",
            "Step [60990/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0398, d_svhn_loss: 0.0139, d_fake_loss: 0.0671, g_loss: 1.0964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7559652328491211, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [61000/80000], d_real_loss: 0.0540, d_mnist_loss: 0.0317, d_svhn_loss: 0.0223, d_fake_loss: 0.0428, g_loss: 1.0642\n",
            "saved ./samples_fashion/sample-61000-m-s.png\n",
            "saved ./samples_fashion/sample-61000-s-m.png\n",
            "Step [61010/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0439, d_svhn_loss: 0.0203, d_fake_loss: 0.0373, g_loss: 1.0528\n",
            "Step [61020/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0214, d_svhn_loss: 0.0194, d_fake_loss: 0.0378, g_loss: 1.1957\n",
            "Step [61030/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0414, d_svhn_loss: 0.0208, d_fake_loss: 0.0419, g_loss: 0.9719\n",
            "Step [61040/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0307, d_svhn_loss: 0.0285, d_fake_loss: 0.0408, g_loss: 1.0441\n",
            "Step [61050/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0171, d_svhn_loss: 0.0388, d_fake_loss: 0.0344, g_loss: 1.2559\n",
            "Step [61060/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0432, d_svhn_loss: 0.0230, d_fake_loss: 0.0281, g_loss: 1.0409\n",
            "Step [61070/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0163, d_svhn_loss: 0.0384, d_fake_loss: 0.0424, g_loss: 1.1467\n",
            "Step [61080/80000], d_real_loss: 0.1243, d_mnist_loss: 0.0204, d_svhn_loss: 0.1039, d_fake_loss: 0.0575, g_loss: 1.2652\n",
            "Step [61090/80000], d_real_loss: 0.0783, d_mnist_loss: 0.0241, d_svhn_loss: 0.0542, d_fake_loss: 0.0470, g_loss: 1.1284\n",
            "Step [61100/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0452, d_svhn_loss: 0.0242, d_fake_loss: 0.0332, g_loss: 1.0307\n",
            "Step [61110/80000], d_real_loss: 0.1215, d_mnist_loss: 0.0146, d_svhn_loss: 0.1068, d_fake_loss: 0.0342, g_loss: 1.0861\n",
            "Step [61120/80000], d_real_loss: 0.1061, d_mnist_loss: 0.0744, d_svhn_loss: 0.0316, d_fake_loss: 0.0645, g_loss: 1.0855\n",
            "Step [61130/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0564, d_svhn_loss: 0.0303, d_fake_loss: 0.0463, g_loss: 1.1202\n",
            "Step [61140/80000], d_real_loss: 0.0970, d_mnist_loss: 0.0614, d_svhn_loss: 0.0356, d_fake_loss: 0.0551, g_loss: 1.0197\n",
            "Step [61150/80000], d_real_loss: 0.0923, d_mnist_loss: 0.0730, d_svhn_loss: 0.0193, d_fake_loss: 0.0563, g_loss: 1.0059\n",
            "Step [61160/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0260, d_svhn_loss: 0.0200, d_fake_loss: 0.0438, g_loss: 1.0512\n",
            "Step [61170/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0173, d_svhn_loss: 0.0202, d_fake_loss: 0.0326, g_loss: 1.0248\n",
            "Step [61180/80000], d_real_loss: 0.1194, d_mnist_loss: 0.0989, d_svhn_loss: 0.0205, d_fake_loss: 0.0576, g_loss: 1.0944\n",
            "Step [61190/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0313, d_svhn_loss: 0.0482, d_fake_loss: 0.0750, g_loss: 0.8782\n",
            "Step [61200/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0176, d_svhn_loss: 0.0367, d_fake_loss: 0.0342, g_loss: 1.0794\n",
            "Step [61210/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0512, d_svhn_loss: 0.0405, d_fake_loss: 0.0301, g_loss: 1.2640\n",
            "Step [61220/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0247, d_svhn_loss: 0.0405, d_fake_loss: 0.0556, g_loss: 1.0346\n",
            "Step [61230/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0228, d_svhn_loss: 0.0229, d_fake_loss: 0.1087, g_loss: 1.1183\n",
            "Step [61240/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0394, d_svhn_loss: 0.0179, d_fake_loss: 0.0400, g_loss: 1.1649\n",
            "Step [61250/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0130, d_svhn_loss: 0.0161, d_fake_loss: 0.0385, g_loss: 1.0543\n",
            "Step [61260/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0290, d_svhn_loss: 0.0145, d_fake_loss: 0.0318, g_loss: 1.0685\n",
            "Step [61270/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0142, d_svhn_loss: 0.0261, d_fake_loss: 0.0918, g_loss: 1.1865\n",
            "Step [61280/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0262, d_svhn_loss: 0.0221, d_fake_loss: 0.0335, g_loss: 1.1204\n",
            "Step [61290/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0196, d_svhn_loss: 0.0283, d_fake_loss: 0.0285, g_loss: 1.1810\n",
            "Step [61300/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0129, d_svhn_loss: 0.0341, d_fake_loss: 0.0286, g_loss: 1.1536\n",
            "Step [61310/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0206, d_svhn_loss: 0.0239, d_fake_loss: 0.1065, g_loss: 1.2994\n",
            "Step [61320/80000], d_real_loss: 0.1401, d_mnist_loss: 0.1234, d_svhn_loss: 0.0167, d_fake_loss: 0.0561, g_loss: 1.2222\n",
            "Step [61330/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0228, d_svhn_loss: 0.0559, d_fake_loss: 0.0464, g_loss: 1.0768\n",
            "Step [61340/80000], d_real_loss: 0.0292, d_mnist_loss: 0.0208, d_svhn_loss: 0.0085, d_fake_loss: 0.0424, g_loss: 1.2328\n",
            "Step [61350/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0140, d_svhn_loss: 0.0170, d_fake_loss: 0.0350, g_loss: 1.1076\n",
            "Step [61360/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0356, d_svhn_loss: 0.0137, d_fake_loss: 0.0749, g_loss: 1.2204\n",
            "Step [61370/80000], d_real_loss: 0.0667, d_mnist_loss: 0.0463, d_svhn_loss: 0.0204, d_fake_loss: 0.0370, g_loss: 1.1616\n",
            "Step [61380/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0135, d_svhn_loss: 0.0144, d_fake_loss: 0.0556, g_loss: 1.0578\n",
            "Step [61390/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0243, d_svhn_loss: 0.0149, d_fake_loss: 0.0941, g_loss: 1.1706\n",
            "Step [61400/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0162, d_svhn_loss: 0.0240, d_fake_loss: 0.0323, g_loss: 1.0874\n",
            "Step [61410/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0525, d_svhn_loss: 0.0281, d_fake_loss: 0.0715, g_loss: 1.1519\n",
            "Step [61420/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0343, d_svhn_loss: 0.0194, d_fake_loss: 0.0852, g_loss: 1.1244\n",
            "Step [61430/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0110, d_svhn_loss: 0.0317, d_fake_loss: 0.0269, g_loss: 1.1316\n",
            "Step [61440/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0137, d_svhn_loss: 0.0256, d_fake_loss: 0.2048, g_loss: 1.0994\n",
            "Step [61450/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0181, d_svhn_loss: 0.0398, d_fake_loss: 0.0355, g_loss: 0.9565\n",
            "Step [61460/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0234, d_svhn_loss: 0.0264, d_fake_loss: 0.0441, g_loss: 1.1223\n",
            "Step [61470/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0192, d_svhn_loss: 0.0308, d_fake_loss: 0.0303, g_loss: 1.1541\n",
            "Step [61480/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0167, d_svhn_loss: 0.0162, d_fake_loss: 0.0515, g_loss: 1.1601\n",
            "Step [61490/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0268, d_svhn_loss: 0.0330, d_fake_loss: 0.0809, g_loss: 1.1915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7453504800796509, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [61500/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0165, d_svhn_loss: 0.0320, d_fake_loss: 0.0577, g_loss: 1.2651\n",
            "saved ./samples_fashion/sample-61500-m-s.png\n",
            "saved ./samples_fashion/sample-61500-s-m.png\n",
            "Step [61510/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0201, d_svhn_loss: 0.0193, d_fake_loss: 0.1261, g_loss: 1.4658\n",
            "Step [61520/80000], d_real_loss: 0.0801, d_mnist_loss: 0.0323, d_svhn_loss: 0.0478, d_fake_loss: 0.0597, g_loss: 1.2881\n",
            "Step [61530/80000], d_real_loss: 0.0934, d_mnist_loss: 0.0714, d_svhn_loss: 0.0220, d_fake_loss: 0.1575, g_loss: 1.2741\n",
            "Step [61540/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0322, d_svhn_loss: 0.0281, d_fake_loss: 0.1178, g_loss: 1.2625\n",
            "Step [61550/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0169, d_svhn_loss: 0.0393, d_fake_loss: 0.0385, g_loss: 1.0954\n",
            "Step [61560/80000], d_real_loss: 0.1054, d_mnist_loss: 0.0886, d_svhn_loss: 0.0167, d_fake_loss: 0.1086, g_loss: 1.2683\n",
            "Step [61570/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0442, d_svhn_loss: 0.0159, d_fake_loss: 0.0576, g_loss: 0.9740\n",
            "Step [61580/80000], d_real_loss: 0.1328, d_mnist_loss: 0.0388, d_svhn_loss: 0.0940, d_fake_loss: 0.0448, g_loss: 1.0185\n",
            "Step [61590/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0269, d_svhn_loss: 0.0311, d_fake_loss: 0.0481, g_loss: 1.1056\n",
            "Step [61600/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0301, d_svhn_loss: 0.0267, d_fake_loss: 0.0366, g_loss: 1.1031\n",
            "Step [61610/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0156, d_svhn_loss: 0.0193, d_fake_loss: 0.0469, g_loss: 1.1632\n",
            "Step [61620/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0141, d_svhn_loss: 0.0411, d_fake_loss: 0.0408, g_loss: 1.0730\n",
            "Step [61630/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0168, d_svhn_loss: 0.0179, d_fake_loss: 0.0566, g_loss: 1.2010\n",
            "Step [61640/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0194, d_svhn_loss: 0.0253, d_fake_loss: 0.0400, g_loss: 1.2109\n",
            "Step [61650/80000], d_real_loss: 0.1814, d_mnist_loss: 0.1703, d_svhn_loss: 0.0111, d_fake_loss: 0.0764, g_loss: 1.3693\n",
            "Step [61660/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0178, d_svhn_loss: 0.0306, d_fake_loss: 0.0362, g_loss: 1.1468\n",
            "Step [61670/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0211, d_svhn_loss: 0.0240, d_fake_loss: 0.0549, g_loss: 1.0576\n",
            "Step [61680/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0186, d_svhn_loss: 0.0563, d_fake_loss: 0.0380, g_loss: 1.0460\n",
            "Step [61690/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0158, d_svhn_loss: 0.0673, d_fake_loss: 0.0327, g_loss: 1.1736\n",
            "Step [61700/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0230, d_svhn_loss: 0.0528, d_fake_loss: 0.0531, g_loss: 0.9922\n",
            "Step [61710/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0263, d_svhn_loss: 0.0222, d_fake_loss: 0.0366, g_loss: 1.1063\n",
            "Step [61720/80000], d_real_loss: 0.0953, d_mnist_loss: 0.0108, d_svhn_loss: 0.0844, d_fake_loss: 0.1795, g_loss: 1.0543\n",
            "Step [61730/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0228, d_svhn_loss: 0.0294, d_fake_loss: 0.1205, g_loss: 1.3483\n",
            "Step [61740/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0392, d_svhn_loss: 0.0214, d_fake_loss: 0.0419, g_loss: 1.1786\n",
            "Step [61750/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0447, d_svhn_loss: 0.0190, d_fake_loss: 0.0260, g_loss: 1.1837\n",
            "Step [61760/80000], d_real_loss: 0.2180, d_mnist_loss: 0.1725, d_svhn_loss: 0.0454, d_fake_loss: 0.0397, g_loss: 1.2603\n",
            "Step [61770/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0184, d_svhn_loss: 0.0198, d_fake_loss: 0.0442, g_loss: 1.1062\n",
            "Step [61780/80000], d_real_loss: 0.1151, d_mnist_loss: 0.0205, d_svhn_loss: 0.0946, d_fake_loss: 0.0709, g_loss: 1.1832\n",
            "Step [61790/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0162, d_svhn_loss: 0.0418, d_fake_loss: 0.0359, g_loss: 1.0980\n",
            "Step [61800/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0172, d_svhn_loss: 0.0143, d_fake_loss: 0.0274, g_loss: 1.1018\n",
            "Step [61810/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0158, d_svhn_loss: 0.0539, d_fake_loss: 0.0699, g_loss: 1.2647\n",
            "Step [61820/80000], d_real_loss: 0.1272, d_mnist_loss: 0.0162, d_svhn_loss: 0.1111, d_fake_loss: 0.0387, g_loss: 1.0808\n",
            "Step [61830/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0196, d_svhn_loss: 0.0178, d_fake_loss: 0.0283, g_loss: 1.1019\n",
            "Step [61840/80000], d_real_loss: 0.1011, d_mnist_loss: 0.0306, d_svhn_loss: 0.0704, d_fake_loss: 0.0240, g_loss: 1.0554\n",
            "Step [61850/80000], d_real_loss: 0.0746, d_mnist_loss: 0.0549, d_svhn_loss: 0.0197, d_fake_loss: 0.0408, g_loss: 1.1205\n",
            "Step [61860/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0271, d_svhn_loss: 0.0316, d_fake_loss: 0.0509, g_loss: 1.2678\n",
            "Step [61870/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0104, d_svhn_loss: 0.0372, d_fake_loss: 0.0362, g_loss: 1.2318\n",
            "Step [61880/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0190, d_svhn_loss: 0.0244, d_fake_loss: 0.0349, g_loss: 1.2442\n",
            "Step [61890/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0228, d_svhn_loss: 0.0326, d_fake_loss: 0.0232, g_loss: 1.1732\n",
            "Step [61900/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0198, d_svhn_loss: 0.0390, d_fake_loss: 0.0341, g_loss: 1.1138\n",
            "Step [61910/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0167, d_svhn_loss: 0.0432, d_fake_loss: 0.0380, g_loss: 1.0856\n",
            "Step [61920/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0178, d_svhn_loss: 0.0248, d_fake_loss: 0.0422, g_loss: 1.1840\n",
            "Step [61930/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0107, d_svhn_loss: 0.0531, d_fake_loss: 0.0225, g_loss: 1.0091\n",
            "Step [61940/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0204, d_svhn_loss: 0.0421, d_fake_loss: 0.0430, g_loss: 1.1494\n",
            "Step [61950/80000], d_real_loss: 0.0307, d_mnist_loss: 0.0111, d_svhn_loss: 0.0196, d_fake_loss: 0.1223, g_loss: 0.8569\n",
            "Step [61960/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0161, d_svhn_loss: 0.0407, d_fake_loss: 0.0954, g_loss: 1.2156\n",
            "Step [61970/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0177, d_svhn_loss: 0.0275, d_fake_loss: 0.0464, g_loss: 1.0943\n",
            "Step [61980/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0241, d_svhn_loss: 0.0166, d_fake_loss: 0.0370, g_loss: 1.3575\n",
            "Step [61990/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0240, d_svhn_loss: 0.0193, d_fake_loss: 0.0624, g_loss: 0.9830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.729954719543457, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [62000/80000], d_real_loss: 0.1776, d_mnist_loss: 0.0972, d_svhn_loss: 0.0803, d_fake_loss: 0.0604, g_loss: 1.3358\n",
            "saved ./samples_fashion/sample-62000-m-s.png\n",
            "saved ./samples_fashion/sample-62000-s-m.png\n",
            "Step [62010/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0190, d_svhn_loss: 0.0233, d_fake_loss: 0.1290, g_loss: 1.3497\n",
            "Step [62020/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0200, d_svhn_loss: 0.0181, d_fake_loss: 0.0340, g_loss: 1.0291\n",
            "Step [62030/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0180, d_svhn_loss: 0.0209, d_fake_loss: 0.0380, g_loss: 1.1990\n",
            "Step [62040/80000], d_real_loss: 0.1149, d_mnist_loss: 0.0732, d_svhn_loss: 0.0416, d_fake_loss: 0.0546, g_loss: 1.1629\n",
            "Step [62050/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0170, d_svhn_loss: 0.0547, d_fake_loss: 0.0561, g_loss: 1.0961\n",
            "Step [62060/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0200, d_svhn_loss: 0.0176, d_fake_loss: 0.0176, g_loss: 1.1405\n",
            "Step [62070/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0207, d_svhn_loss: 0.0155, d_fake_loss: 0.0387, g_loss: 1.3665\n",
            "Step [62080/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0402, d_svhn_loss: 0.0206, d_fake_loss: 0.0322, g_loss: 1.0812\n",
            "Step [62090/80000], d_real_loss: 0.1585, d_mnist_loss: 0.1289, d_svhn_loss: 0.0296, d_fake_loss: 0.0291, g_loss: 1.1956\n",
            "Step [62100/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0332, d_svhn_loss: 0.0206, d_fake_loss: 0.0419, g_loss: 1.1180\n",
            "Step [62110/80000], d_real_loss: 0.1035, d_mnist_loss: 0.0775, d_svhn_loss: 0.0260, d_fake_loss: 0.1310, g_loss: 1.0870\n",
            "Step [62120/80000], d_real_loss: 0.1067, d_mnist_loss: 0.0147, d_svhn_loss: 0.0921, d_fake_loss: 0.0831, g_loss: 1.1978\n",
            "Step [62130/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0338, d_svhn_loss: 0.0361, d_fake_loss: 0.0317, g_loss: 1.0076\n",
            "Step [62140/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0232, d_svhn_loss: 0.0450, d_fake_loss: 0.0313, g_loss: 1.1872\n",
            "Step [62150/80000], d_real_loss: 0.1441, d_mnist_loss: 0.1220, d_svhn_loss: 0.0221, d_fake_loss: 0.0502, g_loss: 1.3053\n",
            "Step [62160/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0381, d_svhn_loss: 0.0297, d_fake_loss: 0.1387, g_loss: 1.1707\n",
            "Step [62170/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0157, d_svhn_loss: 0.0277, d_fake_loss: 0.0313, g_loss: 1.1598\n",
            "Step [62180/80000], d_real_loss: 0.1856, d_mnist_loss: 0.0384, d_svhn_loss: 0.1473, d_fake_loss: 0.0758, g_loss: 1.1074\n",
            "Step [62190/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0331, d_svhn_loss: 0.0266, d_fake_loss: 0.0482, g_loss: 1.0516\n",
            "Step [62200/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0499, d_svhn_loss: 0.0369, d_fake_loss: 0.0628, g_loss: 1.1466\n",
            "Step [62210/80000], d_real_loss: 0.0370, d_mnist_loss: 0.0145, d_svhn_loss: 0.0225, d_fake_loss: 0.0270, g_loss: 1.1425\n",
            "Step [62220/80000], d_real_loss: 0.0897, d_mnist_loss: 0.0206, d_svhn_loss: 0.0691, d_fake_loss: 0.0683, g_loss: 1.2071\n",
            "Step [62230/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0324, d_svhn_loss: 0.0307, d_fake_loss: 0.0658, g_loss: 1.1677\n",
            "Step [62240/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0287, d_svhn_loss: 0.0307, d_fake_loss: 0.0461, g_loss: 1.1303\n",
            "Step [62250/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0437, d_svhn_loss: 0.0182, d_fake_loss: 0.1496, g_loss: 1.3054\n",
            "Step [62260/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0181, d_svhn_loss: 0.0156, d_fake_loss: 0.0181, g_loss: 1.1816\n",
            "Step [62270/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0404, d_svhn_loss: 0.0176, d_fake_loss: 0.0623, g_loss: 1.1403\n",
            "Step [62280/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0222, d_svhn_loss: 0.0140, d_fake_loss: 0.0439, g_loss: 1.2404\n",
            "Step [62290/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0229, d_svhn_loss: 0.0453, d_fake_loss: 0.0330, g_loss: 1.1247\n",
            "Step [62300/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0462, d_svhn_loss: 0.0351, d_fake_loss: 0.0517, g_loss: 1.1466\n",
            "Step [62310/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0156, d_svhn_loss: 0.0587, d_fake_loss: 0.0328, g_loss: 1.2104\n",
            "Step [62320/80000], d_real_loss: 0.0994, d_mnist_loss: 0.0325, d_svhn_loss: 0.0669, d_fake_loss: 0.0640, g_loss: 1.1996\n",
            "Step [62330/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0208, d_svhn_loss: 0.0188, d_fake_loss: 0.0474, g_loss: 1.1992\n",
            "Step [62340/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0135, d_svhn_loss: 0.0205, d_fake_loss: 0.0999, g_loss: 0.8143\n",
            "Step [62350/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0296, d_svhn_loss: 0.0370, d_fake_loss: 0.0311, g_loss: 1.1847\n",
            "Step [62360/80000], d_real_loss: 0.1410, d_mnist_loss: 0.0273, d_svhn_loss: 0.1137, d_fake_loss: 0.0985, g_loss: 1.0084\n",
            "Step [62370/80000], d_real_loss: 0.1044, d_mnist_loss: 0.0355, d_svhn_loss: 0.0689, d_fake_loss: 0.0386, g_loss: 1.0533\n",
            "Step [62380/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0209, d_svhn_loss: 0.0158, d_fake_loss: 0.0777, g_loss: 1.0440\n",
            "Step [62390/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0170, d_svhn_loss: 0.0389, d_fake_loss: 0.0277, g_loss: 1.3025\n",
            "Step [62400/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0190, d_svhn_loss: 0.0209, d_fake_loss: 0.0937, g_loss: 1.2780\n",
            "Step [62410/80000], d_real_loss: 0.1210, d_mnist_loss: 0.0754, d_svhn_loss: 0.0456, d_fake_loss: 0.0659, g_loss: 1.1420\n",
            "Step [62420/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0233, d_svhn_loss: 0.0202, d_fake_loss: 0.0612, g_loss: 1.2244\n",
            "Step [62430/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0156, d_svhn_loss: 0.0116, d_fake_loss: 0.0986, g_loss: 1.2998\n",
            "Step [62440/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0169, d_svhn_loss: 0.0281, d_fake_loss: 0.0457, g_loss: 1.1513\n",
            "Step [62450/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0199, d_svhn_loss: 0.0286, d_fake_loss: 0.0372, g_loss: 1.0997\n",
            "Step [62460/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0358, d_svhn_loss: 0.0245, d_fake_loss: 0.0484, g_loss: 1.2046\n",
            "Step [62470/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0545, d_svhn_loss: 0.0101, d_fake_loss: 0.0789, g_loss: 1.1476\n",
            "Step [62480/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0126, d_svhn_loss: 0.0214, d_fake_loss: 0.0735, g_loss: 1.0482\n",
            "Step [62490/80000], d_real_loss: 0.0999, d_mnist_loss: 0.0806, d_svhn_loss: 0.0193, d_fake_loss: 0.0378, g_loss: 1.1605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7530106902122498, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [62500/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0351, d_svhn_loss: 0.0201, d_fake_loss: 0.0663, g_loss: 1.2053\n",
            "saved ./samples_fashion/sample-62500-m-s.png\n",
            "saved ./samples_fashion/sample-62500-s-m.png\n",
            "Step [62510/80000], d_real_loss: 0.1032, d_mnist_loss: 0.0859, d_svhn_loss: 0.0174, d_fake_loss: 0.0522, g_loss: 1.1127\n",
            "Step [62520/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0191, d_svhn_loss: 0.0128, d_fake_loss: 0.0345, g_loss: 1.2051\n",
            "Step [62530/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0176, d_svhn_loss: 0.0349, d_fake_loss: 0.0615, g_loss: 1.1236\n",
            "Step [62540/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0125, d_svhn_loss: 0.0359, d_fake_loss: 0.0465, g_loss: 1.2067\n",
            "Step [62550/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0174, d_svhn_loss: 0.0213, d_fake_loss: 0.0794, g_loss: 1.2063\n",
            "Step [62560/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0177, d_svhn_loss: 0.0283, d_fake_loss: 0.0339, g_loss: 1.1492\n",
            "Step [62570/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0275, d_svhn_loss: 0.0197, d_fake_loss: 0.0325, g_loss: 1.0141\n",
            "Step [62580/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0169, d_svhn_loss: 0.0261, d_fake_loss: 0.0542, g_loss: 1.2568\n",
            "Step [62590/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0175, d_svhn_loss: 0.0288, d_fake_loss: 0.0289, g_loss: 1.1279\n",
            "Step [62600/80000], d_real_loss: 0.1236, d_mnist_loss: 0.0982, d_svhn_loss: 0.0254, d_fake_loss: 0.1328, g_loss: 1.6591\n",
            "Step [62610/80000], d_real_loss: 0.1066, d_mnist_loss: 0.0131, d_svhn_loss: 0.0934, d_fake_loss: 0.0492, g_loss: 1.1120\n",
            "Step [62620/80000], d_real_loss: 0.1621, d_mnist_loss: 0.1308, d_svhn_loss: 0.0313, d_fake_loss: 0.0940, g_loss: 1.5013\n",
            "Step [62630/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0145, d_svhn_loss: 0.0183, d_fake_loss: 0.0546, g_loss: 1.1794\n",
            "Step [62640/80000], d_real_loss: 0.0543, d_mnist_loss: 0.0330, d_svhn_loss: 0.0213, d_fake_loss: 0.0667, g_loss: 1.1762\n",
            "Step [62650/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0171, d_svhn_loss: 0.0223, d_fake_loss: 0.1263, g_loss: 1.2844\n",
            "Step [62660/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0190, d_svhn_loss: 0.0187, d_fake_loss: 0.0228, g_loss: 1.1389\n",
            "Step [62670/80000], d_real_loss: 0.0929, d_mnist_loss: 0.0752, d_svhn_loss: 0.0176, d_fake_loss: 0.1465, g_loss: 1.2873\n",
            "Step [62680/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0163, d_svhn_loss: 0.0212, d_fake_loss: 0.0805, g_loss: 1.2905\n",
            "Step [62690/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0109, d_svhn_loss: 0.0259, d_fake_loss: 0.0261, g_loss: 1.1383\n",
            "Step [62700/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0254, d_svhn_loss: 0.0352, d_fake_loss: 0.0327, g_loss: 1.1054\n",
            "Step [62710/80000], d_real_loss: 0.0710, d_mnist_loss: 0.0422, d_svhn_loss: 0.0289, d_fake_loss: 0.0706, g_loss: 1.3040\n",
            "Step [62720/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0166, d_svhn_loss: 0.0301, d_fake_loss: 0.0504, g_loss: 1.0478\n",
            "Step [62730/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0289, d_svhn_loss: 0.0190, d_fake_loss: 0.0494, g_loss: 1.2157\n",
            "Step [62740/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0359, d_svhn_loss: 0.0227, d_fake_loss: 0.0345, g_loss: 1.1345\n",
            "Step [62750/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0200, d_svhn_loss: 0.0285, d_fake_loss: 0.0421, g_loss: 1.1662\n",
            "Step [62760/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0248, d_svhn_loss: 0.0151, d_fake_loss: 0.0303, g_loss: 1.1451\n",
            "Step [62770/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0176, d_svhn_loss: 0.0608, d_fake_loss: 0.1396, g_loss: 1.0314\n",
            "Step [62780/80000], d_real_loss: 0.1059, d_mnist_loss: 0.0731, d_svhn_loss: 0.0328, d_fake_loss: 0.1246, g_loss: 1.1953\n",
            "Step [62790/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0280, d_svhn_loss: 0.0294, d_fake_loss: 0.1997, g_loss: 1.1362\n",
            "Step [62800/80000], d_real_loss: 0.0893, d_mnist_loss: 0.0451, d_svhn_loss: 0.0441, d_fake_loss: 0.0825, g_loss: 1.1297\n",
            "Step [62810/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0181, d_svhn_loss: 0.0211, d_fake_loss: 0.0404, g_loss: 1.0693\n",
            "Step [62820/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0416, d_svhn_loss: 0.0248, d_fake_loss: 0.0848, g_loss: 1.1310\n",
            "Step [62830/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0183, d_svhn_loss: 0.0224, d_fake_loss: 0.0587, g_loss: 1.1806\n",
            "Step [62840/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0204, d_svhn_loss: 0.0177, d_fake_loss: 0.0334, g_loss: 1.0197\n",
            "Step [62850/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0166, d_svhn_loss: 0.0302, d_fake_loss: 0.0764, g_loss: 1.2173\n",
            "Step [62860/80000], d_real_loss: 0.1717, d_mnist_loss: 0.0205, d_svhn_loss: 0.1512, d_fake_loss: 0.0688, g_loss: 1.0837\n",
            "Step [62870/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0120, d_svhn_loss: 0.0256, d_fake_loss: 0.0401, g_loss: 1.1803\n",
            "Step [62880/80000], d_real_loss: 0.1955, d_mnist_loss: 0.0411, d_svhn_loss: 0.1544, d_fake_loss: 0.1154, g_loss: 0.9720\n",
            "Step [62890/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0164, d_svhn_loss: 0.0170, d_fake_loss: 0.0898, g_loss: 1.3674\n",
            "Step [62900/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0120, d_svhn_loss: 0.0223, d_fake_loss: 0.0183, g_loss: 1.2243\n",
            "Step [62910/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0181, d_svhn_loss: 0.0279, d_fake_loss: 0.0368, g_loss: 1.1586\n",
            "Step [62920/80000], d_real_loss: 0.1083, d_mnist_loss: 0.0250, d_svhn_loss: 0.0834, d_fake_loss: 0.0297, g_loss: 1.0949\n",
            "Step [62930/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0264, d_svhn_loss: 0.0264, d_fake_loss: 0.0270, g_loss: 1.1220\n",
            "Step [62940/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0182, d_svhn_loss: 0.0451, d_fake_loss: 0.1852, g_loss: 1.3387\n",
            "Step [62950/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0197, d_svhn_loss: 0.0176, d_fake_loss: 0.0621, g_loss: 1.3169\n",
            "Step [62960/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0196, d_svhn_loss: 0.0181, d_fake_loss: 0.0387, g_loss: 1.1378\n",
            "Step [62970/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0173, d_svhn_loss: 0.0351, d_fake_loss: 0.0417, g_loss: 1.0435\n",
            "Step [62980/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0310, d_svhn_loss: 0.0371, d_fake_loss: 0.0385, g_loss: 1.0306\n",
            "Step [62990/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0267, d_svhn_loss: 0.0197, d_fake_loss: 0.0477, g_loss: 1.1151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8260932564735413, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [63000/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0126, d_svhn_loss: 0.0199, d_fake_loss: 0.0487, g_loss: 1.1799\n",
            "saved ./samples_fashion/sample-63000-m-s.png\n",
            "saved ./samples_fashion/sample-63000-s-m.png\n",
            "Step [63010/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0256, d_svhn_loss: 0.0165, d_fake_loss: 0.0474, g_loss: 1.0792\n",
            "Step [63020/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0237, d_svhn_loss: 0.0295, d_fake_loss: 0.0681, g_loss: 0.9899\n",
            "Step [63030/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0251, d_svhn_loss: 0.0209, d_fake_loss: 0.0417, g_loss: 1.2012\n",
            "Step [63040/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0221, d_svhn_loss: 0.0285, d_fake_loss: 0.0977, g_loss: 1.1530\n",
            "Step [63050/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0154, d_svhn_loss: 0.0363, d_fake_loss: 0.1151, g_loss: 1.3065\n",
            "Step [63060/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0154, d_svhn_loss: 0.0257, d_fake_loss: 0.0754, g_loss: 1.2183\n",
            "Step [63070/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0236, d_svhn_loss: 0.0171, d_fake_loss: 0.0857, g_loss: 1.4122\n",
            "Step [63080/80000], d_real_loss: 0.1029, d_mnist_loss: 0.0216, d_svhn_loss: 0.0813, d_fake_loss: 0.1060, g_loss: 1.1573\n",
            "Step [63090/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0421, d_svhn_loss: 0.0159, d_fake_loss: 0.0672, g_loss: 1.4464\n",
            "Step [63100/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0189, d_svhn_loss: 0.0342, d_fake_loss: 0.1381, g_loss: 1.1418\n",
            "Step [63110/80000], d_real_loss: 0.0887, d_mnist_loss: 0.0530, d_svhn_loss: 0.0357, d_fake_loss: 0.0301, g_loss: 1.1306\n",
            "Step [63120/80000], d_real_loss: 0.0712, d_mnist_loss: 0.0632, d_svhn_loss: 0.0079, d_fake_loss: 0.1218, g_loss: 1.2334\n",
            "Step [63130/80000], d_real_loss: 0.0896, d_mnist_loss: 0.0492, d_svhn_loss: 0.0404, d_fake_loss: 0.0707, g_loss: 0.9242\n",
            "Step [63140/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0471, d_svhn_loss: 0.0701, d_fake_loss: 0.0379, g_loss: 1.1152\n",
            "Step [63150/80000], d_real_loss: 0.1309, d_mnist_loss: 0.1129, d_svhn_loss: 0.0180, d_fake_loss: 0.0769, g_loss: 1.1361\n",
            "Step [63160/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0089, d_svhn_loss: 0.0266, d_fake_loss: 0.0322, g_loss: 1.0340\n",
            "Step [63170/80000], d_real_loss: 0.0430, d_mnist_loss: 0.0153, d_svhn_loss: 0.0276, d_fake_loss: 0.0412, g_loss: 1.1217\n",
            "Step [63180/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0188, d_svhn_loss: 0.0283, d_fake_loss: 0.0472, g_loss: 1.1447\n",
            "Step [63190/80000], d_real_loss: 0.0949, d_mnist_loss: 0.0664, d_svhn_loss: 0.0285, d_fake_loss: 0.0327, g_loss: 1.0103\n",
            "Step [63200/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0130, d_svhn_loss: 0.0214, d_fake_loss: 0.0889, g_loss: 0.9614\n",
            "Step [63210/80000], d_real_loss: 0.1825, d_mnist_loss: 0.0485, d_svhn_loss: 0.1340, d_fake_loss: 0.1210, g_loss: 1.0639\n",
            "Step [63220/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0234, d_svhn_loss: 0.0149, d_fake_loss: 0.0290, g_loss: 1.0766\n",
            "Step [63230/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0216, d_svhn_loss: 0.0264, d_fake_loss: 0.0739, g_loss: 1.4251\n",
            "Step [63240/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0218, d_svhn_loss: 0.0356, d_fake_loss: 0.1035, g_loss: 1.1860\n",
            "Step [63250/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0278, d_svhn_loss: 0.0363, d_fake_loss: 0.1019, g_loss: 1.2114\n",
            "Step [63260/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0168, d_svhn_loss: 0.0149, d_fake_loss: 0.1011, g_loss: 1.2895\n",
            "Step [63270/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0203, d_svhn_loss: 0.0228, d_fake_loss: 0.0436, g_loss: 1.0956\n",
            "Step [63280/80000], d_real_loss: 0.0751, d_mnist_loss: 0.0210, d_svhn_loss: 0.0541, d_fake_loss: 0.0450, g_loss: 1.1344\n",
            "Step [63290/80000], d_real_loss: 0.0253, d_mnist_loss: 0.0140, d_svhn_loss: 0.0113, d_fake_loss: 0.0678, g_loss: 1.2142\n",
            "Step [63300/80000], d_real_loss: 0.1146, d_mnist_loss: 0.0616, d_svhn_loss: 0.0529, d_fake_loss: 0.0837, g_loss: 1.1689\n",
            "Step [63310/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0156, d_svhn_loss: 0.0209, d_fake_loss: 0.0522, g_loss: 1.2136\n",
            "Step [63320/80000], d_real_loss: 0.0950, d_mnist_loss: 0.0221, d_svhn_loss: 0.0729, d_fake_loss: 0.0568, g_loss: 1.0470\n",
            "Step [63330/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0413, d_svhn_loss: 0.0199, d_fake_loss: 0.0598, g_loss: 1.0565\n",
            "Step [63340/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0111, d_svhn_loss: 0.0481, d_fake_loss: 0.0571, g_loss: 1.2393\n",
            "Step [63350/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0184, d_svhn_loss: 0.0209, d_fake_loss: 0.0541, g_loss: 1.0660\n",
            "Step [63360/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0513, d_svhn_loss: 0.0223, d_fake_loss: 0.0510, g_loss: 1.0357\n",
            "Step [63370/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0349, d_svhn_loss: 0.0218, d_fake_loss: 0.0427, g_loss: 1.0560\n",
            "Step [63380/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0140, d_svhn_loss: 0.0308, d_fake_loss: 0.0944, g_loss: 1.1530\n",
            "Step [63390/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0314, d_svhn_loss: 0.0398, d_fake_loss: 0.0422, g_loss: 1.0949\n",
            "Step [63400/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0297, d_svhn_loss: 0.0152, d_fake_loss: 0.0822, g_loss: 1.2057\n",
            "Step [63410/80000], d_real_loss: 0.0826, d_mnist_loss: 0.0504, d_svhn_loss: 0.0322, d_fake_loss: 0.0625, g_loss: 1.3308\n",
            "Step [63420/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0155, d_svhn_loss: 0.0415, d_fake_loss: 0.0468, g_loss: 1.2315\n",
            "Step [63430/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0227, d_svhn_loss: 0.0251, d_fake_loss: 0.0399, g_loss: 1.1488\n",
            "Step [63440/80000], d_real_loss: 0.0689, d_mnist_loss: 0.0284, d_svhn_loss: 0.0405, d_fake_loss: 0.0894, g_loss: 1.0388\n",
            "Step [63450/80000], d_real_loss: 0.0432, d_mnist_loss: 0.0142, d_svhn_loss: 0.0290, d_fake_loss: 0.0650, g_loss: 1.1281\n",
            "Step [63460/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0312, d_svhn_loss: 0.0109, d_fake_loss: 0.0294, g_loss: 1.1108\n",
            "Step [63470/80000], d_real_loss: 0.0747, d_mnist_loss: 0.0429, d_svhn_loss: 0.0318, d_fake_loss: 0.0395, g_loss: 1.0527\n",
            "Step [63480/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0268, d_svhn_loss: 0.0491, d_fake_loss: 0.0378, g_loss: 1.0983\n",
            "Step [63490/80000], d_real_loss: 0.0990, d_mnist_loss: 0.0714, d_svhn_loss: 0.0276, d_fake_loss: 0.0821, g_loss: 1.0776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7117996215820312, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [63500/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0189, d_svhn_loss: 0.0224, d_fake_loss: 0.0658, g_loss: 1.0917\n",
            "saved ./samples_fashion/sample-63500-m-s.png\n",
            "saved ./samples_fashion/sample-63500-s-m.png\n",
            "Step [63510/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0139, d_svhn_loss: 0.0308, d_fake_loss: 0.0803, g_loss: 1.1180\n",
            "Step [63520/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0218, d_svhn_loss: 0.0192, d_fake_loss: 0.0391, g_loss: 1.1720\n",
            "Step [63530/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0329, d_svhn_loss: 0.0260, d_fake_loss: 0.0826, g_loss: 1.3139\n",
            "Step [63540/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0258, d_svhn_loss: 0.0216, d_fake_loss: 0.1207, g_loss: 1.1095\n",
            "Step [63550/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0249, d_svhn_loss: 0.0230, d_fake_loss: 0.0753, g_loss: 1.3090\n",
            "Step [63560/80000], d_real_loss: 0.1007, d_mnist_loss: 0.0456, d_svhn_loss: 0.0551, d_fake_loss: 0.0890, g_loss: 1.0478\n",
            "Step [63570/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0109, d_svhn_loss: 0.0378, d_fake_loss: 0.0577, g_loss: 1.1128\n",
            "Step [63580/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0306, d_svhn_loss: 0.0303, d_fake_loss: 0.0432, g_loss: 1.3221\n",
            "Step [63590/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0200, d_svhn_loss: 0.0290, d_fake_loss: 0.0411, g_loss: 1.1451\n",
            "Step [63600/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0234, d_svhn_loss: 0.0228, d_fake_loss: 0.0381, g_loss: 1.3018\n",
            "Step [63610/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0151, d_svhn_loss: 0.0165, d_fake_loss: 0.0313, g_loss: 1.2810\n",
            "Step [63620/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0197, d_svhn_loss: 0.0395, d_fake_loss: 0.0301, g_loss: 1.0875\n",
            "Step [63630/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0135, d_svhn_loss: 0.0304, d_fake_loss: 0.0257, g_loss: 1.2292\n",
            "Step [63640/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0163, d_svhn_loss: 0.0234, d_fake_loss: 0.0331, g_loss: 0.9872\n",
            "Step [63650/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0203, d_svhn_loss: 0.0222, d_fake_loss: 0.0323, g_loss: 1.1764\n",
            "Step [63660/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0144, d_svhn_loss: 0.0291, d_fake_loss: 0.0371, g_loss: 1.2029\n",
            "Step [63670/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0270, d_svhn_loss: 0.0184, d_fake_loss: 0.0324, g_loss: 1.3270\n",
            "Step [63680/80000], d_real_loss: 0.0858, d_mnist_loss: 0.0417, d_svhn_loss: 0.0441, d_fake_loss: 0.1143, g_loss: 1.0372\n",
            "Step [63690/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0293, d_svhn_loss: 0.0187, d_fake_loss: 0.0766, g_loss: 1.2299\n",
            "Step [63700/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0174, d_svhn_loss: 0.0549, d_fake_loss: 0.0419, g_loss: 1.1703\n",
            "Step [63710/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0114, d_svhn_loss: 0.0154, d_fake_loss: 0.0277, g_loss: 1.1597\n",
            "Step [63720/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0223, d_svhn_loss: 0.0241, d_fake_loss: 0.0522, g_loss: 1.1124\n",
            "Step [63730/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0294, d_svhn_loss: 0.0252, d_fake_loss: 0.0792, g_loss: 1.0578\n",
            "Step [63740/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0161, d_svhn_loss: 0.0171, d_fake_loss: 0.0279, g_loss: 1.2066\n",
            "Step [63750/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0149, d_svhn_loss: 0.0351, d_fake_loss: 0.0289, g_loss: 1.3088\n",
            "Step [63760/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0269, d_svhn_loss: 0.0192, d_fake_loss: 0.0370, g_loss: 1.1132\n",
            "Step [63770/80000], d_real_loss: 0.1049, d_mnist_loss: 0.0266, d_svhn_loss: 0.0783, d_fake_loss: 0.0324, g_loss: 1.0479\n",
            "Step [63780/80000], d_real_loss: 0.0823, d_mnist_loss: 0.0195, d_svhn_loss: 0.0628, d_fake_loss: 0.1048, g_loss: 0.9545\n",
            "Step [63790/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0151, d_svhn_loss: 0.0139, d_fake_loss: 0.0983, g_loss: 1.2585\n",
            "Step [63800/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0245, d_svhn_loss: 0.0167, d_fake_loss: 0.0735, g_loss: 1.2070\n",
            "Step [63810/80000], d_real_loss: 0.0255, d_mnist_loss: 0.0114, d_svhn_loss: 0.0141, d_fake_loss: 0.0517, g_loss: 1.0532\n",
            "Step [63820/80000], d_real_loss: 0.1454, d_mnist_loss: 0.0868, d_svhn_loss: 0.0586, d_fake_loss: 0.1029, g_loss: 1.0411\n",
            "Step [63830/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0242, d_svhn_loss: 0.0227, d_fake_loss: 0.0528, g_loss: 1.0788\n",
            "Step [63840/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0169, d_svhn_loss: 0.0325, d_fake_loss: 0.0453, g_loss: 1.1574\n",
            "Step [63850/80000], d_real_loss: 0.0822, d_mnist_loss: 0.0143, d_svhn_loss: 0.0678, d_fake_loss: 0.1655, g_loss: 1.1828\n",
            "Step [63860/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0487, d_svhn_loss: 0.0161, d_fake_loss: 0.0261, g_loss: 1.0424\n",
            "Step [63870/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0180, d_svhn_loss: 0.0542, d_fake_loss: 0.0874, g_loss: 1.1141\n",
            "Step [63880/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0131, d_svhn_loss: 0.0271, d_fake_loss: 0.1456, g_loss: 1.3193\n",
            "Step [63890/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0432, d_svhn_loss: 0.0238, d_fake_loss: 0.0272, g_loss: 1.0865\n",
            "Step [63900/80000], d_real_loss: 0.0952, d_mnist_loss: 0.0704, d_svhn_loss: 0.0249, d_fake_loss: 0.1038, g_loss: 1.2776\n",
            "Step [63910/80000], d_real_loss: 0.0695, d_mnist_loss: 0.0524, d_svhn_loss: 0.0171, d_fake_loss: 0.0728, g_loss: 1.1781\n",
            "Step [63920/80000], d_real_loss: 0.0507, d_mnist_loss: 0.0318, d_svhn_loss: 0.0190, d_fake_loss: 0.0279, g_loss: 1.1043\n",
            "Step [63930/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0169, d_svhn_loss: 0.0176, d_fake_loss: 0.0441, g_loss: 1.1815\n",
            "Step [63940/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0353, d_svhn_loss: 0.0209, d_fake_loss: 0.0435, g_loss: 1.3625\n",
            "Step [63950/80000], d_real_loss: 0.0901, d_mnist_loss: 0.0597, d_svhn_loss: 0.0303, d_fake_loss: 0.0291, g_loss: 1.1065\n",
            "Step [63960/80000], d_real_loss: 0.0587, d_mnist_loss: 0.0253, d_svhn_loss: 0.0335, d_fake_loss: 0.0389, g_loss: 1.2198\n",
            "Step [63970/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0295, d_svhn_loss: 0.0259, d_fake_loss: 0.0375, g_loss: 1.0275\n",
            "Step [63980/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0145, d_svhn_loss: 0.0197, d_fake_loss: 0.0753, g_loss: 1.4034\n",
            "Step [63990/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0453, d_svhn_loss: 0.0185, d_fake_loss: 0.0583, g_loss: 1.3008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7070045471191406, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [64000/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0145, d_svhn_loss: 0.0201, d_fake_loss: 0.0615, g_loss: 1.1769\n",
            "saved ./samples_fashion/sample-64000-m-s.png\n",
            "saved ./samples_fashion/sample-64000-s-m.png\n",
            "Step [64010/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0210, d_svhn_loss: 0.0243, d_fake_loss: 0.0353, g_loss: 1.0960\n",
            "Step [64020/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0241, d_svhn_loss: 0.0360, d_fake_loss: 0.0342, g_loss: 1.1488\n",
            "Step [64030/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0442, d_svhn_loss: 0.0157, d_fake_loss: 0.0584, g_loss: 1.1955\n",
            "Step [64040/80000], d_real_loss: 0.0879, d_mnist_loss: 0.0498, d_svhn_loss: 0.0382, d_fake_loss: 0.0346, g_loss: 1.1392\n",
            "Step [64050/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0325, d_svhn_loss: 0.0251, d_fake_loss: 0.0492, g_loss: 1.1647\n",
            "Step [64060/80000], d_real_loss: 0.0728, d_mnist_loss: 0.0220, d_svhn_loss: 0.0508, d_fake_loss: 0.1210, g_loss: 1.0857\n",
            "Step [64070/80000], d_real_loss: 0.1660, d_mnist_loss: 0.0650, d_svhn_loss: 0.1010, d_fake_loss: 0.0459, g_loss: 1.0595\n",
            "Step [64080/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0202, d_svhn_loss: 0.0200, d_fake_loss: 0.1334, g_loss: 1.3148\n",
            "Step [64090/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0395, d_svhn_loss: 0.0191, d_fake_loss: 0.1161, g_loss: 1.4057\n",
            "Step [64100/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0159, d_svhn_loss: 0.0340, d_fake_loss: 0.0384, g_loss: 1.0505\n",
            "Step [64110/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0267, d_svhn_loss: 0.0330, d_fake_loss: 0.0435, g_loss: 1.1417\n",
            "Step [64120/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0430, d_svhn_loss: 0.0222, d_fake_loss: 0.0348, g_loss: 0.9930\n",
            "Step [64130/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0183, d_svhn_loss: 0.0147, d_fake_loss: 0.0483, g_loss: 1.2304\n",
            "Step [64140/80000], d_real_loss: 0.1290, d_mnist_loss: 0.0700, d_svhn_loss: 0.0590, d_fake_loss: 0.0338, g_loss: 1.0220\n",
            "Step [64150/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0294, d_svhn_loss: 0.0107, d_fake_loss: 0.0574, g_loss: 1.1824\n",
            "Step [64160/80000], d_real_loss: 0.1365, d_mnist_loss: 0.0184, d_svhn_loss: 0.1182, d_fake_loss: 0.0687, g_loss: 1.2923\n",
            "Step [64170/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0216, d_svhn_loss: 0.0321, d_fake_loss: 0.0747, g_loss: 1.0833\n",
            "Step [64180/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0272, d_svhn_loss: 0.0303, d_fake_loss: 0.0451, g_loss: 1.1203\n",
            "Step [64190/80000], d_real_loss: 0.0931, d_mnist_loss: 0.0731, d_svhn_loss: 0.0200, d_fake_loss: 0.1309, g_loss: 1.4518\n",
            "Step [64200/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0157, d_svhn_loss: 0.0186, d_fake_loss: 0.0381, g_loss: 1.1480\n",
            "Step [64210/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0174, d_svhn_loss: 0.0225, d_fake_loss: 0.1056, g_loss: 0.9687\n",
            "Step [64220/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0650, d_svhn_loss: 0.0187, d_fake_loss: 0.0300, g_loss: 0.9884\n",
            "Step [64230/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0700, d_svhn_loss: 0.0200, d_fake_loss: 0.0666, g_loss: 1.1176\n",
            "Step [64240/80000], d_real_loss: 0.0649, d_mnist_loss: 0.0320, d_svhn_loss: 0.0329, d_fake_loss: 0.0543, g_loss: 1.1547\n",
            "Step [64250/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0343, d_svhn_loss: 0.0238, d_fake_loss: 0.1568, g_loss: 1.3682\n",
            "Step [64260/80000], d_real_loss: 0.0907, d_mnist_loss: 0.0158, d_svhn_loss: 0.0749, d_fake_loss: 0.0487, g_loss: 1.1499\n",
            "Step [64270/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0239, d_svhn_loss: 0.0296, d_fake_loss: 0.0459, g_loss: 1.2350\n",
            "Step [64280/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0209, d_svhn_loss: 0.0234, d_fake_loss: 0.0329, g_loss: 1.2062\n",
            "Step [64290/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0303, d_svhn_loss: 0.0217, d_fake_loss: 0.0416, g_loss: 1.0653\n",
            "Step [64300/80000], d_real_loss: 0.0681, d_mnist_loss: 0.0173, d_svhn_loss: 0.0508, d_fake_loss: 0.0420, g_loss: 1.1364\n",
            "Step [64310/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0178, d_svhn_loss: 0.0172, d_fake_loss: 0.0416, g_loss: 1.0681\n",
            "Step [64320/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0290, d_svhn_loss: 0.0288, d_fake_loss: 0.0740, g_loss: 1.1331\n",
            "Step [64330/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0153, d_svhn_loss: 0.0248, d_fake_loss: 0.0927, g_loss: 1.3299\n",
            "Step [64340/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0189, d_svhn_loss: 0.0151, d_fake_loss: 0.0663, g_loss: 1.0049\n",
            "Step [64350/80000], d_real_loss: 0.0512, d_mnist_loss: 0.0249, d_svhn_loss: 0.0264, d_fake_loss: 0.0409, g_loss: 1.1196\n",
            "Step [64360/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0194, d_svhn_loss: 0.0217, d_fake_loss: 0.1489, g_loss: 1.2894\n",
            "Step [64370/80000], d_real_loss: 0.0827, d_mnist_loss: 0.0553, d_svhn_loss: 0.0274, d_fake_loss: 0.0671, g_loss: 1.1840\n",
            "Step [64380/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0133, d_svhn_loss: 0.0266, d_fake_loss: 0.0601, g_loss: 1.1560\n",
            "Step [64390/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0379, d_svhn_loss: 0.0176, d_fake_loss: 0.0353, g_loss: 1.2455\n",
            "Step [64400/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0198, d_svhn_loss: 0.0328, d_fake_loss: 0.0970, g_loss: 1.1320\n",
            "Step [64410/80000], d_real_loss: 0.0315, d_mnist_loss: 0.0195, d_svhn_loss: 0.0119, d_fake_loss: 0.0777, g_loss: 1.1225\n",
            "Step [64420/80000], d_real_loss: 0.0722, d_mnist_loss: 0.0382, d_svhn_loss: 0.0339, d_fake_loss: 0.0221, g_loss: 1.1668\n",
            "Step [64430/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0365, d_svhn_loss: 0.0375, d_fake_loss: 0.0372, g_loss: 1.1808\n",
            "Step [64440/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0186, d_svhn_loss: 0.0201, d_fake_loss: 0.1606, g_loss: 1.1356\n",
            "Step [64450/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0135, d_svhn_loss: 0.0531, d_fake_loss: 0.0693, g_loss: 1.2446\n",
            "Step [64460/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0223, d_svhn_loss: 0.0307, d_fake_loss: 0.0398, g_loss: 1.0945\n",
            "Step [64470/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0157, d_svhn_loss: 0.0276, d_fake_loss: 0.1117, g_loss: 1.1008\n",
            "Step [64480/80000], d_real_loss: 0.1390, d_mnist_loss: 0.1221, d_svhn_loss: 0.0169, d_fake_loss: 0.1791, g_loss: 1.2791\n",
            "Step [64490/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0249, d_svhn_loss: 0.0218, d_fake_loss: 0.0556, g_loss: 1.1629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7631527185440063, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [64500/80000], d_real_loss: 0.0978, d_mnist_loss: 0.0225, d_svhn_loss: 0.0753, d_fake_loss: 0.0306, g_loss: 1.2097\n",
            "saved ./samples_fashion/sample-64500-m-s.png\n",
            "saved ./samples_fashion/sample-64500-s-m.png\n",
            "Step [64510/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0190, d_svhn_loss: 0.0482, d_fake_loss: 0.0394, g_loss: 1.1515\n",
            "Step [64520/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0735, d_svhn_loss: 0.0115, d_fake_loss: 0.0412, g_loss: 1.1718\n",
            "Step [64530/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0178, d_svhn_loss: 0.0204, d_fake_loss: 0.0572, g_loss: 1.1909\n",
            "Step [64540/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0380, d_svhn_loss: 0.0152, d_fake_loss: 0.0474, g_loss: 1.0971\n",
            "Step [64550/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0143, d_svhn_loss: 0.0222, d_fake_loss: 0.0730, g_loss: 0.9125\n",
            "Step [64560/80000], d_real_loss: 0.0732, d_mnist_loss: 0.0216, d_svhn_loss: 0.0516, d_fake_loss: 0.0486, g_loss: 0.9130\n",
            "Step [64570/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0150, d_svhn_loss: 0.0154, d_fake_loss: 0.0248, g_loss: 1.0636\n",
            "Step [64580/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0515, d_svhn_loss: 0.0230, d_fake_loss: 0.0358, g_loss: 1.1042\n",
            "Step [64590/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0334, d_svhn_loss: 0.0291, d_fake_loss: 0.0362, g_loss: 1.0643\n",
            "Step [64600/80000], d_real_loss: 0.2168, d_mnist_loss: 0.1587, d_svhn_loss: 0.0581, d_fake_loss: 0.0586, g_loss: 1.3025\n",
            "Step [64610/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0130, d_svhn_loss: 0.0179, d_fake_loss: 0.0316, g_loss: 1.2158\n",
            "Step [64620/80000], d_real_loss: 0.0399, d_mnist_loss: 0.0211, d_svhn_loss: 0.0189, d_fake_loss: 0.0576, g_loss: 1.1870\n",
            "Step [64630/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0152, d_svhn_loss: 0.0318, d_fake_loss: 0.0311, g_loss: 1.0640\n",
            "Step [64640/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0187, d_svhn_loss: 0.0210, d_fake_loss: 0.0272, g_loss: 1.0109\n",
            "Step [64650/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0160, d_svhn_loss: 0.0368, d_fake_loss: 0.0296, g_loss: 1.1882\n",
            "Step [64660/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0251, d_svhn_loss: 0.0175, d_fake_loss: 0.0762, g_loss: 0.9459\n",
            "Step [64670/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0459, d_svhn_loss: 0.0270, d_fake_loss: 0.0191, g_loss: 1.0261\n",
            "Step [64680/80000], d_real_loss: 0.2204, d_mnist_loss: 0.2058, d_svhn_loss: 0.0146, d_fake_loss: 0.0677, g_loss: 1.3920\n",
            "Step [64690/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0217, d_svhn_loss: 0.0398, d_fake_loss: 0.1189, g_loss: 1.2339\n",
            "Step [64700/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0255, d_svhn_loss: 0.0156, d_fake_loss: 0.0357, g_loss: 1.1292\n",
            "Step [64710/80000], d_real_loss: 0.0990, d_mnist_loss: 0.0184, d_svhn_loss: 0.0807, d_fake_loss: 0.0317, g_loss: 1.1683\n",
            "Step [64720/80000], d_real_loss: 0.0796, d_mnist_loss: 0.0288, d_svhn_loss: 0.0508, d_fake_loss: 0.1136, g_loss: 1.1959\n",
            "Step [64730/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0199, d_svhn_loss: 0.0208, d_fake_loss: 0.0606, g_loss: 1.3658\n",
            "Step [64740/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0377, d_svhn_loss: 0.0231, d_fake_loss: 0.0308, g_loss: 1.0500\n",
            "Step [64750/80000], d_real_loss: 0.0695, d_mnist_loss: 0.0216, d_svhn_loss: 0.0480, d_fake_loss: 0.0376, g_loss: 1.1319\n",
            "Step [64760/80000], d_real_loss: 0.0621, d_mnist_loss: 0.0287, d_svhn_loss: 0.0334, d_fake_loss: 0.0203, g_loss: 0.9766\n",
            "Step [64770/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0409, d_svhn_loss: 0.0189, d_fake_loss: 0.1079, g_loss: 1.0715\n",
            "Step [64780/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0223, d_svhn_loss: 0.0183, d_fake_loss: 0.0814, g_loss: 1.3261\n",
            "Step [64790/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0163, d_svhn_loss: 0.0247, d_fake_loss: 0.0557, g_loss: 1.0954\n",
            "Step [64800/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0355, d_svhn_loss: 0.0397, d_fake_loss: 0.0286, g_loss: 1.0841\n",
            "Step [64810/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0163, d_svhn_loss: 0.0317, d_fake_loss: 0.0388, g_loss: 1.4414\n",
            "Step [64820/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0203, d_svhn_loss: 0.0275, d_fake_loss: 0.0353, g_loss: 1.1526\n",
            "Step [64830/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0193, d_svhn_loss: 0.0217, d_fake_loss: 0.0393, g_loss: 1.0118\n",
            "Step [64840/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0206, d_svhn_loss: 0.0239, d_fake_loss: 0.0343, g_loss: 1.1240\n",
            "Step [64850/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0189, d_svhn_loss: 0.0172, d_fake_loss: 0.0235, g_loss: 1.0400\n",
            "Step [64860/80000], d_real_loss: 0.1014, d_mnist_loss: 0.0463, d_svhn_loss: 0.0552, d_fake_loss: 0.1298, g_loss: 1.0289\n",
            "Step [64870/80000], d_real_loss: 0.0734, d_mnist_loss: 0.0566, d_svhn_loss: 0.0168, d_fake_loss: 0.0752, g_loss: 1.2474\n",
            "Step [64880/80000], d_real_loss: 0.0964, d_mnist_loss: 0.0386, d_svhn_loss: 0.0578, d_fake_loss: 0.0518, g_loss: 1.2408\n",
            "Step [64890/80000], d_real_loss: 0.0390, d_mnist_loss: 0.0153, d_svhn_loss: 0.0237, d_fake_loss: 0.0532, g_loss: 1.1381\n",
            "Step [64900/80000], d_real_loss: 0.1722, d_mnist_loss: 0.0880, d_svhn_loss: 0.0842, d_fake_loss: 0.1697, g_loss: 0.8487\n",
            "Step [64910/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0158, d_svhn_loss: 0.0285, d_fake_loss: 0.0434, g_loss: 1.1088\n",
            "Step [64920/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0232, d_svhn_loss: 0.0253, d_fake_loss: 0.0309, g_loss: 1.0954\n",
            "Step [64930/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0138, d_svhn_loss: 0.0298, d_fake_loss: 0.0625, g_loss: 1.0851\n",
            "Step [64940/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0299, d_svhn_loss: 0.0206, d_fake_loss: 0.0741, g_loss: 1.3791\n",
            "Step [64950/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0402, d_svhn_loss: 0.0161, d_fake_loss: 0.0451, g_loss: 1.1359\n",
            "Step [64960/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0471, d_svhn_loss: 0.0373, d_fake_loss: 0.0257, g_loss: 0.9575\n",
            "Step [64970/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0136, d_svhn_loss: 0.0210, d_fake_loss: 0.0287, g_loss: 1.0757\n",
            "Step [64980/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0460, d_svhn_loss: 0.0185, d_fake_loss: 0.0597, g_loss: 1.0320\n",
            "Step [64990/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0241, d_svhn_loss: 0.0155, d_fake_loss: 0.0543, g_loss: 1.1761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7419912815093994, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [65000/80000], d_real_loss: 0.1279, d_mnist_loss: 0.1096, d_svhn_loss: 0.0184, d_fake_loss: 0.0491, g_loss: 1.1253\n",
            "saved ./samples_fashion/sample-65000-m-s.png\n",
            "saved ./samples_fashion/sample-65000-s-m.png\n",
            "Step [65010/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0166, d_svhn_loss: 0.0411, d_fake_loss: 0.0335, g_loss: 1.1675\n",
            "Step [65020/80000], d_real_loss: 0.0613, d_mnist_loss: 0.0442, d_svhn_loss: 0.0170, d_fake_loss: 0.0620, g_loss: 1.1593\n",
            "Step [65030/80000], d_real_loss: 0.1017, d_mnist_loss: 0.0229, d_svhn_loss: 0.0788, d_fake_loss: 0.0511, g_loss: 1.0096\n",
            "Step [65040/80000], d_real_loss: 0.1017, d_mnist_loss: 0.0849, d_svhn_loss: 0.0168, d_fake_loss: 0.0286, g_loss: 1.1369\n",
            "Step [65050/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0217, d_svhn_loss: 0.0394, d_fake_loss: 0.0814, g_loss: 1.1839\n",
            "Step [65060/80000], d_real_loss: 0.0626, d_mnist_loss: 0.0195, d_svhn_loss: 0.0431, d_fake_loss: 0.1270, g_loss: 1.1652\n",
            "Step [65070/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0163, d_svhn_loss: 0.0168, d_fake_loss: 0.0371, g_loss: 1.1137\n",
            "Step [65080/80000], d_real_loss: 0.0644, d_mnist_loss: 0.0175, d_svhn_loss: 0.0469, d_fake_loss: 0.0383, g_loss: 1.1751\n",
            "Step [65090/80000], d_real_loss: 0.0880, d_mnist_loss: 0.0527, d_svhn_loss: 0.0353, d_fake_loss: 0.1753, g_loss: 1.2272\n",
            "Step [65100/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0175, d_svhn_loss: 0.0233, d_fake_loss: 0.0361, g_loss: 1.1203\n",
            "Step [65110/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0324, d_svhn_loss: 0.0155, d_fake_loss: 0.0291, g_loss: 0.9442\n",
            "Step [65120/80000], d_real_loss: 0.0484, d_mnist_loss: 0.0235, d_svhn_loss: 0.0249, d_fake_loss: 0.0500, g_loss: 1.2180\n",
            "Step [65130/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0248, d_svhn_loss: 0.0152, d_fake_loss: 0.0312, g_loss: 1.1135\n",
            "Step [65140/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0210, d_svhn_loss: 0.0465, d_fake_loss: 0.0247, g_loss: 1.0153\n",
            "Step [65150/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0356, d_svhn_loss: 0.0259, d_fake_loss: 0.1564, g_loss: 1.2186\n",
            "Step [65160/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0462, d_svhn_loss: 0.0320, d_fake_loss: 0.0331, g_loss: 1.0589\n",
            "Step [65170/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0436, d_svhn_loss: 0.0206, d_fake_loss: 0.0349, g_loss: 1.0759\n",
            "Step [65180/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0389, d_svhn_loss: 0.0217, d_fake_loss: 0.0423, g_loss: 1.0540\n",
            "Step [65190/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0191, d_svhn_loss: 0.0189, d_fake_loss: 0.0389, g_loss: 1.1341\n",
            "Step [65200/80000], d_real_loss: 0.1548, d_mnist_loss: 0.0307, d_svhn_loss: 0.1240, d_fake_loss: 0.0269, g_loss: 1.1859\n",
            "Step [65210/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0219, d_svhn_loss: 0.0379, d_fake_loss: 0.0364, g_loss: 1.0724\n",
            "Step [65220/80000], d_real_loss: 0.0687, d_mnist_loss: 0.0517, d_svhn_loss: 0.0170, d_fake_loss: 0.0417, g_loss: 1.1917\n",
            "Step [65230/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0177, d_svhn_loss: 0.0159, d_fake_loss: 0.0347, g_loss: 1.4375\n",
            "Step [65240/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0215, d_svhn_loss: 0.0365, d_fake_loss: 0.0675, g_loss: 1.0016\n",
            "Step [65250/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0607, d_svhn_loss: 0.0175, d_fake_loss: 0.0434, g_loss: 1.0440\n",
            "Step [65260/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0183, d_svhn_loss: 0.0330, d_fake_loss: 0.0545, g_loss: 1.2417\n",
            "Step [65270/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0263, d_svhn_loss: 0.0300, d_fake_loss: 0.0269, g_loss: 1.0515\n",
            "Step [65280/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0156, d_svhn_loss: 0.0194, d_fake_loss: 0.0731, g_loss: 1.3264\n",
            "Step [65290/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0435, d_svhn_loss: 0.0164, d_fake_loss: 0.0586, g_loss: 1.0681\n",
            "Step [65300/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0262, d_svhn_loss: 0.0287, d_fake_loss: 0.0296, g_loss: 1.0959\n",
            "Step [65310/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0227, d_svhn_loss: 0.0255, d_fake_loss: 0.0589, g_loss: 1.1621\n",
            "Step [65320/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0213, d_svhn_loss: 0.0228, d_fake_loss: 0.0844, g_loss: 1.0367\n",
            "Step [65330/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0166, d_svhn_loss: 0.0522, d_fake_loss: 0.0597, g_loss: 1.1375\n",
            "Step [65340/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0187, d_svhn_loss: 0.0186, d_fake_loss: 0.0263, g_loss: 1.0596\n",
            "Step [65350/80000], d_real_loss: 0.0343, d_mnist_loss: 0.0206, d_svhn_loss: 0.0137, d_fake_loss: 0.0473, g_loss: 1.2246\n",
            "Step [65360/80000], d_real_loss: 0.1423, d_mnist_loss: 0.1218, d_svhn_loss: 0.0205, d_fake_loss: 0.1123, g_loss: 1.3107\n",
            "Step [65370/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0327, d_svhn_loss: 0.0307, d_fake_loss: 0.0865, g_loss: 1.2956\n",
            "Step [65380/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0232, d_svhn_loss: 0.0290, d_fake_loss: 0.0368, g_loss: 1.1741\n",
            "Step [65390/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0344, d_svhn_loss: 0.0185, d_fake_loss: 0.0728, g_loss: 1.1347\n",
            "Step [65400/80000], d_real_loss: 0.0726, d_mnist_loss: 0.0229, d_svhn_loss: 0.0498, d_fake_loss: 0.0684, g_loss: 1.0434\n",
            "Step [65410/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0131, d_svhn_loss: 0.0277, d_fake_loss: 0.0517, g_loss: 1.2800\n",
            "Step [65420/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0322, d_svhn_loss: 0.0150, d_fake_loss: 0.0304, g_loss: 1.2354\n",
            "Step [65430/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0172, d_svhn_loss: 0.0189, d_fake_loss: 0.0432, g_loss: 1.2007\n",
            "Step [65440/80000], d_real_loss: 0.0830, d_mnist_loss: 0.0595, d_svhn_loss: 0.0234, d_fake_loss: 0.0700, g_loss: 1.1632\n",
            "Step [65450/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0209, d_svhn_loss: 0.0310, d_fake_loss: 0.0640, g_loss: 1.1185\n",
            "Step [65460/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0154, d_svhn_loss: 0.0296, d_fake_loss: 0.0636, g_loss: 1.1868\n",
            "Step [65470/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0415, d_svhn_loss: 0.0287, d_fake_loss: 0.0613, g_loss: 1.2767\n",
            "Step [65480/80000], d_real_loss: 0.0760, d_mnist_loss: 0.0382, d_svhn_loss: 0.0378, d_fake_loss: 0.0352, g_loss: 1.1167\n",
            "Step [65490/80000], d_real_loss: 0.3407, d_mnist_loss: 0.1879, d_svhn_loss: 0.1528, d_fake_loss: 0.0881, g_loss: 0.7649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.6961177587509155, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [65500/80000], d_real_loss: 0.0922, d_mnist_loss: 0.0696, d_svhn_loss: 0.0225, d_fake_loss: 0.0261, g_loss: 1.0334\n",
            "saved ./samples_fashion/sample-65500-m-s.png\n",
            "saved ./samples_fashion/sample-65500-s-m.png\n",
            "Step [65510/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0132, d_svhn_loss: 0.0323, d_fake_loss: 0.0742, g_loss: 1.1778\n",
            "Step [65520/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0124, d_svhn_loss: 0.0179, d_fake_loss: 0.0385, g_loss: 1.1837\n",
            "Step [65530/80000], d_real_loss: 0.1177, d_mnist_loss: 0.0197, d_svhn_loss: 0.0979, d_fake_loss: 0.0570, g_loss: 1.2692\n",
            "Step [65540/80000], d_real_loss: 0.0850, d_mnist_loss: 0.0609, d_svhn_loss: 0.0241, d_fake_loss: 0.0490, g_loss: 1.0693\n",
            "Step [65550/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0195, d_svhn_loss: 0.0181, d_fake_loss: 0.0487, g_loss: 1.1769\n",
            "Step [65560/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0285, d_svhn_loss: 0.0342, d_fake_loss: 0.0517, g_loss: 1.2096\n",
            "Step [65570/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0177, d_svhn_loss: 0.0190, d_fake_loss: 0.0221, g_loss: 1.1279\n",
            "Step [65580/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0264, d_svhn_loss: 0.0192, d_fake_loss: 0.0625, g_loss: 1.1947\n",
            "Step [65590/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0177, d_svhn_loss: 0.0388, d_fake_loss: 0.0544, g_loss: 1.1711\n",
            "Step [65600/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0137, d_svhn_loss: 0.0343, d_fake_loss: 0.0287, g_loss: 1.0607\n",
            "Step [65610/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0276, d_svhn_loss: 0.0567, d_fake_loss: 0.1466, g_loss: 1.1399\n",
            "Step [65620/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0302, d_svhn_loss: 0.0191, d_fake_loss: 0.0340, g_loss: 1.0624\n",
            "Step [65630/80000], d_real_loss: 0.1115, d_mnist_loss: 0.0140, d_svhn_loss: 0.0975, d_fake_loss: 0.0459, g_loss: 1.3145\n",
            "Step [65640/80000], d_real_loss: 0.0945, d_mnist_loss: 0.0601, d_svhn_loss: 0.0344, d_fake_loss: 0.0500, g_loss: 1.1714\n",
            "Step [65650/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0214, d_svhn_loss: 0.0286, d_fake_loss: 0.0221, g_loss: 1.1673\n",
            "Step [65660/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0316, d_svhn_loss: 0.0309, d_fake_loss: 0.0230, g_loss: 1.2274\n",
            "Step [65670/80000], d_real_loss: 0.0794, d_mnist_loss: 0.0291, d_svhn_loss: 0.0503, d_fake_loss: 0.0223, g_loss: 1.1799\n",
            "Step [65680/80000], d_real_loss: 0.0973, d_mnist_loss: 0.0821, d_svhn_loss: 0.0151, d_fake_loss: 0.2150, g_loss: 1.7110\n",
            "Step [65690/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0211, d_svhn_loss: 0.0145, d_fake_loss: 0.0320, g_loss: 1.0612\n",
            "Step [65700/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0143, d_svhn_loss: 0.0231, d_fake_loss: 0.0300, g_loss: 1.1996\n",
            "Step [65710/80000], d_real_loss: 0.0617, d_mnist_loss: 0.0468, d_svhn_loss: 0.0149, d_fake_loss: 0.1100, g_loss: 1.0342\n",
            "Step [65720/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0208, d_svhn_loss: 0.0195, d_fake_loss: 0.0407, g_loss: 1.1149\n",
            "Step [65730/80000], d_real_loss: 0.0418, d_mnist_loss: 0.0217, d_svhn_loss: 0.0201, d_fake_loss: 0.0238, g_loss: 1.1160\n",
            "Step [65740/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0259, d_svhn_loss: 0.0120, d_fake_loss: 0.0740, g_loss: 1.0889\n",
            "Step [65750/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0523, d_svhn_loss: 0.0421, d_fake_loss: 0.0300, g_loss: 1.0657\n",
            "Step [65760/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0270, d_svhn_loss: 0.0390, d_fake_loss: 0.0613, g_loss: 1.3680\n",
            "Step [65770/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0191, d_svhn_loss: 0.0202, d_fake_loss: 0.0405, g_loss: 1.2148\n",
            "Step [65780/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0150, d_svhn_loss: 0.0252, d_fake_loss: 0.0606, g_loss: 1.0356\n",
            "Step [65790/80000], d_real_loss: 0.0351, d_mnist_loss: 0.0139, d_svhn_loss: 0.0213, d_fake_loss: 0.0331, g_loss: 1.2054\n",
            "Step [65800/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0437, d_svhn_loss: 0.0409, d_fake_loss: 0.0327, g_loss: 1.0483\n",
            "Step [65810/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0217, d_svhn_loss: 0.0176, d_fake_loss: 0.1094, g_loss: 1.3338\n",
            "Step [65820/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0186, d_svhn_loss: 0.0314, d_fake_loss: 0.0368, g_loss: 1.1626\n",
            "Step [65830/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0436, d_svhn_loss: 0.0226, d_fake_loss: 0.0406, g_loss: 1.2090\n",
            "Step [65840/80000], d_real_loss: 0.1401, d_mnist_loss: 0.0912, d_svhn_loss: 0.0489, d_fake_loss: 0.1040, g_loss: 1.0352\n",
            "Step [65850/80000], d_real_loss: 0.0816, d_mnist_loss: 0.0174, d_svhn_loss: 0.0641, d_fake_loss: 0.0324, g_loss: 1.0865\n",
            "Step [65860/80000], d_real_loss: 0.0706, d_mnist_loss: 0.0447, d_svhn_loss: 0.0259, d_fake_loss: 0.0470, g_loss: 1.2926\n",
            "Step [65870/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0364, d_svhn_loss: 0.0162, d_fake_loss: 0.0487, g_loss: 1.1469\n",
            "Step [65880/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0360, d_svhn_loss: 0.0343, d_fake_loss: 0.0321, g_loss: 1.0008\n",
            "Step [65890/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0170, d_svhn_loss: 0.0146, d_fake_loss: 0.0448, g_loss: 1.0113\n",
            "Step [65900/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0451, d_svhn_loss: 0.0176, d_fake_loss: 0.0602, g_loss: 1.1854\n",
            "Step [65910/80000], d_real_loss: 0.1022, d_mnist_loss: 0.0737, d_svhn_loss: 0.0284, d_fake_loss: 0.0284, g_loss: 1.0045\n",
            "Step [65920/80000], d_real_loss: 0.0499, d_mnist_loss: 0.0223, d_svhn_loss: 0.0276, d_fake_loss: 0.0343, g_loss: 1.0636\n",
            "Step [65930/80000], d_real_loss: 0.0638, d_mnist_loss: 0.0122, d_svhn_loss: 0.0516, d_fake_loss: 0.0540, g_loss: 1.0659\n",
            "Step [65940/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0327, d_svhn_loss: 0.0266, d_fake_loss: 0.0349, g_loss: 1.2826\n",
            "Step [65950/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0415, d_svhn_loss: 0.0152, d_fake_loss: 0.0301, g_loss: 1.2419\n",
            "Step [65960/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0148, d_svhn_loss: 0.0318, d_fake_loss: 0.0345, g_loss: 1.1760\n",
            "Step [65970/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0236, d_svhn_loss: 0.0215, d_fake_loss: 0.0814, g_loss: 1.1576\n",
            "Step [65980/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0337, d_svhn_loss: 0.0164, d_fake_loss: 0.0439, g_loss: 1.0782\n",
            "Step [65990/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0337, d_svhn_loss: 0.0290, d_fake_loss: 0.0328, g_loss: 1.3058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9026647806167603, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [66000/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0131, d_svhn_loss: 0.0177, d_fake_loss: 0.0460, g_loss: 1.1193\n",
            "saved ./samples_fashion/sample-66000-m-s.png\n",
            "saved ./samples_fashion/sample-66000-s-m.png\n",
            "Step [66010/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0293, d_svhn_loss: 0.0203, d_fake_loss: 0.0745, g_loss: 1.2448\n",
            "Step [66020/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0319, d_svhn_loss: 0.0318, d_fake_loss: 0.0521, g_loss: 1.1978\n",
            "Step [66030/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0157, d_svhn_loss: 0.0151, d_fake_loss: 0.0994, g_loss: 1.0151\n",
            "Step [66040/80000], d_real_loss: 0.1187, d_mnist_loss: 0.0185, d_svhn_loss: 0.1002, d_fake_loss: 0.0443, g_loss: 1.0291\n",
            "Step [66050/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0138, d_svhn_loss: 0.0152, d_fake_loss: 0.0599, g_loss: 1.2866\n",
            "Step [66060/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0201, d_svhn_loss: 0.0136, d_fake_loss: 0.0266, g_loss: 1.1590\n",
            "Step [66070/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0149, d_svhn_loss: 0.0323, d_fake_loss: 0.0310, g_loss: 1.1965\n",
            "Step [66080/80000], d_real_loss: 0.1159, d_mnist_loss: 0.0668, d_svhn_loss: 0.0492, d_fake_loss: 0.0243, g_loss: 1.0851\n",
            "Step [66090/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0220, d_svhn_loss: 0.0242, d_fake_loss: 0.0786, g_loss: 1.2543\n",
            "Step [66100/80000], d_real_loss: 0.0799, d_mnist_loss: 0.0285, d_svhn_loss: 0.0514, d_fake_loss: 0.0888, g_loss: 1.2034\n",
            "Step [66110/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0326, d_svhn_loss: 0.0189, d_fake_loss: 0.1181, g_loss: 1.4307\n",
            "Step [66120/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0459, d_svhn_loss: 0.0283, d_fake_loss: 0.1168, g_loss: 1.1546\n",
            "Step [66130/80000], d_real_loss: 0.1828, d_mnist_loss: 0.0164, d_svhn_loss: 0.1664, d_fake_loss: 0.1183, g_loss: 1.1172\n",
            "Step [66140/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0390, d_svhn_loss: 0.0197, d_fake_loss: 0.0390, g_loss: 1.2367\n",
            "Step [66150/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0243, d_svhn_loss: 0.0173, d_fake_loss: 0.0603, g_loss: 1.4006\n",
            "Step [66160/80000], d_real_loss: 0.0591, d_mnist_loss: 0.0428, d_svhn_loss: 0.0163, d_fake_loss: 0.0518, g_loss: 1.2017\n",
            "Step [66170/80000], d_real_loss: 0.0839, d_mnist_loss: 0.0641, d_svhn_loss: 0.0198, d_fake_loss: 0.1332, g_loss: 0.8770\n",
            "Step [66180/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0190, d_svhn_loss: 0.0433, d_fake_loss: 0.0601, g_loss: 0.9082\n",
            "Step [66190/80000], d_real_loss: 0.1214, d_mnist_loss: 0.1006, d_svhn_loss: 0.0208, d_fake_loss: 0.1483, g_loss: 1.0868\n",
            "Step [66200/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0278, d_svhn_loss: 0.0175, d_fake_loss: 0.0950, g_loss: 1.1008\n",
            "Step [66210/80000], d_real_loss: 0.1629, d_mnist_loss: 0.0677, d_svhn_loss: 0.0952, d_fake_loss: 0.0440, g_loss: 0.9537\n",
            "Step [66220/80000], d_real_loss: 0.0646, d_mnist_loss: 0.0171, d_svhn_loss: 0.0475, d_fake_loss: 0.0409, g_loss: 1.0967\n",
            "Step [66230/80000], d_real_loss: 0.0985, d_mnist_loss: 0.0222, d_svhn_loss: 0.0763, d_fake_loss: 0.0298, g_loss: 1.1573\n",
            "Step [66240/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0165, d_svhn_loss: 0.0316, d_fake_loss: 0.0418, g_loss: 1.1925\n",
            "Step [66250/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0145, d_svhn_loss: 0.0528, d_fake_loss: 0.1053, g_loss: 1.2537\n",
            "Step [66260/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0284, d_svhn_loss: 0.0361, d_fake_loss: 0.0816, g_loss: 1.1524\n",
            "Step [66270/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0173, d_svhn_loss: 0.0362, d_fake_loss: 0.0709, g_loss: 1.2471\n",
            "Step [66280/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0227, d_svhn_loss: 0.0153, d_fake_loss: 0.0567, g_loss: 1.2491\n",
            "Step [66290/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0424, d_svhn_loss: 0.0228, d_fake_loss: 0.1543, g_loss: 1.1060\n",
            "Step [66300/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0113, d_svhn_loss: 0.0264, d_fake_loss: 0.0285, g_loss: 1.1903\n",
            "Step [66310/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0280, d_svhn_loss: 0.0548, d_fake_loss: 0.0419, g_loss: 1.2240\n",
            "Step [66320/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0214, d_svhn_loss: 0.0177, d_fake_loss: 0.0871, g_loss: 1.3805\n",
            "Step [66330/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0409, d_svhn_loss: 0.0193, d_fake_loss: 0.0562, g_loss: 1.1701\n",
            "Step [66340/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0239, d_svhn_loss: 0.0371, d_fake_loss: 0.0640, g_loss: 1.1245\n",
            "Step [66350/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0157, d_svhn_loss: 0.0277, d_fake_loss: 0.0656, g_loss: 1.1287\n",
            "Step [66360/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0220, d_svhn_loss: 0.0191, d_fake_loss: 0.0310, g_loss: 1.1822\n",
            "Step [66370/80000], d_real_loss: 0.0853, d_mnist_loss: 0.0640, d_svhn_loss: 0.0213, d_fake_loss: 0.0433, g_loss: 0.9245\n",
            "Step [66380/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0568, d_svhn_loss: 0.0238, d_fake_loss: 0.0641, g_loss: 1.1650\n",
            "Step [66390/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0184, d_svhn_loss: 0.0184, d_fake_loss: 0.0448, g_loss: 1.1474\n",
            "Step [66400/80000], d_real_loss: 0.0738, d_mnist_loss: 0.0479, d_svhn_loss: 0.0260, d_fake_loss: 0.0422, g_loss: 1.1842\n",
            "Step [66410/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0216, d_svhn_loss: 0.0228, d_fake_loss: 0.1247, g_loss: 1.2684\n",
            "Step [66420/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0218, d_svhn_loss: 0.0245, d_fake_loss: 0.0341, g_loss: 1.1072\n",
            "Step [66430/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0392, d_svhn_loss: 0.0216, d_fake_loss: 0.0230, g_loss: 1.0045\n",
            "Step [66440/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0142, d_svhn_loss: 0.0352, d_fake_loss: 0.0387, g_loss: 1.2290\n",
            "Step [66450/80000], d_real_loss: 0.1652, d_mnist_loss: 0.0470, d_svhn_loss: 0.1182, d_fake_loss: 0.0367, g_loss: 1.1487\n",
            "Step [66460/80000], d_real_loss: 0.0665, d_mnist_loss: 0.0499, d_svhn_loss: 0.0166, d_fake_loss: 0.0803, g_loss: 1.0280\n",
            "Step [66470/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0393, d_svhn_loss: 0.0327, d_fake_loss: 0.0472, g_loss: 1.3464\n",
            "Step [66480/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0349, d_svhn_loss: 0.0142, d_fake_loss: 0.0779, g_loss: 1.1902\n",
            "Step [66490/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0282, d_svhn_loss: 0.0204, d_fake_loss: 0.0524, g_loss: 1.2048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7392919063568115, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [66500/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0205, d_svhn_loss: 0.0555, d_fake_loss: 0.1065, g_loss: 1.1734\n",
            "saved ./samples_fashion/sample-66500-m-s.png\n",
            "saved ./samples_fashion/sample-66500-s-m.png\n",
            "Step [66510/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0146, d_svhn_loss: 0.0279, d_fake_loss: 0.0503, g_loss: 1.1403\n",
            "Step [66520/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0208, d_svhn_loss: 0.0232, d_fake_loss: 0.0938, g_loss: 1.2625\n",
            "Step [66530/80000], d_real_loss: 0.0989, d_mnist_loss: 0.0793, d_svhn_loss: 0.0195, d_fake_loss: 0.0417, g_loss: 1.0055\n",
            "Step [66540/80000], d_real_loss: 0.1601, d_mnist_loss: 0.0625, d_svhn_loss: 0.0976, d_fake_loss: 0.0462, g_loss: 1.0781\n",
            "Step [66550/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0226, d_svhn_loss: 0.0560, d_fake_loss: 0.0367, g_loss: 1.1724\n",
            "Step [66560/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0182, d_svhn_loss: 0.0458, d_fake_loss: 0.0304, g_loss: 1.2228\n",
            "Step [66570/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0233, d_svhn_loss: 0.0163, d_fake_loss: 0.0947, g_loss: 1.2491\n",
            "Step [66580/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0569, d_svhn_loss: 0.0170, d_fake_loss: 0.0673, g_loss: 0.9398\n",
            "Step [66590/80000], d_real_loss: 0.0362, d_mnist_loss: 0.0213, d_svhn_loss: 0.0149, d_fake_loss: 0.0224, g_loss: 1.0773\n",
            "Step [66600/80000], d_real_loss: 0.1202, d_mnist_loss: 0.0907, d_svhn_loss: 0.0294, d_fake_loss: 0.0753, g_loss: 1.2050\n",
            "Step [66610/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0307, d_svhn_loss: 0.0307, d_fake_loss: 0.0558, g_loss: 1.1836\n",
            "Step [66620/80000], d_real_loss: 0.1472, d_mnist_loss: 0.1267, d_svhn_loss: 0.0206, d_fake_loss: 0.0368, g_loss: 0.9978\n",
            "Step [66630/80000], d_real_loss: 0.0272, d_mnist_loss: 0.0166, d_svhn_loss: 0.0107, d_fake_loss: 0.0347, g_loss: 1.1999\n",
            "Step [66640/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0217, d_svhn_loss: 0.0220, d_fake_loss: 0.0333, g_loss: 1.2113\n",
            "Step [66650/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0238, d_svhn_loss: 0.0219, d_fake_loss: 0.0508, g_loss: 1.1284\n",
            "Step [66660/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0331, d_svhn_loss: 0.0155, d_fake_loss: 0.0396, g_loss: 0.9712\n",
            "Step [66670/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0208, d_svhn_loss: 0.0164, d_fake_loss: 0.0547, g_loss: 1.1034\n",
            "Step [66680/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0363, d_svhn_loss: 0.0166, d_fake_loss: 0.0587, g_loss: 1.0957\n",
            "Step [66690/80000], d_real_loss: 0.1248, d_mnist_loss: 0.0934, d_svhn_loss: 0.0314, d_fake_loss: 0.0649, g_loss: 1.2848\n",
            "Step [66700/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0186, d_svhn_loss: 0.0202, d_fake_loss: 0.0477, g_loss: 1.2175\n",
            "Step [66710/80000], d_real_loss: 0.0858, d_mnist_loss: 0.0293, d_svhn_loss: 0.0565, d_fake_loss: 0.0509, g_loss: 1.0864\n",
            "Step [66720/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0190, d_svhn_loss: 0.0154, d_fake_loss: 0.0257, g_loss: 1.0715\n",
            "Step [66730/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0163, d_svhn_loss: 0.0211, d_fake_loss: 0.0455, g_loss: 1.1383\n",
            "Step [66740/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0241, d_svhn_loss: 0.0184, d_fake_loss: 0.0536, g_loss: 1.2097\n",
            "Step [66750/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0208, d_svhn_loss: 0.0282, d_fake_loss: 0.0271, g_loss: 1.1330\n",
            "Step [66760/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0151, d_svhn_loss: 0.0205, d_fake_loss: 0.0500, g_loss: 1.2363\n",
            "Step [66770/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0113, d_svhn_loss: 0.0196, d_fake_loss: 0.0764, g_loss: 1.1313\n",
            "Step [66780/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0198, d_svhn_loss: 0.0576, d_fake_loss: 0.0370, g_loss: 1.0927\n",
            "Step [66790/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0192, d_svhn_loss: 0.0406, d_fake_loss: 0.0690, g_loss: 1.3781\n",
            "Step [66800/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0201, d_svhn_loss: 0.0170, d_fake_loss: 0.0598, g_loss: 1.1137\n",
            "Step [66810/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0125, d_svhn_loss: 0.0217, d_fake_loss: 0.1112, g_loss: 1.2573\n",
            "Step [66820/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0167, d_svhn_loss: 0.0207, d_fake_loss: 0.0319, g_loss: 1.1095\n",
            "Step [66830/80000], d_real_loss: 0.0928, d_mnist_loss: 0.0487, d_svhn_loss: 0.0441, d_fake_loss: 0.0602, g_loss: 1.0433\n",
            "Step [66840/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0295, d_svhn_loss: 0.0145, d_fake_loss: 0.0400, g_loss: 1.0992\n",
            "Step [66850/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0270, d_svhn_loss: 0.0126, d_fake_loss: 0.0369, g_loss: 1.1219\n",
            "Step [66860/80000], d_real_loss: 0.0352, d_mnist_loss: 0.0106, d_svhn_loss: 0.0246, d_fake_loss: 0.0273, g_loss: 1.2178\n",
            "Step [66870/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0202, d_svhn_loss: 0.0194, d_fake_loss: 0.0316, g_loss: 1.2299\n",
            "Step [66880/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0129, d_svhn_loss: 0.0193, d_fake_loss: 0.0197, g_loss: 1.0290\n",
            "Step [66890/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0148, d_svhn_loss: 0.0357, d_fake_loss: 0.0423, g_loss: 1.1190\n",
            "Step [66900/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0137, d_svhn_loss: 0.0537, d_fake_loss: 0.0577, g_loss: 1.0312\n",
            "Step [66910/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0154, d_svhn_loss: 0.0489, d_fake_loss: 0.0730, g_loss: 1.1419\n",
            "Step [66920/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0435, d_svhn_loss: 0.0315, d_fake_loss: 0.0330, g_loss: 1.2698\n",
            "Step [66930/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0400, d_svhn_loss: 0.0236, d_fake_loss: 0.0360, g_loss: 1.0176\n",
            "Step [66940/80000], d_real_loss: 0.0694, d_mnist_loss: 0.0205, d_svhn_loss: 0.0489, d_fake_loss: 0.0506, g_loss: 1.0882\n",
            "Step [66950/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0247, d_svhn_loss: 0.0291, d_fake_loss: 0.0341, g_loss: 1.1798\n",
            "Step [66960/80000], d_real_loss: 0.0683, d_mnist_loss: 0.0267, d_svhn_loss: 0.0417, d_fake_loss: 0.0371, g_loss: 1.0795\n",
            "Step [66970/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0214, d_svhn_loss: 0.0290, d_fake_loss: 0.0259, g_loss: 1.1984\n",
            "Step [66980/80000], d_real_loss: 0.0760, d_mnist_loss: 0.0367, d_svhn_loss: 0.0393, d_fake_loss: 0.1362, g_loss: 1.2792\n",
            "Step [66990/80000], d_real_loss: 0.0532, d_mnist_loss: 0.0146, d_svhn_loss: 0.0385, d_fake_loss: 0.0277, g_loss: 1.1676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7109243273735046, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [67000/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0220, d_svhn_loss: 0.0236, d_fake_loss: 0.0781, g_loss: 1.1501\n",
            "saved ./samples_fashion/sample-67000-m-s.png\n",
            "saved ./samples_fashion/sample-67000-s-m.png\n",
            "Step [67010/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0205, d_svhn_loss: 0.0203, d_fake_loss: 0.0212, g_loss: 1.1360\n",
            "Step [67020/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0269, d_svhn_loss: 0.0184, d_fake_loss: 0.0607, g_loss: 1.3046\n",
            "Step [67030/80000], d_real_loss: 0.1003, d_mnist_loss: 0.0639, d_svhn_loss: 0.0364, d_fake_loss: 0.0909, g_loss: 1.0848\n",
            "Step [67040/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0240, d_svhn_loss: 0.0264, d_fake_loss: 0.0491, g_loss: 1.1865\n",
            "Step [67050/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0178, d_svhn_loss: 0.0275, d_fake_loss: 0.0373, g_loss: 1.2116\n",
            "Step [67060/80000], d_real_loss: 0.0799, d_mnist_loss: 0.0399, d_svhn_loss: 0.0400, d_fake_loss: 0.0484, g_loss: 1.1362\n",
            "Step [67070/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0137, d_svhn_loss: 0.0242, d_fake_loss: 0.0295, g_loss: 1.1110\n",
            "Step [67080/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0349, d_svhn_loss: 0.0210, d_fake_loss: 0.0394, g_loss: 0.9919\n",
            "Step [67090/80000], d_real_loss: 0.0864, d_mnist_loss: 0.0229, d_svhn_loss: 0.0635, d_fake_loss: 0.0647, g_loss: 1.0296\n",
            "Step [67100/80000], d_real_loss: 0.1401, d_mnist_loss: 0.0188, d_svhn_loss: 0.1213, d_fake_loss: 0.1378, g_loss: 1.1027\n",
            "Step [67110/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0666, d_svhn_loss: 0.0176, d_fake_loss: 0.0716, g_loss: 1.2056\n",
            "Step [67120/80000], d_real_loss: 0.1407, d_mnist_loss: 0.1234, d_svhn_loss: 0.0174, d_fake_loss: 0.0374, g_loss: 1.1903\n",
            "Step [67130/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0420, d_svhn_loss: 0.0313, d_fake_loss: 0.0277, g_loss: 1.2070\n",
            "Step [67140/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0175, d_svhn_loss: 0.0199, d_fake_loss: 0.0700, g_loss: 1.0353\n",
            "Step [67150/80000], d_real_loss: 0.0889, d_mnist_loss: 0.0362, d_svhn_loss: 0.0526, d_fake_loss: 0.0650, g_loss: 1.0997\n",
            "Step [67160/80000], d_real_loss: 0.0884, d_mnist_loss: 0.0652, d_svhn_loss: 0.0232, d_fake_loss: 0.1560, g_loss: 1.2127\n",
            "Step [67170/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0170, d_svhn_loss: 0.0385, d_fake_loss: 0.0334, g_loss: 1.1079\n",
            "Step [67180/80000], d_real_loss: 0.0992, d_mnist_loss: 0.0311, d_svhn_loss: 0.0680, d_fake_loss: 0.0550, g_loss: 1.0261\n",
            "Step [67190/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0649, d_svhn_loss: 0.0157, d_fake_loss: 0.0851, g_loss: 1.1582\n",
            "Step [67200/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0209, d_svhn_loss: 0.0291, d_fake_loss: 0.0433, g_loss: 1.1331\n",
            "Step [67210/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0365, d_svhn_loss: 0.0198, d_fake_loss: 0.0877, g_loss: 1.1558\n",
            "Step [67220/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0160, d_svhn_loss: 0.0565, d_fake_loss: 0.0559, g_loss: 1.1859\n",
            "Step [67230/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0319, d_svhn_loss: 0.0260, d_fake_loss: 0.0739, g_loss: 1.1404\n",
            "Step [67240/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0140, d_svhn_loss: 0.0545, d_fake_loss: 0.0862, g_loss: 1.2005\n",
            "Step [67250/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0215, d_svhn_loss: 0.0170, d_fake_loss: 0.0602, g_loss: 1.2612\n",
            "Step [67260/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0147, d_svhn_loss: 0.0264, d_fake_loss: 0.0662, g_loss: 1.1462\n",
            "Step [67270/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0200, d_svhn_loss: 0.0258, d_fake_loss: 0.0755, g_loss: 1.1524\n",
            "Step [67280/80000], d_real_loss: 0.1074, d_mnist_loss: 0.0763, d_svhn_loss: 0.0311, d_fake_loss: 0.0415, g_loss: 1.0889\n",
            "Step [67290/80000], d_real_loss: 0.0736, d_mnist_loss: 0.0303, d_svhn_loss: 0.0433, d_fake_loss: 0.0885, g_loss: 1.1141\n",
            "Step [67300/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0214, d_svhn_loss: 0.0333, d_fake_loss: 0.0370, g_loss: 1.1478\n",
            "Step [67310/80000], d_real_loss: 0.0577, d_mnist_loss: 0.0183, d_svhn_loss: 0.0394, d_fake_loss: 0.0298, g_loss: 1.1321\n",
            "Step [67320/80000], d_real_loss: 0.0998, d_mnist_loss: 0.0789, d_svhn_loss: 0.0209, d_fake_loss: 0.0425, g_loss: 1.0411\n",
            "Step [67330/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0174, d_svhn_loss: 0.0247, d_fake_loss: 0.0365, g_loss: 1.1297\n",
            "Step [67340/80000], d_real_loss: 0.1038, d_mnist_loss: 0.0209, d_svhn_loss: 0.0829, d_fake_loss: 0.1239, g_loss: 1.0391\n",
            "Step [67350/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0174, d_svhn_loss: 0.0216, d_fake_loss: 0.0323, g_loss: 1.2191\n",
            "Step [67360/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0179, d_svhn_loss: 0.0287, d_fake_loss: 0.0286, g_loss: 1.1818\n",
            "Step [67370/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0151, d_svhn_loss: 0.0255, d_fake_loss: 0.0552, g_loss: 1.3355\n",
            "Step [67380/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0294, d_svhn_loss: 0.0118, d_fake_loss: 0.0300, g_loss: 1.1058\n",
            "Step [67390/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0463, d_svhn_loss: 0.0190, d_fake_loss: 0.0481, g_loss: 1.0669\n",
            "Step [67400/80000], d_real_loss: 0.0304, d_mnist_loss: 0.0141, d_svhn_loss: 0.0163, d_fake_loss: 0.0336, g_loss: 1.1636\n",
            "Step [67410/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0211, d_svhn_loss: 0.0124, d_fake_loss: 0.0503, g_loss: 1.2767\n",
            "Step [67420/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0171, d_svhn_loss: 0.0215, d_fake_loss: 0.0328, g_loss: 1.2091\n",
            "Step [67430/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0196, d_svhn_loss: 0.0184, d_fake_loss: 0.0411, g_loss: 1.2610\n",
            "Step [67440/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0266, d_svhn_loss: 0.0260, d_fake_loss: 0.0373, g_loss: 0.9899\n",
            "Step [67450/80000], d_real_loss: 0.0728, d_mnist_loss: 0.0579, d_svhn_loss: 0.0149, d_fake_loss: 0.0354, g_loss: 1.0301\n",
            "Step [67460/80000], d_real_loss: 0.0990, d_mnist_loss: 0.0757, d_svhn_loss: 0.0233, d_fake_loss: 0.0865, g_loss: 1.2117\n",
            "Step [67470/80000], d_real_loss: 0.0733, d_mnist_loss: 0.0298, d_svhn_loss: 0.0435, d_fake_loss: 0.0287, g_loss: 1.0781\n",
            "Step [67480/80000], d_real_loss: 0.1334, d_mnist_loss: 0.1111, d_svhn_loss: 0.0223, d_fake_loss: 0.0966, g_loss: 1.1939\n",
            "Step [67490/80000], d_real_loss: 0.0943, d_mnist_loss: 0.0376, d_svhn_loss: 0.0567, d_fake_loss: 0.0784, g_loss: 1.0886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7320488095283508, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [67500/80000], d_real_loss: 0.0302, d_mnist_loss: 0.0157, d_svhn_loss: 0.0145, d_fake_loss: 0.0988, g_loss: 1.2680\n",
            "saved ./samples_fashion/sample-67500-m-s.png\n",
            "saved ./samples_fashion/sample-67500-s-m.png\n",
            "Step [67510/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0296, d_svhn_loss: 0.0307, d_fake_loss: 0.0748, g_loss: 1.0984\n",
            "Step [67520/80000], d_real_loss: 0.1284, d_mnist_loss: 0.0577, d_svhn_loss: 0.0706, d_fake_loss: 0.0441, g_loss: 1.0397\n",
            "Step [67530/80000], d_real_loss: 0.1044, d_mnist_loss: 0.0452, d_svhn_loss: 0.0592, d_fake_loss: 0.0601, g_loss: 1.0461\n",
            "Step [67540/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0162, d_svhn_loss: 0.0239, d_fake_loss: 0.0350, g_loss: 1.1667\n",
            "Step [67550/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0193, d_svhn_loss: 0.0175, d_fake_loss: 0.0248, g_loss: 1.1722\n",
            "Step [67560/80000], d_real_loss: 0.0333, d_mnist_loss: 0.0169, d_svhn_loss: 0.0164, d_fake_loss: 0.0305, g_loss: 1.2513\n",
            "Step [67570/80000], d_real_loss: 0.0624, d_mnist_loss: 0.0426, d_svhn_loss: 0.0199, d_fake_loss: 0.0302, g_loss: 0.9899\n",
            "Step [67580/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0395, d_svhn_loss: 0.0260, d_fake_loss: 0.0305, g_loss: 1.1215\n",
            "Step [67590/80000], d_real_loss: 0.0309, d_mnist_loss: 0.0199, d_svhn_loss: 0.0110, d_fake_loss: 0.0626, g_loss: 1.1880\n",
            "Step [67600/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0293, d_svhn_loss: 0.0225, d_fake_loss: 0.0388, g_loss: 1.1213\n",
            "Step [67610/80000], d_real_loss: 0.0780, d_mnist_loss: 0.0498, d_svhn_loss: 0.0282, d_fake_loss: 0.0287, g_loss: 1.0020\n",
            "Step [67620/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0284, d_svhn_loss: 0.0214, d_fake_loss: 0.0536, g_loss: 1.0063\n",
            "Step [67630/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0246, d_svhn_loss: 0.0189, d_fake_loss: 0.0734, g_loss: 1.3463\n",
            "Step [67640/80000], d_real_loss: 0.1393, d_mnist_loss: 0.0166, d_svhn_loss: 0.1227, d_fake_loss: 0.0499, g_loss: 1.1105\n",
            "Step [67650/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0358, d_svhn_loss: 0.0276, d_fake_loss: 0.0446, g_loss: 1.2229\n",
            "Step [67660/80000], d_real_loss: 0.1478, d_mnist_loss: 0.0932, d_svhn_loss: 0.0546, d_fake_loss: 0.0641, g_loss: 1.0898\n",
            "Step [67670/80000], d_real_loss: 0.0749, d_mnist_loss: 0.0482, d_svhn_loss: 0.0267, d_fake_loss: 0.1015, g_loss: 1.2564\n",
            "Step [67680/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0253, d_svhn_loss: 0.0170, d_fake_loss: 0.0463, g_loss: 1.2288\n",
            "Step [67690/80000], d_real_loss: 0.1216, d_mnist_loss: 0.1046, d_svhn_loss: 0.0170, d_fake_loss: 0.0587, g_loss: 1.2131\n",
            "Step [67700/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0587, d_svhn_loss: 0.0217, d_fake_loss: 0.1536, g_loss: 1.1347\n",
            "Step [67710/80000], d_real_loss: 0.0465, d_mnist_loss: 0.0296, d_svhn_loss: 0.0169, d_fake_loss: 0.0387, g_loss: 0.9865\n",
            "Step [67720/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0158, d_svhn_loss: 0.0221, d_fake_loss: 0.0689, g_loss: 1.0699\n",
            "Step [67730/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0191, d_svhn_loss: 0.0187, d_fake_loss: 0.0352, g_loss: 1.1566\n",
            "Step [67740/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0665, d_svhn_loss: 0.0246, d_fake_loss: 0.0360, g_loss: 1.1680\n",
            "Step [67750/80000], d_real_loss: 0.0793, d_mnist_loss: 0.0242, d_svhn_loss: 0.0551, d_fake_loss: 0.0559, g_loss: 1.0752\n",
            "Step [67760/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0504, d_svhn_loss: 0.0300, d_fake_loss: 0.0422, g_loss: 1.0572\n",
            "Step [67770/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0188, d_svhn_loss: 0.0325, d_fake_loss: 0.0368, g_loss: 1.1636\n",
            "Step [67780/80000], d_real_loss: 0.1318, d_mnist_loss: 0.0775, d_svhn_loss: 0.0543, d_fake_loss: 0.0411, g_loss: 1.1117\n",
            "Step [67790/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0296, d_svhn_loss: 0.0175, d_fake_loss: 0.0462, g_loss: 0.9997\n",
            "Step [67800/80000], d_real_loss: 0.1105, d_mnist_loss: 0.0403, d_svhn_loss: 0.0702, d_fake_loss: 0.0458, g_loss: 1.1164\n",
            "Step [67810/80000], d_real_loss: 0.0627, d_mnist_loss: 0.0205, d_svhn_loss: 0.0422, d_fake_loss: 0.0612, g_loss: 1.3196\n",
            "Step [67820/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0194, d_svhn_loss: 0.0156, d_fake_loss: 0.0264, g_loss: 1.0386\n",
            "Step [67830/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0300, d_svhn_loss: 0.0539, d_fake_loss: 0.0555, g_loss: 1.1476\n",
            "Step [67840/80000], d_real_loss: 0.1295, d_mnist_loss: 0.0642, d_svhn_loss: 0.0653, d_fake_loss: 0.0550, g_loss: 1.1569\n",
            "Step [67850/80000], d_real_loss: 0.0740, d_mnist_loss: 0.0205, d_svhn_loss: 0.0534, d_fake_loss: 0.1375, g_loss: 0.9796\n",
            "Step [67860/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0259, d_svhn_loss: 0.0377, d_fake_loss: 0.0396, g_loss: 1.0762\n",
            "Step [67870/80000], d_real_loss: 0.0699, d_mnist_loss: 0.0499, d_svhn_loss: 0.0200, d_fake_loss: 0.0510, g_loss: 1.1784\n",
            "Step [67880/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0143, d_svhn_loss: 0.0197, d_fake_loss: 0.0271, g_loss: 1.2124\n",
            "Step [67890/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0232, d_svhn_loss: 0.0194, d_fake_loss: 0.0860, g_loss: 1.2526\n",
            "Step [67900/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0158, d_svhn_loss: 0.0207, d_fake_loss: 0.0415, g_loss: 1.1954\n",
            "Step [67910/80000], d_real_loss: 0.0593, d_mnist_loss: 0.0345, d_svhn_loss: 0.0248, d_fake_loss: 0.0441, g_loss: 0.9535\n",
            "Step [67920/80000], d_real_loss: 0.0844, d_mnist_loss: 0.0200, d_svhn_loss: 0.0644, d_fake_loss: 0.0223, g_loss: 1.0847\n",
            "Step [67930/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0139, d_svhn_loss: 0.0330, d_fake_loss: 0.0295, g_loss: 1.2177\n",
            "Step [67940/80000], d_real_loss: 0.1520, d_mnist_loss: 0.0437, d_svhn_loss: 0.1083, d_fake_loss: 0.1535, g_loss: 1.4738\n",
            "Step [67950/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0251, d_svhn_loss: 0.0285, d_fake_loss: 0.0302, g_loss: 1.0158\n",
            "Step [67960/80000], d_real_loss: 0.0714, d_mnist_loss: 0.0450, d_svhn_loss: 0.0264, d_fake_loss: 0.0463, g_loss: 1.1647\n",
            "Step [67970/80000], d_real_loss: 0.0795, d_mnist_loss: 0.0310, d_svhn_loss: 0.0486, d_fake_loss: 0.0345, g_loss: 1.1136\n",
            "Step [67980/80000], d_real_loss: 0.1130, d_mnist_loss: 0.0189, d_svhn_loss: 0.0941, d_fake_loss: 0.0275, g_loss: 1.1967\n",
            "Step [67990/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0358, d_svhn_loss: 0.0157, d_fake_loss: 0.0872, g_loss: 1.2136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7388972640037537, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [68000/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0184, d_svhn_loss: 0.0258, d_fake_loss: 0.0592, g_loss: 1.3323\n",
            "saved ./samples_fashion/sample-68000-m-s.png\n",
            "saved ./samples_fashion/sample-68000-s-m.png\n",
            "Step [68010/80000], d_real_loss: 0.0867, d_mnist_loss: 0.0326, d_svhn_loss: 0.0540, d_fake_loss: 0.0565, g_loss: 1.1305\n",
            "Step [68020/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0218, d_svhn_loss: 0.0276, d_fake_loss: 0.0371, g_loss: 1.2223\n",
            "Step [68030/80000], d_real_loss: 0.0467, d_mnist_loss: 0.0182, d_svhn_loss: 0.0285, d_fake_loss: 0.0401, g_loss: 1.1094\n",
            "Step [68040/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0168, d_svhn_loss: 0.0154, d_fake_loss: 0.0527, g_loss: 1.1658\n",
            "Step [68050/80000], d_real_loss: 0.0802, d_mnist_loss: 0.0228, d_svhn_loss: 0.0574, d_fake_loss: 0.0970, g_loss: 1.0648\n",
            "Step [68060/80000], d_real_loss: 0.0674, d_mnist_loss: 0.0368, d_svhn_loss: 0.0306, d_fake_loss: 0.0630, g_loss: 1.0969\n",
            "Step [68070/80000], d_real_loss: 0.1182, d_mnist_loss: 0.0316, d_svhn_loss: 0.0866, d_fake_loss: 0.0324, g_loss: 1.0928\n",
            "Step [68080/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0484, d_svhn_loss: 0.0184, d_fake_loss: 0.0635, g_loss: 1.0998\n",
            "Step [68090/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0178, d_svhn_loss: 0.0183, d_fake_loss: 0.0628, g_loss: 1.1728\n",
            "Step [68100/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0246, d_svhn_loss: 0.0236, d_fake_loss: 0.0585, g_loss: 1.1631\n",
            "Step [68110/80000], d_real_loss: 0.1449, d_mnist_loss: 0.0281, d_svhn_loss: 0.1169, d_fake_loss: 0.0286, g_loss: 1.0753\n",
            "Step [68120/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0166, d_svhn_loss: 0.0229, d_fake_loss: 0.0471, g_loss: 1.0630\n",
            "Step [68130/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0393, d_svhn_loss: 0.0223, d_fake_loss: 0.1841, g_loss: 1.1079\n",
            "Step [68140/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0303, d_svhn_loss: 0.0417, d_fake_loss: 0.0381, g_loss: 1.0576\n",
            "Step [68150/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0242, d_svhn_loss: 0.0278, d_fake_loss: 0.0417, g_loss: 1.0767\n",
            "Step [68160/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0126, d_svhn_loss: 0.0158, d_fake_loss: 0.0784, g_loss: 1.4500\n",
            "Step [68170/80000], d_real_loss: 0.0353, d_mnist_loss: 0.0189, d_svhn_loss: 0.0164, d_fake_loss: 0.0579, g_loss: 1.1068\n",
            "Step [68180/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0263, d_svhn_loss: 0.0238, d_fake_loss: 0.0801, g_loss: 1.3552\n",
            "Step [68190/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0368, d_svhn_loss: 0.0414, d_fake_loss: 0.0833, g_loss: 1.1521\n",
            "Step [68200/80000], d_real_loss: 0.0702, d_mnist_loss: 0.0442, d_svhn_loss: 0.0260, d_fake_loss: 0.0696, g_loss: 1.2097\n",
            "Step [68210/80000], d_real_loss: 0.1346, d_mnist_loss: 0.0524, d_svhn_loss: 0.0822, d_fake_loss: 0.0279, g_loss: 1.2081\n",
            "Step [68220/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0165, d_svhn_loss: 0.0225, d_fake_loss: 0.0375, g_loss: 1.1335\n",
            "Step [68230/80000], d_real_loss: 0.0723, d_mnist_loss: 0.0233, d_svhn_loss: 0.0489, d_fake_loss: 0.0739, g_loss: 1.0976\n",
            "Step [68240/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0212, d_svhn_loss: 0.0162, d_fake_loss: 0.0424, g_loss: 1.1546\n",
            "Step [68250/80000], d_real_loss: 0.0568, d_mnist_loss: 0.0265, d_svhn_loss: 0.0303, d_fake_loss: 0.0573, g_loss: 1.1310\n",
            "Step [68260/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0164, d_svhn_loss: 0.0213, d_fake_loss: 0.0228, g_loss: 1.2283\n",
            "Step [68270/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0194, d_svhn_loss: 0.0255, d_fake_loss: 0.0566, g_loss: 1.2843\n",
            "Step [68280/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0182, d_svhn_loss: 0.0204, d_fake_loss: 0.0321, g_loss: 1.1007\n",
            "Step [68290/80000], d_real_loss: 0.2401, d_mnist_loss: 0.1572, d_svhn_loss: 0.0828, d_fake_loss: 0.0586, g_loss: 1.1756\n",
            "Step [68300/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0158, d_svhn_loss: 0.0203, d_fake_loss: 0.0574, g_loss: 1.1693\n",
            "Step [68310/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0289, d_svhn_loss: 0.0222, d_fake_loss: 0.0423, g_loss: 1.1584\n",
            "Step [68320/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0148, d_svhn_loss: 0.0220, d_fake_loss: 0.0444, g_loss: 1.0837\n",
            "Step [68330/80000], d_real_loss: 0.0565, d_mnist_loss: 0.0319, d_svhn_loss: 0.0247, d_fake_loss: 0.1109, g_loss: 1.2608\n",
            "Step [68340/80000], d_real_loss: 0.0859, d_mnist_loss: 0.0647, d_svhn_loss: 0.0213, d_fake_loss: 0.0298, g_loss: 1.1673\n",
            "Step [68350/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0124, d_svhn_loss: 0.0193, d_fake_loss: 0.0928, g_loss: 1.1932\n",
            "Step [68360/80000], d_real_loss: 0.2000, d_mnist_loss: 0.0180, d_svhn_loss: 0.1820, d_fake_loss: 0.1273, g_loss: 1.0662\n",
            "Step [68370/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0185, d_svhn_loss: 0.0252, d_fake_loss: 0.0435, g_loss: 1.1329\n",
            "Step [68380/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0384, d_svhn_loss: 0.0437, d_fake_loss: 0.0533, g_loss: 1.0928\n",
            "Step [68390/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0377, d_svhn_loss: 0.0218, d_fake_loss: 0.0347, g_loss: 1.0355\n",
            "Step [68400/80000], d_real_loss: 0.1078, d_mnist_loss: 0.0333, d_svhn_loss: 0.0745, d_fake_loss: 0.0446, g_loss: 1.2431\n",
            "Step [68410/80000], d_real_loss: 0.0595, d_mnist_loss: 0.0338, d_svhn_loss: 0.0257, d_fake_loss: 0.0424, g_loss: 1.2423\n",
            "Step [68420/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0146, d_svhn_loss: 0.0247, d_fake_loss: 0.0367, g_loss: 1.0773\n",
            "Step [68430/80000], d_real_loss: 0.0985, d_mnist_loss: 0.0789, d_svhn_loss: 0.0197, d_fake_loss: 0.0666, g_loss: 1.1168\n",
            "Step [68440/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0326, d_svhn_loss: 0.0282, d_fake_loss: 0.1274, g_loss: 1.2060\n",
            "Step [68450/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0250, d_svhn_loss: 0.0155, d_fake_loss: 0.0430, g_loss: 1.0339\n",
            "Step [68460/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0152, d_svhn_loss: 0.0221, d_fake_loss: 0.0537, g_loss: 1.2209\n",
            "Step [68470/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0149, d_svhn_loss: 0.0218, d_fake_loss: 0.0627, g_loss: 1.2920\n",
            "Step [68480/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0326, d_svhn_loss: 0.0381, d_fake_loss: 0.0653, g_loss: 1.1344\n",
            "Step [68490/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0228, d_svhn_loss: 0.0245, d_fake_loss: 0.0339, g_loss: 1.0442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7701929211616516, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [68500/80000], d_real_loss: 0.0496, d_mnist_loss: 0.0274, d_svhn_loss: 0.0221, d_fake_loss: 0.0451, g_loss: 1.0590\n",
            "saved ./samples_fashion/sample-68500-m-s.png\n",
            "saved ./samples_fashion/sample-68500-s-m.png\n",
            "Step [68510/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0308, d_svhn_loss: 0.0214, d_fake_loss: 0.0416, g_loss: 1.2126\n",
            "Step [68520/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0403, d_svhn_loss: 0.0269, d_fake_loss: 0.0442, g_loss: 1.1712\n",
            "Step [68530/80000], d_real_loss: 0.0589, d_mnist_loss: 0.0391, d_svhn_loss: 0.0198, d_fake_loss: 0.0417, g_loss: 1.0615\n",
            "Step [68540/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0193, d_svhn_loss: 0.0277, d_fake_loss: 0.0318, g_loss: 1.3278\n",
            "Step [68550/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0399, d_svhn_loss: 0.0137, d_fake_loss: 0.0399, g_loss: 1.0213\n",
            "Step [68560/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0194, d_svhn_loss: 0.0184, d_fake_loss: 0.0967, g_loss: 1.2574\n",
            "Step [68570/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0371, d_svhn_loss: 0.0165, d_fake_loss: 0.1034, g_loss: 1.0367\n",
            "Step [68580/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0195, d_svhn_loss: 0.0216, d_fake_loss: 0.0429, g_loss: 1.2733\n",
            "Step [68590/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0257, d_svhn_loss: 0.0260, d_fake_loss: 0.0307, g_loss: 1.2541\n",
            "Step [68600/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0160, d_svhn_loss: 0.0130, d_fake_loss: 0.0510, g_loss: 1.1775\n",
            "Step [68610/80000], d_real_loss: 0.0870, d_mnist_loss: 0.0631, d_svhn_loss: 0.0239, d_fake_loss: 0.0483, g_loss: 1.2400\n",
            "Step [68620/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0393, d_svhn_loss: 0.0190, d_fake_loss: 0.0592, g_loss: 1.2349\n",
            "Step [68630/80000], d_real_loss: 0.0366, d_mnist_loss: 0.0135, d_svhn_loss: 0.0230, d_fake_loss: 0.0441, g_loss: 1.0789\n",
            "Step [68640/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0158, d_svhn_loss: 0.0172, d_fake_loss: 0.0441, g_loss: 1.2349\n",
            "Step [68650/80000], d_real_loss: 0.1152, d_mnist_loss: 0.0726, d_svhn_loss: 0.0427, d_fake_loss: 0.0675, g_loss: 1.1183\n",
            "Step [68660/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0172, d_svhn_loss: 0.0211, d_fake_loss: 0.0504, g_loss: 1.1521\n",
            "Step [68670/80000], d_real_loss: 0.1134, d_mnist_loss: 0.0279, d_svhn_loss: 0.0856, d_fake_loss: 0.0346, g_loss: 1.1321\n",
            "Step [68680/80000], d_real_loss: 0.1463, d_mnist_loss: 0.1297, d_svhn_loss: 0.0166, d_fake_loss: 0.1406, g_loss: 1.3781\n",
            "Step [68690/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0254, d_svhn_loss: 0.0206, d_fake_loss: 0.0338, g_loss: 1.0037\n",
            "Step [68700/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0149, d_svhn_loss: 0.0276, d_fake_loss: 0.0297, g_loss: 1.1733\n",
            "Step [68710/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0141, d_svhn_loss: 0.0235, d_fake_loss: 0.0318, g_loss: 1.2228\n",
            "Step [68720/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0399, d_svhn_loss: 0.0232, d_fake_loss: 0.0296, g_loss: 1.1664\n",
            "Step [68730/80000], d_real_loss: 0.0451, d_mnist_loss: 0.0166, d_svhn_loss: 0.0285, d_fake_loss: 0.0428, g_loss: 1.1732\n",
            "Step [68740/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0150, d_svhn_loss: 0.0500, d_fake_loss: 0.0470, g_loss: 1.1758\n",
            "Step [68750/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0176, d_svhn_loss: 0.0297, d_fake_loss: 0.0228, g_loss: 1.2481\n",
            "Step [68760/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0175, d_svhn_loss: 0.0159, d_fake_loss: 0.0567, g_loss: 1.0642\n",
            "Step [68770/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0233, d_svhn_loss: 0.0181, d_fake_loss: 0.0251, g_loss: 1.2865\n",
            "Step [68780/80000], d_real_loss: 0.0692, d_mnist_loss: 0.0486, d_svhn_loss: 0.0206, d_fake_loss: 0.0678, g_loss: 1.1662\n",
            "Step [68790/80000], d_real_loss: 0.1675, d_mnist_loss: 0.1446, d_svhn_loss: 0.0229, d_fake_loss: 0.1052, g_loss: 1.0873\n",
            "Step [68800/80000], d_real_loss: 0.0289, d_mnist_loss: 0.0159, d_svhn_loss: 0.0130, d_fake_loss: 0.0310, g_loss: 1.1563\n",
            "Step [68810/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0149, d_svhn_loss: 0.0121, d_fake_loss: 0.0468, g_loss: 1.0556\n",
            "Step [68820/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0553, d_svhn_loss: 0.0211, d_fake_loss: 0.0307, g_loss: 1.0561\n",
            "Step [68830/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0138, d_svhn_loss: 0.0241, d_fake_loss: 0.0810, g_loss: 1.5873\n",
            "Step [68840/80000], d_real_loss: 0.0929, d_mnist_loss: 0.0835, d_svhn_loss: 0.0094, d_fake_loss: 0.0440, g_loss: 1.0605\n",
            "Step [68850/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0291, d_svhn_loss: 0.0158, d_fake_loss: 0.1387, g_loss: 1.4267\n",
            "Step [68860/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0117, d_svhn_loss: 0.0192, d_fake_loss: 0.0473, g_loss: 0.9672\n",
            "Step [68870/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0123, d_svhn_loss: 0.0321, d_fake_loss: 0.0365, g_loss: 1.0919\n",
            "Step [68880/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0426, d_svhn_loss: 0.0361, d_fake_loss: 0.1028, g_loss: 1.1762\n",
            "Step [68890/80000], d_real_loss: 0.0977, d_mnist_loss: 0.0469, d_svhn_loss: 0.0508, d_fake_loss: 0.0450, g_loss: 1.0753\n",
            "Step [68900/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0235, d_svhn_loss: 0.0166, d_fake_loss: 0.0328, g_loss: 1.1489\n",
            "Step [68910/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0490, d_svhn_loss: 0.0254, d_fake_loss: 0.0519, g_loss: 1.1650\n",
            "Step [68920/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0185, d_svhn_loss: 0.0248, d_fake_loss: 0.0415, g_loss: 1.2235\n",
            "Step [68930/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0307, d_svhn_loss: 0.0143, d_fake_loss: 0.0413, g_loss: 1.1571\n",
            "Step [68940/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0142, d_svhn_loss: 0.0181, d_fake_loss: 0.0314, g_loss: 1.1358\n",
            "Step [68950/80000], d_real_loss: 0.0682, d_mnist_loss: 0.0280, d_svhn_loss: 0.0402, d_fake_loss: 0.0355, g_loss: 1.0688\n",
            "Step [68960/80000], d_real_loss: 0.0932, d_mnist_loss: 0.0284, d_svhn_loss: 0.0647, d_fake_loss: 0.0431, g_loss: 1.1187\n",
            "Step [68970/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0195, d_svhn_loss: 0.0166, d_fake_loss: 0.0426, g_loss: 1.1766\n",
            "Step [68980/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0218, d_svhn_loss: 0.0466, d_fake_loss: 0.0527, g_loss: 1.2281\n",
            "Step [68990/80000], d_real_loss: 0.1134, d_mnist_loss: 0.0545, d_svhn_loss: 0.0589, d_fake_loss: 0.0436, g_loss: 1.1752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.70566326379776, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [69000/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0127, d_svhn_loss: 0.0274, d_fake_loss: 0.0727, g_loss: 1.2246\n",
            "saved ./samples_fashion/sample-69000-m-s.png\n",
            "saved ./samples_fashion/sample-69000-s-m.png\n",
            "Step [69010/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0234, d_svhn_loss: 0.0256, d_fake_loss: 0.0533, g_loss: 1.0122\n",
            "Step [69020/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0123, d_svhn_loss: 0.0223, d_fake_loss: 0.0511, g_loss: 1.2722\n",
            "Step [69030/80000], d_real_loss: 0.0334, d_mnist_loss: 0.0161, d_svhn_loss: 0.0173, d_fake_loss: 0.0599, g_loss: 1.1941\n",
            "Step [69040/80000], d_real_loss: 0.1054, d_mnist_loss: 0.0171, d_svhn_loss: 0.0883, d_fake_loss: 0.0572, g_loss: 1.1009\n",
            "Step [69050/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0180, d_svhn_loss: 0.0368, d_fake_loss: 0.0888, g_loss: 1.3301\n",
            "Step [69060/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0179, d_svhn_loss: 0.0318, d_fake_loss: 0.0689, g_loss: 1.1216\n",
            "Step [69070/80000], d_real_loss: 0.1179, d_mnist_loss: 0.0329, d_svhn_loss: 0.0850, d_fake_loss: 0.0614, g_loss: 1.1219\n",
            "Step [69080/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0365, d_svhn_loss: 0.0219, d_fake_loss: 0.0342, g_loss: 1.0522\n",
            "Step [69090/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0177, d_svhn_loss: 0.0141, d_fake_loss: 0.0440, g_loss: 1.2371\n",
            "Step [69100/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0182, d_svhn_loss: 0.0135, d_fake_loss: 0.0622, g_loss: 1.2775\n",
            "Step [69110/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0264, d_svhn_loss: 0.0309, d_fake_loss: 0.0300, g_loss: 1.2803\n",
            "Step [69120/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0201, d_svhn_loss: 0.0263, d_fake_loss: 0.1111, g_loss: 1.0309\n",
            "Step [69130/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0170, d_svhn_loss: 0.0235, d_fake_loss: 0.0326, g_loss: 1.1269\n",
            "Step [69140/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0231, d_svhn_loss: 0.0192, d_fake_loss: 0.0557, g_loss: 1.3165\n",
            "Step [69150/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0179, d_svhn_loss: 0.0157, d_fake_loss: 0.0383, g_loss: 1.2750\n",
            "Step [69160/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0196, d_svhn_loss: 0.0167, d_fake_loss: 0.0644, g_loss: 0.9404\n",
            "Step [69170/80000], d_real_loss: 0.0526, d_mnist_loss: 0.0333, d_svhn_loss: 0.0193, d_fake_loss: 0.0418, g_loss: 1.2371\n",
            "Step [69180/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0196, d_svhn_loss: 0.0208, d_fake_loss: 0.0682, g_loss: 1.1177\n",
            "Step [69190/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0168, d_svhn_loss: 0.0199, d_fake_loss: 0.0513, g_loss: 1.1104\n",
            "Step [69200/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0115, d_svhn_loss: 0.0795, d_fake_loss: 0.0606, g_loss: 1.2127\n",
            "Step [69210/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0418, d_svhn_loss: 0.0118, d_fake_loss: 0.0306, g_loss: 1.1378\n",
            "Step [69220/80000], d_real_loss: 0.1288, d_mnist_loss: 0.0213, d_svhn_loss: 0.1075, d_fake_loss: 0.1219, g_loss: 1.0954\n",
            "Step [69230/80000], d_real_loss: 0.1085, d_mnist_loss: 0.0751, d_svhn_loss: 0.0334, d_fake_loss: 0.0497, g_loss: 1.5857\n",
            "Step [69240/80000], d_real_loss: 0.2170, d_mnist_loss: 0.1981, d_svhn_loss: 0.0188, d_fake_loss: 0.0943, g_loss: 1.3801\n",
            "Step [69250/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0171, d_svhn_loss: 0.0287, d_fake_loss: 0.0277, g_loss: 1.1810\n",
            "Step [69260/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0216, d_svhn_loss: 0.0338, d_fake_loss: 0.0516, g_loss: 1.1684\n",
            "Step [69270/80000], d_real_loss: 0.1487, d_mnist_loss: 0.0709, d_svhn_loss: 0.0779, d_fake_loss: 0.0556, g_loss: 1.2019\n",
            "Step [69280/80000], d_real_loss: 0.1039, d_mnist_loss: 0.0808, d_svhn_loss: 0.0231, d_fake_loss: 0.1458, g_loss: 1.4279\n",
            "Step [69290/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0231, d_svhn_loss: 0.0212, d_fake_loss: 0.0650, g_loss: 1.2720\n",
            "Step [69300/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0293, d_svhn_loss: 0.0137, d_fake_loss: 0.0581, g_loss: 1.0897\n",
            "Step [69310/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0263, d_svhn_loss: 0.0206, d_fake_loss: 0.0361, g_loss: 1.1716\n",
            "Step [69320/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0249, d_svhn_loss: 0.0223, d_fake_loss: 0.0586, g_loss: 1.1117\n",
            "Step [69330/80000], d_real_loss: 0.0892, d_mnist_loss: 0.0310, d_svhn_loss: 0.0582, d_fake_loss: 0.0556, g_loss: 1.2677\n",
            "Step [69340/80000], d_real_loss: 0.0516, d_mnist_loss: 0.0265, d_svhn_loss: 0.0251, d_fake_loss: 0.0303, g_loss: 1.1323\n",
            "Step [69350/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0197, d_svhn_loss: 0.0148, d_fake_loss: 0.0284, g_loss: 1.3074\n",
            "Step [69360/80000], d_real_loss: 0.1040, d_mnist_loss: 0.0743, d_svhn_loss: 0.0297, d_fake_loss: 0.0530, g_loss: 1.2483\n",
            "Step [69370/80000], d_real_loss: 0.1726, d_mnist_loss: 0.0738, d_svhn_loss: 0.0988, d_fake_loss: 0.0376, g_loss: 1.1285\n",
            "Step [69380/80000], d_real_loss: 0.0296, d_mnist_loss: 0.0162, d_svhn_loss: 0.0134, d_fake_loss: 0.0320, g_loss: 1.2350\n",
            "Step [69390/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0280, d_svhn_loss: 0.0335, d_fake_loss: 0.0612, g_loss: 1.3406\n",
            "Step [69400/80000], d_real_loss: 0.0653, d_mnist_loss: 0.0192, d_svhn_loss: 0.0460, d_fake_loss: 0.0511, g_loss: 1.2379\n",
            "Step [69410/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0420, d_svhn_loss: 0.0396, d_fake_loss: 0.0801, g_loss: 1.0666\n",
            "Step [69420/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0235, d_svhn_loss: 0.0146, d_fake_loss: 0.0756, g_loss: 1.2532\n",
            "Step [69430/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0185, d_svhn_loss: 0.0276, d_fake_loss: 0.0485, g_loss: 1.4766\n",
            "Step [69440/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0201, d_svhn_loss: 0.0326, d_fake_loss: 0.0459, g_loss: 1.0838\n",
            "Step [69450/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0186, d_svhn_loss: 0.0289, d_fake_loss: 0.0669, g_loss: 1.0215\n",
            "Step [69460/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0152, d_svhn_loss: 0.0213, d_fake_loss: 0.0333, g_loss: 1.1539\n",
            "Step [69470/80000], d_real_loss: 0.0882, d_mnist_loss: 0.0254, d_svhn_loss: 0.0627, d_fake_loss: 0.0549, g_loss: 1.2658\n",
            "Step [69480/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0228, d_svhn_loss: 0.0391, d_fake_loss: 0.0524, g_loss: 1.1436\n",
            "Step [69490/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0194, d_svhn_loss: 0.0278, d_fake_loss: 0.0568, g_loss: 1.2725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7041372060775757, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [69500/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0198, d_svhn_loss: 0.0175, d_fake_loss: 0.1505, g_loss: 1.0454\n",
            "saved ./samples_fashion/sample-69500-m-s.png\n",
            "saved ./samples_fashion/sample-69500-s-m.png\n",
            "Step [69510/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0236, d_svhn_loss: 0.0525, d_fake_loss: 0.0942, g_loss: 1.3103\n",
            "Step [69520/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0434, d_svhn_loss: 0.0304, d_fake_loss: 0.0602, g_loss: 1.1063\n",
            "Step [69530/80000], d_real_loss: 0.1505, d_mnist_loss: 0.1200, d_svhn_loss: 0.0305, d_fake_loss: 0.1467, g_loss: 1.3280\n",
            "Step [69540/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0166, d_svhn_loss: 0.0330, d_fake_loss: 0.0227, g_loss: 1.0954\n",
            "Step [69550/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0150, d_svhn_loss: 0.0570, d_fake_loss: 0.0520, g_loss: 1.0795\n",
            "Step [69560/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0286, d_svhn_loss: 0.0387, d_fake_loss: 0.0625, g_loss: 1.1593\n",
            "Step [69570/80000], d_real_loss: 0.0285, d_mnist_loss: 0.0151, d_svhn_loss: 0.0134, d_fake_loss: 0.0386, g_loss: 1.2247\n",
            "Step [69580/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0398, d_svhn_loss: 0.0156, d_fake_loss: 0.0634, g_loss: 1.1880\n",
            "Step [69590/80000], d_real_loss: 0.0371, d_mnist_loss: 0.0162, d_svhn_loss: 0.0209, d_fake_loss: 0.0266, g_loss: 1.0951\n",
            "Step [69600/80000], d_real_loss: 0.1131, d_mnist_loss: 0.0950, d_svhn_loss: 0.0182, d_fake_loss: 0.0514, g_loss: 1.0702\n",
            "Step [69610/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0227, d_svhn_loss: 0.0157, d_fake_loss: 0.0319, g_loss: 1.1896\n",
            "Step [69620/80000], d_real_loss: 0.0551, d_mnist_loss: 0.0192, d_svhn_loss: 0.0359, d_fake_loss: 0.0399, g_loss: 1.1352\n",
            "Step [69630/80000], d_real_loss: 0.0931, d_mnist_loss: 0.0741, d_svhn_loss: 0.0189, d_fake_loss: 0.0281, g_loss: 1.1180\n",
            "Step [69640/80000], d_real_loss: 0.0781, d_mnist_loss: 0.0162, d_svhn_loss: 0.0620, d_fake_loss: 0.1273, g_loss: 1.3205\n",
            "Step [69650/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0314, d_svhn_loss: 0.0139, d_fake_loss: 0.0465, g_loss: 1.0991\n",
            "Step [69660/80000], d_real_loss: 0.1466, d_mnist_loss: 0.1215, d_svhn_loss: 0.0250, d_fake_loss: 0.0843, g_loss: 0.9478\n",
            "Step [69670/80000], d_real_loss: 0.0799, d_mnist_loss: 0.0202, d_svhn_loss: 0.0597, d_fake_loss: 0.0807, g_loss: 0.9332\n",
            "Step [69680/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0270, d_svhn_loss: 0.0278, d_fake_loss: 0.0912, g_loss: 1.2216\n",
            "Step [69690/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0236, d_svhn_loss: 0.0227, d_fake_loss: 0.0361, g_loss: 1.2636\n",
            "Step [69700/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0311, d_svhn_loss: 0.0252, d_fake_loss: 0.0422, g_loss: 1.1385\n",
            "Step [69710/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0186, d_svhn_loss: 0.0314, d_fake_loss: 0.0504, g_loss: 1.1850\n",
            "Step [69720/80000], d_real_loss: 0.1135, d_mnist_loss: 0.0960, d_svhn_loss: 0.0175, d_fake_loss: 0.0380, g_loss: 1.0324\n",
            "Step [69730/80000], d_real_loss: 0.0930, d_mnist_loss: 0.0773, d_svhn_loss: 0.0157, d_fake_loss: 0.1842, g_loss: 1.4015\n",
            "Step [69740/80000], d_real_loss: 0.0715, d_mnist_loss: 0.0172, d_svhn_loss: 0.0543, d_fake_loss: 0.0706, g_loss: 1.0897\n",
            "Step [69750/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0200, d_svhn_loss: 0.0440, d_fake_loss: 0.0412, g_loss: 1.1851\n",
            "Step [69760/80000], d_real_loss: 0.0541, d_mnist_loss: 0.0329, d_svhn_loss: 0.0212, d_fake_loss: 0.0352, g_loss: 1.0938\n",
            "Step [69770/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0207, d_svhn_loss: 0.0207, d_fake_loss: 0.0304, g_loss: 1.1917\n",
            "Step [69780/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0207, d_svhn_loss: 0.0167, d_fake_loss: 0.0304, g_loss: 1.1366\n",
            "Step [69790/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0326, d_svhn_loss: 0.0134, d_fake_loss: 0.0431, g_loss: 1.0394\n",
            "Step [69800/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0647, d_svhn_loss: 0.0524, d_fake_loss: 0.0873, g_loss: 0.9766\n",
            "Step [69810/80000], d_real_loss: 0.0599, d_mnist_loss: 0.0404, d_svhn_loss: 0.0195, d_fake_loss: 0.0419, g_loss: 1.2011\n",
            "Step [69820/80000], d_real_loss: 0.1048, d_mnist_loss: 0.0694, d_svhn_loss: 0.0355, d_fake_loss: 0.0230, g_loss: 1.2583\n",
            "Step [69830/80000], d_real_loss: 0.0458, d_mnist_loss: 0.0143, d_svhn_loss: 0.0315, d_fake_loss: 0.1445, g_loss: 1.4430\n",
            "Step [69840/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0170, d_svhn_loss: 0.0233, d_fake_loss: 0.0912, g_loss: 1.1534\n",
            "Step [69850/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0350, d_svhn_loss: 0.0211, d_fake_loss: 0.1477, g_loss: 1.1060\n",
            "Step [69860/80000], d_real_loss: 0.0631, d_mnist_loss: 0.0402, d_svhn_loss: 0.0229, d_fake_loss: 0.0332, g_loss: 1.0498\n",
            "Step [69870/80000], d_real_loss: 0.0385, d_mnist_loss: 0.0160, d_svhn_loss: 0.0225, d_fake_loss: 0.0379, g_loss: 1.2137\n",
            "Step [69880/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0174, d_svhn_loss: 0.0416, d_fake_loss: 0.0418, g_loss: 1.1201\n",
            "Step [69890/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0151, d_svhn_loss: 0.0373, d_fake_loss: 0.0326, g_loss: 1.1958\n",
            "Step [69900/80000], d_real_loss: 0.1686, d_mnist_loss: 0.0796, d_svhn_loss: 0.0889, d_fake_loss: 0.0416, g_loss: 1.1125\n",
            "Step [69910/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0179, d_svhn_loss: 0.0193, d_fake_loss: 0.0801, g_loss: 1.3268\n",
            "Step [69920/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0217, d_svhn_loss: 0.0401, d_fake_loss: 0.1231, g_loss: 1.3177\n",
            "Step [69930/80000], d_real_loss: 0.0750, d_mnist_loss: 0.0386, d_svhn_loss: 0.0363, d_fake_loss: 0.0535, g_loss: 1.2277\n",
            "Step [69940/80000], d_real_loss: 0.0601, d_mnist_loss: 0.0386, d_svhn_loss: 0.0215, d_fake_loss: 0.0447, g_loss: 0.9856\n",
            "Step [69950/80000], d_real_loss: 0.0529, d_mnist_loss: 0.0354, d_svhn_loss: 0.0175, d_fake_loss: 0.0326, g_loss: 1.2410\n",
            "Step [69960/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0336, d_svhn_loss: 0.0179, d_fake_loss: 0.0811, g_loss: 1.3339\n",
            "Step [69970/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0167, d_svhn_loss: 0.0643, d_fake_loss: 0.0313, g_loss: 1.1147\n",
            "Step [69980/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0230, d_svhn_loss: 0.0217, d_fake_loss: 0.0480, g_loss: 1.2003\n",
            "Step [69990/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0532, d_svhn_loss: 0.0268, d_fake_loss: 0.0790, g_loss: 0.9599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7661061882972717, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [70000/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0151, d_svhn_loss: 0.0382, d_fake_loss: 0.0286, g_loss: 1.1525\n",
            "saved ./samples_fashion/sample-70000-m-s.png\n",
            "saved ./samples_fashion/sample-70000-s-m.png\n",
            "Step [70010/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0284, d_svhn_loss: 0.0357, d_fake_loss: 0.0495, g_loss: 1.1525\n",
            "Step [70020/80000], d_real_loss: 0.0941, d_mnist_loss: 0.0177, d_svhn_loss: 0.0764, d_fake_loss: 0.0252, g_loss: 1.1352\n",
            "Step [70030/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0216, d_svhn_loss: 0.0436, d_fake_loss: 0.0497, g_loss: 1.0784\n",
            "Step [70040/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0246, d_svhn_loss: 0.0163, d_fake_loss: 0.0415, g_loss: 1.0457\n",
            "Step [70050/80000], d_real_loss: 0.0755, d_mnist_loss: 0.0498, d_svhn_loss: 0.0257, d_fake_loss: 0.0476, g_loss: 1.2660\n",
            "Step [70060/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0342, d_svhn_loss: 0.0229, d_fake_loss: 0.0486, g_loss: 1.0968\n",
            "Step [70070/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0278, d_svhn_loss: 0.0155, d_fake_loss: 0.0344, g_loss: 1.1526\n",
            "Step [70080/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0249, d_svhn_loss: 0.0185, d_fake_loss: 0.0319, g_loss: 1.1010\n",
            "Step [70090/80000], d_real_loss: 0.0290, d_mnist_loss: 0.0115, d_svhn_loss: 0.0175, d_fake_loss: 0.0321, g_loss: 1.0943\n",
            "Step [70100/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0334, d_svhn_loss: 0.0276, d_fake_loss: 0.1107, g_loss: 1.2090\n",
            "Step [70110/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0140, d_svhn_loss: 0.0533, d_fake_loss: 0.0293, g_loss: 1.1840\n",
            "Step [70120/80000], d_real_loss: 0.0990, d_mnist_loss: 0.0433, d_svhn_loss: 0.0558, d_fake_loss: 0.0840, g_loss: 1.1390\n",
            "Step [70130/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0124, d_svhn_loss: 0.0232, d_fake_loss: 0.0767, g_loss: 1.1924\n",
            "Step [70140/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0376, d_svhn_loss: 0.0206, d_fake_loss: 0.0970, g_loss: 1.1419\n",
            "Step [70150/80000], d_real_loss: 0.0271, d_mnist_loss: 0.0132, d_svhn_loss: 0.0138, d_fake_loss: 0.0491, g_loss: 1.2368\n",
            "Step [70160/80000], d_real_loss: 0.1213, d_mnist_loss: 0.0676, d_svhn_loss: 0.0537, d_fake_loss: 0.1108, g_loss: 1.3015\n",
            "Step [70170/80000], d_real_loss: 0.0270, d_mnist_loss: 0.0133, d_svhn_loss: 0.0137, d_fake_loss: 0.0218, g_loss: 1.1465\n",
            "Step [70180/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0182, d_svhn_loss: 0.0229, d_fake_loss: 0.0314, g_loss: 1.2207\n",
            "Step [70190/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0144, d_svhn_loss: 0.0191, d_fake_loss: 0.0295, g_loss: 1.0714\n",
            "Step [70200/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0173, d_svhn_loss: 0.0143, d_fake_loss: 0.0936, g_loss: 1.1280\n",
            "Step [70210/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0193, d_svhn_loss: 0.0233, d_fake_loss: 0.0587, g_loss: 1.1583\n",
            "Step [70220/80000], d_real_loss: 0.0799, d_mnist_loss: 0.0170, d_svhn_loss: 0.0629, d_fake_loss: 0.1252, g_loss: 1.2137\n",
            "Step [70230/80000], d_real_loss: 0.0291, d_mnist_loss: 0.0128, d_svhn_loss: 0.0162, d_fake_loss: 0.0263, g_loss: 1.0431\n",
            "Step [70240/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0120, d_svhn_loss: 0.0226, d_fake_loss: 0.0579, g_loss: 1.1822\n",
            "Step [70250/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0151, d_svhn_loss: 0.0369, d_fake_loss: 0.0263, g_loss: 1.1402\n",
            "Step [70260/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0501, d_svhn_loss: 0.0314, d_fake_loss: 0.1061, g_loss: 0.9414\n",
            "Step [70270/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0524, d_svhn_loss: 0.0281, d_fake_loss: 0.0502, g_loss: 1.1326\n",
            "Step [70280/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0247, d_svhn_loss: 0.0227, d_fake_loss: 0.0413, g_loss: 1.1321\n",
            "Step [70290/80000], d_real_loss: 0.0987, d_mnist_loss: 0.0680, d_svhn_loss: 0.0307, d_fake_loss: 0.1167, g_loss: 1.1539\n",
            "Step [70300/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0335, d_svhn_loss: 0.0245, d_fake_loss: 0.0765, g_loss: 1.0668\n",
            "Step [70310/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0185, d_svhn_loss: 0.0187, d_fake_loss: 0.0522, g_loss: 1.3292\n",
            "Step [70320/80000], d_real_loss: 0.1133, d_mnist_loss: 0.0138, d_svhn_loss: 0.0995, d_fake_loss: 0.0635, g_loss: 1.0928\n",
            "Step [70330/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0150, d_svhn_loss: 0.0218, d_fake_loss: 0.0275, g_loss: 1.1801\n",
            "Step [70340/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0208, d_svhn_loss: 0.0239, d_fake_loss: 0.0241, g_loss: 1.0941\n",
            "Step [70350/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0182, d_svhn_loss: 0.0396, d_fake_loss: 0.0229, g_loss: 1.0808\n",
            "Step [70360/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0080, d_svhn_loss: 0.0442, d_fake_loss: 0.0315, g_loss: 1.1621\n",
            "Step [70370/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0184, d_svhn_loss: 0.0220, d_fake_loss: 0.0471, g_loss: 1.1141\n",
            "Step [70380/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0192, d_svhn_loss: 0.0438, d_fake_loss: 0.0614, g_loss: 1.1974\n",
            "Step [70390/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0196, d_svhn_loss: 0.0332, d_fake_loss: 0.0419, g_loss: 1.1915\n",
            "Step [70400/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0250, d_svhn_loss: 0.0223, d_fake_loss: 0.0257, g_loss: 1.1386\n",
            "Step [70410/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0351, d_svhn_loss: 0.0325, d_fake_loss: 0.0240, g_loss: 1.0808\n",
            "Step [70420/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0189, d_svhn_loss: 0.0317, d_fake_loss: 0.0256, g_loss: 1.1700\n",
            "Step [70430/80000], d_real_loss: 0.1238, d_mnist_loss: 0.0278, d_svhn_loss: 0.0960, d_fake_loss: 0.0546, g_loss: 1.0236\n",
            "Step [70440/80000], d_real_loss: 0.1379, d_mnist_loss: 0.1080, d_svhn_loss: 0.0299, d_fake_loss: 0.0336, g_loss: 1.2409\n",
            "Step [70450/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0290, d_svhn_loss: 0.0210, d_fake_loss: 0.0365, g_loss: 1.0618\n",
            "Step [70460/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0379, d_svhn_loss: 0.0217, d_fake_loss: 0.0578, g_loss: 1.1397\n",
            "Step [70470/80000], d_real_loss: 0.1060, d_mnist_loss: 0.0395, d_svhn_loss: 0.0665, d_fake_loss: 0.0621, g_loss: 0.9805\n",
            "Step [70480/80000], d_real_loss: 0.1069, d_mnist_loss: 0.0193, d_svhn_loss: 0.0876, d_fake_loss: 0.0828, g_loss: 1.2808\n",
            "Step [70490/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0217, d_svhn_loss: 0.0331, d_fake_loss: 0.0708, g_loss: 1.0826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.6728442311286926, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [70500/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0146, d_svhn_loss: 0.0307, d_fake_loss: 0.0558, g_loss: 1.2953\n",
            "saved ./samples_fashion/sample-70500-m-s.png\n",
            "saved ./samples_fashion/sample-70500-s-m.png\n",
            "Step [70510/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0120, d_svhn_loss: 0.0224, d_fake_loss: 0.0302, g_loss: 1.0977\n",
            "Step [70520/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0156, d_svhn_loss: 0.0228, d_fake_loss: 0.0194, g_loss: 1.1849\n",
            "Step [70530/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0281, d_svhn_loss: 0.0130, d_fake_loss: 0.0776, g_loss: 1.1482\n",
            "Step [70540/80000], d_real_loss: 0.0566, d_mnist_loss: 0.0351, d_svhn_loss: 0.0215, d_fake_loss: 0.0374, g_loss: 1.2409\n",
            "Step [70550/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0294, d_svhn_loss: 0.0179, d_fake_loss: 0.0385, g_loss: 1.2069\n",
            "Step [70560/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0379, d_svhn_loss: 0.0089, d_fake_loss: 0.0370, g_loss: 1.2213\n",
            "Step [70570/80000], d_real_loss: 0.0993, d_mnist_loss: 0.0801, d_svhn_loss: 0.0192, d_fake_loss: 0.0629, g_loss: 1.5009\n",
            "Step [70580/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0188, d_svhn_loss: 0.0368, d_fake_loss: 0.0340, g_loss: 1.0155\n",
            "Step [70590/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0167, d_svhn_loss: 0.0208, d_fake_loss: 0.0386, g_loss: 1.2196\n",
            "Step [70600/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0286, d_svhn_loss: 0.0287, d_fake_loss: 0.0782, g_loss: 1.1646\n",
            "Step [70610/80000], d_real_loss: 0.1018, d_mnist_loss: 0.0160, d_svhn_loss: 0.0858, d_fake_loss: 0.0450, g_loss: 1.2483\n",
            "Step [70620/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0449, d_svhn_loss: 0.0356, d_fake_loss: 0.1773, g_loss: 0.8543\n",
            "Step [70630/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0245, d_svhn_loss: 0.0238, d_fake_loss: 0.0951, g_loss: 0.8468\n",
            "Step [70640/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0206, d_svhn_loss: 0.0238, d_fake_loss: 0.0803, g_loss: 1.3372\n",
            "Step [70650/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0172, d_svhn_loss: 0.0291, d_fake_loss: 0.0219, g_loss: 1.1372\n",
            "Step [70660/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0154, d_svhn_loss: 0.0247, d_fake_loss: 0.0418, g_loss: 1.0604\n",
            "Step [70670/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0308, d_svhn_loss: 0.0280, d_fake_loss: 0.0313, g_loss: 1.1163\n",
            "Step [70680/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0210, d_svhn_loss: 0.0317, d_fake_loss: 0.0541, g_loss: 1.2064\n",
            "Step [70690/80000], d_real_loss: 0.0766, d_mnist_loss: 0.0129, d_svhn_loss: 0.0637, d_fake_loss: 0.0626, g_loss: 1.0659\n",
            "Step [70700/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0207, d_svhn_loss: 0.0149, d_fake_loss: 0.0510, g_loss: 1.1161\n",
            "Step [70710/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0174, d_svhn_loss: 0.0504, d_fake_loss: 0.0287, g_loss: 1.0769\n",
            "Step [70720/80000], d_real_loss: 0.0754, d_mnist_loss: 0.0200, d_svhn_loss: 0.0554, d_fake_loss: 0.0302, g_loss: 1.2016\n",
            "Step [70730/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0218, d_svhn_loss: 0.0175, d_fake_loss: 0.0294, g_loss: 1.0690\n",
            "Step [70740/80000], d_real_loss: 0.0793, d_mnist_loss: 0.0138, d_svhn_loss: 0.0655, d_fake_loss: 0.0420, g_loss: 1.2449\n",
            "Step [70750/80000], d_real_loss: 0.0853, d_mnist_loss: 0.0237, d_svhn_loss: 0.0617, d_fake_loss: 0.0246, g_loss: 1.2759\n",
            "Step [70760/80000], d_real_loss: 0.1076, d_mnist_loss: 0.0247, d_svhn_loss: 0.0829, d_fake_loss: 0.0415, g_loss: 1.0294\n",
            "Step [70770/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0449, d_svhn_loss: 0.0180, d_fake_loss: 0.0385, g_loss: 1.0497\n",
            "Step [70780/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0253, d_svhn_loss: 0.0234, d_fake_loss: 0.1046, g_loss: 1.2589\n",
            "Step [70790/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0346, d_svhn_loss: 0.0276, d_fake_loss: 0.0671, g_loss: 1.1453\n",
            "Step [70800/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0300, d_svhn_loss: 0.0250, d_fake_loss: 0.0722, g_loss: 1.2907\n",
            "Step [70810/80000], d_real_loss: 0.0900, d_mnist_loss: 0.0162, d_svhn_loss: 0.0738, d_fake_loss: 0.0927, g_loss: 1.0824\n",
            "Step [70820/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0204, d_svhn_loss: 0.0373, d_fake_loss: 0.0696, g_loss: 1.2020\n",
            "Step [70830/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0304, d_svhn_loss: 0.0282, d_fake_loss: 0.0687, g_loss: 1.1868\n",
            "Step [70840/80000], d_real_loss: 0.1022, d_mnist_loss: 0.0302, d_svhn_loss: 0.0721, d_fake_loss: 0.0829, g_loss: 1.0546\n",
            "Step [70850/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0434, d_svhn_loss: 0.0144, d_fake_loss: 0.1534, g_loss: 1.2649\n",
            "Step [70860/80000], d_real_loss: 0.0573, d_mnist_loss: 0.0204, d_svhn_loss: 0.0369, d_fake_loss: 0.0425, g_loss: 1.1549\n",
            "Step [70870/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0209, d_svhn_loss: 0.0442, d_fake_loss: 0.0529, g_loss: 1.2049\n",
            "Step [70880/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0503, d_svhn_loss: 0.0205, d_fake_loss: 0.0515, g_loss: 1.1713\n",
            "Step [70890/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0179, d_svhn_loss: 0.0150, d_fake_loss: 0.0333, g_loss: 1.0985\n",
            "Step [70900/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0391, d_svhn_loss: 0.0279, d_fake_loss: 0.0281, g_loss: 1.1249\n",
            "Step [70910/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0203, d_svhn_loss: 0.0241, d_fake_loss: 0.0632, g_loss: 1.2548\n",
            "Step [70920/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0128, d_svhn_loss: 0.0747, d_fake_loss: 0.1047, g_loss: 1.2646\n",
            "Step [70930/80000], d_real_loss: 0.0619, d_mnist_loss: 0.0231, d_svhn_loss: 0.0388, d_fake_loss: 0.0570, g_loss: 1.2912\n",
            "Step [70940/80000], d_real_loss: 0.0666, d_mnist_loss: 0.0287, d_svhn_loss: 0.0379, d_fake_loss: 0.0528, g_loss: 1.1912\n",
            "Step [70950/80000], d_real_loss: 0.0557, d_mnist_loss: 0.0256, d_svhn_loss: 0.0302, d_fake_loss: 0.0324, g_loss: 1.2676\n",
            "Step [70960/80000], d_real_loss: 0.0244, d_mnist_loss: 0.0115, d_svhn_loss: 0.0129, d_fake_loss: 0.0654, g_loss: 1.2118\n",
            "Step [70970/80000], d_real_loss: 0.0641, d_mnist_loss: 0.0440, d_svhn_loss: 0.0202, d_fake_loss: 0.0754, g_loss: 1.1164\n",
            "Step [70980/80000], d_real_loss: 0.0320, d_mnist_loss: 0.0158, d_svhn_loss: 0.0163, d_fake_loss: 0.0767, g_loss: 1.2016\n",
            "Step [70990/80000], d_real_loss: 0.0438, d_mnist_loss: 0.0207, d_svhn_loss: 0.0231, d_fake_loss: 0.0372, g_loss: 1.1169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.692408561706543, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [71000/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0241, d_svhn_loss: 0.0342, d_fake_loss: 0.0354, g_loss: 0.9809\n",
            "saved ./samples_fashion/sample-71000-m-s.png\n",
            "saved ./samples_fashion/sample-71000-s-m.png\n",
            "Step [71010/80000], d_real_loss: 0.0938, d_mnist_loss: 0.0489, d_svhn_loss: 0.0449, d_fake_loss: 0.0487, g_loss: 1.1624\n",
            "Step [71020/80000], d_real_loss: 0.0326, d_mnist_loss: 0.0189, d_svhn_loss: 0.0137, d_fake_loss: 0.0247, g_loss: 1.0850\n",
            "Step [71030/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0189, d_svhn_loss: 0.0166, d_fake_loss: 0.0419, g_loss: 1.1542\n",
            "Step [71040/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0237, d_svhn_loss: 0.0198, d_fake_loss: 0.0983, g_loss: 1.3227\n",
            "Step [71050/80000], d_real_loss: 0.1170, d_mnist_loss: 0.0858, d_svhn_loss: 0.0312, d_fake_loss: 0.0398, g_loss: 1.2183\n",
            "Step [71060/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0198, d_svhn_loss: 0.0290, d_fake_loss: 0.0324, g_loss: 1.1132\n",
            "Step [71070/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0197, d_svhn_loss: 0.0514, d_fake_loss: 0.0322, g_loss: 1.2194\n",
            "Step [71080/80000], d_real_loss: 0.0500, d_mnist_loss: 0.0244, d_svhn_loss: 0.0256, d_fake_loss: 0.1011, g_loss: 1.1515\n",
            "Step [71090/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0253, d_svhn_loss: 0.0152, d_fake_loss: 0.0739, g_loss: 1.3511\n",
            "Step [71100/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0199, d_svhn_loss: 0.0211, d_fake_loss: 0.0759, g_loss: 1.3424\n",
            "Step [71110/80000], d_real_loss: 0.0914, d_mnist_loss: 0.0292, d_svhn_loss: 0.0622, d_fake_loss: 0.0503, g_loss: 1.2921\n",
            "Step [71120/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0202, d_svhn_loss: 0.0211, d_fake_loss: 0.0318, g_loss: 0.9728\n",
            "Step [71130/80000], d_real_loss: 0.0428, d_mnist_loss: 0.0246, d_svhn_loss: 0.0183, d_fake_loss: 0.0265, g_loss: 1.2163\n",
            "Step [71140/80000], d_real_loss: 0.0389, d_mnist_loss: 0.0154, d_svhn_loss: 0.0235, d_fake_loss: 0.1285, g_loss: 1.2625\n",
            "Step [71150/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0220, d_svhn_loss: 0.0174, d_fake_loss: 0.0468, g_loss: 1.1651\n",
            "Step [71160/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0192, d_svhn_loss: 0.0248, d_fake_loss: 0.0233, g_loss: 1.1630\n",
            "Step [71170/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0221, d_svhn_loss: 0.0165, d_fake_loss: 0.0392, g_loss: 1.2142\n",
            "Step [71180/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0191, d_svhn_loss: 0.0256, d_fake_loss: 0.1080, g_loss: 1.1283\n",
            "Step [71190/80000], d_real_loss: 0.0445, d_mnist_loss: 0.0276, d_svhn_loss: 0.0169, d_fake_loss: 0.0302, g_loss: 1.1161\n",
            "Step [71200/80000], d_real_loss: 0.0368, d_mnist_loss: 0.0145, d_svhn_loss: 0.0223, d_fake_loss: 0.0990, g_loss: 1.1911\n",
            "Step [71210/80000], d_real_loss: 0.0562, d_mnist_loss: 0.0210, d_svhn_loss: 0.0352, d_fake_loss: 0.0454, g_loss: 1.0941\n",
            "Step [71220/80000], d_real_loss: 0.1091, d_mnist_loss: 0.0916, d_svhn_loss: 0.0175, d_fake_loss: 0.0643, g_loss: 1.2374\n",
            "Step [71230/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0180, d_svhn_loss: 0.0159, d_fake_loss: 0.0765, g_loss: 1.0831\n",
            "Step [71240/80000], d_real_loss: 0.1744, d_mnist_loss: 0.0732, d_svhn_loss: 0.1012, d_fake_loss: 0.1482, g_loss: 1.1360\n",
            "Step [71250/80000], d_real_loss: 0.0367, d_mnist_loss: 0.0199, d_svhn_loss: 0.0168, d_fake_loss: 0.0817, g_loss: 1.2180\n",
            "Step [71260/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0188, d_svhn_loss: 0.0500, d_fake_loss: 0.0316, g_loss: 1.0713\n",
            "Step [71270/80000], d_real_loss: 0.1393, d_mnist_loss: 0.0344, d_svhn_loss: 0.1049, d_fake_loss: 0.0508, g_loss: 1.0986\n",
            "Step [71280/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0142, d_svhn_loss: 0.0172, d_fake_loss: 0.0371, g_loss: 1.1955\n",
            "Step [71290/80000], d_real_loss: 0.0436, d_mnist_loss: 0.0201, d_svhn_loss: 0.0235, d_fake_loss: 0.0887, g_loss: 1.3108\n",
            "Step [71300/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0191, d_svhn_loss: 0.0223, d_fake_loss: 0.0468, g_loss: 1.0874\n",
            "Step [71310/80000], d_real_loss: 0.2054, d_mnist_loss: 0.0608, d_svhn_loss: 0.1446, d_fake_loss: 0.0625, g_loss: 1.0702\n",
            "Step [71320/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0569, d_svhn_loss: 0.0170, d_fake_loss: 0.0546, g_loss: 0.9664\n",
            "Step [71330/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0444, d_svhn_loss: 0.0179, d_fake_loss: 0.0640, g_loss: 1.1650\n",
            "Step [71340/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0108, d_svhn_loss: 0.0185, d_fake_loss: 0.0855, g_loss: 1.2479\n",
            "Step [71350/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0367, d_svhn_loss: 0.0294, d_fake_loss: 0.0803, g_loss: 1.3051\n",
            "Step [71360/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0301, d_svhn_loss: 0.0253, d_fake_loss: 0.0417, g_loss: 1.1282\n",
            "Step [71370/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0141, d_svhn_loss: 0.0203, d_fake_loss: 0.0205, g_loss: 1.1426\n",
            "Step [71380/80000], d_real_loss: 0.0474, d_mnist_loss: 0.0224, d_svhn_loss: 0.0250, d_fake_loss: 0.0376, g_loss: 1.0934\n",
            "Step [71390/80000], d_real_loss: 0.0787, d_mnist_loss: 0.0115, d_svhn_loss: 0.0672, d_fake_loss: 0.0660, g_loss: 1.2619\n",
            "Step [71400/80000], d_real_loss: 0.0938, d_mnist_loss: 0.0340, d_svhn_loss: 0.0598, d_fake_loss: 0.0375, g_loss: 1.1430\n",
            "Step [71410/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0170, d_svhn_loss: 0.0397, d_fake_loss: 0.1151, g_loss: 1.0166\n",
            "Step [71420/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0190, d_svhn_loss: 0.0197, d_fake_loss: 0.0317, g_loss: 1.0505\n",
            "Step [71430/80000], d_real_loss: 0.1865, d_mnist_loss: 0.0242, d_svhn_loss: 0.1622, d_fake_loss: 0.0240, g_loss: 1.1565\n",
            "Step [71440/80000], d_real_loss: 0.0838, d_mnist_loss: 0.0554, d_svhn_loss: 0.0285, d_fake_loss: 0.0293, g_loss: 1.3469\n",
            "Step [71450/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0298, d_svhn_loss: 0.0184, d_fake_loss: 0.0329, g_loss: 1.0658\n",
            "Step [71460/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0240, d_svhn_loss: 0.0212, d_fake_loss: 0.0313, g_loss: 1.0582\n",
            "Step [71470/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0200, d_svhn_loss: 0.0416, d_fake_loss: 0.0496, g_loss: 1.4062\n",
            "Step [71480/80000], d_real_loss: 0.0473, d_mnist_loss: 0.0271, d_svhn_loss: 0.0202, d_fake_loss: 0.0518, g_loss: 1.2260\n",
            "Step [71490/80000], d_real_loss: 0.0917, d_mnist_loss: 0.0197, d_svhn_loss: 0.0720, d_fake_loss: 0.0353, g_loss: 1.0999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7333582043647766, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [71500/80000], d_real_loss: 0.0335, d_mnist_loss: 0.0202, d_svhn_loss: 0.0133, d_fake_loss: 0.0447, g_loss: 1.2587\n",
            "saved ./samples_fashion/sample-71500-m-s.png\n",
            "saved ./samples_fashion/sample-71500-s-m.png\n",
            "Step [71510/80000], d_real_loss: 0.0682, d_mnist_loss: 0.0474, d_svhn_loss: 0.0208, d_fake_loss: 0.0693, g_loss: 1.0615\n",
            "Step [71520/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0210, d_svhn_loss: 0.0206, d_fake_loss: 0.0873, g_loss: 1.2411\n",
            "Step [71530/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0241, d_svhn_loss: 0.0341, d_fake_loss: 0.0302, g_loss: 1.1233\n",
            "Step [71540/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0226, d_svhn_loss: 0.0166, d_fake_loss: 0.0596, g_loss: 1.1155\n",
            "Step [71550/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0170, d_svhn_loss: 0.0162, d_fake_loss: 0.0547, g_loss: 1.1784\n",
            "Step [71560/80000], d_real_loss: 0.0937, d_mnist_loss: 0.0551, d_svhn_loss: 0.0386, d_fake_loss: 0.1030, g_loss: 0.8499\n",
            "Step [71570/80000], d_real_loss: 0.1849, d_mnist_loss: 0.1410, d_svhn_loss: 0.0439, d_fake_loss: 0.0643, g_loss: 1.2655\n",
            "Step [71580/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0160, d_svhn_loss: 0.0233, d_fake_loss: 0.0643, g_loss: 1.1173\n",
            "Step [71590/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0197, d_svhn_loss: 0.0171, d_fake_loss: 0.0844, g_loss: 1.1591\n",
            "Step [71600/80000], d_real_loss: 0.0837, d_mnist_loss: 0.0635, d_svhn_loss: 0.0202, d_fake_loss: 0.0294, g_loss: 0.9818\n",
            "Step [71610/80000], d_real_loss: 0.0821, d_mnist_loss: 0.0406, d_svhn_loss: 0.0415, d_fake_loss: 0.1164, g_loss: 1.1219\n",
            "Step [71620/80000], d_real_loss: 0.1641, d_mnist_loss: 0.0142, d_svhn_loss: 0.1499, d_fake_loss: 0.0853, g_loss: 1.0224\n",
            "Step [71630/80000], d_real_loss: 0.1222, d_mnist_loss: 0.0145, d_svhn_loss: 0.1076, d_fake_loss: 0.0556, g_loss: 1.1442\n",
            "Step [71640/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0477, d_svhn_loss: 0.0235, d_fake_loss: 0.0604, g_loss: 1.0197\n",
            "Step [71650/80000], d_real_loss: 0.1621, d_mnist_loss: 0.0320, d_svhn_loss: 0.1301, d_fake_loss: 0.0467, g_loss: 1.2091\n",
            "Step [71660/80000], d_real_loss: 0.0279, d_mnist_loss: 0.0130, d_svhn_loss: 0.0148, d_fake_loss: 0.0621, g_loss: 1.1129\n",
            "Step [71670/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0108, d_svhn_loss: 0.0248, d_fake_loss: 0.0384, g_loss: 1.1279\n",
            "Step [71680/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0280, d_svhn_loss: 0.0354, d_fake_loss: 0.0407, g_loss: 0.9904\n",
            "Step [71690/80000], d_real_loss: 0.0311, d_mnist_loss: 0.0128, d_svhn_loss: 0.0183, d_fake_loss: 0.0261, g_loss: 1.1700\n",
            "Step [71700/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0167, d_svhn_loss: 0.0136, d_fake_loss: 0.0676, g_loss: 1.2045\n",
            "Step [71710/80000], d_real_loss: 0.0815, d_mnist_loss: 0.0294, d_svhn_loss: 0.0521, d_fake_loss: 0.0472, g_loss: 1.1899\n",
            "Step [71720/80000], d_real_loss: 0.0265, d_mnist_loss: 0.0095, d_svhn_loss: 0.0169, d_fake_loss: 0.0339, g_loss: 1.1815\n",
            "Step [71730/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0099, d_svhn_loss: 0.0663, d_fake_loss: 0.0750, g_loss: 1.2148\n",
            "Step [71740/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0392, d_svhn_loss: 0.0247, d_fake_loss: 0.1128, g_loss: 1.0245\n",
            "Step [71750/80000], d_real_loss: 0.1273, d_mnist_loss: 0.0428, d_svhn_loss: 0.0844, d_fake_loss: 0.0339, g_loss: 1.0217\n",
            "Step [71760/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0102, d_svhn_loss: 0.0178, d_fake_loss: 0.0379, g_loss: 1.0230\n",
            "Step [71770/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0168, d_svhn_loss: 0.0188, d_fake_loss: 0.0413, g_loss: 1.0608\n",
            "Step [71780/80000], d_real_loss: 0.1172, d_mnist_loss: 0.0164, d_svhn_loss: 0.1008, d_fake_loss: 0.0520, g_loss: 1.1220\n",
            "Step [71790/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0310, d_svhn_loss: 0.0273, d_fake_loss: 0.0425, g_loss: 1.1291\n",
            "Step [71800/80000], d_real_loss: 0.0306, d_mnist_loss: 0.0175, d_svhn_loss: 0.0131, d_fake_loss: 0.0228, g_loss: 1.2398\n",
            "Step [71810/80000], d_real_loss: 0.0742, d_mnist_loss: 0.0416, d_svhn_loss: 0.0327, d_fake_loss: 0.0518, g_loss: 1.0705\n",
            "Step [71820/80000], d_real_loss: 0.1324, d_mnist_loss: 0.0768, d_svhn_loss: 0.0557, d_fake_loss: 0.0317, g_loss: 1.0026\n",
            "Step [71830/80000], d_real_loss: 0.0533, d_mnist_loss: 0.0313, d_svhn_loss: 0.0220, d_fake_loss: 0.0403, g_loss: 1.0310\n",
            "Step [71840/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0181, d_svhn_loss: 0.0176, d_fake_loss: 0.0193, g_loss: 1.2503\n",
            "Step [71850/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0113, d_svhn_loss: 0.0487, d_fake_loss: 0.0598, g_loss: 1.1233\n",
            "Step [71860/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0105, d_svhn_loss: 0.0510, d_fake_loss: 0.0541, g_loss: 1.2999\n",
            "Step [71870/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0167, d_svhn_loss: 0.0189, d_fake_loss: 0.0200, g_loss: 1.1803\n",
            "Step [71880/80000], d_real_loss: 0.0356, d_mnist_loss: 0.0176, d_svhn_loss: 0.0180, d_fake_loss: 0.0335, g_loss: 1.1181\n",
            "Step [71890/80000], d_real_loss: 0.1346, d_mnist_loss: 0.0250, d_svhn_loss: 0.1096, d_fake_loss: 0.1566, g_loss: 0.9836\n",
            "Step [71900/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0189, d_svhn_loss: 0.0254, d_fake_loss: 0.0289, g_loss: 1.0776\n",
            "Step [71910/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0431, d_svhn_loss: 0.0266, d_fake_loss: 0.0439, g_loss: 1.0513\n",
            "Step [71920/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0458, d_svhn_loss: 0.0150, d_fake_loss: 0.0270, g_loss: 1.0403\n",
            "Step [71930/80000], d_real_loss: 0.1061, d_mnist_loss: 0.0698, d_svhn_loss: 0.0363, d_fake_loss: 0.0289, g_loss: 1.0765\n",
            "Step [71940/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0170, d_svhn_loss: 0.0286, d_fake_loss: 0.0534, g_loss: 1.1447\n",
            "Step [71950/80000], d_real_loss: 0.0697, d_mnist_loss: 0.0211, d_svhn_loss: 0.0486, d_fake_loss: 0.0437, g_loss: 1.1703\n",
            "Step [71960/80000], d_real_loss: 0.1050, d_mnist_loss: 0.0781, d_svhn_loss: 0.0270, d_fake_loss: 0.0809, g_loss: 1.2537\n",
            "Step [71970/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0176, d_svhn_loss: 0.0293, d_fake_loss: 0.0537, g_loss: 1.1197\n",
            "Step [71980/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0310, d_svhn_loss: 0.0144, d_fake_loss: 0.0331, g_loss: 1.1483\n",
            "Step [71990/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0178, d_svhn_loss: 0.0538, d_fake_loss: 0.0259, g_loss: 1.2271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.8044660091400146, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [72000/80000], d_real_loss: 0.0305, d_mnist_loss: 0.0148, d_svhn_loss: 0.0157, d_fake_loss: 0.0366, g_loss: 1.1593\n",
            "saved ./samples_fashion/sample-72000-m-s.png\n",
            "saved ./samples_fashion/sample-72000-s-m.png\n",
            "Step [72010/80000], d_real_loss: 0.1165, d_mnist_loss: 0.0957, d_svhn_loss: 0.0208, d_fake_loss: 0.0510, g_loss: 0.9961\n",
            "Step [72020/80000], d_real_loss: 0.0384, d_mnist_loss: 0.0245, d_svhn_loss: 0.0139, d_fake_loss: 0.0552, g_loss: 0.9828\n",
            "Step [72030/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0119, d_svhn_loss: 0.0256, d_fake_loss: 0.0527, g_loss: 1.1776\n",
            "Step [72040/80000], d_real_loss: 0.1454, d_mnist_loss: 0.0682, d_svhn_loss: 0.0772, d_fake_loss: 0.0536, g_loss: 1.1032\n",
            "Step [72050/80000], d_real_loss: 0.0358, d_mnist_loss: 0.0170, d_svhn_loss: 0.0188, d_fake_loss: 0.0468, g_loss: 0.9859\n",
            "Step [72060/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0106, d_svhn_loss: 0.0419, d_fake_loss: 0.0405, g_loss: 1.1194\n",
            "Step [72070/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0136, d_svhn_loss: 0.0280, d_fake_loss: 0.0647, g_loss: 1.1467\n",
            "Step [72080/80000], d_real_loss: 0.0890, d_mnist_loss: 0.0417, d_svhn_loss: 0.0473, d_fake_loss: 0.0417, g_loss: 1.0685\n",
            "Step [72090/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0129, d_svhn_loss: 0.0359, d_fake_loss: 0.0954, g_loss: 1.3734\n",
            "Step [72100/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0339, d_svhn_loss: 0.0285, d_fake_loss: 0.0274, g_loss: 1.1271\n",
            "Step [72110/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0377, d_svhn_loss: 0.0307, d_fake_loss: 0.0599, g_loss: 1.1732\n",
            "Step [72120/80000], d_real_loss: 0.0301, d_mnist_loss: 0.0151, d_svhn_loss: 0.0150, d_fake_loss: 0.0943, g_loss: 1.2488\n",
            "Step [72130/80000], d_real_loss: 0.0764, d_mnist_loss: 0.0419, d_svhn_loss: 0.0344, d_fake_loss: 0.1206, g_loss: 1.3373\n",
            "Step [72140/80000], d_real_loss: 0.0669, d_mnist_loss: 0.0154, d_svhn_loss: 0.0515, d_fake_loss: 0.0721, g_loss: 1.1648\n",
            "Step [72150/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0281, d_svhn_loss: 0.0208, d_fake_loss: 0.0391, g_loss: 1.0639\n",
            "Step [72160/80000], d_real_loss: 0.0580, d_mnist_loss: 0.0352, d_svhn_loss: 0.0228, d_fake_loss: 0.0452, g_loss: 1.3042\n",
            "Step [72170/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0141, d_svhn_loss: 0.0365, d_fake_loss: 0.0433, g_loss: 1.1158\n",
            "Step [72180/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0151, d_svhn_loss: 0.0507, d_fake_loss: 0.0409, g_loss: 1.1337\n",
            "Step [72190/80000], d_real_loss: 0.0480, d_mnist_loss: 0.0356, d_svhn_loss: 0.0124, d_fake_loss: 0.0623, g_loss: 1.1238\n",
            "Step [72200/80000], d_real_loss: 0.0481, d_mnist_loss: 0.0244, d_svhn_loss: 0.0237, d_fake_loss: 0.0478, g_loss: 1.2006\n",
            "Step [72210/80000], d_real_loss: 0.0806, d_mnist_loss: 0.0632, d_svhn_loss: 0.0174, d_fake_loss: 0.0432, g_loss: 1.0795\n",
            "Step [72220/80000], d_real_loss: 0.0859, d_mnist_loss: 0.0511, d_svhn_loss: 0.0348, d_fake_loss: 0.0275, g_loss: 1.0351\n",
            "Step [72230/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0165, d_svhn_loss: 0.0254, d_fake_loss: 0.0884, g_loss: 1.1144\n",
            "Step [72240/80000], d_real_loss: 0.0505, d_mnist_loss: 0.0348, d_svhn_loss: 0.0157, d_fake_loss: 0.0526, g_loss: 1.2251\n",
            "Step [72250/80000], d_real_loss: 0.0241, d_mnist_loss: 0.0130, d_svhn_loss: 0.0111, d_fake_loss: 0.0873, g_loss: 1.1755\n",
            "Step [72260/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0209, d_svhn_loss: 0.0099, d_fake_loss: 0.0220, g_loss: 1.1874\n",
            "Step [72270/80000], d_real_loss: 0.0283, d_mnist_loss: 0.0122, d_svhn_loss: 0.0160, d_fake_loss: 0.0598, g_loss: 1.1692\n",
            "Step [72280/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0271, d_svhn_loss: 0.0266, d_fake_loss: 0.0836, g_loss: 0.9939\n",
            "Step [72290/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0146, d_svhn_loss: 0.0182, d_fake_loss: 0.0198, g_loss: 1.0434\n",
            "Step [72300/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0168, d_svhn_loss: 0.0516, d_fake_loss: 0.0575, g_loss: 0.8519\n",
            "Step [72310/80000], d_real_loss: 0.0675, d_mnist_loss: 0.0201, d_svhn_loss: 0.0474, d_fake_loss: 0.0966, g_loss: 1.2644\n",
            "Step [72320/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0136, d_svhn_loss: 0.0240, d_fake_loss: 0.1225, g_loss: 1.1720\n",
            "Step [72330/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0129, d_svhn_loss: 0.0267, d_fake_loss: 0.0181, g_loss: 1.1122\n",
            "Step [72340/80000], d_real_loss: 0.0758, d_mnist_loss: 0.0223, d_svhn_loss: 0.0535, d_fake_loss: 0.0433, g_loss: 1.1392\n",
            "Step [72350/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0291, d_svhn_loss: 0.0538, d_fake_loss: 0.0918, g_loss: 1.2076\n",
            "Step [72360/80000], d_real_loss: 0.0598, d_mnist_loss: 0.0413, d_svhn_loss: 0.0184, d_fake_loss: 0.0340, g_loss: 1.1292\n",
            "Step [72370/80000], d_real_loss: 0.0472, d_mnist_loss: 0.0300, d_svhn_loss: 0.0172, d_fake_loss: 0.0608, g_loss: 1.1166\n",
            "Step [72380/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0248, d_svhn_loss: 0.0231, d_fake_loss: 0.0317, g_loss: 1.1733\n",
            "Step [72390/80000], d_real_loss: 0.0337, d_mnist_loss: 0.0202, d_svhn_loss: 0.0135, d_fake_loss: 0.0273, g_loss: 1.1754\n",
            "Step [72400/80000], d_real_loss: 0.1021, d_mnist_loss: 0.0611, d_svhn_loss: 0.0409, d_fake_loss: 0.0780, g_loss: 1.3476\n",
            "Step [72410/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0139, d_svhn_loss: 0.0347, d_fake_loss: 0.0588, g_loss: 0.9771\n",
            "Step [72420/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0122, d_svhn_loss: 0.0232, d_fake_loss: 0.0387, g_loss: 1.1621\n",
            "Step [72430/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0298, d_svhn_loss: 0.0364, d_fake_loss: 0.0343, g_loss: 1.0535\n",
            "Step [72440/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0364, d_svhn_loss: 0.0278, d_fake_loss: 0.0903, g_loss: 1.1838\n",
            "Step [72450/80000], d_real_loss: 0.0318, d_mnist_loss: 0.0128, d_svhn_loss: 0.0191, d_fake_loss: 0.0305, g_loss: 1.1033\n",
            "Step [72460/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0180, d_svhn_loss: 0.0310, d_fake_loss: 0.0303, g_loss: 1.1378\n",
            "Step [72470/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0124, d_svhn_loss: 0.0212, d_fake_loss: 0.0718, g_loss: 1.1735\n",
            "Step [72480/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0164, d_svhn_loss: 0.0154, d_fake_loss: 0.0715, g_loss: 1.2224\n",
            "Step [72490/80000], d_real_loss: 0.0853, d_mnist_loss: 0.0219, d_svhn_loss: 0.0634, d_fake_loss: 0.0681, g_loss: 1.1622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7606183290481567, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [72500/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0377, d_svhn_loss: 0.0169, d_fake_loss: 0.0833, g_loss: 1.2274\n",
            "saved ./samples_fashion/sample-72500-m-s.png\n",
            "saved ./samples_fashion/sample-72500-s-m.png\n",
            "Step [72510/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0334, d_svhn_loss: 0.0325, d_fake_loss: 0.0701, g_loss: 1.2055\n",
            "Step [72520/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0160, d_svhn_loss: 0.0458, d_fake_loss: 0.0402, g_loss: 1.1465\n",
            "Step [72530/80000], d_real_loss: 0.1098, d_mnist_loss: 0.0385, d_svhn_loss: 0.0713, d_fake_loss: 0.1180, g_loss: 1.3561\n",
            "Step [72540/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0395, d_svhn_loss: 0.0239, d_fake_loss: 0.0859, g_loss: 1.3542\n",
            "Step [72550/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0152, d_svhn_loss: 0.0516, d_fake_loss: 0.0491, g_loss: 1.0346\n",
            "Step [72560/80000], d_real_loss: 0.1882, d_mnist_loss: 0.1513, d_svhn_loss: 0.0368, d_fake_loss: 0.0884, g_loss: 1.4797\n",
            "Step [72570/80000], d_real_loss: 0.0634, d_mnist_loss: 0.0282, d_svhn_loss: 0.0353, d_fake_loss: 0.0311, g_loss: 1.1571\n",
            "Step [72580/80000], d_real_loss: 0.0923, d_mnist_loss: 0.0707, d_svhn_loss: 0.0216, d_fake_loss: 0.0475, g_loss: 1.1300\n",
            "Step [72590/80000], d_real_loss: 0.1208, d_mnist_loss: 0.0857, d_svhn_loss: 0.0350, d_fake_loss: 0.1248, g_loss: 1.2657\n",
            "Step [72600/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0353, d_svhn_loss: 0.0206, d_fake_loss: 0.0272, g_loss: 1.2270\n",
            "Step [72610/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0277, d_svhn_loss: 0.0283, d_fake_loss: 0.1318, g_loss: 1.1713\n",
            "Step [72620/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0170, d_svhn_loss: 0.0368, d_fake_loss: 0.0459, g_loss: 1.2510\n",
            "Step [72630/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0136, d_svhn_loss: 0.0228, d_fake_loss: 0.1737, g_loss: 1.2318\n",
            "Step [72640/80000], d_real_loss: 0.0402, d_mnist_loss: 0.0180, d_svhn_loss: 0.0222, d_fake_loss: 0.0548, g_loss: 1.1475\n",
            "Step [72650/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0226, d_svhn_loss: 0.0408, d_fake_loss: 0.0321, g_loss: 1.1253\n",
            "Step [72660/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0198, d_svhn_loss: 0.0213, d_fake_loss: 0.0319, g_loss: 1.1701\n",
            "Step [72670/80000], d_real_loss: 0.0809, d_mnist_loss: 0.0376, d_svhn_loss: 0.0434, d_fake_loss: 0.0885, g_loss: 1.1974\n",
            "Step [72680/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0178, d_svhn_loss: 0.0310, d_fake_loss: 0.0714, g_loss: 1.2613\n",
            "Step [72690/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0144, d_svhn_loss: 0.0463, d_fake_loss: 0.0584, g_loss: 1.0960\n",
            "Step [72700/80000], d_real_loss: 0.0988, d_mnist_loss: 0.0104, d_svhn_loss: 0.0885, d_fake_loss: 0.0738, g_loss: 1.3222\n",
            "Step [72710/80000], d_real_loss: 0.1029, d_mnist_loss: 0.0252, d_svhn_loss: 0.0777, d_fake_loss: 0.0414, g_loss: 1.1908\n",
            "Step [72720/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0453, d_svhn_loss: 0.0184, d_fake_loss: 0.0253, g_loss: 1.0609\n",
            "Step [72730/80000], d_real_loss: 0.0469, d_mnist_loss: 0.0300, d_svhn_loss: 0.0170, d_fake_loss: 0.0314, g_loss: 1.1044\n",
            "Step [72740/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0175, d_svhn_loss: 0.0188, d_fake_loss: 0.0243, g_loss: 1.2469\n",
            "Step [72750/80000], d_real_loss: 0.1100, d_mnist_loss: 0.0605, d_svhn_loss: 0.0495, d_fake_loss: 0.0472, g_loss: 1.0643\n",
            "Step [72760/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0211, d_svhn_loss: 0.0205, d_fake_loss: 0.1011, g_loss: 1.0610\n",
            "Step [72770/80000], d_real_loss: 0.0643, d_mnist_loss: 0.0405, d_svhn_loss: 0.0238, d_fake_loss: 0.1068, g_loss: 1.2017\n",
            "Step [72780/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0187, d_svhn_loss: 0.0291, d_fake_loss: 0.0483, g_loss: 1.0404\n",
            "Step [72790/80000], d_real_loss: 0.0520, d_mnist_loss: 0.0222, d_svhn_loss: 0.0297, d_fake_loss: 0.0293, g_loss: 1.1952\n",
            "Step [72800/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0151, d_svhn_loss: 0.0474, d_fake_loss: 0.0458, g_loss: 1.1380\n",
            "Step [72810/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0141, d_svhn_loss: 0.0174, d_fake_loss: 0.0361, g_loss: 1.2014\n",
            "Step [72820/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0122, d_svhn_loss: 0.0173, d_fake_loss: 0.0278, g_loss: 1.1830\n",
            "Step [72830/80000], d_real_loss: 0.0494, d_mnist_loss: 0.0182, d_svhn_loss: 0.0312, d_fake_loss: 0.0990, g_loss: 1.2206\n",
            "Step [72840/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0158, d_svhn_loss: 0.0189, d_fake_loss: 0.0431, g_loss: 1.1126\n",
            "Step [72850/80000], d_real_loss: 0.1080, d_mnist_loss: 0.0887, d_svhn_loss: 0.0192, d_fake_loss: 0.0296, g_loss: 1.0848\n",
            "Step [72860/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0199, d_svhn_loss: 0.0223, d_fake_loss: 0.0252, g_loss: 1.0369\n",
            "Step [72870/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0306, d_svhn_loss: 0.0103, d_fake_loss: 0.0583, g_loss: 1.0730\n",
            "Step [72880/80000], d_real_loss: 0.2605, d_mnist_loss: 0.1487, d_svhn_loss: 0.1118, d_fake_loss: 0.1994, g_loss: 1.2093\n",
            "Step [72890/80000], d_real_loss: 0.0632, d_mnist_loss: 0.0533, d_svhn_loss: 0.0099, d_fake_loss: 0.0712, g_loss: 1.2345\n",
            "Step [72900/80000], d_real_loss: 0.0576, d_mnist_loss: 0.0336, d_svhn_loss: 0.0240, d_fake_loss: 0.0252, g_loss: 1.1401\n",
            "Step [72910/80000], d_real_loss: 0.0804, d_mnist_loss: 0.0563, d_svhn_loss: 0.0241, d_fake_loss: 0.0366, g_loss: 1.1385\n",
            "Step [72920/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0218, d_svhn_loss: 0.0122, d_fake_loss: 0.0720, g_loss: 1.1553\n",
            "Step [72930/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0174, d_svhn_loss: 0.0168, d_fake_loss: 0.0900, g_loss: 1.3292\n",
            "Step [72940/80000], d_real_loss: 0.0549, d_mnist_loss: 0.0353, d_svhn_loss: 0.0197, d_fake_loss: 0.0232, g_loss: 1.1455\n",
            "Step [72950/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0205, d_svhn_loss: 0.0271, d_fake_loss: 0.0660, g_loss: 1.1147\n",
            "Step [72960/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0579, d_svhn_loss: 0.0150, d_fake_loss: 0.0607, g_loss: 1.1203\n",
            "Step [72970/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0152, d_svhn_loss: 0.0269, d_fake_loss: 0.0276, g_loss: 1.1089\n",
            "Step [72980/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0184, d_svhn_loss: 0.0158, d_fake_loss: 0.0763, g_loss: 1.1728\n",
            "Step [72990/80000], d_real_loss: 0.0717, d_mnist_loss: 0.0492, d_svhn_loss: 0.0225, d_fake_loss: 0.0253, g_loss: 1.0975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7530568838119507, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [73000/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0177, d_svhn_loss: 0.0239, d_fake_loss: 0.0462, g_loss: 1.1935\n",
            "saved ./samples_fashion/sample-73000-m-s.png\n",
            "saved ./samples_fashion/sample-73000-s-m.png\n",
            "Step [73010/80000], d_real_loss: 0.0490, d_mnist_loss: 0.0152, d_svhn_loss: 0.0338, d_fake_loss: 0.0253, g_loss: 1.0254\n",
            "Step [73020/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0471, d_svhn_loss: 0.0163, d_fake_loss: 0.0243, g_loss: 1.0683\n",
            "Step [73030/80000], d_real_loss: 0.0446, d_mnist_loss: 0.0153, d_svhn_loss: 0.0294, d_fake_loss: 0.0601, g_loss: 1.1652\n",
            "Step [73040/80000], d_real_loss: 0.0789, d_mnist_loss: 0.0546, d_svhn_loss: 0.0243, d_fake_loss: 0.0610, g_loss: 1.1344\n",
            "Step [73050/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0199, d_svhn_loss: 0.0257, d_fake_loss: 0.0510, g_loss: 1.1664\n",
            "Step [73060/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0217, d_svhn_loss: 0.0153, d_fake_loss: 0.0633, g_loss: 1.1627\n",
            "Step [73070/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0181, d_svhn_loss: 0.0435, d_fake_loss: 0.0608, g_loss: 1.1659\n",
            "Step [73080/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0479, d_svhn_loss: 0.0164, d_fake_loss: 0.1155, g_loss: 1.2509\n",
            "Step [73090/80000], d_real_loss: 0.0939, d_mnist_loss: 0.0163, d_svhn_loss: 0.0776, d_fake_loss: 0.1039, g_loss: 1.4361\n",
            "Step [73100/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0352, d_svhn_loss: 0.0369, d_fake_loss: 0.0422, g_loss: 1.1982\n",
            "Step [73110/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0182, d_svhn_loss: 0.0198, d_fake_loss: 0.0395, g_loss: 1.1872\n",
            "Step [73120/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0535, d_svhn_loss: 0.0298, d_fake_loss: 0.0357, g_loss: 1.1481\n",
            "Step [73130/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0200, d_svhn_loss: 0.0222, d_fake_loss: 0.0429, g_loss: 1.1673\n",
            "Step [73140/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0271, d_svhn_loss: 0.0185, d_fake_loss: 0.0468, g_loss: 1.1297\n",
            "Step [73150/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0129, d_svhn_loss: 0.0201, d_fake_loss: 0.0539, g_loss: 1.1629\n",
            "Step [73160/80000], d_real_loss: 0.0816, d_mnist_loss: 0.0550, d_svhn_loss: 0.0266, d_fake_loss: 0.0599, g_loss: 1.2125\n",
            "Step [73170/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0610, d_svhn_loss: 0.0210, d_fake_loss: 0.0355, g_loss: 1.1141\n",
            "Step [73180/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0205, d_svhn_loss: 0.0145, d_fake_loss: 0.0760, g_loss: 1.3410\n",
            "Step [73190/80000], d_real_loss: 0.1517, d_mnist_loss: 0.0338, d_svhn_loss: 0.1180, d_fake_loss: 0.0326, g_loss: 1.0625\n",
            "Step [73200/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0156, d_svhn_loss: 0.0143, d_fake_loss: 0.0304, g_loss: 1.1057\n",
            "Step [73210/80000], d_real_loss: 0.1111, d_mnist_loss: 0.0940, d_svhn_loss: 0.0171, d_fake_loss: 0.0330, g_loss: 1.1399\n",
            "Step [73220/80000], d_real_loss: 0.0931, d_mnist_loss: 0.0697, d_svhn_loss: 0.0234, d_fake_loss: 0.0651, g_loss: 1.1886\n",
            "Step [73230/80000], d_real_loss: 0.0843, d_mnist_loss: 0.0271, d_svhn_loss: 0.0573, d_fake_loss: 0.0258, g_loss: 1.2746\n",
            "Step [73240/80000], d_real_loss: 0.0700, d_mnist_loss: 0.0107, d_svhn_loss: 0.0594, d_fake_loss: 0.0691, g_loss: 1.3304\n",
            "Step [73250/80000], d_real_loss: 0.2687, d_mnist_loss: 0.0748, d_svhn_loss: 0.1939, d_fake_loss: 0.0531, g_loss: 1.1605\n",
            "Step [73260/80000], d_real_loss: 0.1030, d_mnist_loss: 0.0205, d_svhn_loss: 0.0826, d_fake_loss: 0.0464, g_loss: 1.1106\n",
            "Step [73270/80000], d_real_loss: 0.2065, d_mnist_loss: 0.1349, d_svhn_loss: 0.0716, d_fake_loss: 0.0727, g_loss: 1.1625\n",
            "Step [73280/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0350, d_svhn_loss: 0.0138, d_fake_loss: 0.0220, g_loss: 1.0988\n",
            "Step [73290/80000], d_real_loss: 0.0608, d_mnist_loss: 0.0429, d_svhn_loss: 0.0179, d_fake_loss: 0.1073, g_loss: 1.1167\n",
            "Step [73300/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0158, d_svhn_loss: 0.0255, d_fake_loss: 0.0378, g_loss: 1.1470\n",
            "Step [73310/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0126, d_svhn_loss: 0.0199, d_fake_loss: 0.0590, g_loss: 1.1158\n",
            "Step [73320/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0229, d_svhn_loss: 0.0571, d_fake_loss: 0.0279, g_loss: 1.1564\n",
            "Step [73330/80000], d_real_loss: 0.0468, d_mnist_loss: 0.0209, d_svhn_loss: 0.0259, d_fake_loss: 0.0339, g_loss: 1.1109\n",
            "Step [73340/80000], d_real_loss: 0.0630, d_mnist_loss: 0.0115, d_svhn_loss: 0.0515, d_fake_loss: 0.0279, g_loss: 1.0964\n",
            "Step [73350/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0140, d_svhn_loss: 0.0380, d_fake_loss: 0.0501, g_loss: 1.0296\n",
            "Step [73360/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0148, d_svhn_loss: 0.0292, d_fake_loss: 0.0647, g_loss: 1.2807\n",
            "Step [73370/80000], d_real_loss: 0.0222, d_mnist_loss: 0.0096, d_svhn_loss: 0.0125, d_fake_loss: 0.0564, g_loss: 1.2540\n",
            "Step [73380/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0382, d_svhn_loss: 0.0160, d_fake_loss: 0.1077, g_loss: 1.2895\n",
            "Step [73390/80000], d_real_loss: 0.0763, d_mnist_loss: 0.0444, d_svhn_loss: 0.0319, d_fake_loss: 0.0413, g_loss: 1.2340\n",
            "Step [73400/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0212, d_svhn_loss: 0.0245, d_fake_loss: 0.0442, g_loss: 1.1986\n",
            "Step [73410/80000], d_real_loss: 0.0970, d_mnist_loss: 0.0145, d_svhn_loss: 0.0825, d_fake_loss: 0.0755, g_loss: 1.1526\n",
            "Step [73420/80000], d_real_loss: 0.0973, d_mnist_loss: 0.0665, d_svhn_loss: 0.0307, d_fake_loss: 0.0585, g_loss: 1.1802\n",
            "Step [73430/80000], d_real_loss: 0.0408, d_mnist_loss: 0.0164, d_svhn_loss: 0.0244, d_fake_loss: 0.0358, g_loss: 1.1088\n",
            "Step [73440/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0238, d_svhn_loss: 0.0238, d_fake_loss: 0.0537, g_loss: 1.1491\n",
            "Step [73450/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0158, d_svhn_loss: 0.0235, d_fake_loss: 0.0530, g_loss: 1.2127\n",
            "Step [73460/80000], d_real_loss: 0.1066, d_mnist_loss: 0.0812, d_svhn_loss: 0.0254, d_fake_loss: 0.0604, g_loss: 1.0744\n",
            "Step [73470/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0299, d_svhn_loss: 0.0107, d_fake_loss: 0.0756, g_loss: 1.1672\n",
            "Step [73480/80000], d_real_loss: 0.0535, d_mnist_loss: 0.0324, d_svhn_loss: 0.0212, d_fake_loss: 0.1440, g_loss: 1.2412\n",
            "Step [73490/80000], d_real_loss: 0.0776, d_mnist_loss: 0.0220, d_svhn_loss: 0.0556, d_fake_loss: 0.0442, g_loss: 1.1697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7805906534194946, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [73500/80000], d_real_loss: 0.0571, d_mnist_loss: 0.0210, d_svhn_loss: 0.0361, d_fake_loss: 0.0430, g_loss: 1.0976\n",
            "saved ./samples_fashion/sample-73500-m-s.png\n",
            "saved ./samples_fashion/sample-73500-s-m.png\n",
            "Step [73510/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0204, d_svhn_loss: 0.0215, d_fake_loss: 0.0600, g_loss: 1.2370\n",
            "Step [73520/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0142, d_svhn_loss: 0.0381, d_fake_loss: 0.0477, g_loss: 1.0443\n",
            "Step [73530/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0153, d_svhn_loss: 0.0205, d_fake_loss: 0.0307, g_loss: 1.1861\n",
            "Step [73540/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0175, d_svhn_loss: 0.0218, d_fake_loss: 0.0361, g_loss: 1.0376\n",
            "Step [73550/80000], d_real_loss: 0.1201, d_mnist_loss: 0.0999, d_svhn_loss: 0.0202, d_fake_loss: 0.0512, g_loss: 1.0584\n",
            "Step [73560/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0184, d_svhn_loss: 0.0383, d_fake_loss: 0.0654, g_loss: 1.1879\n",
            "Step [73570/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0257, d_svhn_loss: 0.0205, d_fake_loss: 0.0630, g_loss: 1.1093\n",
            "Step [73580/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0128, d_svhn_loss: 0.0165, d_fake_loss: 0.0849, g_loss: 1.2214\n",
            "Step [73590/80000], d_real_loss: 0.0300, d_mnist_loss: 0.0179, d_svhn_loss: 0.0122, d_fake_loss: 0.0922, g_loss: 1.0946\n",
            "Step [73600/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0422, d_svhn_loss: 0.0187, d_fake_loss: 0.1174, g_loss: 1.2979\n",
            "Step [73610/80000], d_real_loss: 0.0774, d_mnist_loss: 0.0383, d_svhn_loss: 0.0391, d_fake_loss: 0.1160, g_loss: 0.8674\n",
            "Step [73620/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0169, d_svhn_loss: 0.0225, d_fake_loss: 0.0389, g_loss: 1.0921\n",
            "Step [73630/80000], d_real_loss: 0.0712, d_mnist_loss: 0.0182, d_svhn_loss: 0.0529, d_fake_loss: 0.0643, g_loss: 1.1701\n",
            "Step [73640/80000], d_real_loss: 0.1181, d_mnist_loss: 0.0797, d_svhn_loss: 0.0383, d_fake_loss: 0.0334, g_loss: 1.2184\n",
            "Step [73650/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0125, d_svhn_loss: 0.0216, d_fake_loss: 0.0314, g_loss: 1.1556\n",
            "Step [73660/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0232, d_svhn_loss: 0.0187, d_fake_loss: 0.0289, g_loss: 1.1779\n",
            "Step [73670/80000], d_real_loss: 0.0718, d_mnist_loss: 0.0321, d_svhn_loss: 0.0396, d_fake_loss: 0.0810, g_loss: 1.1444\n",
            "Step [73680/80000], d_real_loss: 0.1102, d_mnist_loss: 0.0455, d_svhn_loss: 0.0646, d_fake_loss: 0.0495, g_loss: 1.0127\n",
            "Step [73690/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0483, d_svhn_loss: 0.0345, d_fake_loss: 0.0595, g_loss: 1.0826\n",
            "Step [73700/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0163, d_svhn_loss: 0.0272, d_fake_loss: 0.0685, g_loss: 1.1006\n",
            "Step [73710/80000], d_real_loss: 0.1325, d_mnist_loss: 0.0466, d_svhn_loss: 0.0859, d_fake_loss: 0.0264, g_loss: 0.9818\n",
            "Step [73720/80000], d_real_loss: 0.0678, d_mnist_loss: 0.0339, d_svhn_loss: 0.0339, d_fake_loss: 0.0989, g_loss: 1.1533\n",
            "Step [73730/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0159, d_svhn_loss: 0.0197, d_fake_loss: 0.0295, g_loss: 1.1248\n",
            "Step [73740/80000], d_real_loss: 0.0953, d_mnist_loss: 0.0654, d_svhn_loss: 0.0299, d_fake_loss: 0.0544, g_loss: 1.2094\n",
            "Step [73750/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0232, d_svhn_loss: 0.0415, d_fake_loss: 0.0663, g_loss: 1.3131\n",
            "Step [73760/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0205, d_svhn_loss: 0.0164, d_fake_loss: 0.0306, g_loss: 1.1834\n",
            "Step [73770/80000], d_real_loss: 0.0610, d_mnist_loss: 0.0190, d_svhn_loss: 0.0420, d_fake_loss: 0.0743, g_loss: 1.2065\n",
            "Step [73780/80000], d_real_loss: 0.0379, d_mnist_loss: 0.0203, d_svhn_loss: 0.0176, d_fake_loss: 0.0579, g_loss: 1.2582\n",
            "Step [73790/80000], d_real_loss: 0.0376, d_mnist_loss: 0.0136, d_svhn_loss: 0.0240, d_fake_loss: 0.0628, g_loss: 1.1999\n",
            "Step [73800/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0238, d_svhn_loss: 0.0402, d_fake_loss: 0.0677, g_loss: 1.1189\n",
            "Step [73810/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0190, d_svhn_loss: 0.0242, d_fake_loss: 0.0412, g_loss: 1.2117\n",
            "Step [73820/80000], d_real_loss: 0.0679, d_mnist_loss: 0.0160, d_svhn_loss: 0.0520, d_fake_loss: 0.0640, g_loss: 1.1516\n",
            "Step [73830/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0160, d_svhn_loss: 0.0200, d_fake_loss: 0.0420, g_loss: 1.1633\n",
            "Step [73840/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0133, d_svhn_loss: 0.0189, d_fake_loss: 0.0232, g_loss: 1.2030\n",
            "Step [73850/80000], d_real_loss: 0.0471, d_mnist_loss: 0.0294, d_svhn_loss: 0.0177, d_fake_loss: 0.0345, g_loss: 0.9579\n",
            "Step [73860/80000], d_real_loss: 0.0542, d_mnist_loss: 0.0182, d_svhn_loss: 0.0360, d_fake_loss: 0.0651, g_loss: 1.0025\n",
            "Step [73870/80000], d_real_loss: 0.1249, d_mnist_loss: 0.0402, d_svhn_loss: 0.0847, d_fake_loss: 0.0561, g_loss: 1.0834\n",
            "Step [73880/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0126, d_svhn_loss: 0.0253, d_fake_loss: 0.0935, g_loss: 1.1894\n",
            "Step [73890/80000], d_real_loss: 0.1275, d_mnist_loss: 0.0910, d_svhn_loss: 0.0365, d_fake_loss: 0.0365, g_loss: 1.0740\n",
            "Step [73900/80000], d_real_loss: 0.0395, d_mnist_loss: 0.0229, d_svhn_loss: 0.0166, d_fake_loss: 0.0285, g_loss: 1.1643\n",
            "Step [73910/80000], d_real_loss: 0.0424, d_mnist_loss: 0.0267, d_svhn_loss: 0.0157, d_fake_loss: 0.0272, g_loss: 1.0776\n",
            "Step [73920/80000], d_real_loss: 0.0336, d_mnist_loss: 0.0207, d_svhn_loss: 0.0129, d_fake_loss: 0.0556, g_loss: 1.1462\n",
            "Step [73930/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0147, d_svhn_loss: 0.0171, d_fake_loss: 0.0312, g_loss: 1.0692\n",
            "Step [73940/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0179, d_svhn_loss: 0.0185, d_fake_loss: 0.0483, g_loss: 1.1658\n",
            "Step [73950/80000], d_real_loss: 0.0274, d_mnist_loss: 0.0134, d_svhn_loss: 0.0140, d_fake_loss: 0.0258, g_loss: 1.1824\n",
            "Step [73960/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0408, d_svhn_loss: 0.0117, d_fake_loss: 0.0330, g_loss: 0.9312\n",
            "Step [73970/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0257, d_svhn_loss: 0.0234, d_fake_loss: 0.0363, g_loss: 1.0973\n",
            "Step [73980/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0207, d_svhn_loss: 0.0153, d_fake_loss: 0.0608, g_loss: 1.1680\n",
            "Step [73990/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0150, d_svhn_loss: 0.0453, d_fake_loss: 0.0296, g_loss: 1.0586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7247403860092163, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [74000/80000], d_real_loss: 0.0459, d_mnist_loss: 0.0157, d_svhn_loss: 0.0302, d_fake_loss: 0.0676, g_loss: 1.4111\n",
            "saved ./samples_fashion/sample-74000-m-s.png\n",
            "saved ./samples_fashion/sample-74000-s-m.png\n",
            "Step [74010/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0210, d_svhn_loss: 0.0315, d_fake_loss: 0.0420, g_loss: 1.1237\n",
            "Step [74020/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0303, d_svhn_loss: 0.0160, d_fake_loss: 0.0321, g_loss: 1.1602\n",
            "Step [74030/80000], d_real_loss: 0.0594, d_mnist_loss: 0.0175, d_svhn_loss: 0.0419, d_fake_loss: 0.0525, g_loss: 1.1071\n",
            "Step [74040/80000], d_real_loss: 0.0927, d_mnist_loss: 0.0164, d_svhn_loss: 0.0763, d_fake_loss: 0.0826, g_loss: 1.3134\n",
            "Step [74050/80000], d_real_loss: 0.0796, d_mnist_loss: 0.0475, d_svhn_loss: 0.0321, d_fake_loss: 0.0640, g_loss: 1.1217\n",
            "Step [74060/80000], d_real_loss: 0.0603, d_mnist_loss: 0.0229, d_svhn_loss: 0.0373, d_fake_loss: 0.0280, g_loss: 1.2106\n",
            "Step [74070/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0202, d_svhn_loss: 0.0198, d_fake_loss: 0.0859, g_loss: 1.2690\n",
            "Step [74080/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0211, d_svhn_loss: 0.0169, d_fake_loss: 0.0492, g_loss: 1.1475\n",
            "Step [74090/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0152, d_svhn_loss: 0.0226, d_fake_loss: 0.0306, g_loss: 1.1580\n",
            "Step [74100/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0243, d_svhn_loss: 0.0307, d_fake_loss: 0.0503, g_loss: 1.1478\n",
            "Step [74110/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0128, d_svhn_loss: 0.0229, d_fake_loss: 0.0615, g_loss: 1.1833\n",
            "Step [74120/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0200, d_svhn_loss: 0.0548, d_fake_loss: 0.0291, g_loss: 1.1517\n",
            "Step [74130/80000], d_real_loss: 0.0339, d_mnist_loss: 0.0171, d_svhn_loss: 0.0168, d_fake_loss: 0.0334, g_loss: 1.1988\n",
            "Step [74140/80000], d_real_loss: 0.0849, d_mnist_loss: 0.0585, d_svhn_loss: 0.0263, d_fake_loss: 0.0225, g_loss: 1.0074\n",
            "Step [74150/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0215, d_svhn_loss: 0.0605, d_fake_loss: 0.0320, g_loss: 1.1973\n",
            "Step [74160/80000], d_real_loss: 0.1000, d_mnist_loss: 0.0756, d_svhn_loss: 0.0244, d_fake_loss: 0.0311, g_loss: 1.1215\n",
            "Step [74170/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0268, d_svhn_loss: 0.0304, d_fake_loss: 0.0477, g_loss: 1.0903\n",
            "Step [74180/80000], d_real_loss: 0.1023, d_mnist_loss: 0.0847, d_svhn_loss: 0.0176, d_fake_loss: 0.0309, g_loss: 1.1557\n",
            "Step [74190/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0242, d_svhn_loss: 0.0233, d_fake_loss: 0.0515, g_loss: 1.2438\n",
            "Step [74200/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0146, d_svhn_loss: 0.0214, d_fake_loss: 0.0577, g_loss: 1.4309\n",
            "Step [74210/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0172, d_svhn_loss: 0.0157, d_fake_loss: 0.0884, g_loss: 1.0386\n",
            "Step [74220/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0227, d_svhn_loss: 0.0212, d_fake_loss: 0.0545, g_loss: 1.2741\n",
            "Step [74230/80000], d_real_loss: 0.0731, d_mnist_loss: 0.0209, d_svhn_loss: 0.0523, d_fake_loss: 0.0791, g_loss: 1.0695\n",
            "Step [74240/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0196, d_svhn_loss: 0.0215, d_fake_loss: 0.0373, g_loss: 1.1389\n",
            "Step [74250/80000], d_real_loss: 0.0357, d_mnist_loss: 0.0118, d_svhn_loss: 0.0239, d_fake_loss: 0.0422, g_loss: 1.2422\n",
            "Step [74260/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0432, d_svhn_loss: 0.0167, d_fake_loss: 0.0437, g_loss: 1.1884\n",
            "Step [74270/80000], d_real_loss: 0.1192, d_mnist_loss: 0.1002, d_svhn_loss: 0.0190, d_fake_loss: 0.0579, g_loss: 1.0406\n",
            "Step [74280/80000], d_real_loss: 0.0280, d_mnist_loss: 0.0173, d_svhn_loss: 0.0107, d_fake_loss: 0.0614, g_loss: 1.1389\n",
            "Step [74290/80000], d_real_loss: 0.0515, d_mnist_loss: 0.0352, d_svhn_loss: 0.0163, d_fake_loss: 0.0541, g_loss: 1.1975\n",
            "Step [74300/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0346, d_svhn_loss: 0.0374, d_fake_loss: 0.0303, g_loss: 1.1709\n",
            "Step [74310/80000], d_real_loss: 0.0361, d_mnist_loss: 0.0133, d_svhn_loss: 0.0229, d_fake_loss: 0.0692, g_loss: 1.0875\n",
            "Step [74320/80000], d_real_loss: 0.0419, d_mnist_loss: 0.0193, d_svhn_loss: 0.0225, d_fake_loss: 0.0780, g_loss: 1.2467\n",
            "Step [74330/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0200, d_svhn_loss: 0.0145, d_fake_loss: 0.0279, g_loss: 0.9900\n",
            "Step [74340/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0715, d_svhn_loss: 0.0136, d_fake_loss: 0.0402, g_loss: 1.1140\n",
            "Step [74350/80000], d_real_loss: 0.0570, d_mnist_loss: 0.0225, d_svhn_loss: 0.0345, d_fake_loss: 0.0825, g_loss: 1.1179\n",
            "Step [74360/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0302, d_svhn_loss: 0.0196, d_fake_loss: 0.0450, g_loss: 1.1146\n",
            "Step [74370/80000], d_real_loss: 0.0574, d_mnist_loss: 0.0173, d_svhn_loss: 0.0401, d_fake_loss: 0.0770, g_loss: 1.2075\n",
            "Step [74380/80000], d_real_loss: 0.1177, d_mnist_loss: 0.0321, d_svhn_loss: 0.0856, d_fake_loss: 0.0381, g_loss: 1.0855\n",
            "Step [74390/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0217, d_svhn_loss: 0.0226, d_fake_loss: 0.0595, g_loss: 1.2022\n",
            "Step [74400/80000], d_real_loss: 0.1031, d_mnist_loss: 0.0711, d_svhn_loss: 0.0319, d_fake_loss: 0.0437, g_loss: 1.1164\n",
            "Step [74410/80000], d_real_loss: 0.0531, d_mnist_loss: 0.0296, d_svhn_loss: 0.0235, d_fake_loss: 0.0833, g_loss: 1.1748\n",
            "Step [74420/80000], d_real_loss: 0.1641, d_mnist_loss: 0.1289, d_svhn_loss: 0.0352, d_fake_loss: 0.0447, g_loss: 1.1587\n",
            "Step [74430/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0175, d_svhn_loss: 0.0207, d_fake_loss: 0.1251, g_loss: 1.4924\n",
            "Step [74440/80000], d_real_loss: 0.0707, d_mnist_loss: 0.0447, d_svhn_loss: 0.0261, d_fake_loss: 0.0769, g_loss: 1.1115\n",
            "Step [74450/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0226, d_svhn_loss: 0.0151, d_fake_loss: 0.0460, g_loss: 1.1457\n",
            "Step [74460/80000], d_real_loss: 0.0314, d_mnist_loss: 0.0117, d_svhn_loss: 0.0198, d_fake_loss: 0.0205, g_loss: 1.0655\n",
            "Step [74470/80000], d_real_loss: 0.0640, d_mnist_loss: 0.0177, d_svhn_loss: 0.0464, d_fake_loss: 0.0443, g_loss: 1.0508\n",
            "Step [74480/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0189, d_svhn_loss: 0.0286, d_fake_loss: 0.0332, g_loss: 1.0946\n",
            "Step [74490/80000], d_real_loss: 0.0325, d_mnist_loss: 0.0184, d_svhn_loss: 0.0141, d_fake_loss: 0.0244, g_loss: 1.0855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7411165237426758, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [74500/80000], d_real_loss: 0.0748, d_mnist_loss: 0.0510, d_svhn_loss: 0.0237, d_fake_loss: 0.0887, g_loss: 1.0997\n",
            "saved ./samples_fashion/sample-74500-m-s.png\n",
            "saved ./samples_fashion/sample-74500-s-m.png\n",
            "Step [74510/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0164, d_svhn_loss: 0.0220, d_fake_loss: 0.0317, g_loss: 1.0768\n",
            "Step [74520/80000], d_real_loss: 0.0807, d_mnist_loss: 0.0634, d_svhn_loss: 0.0173, d_fake_loss: 0.0513, g_loss: 0.9513\n",
            "Step [74530/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0135, d_svhn_loss: 0.0230, d_fake_loss: 0.0276, g_loss: 1.1420\n",
            "Step [74540/80000], d_real_loss: 0.1881, d_mnist_loss: 0.0728, d_svhn_loss: 0.1152, d_fake_loss: 0.1540, g_loss: 1.0607\n",
            "Step [74550/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0319, d_svhn_loss: 0.0296, d_fake_loss: 0.0336, g_loss: 1.0148\n",
            "Step [74560/80000], d_real_loss: 0.0360, d_mnist_loss: 0.0130, d_svhn_loss: 0.0230, d_fake_loss: 0.0403, g_loss: 1.1132\n",
            "Step [74570/80000], d_real_loss: 0.0660, d_mnist_loss: 0.0500, d_svhn_loss: 0.0160, d_fake_loss: 0.0981, g_loss: 1.0048\n",
            "Step [74580/80000], d_real_loss: 0.1112, d_mnist_loss: 0.0314, d_svhn_loss: 0.0798, d_fake_loss: 0.0767, g_loss: 1.0546\n",
            "Step [74590/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0127, d_svhn_loss: 0.0250, d_fake_loss: 0.0770, g_loss: 1.1682\n",
            "Step [74600/80000], d_real_loss: 0.1207, d_mnist_loss: 0.0604, d_svhn_loss: 0.0603, d_fake_loss: 0.0998, g_loss: 1.3730\n",
            "Step [74610/80000], d_real_loss: 0.0282, d_mnist_loss: 0.0121, d_svhn_loss: 0.0161, d_fake_loss: 0.1105, g_loss: 1.1467\n",
            "Step [74620/80000], d_real_loss: 0.1039, d_mnist_loss: 0.0453, d_svhn_loss: 0.0586, d_fake_loss: 0.0297, g_loss: 1.0827\n",
            "Step [74630/80000], d_real_loss: 0.0338, d_mnist_loss: 0.0118, d_svhn_loss: 0.0221, d_fake_loss: 0.0713, g_loss: 1.1421\n",
            "Step [74640/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0127, d_svhn_loss: 0.0284, d_fake_loss: 0.0926, g_loss: 1.2994\n",
            "Step [74650/80000], d_real_loss: 0.0845, d_mnist_loss: 0.0281, d_svhn_loss: 0.0563, d_fake_loss: 0.0807, g_loss: 1.0957\n",
            "Step [74660/80000], d_real_loss: 0.0491, d_mnist_loss: 0.0256, d_svhn_loss: 0.0235, d_fake_loss: 0.0356, g_loss: 1.1438\n",
            "Step [74670/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0324, d_svhn_loss: 0.0198, d_fake_loss: 0.0605, g_loss: 1.1025\n",
            "Step [74680/80000], d_real_loss: 0.0910, d_mnist_loss: 0.0242, d_svhn_loss: 0.0669, d_fake_loss: 0.0538, g_loss: 1.0443\n",
            "Step [74690/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0258, d_svhn_loss: 0.0510, d_fake_loss: 0.0377, g_loss: 1.2252\n",
            "Step [74700/80000], d_real_loss: 0.0404, d_mnist_loss: 0.0193, d_svhn_loss: 0.0211, d_fake_loss: 0.0910, g_loss: 1.2509\n",
            "Step [74710/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0167, d_svhn_loss: 0.0287, d_fake_loss: 0.0372, g_loss: 1.1231\n",
            "Step [74720/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0356, d_svhn_loss: 0.0364, d_fake_loss: 0.0481, g_loss: 1.0929\n",
            "Step [74730/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0255, d_svhn_loss: 0.0254, d_fake_loss: 0.0601, g_loss: 1.2008\n",
            "Step [74740/80000], d_real_loss: 0.1050, d_mnist_loss: 0.0368, d_svhn_loss: 0.0682, d_fake_loss: 0.0780, g_loss: 1.1376\n",
            "Step [74750/80000], d_real_loss: 0.0911, d_mnist_loss: 0.0475, d_svhn_loss: 0.0436, d_fake_loss: 0.0512, g_loss: 1.1303\n",
            "Step [74760/80000], d_real_loss: 0.0656, d_mnist_loss: 0.0445, d_svhn_loss: 0.0211, d_fake_loss: 0.0502, g_loss: 1.2276\n",
            "Step [74770/80000], d_real_loss: 0.0359, d_mnist_loss: 0.0150, d_svhn_loss: 0.0210, d_fake_loss: 0.0366, g_loss: 1.1348\n",
            "Step [74780/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0298, d_svhn_loss: 0.0225, d_fake_loss: 0.0257, g_loss: 1.0499\n",
            "Step [74790/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0119, d_svhn_loss: 0.0255, d_fake_loss: 0.0478, g_loss: 1.1729\n",
            "Step [74800/80000], d_real_loss: 0.0567, d_mnist_loss: 0.0207, d_svhn_loss: 0.0360, d_fake_loss: 0.0240, g_loss: 1.1347\n",
            "Step [74810/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0156, d_svhn_loss: 0.0245, d_fake_loss: 0.0275, g_loss: 1.1418\n",
            "Step [74820/80000], d_real_loss: 0.0846, d_mnist_loss: 0.0148, d_svhn_loss: 0.0698, d_fake_loss: 0.0699, g_loss: 1.1534\n",
            "Step [74830/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0193, d_svhn_loss: 0.0324, d_fake_loss: 0.0349, g_loss: 1.1459\n",
            "Step [74840/80000], d_real_loss: 0.1162, d_mnist_loss: 0.0782, d_svhn_loss: 0.0379, d_fake_loss: 0.0732, g_loss: 1.1513\n",
            "Step [74850/80000], d_real_loss: 0.0561, d_mnist_loss: 0.0332, d_svhn_loss: 0.0228, d_fake_loss: 0.0442, g_loss: 1.2572\n",
            "Step [74860/80000], d_real_loss: 0.0836, d_mnist_loss: 0.0496, d_svhn_loss: 0.0340, d_fake_loss: 0.0486, g_loss: 1.1284\n",
            "Step [74870/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0297, d_svhn_loss: 0.0330, d_fake_loss: 0.0500, g_loss: 1.1140\n",
            "Step [74880/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0479, d_svhn_loss: 0.0229, d_fake_loss: 0.0612, g_loss: 0.8320\n",
            "Step [74890/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0384, d_svhn_loss: 0.0164, d_fake_loss: 0.0464, g_loss: 0.9787\n",
            "Step [74900/80000], d_real_loss: 0.0724, d_mnist_loss: 0.0261, d_svhn_loss: 0.0463, d_fake_loss: 0.0804, g_loss: 0.9885\n",
            "Step [74910/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0342, d_svhn_loss: 0.0222, d_fake_loss: 0.0294, g_loss: 1.0857\n",
            "Step [74920/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0130, d_svhn_loss: 0.0180, d_fake_loss: 0.0581, g_loss: 1.1051\n",
            "Step [74930/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0379, d_svhn_loss: 0.0283, d_fake_loss: 0.0385, g_loss: 1.0047\n",
            "Step [74940/80000], d_real_loss: 0.1894, d_mnist_loss: 0.1544, d_svhn_loss: 0.0350, d_fake_loss: 0.0346, g_loss: 0.8891\n",
            "Step [74950/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0381, d_svhn_loss: 0.0147, d_fake_loss: 0.0207, g_loss: 1.0228\n",
            "Step [74960/80000], d_real_loss: 0.0725, d_mnist_loss: 0.0545, d_svhn_loss: 0.0180, d_fake_loss: 0.1194, g_loss: 1.0624\n",
            "Step [74970/80000], d_real_loss: 0.0992, d_mnist_loss: 0.0185, d_svhn_loss: 0.0807, d_fake_loss: 0.0664, g_loss: 1.1431\n",
            "Step [74980/80000], d_real_loss: 0.0639, d_mnist_loss: 0.0214, d_svhn_loss: 0.0425, d_fake_loss: 0.0675, g_loss: 1.1847\n",
            "Step [74990/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0130, d_svhn_loss: 0.0247, d_fake_loss: 0.0326, g_loss: 1.1236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7577044367790222, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [75000/80000], d_real_loss: 0.0416, d_mnist_loss: 0.0254, d_svhn_loss: 0.0162, d_fake_loss: 0.0402, g_loss: 1.0213\n",
            "saved ./samples_fashion/sample-75000-m-s.png\n",
            "saved ./samples_fashion/sample-75000-s-m.png\n",
            "Step [75010/80000], d_real_loss: 0.0920, d_mnist_loss: 0.0725, d_svhn_loss: 0.0195, d_fake_loss: 0.0308, g_loss: 1.0491\n",
            "Step [75020/80000], d_real_loss: 0.0553, d_mnist_loss: 0.0255, d_svhn_loss: 0.0298, d_fake_loss: 0.0348, g_loss: 1.2739\n",
            "Step [75030/80000], d_real_loss: 0.0955, d_mnist_loss: 0.0532, d_svhn_loss: 0.0423, d_fake_loss: 0.0432, g_loss: 1.1425\n",
            "Step [75040/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0358, d_svhn_loss: 0.0201, d_fake_loss: 0.0319, g_loss: 1.0228\n",
            "Step [75050/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0207, d_svhn_loss: 0.0176, d_fake_loss: 0.0712, g_loss: 1.3316\n",
            "Step [75060/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0346, d_svhn_loss: 0.0213, d_fake_loss: 0.0212, g_loss: 1.1221\n",
            "Step [75070/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0106, d_svhn_loss: 0.0671, d_fake_loss: 0.0476, g_loss: 1.1475\n",
            "Step [75080/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0284, d_svhn_loss: 0.0219, d_fake_loss: 0.0551, g_loss: 1.2122\n",
            "Step [75090/80000], d_real_loss: 0.0536, d_mnist_loss: 0.0363, d_svhn_loss: 0.0173, d_fake_loss: 0.1427, g_loss: 1.1346\n",
            "Step [75100/80000], d_real_loss: 0.0903, d_mnist_loss: 0.0616, d_svhn_loss: 0.0287, d_fake_loss: 0.0411, g_loss: 0.9972\n",
            "Step [75110/80000], d_real_loss: 0.0293, d_mnist_loss: 0.0143, d_svhn_loss: 0.0150, d_fake_loss: 0.0391, g_loss: 1.0242\n",
            "Step [75120/80000], d_real_loss: 0.0422, d_mnist_loss: 0.0234, d_svhn_loss: 0.0188, d_fake_loss: 0.1085, g_loss: 1.1528\n",
            "Step [75130/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0166, d_svhn_loss: 0.0332, d_fake_loss: 0.0407, g_loss: 1.1639\n",
            "Step [75140/80000], d_real_loss: 0.0769, d_mnist_loss: 0.0437, d_svhn_loss: 0.0332, d_fake_loss: 0.0712, g_loss: 1.0630\n",
            "Step [75150/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0191, d_svhn_loss: 0.0191, d_fake_loss: 0.0632, g_loss: 1.1508\n",
            "Step [75160/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0146, d_svhn_loss: 0.0183, d_fake_loss: 0.0381, g_loss: 1.1341\n",
            "Step [75170/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0482, d_svhn_loss: 0.0175, d_fake_loss: 0.0883, g_loss: 1.1029\n",
            "Step [75180/80000], d_real_loss: 0.0602, d_mnist_loss: 0.0171, d_svhn_loss: 0.0431, d_fake_loss: 0.0302, g_loss: 1.1176\n",
            "Step [75190/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0185, d_svhn_loss: 0.0189, d_fake_loss: 0.0412, g_loss: 1.1941\n",
            "Step [75200/80000], d_real_loss: 0.0527, d_mnist_loss: 0.0356, d_svhn_loss: 0.0171, d_fake_loss: 0.0301, g_loss: 1.0247\n",
            "Step [75210/80000], d_real_loss: 0.0761, d_mnist_loss: 0.0661, d_svhn_loss: 0.0100, d_fake_loss: 0.0573, g_loss: 1.0121\n",
            "Step [75220/80000], d_real_loss: 0.0256, d_mnist_loss: 0.0133, d_svhn_loss: 0.0123, d_fake_loss: 0.1067, g_loss: 1.2658\n",
            "Step [75230/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0175, d_svhn_loss: 0.0231, d_fake_loss: 0.0463, g_loss: 1.2324\n",
            "Step [75240/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0248, d_svhn_loss: 0.0253, d_fake_loss: 0.0661, g_loss: 1.1512\n",
            "Step [75250/80000], d_real_loss: 0.0858, d_mnist_loss: 0.0651, d_svhn_loss: 0.0207, d_fake_loss: 0.0502, g_loss: 1.0249\n",
            "Step [75260/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0208, d_svhn_loss: 0.0219, d_fake_loss: 0.0362, g_loss: 1.0676\n",
            "Step [75270/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0220, d_svhn_loss: 0.0197, d_fake_loss: 0.0285, g_loss: 1.0864\n",
            "Step [75280/80000], d_real_loss: 0.0463, d_mnist_loss: 0.0309, d_svhn_loss: 0.0154, d_fake_loss: 0.0472, g_loss: 1.3218\n",
            "Step [75290/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0253, d_svhn_loss: 0.0119, d_fake_loss: 0.0714, g_loss: 1.3979\n",
            "Step [75300/80000], d_real_loss: 0.0590, d_mnist_loss: 0.0121, d_svhn_loss: 0.0468, d_fake_loss: 0.1105, g_loss: 1.0999\n",
            "Step [75310/80000], d_real_loss: 0.0317, d_mnist_loss: 0.0175, d_svhn_loss: 0.0142, d_fake_loss: 0.0539, g_loss: 1.1685\n",
            "Step [75320/80000], d_real_loss: 0.0433, d_mnist_loss: 0.0268, d_svhn_loss: 0.0165, d_fake_loss: 0.0337, g_loss: 1.1108\n",
            "Step [75330/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0191, d_svhn_loss: 0.0197, d_fake_loss: 0.0612, g_loss: 1.1789\n",
            "Step [75340/80000], d_real_loss: 0.1009, d_mnist_loss: 0.0474, d_svhn_loss: 0.0535, d_fake_loss: 0.0560, g_loss: 1.0307\n",
            "Step [75350/80000], d_real_loss: 0.0295, d_mnist_loss: 0.0149, d_svhn_loss: 0.0146, d_fake_loss: 0.0263, g_loss: 1.1110\n",
            "Step [75360/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0194, d_svhn_loss: 0.0325, d_fake_loss: 0.0544, g_loss: 1.2175\n",
            "Step [75370/80000], d_real_loss: 0.0813, d_mnist_loss: 0.0204, d_svhn_loss: 0.0609, d_fake_loss: 0.0431, g_loss: 1.1214\n",
            "Step [75380/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0428, d_svhn_loss: 0.0188, d_fake_loss: 0.0371, g_loss: 1.1512\n",
            "Step [75390/80000], d_real_loss: 0.1148, d_mnist_loss: 0.0285, d_svhn_loss: 0.0863, d_fake_loss: 0.0318, g_loss: 1.2379\n",
            "Step [75400/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0177, d_svhn_loss: 0.0386, d_fake_loss: 0.0334, g_loss: 1.1626\n",
            "Step [75410/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0323, d_svhn_loss: 0.0363, d_fake_loss: 0.0522, g_loss: 1.3212\n",
            "Step [75420/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0233, d_svhn_loss: 0.0285, d_fake_loss: 0.0976, g_loss: 1.2846\n",
            "Step [75430/80000], d_real_loss: 0.0556, d_mnist_loss: 0.0273, d_svhn_loss: 0.0283, d_fake_loss: 0.0466, g_loss: 1.1183\n",
            "Step [75440/80000], d_real_loss: 0.1159, d_mnist_loss: 0.0828, d_svhn_loss: 0.0331, d_fake_loss: 0.1414, g_loss: 1.0510\n",
            "Step [75450/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0179, d_svhn_loss: 0.0152, d_fake_loss: 0.0407, g_loss: 1.0454\n",
            "Step [75460/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0237, d_svhn_loss: 0.0204, d_fake_loss: 0.0335, g_loss: 1.1566\n",
            "Step [75470/80000], d_real_loss: 0.0680, d_mnist_loss: 0.0434, d_svhn_loss: 0.0246, d_fake_loss: 0.0742, g_loss: 1.3139\n",
            "Step [75480/80000], d_real_loss: 0.0636, d_mnist_loss: 0.0265, d_svhn_loss: 0.0371, d_fake_loss: 0.0332, g_loss: 1.1048\n",
            "Step [75490/80000], d_real_loss: 0.0790, d_mnist_loss: 0.0259, d_svhn_loss: 0.0531, d_fake_loss: 0.0254, g_loss: 1.0594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7063824534416199, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [75500/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0179, d_svhn_loss: 0.0341, d_fake_loss: 0.1196, g_loss: 1.1873\n",
            "saved ./samples_fashion/sample-75500-m-s.png\n",
            "saved ./samples_fashion/sample-75500-s-m.png\n",
            "Step [75510/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0179, d_svhn_loss: 0.0184, d_fake_loss: 0.0252, g_loss: 1.1537\n",
            "Step [75520/80000], d_real_loss: 0.0887, d_mnist_loss: 0.0697, d_svhn_loss: 0.0190, d_fake_loss: 0.0431, g_loss: 1.1881\n",
            "Step [75530/80000], d_real_loss: 0.0405, d_mnist_loss: 0.0182, d_svhn_loss: 0.0224, d_fake_loss: 0.0776, g_loss: 1.4087\n",
            "Step [75540/80000], d_real_loss: 0.1575, d_mnist_loss: 0.0576, d_svhn_loss: 0.0998, d_fake_loss: 0.0472, g_loss: 1.1167\n",
            "Step [75550/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0214, d_svhn_loss: 0.0209, d_fake_loss: 0.0310, g_loss: 1.0595\n",
            "Step [75560/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0216, d_svhn_loss: 0.0184, d_fake_loss: 0.0376, g_loss: 1.1603\n",
            "Step [75570/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0261, d_svhn_loss: 0.0224, d_fake_loss: 0.0539, g_loss: 1.2215\n",
            "Step [75580/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0141, d_svhn_loss: 0.0188, d_fake_loss: 0.0614, g_loss: 1.2219\n",
            "Step [75590/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0208, d_svhn_loss: 0.0172, d_fake_loss: 0.0460, g_loss: 1.0955\n",
            "Step [75600/80000], d_real_loss: 0.1833, d_mnist_loss: 0.0577, d_svhn_loss: 0.1256, d_fake_loss: 0.1771, g_loss: 1.4597\n",
            "Step [75610/80000], d_real_loss: 0.0607, d_mnist_loss: 0.0168, d_svhn_loss: 0.0439, d_fake_loss: 0.0458, g_loss: 1.3351\n",
            "Step [75620/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0295, d_svhn_loss: 0.0206, d_fake_loss: 0.0274, g_loss: 1.1618\n",
            "Step [75630/80000], d_real_loss: 0.0903, d_mnist_loss: 0.0551, d_svhn_loss: 0.0352, d_fake_loss: 0.0431, g_loss: 1.2666\n",
            "Step [75640/80000], d_real_loss: 0.1394, d_mnist_loss: 0.1197, d_svhn_loss: 0.0197, d_fake_loss: 0.0700, g_loss: 1.3219\n",
            "Step [75650/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0233, d_svhn_loss: 0.0276, d_fake_loss: 0.0531, g_loss: 1.1670\n",
            "Step [75660/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0317, d_svhn_loss: 0.0255, d_fake_loss: 0.1060, g_loss: 1.3092\n",
            "Step [75670/80000], d_real_loss: 0.0850, d_mnist_loss: 0.0291, d_svhn_loss: 0.0560, d_fake_loss: 0.0511, g_loss: 0.9361\n",
            "Step [75680/80000], d_real_loss: 0.0620, d_mnist_loss: 0.0184, d_svhn_loss: 0.0436, d_fake_loss: 0.0327, g_loss: 1.2337\n",
            "Step [75690/80000], d_real_loss: 0.0782, d_mnist_loss: 0.0131, d_svhn_loss: 0.0651, d_fake_loss: 0.0432, g_loss: 1.1399\n",
            "Step [75700/80000], d_real_loss: 0.1261, d_mnist_loss: 0.1015, d_svhn_loss: 0.0246, d_fake_loss: 0.0657, g_loss: 1.2043\n",
            "Step [75710/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0164, d_svhn_loss: 0.0217, d_fake_loss: 0.0666, g_loss: 1.1665\n",
            "Step [75720/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0148, d_svhn_loss: 0.0367, d_fake_loss: 0.0283, g_loss: 1.1328\n",
            "Step [75730/80000], d_real_loss: 0.0637, d_mnist_loss: 0.0260, d_svhn_loss: 0.0377, d_fake_loss: 0.1081, g_loss: 1.1444\n",
            "Step [75740/80000], d_real_loss: 0.0434, d_mnist_loss: 0.0153, d_svhn_loss: 0.0281, d_fake_loss: 0.0264, g_loss: 1.1719\n",
            "Step [75750/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0130, d_svhn_loss: 0.0383, d_fake_loss: 0.0651, g_loss: 1.2573\n",
            "Step [75760/80000], d_real_loss: 0.0521, d_mnist_loss: 0.0186, d_svhn_loss: 0.0335, d_fake_loss: 0.1479, g_loss: 1.3219\n",
            "Step [75770/80000], d_real_loss: 0.0716, d_mnist_loss: 0.0574, d_svhn_loss: 0.0142, d_fake_loss: 0.0748, g_loss: 1.1545\n",
            "Step [75780/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0378, d_svhn_loss: 0.0176, d_fake_loss: 0.0505, g_loss: 0.9874\n",
            "Step [75790/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0569, d_svhn_loss: 0.0349, d_fake_loss: 0.1846, g_loss: 1.1952\n",
            "Step [75800/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0155, d_svhn_loss: 0.0201, d_fake_loss: 0.0530, g_loss: 1.0946\n",
            "Step [75810/80000], d_real_loss: 0.0688, d_mnist_loss: 0.0231, d_svhn_loss: 0.0457, d_fake_loss: 0.0413, g_loss: 1.1414\n",
            "Step [75820/80000], d_real_loss: 0.1376, d_mnist_loss: 0.0669, d_svhn_loss: 0.0707, d_fake_loss: 0.0471, g_loss: 1.0526\n",
            "Step [75830/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0180, d_svhn_loss: 0.0189, d_fake_loss: 0.0627, g_loss: 1.1145\n",
            "Step [75840/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0231, d_svhn_loss: 0.0183, d_fake_loss: 0.0461, g_loss: 1.0364\n",
            "Step [75850/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0361, d_svhn_loss: 0.0099, d_fake_loss: 0.0420, g_loss: 0.9855\n",
            "Step [75860/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0213, d_svhn_loss: 0.0158, d_fake_loss: 0.0645, g_loss: 1.2772\n",
            "Step [75870/80000], d_real_loss: 0.0871, d_mnist_loss: 0.0695, d_svhn_loss: 0.0176, d_fake_loss: 0.1343, g_loss: 1.2013\n",
            "Step [75880/80000], d_real_loss: 0.0979, d_mnist_loss: 0.0386, d_svhn_loss: 0.0593, d_fake_loss: 0.0504, g_loss: 1.2400\n",
            "Step [75890/80000], d_real_loss: 0.1061, d_mnist_loss: 0.0181, d_svhn_loss: 0.0880, d_fake_loss: 0.0731, g_loss: 1.3111\n",
            "Step [75900/80000], d_real_loss: 0.0297, d_mnist_loss: 0.0169, d_svhn_loss: 0.0128, d_fake_loss: 0.1158, g_loss: 1.1102\n",
            "Step [75910/80000], d_real_loss: 0.1236, d_mnist_loss: 0.0659, d_svhn_loss: 0.0577, d_fake_loss: 0.1061, g_loss: 1.2484\n",
            "Step [75920/80000], d_real_loss: 0.1186, d_mnist_loss: 0.0266, d_svhn_loss: 0.0920, d_fake_loss: 0.0642, g_loss: 0.9781\n",
            "Step [75930/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0276, d_svhn_loss: 0.0137, d_fake_loss: 0.1218, g_loss: 1.0668\n",
            "Step [75940/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0181, d_svhn_loss: 0.0225, d_fake_loss: 0.0573, g_loss: 1.1082\n",
            "Step [75950/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0408, d_svhn_loss: 0.0175, d_fake_loss: 0.0657, g_loss: 1.1241\n",
            "Step [75960/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0274, d_svhn_loss: 0.0394, d_fake_loss: 0.0611, g_loss: 1.1043\n",
            "Step [75970/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0622, d_svhn_loss: 0.0198, d_fake_loss: 0.0393, g_loss: 1.1030\n",
            "Step [75980/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0280, d_svhn_loss: 0.0367, d_fake_loss: 0.0766, g_loss: 1.2988\n",
            "Step [75990/80000], d_real_loss: 0.1007, d_mnist_loss: 0.0210, d_svhn_loss: 0.0797, d_fake_loss: 0.0685, g_loss: 1.2183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7616478204727173, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [76000/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0293, d_svhn_loss: 0.0231, d_fake_loss: 0.0889, g_loss: 1.2348\n",
            "saved ./samples_fashion/sample-76000-m-s.png\n",
            "saved ./samples_fashion/sample-76000-s-m.png\n",
            "Step [76010/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0239, d_svhn_loss: 0.0250, d_fake_loss: 0.0272, g_loss: 1.0473\n",
            "Step [76020/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0198, d_svhn_loss: 0.0144, d_fake_loss: 0.0483, g_loss: 1.2352\n",
            "Step [76030/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0148, d_svhn_loss: 0.0405, d_fake_loss: 0.0548, g_loss: 1.2199\n",
            "Step [76040/80000], d_real_loss: 0.0935, d_mnist_loss: 0.0724, d_svhn_loss: 0.0211, d_fake_loss: 0.0594, g_loss: 1.1335\n",
            "Step [76050/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0114, d_svhn_loss: 0.0323, d_fake_loss: 0.0346, g_loss: 1.0757\n",
            "Step [76060/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0177, d_svhn_loss: 0.0406, d_fake_loss: 0.0309, g_loss: 1.1727\n",
            "Step [76070/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0398, d_svhn_loss: 0.0415, d_fake_loss: 0.0281, g_loss: 1.0362\n",
            "Step [76080/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0251, d_svhn_loss: 0.0313, d_fake_loss: 0.0293, g_loss: 1.2141\n",
            "Step [76090/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0368, d_svhn_loss: 0.0374, d_fake_loss: 0.0938, g_loss: 0.9848\n",
            "Step [76100/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0365, d_svhn_loss: 0.0180, d_fake_loss: 0.0751, g_loss: 1.0831\n",
            "Step [76110/80000], d_real_loss: 0.0611, d_mnist_loss: 0.0256, d_svhn_loss: 0.0355, d_fake_loss: 0.0349, g_loss: 1.2523\n",
            "Step [76120/80000], d_real_loss: 0.0495, d_mnist_loss: 0.0180, d_svhn_loss: 0.0315, d_fake_loss: 0.0360, g_loss: 1.1390\n",
            "Step [76130/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0127, d_svhn_loss: 0.0151, d_fake_loss: 0.0551, g_loss: 1.1288\n",
            "Step [76140/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0563, d_svhn_loss: 0.0179, d_fake_loss: 0.0705, g_loss: 1.1188\n",
            "Step [76150/80000], d_real_loss: 0.0698, d_mnist_loss: 0.0292, d_svhn_loss: 0.0406, d_fake_loss: 0.0471, g_loss: 1.0693\n",
            "Step [76160/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0199, d_svhn_loss: 0.0179, d_fake_loss: 0.0364, g_loss: 1.0210\n",
            "Step [76170/80000], d_real_loss: 0.0406, d_mnist_loss: 0.0174, d_svhn_loss: 0.0232, d_fake_loss: 0.0218, g_loss: 1.1609\n",
            "Step [76180/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0240, d_svhn_loss: 0.0335, d_fake_loss: 0.0291, g_loss: 1.1473\n",
            "Step [76190/80000], d_real_loss: 0.0429, d_mnist_loss: 0.0226, d_svhn_loss: 0.0204, d_fake_loss: 0.0466, g_loss: 1.2518\n",
            "Step [76200/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0263, d_svhn_loss: 0.0203, d_fake_loss: 0.0570, g_loss: 1.1658\n",
            "Step [76210/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0453, d_svhn_loss: 0.0331, d_fake_loss: 0.0427, g_loss: 1.1521\n",
            "Step [76220/80000], d_real_loss: 0.0961, d_mnist_loss: 0.0148, d_svhn_loss: 0.0812, d_fake_loss: 0.0931, g_loss: 1.0629\n",
            "Step [76230/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0349, d_svhn_loss: 0.0203, d_fake_loss: 0.0293, g_loss: 1.0814\n",
            "Step [76240/80000], d_real_loss: 0.0498, d_mnist_loss: 0.0224, d_svhn_loss: 0.0273, d_fake_loss: 0.0294, g_loss: 1.0501\n",
            "Step [76250/80000], d_real_loss: 0.0788, d_mnist_loss: 0.0219, d_svhn_loss: 0.0569, d_fake_loss: 0.0304, g_loss: 1.2955\n",
            "Step [76260/80000], d_real_loss: 0.0340, d_mnist_loss: 0.0192, d_svhn_loss: 0.0148, d_fake_loss: 0.0352, g_loss: 1.1623\n",
            "Step [76270/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0354, d_svhn_loss: 0.0192, d_fake_loss: 0.0575, g_loss: 1.3052\n",
            "Step [76280/80000], d_real_loss: 0.1156, d_mnist_loss: 0.0489, d_svhn_loss: 0.0668, d_fake_loss: 0.0608, g_loss: 1.0429\n",
            "Step [76290/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0414, d_svhn_loss: 0.0174, d_fake_loss: 0.0559, g_loss: 1.1692\n",
            "Step [76300/80000], d_real_loss: 0.0739, d_mnist_loss: 0.0172, d_svhn_loss: 0.0566, d_fake_loss: 0.0381, g_loss: 1.0872\n",
            "Step [76310/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0157, d_svhn_loss: 0.0152, d_fake_loss: 0.0506, g_loss: 1.1743\n",
            "Step [76320/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0136, d_svhn_loss: 0.0377, d_fake_loss: 0.0464, g_loss: 1.1782\n",
            "Step [76330/80000], d_real_loss: 0.0625, d_mnist_loss: 0.0477, d_svhn_loss: 0.0148, d_fake_loss: 0.0407, g_loss: 1.0211\n",
            "Step [76340/80000], d_real_loss: 0.0342, d_mnist_loss: 0.0224, d_svhn_loss: 0.0117, d_fake_loss: 0.1059, g_loss: 1.1766\n",
            "Step [76350/80000], d_real_loss: 0.0550, d_mnist_loss: 0.0311, d_svhn_loss: 0.0238, d_fake_loss: 0.0275, g_loss: 1.0719\n",
            "Step [76360/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0335, d_svhn_loss: 0.0449, d_fake_loss: 0.0790, g_loss: 1.3649\n",
            "Step [76370/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0130, d_svhn_loss: 0.0393, d_fake_loss: 0.0672, g_loss: 1.3292\n",
            "Step [76380/80000], d_real_loss: 0.0233, d_mnist_loss: 0.0094, d_svhn_loss: 0.0140, d_fake_loss: 0.0710, g_loss: 1.1728\n",
            "Step [76390/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0370, d_svhn_loss: 0.0130, d_fake_loss: 0.0308, g_loss: 0.9839\n",
            "Step [76400/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0214, d_svhn_loss: 0.0374, d_fake_loss: 0.0440, g_loss: 1.3010\n",
            "Step [76410/80000], d_real_loss: 0.0545, d_mnist_loss: 0.0129, d_svhn_loss: 0.0416, d_fake_loss: 0.0837, g_loss: 1.1819\n",
            "Step [76420/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0194, d_svhn_loss: 0.0202, d_fake_loss: 0.0321, g_loss: 1.0872\n",
            "Step [76430/80000], d_real_loss: 0.0659, d_mnist_loss: 0.0138, d_svhn_loss: 0.0521, d_fake_loss: 0.0354, g_loss: 1.1220\n",
            "Step [76440/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0295, d_svhn_loss: 0.0155, d_fake_loss: 0.0385, g_loss: 1.1951\n",
            "Step [76450/80000], d_real_loss: 0.0968, d_mnist_loss: 0.0140, d_svhn_loss: 0.0828, d_fake_loss: 0.0337, g_loss: 1.1032\n",
            "Step [76460/80000], d_real_loss: 0.0618, d_mnist_loss: 0.0450, d_svhn_loss: 0.0168, d_fake_loss: 0.0459, g_loss: 1.2003\n",
            "Step [76470/80000], d_real_loss: 0.0382, d_mnist_loss: 0.0250, d_svhn_loss: 0.0132, d_fake_loss: 0.0361, g_loss: 1.2323\n",
            "Step [76480/80000], d_real_loss: 0.0310, d_mnist_loss: 0.0125, d_svhn_loss: 0.0185, d_fake_loss: 0.0332, g_loss: 1.0787\n",
            "Step [76490/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0181, d_svhn_loss: 0.0532, d_fake_loss: 0.0454, g_loss: 1.1656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7295401096343994, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [76500/80000], d_real_loss: 0.0393, d_mnist_loss: 0.0238, d_svhn_loss: 0.0155, d_fake_loss: 0.0521, g_loss: 1.1621\n",
            "saved ./samples_fashion/sample-76500-m-s.png\n",
            "saved ./samples_fashion/sample-76500-s-m.png\n",
            "Step [76510/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0193, d_svhn_loss: 0.0497, d_fake_loss: 0.0223, g_loss: 1.1976\n",
            "Step [76520/80000], d_real_loss: 0.0397, d_mnist_loss: 0.0142, d_svhn_loss: 0.0255, d_fake_loss: 0.0266, g_loss: 1.1640\n",
            "Step [76530/80000], d_real_loss: 0.0812, d_mnist_loss: 0.0432, d_svhn_loss: 0.0381, d_fake_loss: 0.0567, g_loss: 1.1873\n",
            "Step [76540/80000], d_real_loss: 0.0517, d_mnist_loss: 0.0224, d_svhn_loss: 0.0293, d_fake_loss: 0.0654, g_loss: 1.1338\n",
            "Step [76550/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0185, d_svhn_loss: 0.0179, d_fake_loss: 0.1217, g_loss: 1.3757\n",
            "Step [76560/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0227, d_svhn_loss: 0.0437, d_fake_loss: 0.0340, g_loss: 1.2488\n",
            "Step [76570/80000], d_real_loss: 0.1662, d_mnist_loss: 0.1154, d_svhn_loss: 0.0508, d_fake_loss: 0.0770, g_loss: 1.1953\n",
            "Step [76580/80000], d_real_loss: 0.0905, d_mnist_loss: 0.0142, d_svhn_loss: 0.0763, d_fake_loss: 0.0639, g_loss: 1.3578\n",
            "Step [76590/80000], d_real_loss: 0.0993, d_mnist_loss: 0.0743, d_svhn_loss: 0.0249, d_fake_loss: 0.0668, g_loss: 1.2378\n",
            "Step [76600/80000], d_real_loss: 0.1347, d_mnist_loss: 0.0940, d_svhn_loss: 0.0407, d_fake_loss: 0.0540, g_loss: 1.2146\n",
            "Step [76610/80000], d_real_loss: 0.1328, d_mnist_loss: 0.1190, d_svhn_loss: 0.0138, d_fake_loss: 0.0400, g_loss: 1.1431\n",
            "Step [76620/80000], d_real_loss: 0.0363, d_mnist_loss: 0.0183, d_svhn_loss: 0.0180, d_fake_loss: 0.0323, g_loss: 1.1077\n",
            "Step [76630/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0230, d_svhn_loss: 0.0420, d_fake_loss: 0.0632, g_loss: 1.3109\n",
            "Step [76640/80000], d_real_loss: 0.0743, d_mnist_loss: 0.0194, d_svhn_loss: 0.0549, d_fake_loss: 0.0364, g_loss: 1.1720\n",
            "Step [76650/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0233, d_svhn_loss: 0.0187, d_fake_loss: 0.0536, g_loss: 0.9691\n",
            "Step [76660/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0286, d_svhn_loss: 0.0369, d_fake_loss: 0.0602, g_loss: 1.1223\n",
            "Step [76670/80000], d_real_loss: 0.0355, d_mnist_loss: 0.0171, d_svhn_loss: 0.0184, d_fake_loss: 0.0360, g_loss: 1.2191\n",
            "Step [76680/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0201, d_svhn_loss: 0.0342, d_fake_loss: 0.0383, g_loss: 1.0328\n",
            "Step [76690/80000], d_real_loss: 0.0778, d_mnist_loss: 0.0556, d_svhn_loss: 0.0221, d_fake_loss: 0.0438, g_loss: 1.0408\n",
            "Step [76700/80000], d_real_loss: 0.0504, d_mnist_loss: 0.0361, d_svhn_loss: 0.0143, d_fake_loss: 0.0357, g_loss: 1.0628\n",
            "Step [76710/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0341, d_svhn_loss: 0.0170, d_fake_loss: 0.0279, g_loss: 0.9919\n",
            "Step [76720/80000], d_real_loss: 0.0648, d_mnist_loss: 0.0336, d_svhn_loss: 0.0311, d_fake_loss: 0.0514, g_loss: 1.1163\n",
            "Step [76730/80000], d_real_loss: 0.0539, d_mnist_loss: 0.0152, d_svhn_loss: 0.0387, d_fake_loss: 0.0230, g_loss: 0.9862\n",
            "Step [76740/80000], d_real_loss: 0.0741, d_mnist_loss: 0.0317, d_svhn_loss: 0.0424, d_fake_loss: 0.0260, g_loss: 1.1947\n",
            "Step [76750/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0161, d_svhn_loss: 0.0332, d_fake_loss: 0.0302, g_loss: 1.0590\n",
            "Step [76760/80000], d_real_loss: 0.0375, d_mnist_loss: 0.0198, d_svhn_loss: 0.0177, d_fake_loss: 0.0783, g_loss: 1.0585\n",
            "Step [76770/80000], d_real_loss: 0.0662, d_mnist_loss: 0.0486, d_svhn_loss: 0.0176, d_fake_loss: 0.1365, g_loss: 1.3342\n",
            "Step [76780/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0247, d_svhn_loss: 0.0162, d_fake_loss: 0.0455, g_loss: 1.1203\n",
            "Step [76790/80000], d_real_loss: 0.0479, d_mnist_loss: 0.0186, d_svhn_loss: 0.0293, d_fake_loss: 0.0365, g_loss: 1.1830\n",
            "Step [76800/80000], d_real_loss: 0.0708, d_mnist_loss: 0.0413, d_svhn_loss: 0.0295, d_fake_loss: 0.0637, g_loss: 1.0744\n",
            "Step [76810/80000], d_real_loss: 0.0462, d_mnist_loss: 0.0244, d_svhn_loss: 0.0219, d_fake_loss: 0.0592, g_loss: 1.0031\n",
            "Step [76820/80000], d_real_loss: 0.0558, d_mnist_loss: 0.0310, d_svhn_loss: 0.0248, d_fake_loss: 0.0266, g_loss: 1.0567\n",
            "Step [76830/80000], d_real_loss: 0.0713, d_mnist_loss: 0.0451, d_svhn_loss: 0.0262, d_fake_loss: 0.0239, g_loss: 1.1246\n",
            "Step [76840/80000], d_real_loss: 0.1353, d_mnist_loss: 0.1160, d_svhn_loss: 0.0193, d_fake_loss: 0.0294, g_loss: 1.0299\n",
            "Step [76850/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0138, d_svhn_loss: 0.0146, d_fake_loss: 0.0681, g_loss: 1.3376\n",
            "Step [76860/80000], d_real_loss: 0.0460, d_mnist_loss: 0.0253, d_svhn_loss: 0.0207, d_fake_loss: 0.0796, g_loss: 1.1515\n",
            "Step [76870/80000], d_real_loss: 0.0583, d_mnist_loss: 0.0400, d_svhn_loss: 0.0183, d_fake_loss: 0.0530, g_loss: 1.0807\n",
            "Step [76880/80000], d_real_loss: 0.1219, d_mnist_loss: 0.0218, d_svhn_loss: 0.1001, d_fake_loss: 0.0201, g_loss: 1.1078\n",
            "Step [76890/80000], d_real_loss: 0.0875, d_mnist_loss: 0.0133, d_svhn_loss: 0.0742, d_fake_loss: 0.0367, g_loss: 1.2304\n",
            "Step [76900/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0193, d_svhn_loss: 0.0230, d_fake_loss: 0.0398, g_loss: 1.3151\n",
            "Step [76910/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0206, d_svhn_loss: 0.0228, d_fake_loss: 0.0529, g_loss: 1.2630\n",
            "Step [76920/80000], d_real_loss: 0.0453, d_mnist_loss: 0.0268, d_svhn_loss: 0.0185, d_fake_loss: 0.0577, g_loss: 1.0692\n",
            "Step [76930/80000], d_real_loss: 0.0547, d_mnist_loss: 0.0268, d_svhn_loss: 0.0280, d_fake_loss: 0.0465, g_loss: 1.0191\n",
            "Step [76940/80000], d_real_loss: 0.0410, d_mnist_loss: 0.0262, d_svhn_loss: 0.0148, d_fake_loss: 0.0620, g_loss: 1.2069\n",
            "Step [76950/80000], d_real_loss: 0.0684, d_mnist_loss: 0.0180, d_svhn_loss: 0.0504, d_fake_loss: 0.0343, g_loss: 1.2674\n",
            "Step [76960/80000], d_real_loss: 0.0364, d_mnist_loss: 0.0234, d_svhn_loss: 0.0130, d_fake_loss: 0.0306, g_loss: 1.0852\n",
            "Step [76970/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0310, d_svhn_loss: 0.0304, d_fake_loss: 0.0217, g_loss: 1.1536\n",
            "Step [76980/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0231, d_svhn_loss: 0.0348, d_fake_loss: 0.0953, g_loss: 1.3349\n",
            "Step [76990/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0224, d_svhn_loss: 0.0263, d_fake_loss: 0.1032, g_loss: 1.0695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.695491373538971, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [77000/80000], d_real_loss: 0.0426, d_mnist_loss: 0.0191, d_svhn_loss: 0.0235, d_fake_loss: 0.1006, g_loss: 1.1662\n",
            "saved ./samples_fashion/sample-77000-m-s.png\n",
            "saved ./samples_fashion/sample-77000-s-m.png\n",
            "Step [77010/80000], d_real_loss: 0.0522, d_mnist_loss: 0.0252, d_svhn_loss: 0.0270, d_fake_loss: 0.0323, g_loss: 1.0439\n",
            "Step [77020/80000], d_real_loss: 0.0417, d_mnist_loss: 0.0224, d_svhn_loss: 0.0193, d_fake_loss: 0.0312, g_loss: 1.1857\n",
            "Step [77030/80000], d_real_loss: 0.0322, d_mnist_loss: 0.0128, d_svhn_loss: 0.0193, d_fake_loss: 0.0639, g_loss: 1.2313\n",
            "Step [77040/80000], d_real_loss: 0.0559, d_mnist_loss: 0.0181, d_svhn_loss: 0.0379, d_fake_loss: 0.0607, g_loss: 1.1639\n",
            "Step [77050/80000], d_real_loss: 0.0809, d_mnist_loss: 0.0275, d_svhn_loss: 0.0534, d_fake_loss: 0.0625, g_loss: 1.1277\n",
            "Step [77060/80000], d_real_loss: 0.1121, d_mnist_loss: 0.0521, d_svhn_loss: 0.0599, d_fake_loss: 0.1910, g_loss: 1.3609\n",
            "Step [77070/80000], d_real_loss: 0.0444, d_mnist_loss: 0.0281, d_svhn_loss: 0.0163, d_fake_loss: 0.0827, g_loss: 1.1393\n",
            "Step [77080/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0191, d_svhn_loss: 0.0222, d_fake_loss: 0.0414, g_loss: 1.2482\n",
            "Step [77090/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0380, d_svhn_loss: 0.0106, d_fake_loss: 0.0569, g_loss: 1.2101\n",
            "Step [77100/80000], d_real_loss: 0.1209, d_mnist_loss: 0.0430, d_svhn_loss: 0.0779, d_fake_loss: 0.0857, g_loss: 1.0817\n",
            "Step [77110/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0203, d_svhn_loss: 0.0175, d_fake_loss: 0.0305, g_loss: 1.0815\n",
            "Step [77120/80000], d_real_loss: 0.0584, d_mnist_loss: 0.0252, d_svhn_loss: 0.0332, d_fake_loss: 0.0567, g_loss: 1.0807\n",
            "Step [77130/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0216, d_svhn_loss: 0.0127, d_fake_loss: 0.0296, g_loss: 1.1416\n",
            "Step [77140/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0235, d_svhn_loss: 0.0153, d_fake_loss: 0.0682, g_loss: 1.1054\n",
            "Step [77150/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0401, d_svhn_loss: 0.0228, d_fake_loss: 0.0302, g_loss: 1.1327\n",
            "Step [77160/80000], d_real_loss: 0.0455, d_mnist_loss: 0.0281, d_svhn_loss: 0.0175, d_fake_loss: 0.0290, g_loss: 1.2152\n",
            "Step [77170/80000], d_real_loss: 0.0777, d_mnist_loss: 0.0339, d_svhn_loss: 0.0438, d_fake_loss: 0.0674, g_loss: 1.1444\n",
            "Step [77180/80000], d_real_loss: 0.0768, d_mnist_loss: 0.0297, d_svhn_loss: 0.0471, d_fake_loss: 0.1005, g_loss: 1.1275\n",
            "Step [77190/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0130, d_svhn_loss: 0.0239, d_fake_loss: 0.0487, g_loss: 1.0638\n",
            "Step [77200/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0240, d_svhn_loss: 0.0243, d_fake_loss: 0.0373, g_loss: 1.1561\n",
            "Step [77210/80000], d_real_loss: 0.1025, d_mnist_loss: 0.0355, d_svhn_loss: 0.0670, d_fake_loss: 0.0388, g_loss: 0.9939\n",
            "Step [77220/80000], d_real_loss: 0.0747, d_mnist_loss: 0.0579, d_svhn_loss: 0.0168, d_fake_loss: 0.0991, g_loss: 0.9452\n",
            "Step [77230/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0176, d_svhn_loss: 0.0235, d_fake_loss: 0.0476, g_loss: 1.1146\n",
            "Step [77240/80000], d_real_loss: 0.0316, d_mnist_loss: 0.0144, d_svhn_loss: 0.0173, d_fake_loss: 0.0294, g_loss: 1.1452\n",
            "Step [77250/80000], d_real_loss: 0.0592, d_mnist_loss: 0.0330, d_svhn_loss: 0.0263, d_fake_loss: 0.0802, g_loss: 1.2801\n",
            "Step [77260/80000], d_real_loss: 0.0677, d_mnist_loss: 0.0290, d_svhn_loss: 0.0388, d_fake_loss: 0.0662, g_loss: 1.1776\n",
            "Step [77270/80000], d_real_loss: 0.1410, d_mnist_loss: 0.0491, d_svhn_loss: 0.0919, d_fake_loss: 0.0734, g_loss: 1.2490\n",
            "Step [77280/80000], d_real_loss: 0.0268, d_mnist_loss: 0.0095, d_svhn_loss: 0.0173, d_fake_loss: 0.0516, g_loss: 1.1026\n",
            "Step [77290/80000], d_real_loss: 0.0831, d_mnist_loss: 0.0624, d_svhn_loss: 0.0207, d_fake_loss: 0.0329, g_loss: 1.0693\n",
            "Step [77300/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0206, d_svhn_loss: 0.0245, d_fake_loss: 0.0375, g_loss: 1.1519\n",
            "Step [77310/80000], d_real_loss: 0.0411, d_mnist_loss: 0.0205, d_svhn_loss: 0.0207, d_fake_loss: 0.0318, g_loss: 1.0701\n",
            "Step [77320/80000], d_real_loss: 0.0548, d_mnist_loss: 0.0277, d_svhn_loss: 0.0271, d_fake_loss: 0.0379, g_loss: 1.1378\n",
            "Step [77330/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0193, d_svhn_loss: 0.0255, d_fake_loss: 0.0717, g_loss: 1.3639\n",
            "Step [77340/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0294, d_svhn_loss: 0.0220, d_fake_loss: 0.0728, g_loss: 1.3036\n",
            "Step [77350/80000], d_real_loss: 0.1086, d_mnist_loss: 0.0720, d_svhn_loss: 0.0365, d_fake_loss: 0.0837, g_loss: 1.2176\n",
            "Step [77360/80000], d_real_loss: 0.0579, d_mnist_loss: 0.0227, d_svhn_loss: 0.0352, d_fake_loss: 0.0474, g_loss: 1.3187\n",
            "Step [77370/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0151, d_svhn_loss: 0.0232, d_fake_loss: 0.0790, g_loss: 1.1093\n",
            "Step [77380/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0142, d_svhn_loss: 0.0222, d_fake_loss: 0.0605, g_loss: 1.2147\n",
            "Step [77390/80000], d_real_loss: 0.1026, d_mnist_loss: 0.0267, d_svhn_loss: 0.0758, d_fake_loss: 0.1001, g_loss: 1.2850\n",
            "Step [77400/80000], d_real_loss: 0.0622, d_mnist_loss: 0.0142, d_svhn_loss: 0.0480, d_fake_loss: 0.0314, g_loss: 1.1458\n",
            "Step [77410/80000], d_real_loss: 0.0664, d_mnist_loss: 0.0425, d_svhn_loss: 0.0239, d_fake_loss: 0.0487, g_loss: 1.0993\n",
            "Step [77420/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0140, d_svhn_loss: 0.0309, d_fake_loss: 0.0334, g_loss: 1.1440\n",
            "Step [77430/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0165, d_svhn_loss: 0.0185, d_fake_loss: 0.0382, g_loss: 1.1300\n",
            "Step [77440/80000], d_real_loss: 0.0483, d_mnist_loss: 0.0234, d_svhn_loss: 0.0249, d_fake_loss: 0.0354, g_loss: 1.1797\n",
            "Step [77450/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0135, d_svhn_loss: 0.0479, d_fake_loss: 0.0886, g_loss: 1.1306\n",
            "Step [77460/80000], d_real_loss: 0.0623, d_mnist_loss: 0.0239, d_svhn_loss: 0.0384, d_fake_loss: 0.0454, g_loss: 1.1094\n",
            "Step [77470/80000], d_real_loss: 0.0581, d_mnist_loss: 0.0268, d_svhn_loss: 0.0313, d_fake_loss: 0.0750, g_loss: 1.1806\n",
            "Step [77480/80000], d_real_loss: 0.0962, d_mnist_loss: 0.0702, d_svhn_loss: 0.0260, d_fake_loss: 0.0772, g_loss: 1.0385\n",
            "Step [77490/80000], d_real_loss: 0.0413, d_mnist_loss: 0.0180, d_svhn_loss: 0.0233, d_fake_loss: 0.0371, g_loss: 1.1100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.6781570911407471, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [77500/80000], d_real_loss: 0.0840, d_mnist_loss: 0.0166, d_svhn_loss: 0.0674, d_fake_loss: 0.0399, g_loss: 1.0852\n",
            "saved ./samples_fashion/sample-77500-m-s.png\n",
            "saved ./samples_fashion/sample-77500-s-m.png\n",
            "Step [77510/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0133, d_svhn_loss: 0.0514, d_fake_loss: 0.0645, g_loss: 1.1933\n",
            "Step [77520/80000], d_real_loss: 0.0609, d_mnist_loss: 0.0278, d_svhn_loss: 0.0331, d_fake_loss: 0.1405, g_loss: 1.0103\n",
            "Step [77530/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0179, d_svhn_loss: 0.0346, d_fake_loss: 0.0239, g_loss: 1.1482\n",
            "Step [77540/80000], d_real_loss: 0.0673, d_mnist_loss: 0.0224, d_svhn_loss: 0.0449, d_fake_loss: 0.1078, g_loss: 1.2089\n",
            "Step [77550/80000], d_real_loss: 0.0711, d_mnist_loss: 0.0422, d_svhn_loss: 0.0289, d_fake_loss: 0.0675, g_loss: 1.1895\n",
            "Step [77560/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0168, d_svhn_loss: 0.0163, d_fake_loss: 0.0632, g_loss: 0.9833\n",
            "Step [77570/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0327, d_svhn_loss: 0.0164, d_fake_loss: 0.0282, g_loss: 1.0896\n",
            "Step [77580/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0206, d_svhn_loss: 0.0244, d_fake_loss: 0.0283, g_loss: 1.1308\n",
            "Step [77590/80000], d_real_loss: 0.0670, d_mnist_loss: 0.0389, d_svhn_loss: 0.0281, d_fake_loss: 0.0608, g_loss: 0.9745\n",
            "Step [77600/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0293, d_svhn_loss: 0.0270, d_fake_loss: 0.0320, g_loss: 1.0545\n",
            "Step [77610/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0174, d_svhn_loss: 0.0547, d_fake_loss: 0.0876, g_loss: 1.2711\n",
            "Step [77620/80000], d_real_loss: 0.0477, d_mnist_loss: 0.0229, d_svhn_loss: 0.0248, d_fake_loss: 0.1133, g_loss: 1.2885\n",
            "Step [77630/80000], d_real_loss: 0.0441, d_mnist_loss: 0.0157, d_svhn_loss: 0.0284, d_fake_loss: 0.1116, g_loss: 1.0746\n",
            "Step [77640/80000], d_real_loss: 0.0457, d_mnist_loss: 0.0120, d_svhn_loss: 0.0338, d_fake_loss: 0.0507, g_loss: 1.1603\n",
            "Step [77650/80000], d_real_loss: 0.2080, d_mnist_loss: 0.0635, d_svhn_loss: 0.1445, d_fake_loss: 0.0291, g_loss: 1.0314\n",
            "Step [77660/80000], d_real_loss: 0.1442, d_mnist_loss: 0.0820, d_svhn_loss: 0.0622, d_fake_loss: 0.0520, g_loss: 1.2473\n",
            "Step [77670/80000], d_real_loss: 0.0615, d_mnist_loss: 0.0421, d_svhn_loss: 0.0194, d_fake_loss: 0.0392, g_loss: 1.0668\n",
            "Step [77680/80000], d_real_loss: 0.0651, d_mnist_loss: 0.0283, d_svhn_loss: 0.0368, d_fake_loss: 0.1212, g_loss: 1.0206\n",
            "Step [77690/80000], d_real_loss: 0.0391, d_mnist_loss: 0.0239, d_svhn_loss: 0.0152, d_fake_loss: 0.0276, g_loss: 1.1143\n",
            "Step [77700/80000], d_real_loss: 0.0737, d_mnist_loss: 0.0503, d_svhn_loss: 0.0234, d_fake_loss: 0.0920, g_loss: 1.0425\n",
            "Step [77710/80000], d_real_loss: 0.0431, d_mnist_loss: 0.0227, d_svhn_loss: 0.0204, d_fake_loss: 0.0808, g_loss: 1.1853\n",
            "Step [77720/80000], d_real_loss: 0.0381, d_mnist_loss: 0.0167, d_svhn_loss: 0.0214, d_fake_loss: 0.0303, g_loss: 1.1683\n",
            "Step [77730/80000], d_real_loss: 0.0876, d_mnist_loss: 0.0649, d_svhn_loss: 0.0227, d_fake_loss: 0.0594, g_loss: 1.2339\n",
            "Step [77740/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0147, d_svhn_loss: 0.0268, d_fake_loss: 0.0343, g_loss: 1.1307\n",
            "Step [77750/80000], d_real_loss: 0.0303, d_mnist_loss: 0.0118, d_svhn_loss: 0.0185, d_fake_loss: 0.0822, g_loss: 1.1314\n",
            "Step [77760/80000], d_real_loss: 0.0284, d_mnist_loss: 0.0116, d_svhn_loss: 0.0168, d_fake_loss: 0.0460, g_loss: 1.1786\n",
            "Step [77770/80000], d_real_loss: 0.0452, d_mnist_loss: 0.0201, d_svhn_loss: 0.0252, d_fake_loss: 0.0647, g_loss: 1.2071\n",
            "Step [77780/80000], d_real_loss: 0.0448, d_mnist_loss: 0.0238, d_svhn_loss: 0.0210, d_fake_loss: 0.0434, g_loss: 1.1030\n",
            "Step [77790/80000], d_real_loss: 0.0299, d_mnist_loss: 0.0150, d_svhn_loss: 0.0149, d_fake_loss: 0.0503, g_loss: 1.3117\n",
            "Step [77800/80000], d_real_loss: 0.0833, d_mnist_loss: 0.0165, d_svhn_loss: 0.0668, d_fake_loss: 0.0546, g_loss: 1.2729\n",
            "Step [77810/80000], d_real_loss: 0.0385, d_mnist_loss: 0.0134, d_svhn_loss: 0.0251, d_fake_loss: 0.0322, g_loss: 1.1173\n",
            "Step [77820/80000], d_real_loss: 0.0745, d_mnist_loss: 0.0467, d_svhn_loss: 0.0278, d_fake_loss: 0.0316, g_loss: 1.0666\n",
            "Step [77830/80000], d_real_loss: 0.0298, d_mnist_loss: 0.0112, d_svhn_loss: 0.0186, d_fake_loss: 0.0508, g_loss: 1.1215\n",
            "Step [77840/80000], d_real_loss: 0.0560, d_mnist_loss: 0.0299, d_svhn_loss: 0.0261, d_fake_loss: 0.0418, g_loss: 0.9885\n",
            "Step [77850/80000], d_real_loss: 0.0918, d_mnist_loss: 0.0266, d_svhn_loss: 0.0652, d_fake_loss: 0.1024, g_loss: 1.0788\n",
            "Step [77860/80000], d_real_loss: 0.0784, d_mnist_loss: 0.0350, d_svhn_loss: 0.0434, d_fake_loss: 0.0235, g_loss: 1.1766\n",
            "Step [77870/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0156, d_svhn_loss: 0.0243, d_fake_loss: 0.0494, g_loss: 1.1124\n",
            "Step [77880/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0190, d_svhn_loss: 0.0302, d_fake_loss: 0.0636, g_loss: 1.0569\n",
            "Step [77890/80000], d_real_loss: 0.0597, d_mnist_loss: 0.0174, d_svhn_loss: 0.0424, d_fake_loss: 0.0498, g_loss: 1.1885\n",
            "Step [77900/80000], d_real_loss: 0.0486, d_mnist_loss: 0.0170, d_svhn_loss: 0.0316, d_fake_loss: 0.0461, g_loss: 1.3183\n",
            "Step [77910/80000], d_real_loss: 0.0805, d_mnist_loss: 0.0305, d_svhn_loss: 0.0500, d_fake_loss: 0.0262, g_loss: 1.1491\n",
            "Step [77920/80000], d_real_loss: 0.0564, d_mnist_loss: 0.0370, d_svhn_loss: 0.0195, d_fake_loss: 0.0317, g_loss: 1.0345\n",
            "Step [77930/80000], d_real_loss: 0.0427, d_mnist_loss: 0.0233, d_svhn_loss: 0.0194, d_fake_loss: 0.0279, g_loss: 1.1044\n",
            "Step [77940/80000], d_real_loss: 0.3245, d_mnist_loss: 0.2089, d_svhn_loss: 0.1155, d_fake_loss: 0.0702, g_loss: 1.5294\n",
            "Step [77950/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0339, d_svhn_loss: 0.0258, d_fake_loss: 0.0305, g_loss: 1.2872\n",
            "Step [77960/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0152, d_svhn_loss: 0.0271, d_fake_loss: 0.0416, g_loss: 0.9986\n",
            "Step [77970/80000], d_real_loss: 0.0606, d_mnist_loss: 0.0395, d_svhn_loss: 0.0211, d_fake_loss: 0.0372, g_loss: 1.1680\n",
            "Step [77980/80000], d_real_loss: 0.0492, d_mnist_loss: 0.0277, d_svhn_loss: 0.0216, d_fake_loss: 0.0480, g_loss: 1.2179\n",
            "Step [77990/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0270, d_svhn_loss: 0.0223, d_fake_loss: 0.0439, g_loss: 0.9789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.6847075819969177, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [78000/80000], d_real_loss: 0.0877, d_mnist_loss: 0.0196, d_svhn_loss: 0.0681, d_fake_loss: 0.0324, g_loss: 1.0904\n",
            "saved ./samples_fashion/sample-78000-m-s.png\n",
            "saved ./samples_fashion/sample-78000-s-m.png\n",
            "Step [78010/80000], d_real_loss: 0.0321, d_mnist_loss: 0.0192, d_svhn_loss: 0.0129, d_fake_loss: 0.0401, g_loss: 1.0920\n",
            "Step [78020/80000], d_real_loss: 0.0374, d_mnist_loss: 0.0194, d_svhn_loss: 0.0179, d_fake_loss: 0.0359, g_loss: 1.1888\n",
            "Step [78030/80000], d_real_loss: 0.0525, d_mnist_loss: 0.0189, d_svhn_loss: 0.0335, d_fake_loss: 0.0491, g_loss: 1.1964\n",
            "Step [78040/80000], d_real_loss: 0.1093, d_mnist_loss: 0.0230, d_svhn_loss: 0.0863, d_fake_loss: 0.0325, g_loss: 1.1775\n",
            "Step [78050/80000], d_real_loss: 0.0443, d_mnist_loss: 0.0182, d_svhn_loss: 0.0261, d_fake_loss: 0.0342, g_loss: 0.9685\n",
            "Step [78060/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0208, d_svhn_loss: 0.0242, d_fake_loss: 0.0217, g_loss: 1.1695\n",
            "Step [78070/80000], d_real_loss: 0.0519, d_mnist_loss: 0.0302, d_svhn_loss: 0.0216, d_fake_loss: 0.0500, g_loss: 1.2873\n",
            "Step [78080/80000], d_real_loss: 0.0552, d_mnist_loss: 0.0288, d_svhn_loss: 0.0264, d_fake_loss: 0.1198, g_loss: 1.0769\n",
            "Step [78090/80000], d_real_loss: 0.0614, d_mnist_loss: 0.0417, d_svhn_loss: 0.0197, d_fake_loss: 0.0423, g_loss: 1.1393\n",
            "Step [78100/80000], d_real_loss: 0.1240, d_mnist_loss: 0.1082, d_svhn_loss: 0.0158, d_fake_loss: 0.0655, g_loss: 1.7646\n",
            "Step [78110/80000], d_real_loss: 0.0478, d_mnist_loss: 0.0230, d_svhn_loss: 0.0248, d_fake_loss: 0.0308, g_loss: 1.0907\n",
            "Step [78120/80000], d_real_loss: 0.0633, d_mnist_loss: 0.0155, d_svhn_loss: 0.0478, d_fake_loss: 0.0896, g_loss: 0.9151\n",
            "Step [78130/80000], d_real_loss: 0.0308, d_mnist_loss: 0.0134, d_svhn_loss: 0.0174, d_fake_loss: 0.0413, g_loss: 1.1305\n",
            "Step [78140/80000], d_real_loss: 0.0760, d_mnist_loss: 0.0615, d_svhn_loss: 0.0145, d_fake_loss: 0.0987, g_loss: 1.2430\n",
            "Step [78150/80000], d_real_loss: 0.0686, d_mnist_loss: 0.0483, d_svhn_loss: 0.0202, d_fake_loss: 0.0606, g_loss: 1.1192\n",
            "Step [78160/80000], d_real_loss: 0.0538, d_mnist_loss: 0.0309, d_svhn_loss: 0.0229, d_fake_loss: 0.0493, g_loss: 1.0090\n",
            "Step [78170/80000], d_real_loss: 0.1658, d_mnist_loss: 0.1436, d_svhn_loss: 0.0222, d_fake_loss: 0.0450, g_loss: 1.2309\n",
            "Step [78180/80000], d_real_loss: 0.0345, d_mnist_loss: 0.0150, d_svhn_loss: 0.0195, d_fake_loss: 0.0333, g_loss: 1.0986\n",
            "Step [78190/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0185, d_svhn_loss: 0.0165, d_fake_loss: 0.0747, g_loss: 1.1620\n",
            "Step [78200/80000], d_real_loss: 0.0680, d_mnist_loss: 0.0384, d_svhn_loss: 0.0296, d_fake_loss: 0.0506, g_loss: 1.1147\n",
            "Step [78210/80000], d_real_loss: 0.0635, d_mnist_loss: 0.0259, d_svhn_loss: 0.0376, d_fake_loss: 0.0332, g_loss: 1.0523\n",
            "Step [78220/80000], d_real_loss: 0.0514, d_mnist_loss: 0.0364, d_svhn_loss: 0.0150, d_fake_loss: 0.0420, g_loss: 1.0888\n",
            "Step [78230/80000], d_real_loss: 0.0945, d_mnist_loss: 0.0168, d_svhn_loss: 0.0776, d_fake_loss: 0.0433, g_loss: 1.1451\n",
            "Step [78240/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0181, d_svhn_loss: 0.0308, d_fake_loss: 0.0601, g_loss: 1.1349\n",
            "Step [78250/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0174, d_svhn_loss: 0.0337, d_fake_loss: 0.0427, g_loss: 1.2345\n",
            "Step [78260/80000], d_real_loss: 0.0388, d_mnist_loss: 0.0182, d_svhn_loss: 0.0205, d_fake_loss: 0.0425, g_loss: 1.0546\n",
            "Step [78270/80000], d_real_loss: 0.1079, d_mnist_loss: 0.0755, d_svhn_loss: 0.0323, d_fake_loss: 0.0366, g_loss: 1.0867\n",
            "Step [78280/80000], d_real_loss: 0.0501, d_mnist_loss: 0.0308, d_svhn_loss: 0.0192, d_fake_loss: 0.0346, g_loss: 1.2592\n",
            "Step [78290/80000], d_real_loss: 0.0823, d_mnist_loss: 0.0454, d_svhn_loss: 0.0369, d_fake_loss: 0.0473, g_loss: 1.2390\n",
            "Step [78300/80000], d_real_loss: 0.0575, d_mnist_loss: 0.0318, d_svhn_loss: 0.0258, d_fake_loss: 0.1244, g_loss: 1.3497\n",
            "Step [78310/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0195, d_svhn_loss: 0.0151, d_fake_loss: 0.0483, g_loss: 1.0672\n",
            "Step [78320/80000], d_real_loss: 0.0447, d_mnist_loss: 0.0223, d_svhn_loss: 0.0224, d_fake_loss: 0.1792, g_loss: 1.2938\n",
            "Step [78330/80000], d_real_loss: 0.0650, d_mnist_loss: 0.0343, d_svhn_loss: 0.0307, d_fake_loss: 0.1199, g_loss: 1.2378\n",
            "Step [78340/80000], d_real_loss: 0.0803, d_mnist_loss: 0.0255, d_svhn_loss: 0.0547, d_fake_loss: 0.0305, g_loss: 1.0200\n",
            "Step [78350/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0216, d_svhn_loss: 0.0330, d_fake_loss: 0.0507, g_loss: 1.1199\n",
            "Step [78360/80000], d_real_loss: 0.0588, d_mnist_loss: 0.0446, d_svhn_loss: 0.0142, d_fake_loss: 0.1473, g_loss: 1.1458\n",
            "Step [78370/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0222, d_svhn_loss: 0.0174, d_fake_loss: 0.0397, g_loss: 1.2962\n",
            "Step [78380/80000], d_real_loss: 0.0407, d_mnist_loss: 0.0235, d_svhn_loss: 0.0171, d_fake_loss: 0.1019, g_loss: 1.0365\n",
            "Step [78390/80000], d_real_loss: 0.0421, d_mnist_loss: 0.0183, d_svhn_loss: 0.0238, d_fake_loss: 0.1270, g_loss: 1.2023\n",
            "Step [78400/80000], d_real_loss: 0.1006, d_mnist_loss: 0.0178, d_svhn_loss: 0.0828, d_fake_loss: 0.0426, g_loss: 1.1194\n",
            "Step [78410/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0213, d_svhn_loss: 0.0156, d_fake_loss: 0.0855, g_loss: 1.2792\n",
            "Step [78420/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0224, d_svhn_loss: 0.0251, d_fake_loss: 0.0499, g_loss: 1.1062\n",
            "Step [78430/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0147, d_svhn_loss: 0.0241, d_fake_loss: 0.1072, g_loss: 1.1804\n",
            "Step [78440/80000], d_real_loss: 0.0658, d_mnist_loss: 0.0279, d_svhn_loss: 0.0380, d_fake_loss: 0.0687, g_loss: 1.1254\n",
            "Step [78450/80000], d_real_loss: 0.0323, d_mnist_loss: 0.0154, d_svhn_loss: 0.0169, d_fake_loss: 0.0278, g_loss: 1.1607\n",
            "Step [78460/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0348, d_svhn_loss: 0.0381, d_fake_loss: 0.0301, g_loss: 1.0655\n",
            "Step [78470/80000], d_real_loss: 0.0396, d_mnist_loss: 0.0187, d_svhn_loss: 0.0208, d_fake_loss: 0.0703, g_loss: 1.1817\n",
            "Step [78480/80000], d_real_loss: 0.0394, d_mnist_loss: 0.0238, d_svhn_loss: 0.0156, d_fake_loss: 0.0354, g_loss: 1.0993\n",
            "Step [78490/80000], d_real_loss: 0.0931, d_mnist_loss: 0.0200, d_svhn_loss: 0.0731, d_fake_loss: 0.0897, g_loss: 1.2782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7002922296524048, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [78500/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0288, d_svhn_loss: 0.0275, d_fake_loss: 0.0693, g_loss: 1.2612\n",
            "saved ./samples_fashion/sample-78500-m-s.png\n",
            "saved ./samples_fashion/sample-78500-s-m.png\n",
            "Step [78510/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0241, d_svhn_loss: 0.0197, d_fake_loss: 0.0573, g_loss: 1.2566\n",
            "Step [78520/80000], d_real_loss: 0.0829, d_mnist_loss: 0.0295, d_svhn_loss: 0.0534, d_fake_loss: 0.0282, g_loss: 1.0378\n",
            "Step [78530/80000], d_real_loss: 0.0654, d_mnist_loss: 0.0428, d_svhn_loss: 0.0226, d_fake_loss: 0.0396, g_loss: 1.0680\n",
            "Step [78540/80000], d_real_loss: 0.0537, d_mnist_loss: 0.0300, d_svhn_loss: 0.0237, d_fake_loss: 0.0401, g_loss: 1.1849\n",
            "Step [78550/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0195, d_svhn_loss: 0.0280, d_fake_loss: 0.1239, g_loss: 1.2157\n",
            "Step [78560/80000], d_real_loss: 0.0372, d_mnist_loss: 0.0186, d_svhn_loss: 0.0186, d_fake_loss: 0.0305, g_loss: 1.2625\n",
            "Step [78570/80000], d_real_loss: 0.0701, d_mnist_loss: 0.0298, d_svhn_loss: 0.0403, d_fake_loss: 0.0344, g_loss: 1.1531\n",
            "Step [78580/80000], d_real_loss: 0.0423, d_mnist_loss: 0.0196, d_svhn_loss: 0.0228, d_fake_loss: 0.0422, g_loss: 1.1271\n",
            "Step [78590/80000], d_real_loss: 0.0868, d_mnist_loss: 0.0248, d_svhn_loss: 0.0620, d_fake_loss: 0.0581, g_loss: 1.0964\n",
            "Step [78600/80000], d_real_loss: 0.0409, d_mnist_loss: 0.0229, d_svhn_loss: 0.0180, d_fake_loss: 0.0473, g_loss: 1.0404\n",
            "Step [78610/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0228, d_svhn_loss: 0.0233, d_fake_loss: 0.0425, g_loss: 1.1343\n",
            "Step [78620/80000], d_real_loss: 0.0578, d_mnist_loss: 0.0156, d_svhn_loss: 0.0422, d_fake_loss: 0.0310, g_loss: 1.1009\n",
            "Step [78630/80000], d_real_loss: 0.0957, d_mnist_loss: 0.0210, d_svhn_loss: 0.0747, d_fake_loss: 0.0914, g_loss: 1.0645\n",
            "Step [78640/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0267, d_svhn_loss: 0.0116, d_fake_loss: 0.1175, g_loss: 1.1653\n",
            "Step [78650/80000], d_real_loss: 0.0349, d_mnist_loss: 0.0194, d_svhn_loss: 0.0155, d_fake_loss: 0.0465, g_loss: 1.1992\n",
            "Step [78660/80000], d_real_loss: 0.0470, d_mnist_loss: 0.0210, d_svhn_loss: 0.0260, d_fake_loss: 0.0386, g_loss: 1.2338\n",
            "Step [78670/80000], d_real_loss: 0.0328, d_mnist_loss: 0.0160, d_svhn_loss: 0.0167, d_fake_loss: 0.0273, g_loss: 1.1682\n",
            "Step [78680/80000], d_real_loss: 0.0851, d_mnist_loss: 0.0297, d_svhn_loss: 0.0555, d_fake_loss: 0.0363, g_loss: 1.1091\n",
            "Step [78690/80000], d_real_loss: 0.0800, d_mnist_loss: 0.0568, d_svhn_loss: 0.0232, d_fake_loss: 0.0671, g_loss: 1.0134\n",
            "Step [78700/80000], d_real_loss: 0.0401, d_mnist_loss: 0.0177, d_svhn_loss: 0.0223, d_fake_loss: 0.0714, g_loss: 1.1366\n",
            "Step [78710/80000], d_real_loss: 0.0657, d_mnist_loss: 0.0294, d_svhn_loss: 0.0363, d_fake_loss: 0.0449, g_loss: 1.1799\n",
            "Step [78720/80000], d_real_loss: 0.0331, d_mnist_loss: 0.0151, d_svhn_loss: 0.0180, d_fake_loss: 0.0245, g_loss: 1.2146\n",
            "Step [78730/80000], d_real_loss: 0.0955, d_mnist_loss: 0.0152, d_svhn_loss: 0.0804, d_fake_loss: 0.0281, g_loss: 1.1609\n",
            "Step [78740/80000], d_real_loss: 0.1072, d_mnist_loss: 0.0490, d_svhn_loss: 0.0582, d_fake_loss: 0.0725, g_loss: 1.1987\n",
            "Step [78750/80000], d_real_loss: 0.0398, d_mnist_loss: 0.0169, d_svhn_loss: 0.0229, d_fake_loss: 0.0284, g_loss: 1.1512\n",
            "Step [78760/80000], d_real_loss: 0.0415, d_mnist_loss: 0.0223, d_svhn_loss: 0.0193, d_fake_loss: 0.1165, g_loss: 1.1243\n",
            "Step [78770/80000], d_real_loss: 0.0652, d_mnist_loss: 0.0331, d_svhn_loss: 0.0321, d_fake_loss: 0.0352, g_loss: 1.0280\n",
            "Step [78780/80000], d_real_loss: 0.0420, d_mnist_loss: 0.0203, d_svhn_loss: 0.0217, d_fake_loss: 0.0718, g_loss: 1.1547\n",
            "Step [78790/80000], d_real_loss: 0.0663, d_mnist_loss: 0.0204, d_svhn_loss: 0.0460, d_fake_loss: 0.1383, g_loss: 1.1009\n",
            "Step [78800/80000], d_real_loss: 0.0350, d_mnist_loss: 0.0177, d_svhn_loss: 0.0174, d_fake_loss: 0.0467, g_loss: 1.2157\n",
            "Step [78810/80000], d_real_loss: 0.0755, d_mnist_loss: 0.0529, d_svhn_loss: 0.0225, d_fake_loss: 0.0531, g_loss: 1.0201\n",
            "Step [78820/80000], d_real_loss: 0.0488, d_mnist_loss: 0.0214, d_svhn_loss: 0.0274, d_fake_loss: 0.0387, g_loss: 1.1536\n",
            "Step [78830/80000], d_real_loss: 0.0440, d_mnist_loss: 0.0262, d_svhn_loss: 0.0178, d_fake_loss: 0.0696, g_loss: 1.1382\n",
            "Step [78840/80000], d_real_loss: 0.0330, d_mnist_loss: 0.0179, d_svhn_loss: 0.0151, d_fake_loss: 0.0774, g_loss: 1.0153\n",
            "Step [78850/80000], d_real_loss: 0.0647, d_mnist_loss: 0.0292, d_svhn_loss: 0.0355, d_fake_loss: 0.0360, g_loss: 1.1904\n",
            "Step [78860/80000], d_real_loss: 0.0380, d_mnist_loss: 0.0180, d_svhn_loss: 0.0200, d_fake_loss: 0.0643, g_loss: 1.2972\n",
            "Step [78870/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0186, d_svhn_loss: 0.0197, d_fake_loss: 0.0360, g_loss: 1.1077\n",
            "Step [78880/80000], d_real_loss: 0.0655, d_mnist_loss: 0.0341, d_svhn_loss: 0.0313, d_fake_loss: 0.0493, g_loss: 1.2595\n",
            "Step [78890/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0196, d_svhn_loss: 0.0158, d_fake_loss: 0.0857, g_loss: 1.1248\n",
            "Step [78900/80000], d_real_loss: 0.0332, d_mnist_loss: 0.0117, d_svhn_loss: 0.0215, d_fake_loss: 0.0539, g_loss: 1.1315\n",
            "Step [78910/80000], d_real_loss: 0.0454, d_mnist_loss: 0.0186, d_svhn_loss: 0.0268, d_fake_loss: 0.0402, g_loss: 1.0407\n",
            "Step [78920/80000], d_real_loss: 0.0497, d_mnist_loss: 0.0291, d_svhn_loss: 0.0207, d_fake_loss: 0.0469, g_loss: 1.1769\n",
            "Step [78930/80000], d_real_loss: 0.0456, d_mnist_loss: 0.0198, d_svhn_loss: 0.0258, d_fake_loss: 0.0382, g_loss: 1.1666\n",
            "Step [78940/80000], d_real_loss: 0.1066, d_mnist_loss: 0.0736, d_svhn_loss: 0.0330, d_fake_loss: 0.0513, g_loss: 0.8876\n",
            "Step [78950/80000], d_real_loss: 0.0907, d_mnist_loss: 0.0683, d_svhn_loss: 0.0223, d_fake_loss: 0.0855, g_loss: 1.1626\n",
            "Step [78960/80000], d_real_loss: 0.0596, d_mnist_loss: 0.0388, d_svhn_loss: 0.0208, d_fake_loss: 0.0371, g_loss: 1.5181\n",
            "Step [78970/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0129, d_svhn_loss: 0.0225, d_fake_loss: 0.0447, g_loss: 1.1210\n",
            "Step [78980/80000], d_real_loss: 0.0365, d_mnist_loss: 0.0167, d_svhn_loss: 0.0199, d_fake_loss: 0.0412, g_loss: 1.1953\n",
            "Step [78990/80000], d_real_loss: 0.0810, d_mnist_loss: 0.0633, d_svhn_loss: 0.0177, d_fake_loss: 0.0602, g_loss: 0.9155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7313166856765747, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [79000/80000], d_real_loss: 0.0528, d_mnist_loss: 0.0355, d_svhn_loss: 0.0173, d_fake_loss: 0.0483, g_loss: 1.1538\n",
            "saved ./samples_fashion/sample-79000-m-s.png\n",
            "saved ./samples_fashion/sample-79000-s-m.png\n",
            "Step [79010/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0247, d_svhn_loss: 0.0425, d_fake_loss: 0.0319, g_loss: 1.1850\n",
            "Step [79020/80000], d_real_loss: 0.0277, d_mnist_loss: 0.0145, d_svhn_loss: 0.0133, d_fake_loss: 0.0448, g_loss: 1.1326\n",
            "Step [79030/80000], d_real_loss: 0.0645, d_mnist_loss: 0.0171, d_svhn_loss: 0.0474, d_fake_loss: 0.0408, g_loss: 1.1622\n",
            "Step [79040/80000], d_real_loss: 0.0690, d_mnist_loss: 0.0508, d_svhn_loss: 0.0182, d_fake_loss: 0.0534, g_loss: 1.0936\n",
            "Step [79050/80000], d_real_loss: 0.1672, d_mnist_loss: 0.0883, d_svhn_loss: 0.0789, d_fake_loss: 0.0596, g_loss: 1.3492\n",
            "Step [79060/80000], d_real_loss: 0.0511, d_mnist_loss: 0.0271, d_svhn_loss: 0.0241, d_fake_loss: 0.0794, g_loss: 1.0758\n",
            "Step [79070/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0246, d_svhn_loss: 0.0154, d_fake_loss: 0.0304, g_loss: 1.2898\n",
            "Step [79080/80000], d_real_loss: 0.0612, d_mnist_loss: 0.0323, d_svhn_loss: 0.0290, d_fake_loss: 0.0387, g_loss: 1.0569\n",
            "Step [79090/80000], d_real_loss: 0.0412, d_mnist_loss: 0.0280, d_svhn_loss: 0.0132, d_fake_loss: 0.0352, g_loss: 1.1239\n",
            "Step [79100/80000], d_real_loss: 0.0387, d_mnist_loss: 0.0240, d_svhn_loss: 0.0147, d_fake_loss: 0.0682, g_loss: 1.3259\n",
            "Step [79110/80000], d_real_loss: 0.0383, d_mnist_loss: 0.0232, d_svhn_loss: 0.0151, d_fake_loss: 0.0515, g_loss: 0.9780\n",
            "Step [79120/80000], d_real_loss: 0.0348, d_mnist_loss: 0.0157, d_svhn_loss: 0.0191, d_fake_loss: 0.0524, g_loss: 1.0986\n",
            "Step [79130/80000], d_real_loss: 0.0572, d_mnist_loss: 0.0326, d_svhn_loss: 0.0246, d_fake_loss: 0.0464, g_loss: 1.1680\n",
            "Step [79140/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0543, d_svhn_loss: 0.0401, d_fake_loss: 0.0520, g_loss: 1.2700\n",
            "Step [79150/80000], d_real_loss: 0.0729, d_mnist_loss: 0.0279, d_svhn_loss: 0.0450, d_fake_loss: 0.0417, g_loss: 1.0851\n",
            "Step [79160/80000], d_real_loss: 0.1050, d_mnist_loss: 0.0627, d_svhn_loss: 0.0424, d_fake_loss: 0.0450, g_loss: 1.0563\n",
            "Step [79170/80000], d_real_loss: 0.0327, d_mnist_loss: 0.0107, d_svhn_loss: 0.0220, d_fake_loss: 0.0327, g_loss: 1.2083\n",
            "Step [79180/80000], d_real_loss: 0.0414, d_mnist_loss: 0.0112, d_svhn_loss: 0.0303, d_fake_loss: 0.0358, g_loss: 1.1217\n",
            "Step [79190/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0183, d_svhn_loss: 0.0310, d_fake_loss: 0.0315, g_loss: 1.0945\n",
            "Step [79200/80000], d_real_loss: 0.0377, d_mnist_loss: 0.0233, d_svhn_loss: 0.0144, d_fake_loss: 0.0331, g_loss: 1.0383\n",
            "Step [79210/80000], d_real_loss: 0.0752, d_mnist_loss: 0.0283, d_svhn_loss: 0.0469, d_fake_loss: 0.0691, g_loss: 0.9741\n",
            "Step [79220/80000], d_real_loss: 0.0762, d_mnist_loss: 0.0133, d_svhn_loss: 0.0630, d_fake_loss: 0.0669, g_loss: 1.0674\n",
            "Step [79230/80000], d_real_loss: 0.0485, d_mnist_loss: 0.0229, d_svhn_loss: 0.0255, d_fake_loss: 0.0244, g_loss: 1.1458\n",
            "Step [79240/80000], d_real_loss: 0.0369, d_mnist_loss: 0.0209, d_svhn_loss: 0.0161, d_fake_loss: 0.0631, g_loss: 1.2221\n",
            "Step [79250/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0170, d_svhn_loss: 0.0230, d_fake_loss: 0.0369, g_loss: 1.0818\n",
            "Step [79260/80000], d_real_loss: 0.0347, d_mnist_loss: 0.0188, d_svhn_loss: 0.0160, d_fake_loss: 0.0576, g_loss: 1.1306\n",
            "Step [79270/80000], d_real_loss: 0.0475, d_mnist_loss: 0.0290, d_svhn_loss: 0.0185, d_fake_loss: 0.1022, g_loss: 1.1735\n",
            "Step [79280/80000], d_real_loss: 0.0476, d_mnist_loss: 0.0271, d_svhn_loss: 0.0206, d_fake_loss: 0.0289, g_loss: 1.1253\n",
            "Step [79290/80000], d_real_loss: 0.0450, d_mnist_loss: 0.0191, d_svhn_loss: 0.0259, d_fake_loss: 0.0743, g_loss: 1.2337\n",
            "Step [79300/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0411, d_svhn_loss: 0.0292, d_fake_loss: 0.0290, g_loss: 1.0165\n",
            "Step [79310/80000], d_real_loss: 0.0513, d_mnist_loss: 0.0238, d_svhn_loss: 0.0275, d_fake_loss: 0.0342, g_loss: 1.1445\n",
            "Step [79320/80000], d_real_loss: 0.0354, d_mnist_loss: 0.0156, d_svhn_loss: 0.0197, d_fake_loss: 0.0255, g_loss: 1.1856\n",
            "Step [79330/80000], d_real_loss: 0.0523, d_mnist_loss: 0.0212, d_svhn_loss: 0.0311, d_fake_loss: 0.0310, g_loss: 1.0594\n",
            "Step [79340/80000], d_real_loss: 0.0600, d_mnist_loss: 0.0308, d_svhn_loss: 0.0291, d_fake_loss: 0.0771, g_loss: 1.1846\n",
            "Step [79350/80000], d_real_loss: 0.1110, d_mnist_loss: 0.0417, d_svhn_loss: 0.0693, d_fake_loss: 0.0740, g_loss: 1.0689\n",
            "Step [79360/80000], d_real_loss: 0.0378, d_mnist_loss: 0.0264, d_svhn_loss: 0.0114, d_fake_loss: 0.0281, g_loss: 1.1571\n",
            "Step [79370/80000], d_real_loss: 0.0487, d_mnist_loss: 0.0286, d_svhn_loss: 0.0202, d_fake_loss: 0.0567, g_loss: 1.1769\n",
            "Step [79380/80000], d_real_loss: 0.0287, d_mnist_loss: 0.0115, d_svhn_loss: 0.0172, d_fake_loss: 0.0572, g_loss: 1.2438\n",
            "Step [79390/80000], d_real_loss: 0.0435, d_mnist_loss: 0.0181, d_svhn_loss: 0.0255, d_fake_loss: 0.0288, g_loss: 1.1057\n",
            "Step [79400/80000], d_real_loss: 0.1378, d_mnist_loss: 0.1025, d_svhn_loss: 0.0352, d_fake_loss: 0.1047, g_loss: 1.1556\n",
            "Step [79410/80000], d_real_loss: 0.0425, d_mnist_loss: 0.0192, d_svhn_loss: 0.0233, d_fake_loss: 0.0797, g_loss: 1.2072\n",
            "Step [79420/80000], d_real_loss: 0.0319, d_mnist_loss: 0.0159, d_svhn_loss: 0.0160, d_fake_loss: 0.0254, g_loss: 1.1966\n",
            "Step [79430/80000], d_real_loss: 0.0944, d_mnist_loss: 0.0552, d_svhn_loss: 0.0392, d_fake_loss: 0.0636, g_loss: 1.1643\n",
            "Step [79440/80000], d_real_loss: 0.1025, d_mnist_loss: 0.0473, d_svhn_loss: 0.0553, d_fake_loss: 0.0615, g_loss: 0.9921\n",
            "Step [79450/80000], d_real_loss: 0.0437, d_mnist_loss: 0.0220, d_svhn_loss: 0.0216, d_fake_loss: 0.0640, g_loss: 1.3064\n",
            "Step [79460/80000], d_real_loss: 0.1664, d_mnist_loss: 0.0517, d_svhn_loss: 0.1148, d_fake_loss: 0.0593, g_loss: 1.0654\n",
            "Step [79470/80000], d_real_loss: 0.0945, d_mnist_loss: 0.0768, d_svhn_loss: 0.0177, d_fake_loss: 0.1176, g_loss: 1.1931\n",
            "Step [79480/80000], d_real_loss: 0.0466, d_mnist_loss: 0.0249, d_svhn_loss: 0.0217, d_fake_loss: 0.0924, g_loss: 1.1584\n",
            "Step [79490/80000], d_real_loss: 0.0346, d_mnist_loss: 0.0179, d_svhn_loss: 0.0167, d_fake_loss: 0.0495, g_loss: 1.1929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.716393232345581, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [79500/80000], d_real_loss: 0.1261, d_mnist_loss: 0.0870, d_svhn_loss: 0.0391, d_fake_loss: 0.1042, g_loss: 1.0240\n",
            "saved ./samples_fashion/sample-79500-m-s.png\n",
            "saved ./samples_fashion/sample-79500-s-m.png\n",
            "Step [79510/80000], d_real_loss: 0.0464, d_mnist_loss: 0.0259, d_svhn_loss: 0.0204, d_fake_loss: 0.0289, g_loss: 1.1134\n",
            "Step [79520/80000], d_real_loss: 0.0820, d_mnist_loss: 0.0254, d_svhn_loss: 0.0566, d_fake_loss: 0.0536, g_loss: 1.1668\n",
            "Step [79530/80000], d_real_loss: 0.0449, d_mnist_loss: 0.0163, d_svhn_loss: 0.0286, d_fake_loss: 0.0365, g_loss: 1.1207\n",
            "Step [79540/80000], d_real_loss: 0.0672, d_mnist_loss: 0.0203, d_svhn_loss: 0.0469, d_fake_loss: 0.0389, g_loss: 1.2329\n",
            "Step [79550/80000], d_real_loss: 0.0544, d_mnist_loss: 0.0244, d_svhn_loss: 0.0300, d_fake_loss: 0.0287, g_loss: 1.1364\n",
            "Step [79560/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0188, d_svhn_loss: 0.0398, d_fake_loss: 0.0372, g_loss: 1.1476\n",
            "Step [79570/80000], d_real_loss: 0.0957, d_mnist_loss: 0.0333, d_svhn_loss: 0.0624, d_fake_loss: 0.0208, g_loss: 1.1951\n",
            "Step [79580/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0293, d_svhn_loss: 0.0375, d_fake_loss: 0.0243, g_loss: 1.1607\n",
            "Step [79590/80000], d_real_loss: 0.0586, d_mnist_loss: 0.0364, d_svhn_loss: 0.0222, d_fake_loss: 0.0226, g_loss: 1.0545\n",
            "Step [79600/80000], d_real_loss: 0.0518, d_mnist_loss: 0.0351, d_svhn_loss: 0.0167, d_fake_loss: 0.0712, g_loss: 1.4844\n",
            "Step [79610/80000], d_real_loss: 0.0780, d_mnist_loss: 0.0263, d_svhn_loss: 0.0517, d_fake_loss: 0.0828, g_loss: 1.2516\n",
            "Step [79620/80000], d_real_loss: 0.0286, d_mnist_loss: 0.0151, d_svhn_loss: 0.0135, d_fake_loss: 0.0531, g_loss: 1.4007\n",
            "Step [79630/80000], d_real_loss: 0.0400, d_mnist_loss: 0.0222, d_svhn_loss: 0.0178, d_fake_loss: 0.0585, g_loss: 1.3420\n",
            "Step [79640/80000], d_real_loss: 0.0582, d_mnist_loss: 0.0406, d_svhn_loss: 0.0177, d_fake_loss: 0.0518, g_loss: 1.1007\n",
            "Step [79650/80000], d_real_loss: 0.0503, d_mnist_loss: 0.0205, d_svhn_loss: 0.0298, d_fake_loss: 0.0469, g_loss: 1.2306\n",
            "Step [79660/80000], d_real_loss: 0.0882, d_mnist_loss: 0.0757, d_svhn_loss: 0.0125, d_fake_loss: 0.1543, g_loss: 0.9298\n",
            "Step [79670/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0125, d_svhn_loss: 0.0315, d_fake_loss: 0.0577, g_loss: 1.0809\n",
            "Step [79680/80000], d_real_loss: 0.0668, d_mnist_loss: 0.0208, d_svhn_loss: 0.0460, d_fake_loss: 0.0277, g_loss: 1.0822\n",
            "Step [79690/80000], d_real_loss: 0.0482, d_mnist_loss: 0.0161, d_svhn_loss: 0.0321, d_fake_loss: 0.0631, g_loss: 1.1825\n",
            "Step [79700/80000], d_real_loss: 0.0721, d_mnist_loss: 0.0153, d_svhn_loss: 0.0569, d_fake_loss: 0.1036, g_loss: 1.2657\n",
            "Step [79710/80000], d_real_loss: 0.0685, d_mnist_loss: 0.0133, d_svhn_loss: 0.0552, d_fake_loss: 0.0289, g_loss: 1.0925\n",
            "Step [79720/80000], d_real_loss: 0.1016, d_mnist_loss: 0.0294, d_svhn_loss: 0.0722, d_fake_loss: 0.0568, g_loss: 1.1411\n",
            "Step [79730/80000], d_real_loss: 0.0344, d_mnist_loss: 0.0160, d_svhn_loss: 0.0183, d_fake_loss: 0.0819, g_loss: 1.2784\n",
            "Step [79740/80000], d_real_loss: 0.0493, d_mnist_loss: 0.0263, d_svhn_loss: 0.0230, d_fake_loss: 0.0712, g_loss: 1.2184\n",
            "Step [79750/80000], d_real_loss: 0.0386, d_mnist_loss: 0.0150, d_svhn_loss: 0.0236, d_fake_loss: 0.1154, g_loss: 1.2986\n",
            "Step [79760/80000], d_real_loss: 0.0629, d_mnist_loss: 0.0203, d_svhn_loss: 0.0426, d_fake_loss: 0.0202, g_loss: 1.2089\n",
            "Step [79770/80000], d_real_loss: 0.0392, d_mnist_loss: 0.0124, d_svhn_loss: 0.0269, d_fake_loss: 0.0334, g_loss: 1.1464\n",
            "Step [79780/80000], d_real_loss: 0.0628, d_mnist_loss: 0.0154, d_svhn_loss: 0.0474, d_fake_loss: 0.0453, g_loss: 1.2585\n",
            "Step [79790/80000], d_real_loss: 0.0546, d_mnist_loss: 0.0241, d_svhn_loss: 0.0305, d_fake_loss: 0.0511, g_loss: 1.1918\n",
            "Step [79800/80000], d_real_loss: 0.0642, d_mnist_loss: 0.0194, d_svhn_loss: 0.0448, d_fake_loss: 0.0401, g_loss: 1.1886\n",
            "Step [79810/80000], d_real_loss: 0.0442, d_mnist_loss: 0.0199, d_svhn_loss: 0.0243, d_fake_loss: 0.0593, g_loss: 1.2293\n",
            "Step [79820/80000], d_real_loss: 0.1186, d_mnist_loss: 0.0310, d_svhn_loss: 0.0876, d_fake_loss: 0.0522, g_loss: 1.1286\n",
            "Step [79830/80000], d_real_loss: 0.0554, d_mnist_loss: 0.0194, d_svhn_loss: 0.0359, d_fake_loss: 0.0397, g_loss: 1.2305\n",
            "Step [79840/80000], d_real_loss: 0.0373, d_mnist_loss: 0.0168, d_svhn_loss: 0.0205, d_fake_loss: 0.0696, g_loss: 1.1552\n",
            "Step [79850/80000], d_real_loss: 0.0461, d_mnist_loss: 0.0245, d_svhn_loss: 0.0216, d_fake_loss: 0.0385, g_loss: 1.1574\n",
            "Step [79860/80000], d_real_loss: 0.0563, d_mnist_loss: 0.0341, d_svhn_loss: 0.0222, d_fake_loss: 0.0987, g_loss: 1.0041\n",
            "Step [79870/80000], d_real_loss: 0.0509, d_mnist_loss: 0.0226, d_svhn_loss: 0.0283, d_fake_loss: 0.0315, g_loss: 1.1733\n",
            "Step [79880/80000], d_real_loss: 0.0329, d_mnist_loss: 0.0109, d_svhn_loss: 0.0221, d_fake_loss: 0.0214, g_loss: 1.1335\n",
            "Step [79890/80000], d_real_loss: 0.0658, d_mnist_loss: 0.0325, d_svhn_loss: 0.0333, d_fake_loss: 0.0395, g_loss: 1.1041\n",
            "Step [79900/80000], d_real_loss: 0.0489, d_mnist_loss: 0.0230, d_svhn_loss: 0.0259, d_fake_loss: 0.0691, g_loss: 1.1951\n",
            "Step [79910/80000], d_real_loss: 0.0341, d_mnist_loss: 0.0219, d_svhn_loss: 0.0121, d_fake_loss: 0.0406, g_loss: 1.2081\n",
            "Step [79920/80000], d_real_loss: 0.0439, d_mnist_loss: 0.0168, d_svhn_loss: 0.0271, d_fake_loss: 0.0321, g_loss: 1.1624\n",
            "Step [79930/80000], d_real_loss: 0.0524, d_mnist_loss: 0.0326, d_svhn_loss: 0.0198, d_fake_loss: 0.0499, g_loss: 1.0274\n",
            "Step [79940/80000], d_real_loss: 0.0616, d_mnist_loss: 0.0249, d_svhn_loss: 0.0368, d_fake_loss: 0.0888, g_loss: 1.3360\n",
            "Step [79950/80000], d_real_loss: 0.0530, d_mnist_loss: 0.0342, d_svhn_loss: 0.0188, d_fake_loss: 0.0365, g_loss: 1.0005\n",
            "Step [79960/80000], d_real_loss: 0.0555, d_mnist_loss: 0.0142, d_svhn_loss: 0.0412, d_fake_loss: 0.0344, g_loss: 1.0700\n",
            "Step [79970/80000], d_real_loss: 0.0403, d_mnist_loss: 0.0191, d_svhn_loss: 0.0212, d_fake_loss: 0.1382, g_loss: 1.3889\n",
            "Step [79980/80000], d_real_loss: 0.0720, d_mnist_loss: 0.0121, d_svhn_loss: 0.0600, d_fake_loss: 0.1321, g_loss: 1.0690\n",
            "Step [79990/80000], d_real_loss: 0.0506, d_mnist_loss: 0.0213, d_svhn_loss: 0.0293, d_fake_loss: 0.0432, g_loss: 1.2139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.7544829845428467, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [80000/80000], d_real_loss: 0.0703, d_mnist_loss: 0.0160, d_svhn_loss: 0.0543, d_fake_loss: 0.0348, g_loss: 1.1194\n",
            "saved ./samples_fashion/sample-80000-m-s.png\n",
            "saved ./samples_fashion/sample-80000-s-m.png\n"
          ]
        }
      ],
      "source": [
        "d_real_loss_list1, d_mnist_loss_list1, d_svhn_loss_list1, d_fake_loss_list1, g_loss_list1 = train(fashion_loader, Fashionmnist_loader, sample_path=sample_path2, model_path=model_path2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Plot the loss results* "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "vpCo2tdasSAL",
        "outputId": "4568d65e-6f8b-4360-ecaa-38e0c3a22639"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "classes = [d_real_loss_list1,d_mnist_loss_list1,d_svhn_loss_list1,d_fake_loss_list1,g_loss_list1]\n",
        "labels = ['d_real_loss','d_mnist_loss','d_svhn_loss','d_fake_loss','g_loss']\n",
        "\n",
        "for plt_index in range(1,6):\n",
        "    ax = fig.add_subplot(3,2,plt_index)\n",
        "    plt.plot(range(train_iters+1), classes[plt_index-1], label = labels[plt_index-1])\n",
        "    plt.xlabel(\"iters\")\n",
        "    plt.ylabel(\"loss values\")\n",
        "    pass\n",
        "\n",
        "plt.title(\"The figure of loss in transformation betweem fashionmnist and small fashion product images\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "024464c2b39c4f75bea37fb2e838e487": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0262a1fa4d484af08bb470fdb5ce78ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0460c1b1009d40d587d64b88e7ff1172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0262a1fa4d484af08bb470fdb5ce78ae",
            "max": 4422102,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eee2dbf7e8474a2793b24facba444164",
            "value": 4422102
          }
        },
        "04c779916f08432bbaba5331856c478d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070056be423c4e92a42d991386ca2b75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bbb1a696d0e459d85407e797ec98aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11b9cf716cae496eb6681064630c53f1",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cec282bc878a4dd7a47146b35d149aa0",
            "value": 9912422
          }
        },
        "0ce286599d59446e9f9c1740a6110438": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1079999e90e4f2893b2ef5a9f92ec0a",
            "placeholder": "​",
            "style": "IPY_MODEL_d76c3a8ebb9940129dcf0666fd9d6ff6",
            "value": " 182040794/182040794 [00:03&lt;00:00, 62662898.24it/s]"
          }
        },
        "0d572a2d14b849958bf9769201883d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fec1020d4ba47039df35e6c7e8cf35d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11b9cf716cae496eb6681064630c53f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1718ae104c0f424192e82c8610317c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "197ab77e841b4fbe8078b4b4fb1da1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba2627bae08419297d628a0c88a566e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d0c8a0b43474db8a8cf6021cde89fba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d25b63c7bc14828b8334b934c4d0b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20849f9d84694715898811b94e4f26fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b36a629381f64e8689d9ad7776152bb4",
            "placeholder": "​",
            "style": "IPY_MODEL_c082c2579a804ba18f772c421041fd22",
            "value": " 29515/29515 [00:00&lt;00:00, 206550.29it/s]"
          }
        },
        "20eb3d40c9b2474987da694fdfb422e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2335781a1c9e451888e00e4552dcb68b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "241b44a4e794488ab1a14366409f5921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fc7cfe45bbd4bcd90ed72c7901b2c3d",
              "IPY_MODEL_3a5c68b8ec234f12ba5ea654dd095a7d",
              "IPY_MODEL_2d0aaeef4f7c411e97a45397cc035e0a"
            ],
            "layout": "IPY_MODEL_04c779916f08432bbaba5331856c478d"
          }
        },
        "27cdd0152cb1498d8ef213828f933821": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dab0463e26b84f1c94acdde847c5c4e5",
            "placeholder": "​",
            "style": "IPY_MODEL_93c3e990699a46889bbb96cd3117825d",
            "value": "100%"
          }
        },
        "2a510f199a19429ba186a423ac239a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e7e5767dbcc4d4681efeb993e53ba47",
            "placeholder": "​",
            "style": "IPY_MODEL_35ba1f69f6eb446f8cdafbc5b72128ce",
            "value": " 9912422/9912422 [00:00&lt;00:00, 11514775.36it/s]"
          }
        },
        "2b457e1e39164137a20fc1b5dc9364c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dddbbdbd1b44508b844e14a07c543e3",
              "IPY_MODEL_34e17eb71c184391a6715d07bdfd7046",
              "IPY_MODEL_3b0091c989024cf6a05ee7fd5a44f3c7"
            ],
            "layout": "IPY_MODEL_d2503080e5cf4189b24bf66aac683246"
          }
        },
        "2d0aaeef4f7c411e97a45397cc035e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_024464c2b39c4f75bea37fb2e838e487",
            "placeholder": "​",
            "style": "IPY_MODEL_a3404d41b07e4c7da789d04d56b8551b",
            "value": " 5148/5148 [00:00&lt;00:00, 221017.22it/s]"
          }
        },
        "2e255a7b46c04e289700625b111af01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e7dfc1e331c48c8a886009e91f05983": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34e17eb71c184391a6715d07bdfd7046": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b789f24ad54956a0e638f3a15a5314",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9be12fa3615846f08cc5823f08462996",
            "value": 4542
          }
        },
        "35ba1f69f6eb446f8cdafbc5b72128ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a5c68b8ec234f12ba5ea654dd095a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba2627bae08419297d628a0c88a566e",
            "max": 5148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2335781a1c9e451888e00e4552dcb68b",
            "value": 5148
          }
        },
        "3b0091c989024cf6a05ee7fd5a44f3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84fe62b6b9bc4a1b838277e0c8991e60",
            "placeholder": "​",
            "style": "IPY_MODEL_3ce57a293edc4fb98358c3d332d79a42",
            "value": " 4542/4542 [00:00&lt;00:00, 208002.45it/s]"
          }
        },
        "3b41aad9d49146a283b344281e029dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b50d03b930f4a6dbe052b13cc25abe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcef9c0e4e82437f81e65473741b3edc",
            "placeholder": "​",
            "style": "IPY_MODEL_0d572a2d14b849958bf9769201883d7c",
            "value": "100%"
          }
        },
        "3ce57a293edc4fb98358c3d332d79a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ddd790981cd47378ad7163d3072ea8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dddbbdbd1b44508b844e14a07c543e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_070056be423c4e92a42d991386ca2b75",
            "placeholder": "​",
            "style": "IPY_MODEL_81d37efa74104fe1ba1bdeb48ef75bc1",
            "value": "100%"
          }
        },
        "40dc87c29ddf4b5492c9cd4815901dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4553930f4234235869c97bd984f60d1",
            "placeholder": "​",
            "style": "IPY_MODEL_1d25b63c7bc14828b8334b934c4d0b0a",
            "value": "100%"
          }
        },
        "49323395137a4d52bf640b1c7017e940": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c50c572641945ac8768b3eedb3fd839": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_197ab77e841b4fbe8078b4b4fb1da1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_96c9a0500aa0471396e5b55bbf6c0dc3",
            "value": " 1648877/1648877 [00:00&lt;00:00, 5818725.95it/s]"
          }
        },
        "561ab4b73e9b4574926af119007ec1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0d940c26774469bbb5597af870b6daf",
              "IPY_MODEL_0bbb1a696d0e459d85407e797ec98aa7",
              "IPY_MODEL_2a510f199a19429ba186a423ac239a30"
            ],
            "layout": "IPY_MODEL_6887d0c8b4a3493f8d3d8c40f93c937e"
          }
        },
        "5928acdae82347faa204c867d77fd548": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ae1a283beb640d89bc8af1e561488f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cdf44cd04a34b81bdd0c7bb3349c9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf121e25b6f461998cc4d88881a99e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ddd790981cd47378ad7163d3072ea8a",
            "max": 26421880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ae1a283beb640d89bc8af1e561488f0",
            "value": 26421880
          }
        },
        "5fc7cfe45bbd4bcd90ed72c7901b2c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7faff432e19a4ec9a31688b5875b4fca",
            "placeholder": "​",
            "style": "IPY_MODEL_20eb3d40c9b2474987da694fdfb422e2",
            "value": "100%"
          }
        },
        "64009ebb36d4444aa5fa9138f57795f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "644aecb3d2fd46d4bb716d9cea3379aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ffbde9cd2e4be3a98e488feb0efaa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d0c8a0b43474db8a8cf6021cde89fba",
            "placeholder": "​",
            "style": "IPY_MODEL_2e7dfc1e331c48c8a886009e91f05983",
            "value": " 28881/28881 [00:00&lt;00:00, 1190768.55it/s]"
          }
        },
        "6887d0c8b4a3493f8d3d8c40f93c937e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a294c33d65b4a9ca4e2167a99a3ae4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7e5767dbcc4d4681efeb993e53ba47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "701c97f1148b4a28bed01b9bec9e8966": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad20095203f84e3485d69d721bcd142e",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d51f2f07bfcb44ddadf77b1de7ab0fbe",
            "value": 28881
          }
        },
        "76d5f8651f5d4ad98c63f63278c95a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "785d9a8de5134c8cb7b2ff376e28e2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40dc87c29ddf4b5492c9cd4815901dfa",
              "IPY_MODEL_0460c1b1009d40d587d64b88e7ff1172",
              "IPY_MODEL_99a7609660564bbd81350c1d515ce0c7"
            ],
            "layout": "IPY_MODEL_e8b177753bf2412197a026a2fa4ef3bb"
          }
        },
        "7faff432e19a4ec9a31688b5875b4fca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80776282337c46f2b39bd402c00aa263": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81d37efa74104fe1ba1bdeb48ef75bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84fe62b6b9bc4a1b838277e0c8991e60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fae1f3fe11472da459818c8ff50bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b15e290882b44859365a0ffddb3aad4",
              "IPY_MODEL_85fb547ba22f4424a9a68638c41946d7",
              "IPY_MODEL_4c50c572641945ac8768b3eedb3fd839"
            ],
            "layout": "IPY_MODEL_5cdf44cd04a34b81bdd0c7bb3349c9ee"
          }
        },
        "85fb547ba22f4424a9a68638c41946d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dedb58dd62df4493841ad00a51d7b347",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1718ae104c0f424192e82c8610317c9c",
            "value": 1648877
          }
        },
        "8b15e290882b44859365a0ffddb3aad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f007362cae584e94bac74f91c3879715",
            "placeholder": "​",
            "style": "IPY_MODEL_2e255a7b46c04e289700625b111af01e",
            "value": "100%"
          }
        },
        "8fc8052595734712867bd44cfd7d0102": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93c3e990699a46889bbb96cd3117825d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96c9a0500aa0471396e5b55bbf6c0dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98445261432247aa864f6648fc733347": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91f267d7ec745dca0ef9e1cbaee758e",
            "placeholder": "​",
            "style": "IPY_MODEL_76d5f8651f5d4ad98c63f63278c95a1f",
            "value": "100%"
          }
        },
        "99a7609660564bbd81350c1d515ce0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644aecb3d2fd46d4bb716d9cea3379aa",
            "placeholder": "​",
            "style": "IPY_MODEL_8fc8052595734712867bd44cfd7d0102",
            "value": " 4422102/4422102 [00:01&lt;00:00, 6655417.13it/s]"
          }
        },
        "9b1393b1adf7452fbfd1b70501d6154a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9be12fa3615846f08cc5823f08462996": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9be35c985e1844598095d7b0ad9b2231": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b22237dd6e4726ad1ea71bd3295bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b50d03b930f4a6dbe052b13cc25abe4",
              "IPY_MODEL_701c97f1148b4a28bed01b9bec9e8966",
              "IPY_MODEL_64ffbde9cd2e4be3a98e488feb0efaa9"
            ],
            "layout": "IPY_MODEL_5928acdae82347faa204c867d77fd548"
          }
        },
        "a3404d41b07e4c7da789d04d56b8551b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaeab01448df4b9398941b0732ff5963": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad20095203f84e3485d69d721bcd142e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36a629381f64e8689d9ad7776152bb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c32f318a8a4db2830a7781f08baa0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a294c33d65b4a9ca4e2167a99a3ae4a",
            "placeholder": "​",
            "style": "IPY_MODEL_ec9f50bbbaa544679570b24d34058347",
            "value": " 26421880/26421880 [00:02&lt;00:00, 20403204.29it/s]"
          }
        },
        "b6177b05518643d18070ad9c9d68fd7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b41aad9d49146a283b344281e029dd2",
            "max": 182040794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c70115c6582743a5bbc3b38db8a76635",
            "value": 182040794
          }
        },
        "b725f13af4464aa98cb65f087673cd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27cdd0152cb1498d8ef213828f933821",
              "IPY_MODEL_5cf121e25b6f461998cc4d88881a99e0",
              "IPY_MODEL_b3c32f318a8a4db2830a7781f08baa0e"
            ],
            "layout": "IPY_MODEL_0fec1020d4ba47039df35e6c7e8cf35d"
          }
        },
        "b8b789f24ad54956a0e638f3a15a5314": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b91f267d7ec745dca0ef9e1cbaee758e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcef9c0e4e82437f81e65473741b3edc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c082c2579a804ba18f772c421041fd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0d940c26774469bbb5597af870b6daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64009ebb36d4444aa5fa9138f57795f8",
            "placeholder": "​",
            "style": "IPY_MODEL_c9f5d8edcd7145df98170e4f286216a6",
            "value": "100%"
          }
        },
        "c4553930f4234235869c97bd984f60d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c70115c6582743a5bbc3b38db8a76635": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7fa1d70aaf54d00849f2935200ccd18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9be35c985e1844598095d7b0ad9b2231",
            "placeholder": "​",
            "style": "IPY_MODEL_c9f955df43174d6c869613cb249916e9",
            "value": "100%"
          }
        },
        "c898205ecbe94fdca3ed32633e566dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7fa1d70aaf54d00849f2935200ccd18",
              "IPY_MODEL_eb62930646634f049c448098eb58fb2d",
              "IPY_MODEL_20849f9d84694715898811b94e4f26fc"
            ],
            "layout": "IPY_MODEL_49323395137a4d52bf640b1c7017e940"
          }
        },
        "c9f5d8edcd7145df98170e4f286216a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9f955df43174d6c869613cb249916e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce998c5b1f544057999c9e174e072370": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98445261432247aa864f6648fc733347",
              "IPY_MODEL_b6177b05518643d18070ad9c9d68fd7b",
              "IPY_MODEL_0ce286599d59446e9f9c1740a6110438"
            ],
            "layout": "IPY_MODEL_80776282337c46f2b39bd402c00aa263"
          }
        },
        "cec282bc878a4dd7a47146b35d149aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2503080e5cf4189b24bf66aac683246": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d51f2f07bfcb44ddadf77b1de7ab0fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d76c3a8ebb9940129dcf0666fd9d6ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dab0463e26b84f1c94acdde847c5c4e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dedb58dd62df4493841ad00a51d7b347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1079999e90e4f2893b2ef5a9f92ec0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b177753bf2412197a026a2fa4ef3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb62930646634f049c448098eb58fb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaeab01448df4b9398941b0732ff5963",
            "max": 29515,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b1393b1adf7452fbfd1b70501d6154a",
            "value": 29515
          }
        },
        "ec9f50bbbaa544679570b24d34058347": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eee2dbf7e8474a2793b24facba444164": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f007362cae584e94bac74f91c3879715": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
