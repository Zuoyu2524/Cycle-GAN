{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zuoyu2524/Cycle-GAN/blob/main/CycleGans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img\n",
        "src=\"https://www.imt-atlantique.fr/sites/default/files/Images/Ecole/charte-graphique/IMT_Atlantique_logo_RVB_Baseline_400x272.jpg\"\n",
        "WIDTH=235 HEIGHT=180>\n",
        "\n",
        "<div align='center' >\n",
        "\n",
        "<font size=\"8\"> Final Project of Class Deep Learning</font>\n",
        "\n",
        "<font size=\"5\"> Students Name: Zuoyu Zhang and Xingyuan Kang</font>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "KPrfYY_pxOyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part1 Data pre-processing and importing**"
      ],
      "metadata": {
        "id": "Ug_eCFYzyt1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgXjDK14zDmC",
        "outputId": "4c1fb2b3-c8fd-404e-edd0-c100e41ddb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSBI-oQmzOKF",
        "outputId": "e9688b73-5dc7-4157-eb97-eeb7b7e0f46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from pathlib import Path\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "coYDySmX6aD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqmyMAjJiyTc"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.Resize((32,32)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "            ])\n",
        "        images_path = Path(root)\n",
        "\n",
        "        images_list = list(images_path.glob('*.jpg')) # list(images_path.glob('*.png'))\n",
        "        images_list_str = [ str(x) for x in images_list ]\n",
        "        self.images = images_list_str\n",
        "\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image_path = self.images[item]\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #transform to the RGB\n",
        "        #At this point the image is in the order H,W,C, so the following needs to be transformed into: C, H, W\n",
        "        #Normalize [0, 1] to be consistent with the data read by PIL\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)/255\n",
        "\n",
        "        label = 1 if 'dog' in image_path.split('\\\\')[-1] else 0 # 这是一个label的示例，可自定义\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DF5vgn-iyTi"
      },
      "outputs": [],
      "source": [
        "def get_loader_fashion(image_size, batch_size, num_workers):\n",
        "    \"\"\"Builds and returns Dataloader for Fashion MNIST dataset.\"\"\"\n",
        "    transform = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "\n",
        "    Fashionmnist = datasets.FashionMNIST(root='./Fashionmnist', download=True, transform=transform)\n",
        "\n",
        "\n",
        "    Fashionmnist_loader = torch.utils.data.DataLoader(dataset=Fashionmnist,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          drop_last=True,\n",
        "                          num_workers=num_workers)\n",
        "    return Fashionmnist_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba5dC_ROB3o_"
      },
      "outputs": [],
      "source": [
        "def get_loader(image_size, batch_size, num_workers):\n",
        "    \"\"\"Builds and returns Dataloader for MNIST and SVHN dataset.\"\"\"\n",
        "    transform = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    transform1 = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "    svhn = datasets.SVHN(root='./svhn', download=True, transform=transform)\n",
        "    mnist = datasets.MNIST(root='./mnist', download=True, transform=transform1)\n",
        "\n",
        "    svhn_loader = torch.utils.data.DataLoader(dataset=svhn,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=num_workers)\n",
        "\n",
        "    mnist_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=num_workers)\n",
        "    return svhn_loader, mnist_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww9Ufmt7dFk-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixUYLO0EiyTm"
      },
      "outputs": [],
      "source": [
        "#model hyper-parameters using for creating dataloder\n",
        "image_size=32\n",
        "num_workers=2\n",
        "batch_size=64\n",
        "#Initiate the hyper-parameters for modeling and training\n",
        "use_reconst_loss = True\n",
        "use_labels = False\n",
        "num_classes = 10\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "g_conv_dim = 64\n",
        "d_conv_dim = 64\n",
        "train_iters = 60000\n",
        "lr = 0.0002\n",
        "log_step = 10\n",
        "sample_step = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_f8bOtHdHUO"
      },
      "outputs": [],
      "source": [
        "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom deconvolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rKfUCwSdIXX"
      },
      "outputs": [],
      "source": [
        "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
        "    \"\"\"Custom convolutional layer for simplicity.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
        "    if bn:\n",
        "        layers.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3SZr9P5eTCf"
      },
      "outputs": [],
      "source": [
        "class G12(nn.Module):\n",
        "    \"\"\"Generator for transfering from mnist to svhn\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G12, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(1, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "\n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "\n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 3, 4, bn=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n",
        "\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    # ( \" )\n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    # ( \" )\n",
        "\n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out))              # (?, 3, 32, 32)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhcaXSsOeXuQ"
      },
      "outputs": [],
      "source": [
        "class G21(nn.Module):\n",
        "    \"\"\"Generator for transfering from svhn to mnist\"\"\"\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(G21, self).__init__()\n",
        "        # encoding blocks\n",
        "        self.conv1 = conv(3, conv_dim, 4)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "\n",
        "        # residual blocks\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n",
        "\n",
        "        # decoding blocks\n",
        "        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n",
        "        self.deconv2 = deconv(conv_dim, 1, 4, bn=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n",
        "\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)    # ( \" )\n",
        "        out = F.leaky_relu(self.conv4(out), 0.05)    # ( \" )\n",
        "\n",
        "        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n",
        "        out = F.tanh(self.deconv2(out))              # (?, 1, 32, 32)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fta1wjhgebQw"
      },
      "outputs": [],
      "source": [
        "class D1(nn.Module):\n",
        "    \"\"\"Discriminator for mnist.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D1, self).__init__()\n",
        "        self.conv1 = conv(1, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-38bCORpDvwa"
      },
      "outputs": [],
      "source": [
        "class D2(nn.Module):\n",
        "    \"\"\"Discriminator for svhn.\"\"\"\n",
        "    def __init__(self, conv_dim=64, use_labels=False):\n",
        "        super(D2, self).__init__()\n",
        "        self.conv1 = conv(3, conv_dim, 4, bn=False)\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
        "        n_out = 11 if use_labels else 1\n",
        "        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n",
        "        out = self.fc(out).squeeze()\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aRkAlhHFqxp"
      },
      "outputs": [],
      "source": [
        "def str2bool(v):\n",
        "    return v.lower() in ('true')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ublxhEX3jdGW"
      },
      "outputs": [],
      "source": [
        "def merge_images(batch_size, sources, targets, k=10):\n",
        "    _, _, h, w = sources.shape\n",
        "    row = int(np.sqrt(batch_size))\n",
        "    merged = np.zeros([3, row*h, row*w*2])\n",
        "    for idx, (s, t) in enumerate(zip(sources, targets)):\n",
        "        i = idx // row\n",
        "        j = idx % row\n",
        "        merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
        "        merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
        "    return merged.transpose(1, 2, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vGtA2dSjwkn"
      },
      "outputs": [],
      "source": [
        "def to_var(x):\n",
        "    \"\"\"Converts numpy to variable.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "         x = x.cuda()\n",
        "    return Variable(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLy0NH7kkB85"
      },
      "outputs": [],
      "source": [
        "def to_data(x):\n",
        "    \"\"\"Converts variable to numpy.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cpu()\n",
        "    return x.data.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAe99dDYl6zx"
      },
      "outputs": [],
      "source": [
        "def reset_grad(g_optimizer, d_optimizer):\n",
        "    \"\"\"Zeros the gradient buffers.\"\"\"\n",
        "    g_optimizer.zero_grad()\n",
        "    d_optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "YluS5pss-SUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb_zTNktkaDI"
      },
      "outputs": [],
      "source": [
        "def train(svhn_loader, mnist_loader, train_iters=train_iters, use_labels=use_labels,\n",
        "     use_reconst_loss=use_reconst_loss, num_classes=num_classes, g_conv_dim=g_conv_dim,\n",
        "     d_conv_dim=d_conv_dim, lr=lr, beta1=beta1, beta2=beta2, log_step=log_step,\n",
        "     sample_step=sample_step, sample_path=None, model_path=None):\n",
        "    #============ data process ============#\n",
        "\n",
        "    svhn_iter = iter(svhn_loader)\n",
        "    mnist_iter = iter(mnist_loader)\n",
        "    iter_per_epoch = min(len(svhn_iter), len(mnist_iter))\n",
        "\n",
        "    #fixed mnist and svhn for sampling\n",
        "    fixed_svhn = to_var(svhn_iter.next()[0])\n",
        "    fixed_mnist = to_var(mnist_iter.next()[0])\n",
        "\n",
        "    #============ model creation ============\n",
        "    g12 = G12(conv_dim=g_conv_dim)\n",
        "    g21 = G21(conv_dim=g_conv_dim)\n",
        "    d1 = D1(conv_dim=d_conv_dim, use_labels=True)\n",
        "    d2 = D2(conv_dim=d_conv_dim, use_labels=True)\n",
        "    g_params = list(g12.parameters()) + list(g21.parameters())\n",
        "    d_params = list(d1.parameters()) + list(d2.parameters())\n",
        "\n",
        "    g_optimizer = optim.Adam(g_params, lr, [beta1, beta2])\n",
        "    d_optimizer = optim.Adam(d_params, lr, [beta1, beta2])\n",
        "    if torch.cuda.is_available():\n",
        "            g12.cuda()\n",
        "            g21.cuda()\n",
        "            d1.cuda()\n",
        "            d2.cuda()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    #============ train process ============#\n",
        "    d_real_loss_list = []\n",
        "    d_mnist_loss_list = []\n",
        "    d_svhn_loss_list = []\n",
        "    d_fake_loss_list =[]\n",
        "    g_loss_list = []\n",
        "    for step in range(train_iters+1):\n",
        "      # reset data_iter for each epoch\n",
        "\n",
        "      if (step+1) % iter_per_epoch == 0:\n",
        "          mnist_iter = iter(mnist_loader)\n",
        "          svhn_iter = iter(svhn_loader)\n",
        "\n",
        "      # load svhn and mnist dataset\n",
        "      svhn, s_labels = svhn_iter.next()\n",
        "      svhn, s_labels = to_var(svhn), to_var(s_labels).long().squeeze()\n",
        "      mnist, m_labels = mnist_iter.next()\n",
        "      mnist, m_labels = to_var(mnist), to_var(m_labels)\n",
        "\n",
        "      if use_labels:\n",
        "          mnist_fake_labels = to_var(\n",
        "              torch.Tensor([num_classes]*svhn.size(0)).long())\n",
        "          svhn_fake_labels = to_var(\n",
        "              torch.Tensor([num_classes]*mnist.size(0)).long())\n",
        "\n",
        "      #============ train D ============#\n",
        "\n",
        "      # train with real images\n",
        "      reset_grad(g_optimizer, d_optimizer)\n",
        "      out = d1(mnist)\n",
        "      if use_labels:\n",
        "          d1_loss = criterion(out, m_labels)\n",
        "      else:\n",
        "          d1_loss = torch.mean((out-1)**2)\n",
        "\n",
        "      out = d2(svhn)\n",
        "      if use_labels:\n",
        "          d2_loss = criterion(out, s_labels)\n",
        "      else:\n",
        "          d2_loss = torch.mean((out-1)**2)\n",
        "\n",
        "      d_mnist_loss = d1_loss\n",
        "      d_svhn_loss = d2_loss\n",
        "      d_real_loss = d1_loss + d2_loss\n",
        "      d_real_loss.backward()\n",
        "      d_optimizer.step()\n",
        "\n",
        "      # train with fake images\n",
        "      reset_grad(g_optimizer, d_optimizer)\n",
        "      fake_svhn = g12(mnist)\n",
        "      out = d2(fake_svhn)\n",
        "      if use_labels:\n",
        "          d2_loss = criterion(out, svhn_fake_labels)\n",
        "      else:\n",
        "          d2_loss = torch.mean(out**2)\n",
        "\n",
        "      fake_mnist = g21(svhn)\n",
        "      out = d1(fake_mnist)\n",
        "      if use_labels:\n",
        "          d1_loss = criterion(out, mnist_fake_labels)\n",
        "      else:\n",
        "          d1_loss = torch.mean(out**2)\n",
        "\n",
        "      d_fake_loss = d1_loss + d2_loss\n",
        "      d_fake_loss.backward()\n",
        "      d_optimizer.step()\n",
        "\n",
        "      #============ train G ============#\n",
        "\n",
        "      # train mnist-svhn-mnist cycle\n",
        "      reset_grad(g_optimizer, d_optimizer)\n",
        "      fake_svhn = g12(mnist)\n",
        "      out = d2(fake_svhn)\n",
        "      reconst_mnist = g21(fake_svhn)\n",
        "      if use_labels:\n",
        "          g_loss = criterion(out, m_labels)\n",
        "      else:\n",
        "          g_loss = torch.mean((out-1)**2)\n",
        "\n",
        "      if use_reconst_loss:\n",
        "          g_loss += torch.mean((mnist - reconst_mnist)**2)\n",
        "\n",
        "      g_loss.backward()\n",
        "      g_optimizer.step()\n",
        "\n",
        "      # train svhn-mnist-svhn cycle\n",
        "      reset_grad(g_optimizer, d_optimizer)\n",
        "      fake_mnist = g21(svhn)\n",
        "      out = d1(fake_mnist)\n",
        "      reconst_svhn = g12(fake_mnist)\n",
        "      if use_labels:\n",
        "          g_loss = criterion(out, s_labels)\n",
        "      else:\n",
        "          g_loss = torch.mean((out-1)**2)\n",
        "\n",
        "      if use_reconst_loss:\n",
        "          g_loss += torch.mean((svhn - reconst_svhn)**2)\n",
        "\n",
        "      g_loss.backward()\n",
        "      g_optimizer.step()\n",
        "\n",
        "      # print the log info\n",
        "      if (step+1) % log_step == 0:\n",
        "          print('Step [%d/%d], d_real_loss: %.4f, d_mnist_loss: %.4f, d_svhn_loss: %.4f, '\n",
        "                'd_fake_loss: %.4f, g_loss: %.4f'\n",
        "                %(step+1, train_iters, d_real_loss.item(), d_mnist_loss.item(),\n",
        "                  d_svhn_loss.item(), d_fake_loss.item(), g_loss.item()))\n",
        "      d_real_loss_list.append(d_real_loss.item())\n",
        "      d_mnist_loss_list.append(d_mnist_loss.item())\n",
        "      d_svhn_loss_list.append(d_svhn_loss.item())\n",
        "      d_fake_loss_list.append(d_fake_loss.item())\n",
        "      g_loss_list.append(g_loss.item())\n",
        "\n",
        "      # save the sampled images\n",
        "      if (step+1) % sample_step == 0:\n",
        "          fake_svhn = g12(fixed_mnist)\n",
        "          fake_mnist = g21(fixed_svhn)\n",
        "\n",
        "          mnist, fake_mnist = to_data(fixed_mnist), to_data(fake_mnist)\n",
        "          svhn , fake_svhn = to_data(fixed_svhn), to_data(fake_svhn)\n",
        "\n",
        "          merged = merge_images(batch_size, mnist, fake_svhn)\n",
        "          path = os.path.join(sample_path, 'sample-%d-m-s.png' %(step+1))\n",
        "          #scipy.misc.imsave(path, merged)\n",
        "          imageio.imwrite(path, merged)\n",
        "          print ('saved %s' %path)\n",
        "\n",
        "          merged = merge_images(batch_size, svhn, fake_mnist)\n",
        "          path = os.path.join(sample_path, 'sample-%d-s-m.png' %(step+1))\n",
        "          #scipy.misc.imsave(path, merged)\n",
        "          imageio.imwrite(path, merged)\n",
        "          print ('saved %s' %path)\n",
        "\n",
        "\n",
        "      if (step+1) % 5000 == 0:\n",
        "          # save the model parameters for each epoch\n",
        "          g12_path = os.path.join(model_path, 'g12-%d.pkl' %(step+1))\n",
        "          g21_path = os.path.join(model_path, 'g21-%d.pkl' %(step+1))\n",
        "          d1_path = os.path.join(model_path, 'd1-%d.pkl' %(step+1))\n",
        "          d2_path = os.path.join(model_path, 'd2-%d.pkl' %(step+1))\n",
        "          torch.save(g12.state_dict(), g12_path)\n",
        "          torch.save(g21.state_dict(), g21_path)\n",
        "          torch.save(d1.state_dict(), d1_path)\n",
        "          torch.save(d2.state_dict(), d2_path)\n",
        "    return d_real_loss_list, d_mnist_loss_list, d_svhn_loss_list, d_fake_loss_list, g_loss_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zLfvQo4fKZm"
      },
      "outputs": [],
      "source": [
        "sample_path1 = './samples_mnist_svhn'\n",
        "model_path1 = './models_mnist_svhn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gKgGIdHp6_Y"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(model_path1):\n",
        "    os.makedirs(model_path1)\n",
        "if not os.path.exists(sample_path1):\n",
        "    os.makedirs(sample_path1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmT-IJXNbSF3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481,
          "referenced_widgets": [
            "503f5874e8434572a40ced3070e25145",
            "8ffc1762f31e40b596ef4d6722c019cc",
            "6d7757fff1834a71afcd9e74954951af",
            "34e40568f0074269985944e865755ab7",
            "f266338a6e0d453699f61c2e205f76a0",
            "06cf417f63f1436d8845caa45395d475",
            "04aa2d4602b64480a1229d7cf55cccb7",
            "6759c2072257440f8c8570960f93214a",
            "0c369026a3754724a72927fc3b2f0f8a",
            "c8c83db90c2d4a2b8a4e68cd8873e552",
            "753249d9f0884877880a104a2a2207ae",
            "91ed187dd38848e8a1720432f67125d0",
            "4c6670c27405441d8829b9b2dbd60fc2",
            "2800b89f320a41179bc1c43173649be2",
            "0aedfa8a9c734b8d83c497aae478ba51",
            "1b85359e5c6642548ee72f7d4c4f7e6e",
            "f45653fedc634c3884ed394d8535608b",
            "2c7639bcfc204511bec0171d96358855",
            "aadd4926464f49d6ab080b0204e7ddbe",
            "7f105bb0ae2843d89c8e00ce9fbdb647",
            "1dcc3493b5c74bf8876060ad3fe22361",
            "f860476ed0e5444ebb83d69ec6f5541d",
            "0bf417e12e5d441c84d5a156dff8ed0d",
            "de0dae07b3ce42948d1a230a13b9676d",
            "ca44342d362f4dcfab532e2eb3d9f1b9",
            "8551971bca634910967753615a8856af",
            "8ee5e6bbe0834f7e9cf079c72d191ee5",
            "dbf1502f2e714ccf8317f519f795d149",
            "75b42e95955a4982bd8a1440e6723d94",
            "ed2b067a90c04d05968dc5227a648657",
            "afd73a36ae224d1ba692713ecca9c6bb",
            "7182f771e8f048ba94a39a6681c9d6b5",
            "534e8036bfb2416c8daac51e45833ade",
            "909862a11f974f3d9b758b41409532e6",
            "c90c1bed97954ba9bcea6b537409fc1e",
            "73fe63ce4bff4b9c9faedee2a283d898",
            "9f9dcf06f66e4767b49a4e8de26f2b4d",
            "08dd5301db3f4edc99ebf94bdc1e937e",
            "cf0115fe86534c37b9c7a8a19b5f3ef0",
            "4a50700cf6f84976bfb81057de789cc5",
            "cd1b77bd7ccd49c695dc494e306b3dd5",
            "ea4d7c16e75b4ac4bc0dc79f910013a6",
            "94200059f7d94112948c4a61d3cf19d5",
            "72258eb849784eeeb154e8450ebbe83d",
            "7d69fe6625a74ab198029fd865edfb37",
            "fef566748bfe4d61acda556a43925e69",
            "5738b24fdc6b44cba2416e50a0968093",
            "db64d227eb1f4351a9defa6a29599eaa",
            "d7127bb454ae40779394bd81808d2dac",
            "f8ff662113304860817d441516252c36",
            "0dc46ad7cf5c4ec5b4c800c69e5e2c86",
            "5f5a136733924c2a957d653e2d32ac68",
            "2d8ea2a251334676a84cd2c56ec5f09f",
            "e1ca1ce4a92a48bb84e3501a388f86c2",
            "d22d5e477f504c4ead0896c1d4ab961f"
          ]
        },
        "outputId": "910994c1-d1ca-4eae-a7ef-0d5a2beaea6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./svhn/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/182040794 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "503f5874e8434572a40ced3070e25145"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91ed187dd38848e8a1720432f67125d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bf417e12e5d441c84d5a156dff8ed0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "909862a11f974f3d9b758b41409532e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d69fe6625a74ab198029fd865edfb37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svhn_loader, mnist_loader = get_loader(image_size, batch_size, num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae6DCbZRiyT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5baeb24-7c14-4a57-fc89-a9fcc1675be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        }
      ],
      "source": [
        "d_real_loss_list, d_mnist_loss_list, d_svhn_loss_list, d_fake_loss_list, g_loss_list = train(svhn_loader, mnist_loader, sample_path=sample_path1, model_path=model_path1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "classes = [d_real_loss_list,d_mnist_loss_list,d_svhn_loss_list,d_fake_loss_list,g_loss_list]\n",
        "labels = ['d_real_loss','d_mnist_loss','d_svhn_loss','d_fake_loss','g_loss']\n",
        "# 第一幅图的下标从1开始，设置6张子图\n",
        "for plt_index in range(1,6):\n",
        "    # 往画布上添加子图：按三行二列，添加到下标为plt_index的位置\n",
        "    ax = fig.add_subplot(3,2,plt_index)\n",
        "    # 绘制对应的子图\n",
        "    plt.plot(range(train_iters+1), classes[plt_index-1], label = labels[plt_index-1])\n",
        "    plt.xlabel(\"iters\")\n",
        "    plt.ylabel(\"loss values\")\n",
        "    pass\n",
        "\n",
        "# 显示画布\n",
        "plt.title(\"The figure of loss in transformation betweem mnist and svhn\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "4NrJ6u1fW4Ho",
        "outputId": "4ca1dcaf-1e04-4412-e46b-9779770485d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzZL6rzGiyT6"
      },
      "source": [
        "**New dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os.path\n",
        "import glob\n",
        "def convertjpg(jpgfile,outdir,width=32,height=32):\n",
        "    img=Image.open(jpgfile)\n",
        "    try:\n",
        "        new_img=img.resize((width,height),Image.BILINEAR)\n",
        "        new_img.save(os.path.join(outdir,os.path.basename(jpgfile)))\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "for jpgfile in glob.glob(\"C:/Users/62300/Documents/MCE/deep learning/images/*.jpg\"):\n",
        "    convertjpg(jpgfile,\"C:/Users/62300/Documents/MCE/deep learning/fashion_product_images_small\")"
      ],
      "metadata": {
        "id": "S3E0TMGkCAWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZPIP5BRiyT9"
      },
      "outputs": [],
      "source": [
        "sample_path2 = './samples_fashion'\n",
        "model_path2 = './models_fashion'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(model_path2):\n",
        "    os.makedirs(model_path2)\n",
        "if not os.path.exists(sample_path2):\n",
        "    os.makedirs(sample_path2)"
      ],
      "metadata": {
        "id": "fQ7oQdO3biRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_file = zipfile.ZipFile('./fashion_product_images_small.zip')\n",
        "zip_list = zip_file.namelist() # 得到压缩包里所有文件\n",
        "\n",
        "for f in zip_list:\n",
        "    zip_file.extract(f, '/content') # 循环解压文件到指定目录\n",
        "\n",
        "zip_file.close() # 关闭文件，必须有，释放内存"
      ],
      "metadata": {
        "id": "Icg1kbkdWXwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Fw73_eniyT-"
      },
      "outputs": [],
      "source": [
        "data1 = MyDataset(\"/content/fashion_product_images_small\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je9k8vpVqPCQ",
        "outputId": "decbfec2-ad7d-42c8-d8fb-9038d98a979e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44441"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-OJ4mYaiyT_"
      },
      "outputs": [],
      "source": [
        "fashion_loader = DataLoader(data1, batch_size=64, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0s5tyWIiyUA"
      },
      "outputs": [],
      "source": [
        "Fashionmnist_loader = get_loader_fashion(image_size, batch_size, num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8WIIE1QqIEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a89193-74b3-4e8f-b33e-11af00e88ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [10/60000], d_real_loss: 0.3490, d_mnist_loss: 0.2323, d_svhn_loss: 0.1167, d_fake_loss: 0.3436, g_loss: 1.8219\n",
            "Step [20/60000], d_real_loss: 0.3978, d_mnist_loss: 0.2418, d_svhn_loss: 0.1560, d_fake_loss: 0.4763, g_loss: 1.9687\n",
            "Step [30/60000], d_real_loss: 0.2201, d_mnist_loss: 0.1860, d_svhn_loss: 0.0341, d_fake_loss: 0.4405, g_loss: 1.5503\n",
            "Step [40/60000], d_real_loss: 0.3624, d_mnist_loss: 0.3110, d_svhn_loss: 0.0514, d_fake_loss: 0.4919, g_loss: 1.0345\n",
            "Step [50/60000], d_real_loss: 0.6092, d_mnist_loss: 0.3142, d_svhn_loss: 0.2951, d_fake_loss: 0.6769, g_loss: 1.1208\n",
            "Step [60/60000], d_real_loss: 0.4975, d_mnist_loss: 0.1993, d_svhn_loss: 0.2982, d_fake_loss: 0.4443, g_loss: 1.1618\n",
            "Step [70/60000], d_real_loss: 0.5570, d_mnist_loss: 0.2014, d_svhn_loss: 0.3556, d_fake_loss: 0.4487, g_loss: 0.9268\n",
            "Step [80/60000], d_real_loss: 0.5999, d_mnist_loss: 0.2472, d_svhn_loss: 0.3527, d_fake_loss: 0.3961, g_loss: 1.1336\n",
            "Step [90/60000], d_real_loss: 0.6154, d_mnist_loss: 0.3881, d_svhn_loss: 0.2273, d_fake_loss: 0.6096, g_loss: 1.1763\n",
            "Step [100/60000], d_real_loss: 0.8019, d_mnist_loss: 0.2727, d_svhn_loss: 0.5291, d_fake_loss: 0.4631, g_loss: 0.9552\n",
            "Step [110/60000], d_real_loss: 0.3110, d_mnist_loss: 0.2508, d_svhn_loss: 0.0602, d_fake_loss: 0.2934, g_loss: 0.8092\n",
            "Step [120/60000], d_real_loss: 0.3983, d_mnist_loss: 0.2038, d_svhn_loss: 0.1945, d_fake_loss: 0.4182, g_loss: 0.7550\n",
            "Step [130/60000], d_real_loss: 0.4882, d_mnist_loss: 0.2595, d_svhn_loss: 0.2288, d_fake_loss: 0.5050, g_loss: 0.7241\n",
            "Step [140/60000], d_real_loss: 0.4530, d_mnist_loss: 0.2884, d_svhn_loss: 0.1646, d_fake_loss: 0.4644, g_loss: 0.7429\n",
            "Step [150/60000], d_real_loss: 0.2814, d_mnist_loss: 0.2291, d_svhn_loss: 0.0523, d_fake_loss: 0.6086, g_loss: 0.7809\n",
            "Step [160/60000], d_real_loss: 0.4924, d_mnist_loss: 0.2959, d_svhn_loss: 0.1966, d_fake_loss: 0.3295, g_loss: 0.7371\n",
            "Step [170/60000], d_real_loss: 0.5247, d_mnist_loss: 0.2501, d_svhn_loss: 0.2747, d_fake_loss: 0.2653, g_loss: 0.7454\n",
            "Step [180/60000], d_real_loss: 0.3386, d_mnist_loss: 0.2119, d_svhn_loss: 0.1268, d_fake_loss: 0.2527, g_loss: 0.8168\n",
            "Step [190/60000], d_real_loss: 0.4876, d_mnist_loss: 0.2562, d_svhn_loss: 0.2314, d_fake_loss: 0.3823, g_loss: 0.6861\n",
            "Step [200/60000], d_real_loss: 0.3833, d_mnist_loss: 0.2547, d_svhn_loss: 0.1287, d_fake_loss: 0.3772, g_loss: 0.7493\n",
            "Step [210/60000], d_real_loss: 1.1510, d_mnist_loss: 0.2601, d_svhn_loss: 0.8909, d_fake_loss: 0.6621, g_loss: 0.8841\n",
            "Step [220/60000], d_real_loss: 0.3274, d_mnist_loss: 0.2370, d_svhn_loss: 0.0904, d_fake_loss: 0.4662, g_loss: 0.8791\n",
            "Step [230/60000], d_real_loss: 0.2649, d_mnist_loss: 0.2208, d_svhn_loss: 0.0441, d_fake_loss: 0.5020, g_loss: 0.8166\n",
            "Step [240/60000], d_real_loss: 0.3769, d_mnist_loss: 0.2367, d_svhn_loss: 0.1401, d_fake_loss: 0.4937, g_loss: 0.7548\n",
            "Step [250/60000], d_real_loss: 0.4075, d_mnist_loss: 0.2087, d_svhn_loss: 0.1989, d_fake_loss: 0.3779, g_loss: 0.8550\n",
            "Step [260/60000], d_real_loss: 0.4257, d_mnist_loss: 0.2107, d_svhn_loss: 0.2150, d_fake_loss: 0.2408, g_loss: 0.7737\n",
            "Step [270/60000], d_real_loss: 0.3046, d_mnist_loss: 0.1927, d_svhn_loss: 0.1118, d_fake_loss: 0.2573, g_loss: 0.9011\n",
            "Step [280/60000], d_real_loss: 0.5663, d_mnist_loss: 0.2309, d_svhn_loss: 0.3353, d_fake_loss: 0.3035, g_loss: 0.8574\n",
            "Step [290/60000], d_real_loss: 0.2712, d_mnist_loss: 0.2278, d_svhn_loss: 0.0434, d_fake_loss: 0.3534, g_loss: 0.8832\n",
            "Step [300/60000], d_real_loss: 0.2034, d_mnist_loss: 0.1533, d_svhn_loss: 0.0500, d_fake_loss: 0.2135, g_loss: 0.8720\n",
            "Step [310/60000], d_real_loss: 0.3722, d_mnist_loss: 0.2684, d_svhn_loss: 0.1038, d_fake_loss: 0.3630, g_loss: 0.7538\n",
            "Step [320/60000], d_real_loss: 0.3222, d_mnist_loss: 0.2506, d_svhn_loss: 0.0716, d_fake_loss: 0.3551, g_loss: 0.7261\n",
            "Step [330/60000], d_real_loss: 0.3434, d_mnist_loss: 0.2114, d_svhn_loss: 0.1320, d_fake_loss: 0.3826, g_loss: 0.7675\n",
            "Step [340/60000], d_real_loss: 0.6995, d_mnist_loss: 0.1927, d_svhn_loss: 0.5068, d_fake_loss: 0.2293, g_loss: 0.9053\n",
            "Step [350/60000], d_real_loss: 0.4243, d_mnist_loss: 0.2633, d_svhn_loss: 0.1610, d_fake_loss: 0.3795, g_loss: 0.9420\n",
            "Step [360/60000], d_real_loss: 0.2153, d_mnist_loss: 0.1722, d_svhn_loss: 0.0431, d_fake_loss: 0.2206, g_loss: 0.9088\n",
            "Step [370/60000], d_real_loss: 0.1946, d_mnist_loss: 0.1226, d_svhn_loss: 0.0720, d_fake_loss: 0.2321, g_loss: 0.8429\n",
            "Step [380/60000], d_real_loss: 0.4386, d_mnist_loss: 0.2165, d_svhn_loss: 0.2220, d_fake_loss: 0.3992, g_loss: 0.8532\n",
            "Step [390/60000], d_real_loss: 0.4567, d_mnist_loss: 0.2286, d_svhn_loss: 0.2281, d_fake_loss: 0.2643, g_loss: 0.8378\n",
            "Step [400/60000], d_real_loss: 0.3560, d_mnist_loss: 0.3041, d_svhn_loss: 0.0519, d_fake_loss: 0.3375, g_loss: 0.7621\n",
            "Step [410/60000], d_real_loss: 0.4631, d_mnist_loss: 0.2655, d_svhn_loss: 0.1976, d_fake_loss: 0.2759, g_loss: 0.7583\n",
            "Step [420/60000], d_real_loss: 0.3236, d_mnist_loss: 0.2005, d_svhn_loss: 0.1230, d_fake_loss: 0.4034, g_loss: 1.0109\n",
            "Step [430/60000], d_real_loss: 0.4035, d_mnist_loss: 0.3084, d_svhn_loss: 0.0951, d_fake_loss: 0.4822, g_loss: 0.8490\n",
            "Step [440/60000], d_real_loss: 0.3557, d_mnist_loss: 0.2492, d_svhn_loss: 0.1066, d_fake_loss: 0.5773, g_loss: 0.7916\n",
            "Step [450/60000], d_real_loss: 0.3296, d_mnist_loss: 0.2917, d_svhn_loss: 0.0379, d_fake_loss: 0.4085, g_loss: 0.7876\n",
            "Step [460/60000], d_real_loss: 0.2957, d_mnist_loss: 0.2223, d_svhn_loss: 0.0735, d_fake_loss: 0.2127, g_loss: 0.9345\n",
            "Step [470/60000], d_real_loss: 0.5136, d_mnist_loss: 0.3179, d_svhn_loss: 0.1957, d_fake_loss: 0.3885, g_loss: 0.7580\n",
            "Step [480/60000], d_real_loss: 0.4571, d_mnist_loss: 0.4185, d_svhn_loss: 0.0386, d_fake_loss: 0.4510, g_loss: 0.7336\n",
            "Step [490/60000], d_real_loss: 0.2900, d_mnist_loss: 0.2242, d_svhn_loss: 0.0658, d_fake_loss: 0.2300, g_loss: 0.8691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.999990701675415]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [500/60000], d_real_loss: 0.4906, d_mnist_loss: 0.2743, d_svhn_loss: 0.2163, d_fake_loss: 0.3368, g_loss: 0.8094\n",
            "saved ./samples_fashion/sample-500-m-s.png\n",
            "saved ./samples_fashion/sample-500-s-m.png\n",
            "Step [510/60000], d_real_loss: 0.7473, d_mnist_loss: 0.1943, d_svhn_loss: 0.5530, d_fake_loss: 0.3696, g_loss: 0.8469\n",
            "Step [520/60000], d_real_loss: 0.3028, d_mnist_loss: 0.1810, d_svhn_loss: 0.1218, d_fake_loss: 0.1627, g_loss: 0.8897\n",
            "Step [530/60000], d_real_loss: 0.2364, d_mnist_loss: 0.1923, d_svhn_loss: 0.0441, d_fake_loss: 0.3779, g_loss: 0.8025\n",
            "Step [540/60000], d_real_loss: 0.3801, d_mnist_loss: 0.2738, d_svhn_loss: 0.1063, d_fake_loss: 0.4841, g_loss: 0.7890\n",
            "Step [550/60000], d_real_loss: 0.3486, d_mnist_loss: 0.2270, d_svhn_loss: 0.1216, d_fake_loss: 0.2507, g_loss: 0.8809\n",
            "Step [560/60000], d_real_loss: 0.3284, d_mnist_loss: 0.1743, d_svhn_loss: 0.1541, d_fake_loss: 0.2354, g_loss: 0.9022\n",
            "Step [570/60000], d_real_loss: 0.2664, d_mnist_loss: 0.2118, d_svhn_loss: 0.0546, d_fake_loss: 0.3722, g_loss: 0.8862\n",
            "Step [580/60000], d_real_loss: 0.3119, d_mnist_loss: 0.2457, d_svhn_loss: 0.0662, d_fake_loss: 0.3428, g_loss: 0.9532\n",
            "Step [590/60000], d_real_loss: 0.3720, d_mnist_loss: 0.2716, d_svhn_loss: 0.1004, d_fake_loss: 0.3393, g_loss: 0.9082\n",
            "Step [600/60000], d_real_loss: 0.3956, d_mnist_loss: 0.2745, d_svhn_loss: 0.1212, d_fake_loss: 0.3681, g_loss: 0.8453\n",
            "Step [610/60000], d_real_loss: 0.4457, d_mnist_loss: 0.2293, d_svhn_loss: 0.2164, d_fake_loss: 0.2426, g_loss: 0.8451\n",
            "Step [620/60000], d_real_loss: 0.3482, d_mnist_loss: 0.1797, d_svhn_loss: 0.1685, d_fake_loss: 0.2576, g_loss: 0.9204\n",
            "Step [630/60000], d_real_loss: 0.5123, d_mnist_loss: 0.2503, d_svhn_loss: 0.2620, d_fake_loss: 0.2158, g_loss: 0.8388\n",
            "Step [640/60000], d_real_loss: 0.4085, d_mnist_loss: 0.2384, d_svhn_loss: 0.1701, d_fake_loss: 0.3414, g_loss: 0.9962\n",
            "Step [650/60000], d_real_loss: 0.2994, d_mnist_loss: 0.1979, d_svhn_loss: 0.1014, d_fake_loss: 0.2231, g_loss: 0.9026\n",
            "Step [660/60000], d_real_loss: 0.3294, d_mnist_loss: 0.2664, d_svhn_loss: 0.0630, d_fake_loss: 0.2941, g_loss: 0.8369\n",
            "Step [670/60000], d_real_loss: 0.3309, d_mnist_loss: 0.2425, d_svhn_loss: 0.0884, d_fake_loss: 0.4224, g_loss: 0.9305\n",
            "Step [680/60000], d_real_loss: 0.3355, d_mnist_loss: 0.2657, d_svhn_loss: 0.0699, d_fake_loss: 0.3389, g_loss: 0.9199\n",
            "Step [690/60000], d_real_loss: 1.0116, d_mnist_loss: 0.1808, d_svhn_loss: 0.8308, d_fake_loss: 0.3187, g_loss: 1.0423\n",
            "Step [700/60000], d_real_loss: 0.3590, d_mnist_loss: 0.2639, d_svhn_loss: 0.0950, d_fake_loss: 0.2918, g_loss: 0.8952\n",
            "Step [710/60000], d_real_loss: 0.3397, d_mnist_loss: 0.2444, d_svhn_loss: 0.0953, d_fake_loss: 0.2436, g_loss: 0.8596\n",
            "Step [720/60000], d_real_loss: 0.4185, d_mnist_loss: 0.2032, d_svhn_loss: 0.2152, d_fake_loss: 0.3526, g_loss: 0.9779\n",
            "Step [730/60000], d_real_loss: 0.4460, d_mnist_loss: 0.2779, d_svhn_loss: 0.1682, d_fake_loss: 0.4365, g_loss: 1.0042\n",
            "Step [740/60000], d_real_loss: 0.3832, d_mnist_loss: 0.2586, d_svhn_loss: 0.1246, d_fake_loss: 0.2044, g_loss: 1.0505\n",
            "Step [750/60000], d_real_loss: 0.2370, d_mnist_loss: 0.1660, d_svhn_loss: 0.0710, d_fake_loss: 0.2669, g_loss: 1.1399\n",
            "Step [760/60000], d_real_loss: 0.3074, d_mnist_loss: 0.1513, d_svhn_loss: 0.1561, d_fake_loss: 0.4976, g_loss: 1.0961\n",
            "Step [770/60000], d_real_loss: 0.2537, d_mnist_loss: 0.2008, d_svhn_loss: 0.0529, d_fake_loss: 0.1994, g_loss: 0.9319\n",
            "Step [780/60000], d_real_loss: 0.2846, d_mnist_loss: 0.2105, d_svhn_loss: 0.0740, d_fake_loss: 0.1980, g_loss: 0.9313\n",
            "Step [790/60000], d_real_loss: 0.2929, d_mnist_loss: 0.1584, d_svhn_loss: 0.1345, d_fake_loss: 0.1985, g_loss: 0.9909\n",
            "Step [800/60000], d_real_loss: 0.3994, d_mnist_loss: 0.1771, d_svhn_loss: 0.2223, d_fake_loss: 0.3994, g_loss: 1.2107\n",
            "Step [810/60000], d_real_loss: 0.1965, d_mnist_loss: 0.1542, d_svhn_loss: 0.0423, d_fake_loss: 0.1935, g_loss: 0.9638\n",
            "Step [820/60000], d_real_loss: 0.6837, d_mnist_loss: 0.1890, d_svhn_loss: 0.4947, d_fake_loss: 0.2468, g_loss: 1.0484\n",
            "Step [830/60000], d_real_loss: 0.2904, d_mnist_loss: 0.1201, d_svhn_loss: 0.1703, d_fake_loss: 0.3697, g_loss: 1.0443\n",
            "Step [840/60000], d_real_loss: 0.2566, d_mnist_loss: 0.2146, d_svhn_loss: 0.0421, d_fake_loss: 0.2442, g_loss: 1.1273\n",
            "Step [850/60000], d_real_loss: 0.5027, d_mnist_loss: 0.2068, d_svhn_loss: 0.2959, d_fake_loss: 0.2175, g_loss: 0.9972\n",
            "Step [860/60000], d_real_loss: 0.2489, d_mnist_loss: 0.1787, d_svhn_loss: 0.0702, d_fake_loss: 0.2053, g_loss: 0.9359\n",
            "Step [870/60000], d_real_loss: 0.4294, d_mnist_loss: 0.2662, d_svhn_loss: 0.1632, d_fake_loss: 0.3316, g_loss: 1.0897\n",
            "Step [880/60000], d_real_loss: 0.2151, d_mnist_loss: 0.1481, d_svhn_loss: 0.0670, d_fake_loss: 0.2875, g_loss: 1.1579\n",
            "Step [890/60000], d_real_loss: 0.2471, d_mnist_loss: 0.1907, d_svhn_loss: 0.0564, d_fake_loss: 0.3296, g_loss: 0.9682\n",
            "Step [900/60000], d_real_loss: 0.5828, d_mnist_loss: 0.2542, d_svhn_loss: 0.3285, d_fake_loss: 0.2840, g_loss: 0.9915\n",
            "Step [910/60000], d_real_loss: 0.4481, d_mnist_loss: 0.2125, d_svhn_loss: 0.2356, d_fake_loss: 0.2729, g_loss: 0.9392\n",
            "Step [920/60000], d_real_loss: 0.2961, d_mnist_loss: 0.2062, d_svhn_loss: 0.0899, d_fake_loss: 0.2649, g_loss: 1.1666\n",
            "Step [930/60000], d_real_loss: 0.2055, d_mnist_loss: 0.1506, d_svhn_loss: 0.0550, d_fake_loss: 0.2866, g_loss: 1.1530\n",
            "Step [940/60000], d_real_loss: 0.2201, d_mnist_loss: 0.1407, d_svhn_loss: 0.0794, d_fake_loss: 0.1761, g_loss: 1.1039\n",
            "Step [950/60000], d_real_loss: 0.1922, d_mnist_loss: 0.1158, d_svhn_loss: 0.0764, d_fake_loss: 0.2845, g_loss: 1.1515\n",
            "Step [960/60000], d_real_loss: 0.2950, d_mnist_loss: 0.1853, d_svhn_loss: 0.1097, d_fake_loss: 0.3081, g_loss: 0.9886\n",
            "Step [970/60000], d_real_loss: 0.2422, d_mnist_loss: 0.1901, d_svhn_loss: 0.0521, d_fake_loss: 0.2730, g_loss: 1.0670\n",
            "Step [980/60000], d_real_loss: 0.2543, d_mnist_loss: 0.1938, d_svhn_loss: 0.0605, d_fake_loss: 0.2603, g_loss: 1.0725\n",
            "Step [990/60000], d_real_loss: 0.2230, d_mnist_loss: 0.1787, d_svhn_loss: 0.0443, d_fake_loss: 0.2182, g_loss: 1.1753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999995231628418]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [1000/60000], d_real_loss: 0.2044, d_mnist_loss: 0.1419, d_svhn_loss: 0.0625, d_fake_loss: 0.2342, g_loss: 1.0259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved ./samples_fashion/sample-1000-m-s.png\n",
            "saved ./samples_fashion/sample-1000-s-m.png\n",
            "Step [1010/60000], d_real_loss: 0.1846, d_mnist_loss: 0.1067, d_svhn_loss: 0.0779, d_fake_loss: 0.2789, g_loss: 1.2433\n",
            "Step [1020/60000], d_real_loss: 0.4139, d_mnist_loss: 0.1624, d_svhn_loss: 0.2515, d_fake_loss: 0.3045, g_loss: 1.2099\n",
            "Step [1030/60000], d_real_loss: 0.2593, d_mnist_loss: 0.1641, d_svhn_loss: 0.0952, d_fake_loss: 0.2027, g_loss: 1.0766\n",
            "Step [1040/60000], d_real_loss: 0.4952, d_mnist_loss: 0.2147, d_svhn_loss: 0.2805, d_fake_loss: 0.2487, g_loss: 1.0543\n",
            "Step [1050/60000], d_real_loss: 0.3552, d_mnist_loss: 0.2254, d_svhn_loss: 0.1298, d_fake_loss: 0.2894, g_loss: 1.2292\n",
            "Step [1060/60000], d_real_loss: 0.3046, d_mnist_loss: 0.2147, d_svhn_loss: 0.0899, d_fake_loss: 0.2443, g_loss: 1.0941\n",
            "Step [1070/60000], d_real_loss: 0.2819, d_mnist_loss: 0.1761, d_svhn_loss: 0.1058, d_fake_loss: 0.3446, g_loss: 1.0746\n",
            "Step [1080/60000], d_real_loss: 0.3445, d_mnist_loss: 0.1519, d_svhn_loss: 0.1926, d_fake_loss: 0.1529, g_loss: 1.0302\n",
            "Step [1090/60000], d_real_loss: 0.2034, d_mnist_loss: 0.1576, d_svhn_loss: 0.0458, d_fake_loss: 0.2177, g_loss: 1.2221\n",
            "Step [1100/60000], d_real_loss: 0.1420, d_mnist_loss: 0.0770, d_svhn_loss: 0.0650, d_fake_loss: 0.1618, g_loss: 1.2824\n",
            "Step [1110/60000], d_real_loss: 0.2276, d_mnist_loss: 0.1730, d_svhn_loss: 0.0545, d_fake_loss: 0.4578, g_loss: 1.2355\n",
            "Step [1120/60000], d_real_loss: 0.4935, d_mnist_loss: 0.1548, d_svhn_loss: 0.3386, d_fake_loss: 0.1654, g_loss: 1.1687\n",
            "Step [1130/60000], d_real_loss: 0.4083, d_mnist_loss: 0.2112, d_svhn_loss: 0.1971, d_fake_loss: 0.1751, g_loss: 1.1047\n",
            "Step [1140/60000], d_real_loss: 0.4495, d_mnist_loss: 0.2569, d_svhn_loss: 0.1926, d_fake_loss: 0.2094, g_loss: 1.0557\n",
            "Step [1150/60000], d_real_loss: 0.2856, d_mnist_loss: 0.2118, d_svhn_loss: 0.0738, d_fake_loss: 0.1637, g_loss: 1.0486\n",
            "Step [1160/60000], d_real_loss: 0.1991, d_mnist_loss: 0.1323, d_svhn_loss: 0.0668, d_fake_loss: 0.2955, g_loss: 1.1898\n",
            "Step [1170/60000], d_real_loss: 0.3055, d_mnist_loss: 0.1837, d_svhn_loss: 0.1217, d_fake_loss: 0.2764, g_loss: 1.0287\n",
            "Step [1180/60000], d_real_loss: 0.6782, d_mnist_loss: 0.3438, d_svhn_loss: 0.3345, d_fake_loss: 0.6984, g_loss: 1.1262\n",
            "Step [1190/60000], d_real_loss: 0.2653, d_mnist_loss: 0.2065, d_svhn_loss: 0.0588, d_fake_loss: 0.3323, g_loss: 1.2703\n",
            "Step [1200/60000], d_real_loss: 0.3658, d_mnist_loss: 0.2513, d_svhn_loss: 0.1145, d_fake_loss: 0.3173, g_loss: 1.0323\n",
            "Step [1210/60000], d_real_loss: 0.3155, d_mnist_loss: 0.2005, d_svhn_loss: 0.1150, d_fake_loss: 0.1793, g_loss: 1.2473\n",
            "Step [1220/60000], d_real_loss: 0.1929, d_mnist_loss: 0.1098, d_svhn_loss: 0.0832, d_fake_loss: 0.2604, g_loss: 1.2670\n",
            "Step [1230/60000], d_real_loss: 0.1662, d_mnist_loss: 0.1107, d_svhn_loss: 0.0556, d_fake_loss: 0.2289, g_loss: 1.1946\n",
            "Step [1240/60000], d_real_loss: 0.1687, d_mnist_loss: 0.1149, d_svhn_loss: 0.0539, d_fake_loss: 0.1969, g_loss: 1.4737\n",
            "Step [1250/60000], d_real_loss: 0.2563, d_mnist_loss: 0.1328, d_svhn_loss: 0.1235, d_fake_loss: 0.2976, g_loss: 1.0593\n",
            "Step [1260/60000], d_real_loss: 0.2784, d_mnist_loss: 0.1844, d_svhn_loss: 0.0940, d_fake_loss: 0.2804, g_loss: 1.3009\n",
            "Step [1270/60000], d_real_loss: 0.2926, d_mnist_loss: 0.2076, d_svhn_loss: 0.0851, d_fake_loss: 0.2604, g_loss: 0.9528\n",
            "Step [1280/60000], d_real_loss: 0.2389, d_mnist_loss: 0.1609, d_svhn_loss: 0.0780, d_fake_loss: 0.2330, g_loss: 1.1914\n",
            "Step [1290/60000], d_real_loss: 0.1596, d_mnist_loss: 0.0830, d_svhn_loss: 0.0767, d_fake_loss: 0.2073, g_loss: 1.2140\n",
            "Step [1300/60000], d_real_loss: 0.2118, d_mnist_loss: 0.1053, d_svhn_loss: 0.1065, d_fake_loss: 0.1782, g_loss: 1.0837\n",
            "Step [1310/60000], d_real_loss: 0.2230, d_mnist_loss: 0.1699, d_svhn_loss: 0.0531, d_fake_loss: 0.1416, g_loss: 1.4082\n",
            "Step [1320/60000], d_real_loss: 0.2963, d_mnist_loss: 0.2368, d_svhn_loss: 0.0595, d_fake_loss: 0.2589, g_loss: 1.3128\n",
            "Step [1330/60000], d_real_loss: 0.2584, d_mnist_loss: 0.1834, d_svhn_loss: 0.0751, d_fake_loss: 0.2166, g_loss: 1.4735\n",
            "Step [1340/60000], d_real_loss: 0.2564, d_mnist_loss: 0.1489, d_svhn_loss: 0.1075, d_fake_loss: 0.3142, g_loss: 1.1676\n",
            "Step [1350/60000], d_real_loss: 0.1350, d_mnist_loss: 0.0949, d_svhn_loss: 0.0401, d_fake_loss: 0.1248, g_loss: 1.1484\n",
            "Step [1360/60000], d_real_loss: 0.1815, d_mnist_loss: 0.1163, d_svhn_loss: 0.0653, d_fake_loss: 0.1221, g_loss: 1.1988\n",
            "Step [1370/60000], d_real_loss: 0.3434, d_mnist_loss: 0.1772, d_svhn_loss: 0.1662, d_fake_loss: 0.2937, g_loss: 1.5446\n",
            "Step [1380/60000], d_real_loss: 0.1812, d_mnist_loss: 0.1116, d_svhn_loss: 0.0696, d_fake_loss: 0.1771, g_loss: 1.5066\n",
            "Step [1390/60000], d_real_loss: 0.2626, d_mnist_loss: 0.1265, d_svhn_loss: 0.1361, d_fake_loss: 0.1348, g_loss: 1.3397\n",
            "Step [1400/60000], d_real_loss: 0.1099, d_mnist_loss: 0.0653, d_svhn_loss: 0.0446, d_fake_loss: 0.1538, g_loss: 1.2414\n",
            "Step [1410/60000], d_real_loss: 0.2437, d_mnist_loss: 0.1622, d_svhn_loss: 0.0815, d_fake_loss: 0.3313, g_loss: 1.2250\n",
            "Step [1420/60000], d_real_loss: 0.3327, d_mnist_loss: 0.1732, d_svhn_loss: 0.1595, d_fake_loss: 0.2543, g_loss: 1.4462\n",
            "Step [1430/60000], d_real_loss: 0.3119, d_mnist_loss: 0.1208, d_svhn_loss: 0.1911, d_fake_loss: 0.2432, g_loss: 1.3551\n",
            "Step [1440/60000], d_real_loss: 0.1605, d_mnist_loss: 0.0859, d_svhn_loss: 0.0745, d_fake_loss: 0.1583, g_loss: 1.3005\n",
            "Step [1450/60000], d_real_loss: 0.2010, d_mnist_loss: 0.1109, d_svhn_loss: 0.0901, d_fake_loss: 0.1216, g_loss: 1.1513\n",
            "Step [1460/60000], d_real_loss: 0.3546, d_mnist_loss: 0.2168, d_svhn_loss: 0.1379, d_fake_loss: 0.1045, g_loss: 1.3043\n",
            "Step [1470/60000], d_real_loss: 0.2254, d_mnist_loss: 0.0773, d_svhn_loss: 0.1480, d_fake_loss: 0.2561, g_loss: 1.4290\n",
            "Step [1480/60000], d_real_loss: 0.1306, d_mnist_loss: 0.0681, d_svhn_loss: 0.0625, d_fake_loss: 0.0957, g_loss: 1.1620\n",
            "Step [1490/60000], d_real_loss: 0.1642, d_mnist_loss: 0.0923, d_svhn_loss: 0.0719, d_fake_loss: 0.1258, g_loss: 1.1697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999999403953552]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [1500/60000], d_real_loss: 0.2652, d_mnist_loss: 0.0995, d_svhn_loss: 0.1657, d_fake_loss: 0.1535, g_loss: 1.2289\n",
            "saved ./samples_fashion/sample-1500-m-s.png\n",
            "saved ./samples_fashion/sample-1500-s-m.png\n",
            "Step [1510/60000], d_real_loss: 0.1577, d_mnist_loss: 0.0591, d_svhn_loss: 0.0986, d_fake_loss: 0.3816, g_loss: 1.4703\n",
            "Step [1520/60000], d_real_loss: 0.1599, d_mnist_loss: 0.0900, d_svhn_loss: 0.0699, d_fake_loss: 0.1296, g_loss: 1.3303\n",
            "Step [1530/60000], d_real_loss: 0.2289, d_mnist_loss: 0.1352, d_svhn_loss: 0.0938, d_fake_loss: 0.1135, g_loss: 1.0255\n",
            "Step [1540/60000], d_real_loss: 0.2207, d_mnist_loss: 0.1498, d_svhn_loss: 0.0708, d_fake_loss: 0.1426, g_loss: 1.2456\n",
            "Step [1550/60000], d_real_loss: 0.2898, d_mnist_loss: 0.1354, d_svhn_loss: 0.1544, d_fake_loss: 0.2325, g_loss: 1.8022\n",
            "Step [1560/60000], d_real_loss: 0.2449, d_mnist_loss: 0.1719, d_svhn_loss: 0.0730, d_fake_loss: 0.0842, g_loss: 1.0232\n",
            "Step [1570/60000], d_real_loss: 0.2237, d_mnist_loss: 0.0950, d_svhn_loss: 0.1287, d_fake_loss: 0.0981, g_loss: 1.0809\n",
            "Step [1580/60000], d_real_loss: 0.1288, d_mnist_loss: 0.0837, d_svhn_loss: 0.0451, d_fake_loss: 0.2463, g_loss: 1.4091\n",
            "Step [1590/60000], d_real_loss: 0.1223, d_mnist_loss: 0.0711, d_svhn_loss: 0.0512, d_fake_loss: 0.1247, g_loss: 1.2284\n",
            "Step [1600/60000], d_real_loss: 0.1436, d_mnist_loss: 0.0932, d_svhn_loss: 0.0504, d_fake_loss: 0.1618, g_loss: 1.1152\n",
            "Step [1610/60000], d_real_loss: 0.1877, d_mnist_loss: 0.0989, d_svhn_loss: 0.0888, d_fake_loss: 0.1456, g_loss: 1.2698\n",
            "Step [1620/60000], d_real_loss: 0.3698, d_mnist_loss: 0.0755, d_svhn_loss: 0.2943, d_fake_loss: 0.2857, g_loss: 1.4117\n",
            "Step [1630/60000], d_real_loss: 0.1594, d_mnist_loss: 0.0714, d_svhn_loss: 0.0881, d_fake_loss: 0.0965, g_loss: 1.2387\n",
            "Step [1640/60000], d_real_loss: 0.2111, d_mnist_loss: 0.0664, d_svhn_loss: 0.1446, d_fake_loss: 0.1313, g_loss: 1.1958\n",
            "Step [1650/60000], d_real_loss: 0.3469, d_mnist_loss: 0.1678, d_svhn_loss: 0.1791, d_fake_loss: 0.1664, g_loss: 1.2672\n",
            "Step [1660/60000], d_real_loss: 0.1759, d_mnist_loss: 0.0870, d_svhn_loss: 0.0890, d_fake_loss: 0.1733, g_loss: 1.4606\n",
            "Step [1670/60000], d_real_loss: 0.5630, d_mnist_loss: 0.2931, d_svhn_loss: 0.2699, d_fake_loss: 0.2996, g_loss: 1.3174\n",
            "Step [1680/60000], d_real_loss: 0.1765, d_mnist_loss: 0.0845, d_svhn_loss: 0.0920, d_fake_loss: 0.1336, g_loss: 1.4044\n",
            "Step [1690/60000], d_real_loss: 0.2528, d_mnist_loss: 0.1556, d_svhn_loss: 0.0973, d_fake_loss: 0.2348, g_loss: 1.9888\n",
            "Step [1700/60000], d_real_loss: 0.1352, d_mnist_loss: 0.0512, d_svhn_loss: 0.0840, d_fake_loss: 0.0778, g_loss: 1.0731\n",
            "Step [1710/60000], d_real_loss: 0.1868, d_mnist_loss: 0.0523, d_svhn_loss: 0.1345, d_fake_loss: 0.4065, g_loss: 1.1965\n",
            "Step [1720/60000], d_real_loss: 0.1474, d_mnist_loss: 0.1048, d_svhn_loss: 0.0426, d_fake_loss: 0.3238, g_loss: 1.8867\n",
            "Step [1730/60000], d_real_loss: 0.2203, d_mnist_loss: 0.0465, d_svhn_loss: 0.1738, d_fake_loss: 0.1696, g_loss: 1.5229\n",
            "Step [1740/60000], d_real_loss: 0.3958, d_mnist_loss: 0.1704, d_svhn_loss: 0.2253, d_fake_loss: 0.0944, g_loss: 1.1799\n",
            "Step [1750/60000], d_real_loss: 0.2188, d_mnist_loss: 0.1049, d_svhn_loss: 0.1139, d_fake_loss: 0.2966, g_loss: 1.5341\n",
            "Step [1760/60000], d_real_loss: 0.1410, d_mnist_loss: 0.0585, d_svhn_loss: 0.0824, d_fake_loss: 0.1038, g_loss: 1.2465\n",
            "Step [1770/60000], d_real_loss: 0.4239, d_mnist_loss: 0.0714, d_svhn_loss: 0.3524, d_fake_loss: 0.4655, g_loss: 1.0661\n",
            "Step [1780/60000], d_real_loss: 0.3767, d_mnist_loss: 0.0877, d_svhn_loss: 0.2890, d_fake_loss: 0.5323, g_loss: 1.1375\n",
            "Step [1790/60000], d_real_loss: 0.1795, d_mnist_loss: 0.1087, d_svhn_loss: 0.0708, d_fake_loss: 0.2148, g_loss: 1.0168\n",
            "Step [1800/60000], d_real_loss: 0.2119, d_mnist_loss: 0.1135, d_svhn_loss: 0.0984, d_fake_loss: 0.1698, g_loss: 1.2985\n",
            "Step [1810/60000], d_real_loss: 0.0847, d_mnist_loss: 0.0451, d_svhn_loss: 0.0396, d_fake_loss: 0.0966, g_loss: 1.3369\n",
            "Step [1820/60000], d_real_loss: 0.2458, d_mnist_loss: 0.0697, d_svhn_loss: 0.1762, d_fake_loss: 0.6597, g_loss: 1.1675\n",
            "Step [1830/60000], d_real_loss: 0.4685, d_mnist_loss: 0.2470, d_svhn_loss: 0.2215, d_fake_loss: 0.1871, g_loss: 0.8583\n",
            "Step [1840/60000], d_real_loss: 0.1505, d_mnist_loss: 0.0649, d_svhn_loss: 0.0855, d_fake_loss: 0.1483, g_loss: 1.4164\n",
            "Step [1850/60000], d_real_loss: 0.2158, d_mnist_loss: 0.1602, d_svhn_loss: 0.0557, d_fake_loss: 0.0906, g_loss: 1.4728\n",
            "Step [1860/60000], d_real_loss: 0.2206, d_mnist_loss: 0.0480, d_svhn_loss: 0.1726, d_fake_loss: 0.1128, g_loss: 1.1913\n",
            "Step [1870/60000], d_real_loss: 0.2204, d_mnist_loss: 0.0427, d_svhn_loss: 0.1777, d_fake_loss: 0.1549, g_loss: 1.3341\n",
            "Step [1880/60000], d_real_loss: 0.6598, d_mnist_loss: 0.2829, d_svhn_loss: 0.3769, d_fake_loss: 0.3089, g_loss: 1.4285\n",
            "Step [1890/60000], d_real_loss: 0.1211, d_mnist_loss: 0.0417, d_svhn_loss: 0.0794, d_fake_loss: 0.1932, g_loss: 1.0410\n",
            "Step [1900/60000], d_real_loss: 0.1700, d_mnist_loss: 0.0718, d_svhn_loss: 0.0983, d_fake_loss: 0.1634, g_loss: 1.3352\n",
            "Step [1910/60000], d_real_loss: 0.1568, d_mnist_loss: 0.0496, d_svhn_loss: 0.1072, d_fake_loss: 0.2474, g_loss: 1.3713\n",
            "Step [1920/60000], d_real_loss: 0.1506, d_mnist_loss: 0.0587, d_svhn_loss: 0.0919, d_fake_loss: 0.2186, g_loss: 1.5415\n",
            "Step [1930/60000], d_real_loss: 0.5109, d_mnist_loss: 0.3292, d_svhn_loss: 0.1817, d_fake_loss: 0.3710, g_loss: 1.7360\n",
            "Step [1940/60000], d_real_loss: 0.2327, d_mnist_loss: 0.0506, d_svhn_loss: 0.1821, d_fake_loss: 0.1820, g_loss: 1.3941\n",
            "Step [1950/60000], d_real_loss: 0.2675, d_mnist_loss: 0.0658, d_svhn_loss: 0.2017, d_fake_loss: 0.1721, g_loss: 0.6818\n",
            "Step [1960/60000], d_real_loss: 0.1872, d_mnist_loss: 0.0367, d_svhn_loss: 0.1505, d_fake_loss: 0.0958, g_loss: 1.0242\n",
            "Step [1970/60000], d_real_loss: 0.1892, d_mnist_loss: 0.0658, d_svhn_loss: 0.1234, d_fake_loss: 0.1376, g_loss: 1.3093\n",
            "Step [1980/60000], d_real_loss: 0.1874, d_mnist_loss: 0.1140, d_svhn_loss: 0.0734, d_fake_loss: 0.1017, g_loss: 1.2032\n",
            "Step [1990/60000], d_real_loss: 0.2172, d_mnist_loss: 0.0752, d_svhn_loss: 0.1420, d_fake_loss: 0.0763, g_loss: 1.1164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [2000/60000], d_real_loss: 0.2210, d_mnist_loss: 0.0570, d_svhn_loss: 0.1640, d_fake_loss: 0.0881, g_loss: 1.1563\n",
            "saved ./samples_fashion/sample-2000-m-s.png\n",
            "saved ./samples_fashion/sample-2000-s-m.png\n",
            "Step [2010/60000], d_real_loss: 0.3712, d_mnist_loss: 0.0503, d_svhn_loss: 0.3209, d_fake_loss: 0.1319, g_loss: 1.3173\n",
            "Step [2020/60000], d_real_loss: 0.3796, d_mnist_loss: 0.3026, d_svhn_loss: 0.0770, d_fake_loss: 0.3031, g_loss: 1.9868\n",
            "Step [2030/60000], d_real_loss: 0.1651, d_mnist_loss: 0.0499, d_svhn_loss: 0.1152, d_fake_loss: 0.2740, g_loss: 1.1480\n",
            "Step [2040/60000], d_real_loss: 0.1399, d_mnist_loss: 0.0464, d_svhn_loss: 0.0935, d_fake_loss: 0.3459, g_loss: 1.6348\n",
            "Step [2050/60000], d_real_loss: 0.0994, d_mnist_loss: 0.0541, d_svhn_loss: 0.0453, d_fake_loss: 0.1755, g_loss: 1.4561\n",
            "Step [2060/60000], d_real_loss: 0.1877, d_mnist_loss: 0.1418, d_svhn_loss: 0.0460, d_fake_loss: 0.1933, g_loss: 1.9495\n",
            "Step [2070/60000], d_real_loss: 0.1987, d_mnist_loss: 0.0574, d_svhn_loss: 0.1413, d_fake_loss: 0.2220, g_loss: 1.1967\n",
            "Step [2080/60000], d_real_loss: 0.1551, d_mnist_loss: 0.0504, d_svhn_loss: 0.1047, d_fake_loss: 0.1386, g_loss: 1.3758\n",
            "Step [2090/60000], d_real_loss: 0.1156, d_mnist_loss: 0.0851, d_svhn_loss: 0.0306, d_fake_loss: 0.0976, g_loss: 1.1847\n",
            "Step [2100/60000], d_real_loss: 0.0680, d_mnist_loss: 0.0351, d_svhn_loss: 0.0329, d_fake_loss: 0.2242, g_loss: 1.4543\n",
            "Step [2110/60000], d_real_loss: 0.1488, d_mnist_loss: 0.0373, d_svhn_loss: 0.1115, d_fake_loss: 0.1604, g_loss: 1.2977\n",
            "Step [2120/60000], d_real_loss: 0.1163, d_mnist_loss: 0.0594, d_svhn_loss: 0.0569, d_fake_loss: 0.1019, g_loss: 1.2793\n",
            "Step [2130/60000], d_real_loss: 0.1839, d_mnist_loss: 0.0582, d_svhn_loss: 0.1257, d_fake_loss: 0.0928, g_loss: 1.1806\n",
            "Step [2140/60000], d_real_loss: 0.0920, d_mnist_loss: 0.0334, d_svhn_loss: 0.0586, d_fake_loss: 0.1539, g_loss: 1.8945\n",
            "Step [2150/60000], d_real_loss: 0.1329, d_mnist_loss: 0.0842, d_svhn_loss: 0.0487, d_fake_loss: 0.1467, g_loss: 1.5424\n",
            "Step [2160/60000], d_real_loss: 0.1139, d_mnist_loss: 0.0553, d_svhn_loss: 0.0587, d_fake_loss: 0.3664, g_loss: 1.1560\n",
            "Step [2170/60000], d_real_loss: 0.1867, d_mnist_loss: 0.0602, d_svhn_loss: 0.1265, d_fake_loss: 0.2188, g_loss: 0.6182\n",
            "Step [2180/60000], d_real_loss: 0.1437, d_mnist_loss: 0.0700, d_svhn_loss: 0.0736, d_fake_loss: 0.2846, g_loss: 1.3246\n",
            "Step [2190/60000], d_real_loss: 0.2707, d_mnist_loss: 0.1258, d_svhn_loss: 0.1449, d_fake_loss: 0.2366, g_loss: 1.1715\n",
            "Step [2200/60000], d_real_loss: 0.1086, d_mnist_loss: 0.0306, d_svhn_loss: 0.0779, d_fake_loss: 0.0811, g_loss: 1.0893\n",
            "Step [2210/60000], d_real_loss: 0.1120, d_mnist_loss: 0.0413, d_svhn_loss: 0.0708, d_fake_loss: 0.1946, g_loss: 1.5672\n",
            "Step [2220/60000], d_real_loss: 0.1425, d_mnist_loss: 0.0982, d_svhn_loss: 0.0443, d_fake_loss: 0.1036, g_loss: 1.0207\n",
            "Step [2230/60000], d_real_loss: 0.2225, d_mnist_loss: 0.0526, d_svhn_loss: 0.1699, d_fake_loss: 0.0853, g_loss: 1.0836\n",
            "Step [2240/60000], d_real_loss: 0.3032, d_mnist_loss: 0.0755, d_svhn_loss: 0.2277, d_fake_loss: 0.2823, g_loss: 0.7859\n",
            "Step [2250/60000], d_real_loss: 0.2450, d_mnist_loss: 0.0707, d_svhn_loss: 0.1743, d_fake_loss: 0.1105, g_loss: 1.2054\n",
            "Step [2260/60000], d_real_loss: 0.1679, d_mnist_loss: 0.1278, d_svhn_loss: 0.0401, d_fake_loss: 0.1006, g_loss: 1.5665\n",
            "Step [2270/60000], d_real_loss: 0.1320, d_mnist_loss: 0.0821, d_svhn_loss: 0.0498, d_fake_loss: 0.2089, g_loss: 1.2868\n",
            "Step [2280/60000], d_real_loss: 0.1599, d_mnist_loss: 0.0406, d_svhn_loss: 0.1193, d_fake_loss: 0.1058, g_loss: 1.5502\n",
            "Step [2290/60000], d_real_loss: 0.0759, d_mnist_loss: 0.0384, d_svhn_loss: 0.0376, d_fake_loss: 0.1759, g_loss: 1.0270\n",
            "Step [2300/60000], d_real_loss: 0.4163, d_mnist_loss: 0.3720, d_svhn_loss: 0.0443, d_fake_loss: 0.3346, g_loss: 1.3970\n",
            "Step [2310/60000], d_real_loss: 0.1158, d_mnist_loss: 0.0473, d_svhn_loss: 0.0685, d_fake_loss: 0.0833, g_loss: 1.0400\n",
            "Step [2320/60000], d_real_loss: 0.3863, d_mnist_loss: 0.2435, d_svhn_loss: 0.1428, d_fake_loss: 0.3477, g_loss: 1.3768\n",
            "Step [2330/60000], d_real_loss: 0.1028, d_mnist_loss: 0.0394, d_svhn_loss: 0.0634, d_fake_loss: 0.2297, g_loss: 1.1898\n",
            "Step [2340/60000], d_real_loss: 0.0834, d_mnist_loss: 0.0398, d_svhn_loss: 0.0436, d_fake_loss: 0.0663, g_loss: 1.1000\n",
            "Step [2350/60000], d_real_loss: 0.1162, d_mnist_loss: 0.0562, d_svhn_loss: 0.0600, d_fake_loss: 0.2029, g_loss: 1.6951\n",
            "Step [2360/60000], d_real_loss: 0.1732, d_mnist_loss: 0.0484, d_svhn_loss: 0.1248, d_fake_loss: 0.1078, g_loss: 1.0309\n",
            "Step [2370/60000], d_real_loss: 0.1613, d_mnist_loss: 0.0606, d_svhn_loss: 0.1007, d_fake_loss: 0.2109, g_loss: 0.7758\n",
            "Step [2380/60000], d_real_loss: 0.1445, d_mnist_loss: 0.0552, d_svhn_loss: 0.0893, d_fake_loss: 0.1638, g_loss: 1.1491\n",
            "Step [2390/60000], d_real_loss: 0.1359, d_mnist_loss: 0.0498, d_svhn_loss: 0.0860, d_fake_loss: 0.1536, g_loss: 1.0934\n",
            "Step [2400/60000], d_real_loss: 0.2284, d_mnist_loss: 0.0292, d_svhn_loss: 0.1992, d_fake_loss: 0.0746, g_loss: 1.1632\n",
            "Step [2410/60000], d_real_loss: 0.1926, d_mnist_loss: 0.0745, d_svhn_loss: 0.1181, d_fake_loss: 0.1642, g_loss: 1.0383\n",
            "Step [2420/60000], d_real_loss: 0.0990, d_mnist_loss: 0.0595, d_svhn_loss: 0.0395, d_fake_loss: 0.2609, g_loss: 1.7284\n",
            "Step [2430/60000], d_real_loss: 0.2493, d_mnist_loss: 0.0325, d_svhn_loss: 0.2168, d_fake_loss: 0.2536, g_loss: 1.0295\n",
            "Step [2440/60000], d_real_loss: 0.1486, d_mnist_loss: 0.0638, d_svhn_loss: 0.0848, d_fake_loss: 0.2214, g_loss: 1.2205\n",
            "Step [2450/60000], d_real_loss: 0.2422, d_mnist_loss: 0.1807, d_svhn_loss: 0.0616, d_fake_loss: 0.0901, g_loss: 1.6205\n",
            "Step [2460/60000], d_real_loss: 0.1875, d_mnist_loss: 0.0585, d_svhn_loss: 0.1290, d_fake_loss: 0.3947, g_loss: 1.8156\n",
            "Step [2470/60000], d_real_loss: 0.1591, d_mnist_loss: 0.1035, d_svhn_loss: 0.0556, d_fake_loss: 0.1345, g_loss: 1.0519\n",
            "Step [2480/60000], d_real_loss: 0.1464, d_mnist_loss: 0.0515, d_svhn_loss: 0.0949, d_fake_loss: 0.2370, g_loss: 1.1709\n",
            "Step [2490/60000], d_real_loss: 0.1551, d_mnist_loss: 0.0618, d_svhn_loss: 0.0933, d_fake_loss: 0.1494, g_loss: 1.2447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [2500/60000], d_real_loss: 0.1571, d_mnist_loss: 0.0583, d_svhn_loss: 0.0988, d_fake_loss: 0.1419, g_loss: 1.1003\n",
            "saved ./samples_fashion/sample-2500-m-s.png\n",
            "saved ./samples_fashion/sample-2500-s-m.png\n",
            "Step [2510/60000], d_real_loss: 0.3670, d_mnist_loss: 0.2596, d_svhn_loss: 0.1073, d_fake_loss: 0.2257, g_loss: 1.2994\n",
            "Step [2520/60000], d_real_loss: 0.1253, d_mnist_loss: 0.0555, d_svhn_loss: 0.0698, d_fake_loss: 0.1634, g_loss: 0.9578\n",
            "Step [2530/60000], d_real_loss: 0.3000, d_mnist_loss: 0.0437, d_svhn_loss: 0.2563, d_fake_loss: 0.0612, g_loss: 1.0891\n",
            "Step [2540/60000], d_real_loss: 0.3667, d_mnist_loss: 0.0429, d_svhn_loss: 0.3238, d_fake_loss: 0.1827, g_loss: 0.9744\n",
            "Step [2550/60000], d_real_loss: 0.4482, d_mnist_loss: 0.3792, d_svhn_loss: 0.0690, d_fake_loss: 0.2619, g_loss: 1.1288\n",
            "Step [2560/60000], d_real_loss: 0.2341, d_mnist_loss: 0.0406, d_svhn_loss: 0.1935, d_fake_loss: 0.1217, g_loss: 1.4314\n",
            "Step [2570/60000], d_real_loss: 0.2085, d_mnist_loss: 0.1544, d_svhn_loss: 0.0541, d_fake_loss: 0.0803, g_loss: 1.2504\n",
            "Step [2580/60000], d_real_loss: 0.0965, d_mnist_loss: 0.0459, d_svhn_loss: 0.0507, d_fake_loss: 0.2718, g_loss: 0.5822\n",
            "Step [2590/60000], d_real_loss: 0.2546, d_mnist_loss: 0.1252, d_svhn_loss: 0.1294, d_fake_loss: 0.2689, g_loss: 1.5748\n",
            "Step [2600/60000], d_real_loss: 0.3508, d_mnist_loss: 0.0661, d_svhn_loss: 0.2848, d_fake_loss: 0.1531, g_loss: 1.3027\n",
            "Step [2610/60000], d_real_loss: 0.3876, d_mnist_loss: 0.1337, d_svhn_loss: 0.2539, d_fake_loss: 0.3065, g_loss: 1.1895\n",
            "Step [2620/60000], d_real_loss: 0.1620, d_mnist_loss: 0.0311, d_svhn_loss: 0.1310, d_fake_loss: 0.1206, g_loss: 1.3487\n",
            "Step [2630/60000], d_real_loss: 0.1940, d_mnist_loss: 0.0413, d_svhn_loss: 0.1527, d_fake_loss: 0.0951, g_loss: 1.4181\n",
            "Step [2640/60000], d_real_loss: 0.0984, d_mnist_loss: 0.0464, d_svhn_loss: 0.0520, d_fake_loss: 0.3847, g_loss: 1.7263\n",
            "Step [2650/60000], d_real_loss: 0.3289, d_mnist_loss: 0.1788, d_svhn_loss: 0.1501, d_fake_loss: 0.2571, g_loss: 1.3111\n",
            "Step [2660/60000], d_real_loss: 0.1942, d_mnist_loss: 0.0335, d_svhn_loss: 0.1608, d_fake_loss: 0.0869, g_loss: 1.1061\n",
            "Step [2670/60000], d_real_loss: 0.1786, d_mnist_loss: 0.0555, d_svhn_loss: 0.1230, d_fake_loss: 0.1421, g_loss: 1.1017\n",
            "Step [2680/60000], d_real_loss: 0.1666, d_mnist_loss: 0.0421, d_svhn_loss: 0.1245, d_fake_loss: 0.2007, g_loss: 1.2168\n",
            "Step [2690/60000], d_real_loss: 0.1249, d_mnist_loss: 0.0342, d_svhn_loss: 0.0907, d_fake_loss: 0.1049, g_loss: 1.5173\n",
            "Step [2700/60000], d_real_loss: 0.1138, d_mnist_loss: 0.0631, d_svhn_loss: 0.0508, d_fake_loss: 0.2749, g_loss: 0.5681\n",
            "Step [2710/60000], d_real_loss: 0.1673, d_mnist_loss: 0.0790, d_svhn_loss: 0.0884, d_fake_loss: 0.2722, g_loss: 1.2257\n",
            "Step [2720/60000], d_real_loss: 0.2418, d_mnist_loss: 0.0889, d_svhn_loss: 0.1529, d_fake_loss: 0.0977, g_loss: 1.3295\n",
            "Step [2730/60000], d_real_loss: 0.2025, d_mnist_loss: 0.0891, d_svhn_loss: 0.1134, d_fake_loss: 0.3406, g_loss: 1.6139\n",
            "Step [2740/60000], d_real_loss: 0.0881, d_mnist_loss: 0.0373, d_svhn_loss: 0.0508, d_fake_loss: 0.1055, g_loss: 1.2516\n",
            "Step [2750/60000], d_real_loss: 0.1307, d_mnist_loss: 0.0278, d_svhn_loss: 0.1030, d_fake_loss: 0.0753, g_loss: 1.1661\n",
            "Step [2760/60000], d_real_loss: 0.1126, d_mnist_loss: 0.0403, d_svhn_loss: 0.0723, d_fake_loss: 0.2794, g_loss: 1.3580\n",
            "Step [2770/60000], d_real_loss: 0.1616, d_mnist_loss: 0.0312, d_svhn_loss: 0.1304, d_fake_loss: 0.0967, g_loss: 1.4640\n",
            "Step [2780/60000], d_real_loss: 0.1547, d_mnist_loss: 0.0464, d_svhn_loss: 0.1082, d_fake_loss: 0.2917, g_loss: 1.3842\n",
            "Step [2790/60000], d_real_loss: 0.2217, d_mnist_loss: 0.0281, d_svhn_loss: 0.1936, d_fake_loss: 0.1539, g_loss: 1.0862\n",
            "Step [2800/60000], d_real_loss: 0.1707, d_mnist_loss: 0.0325, d_svhn_loss: 0.1382, d_fake_loss: 0.2193, g_loss: 1.5589\n",
            "Step [2810/60000], d_real_loss: 0.0738, d_mnist_loss: 0.0262, d_svhn_loss: 0.0477, d_fake_loss: 0.0692, g_loss: 1.1012\n",
            "Step [2820/60000], d_real_loss: 0.1629, d_mnist_loss: 0.0903, d_svhn_loss: 0.0725, d_fake_loss: 0.0948, g_loss: 1.5682\n",
            "Step [2830/60000], d_real_loss: 0.1022, d_mnist_loss: 0.0442, d_svhn_loss: 0.0580, d_fake_loss: 0.0997, g_loss: 1.0497\n",
            "Step [2840/60000], d_real_loss: 0.0923, d_mnist_loss: 0.0373, d_svhn_loss: 0.0550, d_fake_loss: 0.0649, g_loss: 1.2223\n",
            "Step [2850/60000], d_real_loss: 0.1826, d_mnist_loss: 0.0750, d_svhn_loss: 0.1076, d_fake_loss: 0.3208, g_loss: 1.5466\n",
            "Step [2860/60000], d_real_loss: 0.2505, d_mnist_loss: 0.1601, d_svhn_loss: 0.0904, d_fake_loss: 0.0993, g_loss: 1.3008\n",
            "Step [2870/60000], d_real_loss: 0.0905, d_mnist_loss: 0.0299, d_svhn_loss: 0.0606, d_fake_loss: 0.1031, g_loss: 1.0365\n",
            "Step [2880/60000], d_real_loss: 0.1952, d_mnist_loss: 0.0310, d_svhn_loss: 0.1643, d_fake_loss: 0.3584, g_loss: 1.5996\n",
            "Step [2890/60000], d_real_loss: 0.0860, d_mnist_loss: 0.0453, d_svhn_loss: 0.0408, d_fake_loss: 0.1712, g_loss: 1.3241\n",
            "Step [2900/60000], d_real_loss: 0.1955, d_mnist_loss: 0.0439, d_svhn_loss: 0.1516, d_fake_loss: 0.1224, g_loss: 1.1205\n",
            "Step [2910/60000], d_real_loss: 0.1634, d_mnist_loss: 0.0587, d_svhn_loss: 0.1048, d_fake_loss: 0.1078, g_loss: 0.9153\n",
            "Step [2920/60000], d_real_loss: 0.1528, d_mnist_loss: 0.0489, d_svhn_loss: 0.1039, d_fake_loss: 0.0902, g_loss: 1.0843\n",
            "Step [2930/60000], d_real_loss: 0.2209, d_mnist_loss: 0.0492, d_svhn_loss: 0.1717, d_fake_loss: 0.0783, g_loss: 1.0771\n",
            "Step [2940/60000], d_real_loss: 0.0678, d_mnist_loss: 0.0328, d_svhn_loss: 0.0350, d_fake_loss: 0.0868, g_loss: 1.1337\n",
            "Step [2950/60000], d_real_loss: 0.0805, d_mnist_loss: 0.0277, d_svhn_loss: 0.0528, d_fake_loss: 0.1578, g_loss: 1.4309\n",
            "Step [2960/60000], d_real_loss: 0.1784, d_mnist_loss: 0.0567, d_svhn_loss: 0.1217, d_fake_loss: 0.1598, g_loss: 1.0578\n",
            "Step [2970/60000], d_real_loss: 0.6201, d_mnist_loss: 0.5407, d_svhn_loss: 0.0794, d_fake_loss: 0.1915, g_loss: 1.2891\n",
            "Step [2980/60000], d_real_loss: 0.0893, d_mnist_loss: 0.0369, d_svhn_loss: 0.0524, d_fake_loss: 0.1060, g_loss: 1.2230\n",
            "Step [2990/60000], d_real_loss: 0.1579, d_mnist_loss: 0.0498, d_svhn_loss: 0.1081, d_fake_loss: 0.2143, g_loss: 1.3876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [3000/60000], d_real_loss: 0.2256, d_mnist_loss: 0.0312, d_svhn_loss: 0.1944, d_fake_loss: 0.2853, g_loss: 1.3859\n",
            "saved ./samples_fashion/sample-3000-m-s.png\n",
            "saved ./samples_fashion/sample-3000-s-m.png\n",
            "Step [3010/60000], d_real_loss: 0.1199, d_mnist_loss: 0.0593, d_svhn_loss: 0.0607, d_fake_loss: 0.0850, g_loss: 1.1727\n",
            "Step [3020/60000], d_real_loss: 0.0783, d_mnist_loss: 0.0246, d_svhn_loss: 0.0537, d_fake_loss: 0.0758, g_loss: 1.3412\n",
            "Step [3030/60000], d_real_loss: 0.0785, d_mnist_loss: 0.0470, d_svhn_loss: 0.0315, d_fake_loss: 0.0558, g_loss: 1.1886\n",
            "Step [3040/60000], d_real_loss: 0.0762, d_mnist_loss: 0.0287, d_svhn_loss: 0.0475, d_fake_loss: 0.0565, g_loss: 1.0837\n",
            "Step [3050/60000], d_real_loss: 0.0844, d_mnist_loss: 0.0335, d_svhn_loss: 0.0508, d_fake_loss: 0.1167, g_loss: 1.6174\n",
            "Step [3060/60000], d_real_loss: 0.2161, d_mnist_loss: 0.0711, d_svhn_loss: 0.1450, d_fake_loss: 0.1898, g_loss: 1.3331\n",
            "Step [3070/60000], d_real_loss: 0.1453, d_mnist_loss: 0.0444, d_svhn_loss: 0.1009, d_fake_loss: 0.2668, g_loss: 1.2569\n",
            "Step [3080/60000], d_real_loss: 0.1900, d_mnist_loss: 0.0292, d_svhn_loss: 0.1608, d_fake_loss: 0.1722, g_loss: 1.1887\n",
            "Step [3090/60000], d_real_loss: 0.0969, d_mnist_loss: 0.0427, d_svhn_loss: 0.0542, d_fake_loss: 0.1357, g_loss: 1.5554\n",
            "Step [3100/60000], d_real_loss: 0.0688, d_mnist_loss: 0.0341, d_svhn_loss: 0.0346, d_fake_loss: 0.0582, g_loss: 1.2038\n",
            "Step [3110/60000], d_real_loss: 0.1883, d_mnist_loss: 0.0595, d_svhn_loss: 0.1288, d_fake_loss: 0.1937, g_loss: 1.3672\n",
            "Step [3120/60000], d_real_loss: 0.1757, d_mnist_loss: 0.0263, d_svhn_loss: 0.1494, d_fake_loss: 0.0644, g_loss: 1.2268\n",
            "Step [3130/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0239, d_svhn_loss: 0.0414, d_fake_loss: 0.0735, g_loss: 1.3471\n",
            "Step [3140/60000], d_real_loss: 0.1777, d_mnist_loss: 0.0535, d_svhn_loss: 0.1242, d_fake_loss: 0.1738, g_loss: 0.9625\n",
            "Step [3150/60000], d_real_loss: 0.2409, d_mnist_loss: 0.0352, d_svhn_loss: 0.2056, d_fake_loss: 0.0917, g_loss: 1.3013\n",
            "Step [3160/60000], d_real_loss: 0.3013, d_mnist_loss: 0.2260, d_svhn_loss: 0.0753, d_fake_loss: 0.1178, g_loss: 1.4786\n",
            "Step [3170/60000], d_real_loss: 0.1116, d_mnist_loss: 0.0303, d_svhn_loss: 0.0813, d_fake_loss: 0.0680, g_loss: 1.3436\n",
            "Step [3180/60000], d_real_loss: 0.2360, d_mnist_loss: 0.1827, d_svhn_loss: 0.0533, d_fake_loss: 0.0581, g_loss: 1.2254\n",
            "Step [3190/60000], d_real_loss: 0.2650, d_mnist_loss: 0.0849, d_svhn_loss: 0.1801, d_fake_loss: 0.1490, g_loss: 1.3608\n",
            "Step [3200/60000], d_real_loss: 0.1408, d_mnist_loss: 0.0350, d_svhn_loss: 0.1058, d_fake_loss: 0.0699, g_loss: 1.1572\n",
            "Step [3210/60000], d_real_loss: 0.1621, d_mnist_loss: 0.0609, d_svhn_loss: 0.1012, d_fake_loss: 0.2018, g_loss: 0.9364\n",
            "Step [3220/60000], d_real_loss: 0.0859, d_mnist_loss: 0.0337, d_svhn_loss: 0.0522, d_fake_loss: 0.2052, g_loss: 1.7279\n",
            "Step [3230/60000], d_real_loss: 0.2272, d_mnist_loss: 0.1660, d_svhn_loss: 0.0612, d_fake_loss: 0.2221, g_loss: 1.2915\n",
            "Step [3240/60000], d_real_loss: 0.1725, d_mnist_loss: 0.0723, d_svhn_loss: 0.1001, d_fake_loss: 0.0744, g_loss: 1.4790\n",
            "Step [3250/60000], d_real_loss: 0.1643, d_mnist_loss: 0.0644, d_svhn_loss: 0.0999, d_fake_loss: 0.0903, g_loss: 1.0317\n",
            "Step [3260/60000], d_real_loss: 0.0813, d_mnist_loss: 0.0315, d_svhn_loss: 0.0499, d_fake_loss: 0.0738, g_loss: 1.4691\n",
            "Step [3270/60000], d_real_loss: 0.0861, d_mnist_loss: 0.0400, d_svhn_loss: 0.0461, d_fake_loss: 0.7577, g_loss: 1.1793\n",
            "Step [3280/60000], d_real_loss: 0.1464, d_mnist_loss: 0.1175, d_svhn_loss: 0.0288, d_fake_loss: 0.2007, g_loss: 1.7270\n",
            "Step [3290/60000], d_real_loss: 0.1244, d_mnist_loss: 0.0530, d_svhn_loss: 0.0714, d_fake_loss: 0.1015, g_loss: 0.8376\n",
            "Step [3300/60000], d_real_loss: 0.1101, d_mnist_loss: 0.0601, d_svhn_loss: 0.0500, d_fake_loss: 0.0831, g_loss: 1.2032\n",
            "Step [3310/60000], d_real_loss: 0.1205, d_mnist_loss: 0.0312, d_svhn_loss: 0.0893, d_fake_loss: 0.2540, g_loss: 1.4294\n",
            "Step [3320/60000], d_real_loss: 0.0818, d_mnist_loss: 0.0331, d_svhn_loss: 0.0487, d_fake_loss: 0.0741, g_loss: 1.1850\n",
            "Step [3330/60000], d_real_loss: 0.1248, d_mnist_loss: 0.0585, d_svhn_loss: 0.0663, d_fake_loss: 0.1609, g_loss: 1.1671\n",
            "Step [3340/60000], d_real_loss: 0.1135, d_mnist_loss: 0.0246, d_svhn_loss: 0.0890, d_fake_loss: 0.0869, g_loss: 1.2767\n",
            "Step [3350/60000], d_real_loss: 0.1545, d_mnist_loss: 0.0440, d_svhn_loss: 0.1105, d_fake_loss: 0.0497, g_loss: 0.9321\n",
            "Step [3360/60000], d_real_loss: 0.2738, d_mnist_loss: 0.0601, d_svhn_loss: 0.2137, d_fake_loss: 0.1509, g_loss: 1.7306\n",
            "Step [3370/60000], d_real_loss: 0.1062, d_mnist_loss: 0.0443, d_svhn_loss: 0.0619, d_fake_loss: 0.1042, g_loss: 1.3399\n",
            "Step [3380/60000], d_real_loss: 0.1392, d_mnist_loss: 0.0944, d_svhn_loss: 0.0448, d_fake_loss: 0.3030, g_loss: 1.5165\n",
            "Step [3390/60000], d_real_loss: 0.1512, d_mnist_loss: 0.0255, d_svhn_loss: 0.1258, d_fake_loss: 0.0628, g_loss: 1.2696\n",
            "Step [3400/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0247, d_svhn_loss: 0.0418, d_fake_loss: 0.0719, g_loss: 1.2759\n",
            "Step [3410/60000], d_real_loss: 0.1514, d_mnist_loss: 0.0361, d_svhn_loss: 0.1153, d_fake_loss: 0.1079, g_loss: 0.8259\n",
            "Step [3420/60000], d_real_loss: 0.2033, d_mnist_loss: 0.0611, d_svhn_loss: 0.1422, d_fake_loss: 0.2851, g_loss: 1.5932\n",
            "Step [3430/60000], d_real_loss: 0.0831, d_mnist_loss: 0.0409, d_svhn_loss: 0.0422, d_fake_loss: 0.1229, g_loss: 1.2096\n",
            "Step [3440/60000], d_real_loss: 0.1039, d_mnist_loss: 0.0525, d_svhn_loss: 0.0514, d_fake_loss: 0.1041, g_loss: 1.2532\n",
            "Step [3450/60000], d_real_loss: 0.1461, d_mnist_loss: 0.0313, d_svhn_loss: 0.1148, d_fake_loss: 0.1346, g_loss: 1.3941\n",
            "Step [3460/60000], d_real_loss: 0.0927, d_mnist_loss: 0.0234, d_svhn_loss: 0.0694, d_fake_loss: 0.0672, g_loss: 1.2166\n",
            "Step [3470/60000], d_real_loss: 0.0724, d_mnist_loss: 0.0359, d_svhn_loss: 0.0365, d_fake_loss: 0.1900, g_loss: 1.1774\n",
            "Step [3480/60000], d_real_loss: 0.1879, d_mnist_loss: 0.0918, d_svhn_loss: 0.0962, d_fake_loss: 0.1981, g_loss: 1.3001\n",
            "Step [3490/60000], d_real_loss: 0.0689, d_mnist_loss: 0.0288, d_svhn_loss: 0.0402, d_fake_loss: 0.0532, g_loss: 0.9607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [3500/60000], d_real_loss: 0.4437, d_mnist_loss: 0.1474, d_svhn_loss: 0.2963, d_fake_loss: 0.2555, g_loss: 1.4985\n",
            "saved ./samples_fashion/sample-3500-m-s.png\n",
            "saved ./samples_fashion/sample-3500-s-m.png\n",
            "Step [3510/60000], d_real_loss: 0.1008, d_mnist_loss: 0.0525, d_svhn_loss: 0.0483, d_fake_loss: 0.2142, g_loss: 1.3336\n",
            "Step [3520/60000], d_real_loss: 0.2314, d_mnist_loss: 0.1213, d_svhn_loss: 0.1101, d_fake_loss: 0.1198, g_loss: 1.0872\n",
            "Step [3530/60000], d_real_loss: 0.0966, d_mnist_loss: 0.0179, d_svhn_loss: 0.0787, d_fake_loss: 0.1238, g_loss: 1.2504\n",
            "Step [3540/60000], d_real_loss: 0.1465, d_mnist_loss: 0.0416, d_svhn_loss: 0.1049, d_fake_loss: 0.1430, g_loss: 1.0015\n",
            "Step [3550/60000], d_real_loss: 0.0646, d_mnist_loss: 0.0308, d_svhn_loss: 0.0338, d_fake_loss: 0.0705, g_loss: 1.1574\n",
            "Step [3560/60000], d_real_loss: 0.0779, d_mnist_loss: 0.0245, d_svhn_loss: 0.0533, d_fake_loss: 0.0528, g_loss: 1.2391\n",
            "Step [3570/60000], d_real_loss: 0.0911, d_mnist_loss: 0.0345, d_svhn_loss: 0.0565, d_fake_loss: 0.2447, g_loss: 1.5720\n",
            "Step [3580/60000], d_real_loss: 0.0792, d_mnist_loss: 0.0321, d_svhn_loss: 0.0471, d_fake_loss: 0.0728, g_loss: 1.1080\n",
            "Step [3590/60000], d_real_loss: 0.0922, d_mnist_loss: 0.0236, d_svhn_loss: 0.0686, d_fake_loss: 0.0839, g_loss: 1.2385\n",
            "Step [3600/60000], d_real_loss: 0.0972, d_mnist_loss: 0.0280, d_svhn_loss: 0.0692, d_fake_loss: 0.0677, g_loss: 1.0855\n",
            "Step [3610/60000], d_real_loss: 0.1741, d_mnist_loss: 0.1134, d_svhn_loss: 0.0607, d_fake_loss: 0.1120, g_loss: 0.9630\n",
            "Step [3620/60000], d_real_loss: 0.0927, d_mnist_loss: 0.0562, d_svhn_loss: 0.0365, d_fake_loss: 0.1755, g_loss: 1.2243\n",
            "Step [3630/60000], d_real_loss: 0.1018, d_mnist_loss: 0.0466, d_svhn_loss: 0.0552, d_fake_loss: 0.0975, g_loss: 1.0767\n",
            "Step [3640/60000], d_real_loss: 0.0950, d_mnist_loss: 0.0567, d_svhn_loss: 0.0382, d_fake_loss: 0.0736, g_loss: 1.3450\n",
            "Step [3650/60000], d_real_loss: 0.1982, d_mnist_loss: 0.0474, d_svhn_loss: 0.1508, d_fake_loss: 0.1321, g_loss: 1.3832\n",
            "Step [3660/60000], d_real_loss: 0.0838, d_mnist_loss: 0.0210, d_svhn_loss: 0.0628, d_fake_loss: 0.0496, g_loss: 1.0837\n",
            "Step [3670/60000], d_real_loss: 0.0689, d_mnist_loss: 0.0319, d_svhn_loss: 0.0370, d_fake_loss: 0.2386, g_loss: 1.6702\n",
            "Step [3680/60000], d_real_loss: 0.0803, d_mnist_loss: 0.0326, d_svhn_loss: 0.0477, d_fake_loss: 0.1121, g_loss: 1.2293\n",
            "Step [3690/60000], d_real_loss: 0.0989, d_mnist_loss: 0.0224, d_svhn_loss: 0.0765, d_fake_loss: 0.1209, g_loss: 1.0934\n",
            "Step [3700/60000], d_real_loss: 0.2654, d_mnist_loss: 0.2372, d_svhn_loss: 0.0282, d_fake_loss: 0.4040, g_loss: 1.7276\n",
            "Step [3710/60000], d_real_loss: 0.2132, d_mnist_loss: 0.0426, d_svhn_loss: 0.1706, d_fake_loss: 0.0700, g_loss: 1.1939\n",
            "Step [3720/60000], d_real_loss: 0.0999, d_mnist_loss: 0.0422, d_svhn_loss: 0.0578, d_fake_loss: 0.1231, g_loss: 1.4614\n",
            "Step [3730/60000], d_real_loss: 0.1039, d_mnist_loss: 0.0631, d_svhn_loss: 0.0407, d_fake_loss: 0.0856, g_loss: 1.2995\n",
            "Step [3740/60000], d_real_loss: 0.1335, d_mnist_loss: 0.0912, d_svhn_loss: 0.0423, d_fake_loss: 0.1452, g_loss: 0.7729\n",
            "Step [3750/60000], d_real_loss: 0.0777, d_mnist_loss: 0.0381, d_svhn_loss: 0.0395, d_fake_loss: 0.0428, g_loss: 1.0283\n",
            "Step [3760/60000], d_real_loss: 0.1427, d_mnist_loss: 0.0276, d_svhn_loss: 0.1151, d_fake_loss: 0.0527, g_loss: 1.2491\n",
            "Step [3770/60000], d_real_loss: 0.0996, d_mnist_loss: 0.0362, d_svhn_loss: 0.0633, d_fake_loss: 0.0518, g_loss: 1.2044\n",
            "Step [3780/60000], d_real_loss: 0.1389, d_mnist_loss: 0.0582, d_svhn_loss: 0.0806, d_fake_loss: 0.1707, g_loss: 1.4705\n",
            "Step [3790/60000], d_real_loss: 0.1297, d_mnist_loss: 0.0255, d_svhn_loss: 0.1042, d_fake_loss: 0.3286, g_loss: 1.5566\n",
            "Step [3800/60000], d_real_loss: 0.1319, d_mnist_loss: 0.0208, d_svhn_loss: 0.1111, d_fake_loss: 0.0571, g_loss: 1.1774\n",
            "Step [3810/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0234, d_svhn_loss: 0.0294, d_fake_loss: 0.2218, g_loss: 1.3271\n",
            "Step [3820/60000], d_real_loss: 0.0799, d_mnist_loss: 0.0462, d_svhn_loss: 0.0337, d_fake_loss: 0.0880, g_loss: 1.3095\n",
            "Step [3830/60000], d_real_loss: 0.1182, d_mnist_loss: 0.0486, d_svhn_loss: 0.0696, d_fake_loss: 0.1927, g_loss: 1.5263\n",
            "Step [3840/60000], d_real_loss: 0.0705, d_mnist_loss: 0.0373, d_svhn_loss: 0.0332, d_fake_loss: 0.1023, g_loss: 1.3619\n",
            "Step [3850/60000], d_real_loss: 0.2730, d_mnist_loss: 0.1206, d_svhn_loss: 0.1525, d_fake_loss: 0.2147, g_loss: 1.6449\n",
            "Step [3860/60000], d_real_loss: 0.3799, d_mnist_loss: 0.0224, d_svhn_loss: 0.3576, d_fake_loss: 0.1369, g_loss: 1.0314\n",
            "Step [3870/60000], d_real_loss: 0.2636, d_mnist_loss: 0.0267, d_svhn_loss: 0.2369, d_fake_loss: 0.1766, g_loss: 1.2835\n",
            "Step [3880/60000], d_real_loss: 0.0927, d_mnist_loss: 0.0244, d_svhn_loss: 0.0683, d_fake_loss: 0.1955, g_loss: 1.1019\n",
            "Step [3890/60000], d_real_loss: 0.1361, d_mnist_loss: 0.0273, d_svhn_loss: 0.1088, d_fake_loss: 0.0466, g_loss: 1.1367\n",
            "Step [3900/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0238, d_svhn_loss: 0.0345, d_fake_loss: 0.1600, g_loss: 1.3505\n",
            "Step [3910/60000], d_real_loss: 0.1441, d_mnist_loss: 0.0652, d_svhn_loss: 0.0789, d_fake_loss: 0.4586, g_loss: 2.0634\n",
            "Step [3920/60000], d_real_loss: 0.1063, d_mnist_loss: 0.0259, d_svhn_loss: 0.0804, d_fake_loss: 0.0673, g_loss: 1.2131\n",
            "Step [3930/60000], d_real_loss: 0.0870, d_mnist_loss: 0.0310, d_svhn_loss: 0.0560, d_fake_loss: 0.1801, g_loss: 1.4160\n",
            "Step [3940/60000], d_real_loss: 0.1666, d_mnist_loss: 0.0818, d_svhn_loss: 0.0848, d_fake_loss: 0.4958, g_loss: 2.2644\n",
            "Step [3950/60000], d_real_loss: 0.1244, d_mnist_loss: 0.0483, d_svhn_loss: 0.0761, d_fake_loss: 0.0780, g_loss: 1.2497\n",
            "Step [3960/60000], d_real_loss: 0.0537, d_mnist_loss: 0.0181, d_svhn_loss: 0.0356, d_fake_loss: 0.1833, g_loss: 1.2740\n",
            "Step [3970/60000], d_real_loss: 0.1844, d_mnist_loss: 0.0315, d_svhn_loss: 0.1529, d_fake_loss: 0.2950, g_loss: 1.0416\n",
            "Step [3980/60000], d_real_loss: 0.1723, d_mnist_loss: 0.0161, d_svhn_loss: 0.1562, d_fake_loss: 0.0515, g_loss: 1.0799\n",
            "Step [3990/60000], d_real_loss: 0.2838, d_mnist_loss: 0.0493, d_svhn_loss: 0.2345, d_fake_loss: 0.2076, g_loss: 1.6717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [4000/60000], d_real_loss: 0.1459, d_mnist_loss: 0.0653, d_svhn_loss: 0.0806, d_fake_loss: 0.1248, g_loss: 1.2038\n",
            "saved ./samples_fashion/sample-4000-m-s.png\n",
            "saved ./samples_fashion/sample-4000-s-m.png\n",
            "Step [4010/60000], d_real_loss: 0.0613, d_mnist_loss: 0.0192, d_svhn_loss: 0.0421, d_fake_loss: 0.1201, g_loss: 1.2960\n",
            "Step [4020/60000], d_real_loss: 0.0582, d_mnist_loss: 0.0234, d_svhn_loss: 0.0347, d_fake_loss: 0.0486, g_loss: 1.1979\n",
            "Step [4030/60000], d_real_loss: 0.1767, d_mnist_loss: 0.0610, d_svhn_loss: 0.1157, d_fake_loss: 0.0709, g_loss: 1.0280\n",
            "Step [4040/60000], d_real_loss: 0.0635, d_mnist_loss: 0.0220, d_svhn_loss: 0.0415, d_fake_loss: 0.1043, g_loss: 1.2336\n",
            "Step [4050/60000], d_real_loss: 0.2202, d_mnist_loss: 0.1551, d_svhn_loss: 0.0651, d_fake_loss: 0.0755, g_loss: 1.0108\n",
            "Step [4060/60000], d_real_loss: 0.0502, d_mnist_loss: 0.0212, d_svhn_loss: 0.0290, d_fake_loss: 0.1404, g_loss: 1.1445\n",
            "Step [4070/60000], d_real_loss: 0.1905, d_mnist_loss: 0.0494, d_svhn_loss: 0.1411, d_fake_loss: 0.2064, g_loss: 0.9677\n",
            "Step [4080/60000], d_real_loss: 0.1081, d_mnist_loss: 0.0360, d_svhn_loss: 0.0721, d_fake_loss: 0.0664, g_loss: 1.1019\n",
            "Step [4090/60000], d_real_loss: 0.1150, d_mnist_loss: 0.0302, d_svhn_loss: 0.0848, d_fake_loss: 0.1467, g_loss: 1.1815\n",
            "Step [4100/60000], d_real_loss: 0.1090, d_mnist_loss: 0.0347, d_svhn_loss: 0.0743, d_fake_loss: 0.0390, g_loss: 1.2261\n",
            "Step [4110/60000], d_real_loss: 0.1120, d_mnist_loss: 0.0403, d_svhn_loss: 0.0717, d_fake_loss: 0.0975, g_loss: 1.3248\n",
            "Step [4120/60000], d_real_loss: 0.0647, d_mnist_loss: 0.0327, d_svhn_loss: 0.0320, d_fake_loss: 0.1119, g_loss: 1.3345\n",
            "Step [4130/60000], d_real_loss: 0.1063, d_mnist_loss: 0.0167, d_svhn_loss: 0.0896, d_fake_loss: 0.0678, g_loss: 1.0698\n",
            "Step [4140/60000], d_real_loss: 0.1452, d_mnist_loss: 0.0553, d_svhn_loss: 0.0899, d_fake_loss: 0.0991, g_loss: 0.9731\n",
            "Step [4150/60000], d_real_loss: 0.0839, d_mnist_loss: 0.0270, d_svhn_loss: 0.0570, d_fake_loss: 0.0524, g_loss: 1.1175\n",
            "Step [4160/60000], d_real_loss: 0.0831, d_mnist_loss: 0.0402, d_svhn_loss: 0.0430, d_fake_loss: 0.0904, g_loss: 1.0408\n",
            "Step [4170/60000], d_real_loss: 0.0981, d_mnist_loss: 0.0266, d_svhn_loss: 0.0715, d_fake_loss: 0.0697, g_loss: 1.1467\n",
            "Step [4180/60000], d_real_loss: 0.0890, d_mnist_loss: 0.0260, d_svhn_loss: 0.0629, d_fake_loss: 0.0456, g_loss: 1.0748\n",
            "Step [4190/60000], d_real_loss: 0.1893, d_mnist_loss: 0.0442, d_svhn_loss: 0.1451, d_fake_loss: 0.1698, g_loss: 1.5475\n",
            "Step [4200/60000], d_real_loss: 0.2263, d_mnist_loss: 0.0299, d_svhn_loss: 0.1964, d_fake_loss: 0.0710, g_loss: 1.2734\n",
            "Step [4210/60000], d_real_loss: 0.1413, d_mnist_loss: 0.0332, d_svhn_loss: 0.1081, d_fake_loss: 0.0815, g_loss: 1.4699\n",
            "Step [4220/60000], d_real_loss: 0.2507, d_mnist_loss: 0.1338, d_svhn_loss: 0.1169, d_fake_loss: 0.1359, g_loss: 1.6010\n",
            "Step [4230/60000], d_real_loss: 0.2251, d_mnist_loss: 0.1199, d_svhn_loss: 0.1052, d_fake_loss: 0.1250, g_loss: 1.5213\n",
            "Step [4240/60000], d_real_loss: 0.1591, d_mnist_loss: 0.0424, d_svhn_loss: 0.1167, d_fake_loss: 0.4992, g_loss: 2.0463\n",
            "Step [4250/60000], d_real_loss: 0.0750, d_mnist_loss: 0.0258, d_svhn_loss: 0.0492, d_fake_loss: 0.1340, g_loss: 1.3554\n",
            "Step [4260/60000], d_real_loss: 0.0773, d_mnist_loss: 0.0349, d_svhn_loss: 0.0424, d_fake_loss: 0.0768, g_loss: 1.1007\n",
            "Step [4270/60000], d_real_loss: 0.1281, d_mnist_loss: 0.0344, d_svhn_loss: 0.0936, d_fake_loss: 0.0661, g_loss: 1.2328\n",
            "Step [4280/60000], d_real_loss: 0.1414, d_mnist_loss: 0.0456, d_svhn_loss: 0.0958, d_fake_loss: 0.1714, g_loss: 1.5288\n",
            "Step [4290/60000], d_real_loss: 0.0894, d_mnist_loss: 0.0301, d_svhn_loss: 0.0594, d_fake_loss: 0.1310, g_loss: 1.3194\n",
            "Step [4300/60000], d_real_loss: 0.0795, d_mnist_loss: 0.0192, d_svhn_loss: 0.0604, d_fake_loss: 0.1494, g_loss: 1.0405\n",
            "Step [4310/60000], d_real_loss: 0.2371, d_mnist_loss: 0.1379, d_svhn_loss: 0.0991, d_fake_loss: 0.0521, g_loss: 1.3888\n",
            "Step [4320/60000], d_real_loss: 0.1880, d_mnist_loss: 0.0430, d_svhn_loss: 0.1450, d_fake_loss: 0.0949, g_loss: 0.9122\n",
            "Step [4330/60000], d_real_loss: 0.0866, d_mnist_loss: 0.0331, d_svhn_loss: 0.0534, d_fake_loss: 0.0694, g_loss: 0.9840\n",
            "Step [4340/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0305, d_svhn_loss: 0.0282, d_fake_loss: 0.0618, g_loss: 1.2592\n",
            "Step [4350/60000], d_real_loss: 0.2274, d_mnist_loss: 0.0243, d_svhn_loss: 0.2031, d_fake_loss: 0.0887, g_loss: 1.3111\n",
            "Step [4360/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0248, d_svhn_loss: 0.0424, d_fake_loss: 0.0551, g_loss: 1.0256\n",
            "Step [4370/60000], d_real_loss: 0.2270, d_mnist_loss: 0.1153, d_svhn_loss: 0.1117, d_fake_loss: 0.2225, g_loss: 1.8470\n",
            "Step [4380/60000], d_real_loss: 0.2697, d_mnist_loss: 0.0252, d_svhn_loss: 0.2445, d_fake_loss: 0.0684, g_loss: 1.0268\n",
            "Step [4390/60000], d_real_loss: 0.1194, d_mnist_loss: 0.0432, d_svhn_loss: 0.0761, d_fake_loss: 0.2161, g_loss: 0.8131\n",
            "Step [4400/60000], d_real_loss: 0.0818, d_mnist_loss: 0.0397, d_svhn_loss: 0.0422, d_fake_loss: 0.0829, g_loss: 1.1031\n",
            "Step [4410/60000], d_real_loss: 0.0957, d_mnist_loss: 0.0280, d_svhn_loss: 0.0677, d_fake_loss: 0.0679, g_loss: 1.2720\n",
            "Step [4420/60000], d_real_loss: 0.1285, d_mnist_loss: 0.0455, d_svhn_loss: 0.0830, d_fake_loss: 0.0946, g_loss: 1.4123\n",
            "Step [4430/60000], d_real_loss: 0.0986, d_mnist_loss: 0.0482, d_svhn_loss: 0.0503, d_fake_loss: 0.0858, g_loss: 1.1334\n",
            "Step [4440/60000], d_real_loss: 0.0778, d_mnist_loss: 0.0341, d_svhn_loss: 0.0437, d_fake_loss: 0.2635, g_loss: 1.7909\n",
            "Step [4450/60000], d_real_loss: 0.0790, d_mnist_loss: 0.0303, d_svhn_loss: 0.0487, d_fake_loss: 0.1417, g_loss: 1.0701\n",
            "Step [4460/60000], d_real_loss: 0.0493, d_mnist_loss: 0.0196, d_svhn_loss: 0.0297, d_fake_loss: 0.1706, g_loss: 1.3205\n",
            "Step [4470/60000], d_real_loss: 0.2336, d_mnist_loss: 0.0290, d_svhn_loss: 0.2046, d_fake_loss: 0.0878, g_loss: 1.2724\n",
            "Step [4480/60000], d_real_loss: 0.1144, d_mnist_loss: 0.0161, d_svhn_loss: 0.0983, d_fake_loss: 0.1255, g_loss: 1.0369\n",
            "Step [4490/60000], d_real_loss: 0.0924, d_mnist_loss: 0.0217, d_svhn_loss: 0.0708, d_fake_loss: 0.0440, g_loss: 1.3877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [4500/60000], d_real_loss: 0.0849, d_mnist_loss: 0.0494, d_svhn_loss: 0.0355, d_fake_loss: 0.1280, g_loss: 1.2189\n",
            "saved ./samples_fashion/sample-4500-m-s.png\n",
            "saved ./samples_fashion/sample-4500-s-m.png\n",
            "Step [4510/60000], d_real_loss: 0.1097, d_mnist_loss: 0.0653, d_svhn_loss: 0.0444, d_fake_loss: 0.2399, g_loss: 1.5671\n",
            "Step [4520/60000], d_real_loss: 0.1761, d_mnist_loss: 0.0359, d_svhn_loss: 0.1403, d_fake_loss: 0.9975, g_loss: 2.9674\n",
            "Step [4530/60000], d_real_loss: 0.0957, d_mnist_loss: 0.0485, d_svhn_loss: 0.0472, d_fake_loss: 0.1735, g_loss: 1.2519\n",
            "Step [4540/60000], d_real_loss: 0.0864, d_mnist_loss: 0.0287, d_svhn_loss: 0.0577, d_fake_loss: 0.0672, g_loss: 1.2970\n",
            "Step [4550/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0297, d_svhn_loss: 0.0355, d_fake_loss: 0.0687, g_loss: 0.9648\n",
            "Step [4560/60000], d_real_loss: 0.1700, d_mnist_loss: 0.1272, d_svhn_loss: 0.0428, d_fake_loss: 0.1121, g_loss: 1.4425\n",
            "Step [4570/60000], d_real_loss: 0.2482, d_mnist_loss: 0.1890, d_svhn_loss: 0.0592, d_fake_loss: 0.0985, g_loss: 1.3755\n",
            "Step [4580/60000], d_real_loss: 0.2066, d_mnist_loss: 0.0283, d_svhn_loss: 0.1783, d_fake_loss: 0.1290, g_loss: 1.1188\n",
            "Step [4590/60000], d_real_loss: 0.1027, d_mnist_loss: 0.0411, d_svhn_loss: 0.0617, d_fake_loss: 0.1268, g_loss: 1.2296\n",
            "Step [4600/60000], d_real_loss: 0.0692, d_mnist_loss: 0.0167, d_svhn_loss: 0.0524, d_fake_loss: 0.1016, g_loss: 1.1241\n",
            "Step [4610/60000], d_real_loss: 0.3813, d_mnist_loss: 0.0228, d_svhn_loss: 0.3584, d_fake_loss: 0.0910, g_loss: 1.1217\n",
            "Step [4620/60000], d_real_loss: 0.1215, d_mnist_loss: 0.0225, d_svhn_loss: 0.0990, d_fake_loss: 0.4265, g_loss: 1.1142\n",
            "Step [4630/60000], d_real_loss: 0.1982, d_mnist_loss: 0.0405, d_svhn_loss: 0.1577, d_fake_loss: 0.0757, g_loss: 1.1588\n",
            "Step [4640/60000], d_real_loss: 0.0878, d_mnist_loss: 0.0212, d_svhn_loss: 0.0667, d_fake_loss: 0.0439, g_loss: 1.1109\n",
            "Step [4650/60000], d_real_loss: 0.0814, d_mnist_loss: 0.0261, d_svhn_loss: 0.0553, d_fake_loss: 0.1507, g_loss: 1.0175\n",
            "Step [4660/60000], d_real_loss: 0.0918, d_mnist_loss: 0.0275, d_svhn_loss: 0.0643, d_fake_loss: 0.0638, g_loss: 1.0486\n",
            "Step [4670/60000], d_real_loss: 0.3699, d_mnist_loss: 0.0420, d_svhn_loss: 0.3279, d_fake_loss: 0.1885, g_loss: 1.2018\n",
            "Step [4680/60000], d_real_loss: 0.7745, d_mnist_loss: 0.7342, d_svhn_loss: 0.0404, d_fake_loss: 0.1050, g_loss: 1.4355\n",
            "Step [4690/60000], d_real_loss: 0.1736, d_mnist_loss: 0.1424, d_svhn_loss: 0.0312, d_fake_loss: 0.0960, g_loss: 1.1863\n",
            "Step [4700/60000], d_real_loss: 0.1029, d_mnist_loss: 0.0580, d_svhn_loss: 0.0449, d_fake_loss: 0.1448, g_loss: 1.5050\n",
            "Step [4710/60000], d_real_loss: 0.0827, d_mnist_loss: 0.0265, d_svhn_loss: 0.0562, d_fake_loss: 0.0551, g_loss: 1.1852\n",
            "Step [4720/60000], d_real_loss: 0.1014, d_mnist_loss: 0.0387, d_svhn_loss: 0.0627, d_fake_loss: 0.2165, g_loss: 1.1772\n",
            "Step [4730/60000], d_real_loss: 0.1436, d_mnist_loss: 0.0264, d_svhn_loss: 0.1172, d_fake_loss: 0.1035, g_loss: 1.3856\n",
            "Step [4740/60000], d_real_loss: 0.0685, d_mnist_loss: 0.0314, d_svhn_loss: 0.0371, d_fake_loss: 0.1918, g_loss: 0.8142\n",
            "Step [4750/60000], d_real_loss: 0.1282, d_mnist_loss: 0.0502, d_svhn_loss: 0.0780, d_fake_loss: 0.0734, g_loss: 1.2917\n",
            "Step [4760/60000], d_real_loss: 0.2781, d_mnist_loss: 0.0392, d_svhn_loss: 0.2389, d_fake_loss: 0.0893, g_loss: 1.3032\n",
            "Step [4770/60000], d_real_loss: 0.0988, d_mnist_loss: 0.0583, d_svhn_loss: 0.0406, d_fake_loss: 0.0989, g_loss: 1.1687\n",
            "Step [4780/60000], d_real_loss: 0.0843, d_mnist_loss: 0.0253, d_svhn_loss: 0.0591, d_fake_loss: 0.0744, g_loss: 1.0947\n",
            "Step [4790/60000], d_real_loss: 0.1102, d_mnist_loss: 0.0254, d_svhn_loss: 0.0847, d_fake_loss: 0.1233, g_loss: 1.2709\n",
            "Step [4800/60000], d_real_loss: 0.0852, d_mnist_loss: 0.0336, d_svhn_loss: 0.0516, d_fake_loss: 0.0913, g_loss: 1.5855\n",
            "Step [4810/60000], d_real_loss: 0.0727, d_mnist_loss: 0.0318, d_svhn_loss: 0.0410, d_fake_loss: 0.0714, g_loss: 1.1184\n",
            "Step [4820/60000], d_real_loss: 0.2237, d_mnist_loss: 0.0729, d_svhn_loss: 0.1507, d_fake_loss: 0.3264, g_loss: 1.7880\n",
            "Step [4830/60000], d_real_loss: 0.1857, d_mnist_loss: 0.0499, d_svhn_loss: 0.1358, d_fake_loss: 0.2017, g_loss: 1.2377\n",
            "Step [4840/60000], d_real_loss: 0.1225, d_mnist_loss: 0.0451, d_svhn_loss: 0.0775, d_fake_loss: 0.1976, g_loss: 1.1092\n",
            "Step [4850/60000], d_real_loss: 0.1545, d_mnist_loss: 0.0446, d_svhn_loss: 0.1099, d_fake_loss: 0.1645, g_loss: 1.0364\n",
            "Step [4860/60000], d_real_loss: 0.0745, d_mnist_loss: 0.0247, d_svhn_loss: 0.0498, d_fake_loss: 0.0675, g_loss: 0.7232\n",
            "Step [4870/60000], d_real_loss: 0.1233, d_mnist_loss: 0.0404, d_svhn_loss: 0.0829, d_fake_loss: 0.1598, g_loss: 1.3103\n",
            "Step [4880/60000], d_real_loss: 0.0704, d_mnist_loss: 0.0309, d_svhn_loss: 0.0395, d_fake_loss: 0.0835, g_loss: 1.5226\n",
            "Step [4890/60000], d_real_loss: 0.3270, d_mnist_loss: 0.0315, d_svhn_loss: 0.2954, d_fake_loss: 0.0662, g_loss: 1.1364\n",
            "Step [4900/60000], d_real_loss: 0.1295, d_mnist_loss: 0.0504, d_svhn_loss: 0.0791, d_fake_loss: 0.1485, g_loss: 1.1722\n",
            "Step [4910/60000], d_real_loss: 0.0738, d_mnist_loss: 0.0347, d_svhn_loss: 0.0391, d_fake_loss: 0.0821, g_loss: 1.1110\n",
            "Step [4920/60000], d_real_loss: 0.0588, d_mnist_loss: 0.0242, d_svhn_loss: 0.0346, d_fake_loss: 0.0879, g_loss: 1.1040\n",
            "Step [4930/60000], d_real_loss: 0.0728, d_mnist_loss: 0.0137, d_svhn_loss: 0.0590, d_fake_loss: 0.1455, g_loss: 1.1354\n",
            "Step [4940/60000], d_real_loss: 0.1138, d_mnist_loss: 0.0199, d_svhn_loss: 0.0938, d_fake_loss: 0.0564, g_loss: 1.2063\n",
            "Step [4950/60000], d_real_loss: 0.1055, d_mnist_loss: 0.0378, d_svhn_loss: 0.0677, d_fake_loss: 0.1071, g_loss: 1.0155\n",
            "Step [4960/60000], d_real_loss: 0.0847, d_mnist_loss: 0.0267, d_svhn_loss: 0.0580, d_fake_loss: 0.0788, g_loss: 1.0175\n",
            "Step [4970/60000], d_real_loss: 0.1310, d_mnist_loss: 0.0822, d_svhn_loss: 0.0488, d_fake_loss: 0.2357, g_loss: 1.5774\n",
            "Step [4980/60000], d_real_loss: 0.1748, d_mnist_loss: 0.0537, d_svhn_loss: 0.1211, d_fake_loss: 0.1548, g_loss: 1.5656\n",
            "Step [4990/60000], d_real_loss: 0.0748, d_mnist_loss: 0.0306, d_svhn_loss: 0.0442, d_fake_loss: 0.0643, g_loss: 1.0510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [5000/60000], d_real_loss: 0.0798, d_mnist_loss: 0.0537, d_svhn_loss: 0.0261, d_fake_loss: 0.1355, g_loss: 1.5250\n",
            "saved ./samples_fashion/sample-5000-m-s.png\n",
            "saved ./samples_fashion/sample-5000-s-m.png\n",
            "Step [5010/60000], d_real_loss: 0.0552, d_mnist_loss: 0.0224, d_svhn_loss: 0.0328, d_fake_loss: 0.0457, g_loss: 1.1610\n",
            "Step [5020/60000], d_real_loss: 0.1031, d_mnist_loss: 0.0329, d_svhn_loss: 0.0702, d_fake_loss: 0.0898, g_loss: 1.2215\n",
            "Step [5030/60000], d_real_loss: 0.0561, d_mnist_loss: 0.0232, d_svhn_loss: 0.0328, d_fake_loss: 0.0556, g_loss: 1.2166\n",
            "Step [5040/60000], d_real_loss: 0.0966, d_mnist_loss: 0.0467, d_svhn_loss: 0.0499, d_fake_loss: 0.2479, g_loss: 1.7013\n",
            "Step [5050/60000], d_real_loss: 0.0493, d_mnist_loss: 0.0204, d_svhn_loss: 0.0289, d_fake_loss: 0.0999, g_loss: 1.4826\n",
            "Step [5060/60000], d_real_loss: 0.4140, d_mnist_loss: 0.1754, d_svhn_loss: 0.2386, d_fake_loss: 0.3533, g_loss: 1.5553\n",
            "Step [5070/60000], d_real_loss: 0.0905, d_mnist_loss: 0.0568, d_svhn_loss: 0.0337, d_fake_loss: 0.0905, g_loss: 1.1664\n",
            "Step [5080/60000], d_real_loss: 0.0933, d_mnist_loss: 0.0377, d_svhn_loss: 0.0556, d_fake_loss: 0.0677, g_loss: 1.0255\n",
            "Step [5090/60000], d_real_loss: 0.1224, d_mnist_loss: 0.0557, d_svhn_loss: 0.0667, d_fake_loss: 0.0658, g_loss: 1.3635\n",
            "Step [5100/60000], d_real_loss: 0.1576, d_mnist_loss: 0.1305, d_svhn_loss: 0.0271, d_fake_loss: 0.1312, g_loss: 1.3867\n",
            "Step [5110/60000], d_real_loss: 0.2506, d_mnist_loss: 0.1619, d_svhn_loss: 0.0887, d_fake_loss: 0.2541, g_loss: 1.7091\n",
            "Step [5120/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0108, d_svhn_loss: 0.0319, d_fake_loss: 0.0514, g_loss: 1.0896\n",
            "Step [5130/60000], d_real_loss: 0.1539, d_mnist_loss: 0.0370, d_svhn_loss: 0.1169, d_fake_loss: 0.2042, g_loss: 1.0292\n",
            "Step [5140/60000], d_real_loss: 0.1245, d_mnist_loss: 0.0360, d_svhn_loss: 0.0885, d_fake_loss: 0.0646, g_loss: 0.9612\n",
            "Step [5150/60000], d_real_loss: 0.5494, d_mnist_loss: 0.0212, d_svhn_loss: 0.5282, d_fake_loss: 0.1226, g_loss: 1.1545\n",
            "Step [5160/60000], d_real_loss: 0.1191, d_mnist_loss: 0.0197, d_svhn_loss: 0.0994, d_fake_loss: 0.0984, g_loss: 1.1973\n",
            "Step [5170/60000], d_real_loss: 0.0667, d_mnist_loss: 0.0428, d_svhn_loss: 0.0239, d_fake_loss: 0.0996, g_loss: 1.3747\n",
            "Step [5180/60000], d_real_loss: 0.0755, d_mnist_loss: 0.0233, d_svhn_loss: 0.0521, d_fake_loss: 0.0518, g_loss: 0.9073\n",
            "Step [5190/60000], d_real_loss: 0.1212, d_mnist_loss: 0.0280, d_svhn_loss: 0.0933, d_fake_loss: 0.0886, g_loss: 1.6006\n",
            "Step [5200/60000], d_real_loss: 0.0708, d_mnist_loss: 0.0364, d_svhn_loss: 0.0344, d_fake_loss: 0.0603, g_loss: 1.3441\n",
            "Step [5210/60000], d_real_loss: 0.2310, d_mnist_loss: 0.0502, d_svhn_loss: 0.1808, d_fake_loss: 0.2119, g_loss: 1.2869\n",
            "Step [5220/60000], d_real_loss: 0.1411, d_mnist_loss: 0.1107, d_svhn_loss: 0.0304, d_fake_loss: 0.1374, g_loss: 1.6009\n",
            "Step [5230/60000], d_real_loss: 0.0675, d_mnist_loss: 0.0207, d_svhn_loss: 0.0468, d_fake_loss: 0.2597, g_loss: 1.2317\n",
            "Step [5240/60000], d_real_loss: 0.0610, d_mnist_loss: 0.0192, d_svhn_loss: 0.0418, d_fake_loss: 0.0836, g_loss: 1.3670\n",
            "Step [5250/60000], d_real_loss: 0.0636, d_mnist_loss: 0.0185, d_svhn_loss: 0.0451, d_fake_loss: 0.1799, g_loss: 1.2032\n",
            "Step [5260/60000], d_real_loss: 0.1076, d_mnist_loss: 0.0185, d_svhn_loss: 0.0890, d_fake_loss: 0.1153, g_loss: 1.4419\n",
            "Step [5270/60000], d_real_loss: 0.1386, d_mnist_loss: 0.0163, d_svhn_loss: 0.1223, d_fake_loss: 0.1352, g_loss: 1.2351\n",
            "Step [5280/60000], d_real_loss: 0.0649, d_mnist_loss: 0.0099, d_svhn_loss: 0.0550, d_fake_loss: 0.0953, g_loss: 0.8260\n",
            "Step [5290/60000], d_real_loss: 0.0919, d_mnist_loss: 0.0179, d_svhn_loss: 0.0740, d_fake_loss: 0.0574, g_loss: 1.2486\n",
            "Step [5300/60000], d_real_loss: 0.2172, d_mnist_loss: 0.0290, d_svhn_loss: 0.1881, d_fake_loss: 0.1793, g_loss: 1.0555\n",
            "Step [5310/60000], d_real_loss: 0.1509, d_mnist_loss: 0.0345, d_svhn_loss: 0.1164, d_fake_loss: 0.0938, g_loss: 1.0681\n",
            "Step [5320/60000], d_real_loss: 0.0856, d_mnist_loss: 0.0267, d_svhn_loss: 0.0589, d_fake_loss: 0.0686, g_loss: 1.2031\n",
            "Step [5330/60000], d_real_loss: 0.1694, d_mnist_loss: 0.0849, d_svhn_loss: 0.0845, d_fake_loss: 0.2065, g_loss: 0.9061\n",
            "Step [5340/60000], d_real_loss: 0.0811, d_mnist_loss: 0.0227, d_svhn_loss: 0.0585, d_fake_loss: 0.0567, g_loss: 0.9493\n",
            "Step [5350/60000], d_real_loss: 0.2302, d_mnist_loss: 0.0214, d_svhn_loss: 0.2088, d_fake_loss: 0.2755, g_loss: 1.1540\n",
            "Step [5360/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0143, d_svhn_loss: 0.0529, d_fake_loss: 0.0565, g_loss: 1.3123\n",
            "Step [5370/60000], d_real_loss: 0.0739, d_mnist_loss: 0.0362, d_svhn_loss: 0.0377, d_fake_loss: 0.0606, g_loss: 1.3919\n",
            "Step [5380/60000], d_real_loss: 0.1363, d_mnist_loss: 0.0821, d_svhn_loss: 0.0542, d_fake_loss: 0.0621, g_loss: 0.9784\n",
            "Step [5390/60000], d_real_loss: 0.0771, d_mnist_loss: 0.0167, d_svhn_loss: 0.0604, d_fake_loss: 0.0476, g_loss: 1.0907\n",
            "Step [5400/60000], d_real_loss: 0.0560, d_mnist_loss: 0.0211, d_svhn_loss: 0.0350, d_fake_loss: 0.0597, g_loss: 1.0093\n",
            "Step [5410/60000], d_real_loss: 0.4447, d_mnist_loss: 0.2044, d_svhn_loss: 0.2403, d_fake_loss: 0.1555, g_loss: 1.1517\n",
            "Step [5420/60000], d_real_loss: 0.1148, d_mnist_loss: 0.0685, d_svhn_loss: 0.0462, d_fake_loss: 0.0901, g_loss: 1.1800\n",
            "Step [5430/60000], d_real_loss: 0.0667, d_mnist_loss: 0.0246, d_svhn_loss: 0.0421, d_fake_loss: 0.0699, g_loss: 1.1572\n",
            "Step [5440/60000], d_real_loss: 0.0865, d_mnist_loss: 0.0322, d_svhn_loss: 0.0543, d_fake_loss: 0.1850, g_loss: 1.1477\n",
            "Step [5450/60000], d_real_loss: 0.1562, d_mnist_loss: 0.0250, d_svhn_loss: 0.1311, d_fake_loss: 0.1037, g_loss: 0.8402\n",
            "Step [5460/60000], d_real_loss: 0.0744, d_mnist_loss: 0.0388, d_svhn_loss: 0.0356, d_fake_loss: 0.0735, g_loss: 1.0438\n",
            "Step [5470/60000], d_real_loss: 0.0696, d_mnist_loss: 0.0391, d_svhn_loss: 0.0305, d_fake_loss: 0.1040, g_loss: 1.3050\n",
            "Step [5480/60000], d_real_loss: 0.1579, d_mnist_loss: 0.0421, d_svhn_loss: 0.1158, d_fake_loss: 0.1422, g_loss: 1.6454\n",
            "Step [5490/60000], d_real_loss: 0.1458, d_mnist_loss: 0.0227, d_svhn_loss: 0.1232, d_fake_loss: 0.0691, g_loss: 1.2071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [5500/60000], d_real_loss: 0.0684, d_mnist_loss: 0.0323, d_svhn_loss: 0.0362, d_fake_loss: 0.1220, g_loss: 0.9745\n",
            "saved ./samples_fashion/sample-5500-m-s.png\n",
            "saved ./samples_fashion/sample-5500-s-m.png\n",
            "Step [5510/60000], d_real_loss: 0.0986, d_mnist_loss: 0.0172, d_svhn_loss: 0.0814, d_fake_loss: 0.1122, g_loss: 0.9819\n",
            "Step [5520/60000], d_real_loss: 0.1613, d_mnist_loss: 0.1283, d_svhn_loss: 0.0330, d_fake_loss: 0.1648, g_loss: 1.5090\n",
            "Step [5530/60000], d_real_loss: 0.1169, d_mnist_loss: 0.0294, d_svhn_loss: 0.0874, d_fake_loss: 0.0630, g_loss: 1.0492\n",
            "Step [5540/60000], d_real_loss: 0.1017, d_mnist_loss: 0.0189, d_svhn_loss: 0.0828, d_fake_loss: 0.1759, g_loss: 1.3142\n",
            "Step [5550/60000], d_real_loss: 0.0756, d_mnist_loss: 0.0362, d_svhn_loss: 0.0394, d_fake_loss: 0.1100, g_loss: 1.3669\n",
            "Step [5560/60000], d_real_loss: 0.0577, d_mnist_loss: 0.0322, d_svhn_loss: 0.0255, d_fake_loss: 0.1401, g_loss: 1.5502\n",
            "Step [5570/60000], d_real_loss: 0.0613, d_mnist_loss: 0.0110, d_svhn_loss: 0.0503, d_fake_loss: 0.0712, g_loss: 1.1606\n",
            "Step [5580/60000], d_real_loss: 0.1793, d_mnist_loss: 0.1359, d_svhn_loss: 0.0434, d_fake_loss: 0.1799, g_loss: 1.2693\n",
            "Step [5590/60000], d_real_loss: 0.0719, d_mnist_loss: 0.0404, d_svhn_loss: 0.0315, d_fake_loss: 0.0658, g_loss: 1.2468\n",
            "Step [5600/60000], d_real_loss: 0.1089, d_mnist_loss: 0.0309, d_svhn_loss: 0.0780, d_fake_loss: 0.1131, g_loss: 0.8389\n",
            "Step [5610/60000], d_real_loss: 0.1051, d_mnist_loss: 0.0542, d_svhn_loss: 0.0508, d_fake_loss: 0.0994, g_loss: 1.2044\n",
            "Step [5620/60000], d_real_loss: 0.5694, d_mnist_loss: 0.0445, d_svhn_loss: 0.5250, d_fake_loss: 0.8067, g_loss: 1.2017\n",
            "Step [5630/60000], d_real_loss: 0.3582, d_mnist_loss: 0.0517, d_svhn_loss: 0.3065, d_fake_loss: 0.2710, g_loss: 1.4218\n",
            "Step [5640/60000], d_real_loss: 0.1209, d_mnist_loss: 0.0314, d_svhn_loss: 0.0894, d_fake_loss: 0.0693, g_loss: 1.0949\n",
            "Step [5650/60000], d_real_loss: 0.0805, d_mnist_loss: 0.0387, d_svhn_loss: 0.0418, d_fake_loss: 0.1190, g_loss: 1.1372\n",
            "Step [5660/60000], d_real_loss: 0.1140, d_mnist_loss: 0.0191, d_svhn_loss: 0.0949, d_fake_loss: 0.1056, g_loss: 1.2235\n",
            "Step [5670/60000], d_real_loss: 0.1178, d_mnist_loss: 0.0200, d_svhn_loss: 0.0978, d_fake_loss: 0.0897, g_loss: 1.1073\n",
            "Step [5680/60000], d_real_loss: 0.1150, d_mnist_loss: 0.0169, d_svhn_loss: 0.0981, d_fake_loss: 0.1403, g_loss: 0.7084\n",
            "Step [5690/60000], d_real_loss: 0.0716, d_mnist_loss: 0.0310, d_svhn_loss: 0.0406, d_fake_loss: 0.0508, g_loss: 1.2722\n",
            "Step [5700/60000], d_real_loss: 0.1720, d_mnist_loss: 0.0469, d_svhn_loss: 0.1251, d_fake_loss: 0.2411, g_loss: 1.4216\n",
            "Step [5710/60000], d_real_loss: 0.2858, d_mnist_loss: 0.0363, d_svhn_loss: 0.2495, d_fake_loss: 0.1390, g_loss: 0.9143\n",
            "Step [5720/60000], d_real_loss: 0.1928, d_mnist_loss: 0.0955, d_svhn_loss: 0.0974, d_fake_loss: 0.2100, g_loss: 1.3616\n",
            "Step [5730/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0153, d_svhn_loss: 0.0436, d_fake_loss: 0.0880, g_loss: 1.2240\n",
            "Step [5740/60000], d_real_loss: 0.0623, d_mnist_loss: 0.0210, d_svhn_loss: 0.0413, d_fake_loss: 0.0618, g_loss: 1.0708\n",
            "Step [5750/60000], d_real_loss: 0.0773, d_mnist_loss: 0.0357, d_svhn_loss: 0.0416, d_fake_loss: 0.0778, g_loss: 1.3726\n",
            "Step [5760/60000], d_real_loss: 0.0797, d_mnist_loss: 0.0287, d_svhn_loss: 0.0510, d_fake_loss: 0.0721, g_loss: 0.9887\n",
            "Step [5770/60000], d_real_loss: 0.1287, d_mnist_loss: 0.0202, d_svhn_loss: 0.1085, d_fake_loss: 0.0344, g_loss: 1.1890\n",
            "Step [5780/60000], d_real_loss: 0.1236, d_mnist_loss: 0.0651, d_svhn_loss: 0.0584, d_fake_loss: 0.1208, g_loss: 1.6135\n",
            "Step [5790/60000], d_real_loss: 0.0696, d_mnist_loss: 0.0232, d_svhn_loss: 0.0464, d_fake_loss: 0.0972, g_loss: 1.1225\n",
            "Step [5800/60000], d_real_loss: 0.0897, d_mnist_loss: 0.0234, d_svhn_loss: 0.0663, d_fake_loss: 0.1059, g_loss: 1.6026\n",
            "Step [5810/60000], d_real_loss: 0.3179, d_mnist_loss: 0.2605, d_svhn_loss: 0.0573, d_fake_loss: 0.0708, g_loss: 0.9214\n",
            "Step [5820/60000], d_real_loss: 0.0798, d_mnist_loss: 0.0356, d_svhn_loss: 0.0442, d_fake_loss: 0.2684, g_loss: 1.5507\n",
            "Step [5830/60000], d_real_loss: 0.1225, d_mnist_loss: 0.0300, d_svhn_loss: 0.0924, d_fake_loss: 0.1152, g_loss: 1.3615\n",
            "Step [5840/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0205, d_svhn_loss: 0.0447, d_fake_loss: 0.1294, g_loss: 1.5179\n",
            "Step [5850/60000], d_real_loss: 0.0836, d_mnist_loss: 0.0306, d_svhn_loss: 0.0531, d_fake_loss: 0.0516, g_loss: 0.9716\n",
            "Step [5860/60000], d_real_loss: 0.0832, d_mnist_loss: 0.0403, d_svhn_loss: 0.0429, d_fake_loss: 0.0941, g_loss: 1.1469\n",
            "Step [5870/60000], d_real_loss: 0.2178, d_mnist_loss: 0.1592, d_svhn_loss: 0.0586, d_fake_loss: 0.0943, g_loss: 1.1554\n",
            "Step [5880/60000], d_real_loss: 0.0676, d_mnist_loss: 0.0245, d_svhn_loss: 0.0431, d_fake_loss: 0.0854, g_loss: 1.2224\n",
            "Step [5890/60000], d_real_loss: 0.0567, d_mnist_loss: 0.0235, d_svhn_loss: 0.0332, d_fake_loss: 0.0961, g_loss: 1.6506\n",
            "Step [5900/60000], d_real_loss: 0.0722, d_mnist_loss: 0.0214, d_svhn_loss: 0.0508, d_fake_loss: 0.0556, g_loss: 1.1651\n",
            "Step [5910/60000], d_real_loss: 0.0917, d_mnist_loss: 0.0195, d_svhn_loss: 0.0723, d_fake_loss: 0.0600, g_loss: 1.2376\n",
            "Step [5920/60000], d_real_loss: 0.0578, d_mnist_loss: 0.0253, d_svhn_loss: 0.0325, d_fake_loss: 0.1075, g_loss: 1.0481\n",
            "Step [5930/60000], d_real_loss: 0.0673, d_mnist_loss: 0.0170, d_svhn_loss: 0.0503, d_fake_loss: 0.1201, g_loss: 1.5368\n",
            "Step [5940/60000], d_real_loss: 0.1278, d_mnist_loss: 0.0555, d_svhn_loss: 0.0722, d_fake_loss: 0.0901, g_loss: 1.6347\n",
            "Step [5950/60000], d_real_loss: 0.0733, d_mnist_loss: 0.0221, d_svhn_loss: 0.0512, d_fake_loss: 0.1172, g_loss: 1.2007\n",
            "Step [5960/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0194, d_svhn_loss: 0.0336, d_fake_loss: 0.0780, g_loss: 1.1243\n",
            "Step [5970/60000], d_real_loss: 0.0639, d_mnist_loss: 0.0169, d_svhn_loss: 0.0470, d_fake_loss: 0.0668, g_loss: 1.1630\n",
            "Step [5980/60000], d_real_loss: 0.3732, d_mnist_loss: 0.1658, d_svhn_loss: 0.2074, d_fake_loss: 0.1014, g_loss: 0.8786\n",
            "Step [5990/60000], d_real_loss: 0.1727, d_mnist_loss: 0.1217, d_svhn_loss: 0.0511, d_fake_loss: 0.2488, g_loss: 1.8054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [6000/60000], d_real_loss: 0.0856, d_mnist_loss: 0.0469, d_svhn_loss: 0.0388, d_fake_loss: 0.1824, g_loss: 1.4971\n",
            "saved ./samples_fashion/sample-6000-m-s.png\n",
            "saved ./samples_fashion/sample-6000-s-m.png\n",
            "Step [6010/60000], d_real_loss: 0.0595, d_mnist_loss: 0.0209, d_svhn_loss: 0.0386, d_fake_loss: 0.0771, g_loss: 1.2742\n",
            "Step [6020/60000], d_real_loss: 0.1304, d_mnist_loss: 0.0519, d_svhn_loss: 0.0784, d_fake_loss: 0.0795, g_loss: 1.3008\n",
            "Step [6030/60000], d_real_loss: 0.0517, d_mnist_loss: 0.0118, d_svhn_loss: 0.0399, d_fake_loss: 0.0502, g_loss: 1.2779\n",
            "Step [6040/60000], d_real_loss: 0.1282, d_mnist_loss: 0.0262, d_svhn_loss: 0.1020, d_fake_loss: 0.0777, g_loss: 1.1354\n",
            "Step [6050/60000], d_real_loss: 0.0858, d_mnist_loss: 0.0301, d_svhn_loss: 0.0557, d_fake_loss: 0.1104, g_loss: 1.4881\n",
            "Step [6060/60000], d_real_loss: 0.1231, d_mnist_loss: 0.0207, d_svhn_loss: 0.1024, d_fake_loss: 0.1679, g_loss: 1.2856\n",
            "Step [6070/60000], d_real_loss: 0.0928, d_mnist_loss: 0.0516, d_svhn_loss: 0.0412, d_fake_loss: 0.0443, g_loss: 1.4228\n",
            "Step [6080/60000], d_real_loss: 0.0993, d_mnist_loss: 0.0725, d_svhn_loss: 0.0268, d_fake_loss: 0.0821, g_loss: 1.2623\n",
            "Step [6090/60000], d_real_loss: 0.1448, d_mnist_loss: 0.0186, d_svhn_loss: 0.1262, d_fake_loss: 0.0489, g_loss: 1.1649\n",
            "Step [6100/60000], d_real_loss: 0.1146, d_mnist_loss: 0.0436, d_svhn_loss: 0.0711, d_fake_loss: 0.1207, g_loss: 1.5481\n",
            "Step [6110/60000], d_real_loss: 0.1414, d_mnist_loss: 0.0255, d_svhn_loss: 0.1159, d_fake_loss: 0.2663, g_loss: 0.8842\n",
            "Step [6120/60000], d_real_loss: 0.1008, d_mnist_loss: 0.0210, d_svhn_loss: 0.0798, d_fake_loss: 0.0444, g_loss: 1.1456\n",
            "Step [6130/60000], d_real_loss: 0.0461, d_mnist_loss: 0.0120, d_svhn_loss: 0.0340, d_fake_loss: 0.1449, g_loss: 1.3005\n",
            "Step [6140/60000], d_real_loss: 0.1196, d_mnist_loss: 0.0176, d_svhn_loss: 0.1021, d_fake_loss: 0.0810, g_loss: 1.0795\n",
            "Step [6150/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0375, d_svhn_loss: 0.0297, d_fake_loss: 0.1748, g_loss: 1.0893\n",
            "Step [6160/60000], d_real_loss: 0.1820, d_mnist_loss: 0.0571, d_svhn_loss: 0.1249, d_fake_loss: 0.0652, g_loss: 1.1831\n",
            "Step [6170/60000], d_real_loss: 0.2071, d_mnist_loss: 0.0283, d_svhn_loss: 0.1788, d_fake_loss: 0.1072, g_loss: 1.3274\n",
            "Step [6180/60000], d_real_loss: 0.0570, d_mnist_loss: 0.0268, d_svhn_loss: 0.0302, d_fake_loss: 0.1099, g_loss: 1.0711\n",
            "Step [6190/60000], d_real_loss: 0.0824, d_mnist_loss: 0.0377, d_svhn_loss: 0.0446, d_fake_loss: 0.1317, g_loss: 1.2693\n",
            "Step [6200/60000], d_real_loss: 0.0863, d_mnist_loss: 0.0376, d_svhn_loss: 0.0487, d_fake_loss: 0.1583, g_loss: 1.3189\n",
            "Step [6210/60000], d_real_loss: 0.0485, d_mnist_loss: 0.0263, d_svhn_loss: 0.0222, d_fake_loss: 0.1913, g_loss: 1.0389\n",
            "Step [6220/60000], d_real_loss: 0.0835, d_mnist_loss: 0.0517, d_svhn_loss: 0.0318, d_fake_loss: 0.1467, g_loss: 1.4050\n",
            "Step [6230/60000], d_real_loss: 0.0911, d_mnist_loss: 0.0602, d_svhn_loss: 0.0308, d_fake_loss: 0.1006, g_loss: 1.3075\n",
            "Step [6240/60000], d_real_loss: 0.0798, d_mnist_loss: 0.0172, d_svhn_loss: 0.0626, d_fake_loss: 0.0787, g_loss: 0.7474\n",
            "Step [6250/60000], d_real_loss: 0.0820, d_mnist_loss: 0.0608, d_svhn_loss: 0.0212, d_fake_loss: 0.1062, g_loss: 1.1720\n",
            "Step [6260/60000], d_real_loss: 0.0590, d_mnist_loss: 0.0161, d_svhn_loss: 0.0429, d_fake_loss: 0.0540, g_loss: 1.4026\n",
            "Step [6270/60000], d_real_loss: 0.0579, d_mnist_loss: 0.0194, d_svhn_loss: 0.0385, d_fake_loss: 0.0472, g_loss: 1.2882\n",
            "Step [6280/60000], d_real_loss: 0.0841, d_mnist_loss: 0.0534, d_svhn_loss: 0.0307, d_fake_loss: 0.1944, g_loss: 1.9208\n",
            "Step [6290/60000], d_real_loss: 0.1357, d_mnist_loss: 0.0829, d_svhn_loss: 0.0528, d_fake_loss: 0.0997, g_loss: 1.0658\n",
            "Step [6300/60000], d_real_loss: 0.1459, d_mnist_loss: 0.0255, d_svhn_loss: 0.1204, d_fake_loss: 0.0380, g_loss: 1.2488\n",
            "Step [6310/60000], d_real_loss: 0.1386, d_mnist_loss: 0.0597, d_svhn_loss: 0.0789, d_fake_loss: 0.0818, g_loss: 0.9311\n",
            "Step [6320/60000], d_real_loss: 0.0723, d_mnist_loss: 0.0293, d_svhn_loss: 0.0429, d_fake_loss: 0.1652, g_loss: 0.9394\n",
            "Step [6330/60000], d_real_loss: 0.1208, d_mnist_loss: 0.0354, d_svhn_loss: 0.0854, d_fake_loss: 0.0489, g_loss: 1.1457\n",
            "Step [6340/60000], d_real_loss: 0.0548, d_mnist_loss: 0.0109, d_svhn_loss: 0.0439, d_fake_loss: 0.0657, g_loss: 1.2608\n",
            "Step [6350/60000], d_real_loss: 0.1596, d_mnist_loss: 0.0459, d_svhn_loss: 0.1137, d_fake_loss: 0.4441, g_loss: 1.7994\n",
            "Step [6360/60000], d_real_loss: 0.1601, d_mnist_loss: 0.0148, d_svhn_loss: 0.1453, d_fake_loss: 0.0767, g_loss: 0.8298\n",
            "Step [6370/60000], d_real_loss: 0.1375, d_mnist_loss: 0.0358, d_svhn_loss: 0.1017, d_fake_loss: 0.1811, g_loss: 1.1056\n",
            "Step [6380/60000], d_real_loss: 0.2466, d_mnist_loss: 0.0235, d_svhn_loss: 0.2231, d_fake_loss: 0.3400, g_loss: 1.4941\n",
            "Step [6390/60000], d_real_loss: 0.1558, d_mnist_loss: 0.0554, d_svhn_loss: 0.1005, d_fake_loss: 0.0821, g_loss: 1.3501\n",
            "Step [6400/60000], d_real_loss: 0.0888, d_mnist_loss: 0.0550, d_svhn_loss: 0.0338, d_fake_loss: 0.0897, g_loss: 2.0069\n",
            "Step [6410/60000], d_real_loss: 0.1525, d_mnist_loss: 0.0373, d_svhn_loss: 0.1151, d_fake_loss: 0.1105, g_loss: 1.1673\n",
            "Step [6420/60000], d_real_loss: 0.2247, d_mnist_loss: 0.0266, d_svhn_loss: 0.1981, d_fake_loss: 0.1003, g_loss: 1.2326\n",
            "Step [6430/60000], d_real_loss: 0.1637, d_mnist_loss: 0.0714, d_svhn_loss: 0.0922, d_fake_loss: 0.0584, g_loss: 1.0539\n",
            "Step [6440/60000], d_real_loss: 0.1739, d_mnist_loss: 0.0154, d_svhn_loss: 0.1585, d_fake_loss: 0.0922, g_loss: 1.2186\n",
            "Step [6450/60000], d_real_loss: 0.1242, d_mnist_loss: 0.0889, d_svhn_loss: 0.0353, d_fake_loss: 0.1039, g_loss: 1.6391\n",
            "Step [6460/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0142, d_svhn_loss: 0.0274, d_fake_loss: 0.2275, g_loss: 1.9791\n",
            "Step [6470/60000], d_real_loss: 0.3366, d_mnist_loss: 0.2174, d_svhn_loss: 0.1192, d_fake_loss: 0.4030, g_loss: 1.6528\n",
            "Step [6480/60000], d_real_loss: 0.0444, d_mnist_loss: 0.0173, d_svhn_loss: 0.0271, d_fake_loss: 0.0653, g_loss: 1.2254\n",
            "Step [6490/60000], d_real_loss: 0.0545, d_mnist_loss: 0.0229, d_svhn_loss: 0.0315, d_fake_loss: 0.0844, g_loss: 1.4198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999999403953552]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [6500/60000], d_real_loss: 0.1486, d_mnist_loss: 0.1150, d_svhn_loss: 0.0336, d_fake_loss: 0.3099, g_loss: 2.1055\n",
            "saved ./samples_fashion/sample-6500-m-s.png\n",
            "saved ./samples_fashion/sample-6500-s-m.png\n",
            "Step [6510/60000], d_real_loss: 0.1102, d_mnist_loss: 0.0350, d_svhn_loss: 0.0752, d_fake_loss: 0.4989, g_loss: 1.3623\n",
            "Step [6520/60000], d_real_loss: 0.0630, d_mnist_loss: 0.0237, d_svhn_loss: 0.0393, d_fake_loss: 0.1374, g_loss: 1.1423\n",
            "Step [6530/60000], d_real_loss: 0.0962, d_mnist_loss: 0.0200, d_svhn_loss: 0.0761, d_fake_loss: 0.0736, g_loss: 1.3371\n",
            "Step [6540/60000], d_real_loss: 0.1749, d_mnist_loss: 0.0857, d_svhn_loss: 0.0893, d_fake_loss: 0.0624, g_loss: 1.3289\n",
            "Step [6550/60000], d_real_loss: 0.1239, d_mnist_loss: 0.0940, d_svhn_loss: 0.0299, d_fake_loss: 0.9461, g_loss: 2.0483\n",
            "Step [6560/60000], d_real_loss: 0.0599, d_mnist_loss: 0.0302, d_svhn_loss: 0.0297, d_fake_loss: 0.0542, g_loss: 1.0689\n",
            "Step [6570/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0344, d_svhn_loss: 0.0252, d_fake_loss: 0.2335, g_loss: 1.1369\n",
            "Step [6580/60000], d_real_loss: 0.2520, d_mnist_loss: 0.0235, d_svhn_loss: 0.2285, d_fake_loss: 0.2067, g_loss: 0.7996\n",
            "Step [6590/60000], d_real_loss: 0.1576, d_mnist_loss: 0.0203, d_svhn_loss: 0.1374, d_fake_loss: 0.1119, g_loss: 1.2584\n",
            "Step [6600/60000], d_real_loss: 0.1690, d_mnist_loss: 0.0165, d_svhn_loss: 0.1525, d_fake_loss: 0.2125, g_loss: 1.1937\n",
            "Step [6610/60000], d_real_loss: 0.0884, d_mnist_loss: 0.0184, d_svhn_loss: 0.0699, d_fake_loss: 0.0585, g_loss: 1.3356\n",
            "Step [6620/60000], d_real_loss: 0.1039, d_mnist_loss: 0.0438, d_svhn_loss: 0.0601, d_fake_loss: 0.1331, g_loss: 1.3210\n",
            "Step [6630/60000], d_real_loss: 0.0568, d_mnist_loss: 0.0198, d_svhn_loss: 0.0370, d_fake_loss: 0.1925, g_loss: 1.7758\n",
            "Step [6640/60000], d_real_loss: 0.0844, d_mnist_loss: 0.0257, d_svhn_loss: 0.0587, d_fake_loss: 0.2109, g_loss: 1.2333\n",
            "Step [6650/60000], d_real_loss: 0.0553, d_mnist_loss: 0.0249, d_svhn_loss: 0.0304, d_fake_loss: 0.0500, g_loss: 1.0987\n",
            "Step [6660/60000], d_real_loss: 0.1170, d_mnist_loss: 0.0301, d_svhn_loss: 0.0869, d_fake_loss: 0.1359, g_loss: 0.6946\n",
            "Step [6670/60000], d_real_loss: 0.0881, d_mnist_loss: 0.0272, d_svhn_loss: 0.0609, d_fake_loss: 0.0812, g_loss: 1.2129\n",
            "Step [6680/60000], d_real_loss: 0.0549, d_mnist_loss: 0.0156, d_svhn_loss: 0.0393, d_fake_loss: 0.1090, g_loss: 1.0341\n",
            "Step [6690/60000], d_real_loss: 0.1005, d_mnist_loss: 0.0350, d_svhn_loss: 0.0655, d_fake_loss: 0.0611, g_loss: 1.2159\n",
            "Step [6700/60000], d_real_loss: 0.0520, d_mnist_loss: 0.0188, d_svhn_loss: 0.0332, d_fake_loss: 0.1519, g_loss: 1.4479\n",
            "Step [6710/60000], d_real_loss: 0.0754, d_mnist_loss: 0.0336, d_svhn_loss: 0.0418, d_fake_loss: 0.1276, g_loss: 0.9938\n",
            "Step [6720/60000], d_real_loss: 0.0734, d_mnist_loss: 0.0300, d_svhn_loss: 0.0434, d_fake_loss: 0.2204, g_loss: 1.0880\n",
            "Step [6730/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0156, d_svhn_loss: 0.0299, d_fake_loss: 0.0456, g_loss: 1.3877\n",
            "Step [6740/60000], d_real_loss: 0.0487, d_mnist_loss: 0.0194, d_svhn_loss: 0.0294, d_fake_loss: 0.0631, g_loss: 1.1268\n",
            "Step [6750/60000], d_real_loss: 0.0744, d_mnist_loss: 0.0320, d_svhn_loss: 0.0424, d_fake_loss: 0.1073, g_loss: 1.2060\n",
            "Step [6760/60000], d_real_loss: 0.1243, d_mnist_loss: 0.0103, d_svhn_loss: 0.1140, d_fake_loss: 0.1338, g_loss: 1.4619\n",
            "Step [6770/60000], d_real_loss: 0.0615, d_mnist_loss: 0.0137, d_svhn_loss: 0.0478, d_fake_loss: 0.1082, g_loss: 1.3748\n",
            "Step [6780/60000], d_real_loss: 0.0905, d_mnist_loss: 0.0218, d_svhn_loss: 0.0687, d_fake_loss: 0.0483, g_loss: 1.3057\n",
            "Step [6790/60000], d_real_loss: 0.0832, d_mnist_loss: 0.0303, d_svhn_loss: 0.0529, d_fake_loss: 0.0465, g_loss: 1.1659\n",
            "Step [6800/60000], d_real_loss: 0.1355, d_mnist_loss: 0.0887, d_svhn_loss: 0.0468, d_fake_loss: 0.1014, g_loss: 1.3417\n",
            "Step [6810/60000], d_real_loss: 0.1029, d_mnist_loss: 0.0711, d_svhn_loss: 0.0318, d_fake_loss: 0.0754, g_loss: 1.2035\n",
            "Step [6820/60000], d_real_loss: 0.0790, d_mnist_loss: 0.0352, d_svhn_loss: 0.0438, d_fake_loss: 0.2015, g_loss: 1.4156\n",
            "Step [6830/60000], d_real_loss: 0.0777, d_mnist_loss: 0.0139, d_svhn_loss: 0.0639, d_fake_loss: 0.1966, g_loss: 1.1332\n",
            "Step [6840/60000], d_real_loss: 0.0841, d_mnist_loss: 0.0228, d_svhn_loss: 0.0612, d_fake_loss: 0.0465, g_loss: 1.4319\n",
            "Step [6850/60000], d_real_loss: 0.1094, d_mnist_loss: 0.0257, d_svhn_loss: 0.0837, d_fake_loss: 0.1091, g_loss: 0.8233\n",
            "Step [6860/60000], d_real_loss: 0.0744, d_mnist_loss: 0.0296, d_svhn_loss: 0.0448, d_fake_loss: 0.0511, g_loss: 1.3929\n",
            "Step [6870/60000], d_real_loss: 0.0932, d_mnist_loss: 0.0268, d_svhn_loss: 0.0664, d_fake_loss: 0.0623, g_loss: 1.0691\n",
            "Step [6880/60000], d_real_loss: 0.1043, d_mnist_loss: 0.0626, d_svhn_loss: 0.0416, d_fake_loss: 0.0711, g_loss: 1.2671\n",
            "Step [6890/60000], d_real_loss: 0.2021, d_mnist_loss: 0.1603, d_svhn_loss: 0.0418, d_fake_loss: 0.3351, g_loss: 1.6227\n",
            "Step [6900/60000], d_real_loss: 0.0842, d_mnist_loss: 0.0224, d_svhn_loss: 0.0618, d_fake_loss: 0.0430, g_loss: 0.9876\n",
            "Step [6910/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0241, d_svhn_loss: 0.0425, d_fake_loss: 0.0297, g_loss: 1.1436\n",
            "Step [6920/60000], d_real_loss: 0.0799, d_mnist_loss: 0.0252, d_svhn_loss: 0.0547, d_fake_loss: 0.1447, g_loss: 0.5826\n",
            "Step [6930/60000], d_real_loss: 0.0610, d_mnist_loss: 0.0378, d_svhn_loss: 0.0232, d_fake_loss: 0.1575, g_loss: 0.9761\n",
            "Step [6940/60000], d_real_loss: 0.0767, d_mnist_loss: 0.0183, d_svhn_loss: 0.0584, d_fake_loss: 0.1636, g_loss: 1.2593\n",
            "Step [6950/60000], d_real_loss: 0.0545, d_mnist_loss: 0.0154, d_svhn_loss: 0.0392, d_fake_loss: 0.1222, g_loss: 1.3251\n",
            "Step [6960/60000], d_real_loss: 0.0411, d_mnist_loss: 0.0140, d_svhn_loss: 0.0271, d_fake_loss: 0.0647, g_loss: 1.2731\n",
            "Step [6970/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0230, d_svhn_loss: 0.0505, d_fake_loss: 0.1097, g_loss: 0.8528\n",
            "Step [6980/60000], d_real_loss: 0.1288, d_mnist_loss: 0.0593, d_svhn_loss: 0.0695, d_fake_loss: 0.1702, g_loss: 0.9865\n",
            "Step [6990/60000], d_real_loss: 0.1222, d_mnist_loss: 0.0577, d_svhn_loss: 0.0645, d_fake_loss: 0.0533, g_loss: 1.2155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [7000/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0183, d_svhn_loss: 0.0333, d_fake_loss: 0.0383, g_loss: 1.0629\n",
            "saved ./samples_fashion/sample-7000-m-s.png\n",
            "saved ./samples_fashion/sample-7000-s-m.png\n",
            "Step [7010/60000], d_real_loss: 0.0556, d_mnist_loss: 0.0255, d_svhn_loss: 0.0301, d_fake_loss: 0.0522, g_loss: 1.1243\n",
            "Step [7020/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0281, d_svhn_loss: 0.0254, d_fake_loss: 0.0597, g_loss: 0.8956\n",
            "Step [7030/60000], d_real_loss: 0.1062, d_mnist_loss: 0.0210, d_svhn_loss: 0.0851, d_fake_loss: 0.0572, g_loss: 1.0626\n",
            "Step [7040/60000], d_real_loss: 0.0983, d_mnist_loss: 0.0473, d_svhn_loss: 0.0510, d_fake_loss: 0.1903, g_loss: 1.0411\n",
            "Step [7050/60000], d_real_loss: 0.0481, d_mnist_loss: 0.0149, d_svhn_loss: 0.0333, d_fake_loss: 0.0469, g_loss: 1.2485\n",
            "Step [7060/60000], d_real_loss: 0.0719, d_mnist_loss: 0.0366, d_svhn_loss: 0.0353, d_fake_loss: 0.0986, g_loss: 0.8753\n",
            "Step [7070/60000], d_real_loss: 0.1428, d_mnist_loss: 0.0478, d_svhn_loss: 0.0950, d_fake_loss: 0.3310, g_loss: 1.5691\n",
            "Step [7080/60000], d_real_loss: 0.0864, d_mnist_loss: 0.0209, d_svhn_loss: 0.0655, d_fake_loss: 0.0481, g_loss: 1.1446\n",
            "Step [7090/60000], d_real_loss: 0.1669, d_mnist_loss: 0.1238, d_svhn_loss: 0.0431, d_fake_loss: 0.1343, g_loss: 1.4184\n",
            "Step [7100/60000], d_real_loss: 0.0486, d_mnist_loss: 0.0228, d_svhn_loss: 0.0258, d_fake_loss: 0.0552, g_loss: 1.1353\n",
            "Step [7110/60000], d_real_loss: 0.1352, d_mnist_loss: 0.0166, d_svhn_loss: 0.1186, d_fake_loss: 0.1452, g_loss: 1.2931\n",
            "Step [7120/60000], d_real_loss: 0.0700, d_mnist_loss: 0.0149, d_svhn_loss: 0.0551, d_fake_loss: 0.0533, g_loss: 1.1013\n",
            "Step [7130/60000], d_real_loss: 0.0461, d_mnist_loss: 0.0134, d_svhn_loss: 0.0327, d_fake_loss: 0.0435, g_loss: 0.9738\n",
            "Step [7140/60000], d_real_loss: 0.1050, d_mnist_loss: 0.0163, d_svhn_loss: 0.0887, d_fake_loss: 0.2890, g_loss: 1.2423\n",
            "Step [7150/60000], d_real_loss: 0.0778, d_mnist_loss: 0.0416, d_svhn_loss: 0.0363, d_fake_loss: 0.2569, g_loss: 1.3147\n",
            "Step [7160/60000], d_real_loss: 0.1165, d_mnist_loss: 0.0458, d_svhn_loss: 0.0706, d_fake_loss: 0.0641, g_loss: 1.0835\n",
            "Step [7170/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0171, d_svhn_loss: 0.0269, d_fake_loss: 0.0655, g_loss: 1.2327\n",
            "Step [7180/60000], d_real_loss: 0.1440, d_mnist_loss: 0.0425, d_svhn_loss: 0.1015, d_fake_loss: 0.0588, g_loss: 1.2171\n",
            "Step [7190/60000], d_real_loss: 0.0736, d_mnist_loss: 0.0141, d_svhn_loss: 0.0595, d_fake_loss: 0.0764, g_loss: 0.9167\n",
            "Step [7200/60000], d_real_loss: 0.1229, d_mnist_loss: 0.0771, d_svhn_loss: 0.0458, d_fake_loss: 0.1022, g_loss: 1.5530\n",
            "Step [7210/60000], d_real_loss: 0.0801, d_mnist_loss: 0.0269, d_svhn_loss: 0.0532, d_fake_loss: 0.1934, g_loss: 1.0468\n",
            "Step [7220/60000], d_real_loss: 0.1221, d_mnist_loss: 0.0727, d_svhn_loss: 0.0494, d_fake_loss: 0.1635, g_loss: 1.3643\n",
            "Step [7230/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0141, d_svhn_loss: 0.0333, d_fake_loss: 0.0950, g_loss: 1.4218\n",
            "Step [7240/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0184, d_svhn_loss: 0.0356, d_fake_loss: 0.0382, g_loss: 1.2642\n",
            "Step [7250/60000], d_real_loss: 0.0559, d_mnist_loss: 0.0244, d_svhn_loss: 0.0315, d_fake_loss: 0.0582, g_loss: 1.1941\n",
            "Step [7260/60000], d_real_loss: 0.0919, d_mnist_loss: 0.0168, d_svhn_loss: 0.0751, d_fake_loss: 0.1320, g_loss: 1.0885\n",
            "Step [7270/60000], d_real_loss: 0.1393, d_mnist_loss: 0.0146, d_svhn_loss: 0.1247, d_fake_loss: 0.0776, g_loss: 1.3037\n",
            "Step [7280/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0196, d_svhn_loss: 0.0334, d_fake_loss: 0.0561, g_loss: 0.9627\n",
            "Step [7290/60000], d_real_loss: 0.1441, d_mnist_loss: 0.0651, d_svhn_loss: 0.0790, d_fake_loss: 0.0511, g_loss: 1.3261\n",
            "Step [7300/60000], d_real_loss: 0.0555, d_mnist_loss: 0.0155, d_svhn_loss: 0.0400, d_fake_loss: 0.2780, g_loss: 1.6095\n",
            "Step [7310/60000], d_real_loss: 0.0488, d_mnist_loss: 0.0264, d_svhn_loss: 0.0224, d_fake_loss: 0.0447, g_loss: 1.1523\n",
            "Step [7320/60000], d_real_loss: 0.0772, d_mnist_loss: 0.0431, d_svhn_loss: 0.0341, d_fake_loss: 0.0645, g_loss: 1.1190\n",
            "Step [7330/60000], d_real_loss: 0.1165, d_mnist_loss: 0.0231, d_svhn_loss: 0.0934, d_fake_loss: 0.1229, g_loss: 0.7786\n",
            "Step [7340/60000], d_real_loss: 0.1841, d_mnist_loss: 0.0474, d_svhn_loss: 0.1367, d_fake_loss: 0.3281, g_loss: 1.7038\n",
            "Step [7350/60000], d_real_loss: 0.1666, d_mnist_loss: 0.0241, d_svhn_loss: 0.1425, d_fake_loss: 0.1574, g_loss: 1.0906\n",
            "Step [7360/60000], d_real_loss: 0.0915, d_mnist_loss: 0.0571, d_svhn_loss: 0.0343, d_fake_loss: 0.0699, g_loss: 1.0960\n",
            "Step [7370/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0150, d_svhn_loss: 0.0333, d_fake_loss: 0.0840, g_loss: 1.2378\n",
            "Step [7380/60000], d_real_loss: 0.0897, d_mnist_loss: 0.0273, d_svhn_loss: 0.0624, d_fake_loss: 0.1297, g_loss: 1.0493\n",
            "Step [7390/60000], d_real_loss: 0.0554, d_mnist_loss: 0.0213, d_svhn_loss: 0.0341, d_fake_loss: 0.0622, g_loss: 1.2517\n",
            "Step [7400/60000], d_real_loss: 0.0511, d_mnist_loss: 0.0180, d_svhn_loss: 0.0331, d_fake_loss: 0.1334, g_loss: 1.2026\n",
            "Step [7410/60000], d_real_loss: 0.1607, d_mnist_loss: 0.0303, d_svhn_loss: 0.1304, d_fake_loss: 0.2137, g_loss: 1.6055\n",
            "Step [7420/60000], d_real_loss: 0.0897, d_mnist_loss: 0.0263, d_svhn_loss: 0.0633, d_fake_loss: 0.0934, g_loss: 1.2255\n",
            "Step [7430/60000], d_real_loss: 0.1524, d_mnist_loss: 0.0369, d_svhn_loss: 0.1155, d_fake_loss: 0.0666, g_loss: 1.0552\n",
            "Step [7440/60000], d_real_loss: 0.0612, d_mnist_loss: 0.0269, d_svhn_loss: 0.0343, d_fake_loss: 0.0675, g_loss: 1.1776\n",
            "Step [7450/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0163, d_svhn_loss: 0.0433, d_fake_loss: 0.1145, g_loss: 0.9399\n",
            "Step [7460/60000], d_real_loss: 0.4158, d_mnist_loss: 0.2991, d_svhn_loss: 0.1168, d_fake_loss: 0.2766, g_loss: 1.4734\n",
            "Step [7470/60000], d_real_loss: 0.2355, d_mnist_loss: 0.0305, d_svhn_loss: 0.2050, d_fake_loss: 0.1808, g_loss: 1.4090\n",
            "Step [7480/60000], d_real_loss: 0.0608, d_mnist_loss: 0.0169, d_svhn_loss: 0.0439, d_fake_loss: 0.1198, g_loss: 0.9880\n",
            "Step [7490/60000], d_real_loss: 0.1358, d_mnist_loss: 0.0989, d_svhn_loss: 0.0369, d_fake_loss: 0.1900, g_loss: 1.6323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999999403953552]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [7500/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0134, d_svhn_loss: 0.0318, d_fake_loss: 0.1432, g_loss: 1.2181\n",
            "saved ./samples_fashion/sample-7500-m-s.png\n",
            "saved ./samples_fashion/sample-7500-s-m.png\n",
            "Step [7510/60000], d_real_loss: 0.0508, d_mnist_loss: 0.0155, d_svhn_loss: 0.0353, d_fake_loss: 0.0493, g_loss: 1.3093\n",
            "Step [7520/60000], d_real_loss: 0.0622, d_mnist_loss: 0.0216, d_svhn_loss: 0.0405, d_fake_loss: 0.1179, g_loss: 1.4212\n",
            "Step [7530/60000], d_real_loss: 0.0546, d_mnist_loss: 0.0241, d_svhn_loss: 0.0305, d_fake_loss: 0.1028, g_loss: 1.3568\n",
            "Step [7540/60000], d_real_loss: 0.1571, d_mnist_loss: 0.1261, d_svhn_loss: 0.0310, d_fake_loss: 0.1084, g_loss: 1.1885\n",
            "Step [7550/60000], d_real_loss: 0.0438, d_mnist_loss: 0.0186, d_svhn_loss: 0.0252, d_fake_loss: 0.0562, g_loss: 1.1302\n",
            "Step [7560/60000], d_real_loss: 0.0840, d_mnist_loss: 0.0283, d_svhn_loss: 0.0557, d_fake_loss: 0.0720, g_loss: 1.3573\n",
            "Step [7570/60000], d_real_loss: 0.0769, d_mnist_loss: 0.0221, d_svhn_loss: 0.0548, d_fake_loss: 0.0639, g_loss: 1.1223\n",
            "Step [7580/60000], d_real_loss: 0.0636, d_mnist_loss: 0.0157, d_svhn_loss: 0.0479, d_fake_loss: 0.0738, g_loss: 1.1778\n",
            "Step [7590/60000], d_real_loss: 0.0486, d_mnist_loss: 0.0207, d_svhn_loss: 0.0279, d_fake_loss: 0.0543, g_loss: 1.0505\n",
            "Step [7600/60000], d_real_loss: 0.1383, d_mnist_loss: 0.0179, d_svhn_loss: 0.1204, d_fake_loss: 0.0715, g_loss: 0.9488\n",
            "Step [7610/60000], d_real_loss: 0.0593, d_mnist_loss: 0.0223, d_svhn_loss: 0.0371, d_fake_loss: 0.0430, g_loss: 0.9696\n",
            "Step [7620/60000], d_real_loss: 0.0350, d_mnist_loss: 0.0130, d_svhn_loss: 0.0220, d_fake_loss: 0.0348, g_loss: 1.1398\n",
            "Step [7630/60000], d_real_loss: 0.0887, d_mnist_loss: 0.0239, d_svhn_loss: 0.0647, d_fake_loss: 0.0418, g_loss: 1.1754\n",
            "Step [7640/60000], d_real_loss: 0.0559, d_mnist_loss: 0.0163, d_svhn_loss: 0.0396, d_fake_loss: 0.0505, g_loss: 0.9993\n",
            "Step [7650/60000], d_real_loss: 0.2100, d_mnist_loss: 0.0779, d_svhn_loss: 0.1321, d_fake_loss: 0.0975, g_loss: 1.2256\n",
            "Step [7660/60000], d_real_loss: 0.1492, d_mnist_loss: 0.0727, d_svhn_loss: 0.0765, d_fake_loss: 0.0618, g_loss: 1.0957\n",
            "Step [7670/60000], d_real_loss: 0.1501, d_mnist_loss: 0.0173, d_svhn_loss: 0.1328, d_fake_loss: 0.0875, g_loss: 1.0556\n",
            "Step [7680/60000], d_real_loss: 0.0598, d_mnist_loss: 0.0175, d_svhn_loss: 0.0422, d_fake_loss: 0.0624, g_loss: 1.1852\n",
            "Step [7690/60000], d_real_loss: 0.1455, d_mnist_loss: 0.0219, d_svhn_loss: 0.1236, d_fake_loss: 0.0366, g_loss: 1.1691\n",
            "Step [7700/60000], d_real_loss: 0.0693, d_mnist_loss: 0.0191, d_svhn_loss: 0.0502, d_fake_loss: 0.1433, g_loss: 0.6923\n",
            "Step [7710/60000], d_real_loss: 0.3025, d_mnist_loss: 0.0130, d_svhn_loss: 0.2895, d_fake_loss: 0.5802, g_loss: 1.1558\n",
            "Step [7720/60000], d_real_loss: 0.1695, d_mnist_loss: 0.0166, d_svhn_loss: 0.1529, d_fake_loss: 0.1050, g_loss: 1.2052\n",
            "Step [7730/60000], d_real_loss: 0.0562, d_mnist_loss: 0.0170, d_svhn_loss: 0.0392, d_fake_loss: 0.1317, g_loss: 1.6490\n",
            "Step [7740/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0159, d_svhn_loss: 0.0371, d_fake_loss: 0.0668, g_loss: 0.9729\n",
            "Step [7750/60000], d_real_loss: 0.1739, d_mnist_loss: 0.1469, d_svhn_loss: 0.0270, d_fake_loss: 0.0514, g_loss: 1.6134\n",
            "Step [7760/60000], d_real_loss: 0.0494, d_mnist_loss: 0.0190, d_svhn_loss: 0.0304, d_fake_loss: 0.1163, g_loss: 1.2630\n",
            "Step [7770/60000], d_real_loss: 0.2790, d_mnist_loss: 0.2222, d_svhn_loss: 0.0568, d_fake_loss: 0.1711, g_loss: 1.7303\n",
            "Step [7780/60000], d_real_loss: 0.0914, d_mnist_loss: 0.0594, d_svhn_loss: 0.0321, d_fake_loss: 0.0681, g_loss: 1.1566\n",
            "Step [7790/60000], d_real_loss: 0.0683, d_mnist_loss: 0.0180, d_svhn_loss: 0.0503, d_fake_loss: 0.1014, g_loss: 0.9222\n",
            "Step [7800/60000], d_real_loss: 0.0654, d_mnist_loss: 0.0159, d_svhn_loss: 0.0495, d_fake_loss: 0.0594, g_loss: 1.1093\n",
            "Step [7810/60000], d_real_loss: 0.0756, d_mnist_loss: 0.0388, d_svhn_loss: 0.0367, d_fake_loss: 0.0575, g_loss: 1.2203\n",
            "Step [7820/60000], d_real_loss: 0.0923, d_mnist_loss: 0.0525, d_svhn_loss: 0.0398, d_fake_loss: 0.0615, g_loss: 1.0169\n",
            "Step [7830/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0212, d_svhn_loss: 0.0317, d_fake_loss: 0.0410, g_loss: 1.3174\n",
            "Step [7840/60000], d_real_loss: 0.2866, d_mnist_loss: 0.0254, d_svhn_loss: 0.2612, d_fake_loss: 0.4079, g_loss: 1.3092\n",
            "Step [7850/60000], d_real_loss: 0.1381, d_mnist_loss: 0.0214, d_svhn_loss: 0.1167, d_fake_loss: 0.0967, g_loss: 1.1346\n",
            "Step [7860/60000], d_real_loss: 0.0619, d_mnist_loss: 0.0255, d_svhn_loss: 0.0363, d_fake_loss: 0.0992, g_loss: 1.1032\n",
            "Step [7870/60000], d_real_loss: 0.1124, d_mnist_loss: 0.0115, d_svhn_loss: 0.1009, d_fake_loss: 0.1217, g_loss: 1.8229\n",
            "Step [7880/60000], d_real_loss: 0.1260, d_mnist_loss: 0.0823, d_svhn_loss: 0.0437, d_fake_loss: 0.4181, g_loss: 2.0532\n",
            "Step [7890/60000], d_real_loss: 0.0468, d_mnist_loss: 0.0185, d_svhn_loss: 0.0283, d_fake_loss: 0.0869, g_loss: 1.2608\n",
            "Step [7900/60000], d_real_loss: 0.0619, d_mnist_loss: 0.0256, d_svhn_loss: 0.0362, d_fake_loss: 0.1269, g_loss: 1.1766\n",
            "Step [7910/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0162, d_svhn_loss: 0.0235, d_fake_loss: 0.0773, g_loss: 1.3640\n",
            "Step [7920/60000], d_real_loss: 0.0481, d_mnist_loss: 0.0177, d_svhn_loss: 0.0303, d_fake_loss: 0.1198, g_loss: 0.9518\n",
            "Step [7930/60000], d_real_loss: 0.0959, d_mnist_loss: 0.0719, d_svhn_loss: 0.0240, d_fake_loss: 0.0483, g_loss: 1.0981\n",
            "Step [7940/60000], d_real_loss: 0.0580, d_mnist_loss: 0.0203, d_svhn_loss: 0.0377, d_fake_loss: 0.0826, g_loss: 1.3597\n",
            "Step [7950/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0172, d_svhn_loss: 0.0416, d_fake_loss: 0.1600, g_loss: 1.1825\n",
            "Step [7960/60000], d_real_loss: 0.0620, d_mnist_loss: 0.0295, d_svhn_loss: 0.0324, d_fake_loss: 0.0964, g_loss: 1.3528\n",
            "Step [7970/60000], d_real_loss: 0.1449, d_mnist_loss: 0.0775, d_svhn_loss: 0.0674, d_fake_loss: 0.0459, g_loss: 1.2713\n",
            "Step [7980/60000], d_real_loss: 0.1225, d_mnist_loss: 0.0412, d_svhn_loss: 0.0812, d_fake_loss: 0.0578, g_loss: 1.1046\n",
            "Step [7990/60000], d_real_loss: 0.1124, d_mnist_loss: 0.0700, d_svhn_loss: 0.0424, d_fake_loss: 0.0422, g_loss: 1.0776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999999403953552]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [8000/60000], d_real_loss: 0.0664, d_mnist_loss: 0.0196, d_svhn_loss: 0.0468, d_fake_loss: 0.0437, g_loss: 1.0770\n",
            "saved ./samples_fashion/sample-8000-m-s.png\n",
            "saved ./samples_fashion/sample-8000-s-m.png\n",
            "Step [8010/60000], d_real_loss: 0.1078, d_mnist_loss: 0.0449, d_svhn_loss: 0.0629, d_fake_loss: 0.0914, g_loss: 0.9511\n",
            "Step [8020/60000], d_real_loss: 0.2330, d_mnist_loss: 0.0211, d_svhn_loss: 0.2118, d_fake_loss: 0.0724, g_loss: 1.1277\n",
            "Step [8030/60000], d_real_loss: 0.1821, d_mnist_loss: 0.0164, d_svhn_loss: 0.1657, d_fake_loss: 0.2547, g_loss: 1.0324\n",
            "Step [8040/60000], d_real_loss: 0.0872, d_mnist_loss: 0.0445, d_svhn_loss: 0.0427, d_fake_loss: 0.0670, g_loss: 1.4684\n",
            "Step [8050/60000], d_real_loss: 0.0818, d_mnist_loss: 0.0187, d_svhn_loss: 0.0630, d_fake_loss: 0.0458, g_loss: 1.1098\n",
            "Step [8060/60000], d_real_loss: 0.0897, d_mnist_loss: 0.0637, d_svhn_loss: 0.0261, d_fake_loss: 0.0518, g_loss: 1.0230\n",
            "Step [8070/60000], d_real_loss: 0.1511, d_mnist_loss: 0.1038, d_svhn_loss: 0.0473, d_fake_loss: 0.1528, g_loss: 1.0569\n",
            "Step [8080/60000], d_real_loss: 0.0552, d_mnist_loss: 0.0232, d_svhn_loss: 0.0319, d_fake_loss: 0.1454, g_loss: 1.2072\n",
            "Step [8090/60000], d_real_loss: 0.0814, d_mnist_loss: 0.0170, d_svhn_loss: 0.0643, d_fake_loss: 0.2553, g_loss: 1.2075\n",
            "Step [8100/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0176, d_svhn_loss: 0.0261, d_fake_loss: 0.0501, g_loss: 1.3888\n",
            "Step [8110/60000], d_real_loss: 0.0862, d_mnist_loss: 0.0589, d_svhn_loss: 0.0273, d_fake_loss: 0.1041, g_loss: 1.1419\n",
            "Step [8120/60000], d_real_loss: 0.1187, d_mnist_loss: 0.0844, d_svhn_loss: 0.0342, d_fake_loss: 0.1460, g_loss: 1.6876\n",
            "Step [8130/60000], d_real_loss: 0.0666, d_mnist_loss: 0.0406, d_svhn_loss: 0.0260, d_fake_loss: 0.0804, g_loss: 1.2942\n",
            "Step [8140/60000], d_real_loss: 0.1053, d_mnist_loss: 0.0208, d_svhn_loss: 0.0846, d_fake_loss: 0.1294, g_loss: 1.3367\n",
            "Step [8150/60000], d_real_loss: 0.2700, d_mnist_loss: 0.0449, d_svhn_loss: 0.2251, d_fake_loss: 0.1363, g_loss: 1.0307\n",
            "Step [8160/60000], d_real_loss: 0.0566, d_mnist_loss: 0.0225, d_svhn_loss: 0.0341, d_fake_loss: 0.0640, g_loss: 0.9707\n",
            "Step [8170/60000], d_real_loss: 0.1924, d_mnist_loss: 0.0172, d_svhn_loss: 0.1752, d_fake_loss: 0.1989, g_loss: 1.0136\n",
            "Step [8180/60000], d_real_loss: 0.1136, d_mnist_loss: 0.0628, d_svhn_loss: 0.0508, d_fake_loss: 0.1592, g_loss: 1.3823\n",
            "Step [8190/60000], d_real_loss: 0.0510, d_mnist_loss: 0.0161, d_svhn_loss: 0.0349, d_fake_loss: 0.0804, g_loss: 0.9279\n",
            "Step [8200/60000], d_real_loss: 0.0768, d_mnist_loss: 0.0403, d_svhn_loss: 0.0365, d_fake_loss: 0.0613, g_loss: 1.0194\n",
            "Step [8210/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0247, d_svhn_loss: 0.0229, d_fake_loss: 0.0993, g_loss: 1.0420\n",
            "Step [8220/60000], d_real_loss: 0.0693, d_mnist_loss: 0.0248, d_svhn_loss: 0.0444, d_fake_loss: 0.0623, g_loss: 1.4167\n",
            "Step [8230/60000], d_real_loss: 0.2396, d_mnist_loss: 0.0965, d_svhn_loss: 0.1431, d_fake_loss: 0.0889, g_loss: 1.4772\n",
            "Step [8240/60000], d_real_loss: 1.6197, d_mnist_loss: 0.0180, d_svhn_loss: 1.6017, d_fake_loss: 2.2755, g_loss: 1.2856\n",
            "Step [8250/60000], d_real_loss: 0.4275, d_mnist_loss: 0.0159, d_svhn_loss: 0.4116, d_fake_loss: 0.4368, g_loss: 1.0912\n",
            "Step [8260/60000], d_real_loss: 0.5254, d_mnist_loss: 0.2573, d_svhn_loss: 0.2681, d_fake_loss: 0.5204, g_loss: 1.9454\n",
            "Step [8270/60000], d_real_loss: 0.1734, d_mnist_loss: 0.0513, d_svhn_loss: 0.1221, d_fake_loss: 0.1456, g_loss: 1.3698\n",
            "Step [8280/60000], d_real_loss: 0.2252, d_mnist_loss: 0.0182, d_svhn_loss: 0.2070, d_fake_loss: 0.1453, g_loss: 1.1794\n",
            "Step [8290/60000], d_real_loss: 0.1279, d_mnist_loss: 0.0218, d_svhn_loss: 0.1061, d_fake_loss: 0.1199, g_loss: 1.2074\n",
            "Step [8300/60000], d_real_loss: 0.1377, d_mnist_loss: 0.0638, d_svhn_loss: 0.0739, d_fake_loss: 0.1746, g_loss: 1.1456\n",
            "Step [8310/60000], d_real_loss: 0.0926, d_mnist_loss: 0.0234, d_svhn_loss: 0.0692, d_fake_loss: 0.0817, g_loss: 1.1154\n",
            "Step [8320/60000], d_real_loss: 0.1255, d_mnist_loss: 0.0196, d_svhn_loss: 0.1059, d_fake_loss: 0.2945, g_loss: 1.3691\n",
            "Step [8330/60000], d_real_loss: 0.0881, d_mnist_loss: 0.0148, d_svhn_loss: 0.0733, d_fake_loss: 0.0352, g_loss: 1.3152\n",
            "Step [8340/60000], d_real_loss: 0.0732, d_mnist_loss: 0.0248, d_svhn_loss: 0.0484, d_fake_loss: 0.0618, g_loss: 1.0832\n",
            "Step [8350/60000], d_real_loss: 0.4845, d_mnist_loss: 0.2813, d_svhn_loss: 0.2032, d_fake_loss: 0.2233, g_loss: 1.5344\n",
            "Step [8360/60000], d_real_loss: 0.1897, d_mnist_loss: 0.0451, d_svhn_loss: 0.1447, d_fake_loss: 0.2163, g_loss: 0.9065\n",
            "Step [8370/60000], d_real_loss: 0.0533, d_mnist_loss: 0.0243, d_svhn_loss: 0.0290, d_fake_loss: 0.0690, g_loss: 1.0504\n",
            "Step [8380/60000], d_real_loss: 0.0563, d_mnist_loss: 0.0171, d_svhn_loss: 0.0391, d_fake_loss: 0.0507, g_loss: 1.2244\n",
            "Step [8390/60000], d_real_loss: 0.0877, d_mnist_loss: 0.0112, d_svhn_loss: 0.0765, d_fake_loss: 0.0414, g_loss: 1.1800\n",
            "Step [8400/60000], d_real_loss: 0.1156, d_mnist_loss: 0.0178, d_svhn_loss: 0.0978, d_fake_loss: 0.1748, g_loss: 1.4723\n",
            "Step [8410/60000], d_real_loss: 0.1491, d_mnist_loss: 0.0907, d_svhn_loss: 0.0584, d_fake_loss: 0.1564, g_loss: 0.7437\n",
            "Step [8420/60000], d_real_loss: 0.1993, d_mnist_loss: 0.1506, d_svhn_loss: 0.0487, d_fake_loss: 0.7084, g_loss: 2.4184\n",
            "Step [8430/60000], d_real_loss: 0.0659, d_mnist_loss: 0.0149, d_svhn_loss: 0.0510, d_fake_loss: 0.0764, g_loss: 1.0239\n",
            "Step [8440/60000], d_real_loss: 0.0609, d_mnist_loss: 0.0327, d_svhn_loss: 0.0283, d_fake_loss: 0.0784, g_loss: 1.1699\n",
            "Step [8450/60000], d_real_loss: 0.1224, d_mnist_loss: 0.0194, d_svhn_loss: 0.1030, d_fake_loss: 0.0775, g_loss: 1.2014\n",
            "Step [8460/60000], d_real_loss: 0.0608, d_mnist_loss: 0.0187, d_svhn_loss: 0.0421, d_fake_loss: 0.0855, g_loss: 1.0962\n",
            "Step [8470/60000], d_real_loss: 0.2760, d_mnist_loss: 0.1856, d_svhn_loss: 0.0904, d_fake_loss: 0.2236, g_loss: 1.5961\n",
            "Step [8480/60000], d_real_loss: 0.0877, d_mnist_loss: 0.0566, d_svhn_loss: 0.0311, d_fake_loss: 0.1361, g_loss: 1.2926\n",
            "Step [8490/60000], d_real_loss: 0.4521, d_mnist_loss: 0.4222, d_svhn_loss: 0.0298, d_fake_loss: 0.1896, g_loss: 1.5161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999992847442627]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [8500/60000], d_real_loss: 0.0781, d_mnist_loss: 0.0323, d_svhn_loss: 0.0458, d_fake_loss: 0.0887, g_loss: 1.0955\n",
            "saved ./samples_fashion/sample-8500-m-s.png\n",
            "saved ./samples_fashion/sample-8500-s-m.png\n",
            "Step [8510/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0252, d_svhn_loss: 0.0320, d_fake_loss: 0.0748, g_loss: 0.9323\n",
            "Step [8520/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0187, d_svhn_loss: 0.0353, d_fake_loss: 0.0860, g_loss: 1.0591\n",
            "Step [8530/60000], d_real_loss: 0.0777, d_mnist_loss: 0.0237, d_svhn_loss: 0.0539, d_fake_loss: 0.1210, g_loss: 1.3481\n",
            "Step [8540/60000], d_real_loss: 0.1199, d_mnist_loss: 0.0172, d_svhn_loss: 0.1027, d_fake_loss: 0.0927, g_loss: 1.1402\n",
            "Step [8550/60000], d_real_loss: 0.1143, d_mnist_loss: 0.0293, d_svhn_loss: 0.0850, d_fake_loss: 0.0446, g_loss: 1.1003\n",
            "Step [8560/60000], d_real_loss: 0.2037, d_mnist_loss: 0.0445, d_svhn_loss: 0.1592, d_fake_loss: 0.1970, g_loss: 1.6987\n",
            "Step [8570/60000], d_real_loss: 0.1503, d_mnist_loss: 0.0590, d_svhn_loss: 0.0913, d_fake_loss: 0.0708, g_loss: 1.0970\n",
            "Step [8580/60000], d_real_loss: 0.1207, d_mnist_loss: 0.0391, d_svhn_loss: 0.0815, d_fake_loss: 0.0781, g_loss: 1.0688\n",
            "Step [8590/60000], d_real_loss: 0.1117, d_mnist_loss: 0.0803, d_svhn_loss: 0.0314, d_fake_loss: 0.0775, g_loss: 1.1578\n",
            "Step [8600/60000], d_real_loss: 0.0492, d_mnist_loss: 0.0152, d_svhn_loss: 0.0340, d_fake_loss: 0.0765, g_loss: 0.9967\n",
            "Step [8610/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0109, d_svhn_loss: 0.0375, d_fake_loss: 0.2174, g_loss: 1.3195\n",
            "Step [8620/60000], d_real_loss: 0.0536, d_mnist_loss: 0.0137, d_svhn_loss: 0.0399, d_fake_loss: 0.0553, g_loss: 1.2128\n",
            "Step [8630/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0121, d_svhn_loss: 0.0274, d_fake_loss: 0.0359, g_loss: 1.0920\n",
            "Step [8640/60000], d_real_loss: 0.0823, d_mnist_loss: 0.0342, d_svhn_loss: 0.0481, d_fake_loss: 0.1158, g_loss: 1.2345\n",
            "Step [8650/60000], d_real_loss: 0.0707, d_mnist_loss: 0.0240, d_svhn_loss: 0.0467, d_fake_loss: 0.0789, g_loss: 0.7324\n",
            "Step [8660/60000], d_real_loss: 0.1332, d_mnist_loss: 0.0154, d_svhn_loss: 0.1178, d_fake_loss: 0.0443, g_loss: 1.1189\n",
            "Step [8670/60000], d_real_loss: 0.1856, d_mnist_loss: 0.1434, d_svhn_loss: 0.0423, d_fake_loss: 0.1011, g_loss: 0.8030\n",
            "Step [8680/60000], d_real_loss: 0.0727, d_mnist_loss: 0.0310, d_svhn_loss: 0.0417, d_fake_loss: 0.0530, g_loss: 1.1952\n",
            "Step [8690/60000], d_real_loss: 0.0786, d_mnist_loss: 0.0260, d_svhn_loss: 0.0526, d_fake_loss: 0.0511, g_loss: 1.1391\n",
            "Step [8700/60000], d_real_loss: 0.0562, d_mnist_loss: 0.0207, d_svhn_loss: 0.0355, d_fake_loss: 0.0634, g_loss: 1.2169\n",
            "Step [8710/60000], d_real_loss: 0.1213, d_mnist_loss: 0.0466, d_svhn_loss: 0.0747, d_fake_loss: 0.1771, g_loss: 1.0434\n",
            "Step [8720/60000], d_real_loss: 0.0771, d_mnist_loss: 0.0346, d_svhn_loss: 0.0425, d_fake_loss: 0.1351, g_loss: 1.5975\n",
            "Step [8730/60000], d_real_loss: 0.0994, d_mnist_loss: 0.0571, d_svhn_loss: 0.0424, d_fake_loss: 0.0418, g_loss: 1.0888\n",
            "Step [8740/60000], d_real_loss: 0.0846, d_mnist_loss: 0.0164, d_svhn_loss: 0.0682, d_fake_loss: 0.0451, g_loss: 1.1614\n",
            "Step [8750/60000], d_real_loss: 0.0766, d_mnist_loss: 0.0270, d_svhn_loss: 0.0496, d_fake_loss: 0.0867, g_loss: 1.1357\n",
            "Step [8760/60000], d_real_loss: 0.2950, d_mnist_loss: 0.0578, d_svhn_loss: 0.2372, d_fake_loss: 0.2209, g_loss: 1.1600\n",
            "Step [8770/60000], d_real_loss: 0.0602, d_mnist_loss: 0.0166, d_svhn_loss: 0.0436, d_fake_loss: 0.0587, g_loss: 1.0056\n",
            "Step [8780/60000], d_real_loss: 0.2075, d_mnist_loss: 0.0716, d_svhn_loss: 0.1359, d_fake_loss: 0.1555, g_loss: 1.3844\n",
            "Step [8790/60000], d_real_loss: 0.0681, d_mnist_loss: 0.0228, d_svhn_loss: 0.0453, d_fake_loss: 0.0434, g_loss: 0.9738\n",
            "Step [8800/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0103, d_svhn_loss: 0.0269, d_fake_loss: 0.1226, g_loss: 1.1180\n",
            "Step [8810/60000], d_real_loss: 0.0831, d_mnist_loss: 0.0449, d_svhn_loss: 0.0382, d_fake_loss: 0.1859, g_loss: 1.4354\n",
            "Step [8820/60000], d_real_loss: 0.2018, d_mnist_loss: 0.0652, d_svhn_loss: 0.1366, d_fake_loss: 0.0916, g_loss: 1.1474\n",
            "Step [8830/60000], d_real_loss: 0.0729, d_mnist_loss: 0.0244, d_svhn_loss: 0.0485, d_fake_loss: 0.1629, g_loss: 1.2329\n",
            "Step [8840/60000], d_real_loss: 0.0425, d_mnist_loss: 0.0197, d_svhn_loss: 0.0228, d_fake_loss: 0.0882, g_loss: 1.2665\n",
            "Step [8850/60000], d_real_loss: 0.0613, d_mnist_loss: 0.0180, d_svhn_loss: 0.0433, d_fake_loss: 0.0748, g_loss: 1.0829\n",
            "Step [8860/60000], d_real_loss: 0.0677, d_mnist_loss: 0.0383, d_svhn_loss: 0.0294, d_fake_loss: 0.0550, g_loss: 1.1272\n",
            "Step [8870/60000], d_real_loss: 0.1032, d_mnist_loss: 0.0305, d_svhn_loss: 0.0727, d_fake_loss: 0.1069, g_loss: 1.1742\n",
            "Step [8880/60000], d_real_loss: 0.0845, d_mnist_loss: 0.0314, d_svhn_loss: 0.0532, d_fake_loss: 0.0592, g_loss: 1.1241\n",
            "Step [8890/60000], d_real_loss: 0.0636, d_mnist_loss: 0.0237, d_svhn_loss: 0.0399, d_fake_loss: 0.0667, g_loss: 0.9968\n",
            "Step [8900/60000], d_real_loss: 0.1275, d_mnist_loss: 0.0262, d_svhn_loss: 0.1013, d_fake_loss: 0.0832, g_loss: 1.1801\n",
            "Step [8910/60000], d_real_loss: 0.0688, d_mnist_loss: 0.0356, d_svhn_loss: 0.0332, d_fake_loss: 0.1390, g_loss: 1.1363\n",
            "Step [8920/60000], d_real_loss: 0.1774, d_mnist_loss: 0.1492, d_svhn_loss: 0.0282, d_fake_loss: 0.0548, g_loss: 1.0725\n",
            "Step [8930/60000], d_real_loss: 0.0747, d_mnist_loss: 0.0326, d_svhn_loss: 0.0420, d_fake_loss: 0.0595, g_loss: 1.1064\n",
            "Step [8940/60000], d_real_loss: 0.0859, d_mnist_loss: 0.0228, d_svhn_loss: 0.0631, d_fake_loss: 0.0594, g_loss: 1.2158\n",
            "Step [8950/60000], d_real_loss: 0.0912, d_mnist_loss: 0.0604, d_svhn_loss: 0.0308, d_fake_loss: 0.0701, g_loss: 1.1802\n",
            "Step [8960/60000], d_real_loss: 0.1017, d_mnist_loss: 0.0703, d_svhn_loss: 0.0314, d_fake_loss: 0.0539, g_loss: 1.1876\n",
            "Step [8970/60000], d_real_loss: 0.0571, d_mnist_loss: 0.0156, d_svhn_loss: 0.0415, d_fake_loss: 0.0422, g_loss: 1.1244\n",
            "Step [8980/60000], d_real_loss: 0.1037, d_mnist_loss: 0.0304, d_svhn_loss: 0.0733, d_fake_loss: 0.0655, g_loss: 1.0072\n",
            "Step [8990/60000], d_real_loss: 0.1165, d_mnist_loss: 0.0088, d_svhn_loss: 0.1077, d_fake_loss: 0.0907, g_loss: 1.3760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999982118606567]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [9000/60000], d_real_loss: 0.0858, d_mnist_loss: 0.0141, d_svhn_loss: 0.0717, d_fake_loss: 0.0377, g_loss: 1.0821\n",
            "saved ./samples_fashion/sample-9000-m-s.png\n",
            "saved ./samples_fashion/sample-9000-s-m.png\n",
            "Step [9010/60000], d_real_loss: 0.0998, d_mnist_loss: 0.0182, d_svhn_loss: 0.0815, d_fake_loss: 0.1673, g_loss: 1.2810\n",
            "Step [9020/60000], d_real_loss: 0.1019, d_mnist_loss: 0.0482, d_svhn_loss: 0.0537, d_fake_loss: 0.1288, g_loss: 0.9540\n",
            "Step [9030/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0479, d_svhn_loss: 0.0256, d_fake_loss: 0.0640, g_loss: 1.0717\n",
            "Step [9040/60000], d_real_loss: 0.0737, d_mnist_loss: 0.0439, d_svhn_loss: 0.0298, d_fake_loss: 0.0459, g_loss: 1.1532\n",
            "Step [9050/60000], d_real_loss: 0.1024, d_mnist_loss: 0.0511, d_svhn_loss: 0.0513, d_fake_loss: 0.0548, g_loss: 1.1175\n",
            "Step [9060/60000], d_real_loss: 0.1408, d_mnist_loss: 0.0387, d_svhn_loss: 0.1021, d_fake_loss: 0.1176, g_loss: 1.2923\n",
            "Step [9070/60000], d_real_loss: 0.0408, d_mnist_loss: 0.0154, d_svhn_loss: 0.0254, d_fake_loss: 0.0308, g_loss: 1.0158\n",
            "Step [9080/60000], d_real_loss: 0.1148, d_mnist_loss: 0.0113, d_svhn_loss: 0.1035, d_fake_loss: 0.1618, g_loss: 1.3508\n",
            "Step [9090/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0148, d_svhn_loss: 0.0195, d_fake_loss: 0.0350, g_loss: 1.1530\n",
            "Step [9100/60000], d_real_loss: 0.0676, d_mnist_loss: 0.0368, d_svhn_loss: 0.0308, d_fake_loss: 0.0714, g_loss: 0.7761\n",
            "Step [9110/60000], d_real_loss: 0.0894, d_mnist_loss: 0.0295, d_svhn_loss: 0.0598, d_fake_loss: 0.1083, g_loss: 1.2990\n",
            "Step [9120/60000], d_real_loss: 0.0547, d_mnist_loss: 0.0173, d_svhn_loss: 0.0375, d_fake_loss: 0.0682, g_loss: 1.1958\n",
            "Step [9130/60000], d_real_loss: 0.0489, d_mnist_loss: 0.0228, d_svhn_loss: 0.0260, d_fake_loss: 0.0573, g_loss: 1.1501\n",
            "Step [9140/60000], d_real_loss: 0.1088, d_mnist_loss: 0.0325, d_svhn_loss: 0.0764, d_fake_loss: 0.0681, g_loss: 1.2531\n",
            "Step [9150/60000], d_real_loss: 0.1331, d_mnist_loss: 0.0137, d_svhn_loss: 0.1194, d_fake_loss: 0.1052, g_loss: 1.1108\n",
            "Step [9160/60000], d_real_loss: 0.0905, d_mnist_loss: 0.0471, d_svhn_loss: 0.0433, d_fake_loss: 0.1383, g_loss: 1.4792\n",
            "Step [9170/60000], d_real_loss: 0.0793, d_mnist_loss: 0.0518, d_svhn_loss: 0.0275, d_fake_loss: 0.0634, g_loss: 1.0587\n",
            "Step [9180/60000], d_real_loss: 0.0890, d_mnist_loss: 0.0234, d_svhn_loss: 0.0656, d_fake_loss: 0.0971, g_loss: 1.2518\n",
            "Step [9190/60000], d_real_loss: 0.0559, d_mnist_loss: 0.0209, d_svhn_loss: 0.0350, d_fake_loss: 0.1352, g_loss: 1.5076\n",
            "Step [9200/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0246, d_svhn_loss: 0.0304, d_fake_loss: 0.0490, g_loss: 1.1336\n",
            "Step [9210/60000], d_real_loss: 0.0769, d_mnist_loss: 0.0392, d_svhn_loss: 0.0377, d_fake_loss: 0.1120, g_loss: 1.2441\n",
            "Step [9220/60000], d_real_loss: 0.2576, d_mnist_loss: 0.1713, d_svhn_loss: 0.0864, d_fake_loss: 0.0732, g_loss: 1.4700\n",
            "Step [9230/60000], d_real_loss: 0.1163, d_mnist_loss: 0.0407, d_svhn_loss: 0.0756, d_fake_loss: 0.0971, g_loss: 1.2367\n",
            "Step [9240/60000], d_real_loss: 0.1377, d_mnist_loss: 0.0756, d_svhn_loss: 0.0621, d_fake_loss: 0.1122, g_loss: 1.1712\n",
            "Step [9250/60000], d_real_loss: 0.1379, d_mnist_loss: 0.0242, d_svhn_loss: 0.1137, d_fake_loss: 0.0551, g_loss: 1.2245\n",
            "Step [9260/60000], d_real_loss: 0.0585, d_mnist_loss: 0.0202, d_svhn_loss: 0.0382, d_fake_loss: 0.1091, g_loss: 1.0601\n",
            "Step [9270/60000], d_real_loss: 0.0730, d_mnist_loss: 0.0232, d_svhn_loss: 0.0498, d_fake_loss: 0.0321, g_loss: 1.0660\n",
            "Step [9280/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0123, d_svhn_loss: 0.0253, d_fake_loss: 0.0602, g_loss: 1.3203\n",
            "Step [9290/60000], d_real_loss: 0.1548, d_mnist_loss: 0.1079, d_svhn_loss: 0.0468, d_fake_loss: 0.0873, g_loss: 1.0503\n",
            "Step [9300/60000], d_real_loss: 0.0604, d_mnist_loss: 0.0229, d_svhn_loss: 0.0375, d_fake_loss: 0.0582, g_loss: 1.0099\n",
            "Step [9310/60000], d_real_loss: 0.0757, d_mnist_loss: 0.0349, d_svhn_loss: 0.0408, d_fake_loss: 0.1460, g_loss: 1.3016\n",
            "Step [9320/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0238, d_svhn_loss: 0.0345, d_fake_loss: 0.0839, g_loss: 1.5499\n",
            "Step [9330/60000], d_real_loss: 0.0640, d_mnist_loss: 0.0292, d_svhn_loss: 0.0349, d_fake_loss: 0.0451, g_loss: 1.0502\n",
            "Step [9340/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0144, d_svhn_loss: 0.0293, d_fake_loss: 0.0415, g_loss: 1.0347\n",
            "Step [9350/60000], d_real_loss: 0.0616, d_mnist_loss: 0.0330, d_svhn_loss: 0.0286, d_fake_loss: 0.1081, g_loss: 1.4658\n",
            "Step [9360/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0190, d_svhn_loss: 0.0252, d_fake_loss: 0.0438, g_loss: 1.1731\n",
            "Step [9370/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0262, d_svhn_loss: 0.0410, d_fake_loss: 0.1635, g_loss: 0.9515\n",
            "Step [9380/60000], d_real_loss: 0.1065, d_mnist_loss: 0.0747, d_svhn_loss: 0.0317, d_fake_loss: 0.2027, g_loss: 1.3066\n",
            "Step [9390/60000], d_real_loss: 0.0827, d_mnist_loss: 0.0391, d_svhn_loss: 0.0436, d_fake_loss: 0.1195, g_loss: 1.2617\n",
            "Step [9400/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0383, d_svhn_loss: 0.0213, d_fake_loss: 0.0361, g_loss: 1.0743\n",
            "Step [9410/60000], d_real_loss: 0.0714, d_mnist_loss: 0.0334, d_svhn_loss: 0.0380, d_fake_loss: 0.1361, g_loss: 1.1135\n",
            "Step [9420/60000], d_real_loss: 0.0604, d_mnist_loss: 0.0149, d_svhn_loss: 0.0455, d_fake_loss: 0.0453, g_loss: 1.2945\n",
            "Step [9430/60000], d_real_loss: 0.4680, d_mnist_loss: 0.1877, d_svhn_loss: 0.2803, d_fake_loss: 0.3917, g_loss: 1.2392\n",
            "Step [9440/60000], d_real_loss: 0.0494, d_mnist_loss: 0.0147, d_svhn_loss: 0.0347, d_fake_loss: 0.0449, g_loss: 1.0119\n",
            "Step [9450/60000], d_real_loss: 0.3820, d_mnist_loss: 0.0329, d_svhn_loss: 0.3491, d_fake_loss: 0.1059, g_loss: 1.2968\n",
            "Step [9460/60000], d_real_loss: 0.1368, d_mnist_loss: 0.1004, d_svhn_loss: 0.0365, d_fake_loss: 0.0754, g_loss: 1.3439\n",
            "Step [9470/60000], d_real_loss: 0.0611, d_mnist_loss: 0.0166, d_svhn_loss: 0.0445, d_fake_loss: 0.1650, g_loss: 1.4293\n",
            "Step [9480/60000], d_real_loss: 0.0913, d_mnist_loss: 0.0324, d_svhn_loss: 0.0589, d_fake_loss: 0.0838, g_loss: 1.1122\n",
            "Step [9490/60000], d_real_loss: 0.0803, d_mnist_loss: 0.0152, d_svhn_loss: 0.0651, d_fake_loss: 0.1036, g_loss: 1.2225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999963045120239]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [9500/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0122, d_svhn_loss: 0.0295, d_fake_loss: 0.0719, g_loss: 1.1393\n",
            "saved ./samples_fashion/sample-9500-m-s.png\n",
            "saved ./samples_fashion/sample-9500-s-m.png\n",
            "Step [9510/60000], d_real_loss: 0.1391, d_mnist_loss: 0.0429, d_svhn_loss: 0.0962, d_fake_loss: 0.0714, g_loss: 1.2050\n",
            "Step [9520/60000], d_real_loss: 0.1561, d_mnist_loss: 0.0231, d_svhn_loss: 0.1330, d_fake_loss: 0.1653, g_loss: 1.3159\n",
            "Step [9530/60000], d_real_loss: 0.0534, d_mnist_loss: 0.0225, d_svhn_loss: 0.0309, d_fake_loss: 0.0386, g_loss: 1.1962\n",
            "Step [9540/60000], d_real_loss: 0.0513, d_mnist_loss: 0.0236, d_svhn_loss: 0.0277, d_fake_loss: 0.0381, g_loss: 1.2150\n",
            "Step [9550/60000], d_real_loss: 0.1789, d_mnist_loss: 0.0488, d_svhn_loss: 0.1301, d_fake_loss: 0.0513, g_loss: 1.1006\n",
            "Step [9560/60000], d_real_loss: 0.0845, d_mnist_loss: 0.0369, d_svhn_loss: 0.0476, d_fake_loss: 0.0598, g_loss: 1.1184\n",
            "Step [9570/60000], d_real_loss: 0.0612, d_mnist_loss: 0.0211, d_svhn_loss: 0.0401, d_fake_loss: 0.0721, g_loss: 1.1313\n",
            "Step [9580/60000], d_real_loss: 0.2817, d_mnist_loss: 0.1493, d_svhn_loss: 0.1325, d_fake_loss: 0.0527, g_loss: 1.2945\n",
            "Step [9590/60000], d_real_loss: 0.0619, d_mnist_loss: 0.0197, d_svhn_loss: 0.0422, d_fake_loss: 0.0619, g_loss: 1.1668\n",
            "Step [9600/60000], d_real_loss: 0.0593, d_mnist_loss: 0.0201, d_svhn_loss: 0.0392, d_fake_loss: 0.1074, g_loss: 1.2935\n",
            "Step [9610/60000], d_real_loss: 0.0815, d_mnist_loss: 0.0266, d_svhn_loss: 0.0550, d_fake_loss: 0.0797, g_loss: 1.3017\n",
            "Step [9620/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0205, d_svhn_loss: 0.0359, d_fake_loss: 0.0487, g_loss: 0.9278\n",
            "Step [9630/60000], d_real_loss: 0.0680, d_mnist_loss: 0.0255, d_svhn_loss: 0.0425, d_fake_loss: 0.0546, g_loss: 1.1098\n",
            "Step [9640/60000], d_real_loss: 0.2177, d_mnist_loss: 0.1019, d_svhn_loss: 0.1158, d_fake_loss: 0.1031, g_loss: 1.3533\n",
            "Step [9650/60000], d_real_loss: 0.3530, d_mnist_loss: 0.0721, d_svhn_loss: 0.2809, d_fake_loss: 0.5883, g_loss: 0.8816\n",
            "Step [9660/60000], d_real_loss: 0.0614, d_mnist_loss: 0.0334, d_svhn_loss: 0.0280, d_fake_loss: 0.1079, g_loss: 0.8777\n",
            "Step [9670/60000], d_real_loss: 0.0478, d_mnist_loss: 0.0207, d_svhn_loss: 0.0271, d_fake_loss: 0.0304, g_loss: 1.0967\n",
            "Step [9680/60000], d_real_loss: 0.0743, d_mnist_loss: 0.0335, d_svhn_loss: 0.0408, d_fake_loss: 0.1090, g_loss: 1.1656\n",
            "Step [9690/60000], d_real_loss: 0.0602, d_mnist_loss: 0.0267, d_svhn_loss: 0.0335, d_fake_loss: 0.0491, g_loss: 1.1000\n",
            "Step [9700/60000], d_real_loss: 0.0515, d_mnist_loss: 0.0168, d_svhn_loss: 0.0347, d_fake_loss: 0.0360, g_loss: 1.2151\n",
            "Step [9710/60000], d_real_loss: 0.1214, d_mnist_loss: 0.0823, d_svhn_loss: 0.0391, d_fake_loss: 0.0440, g_loss: 1.2387\n",
            "Step [9720/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0223, d_svhn_loss: 0.0349, d_fake_loss: 0.0906, g_loss: 1.1411\n",
            "Step [9730/60000], d_real_loss: 0.1861, d_mnist_loss: 0.1634, d_svhn_loss: 0.0227, d_fake_loss: 0.1764, g_loss: 1.6101\n",
            "Step [9740/60000], d_real_loss: 0.1042, d_mnist_loss: 0.0555, d_svhn_loss: 0.0488, d_fake_loss: 0.1603, g_loss: 0.9394\n",
            "Step [9750/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0210, d_svhn_loss: 0.0273, d_fake_loss: 0.0427, g_loss: 1.4119\n",
            "Step [9760/60000], d_real_loss: 0.0896, d_mnist_loss: 0.0449, d_svhn_loss: 0.0446, d_fake_loss: 0.0813, g_loss: 1.1305\n",
            "Step [9770/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0191, d_svhn_loss: 0.0237, d_fake_loss: 0.2216, g_loss: 1.2430\n",
            "Step [9780/60000], d_real_loss: 0.0632, d_mnist_loss: 0.0250, d_svhn_loss: 0.0382, d_fake_loss: 0.0623, g_loss: 1.2044\n",
            "Step [9790/60000], d_real_loss: 0.0560, d_mnist_loss: 0.0285, d_svhn_loss: 0.0275, d_fake_loss: 0.1174, g_loss: 1.2311\n",
            "Step [9800/60000], d_real_loss: 0.0686, d_mnist_loss: 0.0178, d_svhn_loss: 0.0508, d_fake_loss: 0.1000, g_loss: 1.2888\n",
            "Step [9810/60000], d_real_loss: 0.0745, d_mnist_loss: 0.0195, d_svhn_loss: 0.0550, d_fake_loss: 0.0517, g_loss: 1.1148\n",
            "Step [9820/60000], d_real_loss: 0.0472, d_mnist_loss: 0.0178, d_svhn_loss: 0.0294, d_fake_loss: 0.1259, g_loss: 1.0201\n",
            "Step [9830/60000], d_real_loss: 0.0858, d_mnist_loss: 0.0133, d_svhn_loss: 0.0724, d_fake_loss: 0.0470, g_loss: 1.2537\n",
            "Step [9840/60000], d_real_loss: 0.0847, d_mnist_loss: 0.0122, d_svhn_loss: 0.0725, d_fake_loss: 0.0723, g_loss: 1.2060\n",
            "Step [9850/60000], d_real_loss: 0.0807, d_mnist_loss: 0.0389, d_svhn_loss: 0.0418, d_fake_loss: 0.0408, g_loss: 1.2334\n",
            "Step [9860/60000], d_real_loss: 0.0646, d_mnist_loss: 0.0147, d_svhn_loss: 0.0499, d_fake_loss: 0.0877, g_loss: 1.0729\n",
            "Step [9870/60000], d_real_loss: 0.0964, d_mnist_loss: 0.0721, d_svhn_loss: 0.0242, d_fake_loss: 0.3539, g_loss: 1.5779\n",
            "Step [9880/60000], d_real_loss: 0.0706, d_mnist_loss: 0.0339, d_svhn_loss: 0.0367, d_fake_loss: 0.2461, g_loss: 0.9181\n",
            "Step [9890/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0178, d_svhn_loss: 0.0262, d_fake_loss: 0.0785, g_loss: 1.2285\n",
            "Step [9900/60000], d_real_loss: 0.0655, d_mnist_loss: 0.0152, d_svhn_loss: 0.0504, d_fake_loss: 0.0729, g_loss: 1.0947\n",
            "Step [9910/60000], d_real_loss: 0.0717, d_mnist_loss: 0.0183, d_svhn_loss: 0.0533, d_fake_loss: 0.0377, g_loss: 1.0837\n",
            "Step [9920/60000], d_real_loss: 0.0444, d_mnist_loss: 0.0165, d_svhn_loss: 0.0279, d_fake_loss: 0.1337, g_loss: 0.9843\n",
            "Step [9930/60000], d_real_loss: 0.0655, d_mnist_loss: 0.0423, d_svhn_loss: 0.0232, d_fake_loss: 0.3618, g_loss: 1.5796\n",
            "Step [9940/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0126, d_svhn_loss: 0.0216, d_fake_loss: 0.0462, g_loss: 1.1846\n",
            "Step [9950/60000], d_real_loss: 0.0601, d_mnist_loss: 0.0122, d_svhn_loss: 0.0479, d_fake_loss: 0.0498, g_loss: 1.1058\n",
            "Step [9960/60000], d_real_loss: 0.0738, d_mnist_loss: 0.0266, d_svhn_loss: 0.0471, d_fake_loss: 0.0854, g_loss: 1.0098\n",
            "Step [9970/60000], d_real_loss: 0.0728, d_mnist_loss: 0.0432, d_svhn_loss: 0.0297, d_fake_loss: 0.0403, g_loss: 1.2569\n",
            "Step [9980/60000], d_real_loss: 0.0857, d_mnist_loss: 0.0172, d_svhn_loss: 0.0686, d_fake_loss: 0.0427, g_loss: 1.0057\n",
            "Step [9990/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0293, d_svhn_loss: 0.0271, d_fake_loss: 0.0344, g_loss: 1.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999977350234985]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [10000/60000], d_real_loss: 0.0806, d_mnist_loss: 0.0165, d_svhn_loss: 0.0640, d_fake_loss: 0.0397, g_loss: 1.4067\n",
            "saved ./samples_fashion/sample-10000-m-s.png\n",
            "saved ./samples_fashion/sample-10000-s-m.png\n",
            "Step [10010/60000], d_real_loss: 0.0776, d_mnist_loss: 0.0468, d_svhn_loss: 0.0308, d_fake_loss: 0.0748, g_loss: 1.4276\n",
            "Step [10020/60000], d_real_loss: 0.2431, d_mnist_loss: 0.1692, d_svhn_loss: 0.0739, d_fake_loss: 0.0541, g_loss: 1.2012\n",
            "Step [10030/60000], d_real_loss: 0.0786, d_mnist_loss: 0.0140, d_svhn_loss: 0.0646, d_fake_loss: 0.0639, g_loss: 1.1707\n",
            "Step [10040/60000], d_real_loss: 0.0860, d_mnist_loss: 0.0592, d_svhn_loss: 0.0269, d_fake_loss: 0.1176, g_loss: 1.3124\n",
            "Step [10050/60000], d_real_loss: 0.1049, d_mnist_loss: 0.0149, d_svhn_loss: 0.0900, d_fake_loss: 0.0391, g_loss: 1.0631\n",
            "Step [10060/60000], d_real_loss: 0.0802, d_mnist_loss: 0.0137, d_svhn_loss: 0.0665, d_fake_loss: 0.0958, g_loss: 1.2442\n",
            "Step [10070/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0112, d_svhn_loss: 0.0340, d_fake_loss: 0.0434, g_loss: 1.1788\n",
            "Step [10080/60000], d_real_loss: 0.1658, d_mnist_loss: 0.1368, d_svhn_loss: 0.0290, d_fake_loss: 0.0539, g_loss: 1.0423\n",
            "Step [10090/60000], d_real_loss: 0.0710, d_mnist_loss: 0.0184, d_svhn_loss: 0.0526, d_fake_loss: 0.0996, g_loss: 0.9318\n",
            "Step [10100/60000], d_real_loss: 0.0810, d_mnist_loss: 0.0488, d_svhn_loss: 0.0322, d_fake_loss: 0.0803, g_loss: 0.7740\n",
            "Step [10110/60000], d_real_loss: 0.0914, d_mnist_loss: 0.0266, d_svhn_loss: 0.0648, d_fake_loss: 0.0361, g_loss: 1.0567\n",
            "Step [10120/60000], d_real_loss: 0.0994, d_mnist_loss: 0.0171, d_svhn_loss: 0.0823, d_fake_loss: 0.0625, g_loss: 1.0932\n",
            "Step [10130/60000], d_real_loss: 0.1223, d_mnist_loss: 0.0132, d_svhn_loss: 0.1091, d_fake_loss: 0.0720, g_loss: 1.1326\n",
            "Step [10140/60000], d_real_loss: 0.0624, d_mnist_loss: 0.0178, d_svhn_loss: 0.0446, d_fake_loss: 0.0483, g_loss: 1.1746\n",
            "Step [10150/60000], d_real_loss: 0.2485, d_mnist_loss: 0.0280, d_svhn_loss: 0.2205, d_fake_loss: 0.0997, g_loss: 1.3800\n",
            "Step [10160/60000], d_real_loss: 0.0782, d_mnist_loss: 0.0189, d_svhn_loss: 0.0593, d_fake_loss: 0.1129, g_loss: 1.0298\n",
            "Step [10170/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0160, d_svhn_loss: 0.0477, d_fake_loss: 0.0969, g_loss: 1.0029\n",
            "Step [10180/60000], d_real_loss: 0.0465, d_mnist_loss: 0.0140, d_svhn_loss: 0.0325, d_fake_loss: 0.1474, g_loss: 1.0656\n",
            "Step [10190/60000], d_real_loss: 0.2211, d_mnist_loss: 0.0395, d_svhn_loss: 0.1816, d_fake_loss: 0.1800, g_loss: 1.2393\n",
            "Step [10200/60000], d_real_loss: 0.0902, d_mnist_loss: 0.0307, d_svhn_loss: 0.0595, d_fake_loss: 0.1154, g_loss: 1.0346\n",
            "Step [10210/60000], d_real_loss: 0.1057, d_mnist_loss: 0.0405, d_svhn_loss: 0.0653, d_fake_loss: 0.1002, g_loss: 1.5628\n",
            "Step [10220/60000], d_real_loss: 0.0547, d_mnist_loss: 0.0236, d_svhn_loss: 0.0311, d_fake_loss: 0.1112, g_loss: 1.1449\n",
            "Step [10230/60000], d_real_loss: 0.0819, d_mnist_loss: 0.0552, d_svhn_loss: 0.0267, d_fake_loss: 0.1055, g_loss: 1.1877\n",
            "Step [10240/60000], d_real_loss: 0.1151, d_mnist_loss: 0.0802, d_svhn_loss: 0.0348, d_fake_loss: 0.0545, g_loss: 1.3093\n",
            "Step [10250/60000], d_real_loss: 0.0708, d_mnist_loss: 0.0232, d_svhn_loss: 0.0476, d_fake_loss: 0.0604, g_loss: 1.3363\n",
            "Step [10260/60000], d_real_loss: 0.1687, d_mnist_loss: 0.0646, d_svhn_loss: 0.1041, d_fake_loss: 0.1470, g_loss: 1.4975\n",
            "Step [10270/60000], d_real_loss: 0.0741, d_mnist_loss: 0.0194, d_svhn_loss: 0.0547, d_fake_loss: 0.1312, g_loss: 0.7341\n",
            "Step [10280/60000], d_real_loss: 0.3953, d_mnist_loss: 0.0311, d_svhn_loss: 0.3641, d_fake_loss: 0.2091, g_loss: 1.0637\n",
            "Step [10290/60000], d_real_loss: 0.0738, d_mnist_loss: 0.0228, d_svhn_loss: 0.0510, d_fake_loss: 0.1057, g_loss: 1.3069\n",
            "Step [10300/60000], d_real_loss: 0.1202, d_mnist_loss: 0.0182, d_svhn_loss: 0.1020, d_fake_loss: 0.1904, g_loss: 1.0664\n",
            "Step [10310/60000], d_real_loss: 0.1067, d_mnist_loss: 0.0183, d_svhn_loss: 0.0884, d_fake_loss: 0.0524, g_loss: 1.0839\n",
            "Step [10320/60000], d_real_loss: 0.0956, d_mnist_loss: 0.0137, d_svhn_loss: 0.0819, d_fake_loss: 0.0828, g_loss: 1.3315\n",
            "Step [10330/60000], d_real_loss: 0.0686, d_mnist_loss: 0.0326, d_svhn_loss: 0.0359, d_fake_loss: 0.0571, g_loss: 1.0296\n",
            "Step [10340/60000], d_real_loss: 0.0894, d_mnist_loss: 0.0378, d_svhn_loss: 0.0516, d_fake_loss: 0.0431, g_loss: 1.0425\n",
            "Step [10350/60000], d_real_loss: 0.2663, d_mnist_loss: 0.0475, d_svhn_loss: 0.2188, d_fake_loss: 0.3418, g_loss: 2.0618\n",
            "Step [10360/60000], d_real_loss: 0.0465, d_mnist_loss: 0.0142, d_svhn_loss: 0.0323, d_fake_loss: 0.0586, g_loss: 1.4298\n",
            "Step [10370/60000], d_real_loss: 0.0981, d_mnist_loss: 0.0695, d_svhn_loss: 0.0286, d_fake_loss: 0.0400, g_loss: 1.3070\n",
            "Step [10380/60000], d_real_loss: 0.0630, d_mnist_loss: 0.0179, d_svhn_loss: 0.0450, d_fake_loss: 0.0444, g_loss: 1.0946\n",
            "Step [10390/60000], d_real_loss: 0.0635, d_mnist_loss: 0.0254, d_svhn_loss: 0.0380, d_fake_loss: 0.0747, g_loss: 1.1528\n",
            "Step [10400/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0317, d_svhn_loss: 0.0223, d_fake_loss: 0.0470, g_loss: 1.2638\n",
            "Step [10410/60000], d_real_loss: 0.0651, d_mnist_loss: 0.0143, d_svhn_loss: 0.0509, d_fake_loss: 0.0717, g_loss: 1.3091\n",
            "Step [10420/60000], d_real_loss: 0.1475, d_mnist_loss: 0.0746, d_svhn_loss: 0.0729, d_fake_loss: 0.0565, g_loss: 0.8764\n",
            "Step [10430/60000], d_real_loss: 0.0812, d_mnist_loss: 0.0562, d_svhn_loss: 0.0250, d_fake_loss: 0.1989, g_loss: 1.1510\n",
            "Step [10440/60000], d_real_loss: 0.0906, d_mnist_loss: 0.0505, d_svhn_loss: 0.0401, d_fake_loss: 0.1141, g_loss: 1.5549\n",
            "Step [10450/60000], d_real_loss: 0.1098, d_mnist_loss: 0.0642, d_svhn_loss: 0.0455, d_fake_loss: 0.4146, g_loss: 1.6595\n",
            "Step [10460/60000], d_real_loss: 0.0644, d_mnist_loss: 0.0352, d_svhn_loss: 0.0292, d_fake_loss: 0.0628, g_loss: 1.0420\n",
            "Step [10470/60000], d_real_loss: 0.0759, d_mnist_loss: 0.0267, d_svhn_loss: 0.0492, d_fake_loss: 0.0449, g_loss: 1.0433\n",
            "Step [10480/60000], d_real_loss: 0.1387, d_mnist_loss: 0.0220, d_svhn_loss: 0.1167, d_fake_loss: 0.1232, g_loss: 1.0699\n",
            "Step [10490/60000], d_real_loss: 0.0643, d_mnist_loss: 0.0191, d_svhn_loss: 0.0452, d_fake_loss: 0.2088, g_loss: 1.1482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999974966049194]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [10500/60000], d_real_loss: 0.0709, d_mnist_loss: 0.0144, d_svhn_loss: 0.0565, d_fake_loss: 0.1759, g_loss: 1.4751\n",
            "saved ./samples_fashion/sample-10500-m-s.png\n",
            "saved ./samples_fashion/sample-10500-s-m.png\n",
            "Step [10510/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0114, d_svhn_loss: 0.0279, d_fake_loss: 0.0462, g_loss: 1.2173\n",
            "Step [10520/60000], d_real_loss: 0.0521, d_mnist_loss: 0.0135, d_svhn_loss: 0.0386, d_fake_loss: 0.0665, g_loss: 1.2660\n",
            "Step [10530/60000], d_real_loss: 0.0682, d_mnist_loss: 0.0271, d_svhn_loss: 0.0410, d_fake_loss: 0.0319, g_loss: 1.2421\n",
            "Step [10540/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0174, d_svhn_loss: 0.0269, d_fake_loss: 0.0687, g_loss: 1.2436\n",
            "Step [10550/60000], d_real_loss: 0.0690, d_mnist_loss: 0.0350, d_svhn_loss: 0.0340, d_fake_loss: 0.0437, g_loss: 0.9830\n",
            "Step [10560/60000], d_real_loss: 0.0948, d_mnist_loss: 0.0541, d_svhn_loss: 0.0407, d_fake_loss: 0.1303, g_loss: 1.1399\n",
            "Step [10570/60000], d_real_loss: 0.0707, d_mnist_loss: 0.0284, d_svhn_loss: 0.0423, d_fake_loss: 0.1022, g_loss: 1.3565\n",
            "Step [10580/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0147, d_svhn_loss: 0.0187, d_fake_loss: 0.0335, g_loss: 1.0042\n",
            "Step [10590/60000], d_real_loss: 0.2173, d_mnist_loss: 0.0161, d_svhn_loss: 0.2012, d_fake_loss: 0.0509, g_loss: 1.0678\n",
            "Step [10600/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0145, d_svhn_loss: 0.0259, d_fake_loss: 0.0327, g_loss: 1.3141\n",
            "Step [10610/60000], d_real_loss: 0.1122, d_mnist_loss: 0.0139, d_svhn_loss: 0.0982, d_fake_loss: 0.1354, g_loss: 0.7678\n",
            "Step [10620/60000], d_real_loss: 0.0911, d_mnist_loss: 0.0534, d_svhn_loss: 0.0377, d_fake_loss: 0.2221, g_loss: 0.6235\n",
            "Step [10630/60000], d_real_loss: 0.0778, d_mnist_loss: 0.0201, d_svhn_loss: 0.0577, d_fake_loss: 0.0730, g_loss: 1.1719\n",
            "Step [10640/60000], d_real_loss: 0.0967, d_mnist_loss: 0.0685, d_svhn_loss: 0.0281, d_fake_loss: 0.0628, g_loss: 1.1270\n",
            "Step [10650/60000], d_real_loss: 0.0680, d_mnist_loss: 0.0151, d_svhn_loss: 0.0529, d_fake_loss: 0.0456, g_loss: 1.0759\n",
            "Step [10660/60000], d_real_loss: 0.0681, d_mnist_loss: 0.0181, d_svhn_loss: 0.0500, d_fake_loss: 0.0912, g_loss: 1.1157\n",
            "Step [10670/60000], d_real_loss: 0.0818, d_mnist_loss: 0.0164, d_svhn_loss: 0.0654, d_fake_loss: 0.0425, g_loss: 1.1851\n",
            "Step [10680/60000], d_real_loss: 0.0710, d_mnist_loss: 0.0327, d_svhn_loss: 0.0383, d_fake_loss: 0.0461, g_loss: 1.0554\n",
            "Step [10690/60000], d_real_loss: 0.1166, d_mnist_loss: 0.0642, d_svhn_loss: 0.0523, d_fake_loss: 0.0822, g_loss: 1.0944\n",
            "Step [10700/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0165, d_svhn_loss: 0.0487, d_fake_loss: 0.0608, g_loss: 1.2727\n",
            "Step [10710/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0265, d_svhn_loss: 0.0327, d_fake_loss: 0.0772, g_loss: 1.1316\n",
            "Step [10720/60000], d_real_loss: 0.0612, d_mnist_loss: 0.0363, d_svhn_loss: 0.0249, d_fake_loss: 0.0416, g_loss: 1.1258\n",
            "Step [10730/60000], d_real_loss: 0.0554, d_mnist_loss: 0.0241, d_svhn_loss: 0.0313, d_fake_loss: 0.2624, g_loss: 1.1537\n",
            "Step [10740/60000], d_real_loss: 0.0910, d_mnist_loss: 0.0133, d_svhn_loss: 0.0777, d_fake_loss: 0.0388, g_loss: 1.0853\n",
            "Step [10750/60000], d_real_loss: 0.1605, d_mnist_loss: 0.0761, d_svhn_loss: 0.0844, d_fake_loss: 0.1412, g_loss: 1.5700\n",
            "Step [10760/60000], d_real_loss: 0.1073, d_mnist_loss: 0.0183, d_svhn_loss: 0.0890, d_fake_loss: 0.0940, g_loss: 1.1860\n",
            "Step [10770/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0183, d_svhn_loss: 0.0272, d_fake_loss: 0.0474, g_loss: 1.1355\n",
            "Step [10780/60000], d_real_loss: 0.0548, d_mnist_loss: 0.0113, d_svhn_loss: 0.0435, d_fake_loss: 0.0444, g_loss: 1.1752\n",
            "Step [10790/60000], d_real_loss: 0.0978, d_mnist_loss: 0.0711, d_svhn_loss: 0.0268, d_fake_loss: 0.1334, g_loss: 1.8276\n",
            "Step [10800/60000], d_real_loss: 0.0945, d_mnist_loss: 0.0426, d_svhn_loss: 0.0519, d_fake_loss: 0.0883, g_loss: 0.8740\n",
            "Step [10810/60000], d_real_loss: 0.0843, d_mnist_loss: 0.0297, d_svhn_loss: 0.0546, d_fake_loss: 0.0656, g_loss: 0.9989\n",
            "Step [10820/60000], d_real_loss: 0.1097, d_mnist_loss: 0.0090, d_svhn_loss: 0.1007, d_fake_loss: 0.1251, g_loss: 1.1015\n",
            "Step [10830/60000], d_real_loss: 0.0822, d_mnist_loss: 0.0120, d_svhn_loss: 0.0702, d_fake_loss: 0.0564, g_loss: 1.3358\n",
            "Step [10840/60000], d_real_loss: 0.1034, d_mnist_loss: 0.0187, d_svhn_loss: 0.0848, d_fake_loss: 0.0421, g_loss: 1.1610\n",
            "Step [10850/60000], d_real_loss: 0.0552, d_mnist_loss: 0.0252, d_svhn_loss: 0.0301, d_fake_loss: 0.0892, g_loss: 1.1808\n",
            "Step [10860/60000], d_real_loss: 0.1132, d_mnist_loss: 0.0783, d_svhn_loss: 0.0348, d_fake_loss: 0.0779, g_loss: 1.1078\n",
            "Step [10870/60000], d_real_loss: 0.2153, d_mnist_loss: 0.1900, d_svhn_loss: 0.0254, d_fake_loss: 0.1224, g_loss: 1.3889\n",
            "Step [10880/60000], d_real_loss: 0.1567, d_mnist_loss: 0.0329, d_svhn_loss: 0.1237, d_fake_loss: 0.0812, g_loss: 1.1835\n",
            "Step [10890/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0114, d_svhn_loss: 0.0228, d_fake_loss: 0.1106, g_loss: 1.4128\n",
            "Step [10900/60000], d_real_loss: 0.1148, d_mnist_loss: 0.0118, d_svhn_loss: 0.1030, d_fake_loss: 0.0719, g_loss: 1.0193\n",
            "Step [10910/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0169, d_svhn_loss: 0.0315, d_fake_loss: 0.0556, g_loss: 1.1688\n",
            "Step [10920/60000], d_real_loss: 0.1726, d_mnist_loss: 0.0535, d_svhn_loss: 0.1191, d_fake_loss: 0.2282, g_loss: 1.4451\n",
            "Step [10930/60000], d_real_loss: 0.0756, d_mnist_loss: 0.0209, d_svhn_loss: 0.0548, d_fake_loss: 0.0870, g_loss: 1.3138\n",
            "Step [10940/60000], d_real_loss: 0.1027, d_mnist_loss: 0.0127, d_svhn_loss: 0.0900, d_fake_loss: 0.0748, g_loss: 1.5528\n",
            "Step [10950/60000], d_real_loss: 0.0644, d_mnist_loss: 0.0360, d_svhn_loss: 0.0284, d_fake_loss: 0.0628, g_loss: 1.2895\n",
            "Step [10960/60000], d_real_loss: 0.1184, d_mnist_loss: 0.0238, d_svhn_loss: 0.0947, d_fake_loss: 0.0735, g_loss: 1.1049\n",
            "Step [10970/60000], d_real_loss: 0.0742, d_mnist_loss: 0.0166, d_svhn_loss: 0.0576, d_fake_loss: 0.1219, g_loss: 1.4485\n",
            "Step [10980/60000], d_real_loss: 0.2552, d_mnist_loss: 0.0152, d_svhn_loss: 0.2400, d_fake_loss: 0.2013, g_loss: 0.9640\n",
            "Step [10990/60000], d_real_loss: 0.1118, d_mnist_loss: 0.0652, d_svhn_loss: 0.0465, d_fake_loss: 0.1093, g_loss: 0.8359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.999996542930603]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [11000/60000], d_real_loss: 0.0677, d_mnist_loss: 0.0452, d_svhn_loss: 0.0225, d_fake_loss: 0.0433, g_loss: 1.1822\n",
            "saved ./samples_fashion/sample-11000-m-s.png\n",
            "saved ./samples_fashion/sample-11000-s-m.png\n",
            "Step [11010/60000], d_real_loss: 0.0492, d_mnist_loss: 0.0212, d_svhn_loss: 0.0280, d_fake_loss: 0.0676, g_loss: 1.1112\n",
            "Step [11020/60000], d_real_loss: 0.0633, d_mnist_loss: 0.0345, d_svhn_loss: 0.0288, d_fake_loss: 0.0879, g_loss: 1.3695\n",
            "Step [11030/60000], d_real_loss: 0.0548, d_mnist_loss: 0.0192, d_svhn_loss: 0.0356, d_fake_loss: 0.0592, g_loss: 1.1977\n",
            "Step [11040/60000], d_real_loss: 0.2405, d_mnist_loss: 0.0164, d_svhn_loss: 0.2241, d_fake_loss: 0.0571, g_loss: 1.1416\n",
            "Step [11050/60000], d_real_loss: 0.0613, d_mnist_loss: 0.0216, d_svhn_loss: 0.0397, d_fake_loss: 0.0889, g_loss: 1.0995\n",
            "Step [11060/60000], d_real_loss: 0.1262, d_mnist_loss: 0.0095, d_svhn_loss: 0.1166, d_fake_loss: 0.0553, g_loss: 1.1846\n",
            "Step [11070/60000], d_real_loss: 0.0853, d_mnist_loss: 0.0174, d_svhn_loss: 0.0679, d_fake_loss: 0.0459, g_loss: 1.1848\n",
            "Step [11080/60000], d_real_loss: 0.0613, d_mnist_loss: 0.0199, d_svhn_loss: 0.0415, d_fake_loss: 0.0737, g_loss: 1.3181\n",
            "Step [11090/60000], d_real_loss: 0.0851, d_mnist_loss: 0.0175, d_svhn_loss: 0.0676, d_fake_loss: 0.0418, g_loss: 1.0860\n",
            "Step [11100/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0260, d_svhn_loss: 0.0247, d_fake_loss: 0.1426, g_loss: 1.6712\n",
            "Step [11110/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0145, d_svhn_loss: 0.0291, d_fake_loss: 0.0627, g_loss: 0.8323\n",
            "Step [11120/60000], d_real_loss: 0.1465, d_mnist_loss: 0.1188, d_svhn_loss: 0.0277, d_fake_loss: 0.3219, g_loss: 1.4225\n",
            "Step [11130/60000], d_real_loss: 0.0700, d_mnist_loss: 0.0404, d_svhn_loss: 0.0296, d_fake_loss: 0.0422, g_loss: 0.9652\n",
            "Step [11140/60000], d_real_loss: 0.0772, d_mnist_loss: 0.0314, d_svhn_loss: 0.0458, d_fake_loss: 0.0557, g_loss: 1.1426\n",
            "Step [11150/60000], d_real_loss: 0.0554, d_mnist_loss: 0.0159, d_svhn_loss: 0.0395, d_fake_loss: 0.0978, g_loss: 1.3179\n",
            "Step [11160/60000], d_real_loss: 0.0505, d_mnist_loss: 0.0157, d_svhn_loss: 0.0348, d_fake_loss: 0.0720, g_loss: 0.9280\n",
            "Step [11170/60000], d_real_loss: 0.0611, d_mnist_loss: 0.0216, d_svhn_loss: 0.0395, d_fake_loss: 0.1429, g_loss: 0.8273\n",
            "Step [11180/60000], d_real_loss: 0.0488, d_mnist_loss: 0.0235, d_svhn_loss: 0.0253, d_fake_loss: 0.0362, g_loss: 1.0240\n",
            "Step [11190/60000], d_real_loss: 0.1404, d_mnist_loss: 0.0156, d_svhn_loss: 0.1248, d_fake_loss: 0.2719, g_loss: 1.2334\n",
            "Step [11200/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0156, d_svhn_loss: 0.0243, d_fake_loss: 0.0777, g_loss: 1.2191\n",
            "Step [11210/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0161, d_svhn_loss: 0.0367, d_fake_loss: 0.0409, g_loss: 1.0480\n",
            "Step [11220/60000], d_real_loss: 0.1380, d_mnist_loss: 0.0145, d_svhn_loss: 0.1235, d_fake_loss: 0.0985, g_loss: 1.1204\n",
            "Step [11230/60000], d_real_loss: 0.0641, d_mnist_loss: 0.0364, d_svhn_loss: 0.0277, d_fake_loss: 0.3313, g_loss: 1.6220\n",
            "Step [11240/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0391, d_svhn_loss: 0.0182, d_fake_loss: 0.0389, g_loss: 1.1995\n",
            "Step [11250/60000], d_real_loss: 0.0806, d_mnist_loss: 0.0210, d_svhn_loss: 0.0597, d_fake_loss: 0.0318, g_loss: 1.0211\n",
            "Step [11260/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0148, d_svhn_loss: 0.0271, d_fake_loss: 0.0432, g_loss: 1.0479\n",
            "Step [11270/60000], d_real_loss: 0.1010, d_mnist_loss: 0.0130, d_svhn_loss: 0.0881, d_fake_loss: 0.0624, g_loss: 0.9498\n",
            "Step [11280/60000], d_real_loss: 0.0509, d_mnist_loss: 0.0201, d_svhn_loss: 0.0308, d_fake_loss: 0.0637, g_loss: 1.1777\n",
            "Step [11290/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0150, d_svhn_loss: 0.0191, d_fake_loss: 0.0902, g_loss: 1.2209\n",
            "Step [11300/60000], d_real_loss: 0.0733, d_mnist_loss: 0.0095, d_svhn_loss: 0.0638, d_fake_loss: 0.0643, g_loss: 1.2563\n",
            "Step [11310/60000], d_real_loss: 0.0417, d_mnist_loss: 0.0156, d_svhn_loss: 0.0261, d_fake_loss: 0.0741, g_loss: 1.2631\n",
            "Step [11320/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0392, d_svhn_loss: 0.0259, d_fake_loss: 0.0504, g_loss: 1.0779\n",
            "Step [11330/60000], d_real_loss: 0.1338, d_mnist_loss: 0.0118, d_svhn_loss: 0.1220, d_fake_loss: 0.0775, g_loss: 1.1648\n",
            "Step [11340/60000], d_real_loss: 0.1421, d_mnist_loss: 0.1177, d_svhn_loss: 0.0244, d_fake_loss: 0.0699, g_loss: 1.4207\n",
            "Step [11350/60000], d_real_loss: 0.3251, d_mnist_loss: 0.2180, d_svhn_loss: 0.1070, d_fake_loss: 0.1958, g_loss: 1.6638\n",
            "Step [11360/60000], d_real_loss: 0.0899, d_mnist_loss: 0.0489, d_svhn_loss: 0.0409, d_fake_loss: 0.1494, g_loss: 1.1030\n",
            "Step [11370/60000], d_real_loss: 0.0613, d_mnist_loss: 0.0169, d_svhn_loss: 0.0444, d_fake_loss: 0.0552, g_loss: 1.1878\n",
            "Step [11380/60000], d_real_loss: 0.0690, d_mnist_loss: 0.0279, d_svhn_loss: 0.0411, d_fake_loss: 0.0368, g_loss: 1.2726\n",
            "Step [11390/60000], d_real_loss: 0.0371, d_mnist_loss: 0.0149, d_svhn_loss: 0.0222, d_fake_loss: 0.0601, g_loss: 1.2563\n",
            "Step [11400/60000], d_real_loss: 0.0999, d_mnist_loss: 0.0235, d_svhn_loss: 0.0764, d_fake_loss: 0.1224, g_loss: 1.0968\n",
            "Step [11410/60000], d_real_loss: 0.0638, d_mnist_loss: 0.0326, d_svhn_loss: 0.0312, d_fake_loss: 0.1138, g_loss: 1.1561\n",
            "Step [11420/60000], d_real_loss: 0.0586, d_mnist_loss: 0.0208, d_svhn_loss: 0.0377, d_fake_loss: 0.1147, g_loss: 1.2857\n",
            "Step [11430/60000], d_real_loss: 0.0636, d_mnist_loss: 0.0194, d_svhn_loss: 0.0442, d_fake_loss: 0.0655, g_loss: 1.3330\n",
            "Step [11440/60000], d_real_loss: 0.1389, d_mnist_loss: 0.0702, d_svhn_loss: 0.0687, d_fake_loss: 0.0852, g_loss: 1.3465\n",
            "Step [11450/60000], d_real_loss: 0.0384, d_mnist_loss: 0.0130, d_svhn_loss: 0.0255, d_fake_loss: 0.0374, g_loss: 1.1649\n",
            "Step [11460/60000], d_real_loss: 0.0602, d_mnist_loss: 0.0174, d_svhn_loss: 0.0427, d_fake_loss: 0.0359, g_loss: 1.1806\n",
            "Step [11470/60000], d_real_loss: 0.1866, d_mnist_loss: 0.0127, d_svhn_loss: 0.1739, d_fake_loss: 0.0698, g_loss: 1.1653\n",
            "Step [11480/60000], d_real_loss: 0.0616, d_mnist_loss: 0.0219, d_svhn_loss: 0.0397, d_fake_loss: 0.0524, g_loss: 0.8546\n",
            "Step [11490/60000], d_real_loss: 0.0634, d_mnist_loss: 0.0334, d_svhn_loss: 0.0300, d_fake_loss: 0.1199, g_loss: 1.0349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999988079071045]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [11500/60000], d_real_loss: 0.0508, d_mnist_loss: 0.0223, d_svhn_loss: 0.0286, d_fake_loss: 0.0311, g_loss: 1.0487\n",
            "saved ./samples_fashion/sample-11500-m-s.png\n",
            "saved ./samples_fashion/sample-11500-s-m.png\n",
            "Step [11510/60000], d_real_loss: 0.2205, d_mnist_loss: 0.0915, d_svhn_loss: 0.1290, d_fake_loss: 0.0455, g_loss: 1.0250\n",
            "Step [11520/60000], d_real_loss: 0.1497, d_mnist_loss: 0.1068, d_svhn_loss: 0.0428, d_fake_loss: 0.1115, g_loss: 1.5179\n",
            "Step [11530/60000], d_real_loss: 0.0666, d_mnist_loss: 0.0228, d_svhn_loss: 0.0438, d_fake_loss: 0.0645, g_loss: 1.2552\n",
            "Step [11540/60000], d_real_loss: 0.0494, d_mnist_loss: 0.0242, d_svhn_loss: 0.0253, d_fake_loss: 0.0601, g_loss: 0.9619\n",
            "Step [11550/60000], d_real_loss: 0.0526, d_mnist_loss: 0.0203, d_svhn_loss: 0.0323, d_fake_loss: 0.1840, g_loss: 1.2940\n",
            "Step [11560/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0171, d_svhn_loss: 0.0305, d_fake_loss: 0.0445, g_loss: 1.0942\n",
            "Step [11570/60000], d_real_loss: 0.0696, d_mnist_loss: 0.0302, d_svhn_loss: 0.0394, d_fake_loss: 0.0915, g_loss: 1.1617\n",
            "Step [11580/60000], d_real_loss: 0.0543, d_mnist_loss: 0.0155, d_svhn_loss: 0.0388, d_fake_loss: 0.0662, g_loss: 1.0801\n",
            "Step [11590/60000], d_real_loss: 0.1532, d_mnist_loss: 0.1101, d_svhn_loss: 0.0432, d_fake_loss: 0.0669, g_loss: 1.1105\n",
            "Step [11600/60000], d_real_loss: 0.1545, d_mnist_loss: 0.0285, d_svhn_loss: 0.1260, d_fake_loss: 0.5036, g_loss: 1.9434\n",
            "Step [11610/60000], d_real_loss: 0.0746, d_mnist_loss: 0.0306, d_svhn_loss: 0.0440, d_fake_loss: 0.1023, g_loss: 1.2088\n",
            "Step [11620/60000], d_real_loss: 0.0862, d_mnist_loss: 0.0301, d_svhn_loss: 0.0561, d_fake_loss: 0.0607, g_loss: 1.0533\n",
            "Step [11630/60000], d_real_loss: 0.0949, d_mnist_loss: 0.0212, d_svhn_loss: 0.0737, d_fake_loss: 0.2996, g_loss: 0.9606\n",
            "Step [11640/60000], d_real_loss: 0.0932, d_mnist_loss: 0.0573, d_svhn_loss: 0.0359, d_fake_loss: 0.0347, g_loss: 1.0507\n",
            "Step [11650/60000], d_real_loss: 0.0680, d_mnist_loss: 0.0192, d_svhn_loss: 0.0488, d_fake_loss: 0.0569, g_loss: 0.9717\n",
            "Step [11660/60000], d_real_loss: 0.1412, d_mnist_loss: 0.0174, d_svhn_loss: 0.1238, d_fake_loss: 0.0519, g_loss: 1.2774\n",
            "Step [11670/60000], d_real_loss: 0.0691, d_mnist_loss: 0.0223, d_svhn_loss: 0.0467, d_fake_loss: 0.0834, g_loss: 0.9129\n",
            "Step [11680/60000], d_real_loss: 0.0502, d_mnist_loss: 0.0155, d_svhn_loss: 0.0347, d_fake_loss: 0.0457, g_loss: 1.1569\n",
            "Step [11690/60000], d_real_loss: 0.0617, d_mnist_loss: 0.0095, d_svhn_loss: 0.0523, d_fake_loss: 0.0354, g_loss: 1.2092\n",
            "Step [11700/60000], d_real_loss: 0.3201, d_mnist_loss: 0.2071, d_svhn_loss: 0.1129, d_fake_loss: 0.0476, g_loss: 1.3411\n",
            "Step [11710/60000], d_real_loss: 0.0816, d_mnist_loss: 0.0269, d_svhn_loss: 0.0547, d_fake_loss: 0.0567, g_loss: 1.2364\n",
            "Step [11720/60000], d_real_loss: 0.3199, d_mnist_loss: 0.0109, d_svhn_loss: 0.3090, d_fake_loss: 0.1377, g_loss: 1.2327\n",
            "Step [11730/60000], d_real_loss: 0.0838, d_mnist_loss: 0.0236, d_svhn_loss: 0.0602, d_fake_loss: 0.0555, g_loss: 1.1820\n",
            "Step [11740/60000], d_real_loss: 0.0647, d_mnist_loss: 0.0121, d_svhn_loss: 0.0527, d_fake_loss: 0.0533, g_loss: 1.1466\n",
            "Step [11750/60000], d_real_loss: 0.0708, d_mnist_loss: 0.0146, d_svhn_loss: 0.0562, d_fake_loss: 0.1422, g_loss: 1.1608\n",
            "Step [11760/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0133, d_svhn_loss: 0.0181, d_fake_loss: 0.0503, g_loss: 1.0184\n",
            "Step [11770/60000], d_real_loss: 0.0602, d_mnist_loss: 0.0108, d_svhn_loss: 0.0493, d_fake_loss: 0.0484, g_loss: 1.2302\n",
            "Step [11780/60000], d_real_loss: 0.0804, d_mnist_loss: 0.0463, d_svhn_loss: 0.0341, d_fake_loss: 0.0284, g_loss: 1.3076\n",
            "Step [11790/60000], d_real_loss: 0.1685, d_mnist_loss: 0.1146, d_svhn_loss: 0.0539, d_fake_loss: 0.1275, g_loss: 1.7145\n",
            "Step [11800/60000], d_real_loss: 0.4363, d_mnist_loss: 0.0640, d_svhn_loss: 0.3724, d_fake_loss: 0.1634, g_loss: 0.9486\n",
            "Step [11810/60000], d_real_loss: 0.0829, d_mnist_loss: 0.0311, d_svhn_loss: 0.0518, d_fake_loss: 0.0456, g_loss: 1.3046\n",
            "Step [11820/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0142, d_svhn_loss: 0.0310, d_fake_loss: 0.0461, g_loss: 1.3383\n",
            "Step [11830/60000], d_real_loss: 0.1205, d_mnist_loss: 0.0229, d_svhn_loss: 0.0975, d_fake_loss: 0.0523, g_loss: 0.9387\n",
            "Step [11840/60000], d_real_loss: 0.0776, d_mnist_loss: 0.0588, d_svhn_loss: 0.0188, d_fake_loss: 0.0936, g_loss: 1.1155\n",
            "Step [11850/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0515, d_svhn_loss: 0.0220, d_fake_loss: 0.0534, g_loss: 1.1867\n",
            "Step [11860/60000], d_real_loss: 0.1530, d_mnist_loss: 0.0312, d_svhn_loss: 0.1218, d_fake_loss: 0.0786, g_loss: 1.2047\n",
            "Step [11870/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0102, d_svhn_loss: 0.0300, d_fake_loss: 0.0495, g_loss: 1.2499\n",
            "Step [11880/60000], d_real_loss: 0.0821, d_mnist_loss: 0.0476, d_svhn_loss: 0.0346, d_fake_loss: 0.0747, g_loss: 1.3695\n",
            "Step [11890/60000], d_real_loss: 0.0781, d_mnist_loss: 0.0138, d_svhn_loss: 0.0642, d_fake_loss: 0.0410, g_loss: 1.0945\n",
            "Step [11900/60000], d_real_loss: 0.0840, d_mnist_loss: 0.0542, d_svhn_loss: 0.0298, d_fake_loss: 0.1049, g_loss: 1.1877\n",
            "Step [11910/60000], d_real_loss: 0.0487, d_mnist_loss: 0.0158, d_svhn_loss: 0.0329, d_fake_loss: 0.0466, g_loss: 0.9337\n",
            "Step [11920/60000], d_real_loss: 0.0877, d_mnist_loss: 0.0132, d_svhn_loss: 0.0745, d_fake_loss: 0.0487, g_loss: 1.1714\n",
            "Step [11930/60000], d_real_loss: 0.0846, d_mnist_loss: 0.0546, d_svhn_loss: 0.0300, d_fake_loss: 0.0492, g_loss: 1.1910\n",
            "Step [11940/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0116, d_svhn_loss: 0.0232, d_fake_loss: 0.0556, g_loss: 0.9512\n",
            "Step [11950/60000], d_real_loss: 0.2227, d_mnist_loss: 0.0181, d_svhn_loss: 0.2046, d_fake_loss: 0.3108, g_loss: 1.2416\n",
            "Step [11960/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0123, d_svhn_loss: 0.0297, d_fake_loss: 0.1072, g_loss: 1.3886\n",
            "Step [11970/60000], d_real_loss: 0.0770, d_mnist_loss: 0.0282, d_svhn_loss: 0.0488, d_fake_loss: 0.0645, g_loss: 1.0438\n",
            "Step [11980/60000], d_real_loss: 0.0818, d_mnist_loss: 0.0208, d_svhn_loss: 0.0610, d_fake_loss: 0.0280, g_loss: 1.0971\n",
            "Step [11990/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0188, d_svhn_loss: 0.0240, d_fake_loss: 0.0615, g_loss: 1.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999862313270569]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [12000/60000], d_real_loss: 0.0539, d_mnist_loss: 0.0185, d_svhn_loss: 0.0354, d_fake_loss: 0.1241, g_loss: 1.1218\n",
            "saved ./samples_fashion/sample-12000-m-s.png\n",
            "saved ./samples_fashion/sample-12000-s-m.png\n",
            "Step [12010/60000], d_real_loss: 0.0628, d_mnist_loss: 0.0316, d_svhn_loss: 0.0312, d_fake_loss: 0.0439, g_loss: 1.3277\n",
            "Step [12020/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0142, d_svhn_loss: 0.0255, d_fake_loss: 0.0867, g_loss: 0.9781\n",
            "Step [12030/60000], d_real_loss: 0.1852, d_mnist_loss: 0.0161, d_svhn_loss: 0.1691, d_fake_loss: 0.0490, g_loss: 1.0383\n",
            "Step [12040/60000], d_real_loss: 0.2360, d_mnist_loss: 0.0426, d_svhn_loss: 0.1933, d_fake_loss: 0.2656, g_loss: 1.3778\n",
            "Step [12050/60000], d_real_loss: 0.0837, d_mnist_loss: 0.0149, d_svhn_loss: 0.0688, d_fake_loss: 0.0454, g_loss: 1.1317\n",
            "Step [12060/60000], d_real_loss: 0.0621, d_mnist_loss: 0.0142, d_svhn_loss: 0.0480, d_fake_loss: 0.0511, g_loss: 1.1065\n",
            "Step [12070/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0109, d_svhn_loss: 0.0266, d_fake_loss: 0.0632, g_loss: 1.2625\n",
            "Step [12080/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0223, d_svhn_loss: 0.0306, d_fake_loss: 0.0317, g_loss: 1.0943\n",
            "Step [12090/60000], d_real_loss: 0.1399, d_mnist_loss: 0.1157, d_svhn_loss: 0.0241, d_fake_loss: 0.0660, g_loss: 1.0951\n",
            "Step [12100/60000], d_real_loss: 0.3506, d_mnist_loss: 0.2530, d_svhn_loss: 0.0976, d_fake_loss: 0.1103, g_loss: 1.0939\n",
            "Step [12110/60000], d_real_loss: 0.0851, d_mnist_loss: 0.0464, d_svhn_loss: 0.0387, d_fake_loss: 0.0879, g_loss: 1.2457\n",
            "Step [12120/60000], d_real_loss: 0.0945, d_mnist_loss: 0.0307, d_svhn_loss: 0.0638, d_fake_loss: 0.0460, g_loss: 1.2396\n",
            "Step [12130/60000], d_real_loss: 0.0912, d_mnist_loss: 0.0190, d_svhn_loss: 0.0721, d_fake_loss: 0.0391, g_loss: 1.1181\n",
            "Step [12140/60000], d_real_loss: 0.0830, d_mnist_loss: 0.0155, d_svhn_loss: 0.0675, d_fake_loss: 0.1165, g_loss: 1.1487\n",
            "Step [12150/60000], d_real_loss: 0.1371, d_mnist_loss: 0.0138, d_svhn_loss: 0.1233, d_fake_loss: 0.0961, g_loss: 1.1617\n",
            "Step [12160/60000], d_real_loss: 0.1131, d_mnist_loss: 0.0416, d_svhn_loss: 0.0715, d_fake_loss: 0.0581, g_loss: 1.4646\n",
            "Step [12170/60000], d_real_loss: 0.0935, d_mnist_loss: 0.0368, d_svhn_loss: 0.0567, d_fake_loss: 0.0537, g_loss: 1.3165\n",
            "Step [12180/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0393, d_svhn_loss: 0.0343, d_fake_loss: 0.1210, g_loss: 0.9057\n",
            "Step [12190/60000], d_real_loss: 0.0890, d_mnist_loss: 0.0135, d_svhn_loss: 0.0755, d_fake_loss: 0.0359, g_loss: 1.1902\n",
            "Step [12200/60000], d_real_loss: 0.0847, d_mnist_loss: 0.0490, d_svhn_loss: 0.0358, d_fake_loss: 0.0973, g_loss: 1.2794\n",
            "Step [12210/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0159, d_svhn_loss: 0.0492, d_fake_loss: 0.1211, g_loss: 1.2343\n",
            "Step [12220/60000], d_real_loss: 0.3715, d_mnist_loss: 0.2721, d_svhn_loss: 0.0993, d_fake_loss: 0.1639, g_loss: 1.1385\n",
            "Step [12230/60000], d_real_loss: 0.3300, d_mnist_loss: 0.0273, d_svhn_loss: 0.3028, d_fake_loss: 0.0634, g_loss: 1.1490\n",
            "Step [12240/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0119, d_svhn_loss: 0.0260, d_fake_loss: 0.0435, g_loss: 1.0586\n",
            "Step [12250/60000], d_real_loss: 0.1198, d_mnist_loss: 0.0509, d_svhn_loss: 0.0689, d_fake_loss: 0.1732, g_loss: 1.0952\n",
            "Step [12260/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0129, d_svhn_loss: 0.0250, d_fake_loss: 0.0538, g_loss: 1.3220\n",
            "Step [12270/60000], d_real_loss: 0.0441, d_mnist_loss: 0.0142, d_svhn_loss: 0.0299, d_fake_loss: 0.0841, g_loss: 0.9378\n",
            "Step [12280/60000], d_real_loss: 0.0610, d_mnist_loss: 0.0318, d_svhn_loss: 0.0292, d_fake_loss: 0.0808, g_loss: 1.0621\n",
            "Step [12290/60000], d_real_loss: 0.4552, d_mnist_loss: 0.0247, d_svhn_loss: 0.4305, d_fake_loss: 0.0690, g_loss: 0.9930\n",
            "Step [12300/60000], d_real_loss: 0.0670, d_mnist_loss: 0.0150, d_svhn_loss: 0.0520, d_fake_loss: 0.0412, g_loss: 1.1893\n",
            "Step [12310/60000], d_real_loss: 0.1265, d_mnist_loss: 0.0097, d_svhn_loss: 0.1168, d_fake_loss: 0.0952, g_loss: 1.1841\n",
            "Step [12320/60000], d_real_loss: 0.0661, d_mnist_loss: 0.0295, d_svhn_loss: 0.0367, d_fake_loss: 0.0510, g_loss: 1.4302\n",
            "Step [12330/60000], d_real_loss: 0.0605, d_mnist_loss: 0.0263, d_svhn_loss: 0.0342, d_fake_loss: 0.0803, g_loss: 0.9074\n",
            "Step [12340/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0249, d_svhn_loss: 0.0323, d_fake_loss: 0.0564, g_loss: 1.2315\n",
            "Step [12350/60000], d_real_loss: 0.0465, d_mnist_loss: 0.0171, d_svhn_loss: 0.0294, d_fake_loss: 0.0903, g_loss: 1.1754\n",
            "Step [12360/60000], d_real_loss: 0.0447, d_mnist_loss: 0.0163, d_svhn_loss: 0.0284, d_fake_loss: 0.0331, g_loss: 1.1827\n",
            "Step [12370/60000], d_real_loss: 0.6326, d_mnist_loss: 0.6065, d_svhn_loss: 0.0261, d_fake_loss: 0.4353, g_loss: 1.7519\n",
            "Step [12380/60000], d_real_loss: 0.1526, d_mnist_loss: 0.0240, d_svhn_loss: 0.1286, d_fake_loss: 0.1319, g_loss: 1.2429\n",
            "Step [12390/60000], d_real_loss: 0.0653, d_mnist_loss: 0.0266, d_svhn_loss: 0.0387, d_fake_loss: 0.1921, g_loss: 1.5997\n",
            "Step [12400/60000], d_real_loss: 0.0764, d_mnist_loss: 0.0176, d_svhn_loss: 0.0588, d_fake_loss: 0.1177, g_loss: 1.3174\n",
            "Step [12410/60000], d_real_loss: 0.1265, d_mnist_loss: 0.0441, d_svhn_loss: 0.0824, d_fake_loss: 0.2168, g_loss: 1.5169\n",
            "Step [12420/60000], d_real_loss: 0.1180, d_mnist_loss: 0.0364, d_svhn_loss: 0.0816, d_fake_loss: 0.0907, g_loss: 1.2982\n",
            "Step [12430/60000], d_real_loss: 0.0576, d_mnist_loss: 0.0128, d_svhn_loss: 0.0448, d_fake_loss: 0.0325, g_loss: 1.3013\n",
            "Step [12440/60000], d_real_loss: 0.0635, d_mnist_loss: 0.0102, d_svhn_loss: 0.0533, d_fake_loss: 0.0684, g_loss: 1.2329\n",
            "Step [12450/60000], d_real_loss: 0.0543, d_mnist_loss: 0.0259, d_svhn_loss: 0.0284, d_fake_loss: 0.1030, g_loss: 1.1446\n",
            "Step [12460/60000], d_real_loss: 0.1107, d_mnist_loss: 0.0547, d_svhn_loss: 0.0560, d_fake_loss: 0.1012, g_loss: 1.0412\n",
            "Step [12470/60000], d_real_loss: 0.0656, d_mnist_loss: 0.0104, d_svhn_loss: 0.0552, d_fake_loss: 0.0689, g_loss: 1.4704\n",
            "Step [12480/60000], d_real_loss: 0.1318, d_mnist_loss: 0.0155, d_svhn_loss: 0.1163, d_fake_loss: 0.0859, g_loss: 1.3415\n",
            "Step [12490/60000], d_real_loss: 0.1143, d_mnist_loss: 0.0819, d_svhn_loss: 0.0324, d_fake_loss: 0.0377, g_loss: 1.1192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999924898147583]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [12500/60000], d_real_loss: 0.0837, d_mnist_loss: 0.0170, d_svhn_loss: 0.0668, d_fake_loss: 0.1203, g_loss: 0.8959\n",
            "saved ./samples_fashion/sample-12500-m-s.png\n",
            "saved ./samples_fashion/sample-12500-s-m.png\n",
            "Step [12510/60000], d_real_loss: 0.0536, d_mnist_loss: 0.0139, d_svhn_loss: 0.0396, d_fake_loss: 0.1466, g_loss: 1.1017\n",
            "Step [12520/60000], d_real_loss: 0.0919, d_mnist_loss: 0.0119, d_svhn_loss: 0.0800, d_fake_loss: 0.0596, g_loss: 1.0493\n",
            "Step [12530/60000], d_real_loss: 0.1008, d_mnist_loss: 0.0771, d_svhn_loss: 0.0237, d_fake_loss: 0.0632, g_loss: 0.9428\n",
            "Step [12540/60000], d_real_loss: 0.1568, d_mnist_loss: 0.0714, d_svhn_loss: 0.0854, d_fake_loss: 0.0556, g_loss: 1.3430\n",
            "Step [12550/60000], d_real_loss: 0.0602, d_mnist_loss: 0.0202, d_svhn_loss: 0.0399, d_fake_loss: 0.0549, g_loss: 1.0187\n",
            "Step [12560/60000], d_real_loss: 0.1031, d_mnist_loss: 0.0208, d_svhn_loss: 0.0823, d_fake_loss: 0.1245, g_loss: 0.6924\n",
            "Step [12570/60000], d_real_loss: 0.1935, d_mnist_loss: 0.0127, d_svhn_loss: 0.1807, d_fake_loss: 0.0508, g_loss: 1.0957\n",
            "Step [12580/60000], d_real_loss: 0.0675, d_mnist_loss: 0.0269, d_svhn_loss: 0.0406, d_fake_loss: 0.0993, g_loss: 0.9258\n",
            "Step [12590/60000], d_real_loss: 0.1206, d_mnist_loss: 0.0891, d_svhn_loss: 0.0315, d_fake_loss: 0.0329, g_loss: 1.0066\n",
            "Step [12600/60000], d_real_loss: 0.0778, d_mnist_loss: 0.0250, d_svhn_loss: 0.0528, d_fake_loss: 0.0818, g_loss: 1.1622\n",
            "Step [12610/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0097, d_svhn_loss: 0.0271, d_fake_loss: 0.0441, g_loss: 1.2701\n",
            "Step [12620/60000], d_real_loss: 0.0593, d_mnist_loss: 0.0411, d_svhn_loss: 0.0182, d_fake_loss: 0.0353, g_loss: 1.3260\n",
            "Step [12630/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0146, d_svhn_loss: 0.0297, d_fake_loss: 0.0671, g_loss: 0.9543\n",
            "Step [12640/60000], d_real_loss: 0.0721, d_mnist_loss: 0.0253, d_svhn_loss: 0.0468, d_fake_loss: 0.0750, g_loss: 0.8792\n",
            "Step [12650/60000], d_real_loss: 0.0878, d_mnist_loss: 0.0159, d_svhn_loss: 0.0720, d_fake_loss: 0.0558, g_loss: 0.9803\n",
            "Step [12660/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0116, d_svhn_loss: 0.0401, d_fake_loss: 0.1224, g_loss: 1.5891\n",
            "Step [12670/60000], d_real_loss: 0.0707, d_mnist_loss: 0.0471, d_svhn_loss: 0.0236, d_fake_loss: 0.0822, g_loss: 1.0374\n",
            "Step [12680/60000], d_real_loss: 0.0941, d_mnist_loss: 0.0181, d_svhn_loss: 0.0761, d_fake_loss: 0.0559, g_loss: 1.1894\n",
            "Step [12690/60000], d_real_loss: 0.2172, d_mnist_loss: 0.0210, d_svhn_loss: 0.1962, d_fake_loss: 0.0516, g_loss: 1.0105\n",
            "Step [12700/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0095, d_svhn_loss: 0.0257, d_fake_loss: 0.0353, g_loss: 1.3201\n",
            "Step [12710/60000], d_real_loss: 0.2305, d_mnist_loss: 0.0432, d_svhn_loss: 0.1873, d_fake_loss: 0.1135, g_loss: 1.1641\n",
            "Step [12720/60000], d_real_loss: 0.0506, d_mnist_loss: 0.0314, d_svhn_loss: 0.0193, d_fake_loss: 0.0583, g_loss: 1.0442\n",
            "Step [12730/60000], d_real_loss: 0.0893, d_mnist_loss: 0.0515, d_svhn_loss: 0.0378, d_fake_loss: 0.1308, g_loss: 1.3537\n",
            "Step [12740/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0167, d_svhn_loss: 0.0247, d_fake_loss: 0.0322, g_loss: 1.0681\n",
            "Step [12750/60000], d_real_loss: 0.0687, d_mnist_loss: 0.0102, d_svhn_loss: 0.0585, d_fake_loss: 0.0944, g_loss: 0.7851\n",
            "Step [12760/60000], d_real_loss: 0.0577, d_mnist_loss: 0.0273, d_svhn_loss: 0.0304, d_fake_loss: 0.0612, g_loss: 1.0394\n",
            "Step [12770/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0135, d_svhn_loss: 0.0452, d_fake_loss: 0.1021, g_loss: 1.4061\n",
            "Step [12780/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0317, d_svhn_loss: 0.0266, d_fake_loss: 0.0680, g_loss: 1.3123\n",
            "Step [12790/60000], d_real_loss: 0.1085, d_mnist_loss: 0.0630, d_svhn_loss: 0.0455, d_fake_loss: 0.1981, g_loss: 1.0911\n",
            "Step [12800/60000], d_real_loss: 0.1606, d_mnist_loss: 0.0331, d_svhn_loss: 0.1276, d_fake_loss: 0.0528, g_loss: 1.0381\n",
            "Step [12810/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0135, d_svhn_loss: 0.0296, d_fake_loss: 0.0417, g_loss: 1.0900\n",
            "Step [12820/60000], d_real_loss: 0.0787, d_mnist_loss: 0.0169, d_svhn_loss: 0.0619, d_fake_loss: 0.0525, g_loss: 1.0018\n",
            "Step [12830/60000], d_real_loss: 0.0638, d_mnist_loss: 0.0356, d_svhn_loss: 0.0283, d_fake_loss: 0.0291, g_loss: 1.1214\n",
            "Step [12840/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0396, d_svhn_loss: 0.0276, d_fake_loss: 0.0972, g_loss: 1.3901\n",
            "Step [12850/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0176, d_svhn_loss: 0.0363, d_fake_loss: 0.0627, g_loss: 1.4346\n",
            "Step [12860/60000], d_real_loss: 0.0880, d_mnist_loss: 0.0093, d_svhn_loss: 0.0787, d_fake_loss: 0.0435, g_loss: 1.0170\n",
            "Step [12870/60000], d_real_loss: 0.0677, d_mnist_loss: 0.0296, d_svhn_loss: 0.0381, d_fake_loss: 0.2364, g_loss: 1.1682\n",
            "Step [12880/60000], d_real_loss: 0.0865, d_mnist_loss: 0.0104, d_svhn_loss: 0.0761, d_fake_loss: 0.2751, g_loss: 1.1918\n",
            "Step [12890/60000], d_real_loss: 0.1225, d_mnist_loss: 0.0228, d_svhn_loss: 0.0997, d_fake_loss: 0.1810, g_loss: 1.1415\n",
            "Step [12900/60000], d_real_loss: 0.0879, d_mnist_loss: 0.0176, d_svhn_loss: 0.0704, d_fake_loss: 0.1590, g_loss: 1.2247\n",
            "Step [12910/60000], d_real_loss: 0.0681, d_mnist_loss: 0.0313, d_svhn_loss: 0.0368, d_fake_loss: 0.0455, g_loss: 1.1831\n",
            "Step [12920/60000], d_real_loss: 0.0610, d_mnist_loss: 0.0145, d_svhn_loss: 0.0465, d_fake_loss: 0.0545, g_loss: 1.3579\n",
            "Step [12930/60000], d_real_loss: 0.0447, d_mnist_loss: 0.0144, d_svhn_loss: 0.0303, d_fake_loss: 0.0717, g_loss: 1.4359\n",
            "Step [12940/60000], d_real_loss: 0.0815, d_mnist_loss: 0.0161, d_svhn_loss: 0.0654, d_fake_loss: 0.1402, g_loss: 0.8943\n",
            "Step [12950/60000], d_real_loss: 0.1200, d_mnist_loss: 0.0512, d_svhn_loss: 0.0687, d_fake_loss: 0.0953, g_loss: 1.3231\n",
            "Step [12960/60000], d_real_loss: 0.0768, d_mnist_loss: 0.0441, d_svhn_loss: 0.0327, d_fake_loss: 0.1167, g_loss: 1.2345\n",
            "Step [12970/60000], d_real_loss: 0.1569, d_mnist_loss: 0.0343, d_svhn_loss: 0.1225, d_fake_loss: 0.1405, g_loss: 1.0181\n",
            "Step [12980/60000], d_real_loss: 0.0758, d_mnist_loss: 0.0104, d_svhn_loss: 0.0654, d_fake_loss: 0.1038, g_loss: 1.0861\n",
            "Step [12990/60000], d_real_loss: 0.0854, d_mnist_loss: 0.0264, d_svhn_loss: 0.0590, d_fake_loss: 0.0371, g_loss: 1.0592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.999965488910675]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [13000/60000], d_real_loss: 0.0723, d_mnist_loss: 0.0410, d_svhn_loss: 0.0313, d_fake_loss: 0.2729, g_loss: 1.3251\n",
            "saved ./samples_fashion/sample-13000-m-s.png\n",
            "saved ./samples_fashion/sample-13000-s-m.png\n",
            "Step [13010/60000], d_real_loss: 0.0926, d_mnist_loss: 0.0144, d_svhn_loss: 0.0781, d_fake_loss: 0.0525, g_loss: 1.1255\n",
            "Step [13020/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0241, d_svhn_loss: 0.0351, d_fake_loss: 0.0843, g_loss: 1.0068\n",
            "Step [13030/60000], d_real_loss: 0.0785, d_mnist_loss: 0.0183, d_svhn_loss: 0.0601, d_fake_loss: 0.0780, g_loss: 1.0062\n",
            "Step [13040/60000], d_real_loss: 0.0858, d_mnist_loss: 0.0129, d_svhn_loss: 0.0729, d_fake_loss: 0.0424, g_loss: 1.1204\n",
            "Step [13050/60000], d_real_loss: 0.1572, d_mnist_loss: 0.0258, d_svhn_loss: 0.1314, d_fake_loss: 0.0528, g_loss: 1.2405\n",
            "Step [13060/60000], d_real_loss: 0.1860, d_mnist_loss: 0.1105, d_svhn_loss: 0.0756, d_fake_loss: 0.0714, g_loss: 1.1524\n",
            "Step [13070/60000], d_real_loss: 0.0853, d_mnist_loss: 0.0396, d_svhn_loss: 0.0457, d_fake_loss: 0.1314, g_loss: 1.2359\n",
            "Step [13080/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0100, d_svhn_loss: 0.0251, d_fake_loss: 0.1007, g_loss: 1.2459\n",
            "Step [13090/60000], d_real_loss: 0.1690, d_mnist_loss: 0.0137, d_svhn_loss: 0.1553, d_fake_loss: 0.0719, g_loss: 1.0515\n",
            "Step [13100/60000], d_real_loss: 0.0621, d_mnist_loss: 0.0201, d_svhn_loss: 0.0420, d_fake_loss: 0.0366, g_loss: 1.0190\n",
            "Step [13110/60000], d_real_loss: 0.0545, d_mnist_loss: 0.0165, d_svhn_loss: 0.0380, d_fake_loss: 0.0632, g_loss: 0.9824\n",
            "Step [13120/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0156, d_svhn_loss: 0.0193, d_fake_loss: 0.0284, g_loss: 1.0698\n",
            "Step [13130/60000], d_real_loss: 0.0522, d_mnist_loss: 0.0124, d_svhn_loss: 0.0398, d_fake_loss: 0.0364, g_loss: 1.0475\n",
            "Step [13140/60000], d_real_loss: 0.0845, d_mnist_loss: 0.0162, d_svhn_loss: 0.0682, d_fake_loss: 0.0347, g_loss: 1.0624\n",
            "Step [13150/60000], d_real_loss: 0.2762, d_mnist_loss: 0.0171, d_svhn_loss: 0.2591, d_fake_loss: 0.1109, g_loss: 1.2470\n",
            "Step [13160/60000], d_real_loss: 0.1190, d_mnist_loss: 0.0421, d_svhn_loss: 0.0769, d_fake_loss: 0.0502, g_loss: 1.0675\n",
            "Step [13170/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0339, d_svhn_loss: 0.0244, d_fake_loss: 0.1816, g_loss: 1.3237\n",
            "Step [13180/60000], d_real_loss: 0.0581, d_mnist_loss: 0.0204, d_svhn_loss: 0.0377, d_fake_loss: 0.1015, g_loss: 0.7803\n",
            "Step [13190/60000], d_real_loss: 0.1229, d_mnist_loss: 0.0892, d_svhn_loss: 0.0337, d_fake_loss: 0.1529, g_loss: 1.5283\n",
            "Step [13200/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0177, d_svhn_loss: 0.0338, d_fake_loss: 0.0559, g_loss: 0.9894\n",
            "Step [13210/60000], d_real_loss: 0.1155, d_mnist_loss: 0.0440, d_svhn_loss: 0.0715, d_fake_loss: 0.1075, g_loss: 1.1924\n",
            "Step [13220/60000], d_real_loss: 0.0810, d_mnist_loss: 0.0434, d_svhn_loss: 0.0377, d_fake_loss: 0.1462, g_loss: 1.2295\n",
            "Step [13230/60000], d_real_loss: 0.0615, d_mnist_loss: 0.0370, d_svhn_loss: 0.0245, d_fake_loss: 0.1017, g_loss: 1.1505\n",
            "Step [13240/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0153, d_svhn_loss: 0.0320, d_fake_loss: 0.0719, g_loss: 1.0381\n",
            "Step [13250/60000], d_real_loss: 0.0809, d_mnist_loss: 0.0324, d_svhn_loss: 0.0484, d_fake_loss: 0.0656, g_loss: 1.1667\n",
            "Step [13260/60000], d_real_loss: 0.0682, d_mnist_loss: 0.0410, d_svhn_loss: 0.0271, d_fake_loss: 0.0473, g_loss: 1.0380\n",
            "Step [13270/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0124, d_svhn_loss: 0.0611, d_fake_loss: 0.0467, g_loss: 1.0138\n",
            "Step [13280/60000], d_real_loss: 0.1218, d_mnist_loss: 0.0152, d_svhn_loss: 0.1067, d_fake_loss: 0.0338, g_loss: 1.0863\n",
            "Step [13290/60000], d_real_loss: 0.0446, d_mnist_loss: 0.0190, d_svhn_loss: 0.0256, d_fake_loss: 0.0359, g_loss: 1.1017\n",
            "Step [13300/60000], d_real_loss: 0.0725, d_mnist_loss: 0.0115, d_svhn_loss: 0.0610, d_fake_loss: 0.0336, g_loss: 1.0440\n",
            "Step [13310/60000], d_real_loss: 0.0752, d_mnist_loss: 0.0326, d_svhn_loss: 0.0425, d_fake_loss: 0.0856, g_loss: 1.1080\n",
            "Step [13320/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0163, d_svhn_loss: 0.0212, d_fake_loss: 0.0432, g_loss: 1.1556\n",
            "Step [13330/60000], d_real_loss: 0.0693, d_mnist_loss: 0.0363, d_svhn_loss: 0.0330, d_fake_loss: 0.0426, g_loss: 1.1554\n",
            "Step [13340/60000], d_real_loss: 0.0441, d_mnist_loss: 0.0119, d_svhn_loss: 0.0322, d_fake_loss: 0.0441, g_loss: 1.1068\n",
            "Step [13350/60000], d_real_loss: 0.0801, d_mnist_loss: 0.0550, d_svhn_loss: 0.0250, d_fake_loss: 0.0397, g_loss: 0.8897\n",
            "Step [13360/60000], d_real_loss: 0.1277, d_mnist_loss: 0.0139, d_svhn_loss: 0.1138, d_fake_loss: 0.0421, g_loss: 1.1669\n",
            "Step [13370/60000], d_real_loss: 0.0922, d_mnist_loss: 0.0293, d_svhn_loss: 0.0629, d_fake_loss: 0.2098, g_loss: 1.1134\n",
            "Step [13380/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0109, d_svhn_loss: 0.0260, d_fake_loss: 0.0770, g_loss: 1.1450\n",
            "Step [13390/60000], d_real_loss: 0.1185, d_mnist_loss: 0.0198, d_svhn_loss: 0.0987, d_fake_loss: 0.0790, g_loss: 0.7192\n",
            "Step [13400/60000], d_real_loss: 0.1930, d_mnist_loss: 0.0480, d_svhn_loss: 0.1450, d_fake_loss: 0.0827, g_loss: 1.2974\n",
            "Step [13410/60000], d_real_loss: 0.0706, d_mnist_loss: 0.0459, d_svhn_loss: 0.0247, d_fake_loss: 0.0715, g_loss: 1.3813\n",
            "Step [13420/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0113, d_svhn_loss: 0.0369, d_fake_loss: 0.0431, g_loss: 1.4183\n",
            "Step [13430/60000], d_real_loss: 0.0662, d_mnist_loss: 0.0143, d_svhn_loss: 0.0519, d_fake_loss: 0.0447, g_loss: 1.3131\n",
            "Step [13440/60000], d_real_loss: 0.0995, d_mnist_loss: 0.0135, d_svhn_loss: 0.0861, d_fake_loss: 0.0582, g_loss: 1.0517\n",
            "Step [13450/60000], d_real_loss: 0.2349, d_mnist_loss: 0.1964, d_svhn_loss: 0.0386, d_fake_loss: 0.1121, g_loss: 1.9592\n",
            "Step [13460/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0161, d_svhn_loss: 0.0202, d_fake_loss: 0.0831, g_loss: 1.1212\n",
            "Step [13470/60000], d_real_loss: 0.1029, d_mnist_loss: 0.0173, d_svhn_loss: 0.0856, d_fake_loss: 0.0488, g_loss: 1.2194\n",
            "Step [13480/60000], d_real_loss: 0.1009, d_mnist_loss: 0.0316, d_svhn_loss: 0.0693, d_fake_loss: 0.1455, g_loss: 1.3098\n",
            "Step [13490/60000], d_real_loss: 0.3690, d_mnist_loss: 0.3321, d_svhn_loss: 0.0369, d_fake_loss: 0.1231, g_loss: 1.3724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.999984622001648]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998807907104, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [13500/60000], d_real_loss: 0.0886, d_mnist_loss: 0.0121, d_svhn_loss: 0.0764, d_fake_loss: 0.0512, g_loss: 1.0627\n",
            "saved ./samples_fashion/sample-13500-m-s.png\n",
            "saved ./samples_fashion/sample-13500-s-m.png\n",
            "Step [13510/60000], d_real_loss: 0.0978, d_mnist_loss: 0.0741, d_svhn_loss: 0.0236, d_fake_loss: 0.1138, g_loss: 1.1214\n",
            "Step [13520/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0310, d_svhn_loss: 0.0355, d_fake_loss: 0.0907, g_loss: 1.1907\n",
            "Step [13530/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0142, d_svhn_loss: 0.0394, d_fake_loss: 0.0305, g_loss: 1.2217\n",
            "Step [13540/60000], d_real_loss: 0.0595, d_mnist_loss: 0.0180, d_svhn_loss: 0.0415, d_fake_loss: 0.1023, g_loss: 1.3909\n",
            "Step [13550/60000], d_real_loss: 0.1178, d_mnist_loss: 0.0614, d_svhn_loss: 0.0564, d_fake_loss: 0.1524, g_loss: 0.8141\n",
            "Step [13560/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0133, d_svhn_loss: 0.0288, d_fake_loss: 0.0713, g_loss: 1.3489\n",
            "Step [13570/60000], d_real_loss: 0.0453, d_mnist_loss: 0.0176, d_svhn_loss: 0.0276, d_fake_loss: 0.0354, g_loss: 1.0839\n",
            "Step [13580/60000], d_real_loss: 0.0496, d_mnist_loss: 0.0117, d_svhn_loss: 0.0379, d_fake_loss: 0.0638, g_loss: 1.0456\n",
            "Step [13590/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0147, d_svhn_loss: 0.0242, d_fake_loss: 0.1093, g_loss: 0.9553\n",
            "Step [13600/60000], d_real_loss: 0.1035, d_mnist_loss: 0.0489, d_svhn_loss: 0.0545, d_fake_loss: 0.1224, g_loss: 1.1614\n",
            "Step [13610/60000], d_real_loss: 0.0503, d_mnist_loss: 0.0121, d_svhn_loss: 0.0382, d_fake_loss: 0.0730, g_loss: 1.1806\n",
            "Step [13620/60000], d_real_loss: 0.0660, d_mnist_loss: 0.0154, d_svhn_loss: 0.0506, d_fake_loss: 0.2314, g_loss: 1.2443\n",
            "Step [13630/60000], d_real_loss: 0.0454, d_mnist_loss: 0.0104, d_svhn_loss: 0.0350, d_fake_loss: 0.0275, g_loss: 1.1011\n",
            "Step [13640/60000], d_real_loss: 0.0509, d_mnist_loss: 0.0228, d_svhn_loss: 0.0281, d_fake_loss: 0.1339, g_loss: 1.3864\n",
            "Step [13650/60000], d_real_loss: 0.1856, d_mnist_loss: 0.1455, d_svhn_loss: 0.0400, d_fake_loss: 0.1141, g_loss: 1.2049\n",
            "Step [13660/60000], d_real_loss: 0.0553, d_mnist_loss: 0.0143, d_svhn_loss: 0.0410, d_fake_loss: 0.0278, g_loss: 1.1640\n",
            "Step [13670/60000], d_real_loss: 0.1462, d_mnist_loss: 0.0415, d_svhn_loss: 0.1047, d_fake_loss: 0.0632, g_loss: 1.2393\n",
            "Step [13680/60000], d_real_loss: 0.0707, d_mnist_loss: 0.0420, d_svhn_loss: 0.0287, d_fake_loss: 0.0375, g_loss: 1.1072\n",
            "Step [13690/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0257, d_svhn_loss: 0.0214, d_fake_loss: 0.0721, g_loss: 1.4495\n",
            "Step [13700/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0301, d_svhn_loss: 0.0272, d_fake_loss: 0.0994, g_loss: 1.0751\n",
            "Step [13710/60000], d_real_loss: 0.0532, d_mnist_loss: 0.0218, d_svhn_loss: 0.0314, d_fake_loss: 0.0379, g_loss: 1.1018\n",
            "Step [13720/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0303, d_svhn_loss: 0.0349, d_fake_loss: 0.0538, g_loss: 1.1941\n",
            "Step [13730/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0208, d_svhn_loss: 0.0262, d_fake_loss: 0.0704, g_loss: 1.3123\n",
            "Step [13740/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0123, d_svhn_loss: 0.0275, d_fake_loss: 0.1928, g_loss: 1.0386\n",
            "Step [13750/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0157, d_svhn_loss: 0.0184, d_fake_loss: 0.0713, g_loss: 1.3551\n",
            "Step [13760/60000], d_real_loss: 0.0441, d_mnist_loss: 0.0239, d_svhn_loss: 0.0202, d_fake_loss: 0.1088, g_loss: 1.0114\n",
            "Step [13770/60000], d_real_loss: 0.1591, d_mnist_loss: 0.0124, d_svhn_loss: 0.1467, d_fake_loss: 0.0865, g_loss: 1.1523\n",
            "Step [13780/60000], d_real_loss: 0.0836, d_mnist_loss: 0.0180, d_svhn_loss: 0.0656, d_fake_loss: 0.0807, g_loss: 1.1037\n",
            "Step [13790/60000], d_real_loss: 1.2644, d_mnist_loss: 0.0444, d_svhn_loss: 1.2199, d_fake_loss: 0.4300, g_loss: 1.5748\n",
            "Step [13800/60000], d_real_loss: 0.0879, d_mnist_loss: 0.0430, d_svhn_loss: 0.0450, d_fake_loss: 0.0339, g_loss: 1.1690\n",
            "Step [13810/60000], d_real_loss: 0.0500, d_mnist_loss: 0.0123, d_svhn_loss: 0.0378, d_fake_loss: 0.0741, g_loss: 1.2322\n",
            "Step [13820/60000], d_real_loss: 0.0751, d_mnist_loss: 0.0146, d_svhn_loss: 0.0604, d_fake_loss: 0.0711, g_loss: 1.4815\n",
            "Step [13830/60000], d_real_loss: 0.0295, d_mnist_loss: 0.0110, d_svhn_loss: 0.0185, d_fake_loss: 0.0347, g_loss: 1.0507\n",
            "Step [13840/60000], d_real_loss: 0.0799, d_mnist_loss: 0.0458, d_svhn_loss: 0.0341, d_fake_loss: 0.0636, g_loss: 1.4001\n",
            "Step [13850/60000], d_real_loss: 0.0972, d_mnist_loss: 0.0467, d_svhn_loss: 0.0506, d_fake_loss: 0.0772, g_loss: 1.0163\n",
            "Step [13860/60000], d_real_loss: 0.1464, d_mnist_loss: 0.1069, d_svhn_loss: 0.0395, d_fake_loss: 0.1122, g_loss: 0.9404\n",
            "Step [13870/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0220, d_svhn_loss: 0.0199, d_fake_loss: 0.0712, g_loss: 1.0328\n",
            "Step [13880/60000], d_real_loss: 0.0704, d_mnist_loss: 0.0194, d_svhn_loss: 0.0510, d_fake_loss: 0.1394, g_loss: 1.0733\n",
            "Step [13890/60000], d_real_loss: 0.1862, d_mnist_loss: 0.0376, d_svhn_loss: 0.1486, d_fake_loss: 0.0881, g_loss: 1.1710\n",
            "Step [13900/60000], d_real_loss: 0.0787, d_mnist_loss: 0.0106, d_svhn_loss: 0.0681, d_fake_loss: 0.0538, g_loss: 0.9384\n",
            "Step [13910/60000], d_real_loss: 0.0426, d_mnist_loss: 0.0133, d_svhn_loss: 0.0293, d_fake_loss: 0.0767, g_loss: 1.3648\n",
            "Step [13920/60000], d_real_loss: 0.2110, d_mnist_loss: 0.0223, d_svhn_loss: 0.1887, d_fake_loss: 0.0912, g_loss: 1.1701\n",
            "Step [13930/60000], d_real_loss: 0.0417, d_mnist_loss: 0.0089, d_svhn_loss: 0.0328, d_fake_loss: 0.0369, g_loss: 1.1898\n",
            "Step [13940/60000], d_real_loss: 0.0462, d_mnist_loss: 0.0154, d_svhn_loss: 0.0307, d_fake_loss: 0.0416, g_loss: 1.2095\n",
            "Step [13950/60000], d_real_loss: 0.0444, d_mnist_loss: 0.0138, d_svhn_loss: 0.0305, d_fake_loss: 0.0423, g_loss: 0.9899\n",
            "Step [13960/60000], d_real_loss: 0.0734, d_mnist_loss: 0.0231, d_svhn_loss: 0.0503, d_fake_loss: 0.1092, g_loss: 1.3255\n",
            "Step [13970/60000], d_real_loss: 0.0489, d_mnist_loss: 0.0117, d_svhn_loss: 0.0371, d_fake_loss: 0.0414, g_loss: 1.1504\n",
            "Step [13980/60000], d_real_loss: 0.0945, d_mnist_loss: 0.0678, d_svhn_loss: 0.0268, d_fake_loss: 0.2099, g_loss: 1.6053\n",
            "Step [13990/60000], d_real_loss: 0.0866, d_mnist_loss: 0.0167, d_svhn_loss: 0.0699, d_fake_loss: 0.1705, g_loss: 1.4717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9999409914016724]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [14000/60000], d_real_loss: 0.0737, d_mnist_loss: 0.0380, d_svhn_loss: 0.0357, d_fake_loss: 0.0725, g_loss: 1.2005\n",
            "saved ./samples_fashion/sample-14000-m-s.png\n",
            "saved ./samples_fashion/sample-14000-s-m.png\n",
            "Step [14010/60000], d_real_loss: 0.0766, d_mnist_loss: 0.0412, d_svhn_loss: 0.0354, d_fake_loss: 0.1290, g_loss: 1.4320\n",
            "Step [14020/60000], d_real_loss: 0.0464, d_mnist_loss: 0.0187, d_svhn_loss: 0.0277, d_fake_loss: 0.0765, g_loss: 1.3489\n",
            "Step [14030/60000], d_real_loss: 0.2377, d_mnist_loss: 0.1717, d_svhn_loss: 0.0661, d_fake_loss: 0.0411, g_loss: 1.5428\n",
            "Step [14040/60000], d_real_loss: 0.2088, d_mnist_loss: 0.0263, d_svhn_loss: 0.1824, d_fake_loss: 0.0618, g_loss: 1.1322\n",
            "Step [14050/60000], d_real_loss: 0.0885, d_mnist_loss: 0.0109, d_svhn_loss: 0.0776, d_fake_loss: 0.0776, g_loss: 1.0927\n",
            "Step [14060/60000], d_real_loss: 0.1614, d_mnist_loss: 0.0151, d_svhn_loss: 0.1463, d_fake_loss: 0.0922, g_loss: 1.0588\n",
            "Step [14070/60000], d_real_loss: 0.0634, d_mnist_loss: 0.0230, d_svhn_loss: 0.0404, d_fake_loss: 0.2436, g_loss: 1.0942\n",
            "Step [14080/60000], d_real_loss: 0.1020, d_mnist_loss: 0.0058, d_svhn_loss: 0.0962, d_fake_loss: 0.0319, g_loss: 1.1271\n",
            "Step [14090/60000], d_real_loss: 0.0931, d_mnist_loss: 0.0756, d_svhn_loss: 0.0175, d_fake_loss: 0.0754, g_loss: 1.0948\n",
            "Step [14100/60000], d_real_loss: 0.0385, d_mnist_loss: 0.0128, d_svhn_loss: 0.0257, d_fake_loss: 0.0789, g_loss: 1.1642\n",
            "Step [14110/60000], d_real_loss: 0.0980, d_mnist_loss: 0.0205, d_svhn_loss: 0.0775, d_fake_loss: 0.0478, g_loss: 1.1234\n",
            "Step [14120/60000], d_real_loss: 0.0643, d_mnist_loss: 0.0266, d_svhn_loss: 0.0377, d_fake_loss: 0.0567, g_loss: 1.2297\n",
            "Step [14130/60000], d_real_loss: 0.0650, d_mnist_loss: 0.0431, d_svhn_loss: 0.0219, d_fake_loss: 0.0595, g_loss: 0.9972\n",
            "Step [14140/60000], d_real_loss: 0.0477, d_mnist_loss: 0.0199, d_svhn_loss: 0.0278, d_fake_loss: 0.1296, g_loss: 1.2046\n",
            "Step [14150/60000], d_real_loss: 0.2919, d_mnist_loss: 0.2141, d_svhn_loss: 0.0778, d_fake_loss: 0.4803, g_loss: 2.1263\n",
            "Step [14160/60000], d_real_loss: 0.0994, d_mnist_loss: 0.0192, d_svhn_loss: 0.0802, d_fake_loss: 0.1533, g_loss: 1.0291\n",
            "Step [14170/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0214, d_svhn_loss: 0.0253, d_fake_loss: 0.0490, g_loss: 1.2982\n",
            "Step [14180/60000], d_real_loss: 0.0465, d_mnist_loss: 0.0174, d_svhn_loss: 0.0291, d_fake_loss: 0.1754, g_loss: 1.0484\n",
            "Step [14190/60000], d_real_loss: 0.1020, d_mnist_loss: 0.0434, d_svhn_loss: 0.0586, d_fake_loss: 0.1709, g_loss: 0.9208\n",
            "Step [14200/60000], d_real_loss: 0.0698, d_mnist_loss: 0.0401, d_svhn_loss: 0.0297, d_fake_loss: 0.0298, g_loss: 1.2871\n",
            "Step [14210/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0109, d_svhn_loss: 0.0253, d_fake_loss: 0.2451, g_loss: 1.1779\n",
            "Step [14220/60000], d_real_loss: 0.0413, d_mnist_loss: 0.0115, d_svhn_loss: 0.0298, d_fake_loss: 0.0431, g_loss: 1.1561\n",
            "Step [14230/60000], d_real_loss: 0.1231, d_mnist_loss: 0.0089, d_svhn_loss: 0.1142, d_fake_loss: 0.0369, g_loss: 1.1900\n",
            "Step [14240/60000], d_real_loss: 0.0517, d_mnist_loss: 0.0107, d_svhn_loss: 0.0410, d_fake_loss: 0.1386, g_loss: 1.2129\n",
            "Step [14250/60000], d_real_loss: 0.0790, d_mnist_loss: 0.0123, d_svhn_loss: 0.0667, d_fake_loss: 0.0585, g_loss: 1.0933\n",
            "Step [14260/60000], d_real_loss: 0.2415, d_mnist_loss: 0.1342, d_svhn_loss: 0.1073, d_fake_loss: 0.1792, g_loss: 1.1338\n",
            "Step [14270/60000], d_real_loss: 0.4300, d_mnist_loss: 0.0124, d_svhn_loss: 0.4177, d_fake_loss: 0.4302, g_loss: 1.1318\n",
            "Step [14280/60000], d_real_loss: 0.2835, d_mnist_loss: 0.2055, d_svhn_loss: 0.0781, d_fake_loss: 0.0843, g_loss: 1.4522\n",
            "Step [14290/60000], d_real_loss: 0.0687, d_mnist_loss: 0.0152, d_svhn_loss: 0.0535, d_fake_loss: 0.0515, g_loss: 1.0624\n",
            "Step [14300/60000], d_real_loss: 0.0422, d_mnist_loss: 0.0215, d_svhn_loss: 0.0207, d_fake_loss: 0.0519, g_loss: 1.3434\n",
            "Step [14310/60000], d_real_loss: 0.0449, d_mnist_loss: 0.0235, d_svhn_loss: 0.0214, d_fake_loss: 0.1176, g_loss: 1.1065\n",
            "Step [14320/60000], d_real_loss: 0.0287, d_mnist_loss: 0.0119, d_svhn_loss: 0.0168, d_fake_loss: 0.0659, g_loss: 1.1121\n",
            "Step [14330/60000], d_real_loss: 0.1767, d_mnist_loss: 0.0144, d_svhn_loss: 0.1623, d_fake_loss: 0.0558, g_loss: 1.0008\n",
            "Step [14340/60000], d_real_loss: 0.0634, d_mnist_loss: 0.0130, d_svhn_loss: 0.0505, d_fake_loss: 0.0320, g_loss: 1.1428\n",
            "Step [14350/60000], d_real_loss: 0.0973, d_mnist_loss: 0.0181, d_svhn_loss: 0.0792, d_fake_loss: 0.0694, g_loss: 1.2114\n",
            "Step [14360/60000], d_real_loss: 0.2153, d_mnist_loss: 0.0133, d_svhn_loss: 0.2019, d_fake_loss: 0.2225, g_loss: 0.9696\n",
            "Step [14370/60000], d_real_loss: 0.0448, d_mnist_loss: 0.0136, d_svhn_loss: 0.0312, d_fake_loss: 0.1204, g_loss: 1.0820\n",
            "Step [14380/60000], d_real_loss: 0.1057, d_mnist_loss: 0.0761, d_svhn_loss: 0.0295, d_fake_loss: 0.0751, g_loss: 1.4314\n",
            "Step [14390/60000], d_real_loss: 0.0584, d_mnist_loss: 0.0232, d_svhn_loss: 0.0352, d_fake_loss: 0.0791, g_loss: 1.1492\n",
            "Step [14400/60000], d_real_loss: 0.0733, d_mnist_loss: 0.0329, d_svhn_loss: 0.0404, d_fake_loss: 0.0480, g_loss: 1.1539\n",
            "Step [14410/60000], d_real_loss: 0.0586, d_mnist_loss: 0.0150, d_svhn_loss: 0.0436, d_fake_loss: 0.0524, g_loss: 1.1644\n",
            "Step [14420/60000], d_real_loss: 0.0737, d_mnist_loss: 0.0247, d_svhn_loss: 0.0490, d_fake_loss: 0.0647, g_loss: 1.1331\n",
            "Step [14430/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0140, d_svhn_loss: 0.0265, d_fake_loss: 0.0754, g_loss: 1.2437\n",
            "Step [14440/60000], d_real_loss: 0.0465, d_mnist_loss: 0.0139, d_svhn_loss: 0.0327, d_fake_loss: 0.0360, g_loss: 1.2949\n",
            "Step [14450/60000], d_real_loss: 0.0659, d_mnist_loss: 0.0312, d_svhn_loss: 0.0347, d_fake_loss: 0.3636, g_loss: 1.2101\n",
            "Step [14460/60000], d_real_loss: 0.0985, d_mnist_loss: 0.0124, d_svhn_loss: 0.0861, d_fake_loss: 0.0823, g_loss: 1.0840\n",
            "Step [14470/60000], d_real_loss: 0.1368, d_mnist_loss: 0.0756, d_svhn_loss: 0.0613, d_fake_loss: 0.0617, g_loss: 1.0928\n",
            "Step [14480/60000], d_real_loss: 0.0576, d_mnist_loss: 0.0207, d_svhn_loss: 0.0369, d_fake_loss: 0.0698, g_loss: 1.2008\n",
            "Step [14490/60000], d_real_loss: 0.0556, d_mnist_loss: 0.0318, d_svhn_loss: 0.0238, d_fake_loss: 0.0287, g_loss: 1.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9997820258140564]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998211860657, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [14500/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0142, d_svhn_loss: 0.0294, d_fake_loss: 0.0339, g_loss: 1.0942\n",
            "saved ./samples_fashion/sample-14500-m-s.png\n",
            "saved ./samples_fashion/sample-14500-s-m.png\n",
            "Step [14510/60000], d_real_loss: 0.1095, d_mnist_loss: 0.0079, d_svhn_loss: 0.1016, d_fake_loss: 0.0484, g_loss: 0.8506\n",
            "Step [14520/60000], d_real_loss: 0.0604, d_mnist_loss: 0.0271, d_svhn_loss: 0.0332, d_fake_loss: 0.0803, g_loss: 1.2776\n",
            "Step [14530/60000], d_real_loss: 0.0816, d_mnist_loss: 0.0274, d_svhn_loss: 0.0542, d_fake_loss: 0.0829, g_loss: 1.1458\n",
            "Step [14540/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0120, d_svhn_loss: 0.0287, d_fake_loss: 0.0423, g_loss: 0.9951\n",
            "Step [14550/60000], d_real_loss: 0.0406, d_mnist_loss: 0.0142, d_svhn_loss: 0.0263, d_fake_loss: 0.0338, g_loss: 1.0437\n",
            "Step [14560/60000], d_real_loss: 0.1457, d_mnist_loss: 0.0358, d_svhn_loss: 0.1099, d_fake_loss: 0.0374, g_loss: 1.0875\n",
            "Step [14570/60000], d_real_loss: 0.0860, d_mnist_loss: 0.0130, d_svhn_loss: 0.0729, d_fake_loss: 0.0442, g_loss: 1.0476\n",
            "Step [14580/60000], d_real_loss: 0.0991, d_mnist_loss: 0.0639, d_svhn_loss: 0.0352, d_fake_loss: 0.0793, g_loss: 1.0760\n",
            "Step [14590/60000], d_real_loss: 0.1179, d_mnist_loss: 0.0399, d_svhn_loss: 0.0780, d_fake_loss: 0.1080, g_loss: 1.3573\n",
            "Step [14600/60000], d_real_loss: 0.1356, d_mnist_loss: 0.0915, d_svhn_loss: 0.0441, d_fake_loss: 0.0639, g_loss: 1.2254\n",
            "Step [14610/60000], d_real_loss: 0.1183, d_mnist_loss: 0.0422, d_svhn_loss: 0.0761, d_fake_loss: 0.2369, g_loss: 1.1272\n",
            "Step [14620/60000], d_real_loss: 0.0986, d_mnist_loss: 0.0229, d_svhn_loss: 0.0757, d_fake_loss: 0.0821, g_loss: 1.0034\n",
            "Step [14630/60000], d_real_loss: 0.0742, d_mnist_loss: 0.0240, d_svhn_loss: 0.0502, d_fake_loss: 0.0648, g_loss: 0.7508\n",
            "Step [14640/60000], d_real_loss: 0.1286, d_mnist_loss: 0.0528, d_svhn_loss: 0.0758, d_fake_loss: 0.0781, g_loss: 1.1201\n",
            "Step [14650/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0238, d_svhn_loss: 0.0327, d_fake_loss: 0.0835, g_loss: 1.0648\n",
            "Step [14660/60000], d_real_loss: 0.0384, d_mnist_loss: 0.0130, d_svhn_loss: 0.0255, d_fake_loss: 0.0458, g_loss: 1.1569\n",
            "Step [14670/60000], d_real_loss: 0.0554, d_mnist_loss: 0.0163, d_svhn_loss: 0.0391, d_fake_loss: 0.0481, g_loss: 0.9913\n",
            "Step [14680/60000], d_real_loss: 0.0459, d_mnist_loss: 0.0148, d_svhn_loss: 0.0312, d_fake_loss: 0.0516, g_loss: 1.2637\n",
            "Step [14690/60000], d_real_loss: 0.1165, d_mnist_loss: 0.0371, d_svhn_loss: 0.0794, d_fake_loss: 0.1105, g_loss: 1.1623\n",
            "Step [14700/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0102, d_svhn_loss: 0.0302, d_fake_loss: 0.0393, g_loss: 1.1510\n",
            "Step [14710/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0152, d_svhn_loss: 0.0244, d_fake_loss: 0.0446, g_loss: 1.2949\n",
            "Step [14720/60000], d_real_loss: 0.0885, d_mnist_loss: 0.0132, d_svhn_loss: 0.0753, d_fake_loss: 0.0426, g_loss: 1.1538\n",
            "Step [14730/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0148, d_svhn_loss: 0.0210, d_fake_loss: 0.0307, g_loss: 1.1831\n",
            "Step [14740/60000], d_real_loss: 0.1604, d_mnist_loss: 0.0278, d_svhn_loss: 0.1327, d_fake_loss: 0.1547, g_loss: 1.1189\n",
            "Step [14750/60000], d_real_loss: 0.0454, d_mnist_loss: 0.0208, d_svhn_loss: 0.0246, d_fake_loss: 0.0524, g_loss: 1.0418\n",
            "Step [14760/60000], d_real_loss: 0.1654, d_mnist_loss: 0.1412, d_svhn_loss: 0.0241, d_fake_loss: 0.1462, g_loss: 1.8909\n",
            "Step [14770/60000], d_real_loss: 0.0616, d_mnist_loss: 0.0403, d_svhn_loss: 0.0213, d_fake_loss: 0.0614, g_loss: 1.2241\n",
            "Step [14780/60000], d_real_loss: 0.0785, d_mnist_loss: 0.0324, d_svhn_loss: 0.0461, d_fake_loss: 0.1101, g_loss: 1.1528\n",
            "Step [14790/60000], d_real_loss: 0.0863, d_mnist_loss: 0.0099, d_svhn_loss: 0.0765, d_fake_loss: 0.1428, g_loss: 1.2588\n",
            "Step [14800/60000], d_real_loss: 0.2096, d_mnist_loss: 0.0444, d_svhn_loss: 0.1653, d_fake_loss: 0.0984, g_loss: 1.2547\n",
            "Step [14810/60000], d_real_loss: 0.0340, d_mnist_loss: 0.0097, d_svhn_loss: 0.0243, d_fake_loss: 0.0360, g_loss: 1.0529\n",
            "Step [14820/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0171, d_svhn_loss: 0.0313, d_fake_loss: 0.0861, g_loss: 1.3727\n",
            "Step [14830/60000], d_real_loss: 0.1017, d_mnist_loss: 0.0246, d_svhn_loss: 0.0771, d_fake_loss: 0.0542, g_loss: 1.2028\n",
            "Step [14840/60000], d_real_loss: 0.0366, d_mnist_loss: 0.0119, d_svhn_loss: 0.0247, d_fake_loss: 0.0261, g_loss: 1.0933\n",
            "Step [14850/60000], d_real_loss: 0.2285, d_mnist_loss: 0.0262, d_svhn_loss: 0.2022, d_fake_loss: 0.0524, g_loss: 1.1306\n",
            "Step [14860/60000], d_real_loss: 0.1377, d_mnist_loss: 0.0997, d_svhn_loss: 0.0381, d_fake_loss: 0.1919, g_loss: 1.7096\n",
            "Step [14870/60000], d_real_loss: 0.0837, d_mnist_loss: 0.0297, d_svhn_loss: 0.0540, d_fake_loss: 0.1402, g_loss: 1.1975\n",
            "Step [14880/60000], d_real_loss: 0.0617, d_mnist_loss: 0.0170, d_svhn_loss: 0.0447, d_fake_loss: 0.0791, g_loss: 1.1064\n",
            "Step [14890/60000], d_real_loss: 0.0588, d_mnist_loss: 0.0272, d_svhn_loss: 0.0316, d_fake_loss: 0.0569, g_loss: 1.0990\n",
            "Step [14900/60000], d_real_loss: 0.0646, d_mnist_loss: 0.0150, d_svhn_loss: 0.0496, d_fake_loss: 0.2674, g_loss: 1.1610\n",
            "Step [14910/60000], d_real_loss: 0.0464, d_mnist_loss: 0.0254, d_svhn_loss: 0.0210, d_fake_loss: 0.0363, g_loss: 1.1708\n",
            "Step [14920/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0160, d_svhn_loss: 0.0422, d_fake_loss: 0.0555, g_loss: 1.1072\n",
            "Step [14930/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0072, d_svhn_loss: 0.0468, d_fake_loss: 0.0889, g_loss: 1.0946\n",
            "Step [14940/60000], d_real_loss: 0.0886, d_mnist_loss: 0.0169, d_svhn_loss: 0.0717, d_fake_loss: 0.1026, g_loss: 0.9939\n",
            "Step [14950/60000], d_real_loss: 0.1746, d_mnist_loss: 0.0348, d_svhn_loss: 0.1398, d_fake_loss: 0.0672, g_loss: 1.2624\n",
            "Step [14960/60000], d_real_loss: 0.0480, d_mnist_loss: 0.0178, d_svhn_loss: 0.0302, d_fake_loss: 0.1032, g_loss: 0.9520\n",
            "Step [14970/60000], d_real_loss: 0.1020, d_mnist_loss: 0.0137, d_svhn_loss: 0.0883, d_fake_loss: 0.2173, g_loss: 1.2219\n",
            "Step [14980/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0135, d_svhn_loss: 0.0430, d_fake_loss: 0.0410, g_loss: 1.0812\n",
            "Step [14990/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0189, d_svhn_loss: 0.0448, d_fake_loss: 0.0502, g_loss: 1.2441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9998865127563477]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998807907104, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [15000/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0100, d_svhn_loss: 0.0352, d_fake_loss: 0.0455, g_loss: 1.0227\n",
            "saved ./samples_fashion/sample-15000-m-s.png\n",
            "saved ./samples_fashion/sample-15000-s-m.png\n",
            "Step [15010/60000], d_real_loss: 0.0989, d_mnist_loss: 0.0229, d_svhn_loss: 0.0760, d_fake_loss: 0.1556, g_loss: 1.3085\n",
            "Step [15020/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0091, d_svhn_loss: 0.0329, d_fake_loss: 0.0431, g_loss: 1.0905\n",
            "Step [15030/60000], d_real_loss: 0.0738, d_mnist_loss: 0.0235, d_svhn_loss: 0.0503, d_fake_loss: 0.1103, g_loss: 1.2835\n",
            "Step [15040/60000], d_real_loss: 0.0383, d_mnist_loss: 0.0171, d_svhn_loss: 0.0213, d_fake_loss: 0.0484, g_loss: 1.1006\n",
            "Step [15050/60000], d_real_loss: 0.1261, d_mnist_loss: 0.0108, d_svhn_loss: 0.1153, d_fake_loss: 0.1163, g_loss: 0.7594\n",
            "Step [15060/60000], d_real_loss: 0.0560, d_mnist_loss: 0.0191, d_svhn_loss: 0.0369, d_fake_loss: 0.0572, g_loss: 1.3201\n",
            "Step [15070/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0131, d_svhn_loss: 0.0300, d_fake_loss: 0.0681, g_loss: 1.3607\n",
            "Step [15080/60000], d_real_loss: 0.0560, d_mnist_loss: 0.0224, d_svhn_loss: 0.0336, d_fake_loss: 0.0878, g_loss: 0.9937\n",
            "Step [15090/60000], d_real_loss: 0.0738, d_mnist_loss: 0.0171, d_svhn_loss: 0.0567, d_fake_loss: 0.0454, g_loss: 1.1436\n",
            "Step [15100/60000], d_real_loss: 0.1403, d_mnist_loss: 0.0535, d_svhn_loss: 0.0868, d_fake_loss: 0.0403, g_loss: 1.1239\n",
            "Step [15110/60000], d_real_loss: 0.0394, d_mnist_loss: 0.0150, d_svhn_loss: 0.0244, d_fake_loss: 0.0381, g_loss: 0.9610\n",
            "Step [15120/60000], d_real_loss: 0.0679, d_mnist_loss: 0.0449, d_svhn_loss: 0.0230, d_fake_loss: 0.0528, g_loss: 1.2915\n",
            "Step [15130/60000], d_real_loss: 0.1075, d_mnist_loss: 0.0096, d_svhn_loss: 0.0979, d_fake_loss: 0.0572, g_loss: 1.1524\n",
            "Step [15140/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0133, d_svhn_loss: 0.0256, d_fake_loss: 0.0473, g_loss: 1.1906\n",
            "Step [15150/60000], d_real_loss: 0.1220, d_mnist_loss: 0.0864, d_svhn_loss: 0.0355, d_fake_loss: 0.0618, g_loss: 1.6469\n",
            "Step [15160/60000], d_real_loss: 0.0545, d_mnist_loss: 0.0146, d_svhn_loss: 0.0398, d_fake_loss: 0.1112, g_loss: 1.0695\n",
            "Step [15170/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0143, d_svhn_loss: 0.0262, d_fake_loss: 0.0918, g_loss: 0.6954\n",
            "Step [15180/60000], d_real_loss: 0.0876, d_mnist_loss: 0.0559, d_svhn_loss: 0.0318, d_fake_loss: 0.0764, g_loss: 1.1913\n",
            "Step [15190/60000], d_real_loss: 0.1663, d_mnist_loss: 0.0171, d_svhn_loss: 0.1492, d_fake_loss: 0.0517, g_loss: 1.0420\n",
            "Step [15200/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0125, d_svhn_loss: 0.0471, d_fake_loss: 0.0784, g_loss: 0.9896\n",
            "Step [15210/60000], d_real_loss: 0.0527, d_mnist_loss: 0.0201, d_svhn_loss: 0.0327, d_fake_loss: 0.0752, g_loss: 1.2580\n",
            "Step [15220/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0159, d_svhn_loss: 0.0262, d_fake_loss: 0.0697, g_loss: 1.2640\n",
            "Step [15230/60000], d_real_loss: 0.0960, d_mnist_loss: 0.0093, d_svhn_loss: 0.0868, d_fake_loss: 0.0287, g_loss: 1.0183\n",
            "Step [15240/60000], d_real_loss: 0.1081, d_mnist_loss: 0.0103, d_svhn_loss: 0.0978, d_fake_loss: 0.1253, g_loss: 1.2547\n",
            "Step [15250/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0130, d_svhn_loss: 0.0246, d_fake_loss: 0.0501, g_loss: 1.4068\n",
            "Step [15260/60000], d_real_loss: 0.1850, d_mnist_loss: 0.0219, d_svhn_loss: 0.1631, d_fake_loss: 0.0820, g_loss: 1.0390\n",
            "Step [15270/60000], d_real_loss: 0.0350, d_mnist_loss: 0.0107, d_svhn_loss: 0.0243, d_fake_loss: 0.0496, g_loss: 1.1297\n",
            "Step [15280/60000], d_real_loss: 0.0577, d_mnist_loss: 0.0202, d_svhn_loss: 0.0374, d_fake_loss: 0.1301, g_loss: 1.3755\n",
            "Step [15290/60000], d_real_loss: 0.0742, d_mnist_loss: 0.0386, d_svhn_loss: 0.0356, d_fake_loss: 0.0469, g_loss: 1.1190\n",
            "Step [15300/60000], d_real_loss: 0.0660, d_mnist_loss: 0.0145, d_svhn_loss: 0.0516, d_fake_loss: 0.0820, g_loss: 1.4614\n",
            "Step [15310/60000], d_real_loss: 0.0463, d_mnist_loss: 0.0172, d_svhn_loss: 0.0291, d_fake_loss: 0.0923, g_loss: 1.2636\n",
            "Step [15320/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0220, d_svhn_loss: 0.0265, d_fake_loss: 0.1003, g_loss: 1.3810\n",
            "Step [15330/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0194, d_svhn_loss: 0.0245, d_fake_loss: 0.0878, g_loss: 1.0094\n",
            "Step [15340/60000], d_real_loss: 0.0510, d_mnist_loss: 0.0248, d_svhn_loss: 0.0262, d_fake_loss: 0.0477, g_loss: 1.1033\n",
            "Step [15350/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0107, d_svhn_loss: 0.0324, d_fake_loss: 0.0592, g_loss: 0.9281\n",
            "Step [15360/60000], d_real_loss: 0.1296, d_mnist_loss: 0.0529, d_svhn_loss: 0.0766, d_fake_loss: 0.1513, g_loss: 1.3367\n",
            "Step [15370/60000], d_real_loss: 0.0745, d_mnist_loss: 0.0106, d_svhn_loss: 0.0639, d_fake_loss: 0.0833, g_loss: 1.2068\n",
            "Step [15380/60000], d_real_loss: 0.1521, d_mnist_loss: 0.0719, d_svhn_loss: 0.0802, d_fake_loss: 0.0350, g_loss: 1.1614\n",
            "Step [15390/60000], d_real_loss: 0.1867, d_mnist_loss: 0.1613, d_svhn_loss: 0.0255, d_fake_loss: 0.1453, g_loss: 1.7232\n",
            "Step [15400/60000], d_real_loss: 0.1012, d_mnist_loss: 0.0322, d_svhn_loss: 0.0689, d_fake_loss: 0.0811, g_loss: 1.1093\n",
            "Step [15410/60000], d_real_loss: 0.1223, d_mnist_loss: 0.0168, d_svhn_loss: 0.1054, d_fake_loss: 0.0421, g_loss: 1.2130\n",
            "Step [15420/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0235, d_svhn_loss: 0.0272, d_fake_loss: 0.0402, g_loss: 1.2077\n",
            "Step [15430/60000], d_real_loss: 0.0757, d_mnist_loss: 0.0286, d_svhn_loss: 0.0471, d_fake_loss: 0.0641, g_loss: 1.2630\n",
            "Step [15440/60000], d_real_loss: 0.0681, d_mnist_loss: 0.0264, d_svhn_loss: 0.0418, d_fake_loss: 0.0532, g_loss: 1.0995\n",
            "Step [15450/60000], d_real_loss: 0.1778, d_mnist_loss: 0.0137, d_svhn_loss: 0.1641, d_fake_loss: 0.0494, g_loss: 1.2058\n",
            "Step [15460/60000], d_real_loss: 0.0930, d_mnist_loss: 0.0402, d_svhn_loss: 0.0527, d_fake_loss: 0.0446, g_loss: 1.2324\n",
            "Step [15470/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0105, d_svhn_loss: 0.0334, d_fake_loss: 0.0340, g_loss: 0.9094\n",
            "Step [15480/60000], d_real_loss: 0.0838, d_mnist_loss: 0.0172, d_svhn_loss: 0.0666, d_fake_loss: 0.0453, g_loss: 1.2176\n",
            "Step [15490/60000], d_real_loss: 0.2779, d_mnist_loss: 0.2163, d_svhn_loss: 0.0616, d_fake_loss: 0.1142, g_loss: 1.1041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9995760917663574]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999993443489075, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [15500/60000], d_real_loss: 0.0454, d_mnist_loss: 0.0207, d_svhn_loss: 0.0248, d_fake_loss: 0.0501, g_loss: 1.0849\n",
            "saved ./samples_fashion/sample-15500-m-s.png\n",
            "saved ./samples_fashion/sample-15500-s-m.png\n",
            "Step [15510/60000], d_real_loss: 0.0909, d_mnist_loss: 0.0304, d_svhn_loss: 0.0605, d_fake_loss: 0.0312, g_loss: 1.2639\n",
            "Step [15520/60000], d_real_loss: 0.0269, d_mnist_loss: 0.0103, d_svhn_loss: 0.0166, d_fake_loss: 0.0839, g_loss: 1.4523\n",
            "Step [15530/60000], d_real_loss: 0.0549, d_mnist_loss: 0.0176, d_svhn_loss: 0.0373, d_fake_loss: 0.0618, g_loss: 0.9540\n",
            "Step [15540/60000], d_real_loss: 0.0458, d_mnist_loss: 0.0121, d_svhn_loss: 0.0337, d_fake_loss: 0.0397, g_loss: 1.3243\n",
            "Step [15550/60000], d_real_loss: 0.0829, d_mnist_loss: 0.0273, d_svhn_loss: 0.0556, d_fake_loss: 0.0562, g_loss: 1.0273\n",
            "Step [15560/60000], d_real_loss: 0.0526, d_mnist_loss: 0.0220, d_svhn_loss: 0.0306, d_fake_loss: 0.1192, g_loss: 1.1952\n",
            "Step [15570/60000], d_real_loss: 0.1072, d_mnist_loss: 0.0547, d_svhn_loss: 0.0525, d_fake_loss: 0.0558, g_loss: 1.2230\n",
            "Step [15580/60000], d_real_loss: 0.1264, d_mnist_loss: 0.0091, d_svhn_loss: 0.1173, d_fake_loss: 0.2396, g_loss: 1.2357\n",
            "Step [15590/60000], d_real_loss: 0.0731, d_mnist_loss: 0.0356, d_svhn_loss: 0.0374, d_fake_loss: 0.0461, g_loss: 1.2323\n",
            "Step [15600/60000], d_real_loss: 0.0541, d_mnist_loss: 0.0257, d_svhn_loss: 0.0284, d_fake_loss: 0.0310, g_loss: 1.2395\n",
            "Step [15610/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0155, d_svhn_loss: 0.0249, d_fake_loss: 0.1657, g_loss: 1.1911\n",
            "Step [15620/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0198, d_svhn_loss: 0.0330, d_fake_loss: 0.0513, g_loss: 1.0000\n",
            "Step [15630/60000], d_real_loss: 0.0668, d_mnist_loss: 0.0152, d_svhn_loss: 0.0516, d_fake_loss: 0.1120, g_loss: 0.7903\n",
            "Step [15640/60000], d_real_loss: 0.2856, d_mnist_loss: 0.2313, d_svhn_loss: 0.0543, d_fake_loss: 0.1476, g_loss: 1.1208\n",
            "Step [15650/60000], d_real_loss: 0.0689, d_mnist_loss: 0.0400, d_svhn_loss: 0.0289, d_fake_loss: 0.0692, g_loss: 1.1775\n",
            "Step [15660/60000], d_real_loss: 0.0629, d_mnist_loss: 0.0089, d_svhn_loss: 0.0540, d_fake_loss: 0.0952, g_loss: 1.1222\n",
            "Step [15670/60000], d_real_loss: 0.0697, d_mnist_loss: 0.0109, d_svhn_loss: 0.0588, d_fake_loss: 0.0783, g_loss: 1.3116\n",
            "Step [15680/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0168, d_svhn_loss: 0.0274, d_fake_loss: 0.2304, g_loss: 1.3989\n",
            "Step [15690/60000], d_real_loss: 0.0534, d_mnist_loss: 0.0173, d_svhn_loss: 0.0361, d_fake_loss: 0.1043, g_loss: 1.1461\n",
            "Step [15700/60000], d_real_loss: 0.0579, d_mnist_loss: 0.0100, d_svhn_loss: 0.0479, d_fake_loss: 0.1005, g_loss: 1.2174\n",
            "Step [15710/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0108, d_svhn_loss: 0.0362, d_fake_loss: 0.0555, g_loss: 1.0622\n",
            "Step [15720/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0186, d_svhn_loss: 0.0214, d_fake_loss: 0.0405, g_loss: 1.3393\n",
            "Step [15730/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0092, d_svhn_loss: 0.0359, d_fake_loss: 0.0668, g_loss: 1.1882\n",
            "Step [15740/60000], d_real_loss: 0.0992, d_mnist_loss: 0.0152, d_svhn_loss: 0.0840, d_fake_loss: 0.0935, g_loss: 1.0617\n",
            "Step [15750/60000], d_real_loss: 0.1333, d_mnist_loss: 0.1104, d_svhn_loss: 0.0229, d_fake_loss: 0.0645, g_loss: 1.2586\n",
            "Step [15760/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0099, d_svhn_loss: 0.0321, d_fake_loss: 0.0955, g_loss: 1.1639\n",
            "Step [15770/60000], d_real_loss: 0.0503, d_mnist_loss: 0.0197, d_svhn_loss: 0.0306, d_fake_loss: 0.1432, g_loss: 1.2672\n",
            "Step [15780/60000], d_real_loss: 0.2263, d_mnist_loss: 0.0980, d_svhn_loss: 0.1282, d_fake_loss: 0.0468, g_loss: 1.4110\n",
            "Step [15790/60000], d_real_loss: 0.0971, d_mnist_loss: 0.0136, d_svhn_loss: 0.0835, d_fake_loss: 0.0672, g_loss: 1.1465\n",
            "Step [15800/60000], d_real_loss: 0.1520, d_mnist_loss: 0.1296, d_svhn_loss: 0.0224, d_fake_loss: 0.0583, g_loss: 1.5190\n",
            "Step [15810/60000], d_real_loss: 0.0638, d_mnist_loss: 0.0141, d_svhn_loss: 0.0498, d_fake_loss: 0.0566, g_loss: 1.2224\n",
            "Step [15820/60000], d_real_loss: 0.0555, d_mnist_loss: 0.0240, d_svhn_loss: 0.0315, d_fake_loss: 0.0800, g_loss: 1.1061\n",
            "Step [15830/60000], d_real_loss: 0.1215, d_mnist_loss: 0.0161, d_svhn_loss: 0.1054, d_fake_loss: 0.0950, g_loss: 1.1317\n",
            "Step [15840/60000], d_real_loss: 0.0559, d_mnist_loss: 0.0131, d_svhn_loss: 0.0428, d_fake_loss: 0.1005, g_loss: 0.9958\n",
            "Step [15850/60000], d_real_loss: 0.1374, d_mnist_loss: 0.0085, d_svhn_loss: 0.1290, d_fake_loss: 0.0552, g_loss: 1.1277\n",
            "Step [15860/60000], d_real_loss: 0.0695, d_mnist_loss: 0.0197, d_svhn_loss: 0.0498, d_fake_loss: 0.0847, g_loss: 1.2774\n",
            "Step [15870/60000], d_real_loss: 0.0503, d_mnist_loss: 0.0107, d_svhn_loss: 0.0396, d_fake_loss: 0.0588, g_loss: 1.2349\n",
            "Step [15880/60000], d_real_loss: 0.1276, d_mnist_loss: 0.0116, d_svhn_loss: 0.1160, d_fake_loss: 0.0677, g_loss: 1.1630\n",
            "Step [15890/60000], d_real_loss: 0.0590, d_mnist_loss: 0.0259, d_svhn_loss: 0.0331, d_fake_loss: 0.0613, g_loss: 1.2011\n",
            "Step [15900/60000], d_real_loss: 0.0702, d_mnist_loss: 0.0102, d_svhn_loss: 0.0600, d_fake_loss: 0.0332, g_loss: 1.1461\n",
            "Step [15910/60000], d_real_loss: 0.1026, d_mnist_loss: 0.0109, d_svhn_loss: 0.0917, d_fake_loss: 0.1466, g_loss: 1.2293\n",
            "Step [15920/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0128, d_svhn_loss: 0.0305, d_fake_loss: 0.0926, g_loss: 1.0799\n",
            "Step [15930/60000], d_real_loss: 0.1114, d_mnist_loss: 0.0324, d_svhn_loss: 0.0790, d_fake_loss: 0.2030, g_loss: 1.3852\n",
            "Step [15940/60000], d_real_loss: 0.0390, d_mnist_loss: 0.0149, d_svhn_loss: 0.0241, d_fake_loss: 0.0603, g_loss: 1.1481\n",
            "Step [15950/60000], d_real_loss: 0.0884, d_mnist_loss: 0.0236, d_svhn_loss: 0.0648, d_fake_loss: 0.2014, g_loss: 1.6270\n",
            "Step [15960/60000], d_real_loss: 0.1461, d_mnist_loss: 0.1202, d_svhn_loss: 0.0259, d_fake_loss: 0.1364, g_loss: 1.2327\n",
            "Step [15970/60000], d_real_loss: 0.0579, d_mnist_loss: 0.0145, d_svhn_loss: 0.0435, d_fake_loss: 0.0304, g_loss: 1.1305\n",
            "Step [15980/60000], d_real_loss: 0.0614, d_mnist_loss: 0.0208, d_svhn_loss: 0.0407, d_fake_loss: 0.0390, g_loss: 1.0525\n",
            "Step [15990/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0156, d_svhn_loss: 0.0262, d_fake_loss: 0.0460, g_loss: 1.2377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9986881613731384]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999991655349731, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [16000/60000], d_real_loss: 0.0761, d_mnist_loss: 0.0293, d_svhn_loss: 0.0468, d_fake_loss: 0.0506, g_loss: 1.0649\n",
            "saved ./samples_fashion/sample-16000-m-s.png\n",
            "saved ./samples_fashion/sample-16000-s-m.png\n",
            "Step [16010/60000], d_real_loss: 0.2031, d_mnist_loss: 0.0146, d_svhn_loss: 0.1885, d_fake_loss: 0.1209, g_loss: 1.1652\n",
            "Step [16020/60000], d_real_loss: 0.0698, d_mnist_loss: 0.0229, d_svhn_loss: 0.0469, d_fake_loss: 0.0815, g_loss: 1.2669\n",
            "Step [16030/60000], d_real_loss: 0.0415, d_mnist_loss: 0.0161, d_svhn_loss: 0.0254, d_fake_loss: 0.0974, g_loss: 1.3862\n",
            "Step [16040/60000], d_real_loss: 0.0791, d_mnist_loss: 0.0162, d_svhn_loss: 0.0629, d_fake_loss: 0.0808, g_loss: 1.2353\n",
            "Step [16050/60000], d_real_loss: 0.0569, d_mnist_loss: 0.0228, d_svhn_loss: 0.0341, d_fake_loss: 0.0486, g_loss: 1.1837\n",
            "Step [16060/60000], d_real_loss: 0.0805, d_mnist_loss: 0.0292, d_svhn_loss: 0.0513, d_fake_loss: 0.0980, g_loss: 1.0575\n",
            "Step [16070/60000], d_real_loss: 0.0731, d_mnist_loss: 0.0385, d_svhn_loss: 0.0346, d_fake_loss: 0.1052, g_loss: 1.3111\n",
            "Step [16080/60000], d_real_loss: 0.0558, d_mnist_loss: 0.0226, d_svhn_loss: 0.0332, d_fake_loss: 0.0805, g_loss: 1.1059\n",
            "Step [16090/60000], d_real_loss: 0.1175, d_mnist_loss: 0.0139, d_svhn_loss: 0.1036, d_fake_loss: 0.0830, g_loss: 1.2833\n",
            "Step [16100/60000], d_real_loss: 0.0388, d_mnist_loss: 0.0119, d_svhn_loss: 0.0269, d_fake_loss: 0.1472, g_loss: 1.0657\n",
            "Step [16110/60000], d_real_loss: 0.0689, d_mnist_loss: 0.0426, d_svhn_loss: 0.0263, d_fake_loss: 0.0497, g_loss: 1.0841\n",
            "Step [16120/60000], d_real_loss: 0.0839, d_mnist_loss: 0.0161, d_svhn_loss: 0.0678, d_fake_loss: 0.0792, g_loss: 1.1623\n",
            "Step [16130/60000], d_real_loss: 0.0567, d_mnist_loss: 0.0216, d_svhn_loss: 0.0350, d_fake_loss: 0.1171, g_loss: 1.3885\n",
            "Step [16140/60000], d_real_loss: 0.0616, d_mnist_loss: 0.0131, d_svhn_loss: 0.0485, d_fake_loss: 0.0486, g_loss: 1.1153\n",
            "Step [16150/60000], d_real_loss: 0.0569, d_mnist_loss: 0.0171, d_svhn_loss: 0.0398, d_fake_loss: 0.1187, g_loss: 1.3709\n",
            "Step [16160/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0100, d_svhn_loss: 0.0537, d_fake_loss: 0.0702, g_loss: 1.1757\n",
            "Step [16170/60000], d_real_loss: 0.0679, d_mnist_loss: 0.0141, d_svhn_loss: 0.0538, d_fake_loss: 0.0773, g_loss: 1.2640\n",
            "Step [16180/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0104, d_svhn_loss: 0.0329, d_fake_loss: 0.0627, g_loss: 1.2168\n",
            "Step [16190/60000], d_real_loss: 0.1447, d_mnist_loss: 0.0126, d_svhn_loss: 0.1321, d_fake_loss: 0.1217, g_loss: 1.2068\n",
            "Step [16200/60000], d_real_loss: 0.6158, d_mnist_loss: 0.0435, d_svhn_loss: 0.5723, d_fake_loss: 0.2835, g_loss: 1.0858\n",
            "Step [16210/60000], d_real_loss: 0.0477, d_mnist_loss: 0.0146, d_svhn_loss: 0.0331, d_fake_loss: 0.0392, g_loss: 1.0176\n",
            "Step [16220/60000], d_real_loss: 0.1708, d_mnist_loss: 0.0141, d_svhn_loss: 0.1567, d_fake_loss: 0.1902, g_loss: 1.5139\n",
            "Step [16230/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0215, d_svhn_loss: 0.0255, d_fake_loss: 0.1737, g_loss: 0.9584\n",
            "Step [16240/60000], d_real_loss: 0.0999, d_mnist_loss: 0.0695, d_svhn_loss: 0.0304, d_fake_loss: 0.0477, g_loss: 0.9378\n",
            "Step [16250/60000], d_real_loss: 0.1407, d_mnist_loss: 0.0484, d_svhn_loss: 0.0923, d_fake_loss: 0.1211, g_loss: 1.0754\n",
            "Step [16260/60000], d_real_loss: 0.0702, d_mnist_loss: 0.0377, d_svhn_loss: 0.0325, d_fake_loss: 0.0492, g_loss: 1.0249\n",
            "Step [16270/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0192, d_svhn_loss: 0.0282, d_fake_loss: 0.0511, g_loss: 1.1787\n",
            "Step [16280/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0087, d_svhn_loss: 0.0355, d_fake_loss: 0.1546, g_loss: 1.3027\n",
            "Step [16290/60000], d_real_loss: 0.0502, d_mnist_loss: 0.0146, d_svhn_loss: 0.0356, d_fake_loss: 0.1019, g_loss: 1.3428\n",
            "Step [16300/60000], d_real_loss: 0.0320, d_mnist_loss: 0.0098, d_svhn_loss: 0.0222, d_fake_loss: 0.0588, g_loss: 1.1397\n",
            "Step [16310/60000], d_real_loss: 0.1345, d_mnist_loss: 0.0350, d_svhn_loss: 0.0994, d_fake_loss: 0.2473, g_loss: 1.5003\n",
            "Step [16320/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0324, d_svhn_loss: 0.0262, d_fake_loss: 0.0390, g_loss: 1.1137\n",
            "Step [16330/60000], d_real_loss: 0.1207, d_mnist_loss: 0.0768, d_svhn_loss: 0.0439, d_fake_loss: 0.0462, g_loss: 1.0642\n",
            "Step [16340/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0157, d_svhn_loss: 0.0250, d_fake_loss: 0.0630, g_loss: 1.2674\n",
            "Step [16350/60000], d_real_loss: 0.1233, d_mnist_loss: 0.0675, d_svhn_loss: 0.0558, d_fake_loss: 0.0965, g_loss: 1.4180\n",
            "Step [16360/60000], d_real_loss: 0.0577, d_mnist_loss: 0.0120, d_svhn_loss: 0.0457, d_fake_loss: 0.1490, g_loss: 1.0763\n",
            "Step [16370/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0086, d_svhn_loss: 0.0385, d_fake_loss: 0.0871, g_loss: 1.1262\n",
            "Step [16380/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0093, d_svhn_loss: 0.0313, d_fake_loss: 0.0982, g_loss: 1.1834\n",
            "Step [16390/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0110, d_svhn_loss: 0.0431, d_fake_loss: 0.0277, g_loss: 1.1351\n",
            "Step [16400/60000], d_real_loss: 0.1122, d_mnist_loss: 0.0202, d_svhn_loss: 0.0920, d_fake_loss: 0.0901, g_loss: 1.1584\n",
            "Step [16410/60000], d_real_loss: 0.1485, d_mnist_loss: 0.0136, d_svhn_loss: 0.1349, d_fake_loss: 0.0905, g_loss: 1.0760\n",
            "Step [16420/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0086, d_svhn_loss: 0.0289, d_fake_loss: 0.0535, g_loss: 1.1530\n",
            "Step [16430/60000], d_real_loss: 0.0761, d_mnist_loss: 0.0382, d_svhn_loss: 0.0379, d_fake_loss: 0.0948, g_loss: 1.3906\n",
            "Step [16440/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0134, d_svhn_loss: 0.0309, d_fake_loss: 0.0480, g_loss: 1.0472\n",
            "Step [16450/60000], d_real_loss: 0.1137, d_mnist_loss: 0.0148, d_svhn_loss: 0.0990, d_fake_loss: 0.0306, g_loss: 0.9438\n",
            "Step [16460/60000], d_real_loss: 0.0968, d_mnist_loss: 0.0560, d_svhn_loss: 0.0408, d_fake_loss: 0.0906, g_loss: 1.1298\n",
            "Step [16470/60000], d_real_loss: 0.0495, d_mnist_loss: 0.0172, d_svhn_loss: 0.0323, d_fake_loss: 0.0506, g_loss: 1.3091\n",
            "Step [16480/60000], d_real_loss: 0.1791, d_mnist_loss: 0.0133, d_svhn_loss: 0.1658, d_fake_loss: 0.0802, g_loss: 0.8145\n",
            "Step [16490/60000], d_real_loss: 0.1280, d_mnist_loss: 0.0166, d_svhn_loss: 0.1114, d_fake_loss: 0.0599, g_loss: 1.0831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9990943670272827]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999992847442627, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [16500/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0134, d_svhn_loss: 0.0243, d_fake_loss: 0.0509, g_loss: 1.0729\n",
            "saved ./samples_fashion/sample-16500-m-s.png\n",
            "saved ./samples_fashion/sample-16500-s-m.png\n",
            "Step [16510/60000], d_real_loss: 0.0841, d_mnist_loss: 0.0117, d_svhn_loss: 0.0725, d_fake_loss: 0.0431, g_loss: 1.1702\n",
            "Step [16520/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0131, d_svhn_loss: 0.0350, d_fake_loss: 0.0717, g_loss: 0.9118\n",
            "Step [16530/60000], d_real_loss: 0.1674, d_mnist_loss: 0.0207, d_svhn_loss: 0.1467, d_fake_loss: 0.0681, g_loss: 1.1950\n",
            "Step [16540/60000], d_real_loss: 0.0689, d_mnist_loss: 0.0283, d_svhn_loss: 0.0405, d_fake_loss: 0.0626, g_loss: 1.3273\n",
            "Step [16550/60000], d_real_loss: 0.1046, d_mnist_loss: 0.0159, d_svhn_loss: 0.0887, d_fake_loss: 0.0582, g_loss: 0.9849\n",
            "Step [16560/60000], d_real_loss: 0.0991, d_mnist_loss: 0.0223, d_svhn_loss: 0.0768, d_fake_loss: 0.0535, g_loss: 1.5585\n",
            "Step [16570/60000], d_real_loss: 0.0817, d_mnist_loss: 0.0543, d_svhn_loss: 0.0274, d_fake_loss: 0.0612, g_loss: 1.1588\n",
            "Step [16580/60000], d_real_loss: 0.0555, d_mnist_loss: 0.0132, d_svhn_loss: 0.0423, d_fake_loss: 0.0528, g_loss: 0.9379\n",
            "Step [16590/60000], d_real_loss: 0.0386, d_mnist_loss: 0.0118, d_svhn_loss: 0.0267, d_fake_loss: 0.0344, g_loss: 1.2187\n",
            "Step [16600/60000], d_real_loss: 0.1049, d_mnist_loss: 0.0106, d_svhn_loss: 0.0943, d_fake_loss: 0.0958, g_loss: 1.2511\n",
            "Step [16610/60000], d_real_loss: 0.1413, d_mnist_loss: 0.1133, d_svhn_loss: 0.0281, d_fake_loss: 0.0429, g_loss: 1.3414\n",
            "Step [16620/60000], d_real_loss: 0.1209, d_mnist_loss: 0.0378, d_svhn_loss: 0.0832, d_fake_loss: 0.1723, g_loss: 1.3015\n",
            "Step [16630/60000], d_real_loss: 0.0889, d_mnist_loss: 0.0389, d_svhn_loss: 0.0501, d_fake_loss: 0.0348, g_loss: 1.0582\n",
            "Step [16640/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0293, d_svhn_loss: 0.0442, d_fake_loss: 0.0468, g_loss: 1.2307\n",
            "Step [16650/60000], d_real_loss: 0.0895, d_mnist_loss: 0.0241, d_svhn_loss: 0.0654, d_fake_loss: 0.0584, g_loss: 1.4088\n",
            "Step [16660/60000], d_real_loss: 0.0441, d_mnist_loss: 0.0261, d_svhn_loss: 0.0181, d_fake_loss: 0.0661, g_loss: 1.1395\n",
            "Step [16670/60000], d_real_loss: 0.0994, d_mnist_loss: 0.0187, d_svhn_loss: 0.0807, d_fake_loss: 0.0770, g_loss: 1.0383\n",
            "Step [16680/60000], d_real_loss: 0.1397, d_mnist_loss: 0.0164, d_svhn_loss: 0.1233, d_fake_loss: 0.0846, g_loss: 1.0105\n",
            "Step [16690/60000], d_real_loss: 0.0843, d_mnist_loss: 0.0202, d_svhn_loss: 0.0641, d_fake_loss: 0.0327, g_loss: 0.9480\n",
            "Step [16700/60000], d_real_loss: 0.0449, d_mnist_loss: 0.0138, d_svhn_loss: 0.0312, d_fake_loss: 0.0887, g_loss: 1.1081\n",
            "Step [16710/60000], d_real_loss: 0.2746, d_mnist_loss: 0.0274, d_svhn_loss: 0.2472, d_fake_loss: 0.0830, g_loss: 1.0416\n",
            "Step [16720/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0121, d_svhn_loss: 0.0429, d_fake_loss: 0.0321, g_loss: 1.0750\n",
            "Step [16730/60000], d_real_loss: 0.0334, d_mnist_loss: 0.0130, d_svhn_loss: 0.0203, d_fake_loss: 0.0488, g_loss: 1.0532\n",
            "Step [16740/60000], d_real_loss: 0.0591, d_mnist_loss: 0.0376, d_svhn_loss: 0.0215, d_fake_loss: 0.0402, g_loss: 0.9311\n",
            "Step [16750/60000], d_real_loss: 0.0985, d_mnist_loss: 0.0157, d_svhn_loss: 0.0828, d_fake_loss: 0.0652, g_loss: 1.0827\n",
            "Step [16760/60000], d_real_loss: 0.0877, d_mnist_loss: 0.0335, d_svhn_loss: 0.0542, d_fake_loss: 0.1527, g_loss: 0.9952\n",
            "Step [16770/60000], d_real_loss: 0.0461, d_mnist_loss: 0.0142, d_svhn_loss: 0.0319, d_fake_loss: 0.0572, g_loss: 1.1115\n",
            "Step [16780/60000], d_real_loss: 0.1040, d_mnist_loss: 0.0243, d_svhn_loss: 0.0797, d_fake_loss: 0.0371, g_loss: 1.0231\n",
            "Step [16790/60000], d_real_loss: 0.0542, d_mnist_loss: 0.0133, d_svhn_loss: 0.0410, d_fake_loss: 0.0379, g_loss: 1.0741\n",
            "Step [16800/60000], d_real_loss: 0.0659, d_mnist_loss: 0.0367, d_svhn_loss: 0.0292, d_fake_loss: 0.0485, g_loss: 1.0284\n",
            "Step [16810/60000], d_real_loss: 0.0868, d_mnist_loss: 0.0324, d_svhn_loss: 0.0544, d_fake_loss: 0.0617, g_loss: 1.0962\n",
            "Step [16820/60000], d_real_loss: 0.1005, d_mnist_loss: 0.0827, d_svhn_loss: 0.0178, d_fake_loss: 0.1699, g_loss: 1.5759\n",
            "Step [16830/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0124, d_svhn_loss: 0.0251, d_fake_loss: 0.0547, g_loss: 1.1068\n",
            "Step [16840/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0136, d_svhn_loss: 0.0529, d_fake_loss: 0.1003, g_loss: 1.1876\n",
            "Step [16850/60000], d_real_loss: 0.0705, d_mnist_loss: 0.0132, d_svhn_loss: 0.0573, d_fake_loss: 0.0338, g_loss: 1.2065\n",
            "Step [16860/60000], d_real_loss: 0.0505, d_mnist_loss: 0.0145, d_svhn_loss: 0.0360, d_fake_loss: 0.2006, g_loss: 0.9563\n",
            "Step [16870/60000], d_real_loss: 0.0489, d_mnist_loss: 0.0149, d_svhn_loss: 0.0339, d_fake_loss: 0.0507, g_loss: 1.1728\n",
            "Step [16880/60000], d_real_loss: 0.0781, d_mnist_loss: 0.0231, d_svhn_loss: 0.0550, d_fake_loss: 0.1172, g_loss: 1.2748\n",
            "Step [16890/60000], d_real_loss: 0.0719, d_mnist_loss: 0.0136, d_svhn_loss: 0.0583, d_fake_loss: 0.0424, g_loss: 1.1010\n",
            "Step [16900/60000], d_real_loss: 0.0808, d_mnist_loss: 0.0381, d_svhn_loss: 0.0427, d_fake_loss: 0.0799, g_loss: 1.0288\n",
            "Step [16910/60000], d_real_loss: 0.1353, d_mnist_loss: 0.0254, d_svhn_loss: 0.1099, d_fake_loss: 0.0726, g_loss: 0.9381\n",
            "Step [16920/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0141, d_svhn_loss: 0.0189, d_fake_loss: 0.0513, g_loss: 1.1420\n",
            "Step [16930/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0108, d_svhn_loss: 0.0252, d_fake_loss: 0.2523, g_loss: 1.2625\n",
            "Step [16940/60000], d_real_loss: 0.1720, d_mnist_loss: 0.0512, d_svhn_loss: 0.1209, d_fake_loss: 0.0475, g_loss: 1.4504\n",
            "Step [16950/60000], d_real_loss: 0.1372, d_mnist_loss: 0.0640, d_svhn_loss: 0.0732, d_fake_loss: 0.1152, g_loss: 1.1982\n",
            "Step [16960/60000], d_real_loss: 0.0976, d_mnist_loss: 0.0327, d_svhn_loss: 0.0648, d_fake_loss: 0.0585, g_loss: 1.1920\n",
            "Step [16970/60000], d_real_loss: 0.0935, d_mnist_loss: 0.0499, d_svhn_loss: 0.0436, d_fake_loss: 0.0256, g_loss: 1.1744\n",
            "Step [16980/60000], d_real_loss: 0.0963, d_mnist_loss: 0.0806, d_svhn_loss: 0.0157, d_fake_loss: 0.1049, g_loss: 1.2217\n",
            "Step [16990/60000], d_real_loss: 0.0386, d_mnist_loss: 0.0116, d_svhn_loss: 0.0270, d_fake_loss: 0.0328, g_loss: 1.1138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9997816681861877]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [17000/60000], d_real_loss: 0.0908, d_mnist_loss: 0.0140, d_svhn_loss: 0.0768, d_fake_loss: 0.0575, g_loss: 1.1572\n",
            "saved ./samples_fashion/sample-17000-m-s.png\n",
            "saved ./samples_fashion/sample-17000-s-m.png\n",
            "Step [17010/60000], d_real_loss: 0.0711, d_mnist_loss: 0.0093, d_svhn_loss: 0.0618, d_fake_loss: 0.0329, g_loss: 1.1882\n",
            "Step [17020/60000], d_real_loss: 0.0599, d_mnist_loss: 0.0209, d_svhn_loss: 0.0390, d_fake_loss: 0.0403, g_loss: 1.2619\n",
            "Step [17030/60000], d_real_loss: 0.0950, d_mnist_loss: 0.0349, d_svhn_loss: 0.0601, d_fake_loss: 0.0833, g_loss: 1.1166\n",
            "Step [17040/60000], d_real_loss: 0.0968, d_mnist_loss: 0.0122, d_svhn_loss: 0.0846, d_fake_loss: 0.0655, g_loss: 1.3024\n",
            "Step [17050/60000], d_real_loss: 0.0489, d_mnist_loss: 0.0306, d_svhn_loss: 0.0184, d_fake_loss: 0.0430, g_loss: 1.0264\n",
            "Step [17060/60000], d_real_loss: 0.0799, d_mnist_loss: 0.0136, d_svhn_loss: 0.0664, d_fake_loss: 0.0624, g_loss: 1.1514\n",
            "Step [17070/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0095, d_svhn_loss: 0.0297, d_fake_loss: 0.0217, g_loss: 1.1775\n",
            "Step [17080/60000], d_real_loss: 0.0808, d_mnist_loss: 0.0169, d_svhn_loss: 0.0639, d_fake_loss: 0.0626, g_loss: 1.1431\n",
            "Step [17090/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0189, d_svhn_loss: 0.0232, d_fake_loss: 0.0529, g_loss: 1.0613\n",
            "Step [17100/60000], d_real_loss: 0.0925, d_mnist_loss: 0.0163, d_svhn_loss: 0.0762, d_fake_loss: 0.2513, g_loss: 1.0363\n",
            "Step [17110/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0128, d_svhn_loss: 0.0274, d_fake_loss: 0.0480, g_loss: 1.0382\n",
            "Step [17120/60000], d_real_loss: 0.1411, d_mnist_loss: 0.0230, d_svhn_loss: 0.1181, d_fake_loss: 0.0456, g_loss: 1.2477\n",
            "Step [17130/60000], d_real_loss: 0.0704, d_mnist_loss: 0.0198, d_svhn_loss: 0.0506, d_fake_loss: 0.0613, g_loss: 1.2213\n",
            "Step [17140/60000], d_real_loss: 0.0802, d_mnist_loss: 0.0082, d_svhn_loss: 0.0721, d_fake_loss: 0.0347, g_loss: 1.1344\n",
            "Step [17150/60000], d_real_loss: 0.0643, d_mnist_loss: 0.0206, d_svhn_loss: 0.0437, d_fake_loss: 0.0466, g_loss: 1.1984\n",
            "Step [17160/60000], d_real_loss: 0.0520, d_mnist_loss: 0.0131, d_svhn_loss: 0.0389, d_fake_loss: 0.0300, g_loss: 1.0177\n",
            "Step [17170/60000], d_real_loss: 0.0296, d_mnist_loss: 0.0093, d_svhn_loss: 0.0203, d_fake_loss: 0.0458, g_loss: 1.1161\n",
            "Step [17180/60000], d_real_loss: 0.0413, d_mnist_loss: 0.0087, d_svhn_loss: 0.0325, d_fake_loss: 0.0531, g_loss: 1.2432\n",
            "Step [17190/60000], d_real_loss: 0.0723, d_mnist_loss: 0.0486, d_svhn_loss: 0.0237, d_fake_loss: 0.0246, g_loss: 0.9570\n",
            "Step [17200/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0146, d_svhn_loss: 0.0257, d_fake_loss: 0.1532, g_loss: 1.1207\n",
            "Step [17210/60000], d_real_loss: 0.0462, d_mnist_loss: 0.0142, d_svhn_loss: 0.0320, d_fake_loss: 0.0390, g_loss: 1.0053\n",
            "Step [17220/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0140, d_svhn_loss: 0.0232, d_fake_loss: 0.0544, g_loss: 1.2902\n",
            "Step [17230/60000], d_real_loss: 0.0498, d_mnist_loss: 0.0132, d_svhn_loss: 0.0366, d_fake_loss: 0.0455, g_loss: 1.0229\n",
            "Step [17240/60000], d_real_loss: 0.0737, d_mnist_loss: 0.0379, d_svhn_loss: 0.0359, d_fake_loss: 0.0483, g_loss: 1.2170\n",
            "Step [17250/60000], d_real_loss: 0.1373, d_mnist_loss: 0.0093, d_svhn_loss: 0.1280, d_fake_loss: 0.0392, g_loss: 1.1597\n",
            "Step [17260/60000], d_real_loss: 0.0736, d_mnist_loss: 0.0256, d_svhn_loss: 0.0480, d_fake_loss: 0.0519, g_loss: 1.0627\n",
            "Step [17270/60000], d_real_loss: 0.0529, d_mnist_loss: 0.0265, d_svhn_loss: 0.0264, d_fake_loss: 0.3199, g_loss: 1.8414\n",
            "Step [17280/60000], d_real_loss: 0.0453, d_mnist_loss: 0.0153, d_svhn_loss: 0.0300, d_fake_loss: 0.0387, g_loss: 1.2147\n",
            "Step [17290/60000], d_real_loss: 0.0494, d_mnist_loss: 0.0244, d_svhn_loss: 0.0250, d_fake_loss: 0.1201, g_loss: 1.2363\n",
            "Step [17300/60000], d_real_loss: 0.0391, d_mnist_loss: 0.0190, d_svhn_loss: 0.0202, d_fake_loss: 0.0404, g_loss: 1.1833\n",
            "Step [17310/60000], d_real_loss: 0.1728, d_mnist_loss: 0.0155, d_svhn_loss: 0.1573, d_fake_loss: 0.0819, g_loss: 1.0404\n",
            "Step [17320/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0174, d_svhn_loss: 0.0263, d_fake_loss: 0.0379, g_loss: 1.0468\n",
            "Step [17330/60000], d_real_loss: 0.0844, d_mnist_loss: 0.0289, d_svhn_loss: 0.0555, d_fake_loss: 0.0356, g_loss: 1.2001\n",
            "Step [17340/60000], d_real_loss: 0.3430, d_mnist_loss: 0.0105, d_svhn_loss: 0.3325, d_fake_loss: 0.0751, g_loss: 0.9811\n",
            "Step [17350/60000], d_real_loss: 0.0970, d_mnist_loss: 0.0100, d_svhn_loss: 0.0870, d_fake_loss: 0.0307, g_loss: 1.0680\n",
            "Step [17360/60000], d_real_loss: 0.0337, d_mnist_loss: 0.0106, d_svhn_loss: 0.0232, d_fake_loss: 0.0824, g_loss: 1.0786\n",
            "Step [17370/60000], d_real_loss: 0.0766, d_mnist_loss: 0.0233, d_svhn_loss: 0.0534, d_fake_loss: 0.0474, g_loss: 1.1112\n",
            "Step [17380/60000], d_real_loss: 0.0290, d_mnist_loss: 0.0081, d_svhn_loss: 0.0209, d_fake_loss: 0.0272, g_loss: 1.2075\n",
            "Step [17390/60000], d_real_loss: 0.2123, d_mnist_loss: 0.1771, d_svhn_loss: 0.0351, d_fake_loss: 0.2964, g_loss: 1.9120\n",
            "Step [17400/60000], d_real_loss: 0.0536, d_mnist_loss: 0.0244, d_svhn_loss: 0.0291, d_fake_loss: 0.0955, g_loss: 1.3048\n",
            "Step [17410/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0122, d_svhn_loss: 0.0219, d_fake_loss: 0.0356, g_loss: 1.1467\n",
            "Step [17420/60000], d_real_loss: 0.0919, d_mnist_loss: 0.0098, d_svhn_loss: 0.0822, d_fake_loss: 0.0484, g_loss: 1.0331\n",
            "Step [17430/60000], d_real_loss: 0.0680, d_mnist_loss: 0.0373, d_svhn_loss: 0.0307, d_fake_loss: 0.0348, g_loss: 1.0783\n",
            "Step [17440/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0084, d_svhn_loss: 0.0226, d_fake_loss: 0.0405, g_loss: 1.1693\n",
            "Step [17450/60000], d_real_loss: 0.0715, d_mnist_loss: 0.0117, d_svhn_loss: 0.0598, d_fake_loss: 0.0567, g_loss: 1.1484\n",
            "Step [17460/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0127, d_svhn_loss: 0.0239, d_fake_loss: 0.0342, g_loss: 1.0795\n",
            "Step [17470/60000], d_real_loss: 0.0840, d_mnist_loss: 0.0126, d_svhn_loss: 0.0714, d_fake_loss: 0.1612, g_loss: 0.9979\n",
            "Step [17480/60000], d_real_loss: 0.0796, d_mnist_loss: 0.0478, d_svhn_loss: 0.0318, d_fake_loss: 0.0683, g_loss: 1.0613\n",
            "Step [17490/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0205, d_svhn_loss: 0.0265, d_fake_loss: 0.0914, g_loss: 1.1786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9994440674781799]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [17500/60000], d_real_loss: 0.0317, d_mnist_loss: 0.0087, d_svhn_loss: 0.0229, d_fake_loss: 0.0306, g_loss: 1.0181\n",
            "saved ./samples_fashion/sample-17500-m-s.png\n",
            "saved ./samples_fashion/sample-17500-s-m.png\n",
            "Step [17510/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0110, d_svhn_loss: 0.0285, d_fake_loss: 0.0407, g_loss: 1.1227\n",
            "Step [17520/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0129, d_svhn_loss: 0.0269, d_fake_loss: 0.0307, g_loss: 0.9866\n",
            "Step [17530/60000], d_real_loss: 0.0923, d_mnist_loss: 0.0462, d_svhn_loss: 0.0461, d_fake_loss: 0.1224, g_loss: 1.4144\n",
            "Step [17540/60000], d_real_loss: 0.0661, d_mnist_loss: 0.0133, d_svhn_loss: 0.0527, d_fake_loss: 0.0710, g_loss: 1.3585\n",
            "Step [17550/60000], d_real_loss: 0.1101, d_mnist_loss: 0.0779, d_svhn_loss: 0.0322, d_fake_loss: 0.0609, g_loss: 1.3095\n",
            "Step [17560/60000], d_real_loss: 0.0517, d_mnist_loss: 0.0093, d_svhn_loss: 0.0424, d_fake_loss: 0.1151, g_loss: 1.0650\n",
            "Step [17570/60000], d_real_loss: 0.1109, d_mnist_loss: 0.0148, d_svhn_loss: 0.0961, d_fake_loss: 0.0451, g_loss: 1.1938\n",
            "Step [17580/60000], d_real_loss: 0.0905, d_mnist_loss: 0.0199, d_svhn_loss: 0.0706, d_fake_loss: 0.1188, g_loss: 1.0270\n",
            "Step [17590/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0189, d_svhn_loss: 0.0216, d_fake_loss: 0.0795, g_loss: 1.0686\n",
            "Step [17600/60000], d_real_loss: 0.0703, d_mnist_loss: 0.0320, d_svhn_loss: 0.0383, d_fake_loss: 0.0380, g_loss: 1.1303\n",
            "Step [17610/60000], d_real_loss: 0.0781, d_mnist_loss: 0.0521, d_svhn_loss: 0.0259, d_fake_loss: 0.0338, g_loss: 1.2889\n",
            "Step [17620/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0137, d_svhn_loss: 0.0455, d_fake_loss: 0.1087, g_loss: 1.0750\n",
            "Step [17630/60000], d_real_loss: 0.0687, d_mnist_loss: 0.0204, d_svhn_loss: 0.0483, d_fake_loss: 0.0967, g_loss: 1.3832\n",
            "Step [17640/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0207, d_svhn_loss: 0.0366, d_fake_loss: 0.0326, g_loss: 1.1999\n",
            "Step [17650/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0090, d_svhn_loss: 0.0328, d_fake_loss: 0.0821, g_loss: 1.0029\n",
            "Step [17660/60000], d_real_loss: 0.0847, d_mnist_loss: 0.0253, d_svhn_loss: 0.0593, d_fake_loss: 0.1820, g_loss: 1.0205\n",
            "Step [17670/60000], d_real_loss: 0.1132, d_mnist_loss: 0.0138, d_svhn_loss: 0.0994, d_fake_loss: 0.2404, g_loss: 1.1279\n",
            "Step [17680/60000], d_real_loss: 0.0458, d_mnist_loss: 0.0248, d_svhn_loss: 0.0210, d_fake_loss: 0.0818, g_loss: 1.0310\n",
            "Step [17690/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0230, d_svhn_loss: 0.0407, d_fake_loss: 0.0580, g_loss: 1.4264\n",
            "Step [17700/60000], d_real_loss: 0.0971, d_mnist_loss: 0.0738, d_svhn_loss: 0.0233, d_fake_loss: 0.1349, g_loss: 1.5523\n",
            "Step [17710/60000], d_real_loss: 0.0702, d_mnist_loss: 0.0360, d_svhn_loss: 0.0342, d_fake_loss: 0.0507, g_loss: 1.1123\n",
            "Step [17720/60000], d_real_loss: 0.0361, d_mnist_loss: 0.0150, d_svhn_loss: 0.0210, d_fake_loss: 0.0403, g_loss: 1.0399\n",
            "Step [17730/60000], d_real_loss: 0.0415, d_mnist_loss: 0.0161, d_svhn_loss: 0.0255, d_fake_loss: 0.0454, g_loss: 1.3620\n",
            "Step [17740/60000], d_real_loss: 0.1160, d_mnist_loss: 0.0120, d_svhn_loss: 0.1040, d_fake_loss: 0.0544, g_loss: 1.3303\n",
            "Step [17750/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0157, d_svhn_loss: 0.0430, d_fake_loss: 0.0547, g_loss: 1.2662\n",
            "Step [17760/60000], d_real_loss: 0.0513, d_mnist_loss: 0.0126, d_svhn_loss: 0.0387, d_fake_loss: 0.0235, g_loss: 1.0283\n",
            "Step [17770/60000], d_real_loss: 0.0524, d_mnist_loss: 0.0259, d_svhn_loss: 0.0264, d_fake_loss: 0.0627, g_loss: 1.2160\n",
            "Step [17780/60000], d_real_loss: 0.0569, d_mnist_loss: 0.0205, d_svhn_loss: 0.0364, d_fake_loss: 0.0338, g_loss: 1.1333\n",
            "Step [17790/60000], d_real_loss: 0.0554, d_mnist_loss: 0.0292, d_svhn_loss: 0.0262, d_fake_loss: 0.0498, g_loss: 0.8584\n",
            "Step [17800/60000], d_real_loss: 0.1311, d_mnist_loss: 0.0179, d_svhn_loss: 0.1132, d_fake_loss: 0.0666, g_loss: 0.9460\n",
            "Step [17810/60000], d_real_loss: 0.1106, d_mnist_loss: 0.0446, d_svhn_loss: 0.0660, d_fake_loss: 0.1430, g_loss: 0.9767\n",
            "Step [17820/60000], d_real_loss: 0.0355, d_mnist_loss: 0.0121, d_svhn_loss: 0.0234, d_fake_loss: 0.0404, g_loss: 1.2487\n",
            "Step [17830/60000], d_real_loss: 0.1026, d_mnist_loss: 0.0685, d_svhn_loss: 0.0341, d_fake_loss: 0.0235, g_loss: 1.3718\n",
            "Step [17840/60000], d_real_loss: 0.1887, d_mnist_loss: 0.0131, d_svhn_loss: 0.1756, d_fake_loss: 0.1024, g_loss: 1.0907\n",
            "Step [17850/60000], d_real_loss: 0.0584, d_mnist_loss: 0.0166, d_svhn_loss: 0.0418, d_fake_loss: 0.1204, g_loss: 1.0064\n",
            "Step [17860/60000], d_real_loss: 0.0614, d_mnist_loss: 0.0241, d_svhn_loss: 0.0373, d_fake_loss: 0.0990, g_loss: 1.1105\n",
            "Step [17870/60000], d_real_loss: 0.2038, d_mnist_loss: 0.0102, d_svhn_loss: 0.1936, d_fake_loss: 0.2052, g_loss: 1.2250\n",
            "Step [17880/60000], d_real_loss: 0.1194, d_mnist_loss: 0.0155, d_svhn_loss: 0.1038, d_fake_loss: 0.0578, g_loss: 1.0280\n",
            "Step [17890/60000], d_real_loss: 0.0498, d_mnist_loss: 0.0320, d_svhn_loss: 0.0179, d_fake_loss: 0.1852, g_loss: 1.4077\n",
            "Step [17900/60000], d_real_loss: 0.0607, d_mnist_loss: 0.0165, d_svhn_loss: 0.0441, d_fake_loss: 0.0535, g_loss: 1.2400\n",
            "Step [17910/60000], d_real_loss: 0.0503, d_mnist_loss: 0.0288, d_svhn_loss: 0.0215, d_fake_loss: 0.0423, g_loss: 1.2561\n",
            "Step [17920/60000], d_real_loss: 0.1581, d_mnist_loss: 0.0160, d_svhn_loss: 0.1421, d_fake_loss: 0.2076, g_loss: 0.8878\n",
            "Step [17930/60000], d_real_loss: 0.1084, d_mnist_loss: 0.0103, d_svhn_loss: 0.0981, d_fake_loss: 0.4665, g_loss: 1.1491\n",
            "Step [17940/60000], d_real_loss: 0.0641, d_mnist_loss: 0.0305, d_svhn_loss: 0.0336, d_fake_loss: 0.0803, g_loss: 1.0471\n",
            "Step [17950/60000], d_real_loss: 0.0499, d_mnist_loss: 0.0102, d_svhn_loss: 0.0397, d_fake_loss: 0.0631, g_loss: 0.9924\n",
            "Step [17960/60000], d_real_loss: 0.0742, d_mnist_loss: 0.0287, d_svhn_loss: 0.0455, d_fake_loss: 0.4745, g_loss: 0.8015\n",
            "Step [17970/60000], d_real_loss: 0.1501, d_mnist_loss: 0.0228, d_svhn_loss: 0.1273, d_fake_loss: 0.0853, g_loss: 1.2590\n",
            "Step [17980/60000], d_real_loss: 0.0604, d_mnist_loss: 0.0127, d_svhn_loss: 0.0477, d_fake_loss: 0.1161, g_loss: 1.2318\n",
            "Step [17990/60000], d_real_loss: 0.0501, d_mnist_loss: 0.0208, d_svhn_loss: 0.0293, d_fake_loss: 0.0269, g_loss: 1.2005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9987569451332092]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [18000/60000], d_real_loss: 0.2753, d_mnist_loss: 0.2439, d_svhn_loss: 0.0314, d_fake_loss: 0.1153, g_loss: 1.2086\n",
            "saved ./samples_fashion/sample-18000-m-s.png\n",
            "saved ./samples_fashion/sample-18000-s-m.png\n",
            "Step [18010/60000], d_real_loss: 0.1595, d_mnist_loss: 0.0647, d_svhn_loss: 0.0948, d_fake_loss: 0.3601, g_loss: 0.6921\n",
            "Step [18020/60000], d_real_loss: 0.0686, d_mnist_loss: 0.0201, d_svhn_loss: 0.0485, d_fake_loss: 0.0278, g_loss: 1.0020\n",
            "Step [18030/60000], d_real_loss: 0.0732, d_mnist_loss: 0.0123, d_svhn_loss: 0.0610, d_fake_loss: 0.0349, g_loss: 1.1216\n",
            "Step [18040/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0119, d_svhn_loss: 0.0397, d_fake_loss: 0.2182, g_loss: 1.1067\n",
            "Step [18050/60000], d_real_loss: 0.0948, d_mnist_loss: 0.0703, d_svhn_loss: 0.0245, d_fake_loss: 0.0525, g_loss: 1.3284\n",
            "Step [18060/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0231, d_svhn_loss: 0.0343, d_fake_loss: 0.1150, g_loss: 1.1804\n",
            "Step [18070/60000], d_real_loss: 0.0487, d_mnist_loss: 0.0089, d_svhn_loss: 0.0398, d_fake_loss: 0.0676, g_loss: 1.1554\n",
            "Step [18080/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0116, d_svhn_loss: 0.0185, d_fake_loss: 0.0297, g_loss: 1.2231\n",
            "Step [18090/60000], d_real_loss: 0.0887, d_mnist_loss: 0.0626, d_svhn_loss: 0.0261, d_fake_loss: 0.0922, g_loss: 0.8678\n",
            "Step [18100/60000], d_real_loss: 0.2068, d_mnist_loss: 0.0255, d_svhn_loss: 0.1813, d_fake_loss: 0.0671, g_loss: 1.0379\n",
            "Step [18110/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0119, d_svhn_loss: 0.0324, d_fake_loss: 0.0615, g_loss: 1.3061\n",
            "Step [18120/60000], d_real_loss: 0.2188, d_mnist_loss: 0.0241, d_svhn_loss: 0.1947, d_fake_loss: 0.0924, g_loss: 1.1469\n",
            "Step [18130/60000], d_real_loss: 0.1135, d_mnist_loss: 0.0897, d_svhn_loss: 0.0238, d_fake_loss: 0.1722, g_loss: 0.6819\n",
            "Step [18140/60000], d_real_loss: 0.0866, d_mnist_loss: 0.0271, d_svhn_loss: 0.0595, d_fake_loss: 0.0372, g_loss: 1.2025\n",
            "Step [18150/60000], d_real_loss: 0.0299, d_mnist_loss: 0.0087, d_svhn_loss: 0.0212, d_fake_loss: 0.0280, g_loss: 1.0974\n",
            "Step [18160/60000], d_real_loss: 0.0276, d_mnist_loss: 0.0085, d_svhn_loss: 0.0190, d_fake_loss: 0.2128, g_loss: 1.3470\n",
            "Step [18170/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0170, d_svhn_loss: 0.0306, d_fake_loss: 0.0477, g_loss: 0.9802\n",
            "Step [18180/60000], d_real_loss: 0.0790, d_mnist_loss: 0.0198, d_svhn_loss: 0.0591, d_fake_loss: 0.1115, g_loss: 1.2556\n",
            "Step [18190/60000], d_real_loss: 0.0500, d_mnist_loss: 0.0230, d_svhn_loss: 0.0270, d_fake_loss: 0.0352, g_loss: 1.1487\n",
            "Step [18200/60000], d_real_loss: 0.0586, d_mnist_loss: 0.0091, d_svhn_loss: 0.0495, d_fake_loss: 0.0641, g_loss: 1.0997\n",
            "Step [18210/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0166, d_svhn_loss: 0.0315, d_fake_loss: 0.1254, g_loss: 0.8837\n",
            "Step [18220/60000], d_real_loss: 0.0485, d_mnist_loss: 0.0095, d_svhn_loss: 0.0391, d_fake_loss: 0.0286, g_loss: 1.0347\n",
            "Step [18230/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0201, d_svhn_loss: 0.0316, d_fake_loss: 0.0406, g_loss: 1.1604\n",
            "Step [18240/60000], d_real_loss: 0.0636, d_mnist_loss: 0.0159, d_svhn_loss: 0.0477, d_fake_loss: 0.0914, g_loss: 1.1885\n",
            "Step [18250/60000], d_real_loss: 0.0599, d_mnist_loss: 0.0336, d_svhn_loss: 0.0263, d_fake_loss: 0.0343, g_loss: 1.0487\n",
            "Step [18260/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0080, d_svhn_loss: 0.0162, d_fake_loss: 0.0336, g_loss: 1.1226\n",
            "Step [18270/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0086, d_svhn_loss: 0.0256, d_fake_loss: 0.0582, g_loss: 1.2639\n",
            "Step [18280/60000], d_real_loss: 0.0498, d_mnist_loss: 0.0277, d_svhn_loss: 0.0221, d_fake_loss: 0.0475, g_loss: 1.2444\n",
            "Step [18290/60000], d_real_loss: 0.1172, d_mnist_loss: 0.0559, d_svhn_loss: 0.0614, d_fake_loss: 0.0984, g_loss: 1.2251\n",
            "Step [18300/60000], d_real_loss: 0.0782, d_mnist_loss: 0.0156, d_svhn_loss: 0.0626, d_fake_loss: 0.0484, g_loss: 0.9743\n",
            "Step [18310/60000], d_real_loss: 0.1415, d_mnist_loss: 0.1178, d_svhn_loss: 0.0237, d_fake_loss: 0.0434, g_loss: 1.4792\n",
            "Step [18320/60000], d_real_loss: 0.0867, d_mnist_loss: 0.0586, d_svhn_loss: 0.0281, d_fake_loss: 0.0985, g_loss: 0.9893\n",
            "Step [18330/60000], d_real_loss: 0.0426, d_mnist_loss: 0.0149, d_svhn_loss: 0.0277, d_fake_loss: 0.0946, g_loss: 1.0733\n",
            "Step [18340/60000], d_real_loss: 0.0381, d_mnist_loss: 0.0137, d_svhn_loss: 0.0244, d_fake_loss: 0.0680, g_loss: 1.2195\n",
            "Step [18350/60000], d_real_loss: 0.0561, d_mnist_loss: 0.0135, d_svhn_loss: 0.0426, d_fake_loss: 0.0421, g_loss: 1.3216\n",
            "Step [18360/60000], d_real_loss: 0.1149, d_mnist_loss: 0.0853, d_svhn_loss: 0.0295, d_fake_loss: 0.0480, g_loss: 1.0882\n",
            "Step [18370/60000], d_real_loss: 0.0345, d_mnist_loss: 0.0132, d_svhn_loss: 0.0213, d_fake_loss: 0.0636, g_loss: 1.0420\n",
            "Step [18380/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0136, d_svhn_loss: 0.0536, d_fake_loss: 0.0382, g_loss: 1.1945\n",
            "Step [18390/60000], d_real_loss: 0.0629, d_mnist_loss: 0.0085, d_svhn_loss: 0.0544, d_fake_loss: 0.0628, g_loss: 1.1879\n",
            "Step [18400/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0279, d_svhn_loss: 0.0200, d_fake_loss: 0.0805, g_loss: 1.1510\n",
            "Step [18410/60000], d_real_loss: 0.1113, d_mnist_loss: 0.0573, d_svhn_loss: 0.0539, d_fake_loss: 0.0337, g_loss: 1.1513\n",
            "Step [18420/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0105, d_svhn_loss: 0.0253, d_fake_loss: 0.1259, g_loss: 1.4262\n",
            "Step [18430/60000], d_real_loss: 0.0746, d_mnist_loss: 0.0212, d_svhn_loss: 0.0533, d_fake_loss: 0.2600, g_loss: 1.1168\n",
            "Step [18440/60000], d_real_loss: 0.0984, d_mnist_loss: 0.0166, d_svhn_loss: 0.0818, d_fake_loss: 0.1410, g_loss: 1.2799\n",
            "Step [18450/60000], d_real_loss: 0.0736, d_mnist_loss: 0.0132, d_svhn_loss: 0.0605, d_fake_loss: 0.1245, g_loss: 1.1079\n",
            "Step [18460/60000], d_real_loss: 0.0613, d_mnist_loss: 0.0113, d_svhn_loss: 0.0499, d_fake_loss: 0.1144, g_loss: 1.2935\n",
            "Step [18470/60000], d_real_loss: 0.0533, d_mnist_loss: 0.0118, d_svhn_loss: 0.0415, d_fake_loss: 0.0249, g_loss: 1.0530\n",
            "Step [18480/60000], d_real_loss: 0.1769, d_mnist_loss: 0.0380, d_svhn_loss: 0.1389, d_fake_loss: 0.0696, g_loss: 1.1463\n",
            "Step [18490/60000], d_real_loss: 0.0648, d_mnist_loss: 0.0348, d_svhn_loss: 0.0301, d_fake_loss: 0.1108, g_loss: 1.1598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9993930459022522]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [18500/60000], d_real_loss: 0.0722, d_mnist_loss: 0.0258, d_svhn_loss: 0.0465, d_fake_loss: 0.0599, g_loss: 1.2429\n",
            "saved ./samples_fashion/sample-18500-m-s.png\n",
            "saved ./samples_fashion/sample-18500-s-m.png\n",
            "Step [18510/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0194, d_svhn_loss: 0.0234, d_fake_loss: 0.0498, g_loss: 1.2435\n",
            "Step [18520/60000], d_real_loss: 0.0846, d_mnist_loss: 0.0111, d_svhn_loss: 0.0735, d_fake_loss: 0.0745, g_loss: 1.0707\n",
            "Step [18530/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0102, d_svhn_loss: 0.0300, d_fake_loss: 0.0317, g_loss: 1.0491\n",
            "Step [18540/60000], d_real_loss: 0.0696, d_mnist_loss: 0.0319, d_svhn_loss: 0.0378, d_fake_loss: 0.1289, g_loss: 1.4638\n",
            "Step [18550/60000], d_real_loss: 0.0582, d_mnist_loss: 0.0096, d_svhn_loss: 0.0486, d_fake_loss: 0.0395, g_loss: 1.2732\n",
            "Step [18560/60000], d_real_loss: 0.0829, d_mnist_loss: 0.0150, d_svhn_loss: 0.0679, d_fake_loss: 0.0385, g_loss: 1.0040\n",
            "Step [18570/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0177, d_svhn_loss: 0.0158, d_fake_loss: 0.0533, g_loss: 1.2105\n",
            "Step [18580/60000], d_real_loss: 0.1691, d_mnist_loss: 0.0118, d_svhn_loss: 0.1573, d_fake_loss: 0.0977, g_loss: 1.0416\n",
            "Step [18590/60000], d_real_loss: 0.0639, d_mnist_loss: 0.0338, d_svhn_loss: 0.0302, d_fake_loss: 0.0436, g_loss: 1.1273\n",
            "Step [18600/60000], d_real_loss: 0.0388, d_mnist_loss: 0.0104, d_svhn_loss: 0.0285, d_fake_loss: 0.0643, g_loss: 1.2547\n",
            "Step [18610/60000], d_real_loss: 0.0542, d_mnist_loss: 0.0096, d_svhn_loss: 0.0446, d_fake_loss: 0.0851, g_loss: 1.2973\n",
            "Step [18620/60000], d_real_loss: 0.1204, d_mnist_loss: 0.0104, d_svhn_loss: 0.1100, d_fake_loss: 0.0510, g_loss: 1.1125\n",
            "Step [18630/60000], d_real_loss: 0.0511, d_mnist_loss: 0.0149, d_svhn_loss: 0.0362, d_fake_loss: 0.1147, g_loss: 0.9893\n",
            "Step [18640/60000], d_real_loss: 0.0716, d_mnist_loss: 0.0211, d_svhn_loss: 0.0505, d_fake_loss: 0.0434, g_loss: 1.1454\n",
            "Step [18650/60000], d_real_loss: 0.0878, d_mnist_loss: 0.0192, d_svhn_loss: 0.0687, d_fake_loss: 0.0518, g_loss: 1.3491\n",
            "Step [18660/60000], d_real_loss: 0.0630, d_mnist_loss: 0.0107, d_svhn_loss: 0.0523, d_fake_loss: 0.0497, g_loss: 1.0148\n",
            "Step [18670/60000], d_real_loss: 0.0731, d_mnist_loss: 0.0224, d_svhn_loss: 0.0507, d_fake_loss: 0.0884, g_loss: 1.2179\n",
            "Step [18680/60000], d_real_loss: 0.0721, d_mnist_loss: 0.0234, d_svhn_loss: 0.0486, d_fake_loss: 0.0304, g_loss: 0.9431\n",
            "Step [18690/60000], d_real_loss: 0.0477, d_mnist_loss: 0.0138, d_svhn_loss: 0.0340, d_fake_loss: 0.0593, g_loss: 1.0864\n",
            "Step [18700/60000], d_real_loss: 0.1428, d_mnist_loss: 0.0124, d_svhn_loss: 0.1304, d_fake_loss: 0.1065, g_loss: 1.3753\n",
            "Step [18710/60000], d_real_loss: 0.0914, d_mnist_loss: 0.0506, d_svhn_loss: 0.0408, d_fake_loss: 0.0883, g_loss: 1.1727\n",
            "Step [18720/60000], d_real_loss: 0.1564, d_mnist_loss: 0.0209, d_svhn_loss: 0.1355, d_fake_loss: 0.0721, g_loss: 1.1127\n",
            "Step [18730/60000], d_real_loss: 0.0782, d_mnist_loss: 0.0116, d_svhn_loss: 0.0666, d_fake_loss: 0.1721, g_loss: 0.9208\n",
            "Step [18740/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0097, d_svhn_loss: 0.0499, d_fake_loss: 0.0292, g_loss: 1.2072\n",
            "Step [18750/60000], d_real_loss: 0.0366, d_mnist_loss: 0.0117, d_svhn_loss: 0.0248, d_fake_loss: 0.1219, g_loss: 1.8680\n",
            "Step [18760/60000], d_real_loss: 0.0593, d_mnist_loss: 0.0332, d_svhn_loss: 0.0261, d_fake_loss: 0.0482, g_loss: 0.9974\n",
            "Step [18770/60000], d_real_loss: 0.0844, d_mnist_loss: 0.0143, d_svhn_loss: 0.0701, d_fake_loss: 0.0413, g_loss: 1.1963\n",
            "Step [18780/60000], d_real_loss: 0.0449, d_mnist_loss: 0.0121, d_svhn_loss: 0.0328, d_fake_loss: 0.0795, g_loss: 1.1174\n",
            "Step [18790/60000], d_real_loss: 0.0653, d_mnist_loss: 0.0312, d_svhn_loss: 0.0341, d_fake_loss: 0.0767, g_loss: 1.1387\n",
            "Step [18800/60000], d_real_loss: 0.0726, d_mnist_loss: 0.0486, d_svhn_loss: 0.0240, d_fake_loss: 0.0904, g_loss: 1.2718\n",
            "Step [18810/60000], d_real_loss: 0.0879, d_mnist_loss: 0.0598, d_svhn_loss: 0.0281, d_fake_loss: 0.0544, g_loss: 1.0875\n",
            "Step [18820/60000], d_real_loss: 0.0663, d_mnist_loss: 0.0208, d_svhn_loss: 0.0455, d_fake_loss: 0.0882, g_loss: 1.1480\n",
            "Step [18830/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0074, d_svhn_loss: 0.0315, d_fake_loss: 0.0794, g_loss: 0.9971\n",
            "Step [18840/60000], d_real_loss: 0.0390, d_mnist_loss: 0.0118, d_svhn_loss: 0.0272, d_fake_loss: 0.0597, g_loss: 1.0475\n",
            "Step [18850/60000], d_real_loss: 0.0690, d_mnist_loss: 0.0256, d_svhn_loss: 0.0434, d_fake_loss: 0.1214, g_loss: 1.2442\n",
            "Step [18860/60000], d_real_loss: 0.0408, d_mnist_loss: 0.0120, d_svhn_loss: 0.0287, d_fake_loss: 0.0499, g_loss: 1.0065\n",
            "Step [18870/60000], d_real_loss: 0.0950, d_mnist_loss: 0.0322, d_svhn_loss: 0.0628, d_fake_loss: 0.0871, g_loss: 1.1701\n",
            "Step [18880/60000], d_real_loss: 0.1793, d_mnist_loss: 0.1528, d_svhn_loss: 0.0265, d_fake_loss: 0.0933, g_loss: 1.5887\n",
            "Step [18890/60000], d_real_loss: 0.0999, d_mnist_loss: 0.0581, d_svhn_loss: 0.0418, d_fake_loss: 0.0647, g_loss: 1.1065\n",
            "Step [18900/60000], d_real_loss: 0.0545, d_mnist_loss: 0.0163, d_svhn_loss: 0.0382, d_fake_loss: 0.0626, g_loss: 1.2609\n",
            "Step [18910/60000], d_real_loss: 0.0936, d_mnist_loss: 0.0112, d_svhn_loss: 0.0824, d_fake_loss: 0.0621, g_loss: 1.3647\n",
            "Step [18920/60000], d_real_loss: 0.1244, d_mnist_loss: 0.0771, d_svhn_loss: 0.0473, d_fake_loss: 0.0695, g_loss: 1.4540\n",
            "Step [18930/60000], d_real_loss: 0.0835, d_mnist_loss: 0.0131, d_svhn_loss: 0.0704, d_fake_loss: 0.0988, g_loss: 1.1184\n",
            "Step [18940/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0102, d_svhn_loss: 0.0209, d_fake_loss: 0.0411, g_loss: 1.0966\n",
            "Step [18950/60000], d_real_loss: 0.0647, d_mnist_loss: 0.0183, d_svhn_loss: 0.0464, d_fake_loss: 0.0480, g_loss: 1.1608\n",
            "Step [18960/60000], d_real_loss: 0.1308, d_mnist_loss: 0.0243, d_svhn_loss: 0.1066, d_fake_loss: 0.1232, g_loss: 1.2240\n",
            "Step [18970/60000], d_real_loss: 0.0334, d_mnist_loss: 0.0143, d_svhn_loss: 0.0191, d_fake_loss: 0.0613, g_loss: 1.1609\n",
            "Step [18980/60000], d_real_loss: 0.2077, d_mnist_loss: 0.1746, d_svhn_loss: 0.0332, d_fake_loss: 0.0927, g_loss: 1.0128\n",
            "Step [18990/60000], d_real_loss: 0.0517, d_mnist_loss: 0.0155, d_svhn_loss: 0.0362, d_fake_loss: 0.0479, g_loss: 0.9736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9993306994438171]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [19000/60000], d_real_loss: 0.0785, d_mnist_loss: 0.0370, d_svhn_loss: 0.0414, d_fake_loss: 0.0321, g_loss: 1.2148\n",
            "saved ./samples_fashion/sample-19000-m-s.png\n",
            "saved ./samples_fashion/sample-19000-s-m.png\n",
            "Step [19010/60000], d_real_loss: 0.0717, d_mnist_loss: 0.0141, d_svhn_loss: 0.0576, d_fake_loss: 0.0513, g_loss: 1.2152\n",
            "Step [19020/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0141, d_svhn_loss: 0.0342, d_fake_loss: 0.0774, g_loss: 1.0494\n",
            "Step [19030/60000], d_real_loss: 0.1431, d_mnist_loss: 0.0519, d_svhn_loss: 0.0912, d_fake_loss: 0.0976, g_loss: 0.5903\n",
            "Step [19040/60000], d_real_loss: 0.0598, d_mnist_loss: 0.0165, d_svhn_loss: 0.0433, d_fake_loss: 0.1159, g_loss: 1.1837\n",
            "Step [19050/60000], d_real_loss: 0.0905, d_mnist_loss: 0.0124, d_svhn_loss: 0.0781, d_fake_loss: 0.0359, g_loss: 1.0643\n",
            "Step [19060/60000], d_real_loss: 0.0524, d_mnist_loss: 0.0294, d_svhn_loss: 0.0230, d_fake_loss: 0.0909, g_loss: 1.4402\n",
            "Step [19070/60000], d_real_loss: 0.0855, d_mnist_loss: 0.0161, d_svhn_loss: 0.0694, d_fake_loss: 0.0330, g_loss: 0.9337\n",
            "Step [19080/60000], d_real_loss: 0.1047, d_mnist_loss: 0.0717, d_svhn_loss: 0.0330, d_fake_loss: 0.0781, g_loss: 1.0507\n",
            "Step [19090/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0297, d_svhn_loss: 0.0267, d_fake_loss: 0.0629, g_loss: 1.0503\n",
            "Step [19100/60000], d_real_loss: 0.0663, d_mnist_loss: 0.0082, d_svhn_loss: 0.0581, d_fake_loss: 0.1154, g_loss: 1.0895\n",
            "Step [19110/60000], d_real_loss: 0.1179, d_mnist_loss: 0.0122, d_svhn_loss: 0.1057, d_fake_loss: 0.0338, g_loss: 1.0473\n",
            "Step [19120/60000], d_real_loss: 0.0684, d_mnist_loss: 0.0086, d_svhn_loss: 0.0598, d_fake_loss: 0.1769, g_loss: 0.8092\n",
            "Step [19130/60000], d_real_loss: 0.1107, d_mnist_loss: 0.0477, d_svhn_loss: 0.0630, d_fake_loss: 0.0832, g_loss: 1.0078\n",
            "Step [19140/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0277, d_svhn_loss: 0.0315, d_fake_loss: 0.0340, g_loss: 1.0953\n",
            "Step [19150/60000], d_real_loss: 0.0666, d_mnist_loss: 0.0127, d_svhn_loss: 0.0540, d_fake_loss: 0.0785, g_loss: 1.1706\n",
            "Step [19160/60000], d_real_loss: 0.0646, d_mnist_loss: 0.0124, d_svhn_loss: 0.0523, d_fake_loss: 0.0366, g_loss: 1.0607\n",
            "Step [19170/60000], d_real_loss: 0.0804, d_mnist_loss: 0.0094, d_svhn_loss: 0.0710, d_fake_loss: 0.3226, g_loss: 1.2739\n",
            "Step [19180/60000], d_real_loss: 0.0951, d_mnist_loss: 0.0090, d_svhn_loss: 0.0861, d_fake_loss: 0.1138, g_loss: 1.0752\n",
            "Step [19190/60000], d_real_loss: 0.0601, d_mnist_loss: 0.0082, d_svhn_loss: 0.0519, d_fake_loss: 0.0626, g_loss: 1.0550\n",
            "Step [19200/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0118, d_svhn_loss: 0.0190, d_fake_loss: 0.0799, g_loss: 1.1658\n",
            "Step [19210/60000], d_real_loss: 0.0834, d_mnist_loss: 0.0202, d_svhn_loss: 0.0631, d_fake_loss: 0.0701, g_loss: 1.3620\n",
            "Step [19220/60000], d_real_loss: 0.0881, d_mnist_loss: 0.0175, d_svhn_loss: 0.0705, d_fake_loss: 0.0221, g_loss: 1.1962\n",
            "Step [19230/60000], d_real_loss: 0.1286, d_mnist_loss: 0.0120, d_svhn_loss: 0.1166, d_fake_loss: 0.0431, g_loss: 1.3106\n",
            "Step [19240/60000], d_real_loss: 0.0625, d_mnist_loss: 0.0125, d_svhn_loss: 0.0499, d_fake_loss: 0.0442, g_loss: 1.1690\n",
            "Step [19250/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0226, d_svhn_loss: 0.0250, d_fake_loss: 0.0328, g_loss: 0.9720\n",
            "Step [19260/60000], d_real_loss: 0.0932, d_mnist_loss: 0.0254, d_svhn_loss: 0.0678, d_fake_loss: 0.0804, g_loss: 1.2579\n",
            "Step [19270/60000], d_real_loss: 0.0786, d_mnist_loss: 0.0551, d_svhn_loss: 0.0235, d_fake_loss: 0.0870, g_loss: 0.9594\n",
            "Step [19280/60000], d_real_loss: 0.0558, d_mnist_loss: 0.0114, d_svhn_loss: 0.0444, d_fake_loss: 0.0980, g_loss: 1.2709\n",
            "Step [19290/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0153, d_svhn_loss: 0.0215, d_fake_loss: 0.0383, g_loss: 1.2799\n",
            "Step [19300/60000], d_real_loss: 0.0795, d_mnist_loss: 0.0137, d_svhn_loss: 0.0658, d_fake_loss: 0.1458, g_loss: 1.0070\n",
            "Step [19310/60000], d_real_loss: 0.3698, d_mnist_loss: 0.3325, d_svhn_loss: 0.0373, d_fake_loss: 0.2480, g_loss: 1.2695\n",
            "Step [19320/60000], d_real_loss: 0.0569, d_mnist_loss: 0.0315, d_svhn_loss: 0.0255, d_fake_loss: 0.0699, g_loss: 1.1110\n",
            "Step [19330/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0174, d_svhn_loss: 0.0150, d_fake_loss: 0.0341, g_loss: 1.0521\n",
            "Step [19340/60000], d_real_loss: 0.0762, d_mnist_loss: 0.0278, d_svhn_loss: 0.0484, d_fake_loss: 0.0640, g_loss: 1.1588\n",
            "Step [19350/60000], d_real_loss: 0.1763, d_mnist_loss: 0.0224, d_svhn_loss: 0.1539, d_fake_loss: 0.0698, g_loss: 1.2774\n",
            "Step [19360/60000], d_real_loss: 0.0660, d_mnist_loss: 0.0148, d_svhn_loss: 0.0512, d_fake_loss: 0.0592, g_loss: 1.2032\n",
            "Step [19370/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0146, d_svhn_loss: 0.0252, d_fake_loss: 0.0832, g_loss: 1.1416\n",
            "Step [19380/60000], d_real_loss: 0.0752, d_mnist_loss: 0.0320, d_svhn_loss: 0.0431, d_fake_loss: 0.0363, g_loss: 1.0270\n",
            "Step [19390/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0135, d_svhn_loss: 0.0183, d_fake_loss: 0.0278, g_loss: 1.2689\n",
            "Step [19400/60000], d_real_loss: 0.0506, d_mnist_loss: 0.0212, d_svhn_loss: 0.0294, d_fake_loss: 0.0281, g_loss: 1.1798\n",
            "Step [19410/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0108, d_svhn_loss: 0.0211, d_fake_loss: 0.0991, g_loss: 1.4675\n",
            "Step [19420/60000], d_real_loss: 0.0575, d_mnist_loss: 0.0326, d_svhn_loss: 0.0249, d_fake_loss: 0.0807, g_loss: 1.1059\n",
            "Step [19430/60000], d_real_loss: 0.0769, d_mnist_loss: 0.0307, d_svhn_loss: 0.0462, d_fake_loss: 0.0351, g_loss: 0.9853\n",
            "Step [19440/60000], d_real_loss: 0.0527, d_mnist_loss: 0.0297, d_svhn_loss: 0.0230, d_fake_loss: 0.1121, g_loss: 1.4018\n",
            "Step [19450/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0094, d_svhn_loss: 0.0308, d_fake_loss: 0.0677, g_loss: 1.0416\n",
            "Step [19460/60000], d_real_loss: 0.0494, d_mnist_loss: 0.0093, d_svhn_loss: 0.0400, d_fake_loss: 0.1004, g_loss: 1.1185\n",
            "Step [19470/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0116, d_svhn_loss: 0.0476, d_fake_loss: 0.0538, g_loss: 1.1979\n",
            "Step [19480/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0090, d_svhn_loss: 0.0353, d_fake_loss: 0.0336, g_loss: 1.1768\n",
            "Step [19490/60000], d_real_loss: 0.0290, d_mnist_loss: 0.0127, d_svhn_loss: 0.0163, d_fake_loss: 0.0601, g_loss: 1.3090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9993313550949097]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [19500/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0083, d_svhn_loss: 0.0582, d_fake_loss: 0.0710, g_loss: 1.1120\n",
            "saved ./samples_fashion/sample-19500-m-s.png\n",
            "saved ./samples_fashion/sample-19500-s-m.png\n",
            "Step [19510/60000], d_real_loss: 0.1331, d_mnist_loss: 0.0093, d_svhn_loss: 0.1238, d_fake_loss: 0.0273, g_loss: 0.9933\n",
            "Step [19520/60000], d_real_loss: 0.2772, d_mnist_loss: 0.2348, d_svhn_loss: 0.0425, d_fake_loss: 0.0819, g_loss: 1.1900\n",
            "Step [19530/60000], d_real_loss: 0.1039, d_mnist_loss: 0.0512, d_svhn_loss: 0.0527, d_fake_loss: 0.0287, g_loss: 1.2958\n",
            "Step [19540/60000], d_real_loss: 0.0509, d_mnist_loss: 0.0114, d_svhn_loss: 0.0396, d_fake_loss: 0.0360, g_loss: 1.0237\n",
            "Step [19550/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0088, d_svhn_loss: 0.0253, d_fake_loss: 0.0660, g_loss: 1.1758\n",
            "Step [19560/60000], d_real_loss: 0.0639, d_mnist_loss: 0.0125, d_svhn_loss: 0.0514, d_fake_loss: 0.1389, g_loss: 0.8706\n",
            "Step [19570/60000], d_real_loss: 0.0593, d_mnist_loss: 0.0244, d_svhn_loss: 0.0349, d_fake_loss: 0.0363, g_loss: 0.9703\n",
            "Step [19580/60000], d_real_loss: 0.0569, d_mnist_loss: 0.0147, d_svhn_loss: 0.0422, d_fake_loss: 0.2333, g_loss: 1.1884\n",
            "Step [19590/60000], d_real_loss: 0.1306, d_mnist_loss: 0.0357, d_svhn_loss: 0.0949, d_fake_loss: 0.1320, g_loss: 1.4329\n",
            "Step [19600/60000], d_real_loss: 0.0701, d_mnist_loss: 0.0339, d_svhn_loss: 0.0362, d_fake_loss: 0.3284, g_loss: 1.1385\n",
            "Step [19610/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0115, d_svhn_loss: 0.0289, d_fake_loss: 0.0672, g_loss: 1.0401\n",
            "Step [19620/60000], d_real_loss: 0.2046, d_mnist_loss: 0.1165, d_svhn_loss: 0.0881, d_fake_loss: 0.1678, g_loss: 1.4539\n",
            "Step [19630/60000], d_real_loss: 0.0848, d_mnist_loss: 0.0439, d_svhn_loss: 0.0409, d_fake_loss: 0.0453, g_loss: 1.2880\n",
            "Step [19640/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0118, d_svhn_loss: 0.0240, d_fake_loss: 0.0655, g_loss: 1.0749\n",
            "Step [19650/60000], d_real_loss: 0.0560, d_mnist_loss: 0.0266, d_svhn_loss: 0.0294, d_fake_loss: 0.0439, g_loss: 1.0679\n",
            "Step [19660/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0129, d_svhn_loss: 0.0228, d_fake_loss: 0.1558, g_loss: 1.1554\n",
            "Step [19670/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0102, d_svhn_loss: 0.0438, d_fake_loss: 0.0930, g_loss: 1.3452\n",
            "Step [19680/60000], d_real_loss: 0.0912, d_mnist_loss: 0.0087, d_svhn_loss: 0.0824, d_fake_loss: 0.0985, g_loss: 1.0578\n",
            "Step [19690/60000], d_real_loss: 0.0394, d_mnist_loss: 0.0141, d_svhn_loss: 0.0253, d_fake_loss: 0.0578, g_loss: 1.1787\n",
            "Step [19700/60000], d_real_loss: 0.0268, d_mnist_loss: 0.0058, d_svhn_loss: 0.0211, d_fake_loss: 0.0563, g_loss: 1.0944\n",
            "Step [19710/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0106, d_svhn_loss: 0.0373, d_fake_loss: 0.1399, g_loss: 1.4505\n",
            "Step [19720/60000], d_real_loss: 0.0585, d_mnist_loss: 0.0305, d_svhn_loss: 0.0280, d_fake_loss: 0.0552, g_loss: 0.9818\n",
            "Step [19730/60000], d_real_loss: 0.1856, d_mnist_loss: 0.0102, d_svhn_loss: 0.1753, d_fake_loss: 0.1196, g_loss: 1.2137\n",
            "Step [19740/60000], d_real_loss: 0.0785, d_mnist_loss: 0.0073, d_svhn_loss: 0.0713, d_fake_loss: 0.0367, g_loss: 1.0001\n",
            "Step [19750/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0142, d_svhn_loss: 0.0206, d_fake_loss: 0.0817, g_loss: 1.1299\n",
            "Step [19760/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0231, d_svhn_loss: 0.0244, d_fake_loss: 0.2306, g_loss: 1.1517\n",
            "Step [19770/60000], d_real_loss: 0.0434, d_mnist_loss: 0.0074, d_svhn_loss: 0.0360, d_fake_loss: 0.0727, g_loss: 0.9630\n",
            "Step [19780/60000], d_real_loss: 0.0558, d_mnist_loss: 0.0239, d_svhn_loss: 0.0320, d_fake_loss: 0.0446, g_loss: 1.0949\n",
            "Step [19790/60000], d_real_loss: 0.0498, d_mnist_loss: 0.0092, d_svhn_loss: 0.0407, d_fake_loss: 0.0496, g_loss: 1.1711\n",
            "Step [19800/60000], d_real_loss: 0.0537, d_mnist_loss: 0.0192, d_svhn_loss: 0.0345, d_fake_loss: 0.0443, g_loss: 1.3376\n",
            "Step [19810/60000], d_real_loss: 0.1613, d_mnist_loss: 0.0124, d_svhn_loss: 0.1489, d_fake_loss: 0.1344, g_loss: 1.0364\n",
            "Step [19820/60000], d_real_loss: 0.0670, d_mnist_loss: 0.0212, d_svhn_loss: 0.0458, d_fake_loss: 0.0614, g_loss: 1.0827\n",
            "Step [19830/60000], d_real_loss: 0.0801, d_mnist_loss: 0.0136, d_svhn_loss: 0.0666, d_fake_loss: 0.0600, g_loss: 1.3299\n",
            "Step [19840/60000], d_real_loss: 0.0339, d_mnist_loss: 0.0120, d_svhn_loss: 0.0219, d_fake_loss: 0.0694, g_loss: 1.3777\n",
            "Step [19850/60000], d_real_loss: 0.1932, d_mnist_loss: 0.0180, d_svhn_loss: 0.1751, d_fake_loss: 0.1297, g_loss: 1.0467\n",
            "Step [19860/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0242, d_svhn_loss: 0.0350, d_fake_loss: 0.0417, g_loss: 1.1105\n",
            "Step [19870/60000], d_real_loss: 0.0773, d_mnist_loss: 0.0095, d_svhn_loss: 0.0678, d_fake_loss: 0.0680, g_loss: 0.9341\n",
            "Step [19880/60000], d_real_loss: 0.0488, d_mnist_loss: 0.0149, d_svhn_loss: 0.0339, d_fake_loss: 0.0764, g_loss: 1.0852\n",
            "Step [19890/60000], d_real_loss: 0.0510, d_mnist_loss: 0.0193, d_svhn_loss: 0.0317, d_fake_loss: 0.1083, g_loss: 1.1600\n",
            "Step [19900/60000], d_real_loss: 0.0611, d_mnist_loss: 0.0274, d_svhn_loss: 0.0337, d_fake_loss: 0.0426, g_loss: 1.2909\n",
            "Step [19910/60000], d_real_loss: 0.1141, d_mnist_loss: 0.0751, d_svhn_loss: 0.0390, d_fake_loss: 0.0443, g_loss: 1.3377\n",
            "Step [19920/60000], d_real_loss: 0.0514, d_mnist_loss: 0.0117, d_svhn_loss: 0.0397, d_fake_loss: 0.1133, g_loss: 1.2900\n",
            "Step [19930/60000], d_real_loss: 0.0702, d_mnist_loss: 0.0419, d_svhn_loss: 0.0283, d_fake_loss: 0.0478, g_loss: 1.1696\n",
            "Step [19940/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0129, d_svhn_loss: 0.0342, d_fake_loss: 0.0395, g_loss: 1.2038\n",
            "Step [19950/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0122, d_svhn_loss: 0.0310, d_fake_loss: 0.0349, g_loss: 1.0895\n",
            "Step [19960/60000], d_real_loss: 0.0337, d_mnist_loss: 0.0120, d_svhn_loss: 0.0217, d_fake_loss: 0.0474, g_loss: 1.0365\n",
            "Step [19970/60000], d_real_loss: 0.0727, d_mnist_loss: 0.0197, d_svhn_loss: 0.0530, d_fake_loss: 0.0481, g_loss: 1.1528\n",
            "Step [19980/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0128, d_svhn_loss: 0.0327, d_fake_loss: 0.0321, g_loss: 1.2089\n",
            "Step [19990/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0144, d_svhn_loss: 0.0284, d_fake_loss: 0.0332, g_loss: 1.1850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9979177713394165]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998807907104, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [20000/60000], d_real_loss: 0.0570, d_mnist_loss: 0.0092, d_svhn_loss: 0.0478, d_fake_loss: 0.0367, g_loss: 1.1412\n",
            "saved ./samples_fashion/sample-20000-m-s.png\n",
            "saved ./samples_fashion/sample-20000-s-m.png\n",
            "Step [20010/60000], d_real_loss: 0.2481, d_mnist_loss: 0.2224, d_svhn_loss: 0.0257, d_fake_loss: 0.1200, g_loss: 1.1171\n",
            "Step [20020/60000], d_real_loss: 0.1085, d_mnist_loss: 0.0151, d_svhn_loss: 0.0934, d_fake_loss: 0.0780, g_loss: 1.2458\n",
            "Step [20030/60000], d_real_loss: 0.1344, d_mnist_loss: 0.0370, d_svhn_loss: 0.0974, d_fake_loss: 0.0862, g_loss: 1.1159\n",
            "Step [20040/60000], d_real_loss: 0.0769, d_mnist_loss: 0.0240, d_svhn_loss: 0.0529, d_fake_loss: 0.1152, g_loss: 1.2444\n",
            "Step [20050/60000], d_real_loss: 0.0804, d_mnist_loss: 0.0338, d_svhn_loss: 0.0466, d_fake_loss: 0.0458, g_loss: 1.1552\n",
            "Step [20060/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0380, d_svhn_loss: 0.0291, d_fake_loss: 0.0479, g_loss: 1.1521\n",
            "Step [20070/60000], d_real_loss: 0.0497, d_mnist_loss: 0.0159, d_svhn_loss: 0.0338, d_fake_loss: 0.0770, g_loss: 1.2681\n",
            "Step [20080/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0159, d_svhn_loss: 0.0239, d_fake_loss: 0.0431, g_loss: 1.1911\n",
            "Step [20090/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0146, d_svhn_loss: 0.0261, d_fake_loss: 0.0491, g_loss: 1.2718\n",
            "Step [20100/60000], d_real_loss: 0.0570, d_mnist_loss: 0.0285, d_svhn_loss: 0.0285, d_fake_loss: 0.0457, g_loss: 1.1542\n",
            "Step [20110/60000], d_real_loss: 0.1407, d_mnist_loss: 0.0850, d_svhn_loss: 0.0557, d_fake_loss: 0.1919, g_loss: 0.8104\n",
            "Step [20120/60000], d_real_loss: 0.0822, d_mnist_loss: 0.0612, d_svhn_loss: 0.0210, d_fake_loss: 0.0741, g_loss: 1.1574\n",
            "Step [20130/60000], d_real_loss: 0.0971, d_mnist_loss: 0.0284, d_svhn_loss: 0.0687, d_fake_loss: 0.1132, g_loss: 1.0541\n",
            "Step [20140/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0136, d_svhn_loss: 0.0394, d_fake_loss: 0.0367, g_loss: 0.9923\n",
            "Step [20150/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0068, d_svhn_loss: 0.0339, d_fake_loss: 0.0855, g_loss: 1.2361\n",
            "Step [20160/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0118, d_svhn_loss: 0.0231, d_fake_loss: 0.0413, g_loss: 1.3077\n",
            "Step [20170/60000], d_real_loss: 0.0409, d_mnist_loss: 0.0118, d_svhn_loss: 0.0291, d_fake_loss: 0.0495, g_loss: 1.1899\n",
            "Step [20180/60000], d_real_loss: 0.3971, d_mnist_loss: 0.0115, d_svhn_loss: 0.3856, d_fake_loss: 0.5640, g_loss: 1.0472\n",
            "Step [20190/60000], d_real_loss: 0.1152, d_mnist_loss: 0.0727, d_svhn_loss: 0.0425, d_fake_loss: 0.0587, g_loss: 0.9928\n",
            "Step [20200/60000], d_real_loss: 0.0383, d_mnist_loss: 0.0128, d_svhn_loss: 0.0255, d_fake_loss: 0.0558, g_loss: 1.3893\n",
            "Step [20210/60000], d_real_loss: 0.1660, d_mnist_loss: 0.1430, d_svhn_loss: 0.0230, d_fake_loss: 0.0721, g_loss: 1.4247\n",
            "Step [20220/60000], d_real_loss: 0.0742, d_mnist_loss: 0.0302, d_svhn_loss: 0.0440, d_fake_loss: 0.0930, g_loss: 1.5802\n",
            "Step [20230/60000], d_real_loss: 0.0438, d_mnist_loss: 0.0084, d_svhn_loss: 0.0353, d_fake_loss: 0.1570, g_loss: 1.1380\n",
            "Step [20240/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0093, d_svhn_loss: 0.0220, d_fake_loss: 0.0305, g_loss: 0.9855\n",
            "Step [20250/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0086, d_svhn_loss: 0.0281, d_fake_loss: 0.0329, g_loss: 0.9880\n",
            "Step [20260/60000], d_real_loss: 0.1100, d_mnist_loss: 0.0281, d_svhn_loss: 0.0819, d_fake_loss: 0.1082, g_loss: 0.9949\n",
            "Step [20270/60000], d_real_loss: 0.1139, d_mnist_loss: 0.0395, d_svhn_loss: 0.0744, d_fake_loss: 0.0962, g_loss: 1.1761\n",
            "Step [20280/60000], d_real_loss: 0.0580, d_mnist_loss: 0.0266, d_svhn_loss: 0.0314, d_fake_loss: 0.0333, g_loss: 1.1130\n",
            "Step [20290/60000], d_real_loss: 0.0800, d_mnist_loss: 0.0135, d_svhn_loss: 0.0666, d_fake_loss: 0.0971, g_loss: 1.2509\n",
            "Step [20300/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0086, d_svhn_loss: 0.0279, d_fake_loss: 0.0438, g_loss: 1.1332\n",
            "Step [20310/60000], d_real_loss: 0.0858, d_mnist_loss: 0.0409, d_svhn_loss: 0.0449, d_fake_loss: 0.0611, g_loss: 1.0523\n",
            "Step [20320/60000], d_real_loss: 0.0495, d_mnist_loss: 0.0165, d_svhn_loss: 0.0330, d_fake_loss: 0.1485, g_loss: 1.1632\n",
            "Step [20330/60000], d_real_loss: 0.1468, d_mnist_loss: 0.0128, d_svhn_loss: 0.1340, d_fake_loss: 0.2698, g_loss: 1.2636\n",
            "Step [20340/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0150, d_svhn_loss: 0.0203, d_fake_loss: 0.0797, g_loss: 0.6970\n",
            "Step [20350/60000], d_real_loss: 0.0588, d_mnist_loss: 0.0193, d_svhn_loss: 0.0395, d_fake_loss: 0.0493, g_loss: 1.0169\n",
            "Step [20360/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0086, d_svhn_loss: 0.0296, d_fake_loss: 0.0534, g_loss: 0.9306\n",
            "Step [20370/60000], d_real_loss: 0.0511, d_mnist_loss: 0.0146, d_svhn_loss: 0.0365, d_fake_loss: 0.0417, g_loss: 1.0876\n",
            "Step [20380/60000], d_real_loss: 0.0461, d_mnist_loss: 0.0114, d_svhn_loss: 0.0347, d_fake_loss: 0.1250, g_loss: 1.1902\n",
            "Step [20390/60000], d_real_loss: 0.0873, d_mnist_loss: 0.0225, d_svhn_loss: 0.0647, d_fake_loss: 0.0682, g_loss: 0.9703\n",
            "Step [20400/60000], d_real_loss: 0.0553, d_mnist_loss: 0.0115, d_svhn_loss: 0.0438, d_fake_loss: 0.0527, g_loss: 1.1788\n",
            "Step [20410/60000], d_real_loss: 0.1108, d_mnist_loss: 0.0074, d_svhn_loss: 0.1034, d_fake_loss: 0.1006, g_loss: 1.1425\n",
            "Step [20420/60000], d_real_loss: 0.0454, d_mnist_loss: 0.0207, d_svhn_loss: 0.0247, d_fake_loss: 0.0579, g_loss: 0.9585\n",
            "Step [20430/60000], d_real_loss: 0.1341, d_mnist_loss: 0.0262, d_svhn_loss: 0.1079, d_fake_loss: 0.0759, g_loss: 1.0835\n",
            "Step [20440/60000], d_real_loss: 0.0970, d_mnist_loss: 0.0388, d_svhn_loss: 0.0582, d_fake_loss: 0.0679, g_loss: 1.1646\n",
            "Step [20450/60000], d_real_loss: 0.1255, d_mnist_loss: 0.0319, d_svhn_loss: 0.0936, d_fake_loss: 0.0381, g_loss: 1.1152\n",
            "Step [20460/60000], d_real_loss: 0.0521, d_mnist_loss: 0.0228, d_svhn_loss: 0.0293, d_fake_loss: 0.1955, g_loss: 0.9037\n",
            "Step [20470/60000], d_real_loss: 0.1014, d_mnist_loss: 0.0730, d_svhn_loss: 0.0284, d_fake_loss: 0.0574, g_loss: 1.4815\n",
            "Step [20480/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0194, d_svhn_loss: 0.0212, d_fake_loss: 0.1428, g_loss: 1.0127\n",
            "Step [20490/60000], d_real_loss: 0.1341, d_mnist_loss: 0.0873, d_svhn_loss: 0.0468, d_fake_loss: 0.0523, g_loss: 1.5856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9963871240615845]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [20500/60000], d_real_loss: 0.1460, d_mnist_loss: 0.0131, d_svhn_loss: 0.1330, d_fake_loss: 0.1806, g_loss: 1.1945\n",
            "saved ./samples_fashion/sample-20500-m-s.png\n",
            "saved ./samples_fashion/sample-20500-s-m.png\n",
            "Step [20510/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0128, d_svhn_loss: 0.0478, d_fake_loss: 0.1387, g_loss: 1.4582\n",
            "Step [20520/60000], d_real_loss: 0.0698, d_mnist_loss: 0.0476, d_svhn_loss: 0.0222, d_fake_loss: 0.1664, g_loss: 0.7088\n",
            "Step [20530/60000], d_real_loss: 0.1016, d_mnist_loss: 0.0114, d_svhn_loss: 0.0902, d_fake_loss: 0.2787, g_loss: 1.1007\n",
            "Step [20540/60000], d_real_loss: 0.0506, d_mnist_loss: 0.0183, d_svhn_loss: 0.0323, d_fake_loss: 0.0321, g_loss: 0.9924\n",
            "Step [20550/60000], d_real_loss: 0.1223, d_mnist_loss: 0.0162, d_svhn_loss: 0.1061, d_fake_loss: 0.0882, g_loss: 1.1976\n",
            "Step [20560/60000], d_real_loss: 0.0777, d_mnist_loss: 0.0103, d_svhn_loss: 0.0674, d_fake_loss: 0.0880, g_loss: 1.2723\n",
            "Step [20570/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0173, d_svhn_loss: 0.0194, d_fake_loss: 0.1459, g_loss: 1.0842\n",
            "Step [20580/60000], d_real_loss: 0.0625, d_mnist_loss: 0.0280, d_svhn_loss: 0.0346, d_fake_loss: 0.0638, g_loss: 1.0865\n",
            "Step [20590/60000], d_real_loss: 0.1144, d_mnist_loss: 0.0092, d_svhn_loss: 0.1052, d_fake_loss: 0.0661, g_loss: 1.3499\n",
            "Step [20600/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0124, d_svhn_loss: 0.0218, d_fake_loss: 0.0580, g_loss: 1.1844\n",
            "Step [20610/60000], d_real_loss: 0.0556, d_mnist_loss: 0.0114, d_svhn_loss: 0.0442, d_fake_loss: 0.0413, g_loss: 1.2648\n",
            "Step [20620/60000], d_real_loss: 0.0726, d_mnist_loss: 0.0182, d_svhn_loss: 0.0544, d_fake_loss: 0.0620, g_loss: 1.3756\n",
            "Step [20630/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0183, d_svhn_loss: 0.0336, d_fake_loss: 0.1248, g_loss: 1.1712\n",
            "Step [20640/60000], d_real_loss: 0.0413, d_mnist_loss: 0.0142, d_svhn_loss: 0.0271, d_fake_loss: 0.0591, g_loss: 1.0532\n",
            "Step [20650/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0195, d_svhn_loss: 0.0242, d_fake_loss: 0.0335, g_loss: 1.0453\n",
            "Step [20660/60000], d_real_loss: 0.1081, d_mnist_loss: 0.0188, d_svhn_loss: 0.0892, d_fake_loss: 0.1397, g_loss: 1.1432\n",
            "Step [20670/60000], d_real_loss: 0.1931, d_mnist_loss: 0.1027, d_svhn_loss: 0.0904, d_fake_loss: 0.1576, g_loss: 1.6226\n",
            "Step [20680/60000], d_real_loss: 0.0481, d_mnist_loss: 0.0197, d_svhn_loss: 0.0284, d_fake_loss: 0.1189, g_loss: 1.3231\n",
            "Step [20690/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0165, d_svhn_loss: 0.0375, d_fake_loss: 0.0962, g_loss: 0.9031\n",
            "Step [20700/60000], d_real_loss: 0.0711, d_mnist_loss: 0.0125, d_svhn_loss: 0.0586, d_fake_loss: 0.0278, g_loss: 1.1419\n",
            "Step [20710/60000], d_real_loss: 0.0563, d_mnist_loss: 0.0107, d_svhn_loss: 0.0457, d_fake_loss: 0.1481, g_loss: 1.1452\n",
            "Step [20720/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0093, d_svhn_loss: 0.0259, d_fake_loss: 0.0915, g_loss: 0.9659\n",
            "Step [20730/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0145, d_svhn_loss: 0.0207, d_fake_loss: 0.0522, g_loss: 1.2335\n",
            "Step [20740/60000], d_real_loss: 0.1040, d_mnist_loss: 0.0768, d_svhn_loss: 0.0273, d_fake_loss: 0.0994, g_loss: 1.4990\n",
            "Step [20750/60000], d_real_loss: 0.0469, d_mnist_loss: 0.0262, d_svhn_loss: 0.0207, d_fake_loss: 0.0430, g_loss: 1.1452\n",
            "Step [20760/60000], d_real_loss: 0.0711, d_mnist_loss: 0.0524, d_svhn_loss: 0.0187, d_fake_loss: 0.0436, g_loss: 1.0721\n",
            "Step [20770/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0127, d_svhn_loss: 0.0280, d_fake_loss: 0.0362, g_loss: 1.1556\n",
            "Step [20780/60000], d_real_loss: 0.0815, d_mnist_loss: 0.0435, d_svhn_loss: 0.0380, d_fake_loss: 0.0518, g_loss: 1.1680\n",
            "Step [20790/60000], d_real_loss: 0.0954, d_mnist_loss: 0.0612, d_svhn_loss: 0.0343, d_fake_loss: 0.0342, g_loss: 0.9138\n",
            "Step [20800/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0135, d_svhn_loss: 0.0269, d_fake_loss: 0.0564, g_loss: 1.1608\n",
            "Step [20810/60000], d_real_loss: 0.0598, d_mnist_loss: 0.0175, d_svhn_loss: 0.0423, d_fake_loss: 0.0433, g_loss: 1.1836\n",
            "Step [20820/60000], d_real_loss: 0.0821, d_mnist_loss: 0.0392, d_svhn_loss: 0.0429, d_fake_loss: 0.0418, g_loss: 1.0398\n",
            "Step [20830/60000], d_real_loss: 0.0660, d_mnist_loss: 0.0322, d_svhn_loss: 0.0338, d_fake_loss: 0.0318, g_loss: 1.0669\n",
            "Step [20840/60000], d_real_loss: 0.1776, d_mnist_loss: 0.0271, d_svhn_loss: 0.1505, d_fake_loss: 0.4033, g_loss: 1.0368\n",
            "Step [20850/60000], d_real_loss: 0.0681, d_mnist_loss: 0.0102, d_svhn_loss: 0.0578, d_fake_loss: 0.0415, g_loss: 1.0083\n",
            "Step [20860/60000], d_real_loss: 0.0502, d_mnist_loss: 0.0234, d_svhn_loss: 0.0268, d_fake_loss: 0.0733, g_loss: 0.8410\n",
            "Step [20870/60000], d_real_loss: 0.1070, d_mnist_loss: 0.0651, d_svhn_loss: 0.0419, d_fake_loss: 0.1437, g_loss: 1.3447\n",
            "Step [20880/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0152, d_svhn_loss: 0.0287, d_fake_loss: 0.0717, g_loss: 1.2211\n",
            "Step [20890/60000], d_real_loss: 0.0633, d_mnist_loss: 0.0130, d_svhn_loss: 0.0503, d_fake_loss: 0.0592, g_loss: 1.1548\n",
            "Step [20900/60000], d_real_loss: 0.1319, d_mnist_loss: 0.0101, d_svhn_loss: 0.1218, d_fake_loss: 0.0667, g_loss: 0.9936\n",
            "Step [20910/60000], d_real_loss: 0.0644, d_mnist_loss: 0.0135, d_svhn_loss: 0.0508, d_fake_loss: 0.1557, g_loss: 1.2656\n",
            "Step [20920/60000], d_real_loss: 0.0842, d_mnist_loss: 0.0098, d_svhn_loss: 0.0744, d_fake_loss: 0.0546, g_loss: 1.1711\n",
            "Step [20930/60000], d_real_loss: 0.0386, d_mnist_loss: 0.0123, d_svhn_loss: 0.0263, d_fake_loss: 0.0824, g_loss: 1.1864\n",
            "Step [20940/60000], d_real_loss: 0.0757, d_mnist_loss: 0.0302, d_svhn_loss: 0.0455, d_fake_loss: 0.1008, g_loss: 1.2600\n",
            "Step [20950/60000], d_real_loss: 0.0497, d_mnist_loss: 0.0117, d_svhn_loss: 0.0379, d_fake_loss: 0.0346, g_loss: 1.0045\n",
            "Step [20960/60000], d_real_loss: 0.1413, d_mnist_loss: 0.0528, d_svhn_loss: 0.0885, d_fake_loss: 0.0564, g_loss: 0.9414\n",
            "Step [20970/60000], d_real_loss: 0.0445, d_mnist_loss: 0.0250, d_svhn_loss: 0.0195, d_fake_loss: 0.0292, g_loss: 1.2699\n",
            "Step [20980/60000], d_real_loss: 0.0494, d_mnist_loss: 0.0116, d_svhn_loss: 0.0379, d_fake_loss: 0.1060, g_loss: 0.9923\n",
            "Step [20990/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0204, d_svhn_loss: 0.0393, d_fake_loss: 0.1837, g_loss: 0.8572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.999060332775116]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [21000/60000], d_real_loss: 0.0456, d_mnist_loss: 0.0129, d_svhn_loss: 0.0327, d_fake_loss: 0.0889, g_loss: 0.9532\n",
            "saved ./samples_fashion/sample-21000-m-s.png\n",
            "saved ./samples_fashion/sample-21000-s-m.png\n",
            "Step [21010/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0196, d_svhn_loss: 0.0246, d_fake_loss: 0.0376, g_loss: 1.0070\n",
            "Step [21020/60000], d_real_loss: 0.0702, d_mnist_loss: 0.0443, d_svhn_loss: 0.0258, d_fake_loss: 0.0353, g_loss: 0.9249\n",
            "Step [21030/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0177, d_svhn_loss: 0.0206, d_fake_loss: 0.0579, g_loss: 1.1544\n",
            "Step [21040/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0226, d_svhn_loss: 0.0509, d_fake_loss: 0.0621, g_loss: 1.2104\n",
            "Step [21050/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0151, d_svhn_loss: 0.0213, d_fake_loss: 0.0363, g_loss: 1.3280\n",
            "Step [21060/60000], d_real_loss: 0.0767, d_mnist_loss: 0.0177, d_svhn_loss: 0.0590, d_fake_loss: 0.0640, g_loss: 1.1545\n",
            "Step [21070/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0190, d_svhn_loss: 0.0285, d_fake_loss: 0.0573, g_loss: 1.0977\n",
            "Step [21080/60000], d_real_loss: 0.0925, d_mnist_loss: 0.0737, d_svhn_loss: 0.0188, d_fake_loss: 0.0402, g_loss: 1.1725\n",
            "Step [21090/60000], d_real_loss: 0.0333, d_mnist_loss: 0.0087, d_svhn_loss: 0.0246, d_fake_loss: 0.0581, g_loss: 1.1933\n",
            "Step [21100/60000], d_real_loss: 0.0915, d_mnist_loss: 0.0113, d_svhn_loss: 0.0802, d_fake_loss: 0.0294, g_loss: 1.1745\n",
            "Step [21110/60000], d_real_loss: 0.0345, d_mnist_loss: 0.0151, d_svhn_loss: 0.0194, d_fake_loss: 0.0375, g_loss: 1.0223\n",
            "Step [21120/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0130, d_svhn_loss: 0.0261, d_fake_loss: 0.0353, g_loss: 1.0109\n",
            "Step [21130/60000], d_real_loss: 0.1006, d_mnist_loss: 0.0748, d_svhn_loss: 0.0258, d_fake_loss: 0.0295, g_loss: 1.0645\n",
            "Step [21140/60000], d_real_loss: 0.0462, d_mnist_loss: 0.0113, d_svhn_loss: 0.0349, d_fake_loss: 0.0568, g_loss: 1.1944\n",
            "Step [21150/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0274, d_svhn_loss: 0.0332, d_fake_loss: 0.0332, g_loss: 1.2226\n",
            "Step [21160/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0192, d_svhn_loss: 0.0201, d_fake_loss: 0.0784, g_loss: 1.1253\n",
            "Step [21170/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0181, d_svhn_loss: 0.0184, d_fake_loss: 0.0316, g_loss: 1.1818\n",
            "Step [21180/60000], d_real_loss: 0.0625, d_mnist_loss: 0.0232, d_svhn_loss: 0.0394, d_fake_loss: 0.1631, g_loss: 0.8270\n",
            "Step [21190/60000], d_real_loss: 0.0853, d_mnist_loss: 0.0201, d_svhn_loss: 0.0652, d_fake_loss: 0.0494, g_loss: 1.0400\n",
            "Step [21200/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0261, d_svhn_loss: 0.0311, d_fake_loss: 0.0612, g_loss: 1.1301\n",
            "Step [21210/60000], d_real_loss: 0.2050, d_mnist_loss: 0.0148, d_svhn_loss: 0.1902, d_fake_loss: 0.1320, g_loss: 1.3251\n",
            "Step [21220/60000], d_real_loss: 0.1026, d_mnist_loss: 0.0515, d_svhn_loss: 0.0512, d_fake_loss: 0.1150, g_loss: 1.3317\n",
            "Step [21230/60000], d_real_loss: 0.0616, d_mnist_loss: 0.0169, d_svhn_loss: 0.0446, d_fake_loss: 0.1191, g_loss: 1.1482\n",
            "Step [21240/60000], d_real_loss: 0.1618, d_mnist_loss: 0.0980, d_svhn_loss: 0.0638, d_fake_loss: 0.0662, g_loss: 1.0768\n",
            "Step [21250/60000], d_real_loss: 0.0632, d_mnist_loss: 0.0145, d_svhn_loss: 0.0486, d_fake_loss: 0.0345, g_loss: 1.1807\n",
            "Step [21260/60000], d_real_loss: 0.0384, d_mnist_loss: 0.0157, d_svhn_loss: 0.0227, d_fake_loss: 0.0634, g_loss: 1.0651\n",
            "Step [21270/60000], d_real_loss: 0.0422, d_mnist_loss: 0.0191, d_svhn_loss: 0.0231, d_fake_loss: 0.0621, g_loss: 1.0484\n",
            "Step [21280/60000], d_real_loss: 0.0291, d_mnist_loss: 0.0112, d_svhn_loss: 0.0179, d_fake_loss: 0.0668, g_loss: 0.9895\n",
            "Step [21290/60000], d_real_loss: 0.1991, d_mnist_loss: 0.1463, d_svhn_loss: 0.0528, d_fake_loss: 0.2017, g_loss: 1.1002\n",
            "Step [21300/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0130, d_svhn_loss: 0.0197, d_fake_loss: 0.0537, g_loss: 1.0477\n",
            "Step [21310/60000], d_real_loss: 0.1726, d_mnist_loss: 0.0097, d_svhn_loss: 0.1629, d_fake_loss: 0.0512, g_loss: 0.9877\n",
            "Step [21320/60000], d_real_loss: 0.1094, d_mnist_loss: 0.0165, d_svhn_loss: 0.0929, d_fake_loss: 0.0693, g_loss: 1.4957\n",
            "Step [21330/60000], d_real_loss: 0.1838, d_mnist_loss: 0.1529, d_svhn_loss: 0.0308, d_fake_loss: 0.0485, g_loss: 1.2349\n",
            "Step [21340/60000], d_real_loss: 0.0488, d_mnist_loss: 0.0283, d_svhn_loss: 0.0206, d_fake_loss: 0.0389, g_loss: 1.0635\n",
            "Step [21350/60000], d_real_loss: 0.0538, d_mnist_loss: 0.0243, d_svhn_loss: 0.0295, d_fake_loss: 0.1461, g_loss: 1.0819\n",
            "Step [21360/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0122, d_svhn_loss: 0.0305, d_fake_loss: 0.0439, g_loss: 1.0536\n",
            "Step [21370/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0120, d_svhn_loss: 0.0228, d_fake_loss: 0.0479, g_loss: 1.1682\n",
            "Step [21380/60000], d_real_loss: 0.0709, d_mnist_loss: 0.0396, d_svhn_loss: 0.0313, d_fake_loss: 0.0476, g_loss: 1.1345\n",
            "Step [21390/60000], d_real_loss: 0.0823, d_mnist_loss: 0.0659, d_svhn_loss: 0.0164, d_fake_loss: 0.0734, g_loss: 1.2474\n",
            "Step [21400/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0258, d_svhn_loss: 0.0330, d_fake_loss: 0.0460, g_loss: 1.1206\n",
            "Step [21410/60000], d_real_loss: 0.0494, d_mnist_loss: 0.0182, d_svhn_loss: 0.0311, d_fake_loss: 0.0418, g_loss: 1.2616\n",
            "Step [21420/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0115, d_svhn_loss: 0.0258, d_fake_loss: 0.0306, g_loss: 1.2127\n",
            "Step [21430/60000], d_real_loss: 0.0753, d_mnist_loss: 0.0268, d_svhn_loss: 0.0484, d_fake_loss: 0.0547, g_loss: 1.0802\n",
            "Step [21440/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0136, d_svhn_loss: 0.0267, d_fake_loss: 0.5832, g_loss: 1.8642\n",
            "Step [21450/60000], d_real_loss: 0.0995, d_mnist_loss: 0.0152, d_svhn_loss: 0.0842, d_fake_loss: 0.0465, g_loss: 1.0725\n",
            "Step [21460/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0162, d_svhn_loss: 0.0312, d_fake_loss: 0.0433, g_loss: 1.1072\n",
            "Step [21470/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0132, d_svhn_loss: 0.0352, d_fake_loss: 0.0532, g_loss: 0.9343\n",
            "Step [21480/60000], d_real_loss: 0.0577, d_mnist_loss: 0.0125, d_svhn_loss: 0.0451, d_fake_loss: 0.0734, g_loss: 1.1320\n",
            "Step [21490/60000], d_real_loss: 0.3668, d_mnist_loss: 0.0096, d_svhn_loss: 0.3571, d_fake_loss: 0.0396, g_loss: 1.1287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9941105246543884]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [21500/60000], d_real_loss: 0.0718, d_mnist_loss: 0.0166, d_svhn_loss: 0.0552, d_fake_loss: 0.0466, g_loss: 1.1092\n",
            "saved ./samples_fashion/sample-21500-m-s.png\n",
            "saved ./samples_fashion/sample-21500-s-m.png\n",
            "Step [21510/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0210, d_svhn_loss: 0.0330, d_fake_loss: 0.0538, g_loss: 1.1745\n",
            "Step [21520/60000], d_real_loss: 0.1135, d_mnist_loss: 0.0170, d_svhn_loss: 0.0965, d_fake_loss: 0.1474, g_loss: 1.2367\n",
            "Step [21530/60000], d_real_loss: 0.0534, d_mnist_loss: 0.0151, d_svhn_loss: 0.0383, d_fake_loss: 0.0419, g_loss: 1.1303\n",
            "Step [21540/60000], d_real_loss: 0.0598, d_mnist_loss: 0.0314, d_svhn_loss: 0.0284, d_fake_loss: 0.0751, g_loss: 1.4149\n",
            "Step [21550/60000], d_real_loss: 0.0885, d_mnist_loss: 0.0256, d_svhn_loss: 0.0629, d_fake_loss: 0.0272, g_loss: 1.2761\n",
            "Step [21560/60000], d_real_loss: 0.0686, d_mnist_loss: 0.0091, d_svhn_loss: 0.0595, d_fake_loss: 0.1244, g_loss: 1.3398\n",
            "Step [21570/60000], d_real_loss: 0.2910, d_mnist_loss: 0.2665, d_svhn_loss: 0.0245, d_fake_loss: 0.1240, g_loss: 1.9992\n",
            "Step [21580/60000], d_real_loss: 0.0710, d_mnist_loss: 0.0336, d_svhn_loss: 0.0374, d_fake_loss: 0.1223, g_loss: 1.2580\n",
            "Step [21590/60000], d_real_loss: 0.0648, d_mnist_loss: 0.0197, d_svhn_loss: 0.0451, d_fake_loss: 0.0998, g_loss: 0.9947\n",
            "Step [21600/60000], d_real_loss: 0.0938, d_mnist_loss: 0.0142, d_svhn_loss: 0.0796, d_fake_loss: 0.0448, g_loss: 1.1165\n",
            "Step [21610/60000], d_real_loss: 0.0430, d_mnist_loss: 0.0087, d_svhn_loss: 0.0342, d_fake_loss: 0.0356, g_loss: 1.1264\n",
            "Step [21620/60000], d_real_loss: 0.0914, d_mnist_loss: 0.0233, d_svhn_loss: 0.0681, d_fake_loss: 0.0540, g_loss: 0.9150\n",
            "Step [21630/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0194, d_svhn_loss: 0.0404, d_fake_loss: 0.0966, g_loss: 1.1126\n",
            "Step [21640/60000], d_real_loss: 0.0880, d_mnist_loss: 0.0530, d_svhn_loss: 0.0350, d_fake_loss: 0.0302, g_loss: 1.0436\n",
            "Step [21650/60000], d_real_loss: 0.0331, d_mnist_loss: 0.0120, d_svhn_loss: 0.0210, d_fake_loss: 0.0654, g_loss: 1.3026\n",
            "Step [21660/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0118, d_svhn_loss: 0.0204, d_fake_loss: 0.1285, g_loss: 1.2661\n",
            "Step [21670/60000], d_real_loss: 0.0623, d_mnist_loss: 0.0309, d_svhn_loss: 0.0313, d_fake_loss: 0.0711, g_loss: 0.9955\n",
            "Step [21680/60000], d_real_loss: 0.0790, d_mnist_loss: 0.0115, d_svhn_loss: 0.0675, d_fake_loss: 0.1667, g_loss: 1.4366\n",
            "Step [21690/60000], d_real_loss: 0.2134, d_mnist_loss: 0.1170, d_svhn_loss: 0.0964, d_fake_loss: 0.0486, g_loss: 1.3005\n",
            "Step [21700/60000], d_real_loss: 0.0356, d_mnist_loss: 0.0112, d_svhn_loss: 0.0244, d_fake_loss: 0.0435, g_loss: 1.3894\n",
            "Step [21710/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0118, d_svhn_loss: 0.0229, d_fake_loss: 0.0559, g_loss: 1.1237\n",
            "Step [21720/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0147, d_svhn_loss: 0.0221, d_fake_loss: 0.0545, g_loss: 1.1863\n",
            "Step [21730/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0146, d_svhn_loss: 0.0256, d_fake_loss: 0.0631, g_loss: 1.1528\n",
            "Step [21740/60000], d_real_loss: 0.0732, d_mnist_loss: 0.0272, d_svhn_loss: 0.0459, d_fake_loss: 0.0450, g_loss: 1.0847\n",
            "Step [21750/60000], d_real_loss: 0.1118, d_mnist_loss: 0.0195, d_svhn_loss: 0.0923, d_fake_loss: 0.2659, g_loss: 1.0376\n",
            "Step [21760/60000], d_real_loss: 0.0752, d_mnist_loss: 0.0426, d_svhn_loss: 0.0326, d_fake_loss: 0.0569, g_loss: 1.2164\n",
            "Step [21770/60000], d_real_loss: 0.0541, d_mnist_loss: 0.0121, d_svhn_loss: 0.0420, d_fake_loss: 0.0697, g_loss: 1.1176\n",
            "Step [21780/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0130, d_svhn_loss: 0.0234, d_fake_loss: 0.0592, g_loss: 1.1506\n",
            "Step [21790/60000], d_real_loss: 0.0719, d_mnist_loss: 0.0221, d_svhn_loss: 0.0498, d_fake_loss: 0.0753, g_loss: 1.1007\n",
            "Step [21800/60000], d_real_loss: 0.0293, d_mnist_loss: 0.0088, d_svhn_loss: 0.0205, d_fake_loss: 0.0454, g_loss: 1.1822\n",
            "Step [21810/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0163, d_svhn_loss: 0.0372, d_fake_loss: 0.0325, g_loss: 1.0659\n",
            "Step [21820/60000], d_real_loss: 0.0522, d_mnist_loss: 0.0138, d_svhn_loss: 0.0384, d_fake_loss: 0.1361, g_loss: 1.1655\n",
            "Step [21830/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0147, d_svhn_loss: 0.0296, d_fake_loss: 0.0355, g_loss: 1.1958\n",
            "Step [21840/60000], d_real_loss: 0.0541, d_mnist_loss: 0.0081, d_svhn_loss: 0.0460, d_fake_loss: 0.0764, g_loss: 1.2191\n",
            "Step [21850/60000], d_real_loss: 0.0321, d_mnist_loss: 0.0105, d_svhn_loss: 0.0216, d_fake_loss: 0.0529, g_loss: 1.0865\n",
            "Step [21860/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0123, d_svhn_loss: 0.0548, d_fake_loss: 0.0217, g_loss: 1.1588\n",
            "Step [21870/60000], d_real_loss: 0.0633, d_mnist_loss: 0.0152, d_svhn_loss: 0.0481, d_fake_loss: 0.0631, g_loss: 1.1796\n",
            "Step [21880/60000], d_real_loss: 0.0716, d_mnist_loss: 0.0437, d_svhn_loss: 0.0279, d_fake_loss: 0.0531, g_loss: 1.0459\n",
            "Step [21890/60000], d_real_loss: 0.0952, d_mnist_loss: 0.0609, d_svhn_loss: 0.0343, d_fake_loss: 0.1123, g_loss: 0.9689\n",
            "Step [21900/60000], d_real_loss: 0.0525, d_mnist_loss: 0.0345, d_svhn_loss: 0.0179, d_fake_loss: 0.0683, g_loss: 1.1424\n",
            "Step [21910/60000], d_real_loss: 0.0681, d_mnist_loss: 0.0492, d_svhn_loss: 0.0189, d_fake_loss: 0.0416, g_loss: 1.1763\n",
            "Step [21920/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0157, d_svhn_loss: 0.0211, d_fake_loss: 0.1101, g_loss: 1.0945\n",
            "Step [21930/60000], d_real_loss: 0.0411, d_mnist_loss: 0.0149, d_svhn_loss: 0.0261, d_fake_loss: 0.0463, g_loss: 1.1782\n",
            "Step [21940/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0080, d_svhn_loss: 0.0273, d_fake_loss: 0.0330, g_loss: 1.2555\n",
            "Step [21950/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0139, d_svhn_loss: 0.0179, d_fake_loss: 0.0451, g_loss: 1.1160\n",
            "Step [21960/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0134, d_svhn_loss: 0.0242, d_fake_loss: 0.0800, g_loss: 1.2233\n",
            "Step [21970/60000], d_real_loss: 0.0370, d_mnist_loss: 0.0233, d_svhn_loss: 0.0137, d_fake_loss: 0.0284, g_loss: 1.0017\n",
            "Step [21980/60000], d_real_loss: 0.1964, d_mnist_loss: 0.0918, d_svhn_loss: 0.1046, d_fake_loss: 0.2482, g_loss: 1.7861\n",
            "Step [21990/60000], d_real_loss: 0.0325, d_mnist_loss: 0.0085, d_svhn_loss: 0.0240, d_fake_loss: 0.0264, g_loss: 1.1135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.994019091129303]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998211860657, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [22000/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0229, d_svhn_loss: 0.0443, d_fake_loss: 0.0693, g_loss: 1.1665\n",
            "saved ./samples_fashion/sample-22000-m-s.png\n",
            "saved ./samples_fashion/sample-22000-s-m.png\n",
            "Step [22010/60000], d_real_loss: 0.0689, d_mnist_loss: 0.0153, d_svhn_loss: 0.0536, d_fake_loss: 0.0468, g_loss: 1.2259\n",
            "Step [22020/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0102, d_svhn_loss: 0.0463, d_fake_loss: 0.0446, g_loss: 1.2882\n",
            "Step [22030/60000], d_real_loss: 0.2154, d_mnist_loss: 0.0187, d_svhn_loss: 0.1967, d_fake_loss: 0.0800, g_loss: 0.9110\n",
            "Step [22040/60000], d_real_loss: 0.2070, d_mnist_loss: 0.0428, d_svhn_loss: 0.1642, d_fake_loss: 0.3296, g_loss: 1.0193\n",
            "Step [22050/60000], d_real_loss: 0.0412, d_mnist_loss: 0.0146, d_svhn_loss: 0.0265, d_fake_loss: 0.0832, g_loss: 1.0303\n",
            "Step [22060/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0155, d_svhn_loss: 0.0266, d_fake_loss: 0.1184, g_loss: 0.5303\n",
            "Step [22070/60000], d_real_loss: 0.0334, d_mnist_loss: 0.0138, d_svhn_loss: 0.0196, d_fake_loss: 0.0589, g_loss: 1.1434\n",
            "Step [22080/60000], d_real_loss: 0.0638, d_mnist_loss: 0.0157, d_svhn_loss: 0.0481, d_fake_loss: 0.0550, g_loss: 0.9657\n",
            "Step [22090/60000], d_real_loss: 0.0711, d_mnist_loss: 0.0074, d_svhn_loss: 0.0637, d_fake_loss: 0.0832, g_loss: 1.3435\n",
            "Step [22100/60000], d_real_loss: 0.1333, d_mnist_loss: 0.0109, d_svhn_loss: 0.1224, d_fake_loss: 0.0808, g_loss: 1.2335\n",
            "Step [22110/60000], d_real_loss: 0.0506, d_mnist_loss: 0.0208, d_svhn_loss: 0.0299, d_fake_loss: 0.0334, g_loss: 1.1150\n",
            "Step [22120/60000], d_real_loss: 0.1199, d_mnist_loss: 0.0347, d_svhn_loss: 0.0853, d_fake_loss: 0.0419, g_loss: 0.9566\n",
            "Step [22130/60000], d_real_loss: 0.0429, d_mnist_loss: 0.0139, d_svhn_loss: 0.0290, d_fake_loss: 0.1081, g_loss: 1.2806\n",
            "Step [22140/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0115, d_svhn_loss: 0.0420, d_fake_loss: 0.0854, g_loss: 1.3294\n",
            "Step [22150/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0333, d_svhn_loss: 0.0337, d_fake_loss: 0.0569, g_loss: 1.0161\n",
            "Step [22160/60000], d_real_loss: 0.0762, d_mnist_loss: 0.0383, d_svhn_loss: 0.0379, d_fake_loss: 0.0331, g_loss: 1.1344\n",
            "Step [22170/60000], d_real_loss: 0.1101, d_mnist_loss: 0.0306, d_svhn_loss: 0.0794, d_fake_loss: 0.0380, g_loss: 0.9713\n",
            "Step [22180/60000], d_real_loss: 0.2334, d_mnist_loss: 0.1014, d_svhn_loss: 0.1320, d_fake_loss: 0.0545, g_loss: 1.0461\n",
            "Step [22190/60000], d_real_loss: 0.0477, d_mnist_loss: 0.0160, d_svhn_loss: 0.0317, d_fake_loss: 0.0625, g_loss: 1.0738\n",
            "Step [22200/60000], d_real_loss: 0.1083, d_mnist_loss: 0.0811, d_svhn_loss: 0.0271, d_fake_loss: 0.0296, g_loss: 0.9842\n",
            "Step [22210/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0097, d_svhn_loss: 0.0322, d_fake_loss: 0.0376, g_loss: 1.0748\n",
            "Step [22220/60000], d_real_loss: 0.0486, d_mnist_loss: 0.0280, d_svhn_loss: 0.0206, d_fake_loss: 0.0284, g_loss: 1.1114\n",
            "Step [22230/60000], d_real_loss: 0.0315, d_mnist_loss: 0.0134, d_svhn_loss: 0.0181, d_fake_loss: 0.0284, g_loss: 1.0096\n",
            "Step [22240/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0123, d_svhn_loss: 0.0465, d_fake_loss: 0.0286, g_loss: 0.9366\n",
            "Step [22250/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0418, d_svhn_loss: 0.0253, d_fake_loss: 0.1217, g_loss: 1.1136\n",
            "Step [22260/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0099, d_svhn_loss: 0.0385, d_fake_loss: 0.0682, g_loss: 1.0311\n",
            "Step [22270/60000], d_real_loss: 0.2087, d_mnist_loss: 0.0109, d_svhn_loss: 0.1977, d_fake_loss: 0.0690, g_loss: 1.0473\n",
            "Step [22280/60000], d_real_loss: 0.0841, d_mnist_loss: 0.0577, d_svhn_loss: 0.0263, d_fake_loss: 0.0525, g_loss: 1.3534\n",
            "Step [22290/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0082, d_svhn_loss: 0.0240, d_fake_loss: 0.0501, g_loss: 1.3743\n",
            "Step [22300/60000], d_real_loss: 0.1836, d_mnist_loss: 0.0164, d_svhn_loss: 0.1673, d_fake_loss: 0.1447, g_loss: 1.3270\n",
            "Step [22310/60000], d_real_loss: 0.0870, d_mnist_loss: 0.0154, d_svhn_loss: 0.0716, d_fake_loss: 0.0351, g_loss: 1.1390\n",
            "Step [22320/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0105, d_svhn_loss: 0.0221, d_fake_loss: 0.0589, g_loss: 1.0490\n",
            "Step [22330/60000], d_real_loss: 0.1042, d_mnist_loss: 0.0387, d_svhn_loss: 0.0655, d_fake_loss: 0.0993, g_loss: 1.3402\n",
            "Step [22340/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0150, d_svhn_loss: 0.0226, d_fake_loss: 0.1025, g_loss: 1.2006\n",
            "Step [22350/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0135, d_svhn_loss: 0.0214, d_fake_loss: 0.0278, g_loss: 0.9705\n",
            "Step [22360/60000], d_real_loss: 0.1165, d_mnist_loss: 0.0524, d_svhn_loss: 0.0641, d_fake_loss: 0.0508, g_loss: 1.3798\n",
            "Step [22370/60000], d_real_loss: 0.0472, d_mnist_loss: 0.0127, d_svhn_loss: 0.0345, d_fake_loss: 0.0442, g_loss: 1.1996\n",
            "Step [22380/60000], d_real_loss: 0.1128, d_mnist_loss: 0.0186, d_svhn_loss: 0.0942, d_fake_loss: 0.0310, g_loss: 1.0220\n",
            "Step [22390/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0114, d_svhn_loss: 0.0281, d_fake_loss: 0.0784, g_loss: 1.2660\n",
            "Step [22400/60000], d_real_loss: 0.0795, d_mnist_loss: 0.0118, d_svhn_loss: 0.0678, d_fake_loss: 0.0394, g_loss: 1.2816\n",
            "Step [22410/60000], d_real_loss: 0.0965, d_mnist_loss: 0.0232, d_svhn_loss: 0.0733, d_fake_loss: 0.0482, g_loss: 1.0539\n",
            "Step [22420/60000], d_real_loss: 0.0552, d_mnist_loss: 0.0368, d_svhn_loss: 0.0184, d_fake_loss: 0.0384, g_loss: 1.1708\n",
            "Step [22430/60000], d_real_loss: 0.0450, d_mnist_loss: 0.0181, d_svhn_loss: 0.0268, d_fake_loss: 0.0275, g_loss: 1.0352\n",
            "Step [22440/60000], d_real_loss: 0.1078, d_mnist_loss: 0.0717, d_svhn_loss: 0.0361, d_fake_loss: 0.1062, g_loss: 1.0760\n",
            "Step [22450/60000], d_real_loss: 0.0757, d_mnist_loss: 0.0503, d_svhn_loss: 0.0254, d_fake_loss: 0.2159, g_loss: 1.2522\n",
            "Step [22460/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0091, d_svhn_loss: 0.0253, d_fake_loss: 0.0321, g_loss: 1.2234\n",
            "Step [22470/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0123, d_svhn_loss: 0.0348, d_fake_loss: 0.0520, g_loss: 1.0936\n",
            "Step [22480/60000], d_real_loss: 0.2508, d_mnist_loss: 0.2292, d_svhn_loss: 0.0215, d_fake_loss: 0.2300, g_loss: 2.6048\n",
            "Step [22490/60000], d_real_loss: 0.1719, d_mnist_loss: 0.0174, d_svhn_loss: 0.1545, d_fake_loss: 0.1315, g_loss: 1.1833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9949390888214111]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999975562095642, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [22500/60000], d_real_loss: 0.0760, d_mnist_loss: 0.0419, d_svhn_loss: 0.0341, d_fake_loss: 0.0950, g_loss: 1.0764\n",
            "saved ./samples_fashion/sample-22500-m-s.png\n",
            "saved ./samples_fashion/sample-22500-s-m.png\n",
            "Step [22510/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0183, d_svhn_loss: 0.0161, d_fake_loss: 0.0324, g_loss: 1.2150\n",
            "Step [22520/60000], d_real_loss: 0.0712, d_mnist_loss: 0.0333, d_svhn_loss: 0.0379, d_fake_loss: 0.0464, g_loss: 1.1097\n",
            "Step [22530/60000], d_real_loss: 0.0650, d_mnist_loss: 0.0349, d_svhn_loss: 0.0301, d_fake_loss: 0.0598, g_loss: 1.2773\n",
            "Step [22540/60000], d_real_loss: 0.0766, d_mnist_loss: 0.0484, d_svhn_loss: 0.0281, d_fake_loss: 0.0554, g_loss: 1.1598\n",
            "Step [22550/60000], d_real_loss: 0.1064, d_mnist_loss: 0.0756, d_svhn_loss: 0.0308, d_fake_loss: 0.0393, g_loss: 1.0565\n",
            "Step [22560/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0118, d_svhn_loss: 0.0310, d_fake_loss: 0.0768, g_loss: 1.4172\n",
            "Step [22570/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0124, d_svhn_loss: 0.0312, d_fake_loss: 0.0395, g_loss: 0.9725\n",
            "Step [22580/60000], d_real_loss: 0.0555, d_mnist_loss: 0.0393, d_svhn_loss: 0.0163, d_fake_loss: 0.0433, g_loss: 1.1922\n",
            "Step [22590/60000], d_real_loss: 0.1755, d_mnist_loss: 0.1509, d_svhn_loss: 0.0246, d_fake_loss: 0.0202, g_loss: 1.1581\n",
            "Step [22600/60000], d_real_loss: 0.1192, d_mnist_loss: 0.0914, d_svhn_loss: 0.0278, d_fake_loss: 0.0555, g_loss: 1.1290\n",
            "Step [22610/60000], d_real_loss: 0.0408, d_mnist_loss: 0.0093, d_svhn_loss: 0.0315, d_fake_loss: 0.1482, g_loss: 1.1348\n",
            "Step [22620/60000], d_real_loss: 0.0748, d_mnist_loss: 0.0402, d_svhn_loss: 0.0346, d_fake_loss: 0.0453, g_loss: 1.0700\n",
            "Step [22630/60000], d_real_loss: 0.1222, d_mnist_loss: 0.0468, d_svhn_loss: 0.0754, d_fake_loss: 0.0808, g_loss: 1.2717\n",
            "Step [22640/60000], d_real_loss: 0.0453, d_mnist_loss: 0.0148, d_svhn_loss: 0.0305, d_fake_loss: 0.0524, g_loss: 1.1393\n",
            "Step [22650/60000], d_real_loss: 0.0709, d_mnist_loss: 0.0145, d_svhn_loss: 0.0565, d_fake_loss: 0.0416, g_loss: 1.1608\n",
            "Step [22660/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0104, d_svhn_loss: 0.0269, d_fake_loss: 0.0720, g_loss: 1.2509\n",
            "Step [22670/60000], d_real_loss: 0.0355, d_mnist_loss: 0.0080, d_svhn_loss: 0.0274, d_fake_loss: 0.1245, g_loss: 1.0994\n",
            "Step [22680/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0122, d_svhn_loss: 0.0406, d_fake_loss: 0.0339, g_loss: 1.0318\n",
            "Step [22690/60000], d_real_loss: 0.0598, d_mnist_loss: 0.0057, d_svhn_loss: 0.0542, d_fake_loss: 0.1915, g_loss: 1.0187\n",
            "Step [22700/60000], d_real_loss: 0.0380, d_mnist_loss: 0.0159, d_svhn_loss: 0.0221, d_fake_loss: 0.0357, g_loss: 1.0607\n",
            "Step [22710/60000], d_real_loss: 0.0464, d_mnist_loss: 0.0219, d_svhn_loss: 0.0245, d_fake_loss: 0.1087, g_loss: 1.4151\n",
            "Step [22720/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0139, d_svhn_loss: 0.0234, d_fake_loss: 0.2072, g_loss: 1.4646\n",
            "Step [22730/60000], d_real_loss: 0.0461, d_mnist_loss: 0.0138, d_svhn_loss: 0.0322, d_fake_loss: 0.2179, g_loss: 1.5622\n",
            "Step [22740/60000], d_real_loss: 0.0886, d_mnist_loss: 0.0138, d_svhn_loss: 0.0748, d_fake_loss: 0.2266, g_loss: 1.1119\n",
            "Step [22750/60000], d_real_loss: 0.0994, d_mnist_loss: 0.0282, d_svhn_loss: 0.0712, d_fake_loss: 0.0338, g_loss: 1.0977\n",
            "Step [22760/60000], d_real_loss: 0.0625, d_mnist_loss: 0.0133, d_svhn_loss: 0.0492, d_fake_loss: 0.0751, g_loss: 1.2647\n",
            "Step [22770/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0085, d_svhn_loss: 0.0241, d_fake_loss: 0.0338, g_loss: 1.3407\n",
            "Step [22780/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0115, d_svhn_loss: 0.0304, d_fake_loss: 0.1390, g_loss: 1.5232\n",
            "Step [22790/60000], d_real_loss: 0.0424, d_mnist_loss: 0.0246, d_svhn_loss: 0.0178, d_fake_loss: 0.0221, g_loss: 1.0877\n",
            "Step [22800/60000], d_real_loss: 0.0384, d_mnist_loss: 0.0082, d_svhn_loss: 0.0301, d_fake_loss: 0.0787, g_loss: 1.2193\n",
            "Step [22810/60000], d_real_loss: 0.1315, d_mnist_loss: 0.0100, d_svhn_loss: 0.1215, d_fake_loss: 0.0296, g_loss: 1.1933\n",
            "Step [22820/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0087, d_svhn_loss: 0.0431, d_fake_loss: 0.0287, g_loss: 1.0809\n",
            "Step [22830/60000], d_real_loss: 0.0868, d_mnist_loss: 0.0400, d_svhn_loss: 0.0467, d_fake_loss: 0.0926, g_loss: 1.2184\n",
            "Step [22840/60000], d_real_loss: 0.0626, d_mnist_loss: 0.0095, d_svhn_loss: 0.0531, d_fake_loss: 0.0499, g_loss: 1.2103\n",
            "Step [22850/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0132, d_svhn_loss: 0.0268, d_fake_loss: 0.0719, g_loss: 1.0496\n",
            "Step [22860/60000], d_real_loss: 0.0505, d_mnist_loss: 0.0092, d_svhn_loss: 0.0414, d_fake_loss: 0.0404, g_loss: 1.2568\n",
            "Step [22870/60000], d_real_loss: 0.0515, d_mnist_loss: 0.0148, d_svhn_loss: 0.0366, d_fake_loss: 0.0447, g_loss: 1.1356\n",
            "Step [22880/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0150, d_svhn_loss: 0.0385, d_fake_loss: 0.0501, g_loss: 0.9634\n",
            "Step [22890/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0173, d_svhn_loss: 0.0225, d_fake_loss: 0.1180, g_loss: 1.1891\n",
            "Step [22900/60000], d_real_loss: 0.1099, d_mnist_loss: 0.0813, d_svhn_loss: 0.0285, d_fake_loss: 0.0656, g_loss: 0.9518\n",
            "Step [22910/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0122, d_svhn_loss: 0.0467, d_fake_loss: 0.1495, g_loss: 1.1938\n",
            "Step [22920/60000], d_real_loss: 0.0803, d_mnist_loss: 0.0135, d_svhn_loss: 0.0668, d_fake_loss: 0.0423, g_loss: 1.1806\n",
            "Step [22930/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0069, d_svhn_loss: 0.0280, d_fake_loss: 0.0906, g_loss: 0.9829\n",
            "Step [22940/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0154, d_svhn_loss: 0.0313, d_fake_loss: 0.0398, g_loss: 1.2369\n",
            "Step [22950/60000], d_real_loss: 0.0531, d_mnist_loss: 0.0126, d_svhn_loss: 0.0405, d_fake_loss: 0.0596, g_loss: 1.1375\n",
            "Step [22960/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0145, d_svhn_loss: 0.0242, d_fake_loss: 0.0352, g_loss: 0.9486\n",
            "Step [22970/60000], d_real_loss: 0.1721, d_mnist_loss: 0.0106, d_svhn_loss: 0.1615, d_fake_loss: 0.1811, g_loss: 1.3171\n",
            "Step [22980/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0091, d_svhn_loss: 0.0218, d_fake_loss: 0.0694, g_loss: 1.0534\n",
            "Step [22990/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0245, d_svhn_loss: 0.0157, d_fake_loss: 0.0240, g_loss: 1.1811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.99455726146698]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998807907104, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [23000/60000], d_real_loss: 0.0496, d_mnist_loss: 0.0110, d_svhn_loss: 0.0386, d_fake_loss: 0.0540, g_loss: 0.9667\n",
            "saved ./samples_fashion/sample-23000-m-s.png\n",
            "saved ./samples_fashion/sample-23000-s-m.png\n",
            "Step [23010/60000], d_real_loss: 0.0789, d_mnist_loss: 0.0176, d_svhn_loss: 0.0613, d_fake_loss: 0.0608, g_loss: 1.1227\n",
            "Step [23020/60000], d_real_loss: 0.0532, d_mnist_loss: 0.0213, d_svhn_loss: 0.0319, d_fake_loss: 0.0575, g_loss: 1.1265\n",
            "Step [23030/60000], d_real_loss: 0.0736, d_mnist_loss: 0.0245, d_svhn_loss: 0.0491, d_fake_loss: 0.2405, g_loss: 1.0671\n",
            "Step [23040/60000], d_real_loss: 0.0623, d_mnist_loss: 0.0152, d_svhn_loss: 0.0470, d_fake_loss: 0.1367, g_loss: 1.6749\n",
            "Step [23050/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0118, d_svhn_loss: 0.0334, d_fake_loss: 0.0414, g_loss: 1.0582\n",
            "Step [23060/60000], d_real_loss: 0.0724, d_mnist_loss: 0.0232, d_svhn_loss: 0.0492, d_fake_loss: 0.1440, g_loss: 1.1844\n",
            "Step [23070/60000], d_real_loss: 0.0422, d_mnist_loss: 0.0146, d_svhn_loss: 0.0276, d_fake_loss: 0.0565, g_loss: 0.9188\n",
            "Step [23080/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0209, d_svhn_loss: 0.0356, d_fake_loss: 0.0982, g_loss: 0.9243\n",
            "Step [23090/60000], d_real_loss: 0.0772, d_mnist_loss: 0.0519, d_svhn_loss: 0.0253, d_fake_loss: 0.0902, g_loss: 1.3651\n",
            "Step [23100/60000], d_real_loss: 0.0469, d_mnist_loss: 0.0136, d_svhn_loss: 0.0333, d_fake_loss: 0.0529, g_loss: 1.0524\n",
            "Step [23110/60000], d_real_loss: 0.1403, d_mnist_loss: 0.0154, d_svhn_loss: 0.1248, d_fake_loss: 0.1901, g_loss: 1.0462\n",
            "Step [23120/60000], d_real_loss: 0.0690, d_mnist_loss: 0.0275, d_svhn_loss: 0.0414, d_fake_loss: 0.0247, g_loss: 1.1785\n",
            "Step [23130/60000], d_real_loss: 0.2476, d_mnist_loss: 0.2284, d_svhn_loss: 0.0192, d_fake_loss: 0.0753, g_loss: 1.1654\n",
            "Step [23140/60000], d_real_loss: 0.0472, d_mnist_loss: 0.0092, d_svhn_loss: 0.0379, d_fake_loss: 0.0952, g_loss: 1.0692\n",
            "Step [23150/60000], d_real_loss: 0.0980, d_mnist_loss: 0.0554, d_svhn_loss: 0.0426, d_fake_loss: 0.0539, g_loss: 0.9357\n",
            "Step [23160/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0094, d_svhn_loss: 0.0478, d_fake_loss: 0.0903, g_loss: 1.0817\n",
            "Step [23170/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0121, d_svhn_loss: 0.0466, d_fake_loss: 0.0432, g_loss: 1.1301\n",
            "Step [23180/60000], d_real_loss: 0.0704, d_mnist_loss: 0.0133, d_svhn_loss: 0.0571, d_fake_loss: 0.1013, g_loss: 1.0007\n",
            "Step [23190/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0088, d_svhn_loss: 0.0333, d_fake_loss: 0.0326, g_loss: 1.1723\n",
            "Step [23200/60000], d_real_loss: 0.1236, d_mnist_loss: 0.0101, d_svhn_loss: 0.1135, d_fake_loss: 0.2913, g_loss: 1.2366\n",
            "Step [23210/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0156, d_svhn_loss: 0.0185, d_fake_loss: 0.0366, g_loss: 1.0644\n",
            "Step [23220/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0150, d_svhn_loss: 0.0266, d_fake_loss: 0.0871, g_loss: 1.2094\n",
            "Step [23230/60000], d_real_loss: 0.0611, d_mnist_loss: 0.0500, d_svhn_loss: 0.0111, d_fake_loss: 0.1190, g_loss: 1.1052\n",
            "Step [23240/60000], d_real_loss: 0.0409, d_mnist_loss: 0.0109, d_svhn_loss: 0.0300, d_fake_loss: 0.0286, g_loss: 1.1338\n",
            "Step [23250/60000], d_real_loss: 0.0438, d_mnist_loss: 0.0186, d_svhn_loss: 0.0253, d_fake_loss: 0.0902, g_loss: 1.0685\n",
            "Step [23260/60000], d_real_loss: 0.0515, d_mnist_loss: 0.0186, d_svhn_loss: 0.0329, d_fake_loss: 0.1702, g_loss: 1.3235\n",
            "Step [23270/60000], d_real_loss: 0.1477, d_mnist_loss: 0.1095, d_svhn_loss: 0.0382, d_fake_loss: 0.3332, g_loss: 1.4770\n",
            "Step [23280/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0116, d_svhn_loss: 0.0321, d_fake_loss: 0.1371, g_loss: 1.1196\n",
            "Step [23290/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0329, d_svhn_loss: 0.0343, d_fake_loss: 0.0829, g_loss: 1.1685\n",
            "Step [23300/60000], d_real_loss: 0.0492, d_mnist_loss: 0.0105, d_svhn_loss: 0.0387, d_fake_loss: 0.1061, g_loss: 1.2026\n",
            "Step [23310/60000], d_real_loss: 0.0786, d_mnist_loss: 0.0346, d_svhn_loss: 0.0440, d_fake_loss: 0.0679, g_loss: 0.9535\n",
            "Step [23320/60000], d_real_loss: 0.0328, d_mnist_loss: 0.0112, d_svhn_loss: 0.0216, d_fake_loss: 0.0270, g_loss: 1.0234\n",
            "Step [23330/60000], d_real_loss: 0.0469, d_mnist_loss: 0.0283, d_svhn_loss: 0.0186, d_fake_loss: 0.0406, g_loss: 1.1252\n",
            "Step [23340/60000], d_real_loss: 0.0999, d_mnist_loss: 0.0291, d_svhn_loss: 0.0707, d_fake_loss: 0.0577, g_loss: 1.0572\n",
            "Step [23350/60000], d_real_loss: 0.0716, d_mnist_loss: 0.0273, d_svhn_loss: 0.0443, d_fake_loss: 0.2971, g_loss: 1.5822\n",
            "Step [23360/60000], d_real_loss: 0.0425, d_mnist_loss: 0.0195, d_svhn_loss: 0.0230, d_fake_loss: 0.0702, g_loss: 1.1036\n",
            "Step [23370/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0093, d_svhn_loss: 0.0323, d_fake_loss: 0.1036, g_loss: 1.3218\n",
            "Step [23380/60000], d_real_loss: 0.5681, d_mnist_loss: 0.5429, d_svhn_loss: 0.0252, d_fake_loss: 0.1880, g_loss: 1.6116\n",
            "Step [23390/60000], d_real_loss: 0.0460, d_mnist_loss: 0.0153, d_svhn_loss: 0.0307, d_fake_loss: 0.0855, g_loss: 1.2436\n",
            "Step [23400/60000], d_real_loss: 0.0510, d_mnist_loss: 0.0134, d_svhn_loss: 0.0376, d_fake_loss: 0.0198, g_loss: 1.0446\n",
            "Step [23410/60000], d_real_loss: 0.0423, d_mnist_loss: 0.0160, d_svhn_loss: 0.0263, d_fake_loss: 0.0445, g_loss: 1.1001\n",
            "Step [23420/60000], d_real_loss: 0.0406, d_mnist_loss: 0.0139, d_svhn_loss: 0.0266, d_fake_loss: 0.0350, g_loss: 1.1512\n",
            "Step [23430/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0133, d_svhn_loss: 0.0306, d_fake_loss: 0.0340, g_loss: 1.0712\n",
            "Step [23440/60000], d_real_loss: 0.1170, d_mnist_loss: 0.0326, d_svhn_loss: 0.0844, d_fake_loss: 0.0596, g_loss: 1.0744\n",
            "Step [23450/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0243, d_svhn_loss: 0.0394, d_fake_loss: 0.0620, g_loss: 1.0227\n",
            "Step [23460/60000], d_real_loss: 0.0445, d_mnist_loss: 0.0241, d_svhn_loss: 0.0205, d_fake_loss: 0.1947, g_loss: 1.1213\n",
            "Step [23470/60000], d_real_loss: 0.0505, d_mnist_loss: 0.0167, d_svhn_loss: 0.0338, d_fake_loss: 0.2153, g_loss: 1.1988\n",
            "Step [23480/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0151, d_svhn_loss: 0.0280, d_fake_loss: 0.1313, g_loss: 1.1500\n",
            "Step [23490/60000], d_real_loss: 0.0448, d_mnist_loss: 0.0102, d_svhn_loss: 0.0346, d_fake_loss: 0.0697, g_loss: 0.9967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [23500/60000], d_real_loss: 0.4252, d_mnist_loss: 0.0245, d_svhn_loss: 0.4007, d_fake_loss: 0.1988, g_loss: 1.1794\n",
            "saved ./samples_fashion/sample-23500-m-s.png\n",
            "saved ./samples_fashion/sample-23500-s-m.png\n",
            "Step [23510/60000], d_real_loss: 0.1119, d_mnist_loss: 0.0106, d_svhn_loss: 0.1013, d_fake_loss: 0.1286, g_loss: 1.2134\n",
            "Step [23520/60000], d_real_loss: 0.0538, d_mnist_loss: 0.0111, d_svhn_loss: 0.0427, d_fake_loss: 0.0698, g_loss: 1.2957\n",
            "Step [23530/60000], d_real_loss: 0.0852, d_mnist_loss: 0.0565, d_svhn_loss: 0.0286, d_fake_loss: 0.0450, g_loss: 1.1860\n",
            "Step [23540/60000], d_real_loss: 0.0317, d_mnist_loss: 0.0099, d_svhn_loss: 0.0219, d_fake_loss: 0.0905, g_loss: 1.1166\n",
            "Step [23550/60000], d_real_loss: 0.0413, d_mnist_loss: 0.0170, d_svhn_loss: 0.0243, d_fake_loss: 0.0355, g_loss: 1.1303\n",
            "Step [23560/60000], d_real_loss: 0.0512, d_mnist_loss: 0.0113, d_svhn_loss: 0.0399, d_fake_loss: 0.0224, g_loss: 1.1172\n",
            "Step [23570/60000], d_real_loss: 0.1397, d_mnist_loss: 0.0213, d_svhn_loss: 0.1184, d_fake_loss: 0.0924, g_loss: 1.1718\n",
            "Step [23580/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0117, d_svhn_loss: 0.0233, d_fake_loss: 0.1219, g_loss: 0.9774\n",
            "Step [23590/60000], d_real_loss: 0.0770, d_mnist_loss: 0.0451, d_svhn_loss: 0.0319, d_fake_loss: 0.1003, g_loss: 1.2405\n",
            "Step [23600/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0350, d_svhn_loss: 0.0200, d_fake_loss: 0.0755, g_loss: 1.1550\n",
            "Step [23610/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0130, d_svhn_loss: 0.0378, d_fake_loss: 0.0453, g_loss: 0.9913\n",
            "Step [23620/60000], d_real_loss: 0.1419, d_mnist_loss: 0.0119, d_svhn_loss: 0.1300, d_fake_loss: 0.0605, g_loss: 1.1436\n",
            "Step [23630/60000], d_real_loss: 0.0430, d_mnist_loss: 0.0194, d_svhn_loss: 0.0237, d_fake_loss: 0.0354, g_loss: 1.0258\n",
            "Step [23640/60000], d_real_loss: 0.0734, d_mnist_loss: 0.0510, d_svhn_loss: 0.0225, d_fake_loss: 0.0884, g_loss: 1.3072\n",
            "Step [23650/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0247, d_svhn_loss: 0.0204, d_fake_loss: 0.0373, g_loss: 1.2413\n",
            "Step [23660/60000], d_real_loss: 0.1014, d_mnist_loss: 0.0086, d_svhn_loss: 0.0928, d_fake_loss: 0.0684, g_loss: 1.2235\n",
            "Step [23670/60000], d_real_loss: 0.0329, d_mnist_loss: 0.0075, d_svhn_loss: 0.0254, d_fake_loss: 0.0890, g_loss: 1.1805\n",
            "Step [23680/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0170, d_svhn_loss: 0.0204, d_fake_loss: 0.0447, g_loss: 0.9668\n",
            "Step [23690/60000], d_real_loss: 0.0383, d_mnist_loss: 0.0183, d_svhn_loss: 0.0200, d_fake_loss: 0.0492, g_loss: 1.2435\n",
            "Step [23700/60000], d_real_loss: 0.1104, d_mnist_loss: 0.0332, d_svhn_loss: 0.0771, d_fake_loss: 0.0417, g_loss: 1.2087\n",
            "Step [23710/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0129, d_svhn_loss: 0.0322, d_fake_loss: 0.0590, g_loss: 1.2760\n",
            "Step [23720/60000], d_real_loss: 0.0527, d_mnist_loss: 0.0265, d_svhn_loss: 0.0263, d_fake_loss: 0.0275, g_loss: 1.2366\n",
            "Step [23730/60000], d_real_loss: 0.0953, d_mnist_loss: 0.0313, d_svhn_loss: 0.0640, d_fake_loss: 0.0389, g_loss: 1.2607\n",
            "Step [23740/60000], d_real_loss: 0.0664, d_mnist_loss: 0.0404, d_svhn_loss: 0.0259, d_fake_loss: 0.0634, g_loss: 1.2949\n",
            "Step [23750/60000], d_real_loss: 0.0862, d_mnist_loss: 0.0243, d_svhn_loss: 0.0619, d_fake_loss: 0.0905, g_loss: 1.1218\n",
            "Step [23760/60000], d_real_loss: 0.2562, d_mnist_loss: 0.0271, d_svhn_loss: 0.2291, d_fake_loss: 0.0753, g_loss: 1.1607\n",
            "Step [23770/60000], d_real_loss: 0.0709, d_mnist_loss: 0.0131, d_svhn_loss: 0.0578, d_fake_loss: 0.0706, g_loss: 1.0816\n",
            "Step [23780/60000], d_real_loss: 0.0936, d_mnist_loss: 0.0610, d_svhn_loss: 0.0327, d_fake_loss: 0.0985, g_loss: 1.1663\n",
            "Step [23790/60000], d_real_loss: 0.1210, d_mnist_loss: 0.0103, d_svhn_loss: 0.1107, d_fake_loss: 0.0242, g_loss: 1.0664\n",
            "Step [23800/60000], d_real_loss: 0.1041, d_mnist_loss: 0.0097, d_svhn_loss: 0.0944, d_fake_loss: 0.0264, g_loss: 1.1253\n",
            "Step [23810/60000], d_real_loss: 0.1218, d_mnist_loss: 0.0119, d_svhn_loss: 0.1099, d_fake_loss: 0.0730, g_loss: 1.0937\n",
            "Step [23820/60000], d_real_loss: 0.0610, d_mnist_loss: 0.0085, d_svhn_loss: 0.0525, d_fake_loss: 0.1184, g_loss: 1.1717\n",
            "Step [23830/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0087, d_svhn_loss: 0.0231, d_fake_loss: 0.0683, g_loss: 1.0199\n",
            "Step [23840/60000], d_real_loss: 0.0472, d_mnist_loss: 0.0179, d_svhn_loss: 0.0293, d_fake_loss: 0.0599, g_loss: 1.0189\n",
            "Step [23850/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0111, d_svhn_loss: 0.0476, d_fake_loss: 0.0316, g_loss: 1.1232\n",
            "Step [23860/60000], d_real_loss: 0.0715, d_mnist_loss: 0.0112, d_svhn_loss: 0.0603, d_fake_loss: 0.1294, g_loss: 1.0146\n",
            "Step [23870/60000], d_real_loss: 0.0415, d_mnist_loss: 0.0094, d_svhn_loss: 0.0322, d_fake_loss: 0.0607, g_loss: 1.0518\n",
            "Step [23880/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0133, d_svhn_loss: 0.0214, d_fake_loss: 0.0639, g_loss: 1.1709\n",
            "Step [23890/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0148, d_svhn_loss: 0.0458, d_fake_loss: 0.0413, g_loss: 0.9540\n",
            "Step [23900/60000], d_real_loss: 0.0542, d_mnist_loss: 0.0221, d_svhn_loss: 0.0322, d_fake_loss: 0.0854, g_loss: 1.2228\n",
            "Step [23910/60000], d_real_loss: 0.2382, d_mnist_loss: 0.0345, d_svhn_loss: 0.2037, d_fake_loss: 0.1002, g_loss: 1.1068\n",
            "Step [23920/60000], d_real_loss: 0.0857, d_mnist_loss: 0.0211, d_svhn_loss: 0.0646, d_fake_loss: 0.0313, g_loss: 1.1382\n",
            "Step [23930/60000], d_real_loss: 0.2876, d_mnist_loss: 0.1529, d_svhn_loss: 0.1347, d_fake_loss: 0.2623, g_loss: 1.5013\n",
            "Step [23940/60000], d_real_loss: 0.0683, d_mnist_loss: 0.0445, d_svhn_loss: 0.0237, d_fake_loss: 0.1511, g_loss: 1.0118\n",
            "Step [23950/60000], d_real_loss: 0.0607, d_mnist_loss: 0.0350, d_svhn_loss: 0.0257, d_fake_loss: 0.2669, g_loss: 1.2539\n",
            "Step [23960/60000], d_real_loss: 0.0461, d_mnist_loss: 0.0231, d_svhn_loss: 0.0230, d_fake_loss: 0.0712, g_loss: 1.1301\n",
            "Step [23970/60000], d_real_loss: 0.0601, d_mnist_loss: 0.0251, d_svhn_loss: 0.0351, d_fake_loss: 0.2307, g_loss: 1.1506\n",
            "Step [23980/60000], d_real_loss: 0.0415, d_mnist_loss: 0.0112, d_svhn_loss: 0.0303, d_fake_loss: 0.0971, g_loss: 1.0439\n",
            "Step [23990/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0130, d_svhn_loss: 0.0297, d_fake_loss: 0.0345, g_loss: 1.0509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [24000/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0139, d_svhn_loss: 0.0202, d_fake_loss: 0.0245, g_loss: 1.2456\n",
            "saved ./samples_fashion/sample-24000-m-s.png\n",
            "saved ./samples_fashion/sample-24000-s-m.png\n",
            "Step [24010/60000], d_real_loss: 0.0435, d_mnist_loss: 0.0122, d_svhn_loss: 0.0313, d_fake_loss: 0.0489, g_loss: 1.3765\n",
            "Step [24020/60000], d_real_loss: 0.0462, d_mnist_loss: 0.0177, d_svhn_loss: 0.0285, d_fake_loss: 0.0964, g_loss: 1.1368\n",
            "Step [24030/60000], d_real_loss: 0.0601, d_mnist_loss: 0.0302, d_svhn_loss: 0.0299, d_fake_loss: 0.0427, g_loss: 1.0921\n",
            "Step [24040/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0137, d_svhn_loss: 0.0300, d_fake_loss: 0.0246, g_loss: 1.1852\n",
            "Step [24050/60000], d_real_loss: 0.0639, d_mnist_loss: 0.0071, d_svhn_loss: 0.0569, d_fake_loss: 0.1200, g_loss: 1.2336\n",
            "Step [24060/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0218, d_svhn_loss: 0.0250, d_fake_loss: 0.0613, g_loss: 1.1726\n",
            "Step [24070/60000], d_real_loss: 0.0750, d_mnist_loss: 0.0127, d_svhn_loss: 0.0623, d_fake_loss: 0.0556, g_loss: 1.1251\n",
            "Step [24080/60000], d_real_loss: 0.1365, d_mnist_loss: 0.0454, d_svhn_loss: 0.0912, d_fake_loss: 0.2074, g_loss: 1.1008\n",
            "Step [24090/60000], d_real_loss: 0.0532, d_mnist_loss: 0.0187, d_svhn_loss: 0.0344, d_fake_loss: 0.0396, g_loss: 1.0786\n",
            "Step [24100/60000], d_real_loss: 0.0527, d_mnist_loss: 0.0092, d_svhn_loss: 0.0435, d_fake_loss: 0.0459, g_loss: 1.2012\n",
            "Step [24110/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0104, d_svhn_loss: 0.0237, d_fake_loss: 0.0385, g_loss: 1.1764\n",
            "Step [24120/60000], d_real_loss: 0.0719, d_mnist_loss: 0.0109, d_svhn_loss: 0.0610, d_fake_loss: 0.0357, g_loss: 0.9542\n",
            "Step [24130/60000], d_real_loss: 0.1347, d_mnist_loss: 0.0364, d_svhn_loss: 0.0983, d_fake_loss: 0.0568, g_loss: 0.9543\n",
            "Step [24140/60000], d_real_loss: 0.0750, d_mnist_loss: 0.0237, d_svhn_loss: 0.0513, d_fake_loss: 0.1497, g_loss: 0.9278\n",
            "Step [24150/60000], d_real_loss: 0.0498, d_mnist_loss: 0.0120, d_svhn_loss: 0.0378, d_fake_loss: 0.0630, g_loss: 1.1376\n",
            "Step [24160/60000], d_real_loss: 0.1174, d_mnist_loss: 0.0094, d_svhn_loss: 0.1080, d_fake_loss: 0.0271, g_loss: 1.1537\n",
            "Step [24170/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0101, d_svhn_loss: 0.0197, d_fake_loss: 0.0363, g_loss: 1.0363\n",
            "Step [24180/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0299, d_svhn_loss: 0.0290, d_fake_loss: 0.1904, g_loss: 1.0325\n",
            "Step [24190/60000], d_real_loss: 0.0567, d_mnist_loss: 0.0073, d_svhn_loss: 0.0494, d_fake_loss: 0.0462, g_loss: 0.9368\n",
            "Step [24200/60000], d_real_loss: 0.0541, d_mnist_loss: 0.0148, d_svhn_loss: 0.0393, d_fake_loss: 0.0344, g_loss: 1.2536\n",
            "Step [24210/60000], d_real_loss: 0.0453, d_mnist_loss: 0.0095, d_svhn_loss: 0.0357, d_fake_loss: 0.1198, g_loss: 1.2035\n",
            "Step [24220/60000], d_real_loss: 0.1049, d_mnist_loss: 0.0222, d_svhn_loss: 0.0828, d_fake_loss: 0.1996, g_loss: 1.1212\n",
            "Step [24230/60000], d_real_loss: 0.1102, d_mnist_loss: 0.0237, d_svhn_loss: 0.0865, d_fake_loss: 0.0717, g_loss: 1.0227\n",
            "Step [24240/60000], d_real_loss: 0.1016, d_mnist_loss: 0.0667, d_svhn_loss: 0.0348, d_fake_loss: 0.0579, g_loss: 1.4100\n",
            "Step [24250/60000], d_real_loss: 0.1380, d_mnist_loss: 0.0324, d_svhn_loss: 0.1056, d_fake_loss: 0.0645, g_loss: 0.9366\n",
            "Step [24260/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0171, d_svhn_loss: 0.0207, d_fake_loss: 0.0416, g_loss: 1.1637\n",
            "Step [24270/60000], d_real_loss: 0.0633, d_mnist_loss: 0.0368, d_svhn_loss: 0.0266, d_fake_loss: 0.0763, g_loss: 0.9876\n",
            "Step [24280/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0077, d_svhn_loss: 0.0405, d_fake_loss: 0.0403, g_loss: 1.0310\n",
            "Step [24290/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0105, d_svhn_loss: 0.0481, d_fake_loss: 0.0434, g_loss: 1.0259\n",
            "Step [24300/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0077, d_svhn_loss: 0.0194, d_fake_loss: 0.0751, g_loss: 1.1165\n",
            "Step [24310/60000], d_real_loss: 0.0466, d_mnist_loss: 0.0131, d_svhn_loss: 0.0335, d_fake_loss: 0.0989, g_loss: 1.0633\n",
            "Step [24320/60000], d_real_loss: 0.0638, d_mnist_loss: 0.0326, d_svhn_loss: 0.0312, d_fake_loss: 0.0392, g_loss: 0.9881\n",
            "Step [24330/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0223, d_svhn_loss: 0.0197, d_fake_loss: 0.0953, g_loss: 1.0546\n",
            "Step [24340/60000], d_real_loss: 0.0478, d_mnist_loss: 0.0184, d_svhn_loss: 0.0294, d_fake_loss: 0.1202, g_loss: 1.2731\n",
            "Step [24350/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0098, d_svhn_loss: 0.0265, d_fake_loss: 0.1036, g_loss: 1.4145\n",
            "Step [24360/60000], d_real_loss: 0.0647, d_mnist_loss: 0.0391, d_svhn_loss: 0.0256, d_fake_loss: 0.1151, g_loss: 1.0507\n",
            "Step [24370/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0094, d_svhn_loss: 0.0334, d_fake_loss: 0.0503, g_loss: 1.1876\n",
            "Step [24380/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0091, d_svhn_loss: 0.0267, d_fake_loss: 0.1090, g_loss: 1.8001\n",
            "Step [24390/60000], d_real_loss: 0.0542, d_mnist_loss: 0.0098, d_svhn_loss: 0.0444, d_fake_loss: 0.0601, g_loss: 1.0028\n",
            "Step [24400/60000], d_real_loss: 0.1267, d_mnist_loss: 0.0187, d_svhn_loss: 0.1081, d_fake_loss: 0.3834, g_loss: 2.0971\n",
            "Step [24410/60000], d_real_loss: 0.1281, d_mnist_loss: 0.0449, d_svhn_loss: 0.0831, d_fake_loss: 0.3571, g_loss: 1.0673\n",
            "Step [24420/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0222, d_svhn_loss: 0.0235, d_fake_loss: 0.0404, g_loss: 1.1638\n",
            "Step [24430/60000], d_real_loss: 0.0441, d_mnist_loss: 0.0163, d_svhn_loss: 0.0278, d_fake_loss: 0.0479, g_loss: 1.1034\n",
            "Step [24440/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0275, d_svhn_loss: 0.0275, d_fake_loss: 0.0541, g_loss: 1.0575\n",
            "Step [24450/60000], d_real_loss: 0.0960, d_mnist_loss: 0.0145, d_svhn_loss: 0.0816, d_fake_loss: 0.0688, g_loss: 1.0434\n",
            "Step [24460/60000], d_real_loss: 0.1323, d_mnist_loss: 0.0107, d_svhn_loss: 0.1216, d_fake_loss: 0.0757, g_loss: 1.0880\n",
            "Step [24470/60000], d_real_loss: 0.0284, d_mnist_loss: 0.0124, d_svhn_loss: 0.0160, d_fake_loss: 0.0356, g_loss: 1.1073\n",
            "Step [24480/60000], d_real_loss: 0.0668, d_mnist_loss: 0.0105, d_svhn_loss: 0.0563, d_fake_loss: 0.0687, g_loss: 1.3710\n",
            "Step [24490/60000], d_real_loss: 0.0795, d_mnist_loss: 0.0087, d_svhn_loss: 0.0708, d_fake_loss: 0.0613, g_loss: 1.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [24500/60000], d_real_loss: 0.0617, d_mnist_loss: 0.0342, d_svhn_loss: 0.0275, d_fake_loss: 0.0353, g_loss: 1.1301\n",
            "saved ./samples_fashion/sample-24500-m-s.png\n",
            "saved ./samples_fashion/sample-24500-s-m.png\n",
            "Step [24510/60000], d_real_loss: 0.0822, d_mnist_loss: 0.0274, d_svhn_loss: 0.0547, d_fake_loss: 0.0625, g_loss: 1.0954\n",
            "Step [24520/60000], d_real_loss: 0.1177, d_mnist_loss: 0.0181, d_svhn_loss: 0.0996, d_fake_loss: 0.0937, g_loss: 1.0214\n",
            "Step [24530/60000], d_real_loss: 0.0423, d_mnist_loss: 0.0102, d_svhn_loss: 0.0321, d_fake_loss: 0.1209, g_loss: 1.3867\n",
            "Step [24540/60000], d_real_loss: 0.0967, d_mnist_loss: 0.0223, d_svhn_loss: 0.0744, d_fake_loss: 0.0341, g_loss: 1.1302\n",
            "Step [24550/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0321, d_svhn_loss: 0.0276, d_fake_loss: 0.1050, g_loss: 1.1138\n",
            "Step [24560/60000], d_real_loss: 0.1008, d_mnist_loss: 0.0605, d_svhn_loss: 0.0402, d_fake_loss: 0.0397, g_loss: 1.4030\n",
            "Step [24570/60000], d_real_loss: 0.1103, d_mnist_loss: 0.0095, d_svhn_loss: 0.1009, d_fake_loss: 0.0430, g_loss: 1.1478\n",
            "Step [24580/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0394, d_svhn_loss: 0.0279, d_fake_loss: 0.0444, g_loss: 1.1555\n",
            "Step [24590/60000], d_real_loss: 0.0523, d_mnist_loss: 0.0149, d_svhn_loss: 0.0374, d_fake_loss: 0.0586, g_loss: 1.2257\n",
            "Step [24600/60000], d_real_loss: 0.0557, d_mnist_loss: 0.0192, d_svhn_loss: 0.0366, d_fake_loss: 0.0600, g_loss: 1.2073\n",
            "Step [24610/60000], d_real_loss: 0.0703, d_mnist_loss: 0.0277, d_svhn_loss: 0.0427, d_fake_loss: 0.0508, g_loss: 1.1447\n",
            "Step [24620/60000], d_real_loss: 0.0512, d_mnist_loss: 0.0183, d_svhn_loss: 0.0329, d_fake_loss: 0.0625, g_loss: 1.1223\n",
            "Step [24630/60000], d_real_loss: 0.1103, d_mnist_loss: 0.0296, d_svhn_loss: 0.0807, d_fake_loss: 0.0751, g_loss: 1.4747\n",
            "Step [24640/60000], d_real_loss: 0.1138, d_mnist_loss: 0.0131, d_svhn_loss: 0.1007, d_fake_loss: 0.0298, g_loss: 0.9691\n",
            "Step [24650/60000], d_real_loss: 0.0522, d_mnist_loss: 0.0089, d_svhn_loss: 0.0433, d_fake_loss: 0.1443, g_loss: 1.3509\n",
            "Step [24660/60000], d_real_loss: 0.0943, d_mnist_loss: 0.0195, d_svhn_loss: 0.0747, d_fake_loss: 0.0705, g_loss: 1.0317\n",
            "Step [24670/60000], d_real_loss: 0.1011, d_mnist_loss: 0.0107, d_svhn_loss: 0.0904, d_fake_loss: 0.1009, g_loss: 1.0964\n",
            "Step [24680/60000], d_real_loss: 0.0687, d_mnist_loss: 0.0333, d_svhn_loss: 0.0354, d_fake_loss: 0.0433, g_loss: 0.9508\n",
            "Step [24690/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0133, d_svhn_loss: 0.0319, d_fake_loss: 0.0407, g_loss: 1.1321\n",
            "Step [24700/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0123, d_svhn_loss: 0.0356, d_fake_loss: 0.0834, g_loss: 1.1573\n",
            "Step [24710/60000], d_real_loss: 0.0271, d_mnist_loss: 0.0094, d_svhn_loss: 0.0177, d_fake_loss: 0.0832, g_loss: 1.1872\n",
            "Step [24720/60000], d_real_loss: 0.0823, d_mnist_loss: 0.0237, d_svhn_loss: 0.0586, d_fake_loss: 0.0906, g_loss: 1.0725\n",
            "Step [24730/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0184, d_svhn_loss: 0.0333, d_fake_loss: 0.0693, g_loss: 0.7941\n",
            "Step [24740/60000], d_real_loss: 0.0614, d_mnist_loss: 0.0088, d_svhn_loss: 0.0526, d_fake_loss: 0.0476, g_loss: 1.2579\n",
            "Step [24750/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0101, d_svhn_loss: 0.0252, d_fake_loss: 0.0548, g_loss: 1.1692\n",
            "Step [24760/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0154, d_svhn_loss: 0.0419, d_fake_loss: 0.2278, g_loss: 0.5708\n",
            "Step [24770/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0116, d_svhn_loss: 0.0312, d_fake_loss: 0.0406, g_loss: 1.1038\n",
            "Step [24780/60000], d_real_loss: 0.0339, d_mnist_loss: 0.0100, d_svhn_loss: 0.0239, d_fake_loss: 0.0550, g_loss: 1.2829\n",
            "Step [24790/60000], d_real_loss: 0.0877, d_mnist_loss: 0.0214, d_svhn_loss: 0.0663, d_fake_loss: 0.0933, g_loss: 1.1225\n",
            "Step [24800/60000], d_real_loss: 0.0321, d_mnist_loss: 0.0144, d_svhn_loss: 0.0177, d_fake_loss: 0.0648, g_loss: 1.1375\n",
            "Step [24810/60000], d_real_loss: 0.1554, d_mnist_loss: 0.0076, d_svhn_loss: 0.1478, d_fake_loss: 0.0859, g_loss: 0.8468\n",
            "Step [24820/60000], d_real_loss: 0.0761, d_mnist_loss: 0.0474, d_svhn_loss: 0.0287, d_fake_loss: 0.0375, g_loss: 1.0557\n",
            "Step [24830/60000], d_real_loss: 0.1848, d_mnist_loss: 0.0218, d_svhn_loss: 0.1631, d_fake_loss: 0.1397, g_loss: 1.1201\n",
            "Step [24840/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0114, d_svhn_loss: 0.0193, d_fake_loss: 0.0241, g_loss: 1.1561\n",
            "Step [24850/60000], d_real_loss: 0.0527, d_mnist_loss: 0.0118, d_svhn_loss: 0.0410, d_fake_loss: 0.0587, g_loss: 0.9395\n",
            "Step [24860/60000], d_real_loss: 0.0921, d_mnist_loss: 0.0114, d_svhn_loss: 0.0806, d_fake_loss: 0.0434, g_loss: 1.2261\n",
            "Step [24870/60000], d_real_loss: 0.0727, d_mnist_loss: 0.0122, d_svhn_loss: 0.0605, d_fake_loss: 0.0837, g_loss: 1.2726\n",
            "Step [24880/60000], d_real_loss: 0.0243, d_mnist_loss: 0.0087, d_svhn_loss: 0.0156, d_fake_loss: 0.0686, g_loss: 1.0129\n",
            "Step [24890/60000], d_real_loss: 0.0524, d_mnist_loss: 0.0304, d_svhn_loss: 0.0220, d_fake_loss: 0.0500, g_loss: 1.0790\n",
            "Step [24900/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0365, d_svhn_loss: 0.0241, d_fake_loss: 0.0358, g_loss: 1.2538\n",
            "Step [24910/60000], d_real_loss: 0.0634, d_mnist_loss: 0.0110, d_svhn_loss: 0.0523, d_fake_loss: 0.1142, g_loss: 1.2513\n",
            "Step [24920/60000], d_real_loss: 0.0509, d_mnist_loss: 0.0255, d_svhn_loss: 0.0254, d_fake_loss: 0.0380, g_loss: 1.0306\n",
            "Step [24930/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0132, d_svhn_loss: 0.0322, d_fake_loss: 0.0543, g_loss: 1.1630\n",
            "Step [24940/60000], d_real_loss: 0.2435, d_mnist_loss: 0.0598, d_svhn_loss: 0.1837, d_fake_loss: 0.0540, g_loss: 1.3834\n",
            "Step [24950/60000], d_real_loss: 0.1080, d_mnist_loss: 0.0143, d_svhn_loss: 0.0937, d_fake_loss: 0.0578, g_loss: 1.1041\n",
            "Step [24960/60000], d_real_loss: 0.1309, d_mnist_loss: 0.0182, d_svhn_loss: 0.1126, d_fake_loss: 0.0428, g_loss: 1.0664\n",
            "Step [24970/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0151, d_svhn_loss: 0.0323, d_fake_loss: 0.0587, g_loss: 1.2155\n",
            "Step [24980/60000], d_real_loss: 0.0453, d_mnist_loss: 0.0264, d_svhn_loss: 0.0189, d_fake_loss: 0.0516, g_loss: 1.0364\n",
            "Step [24990/60000], d_real_loss: 0.1087, d_mnist_loss: 0.0087, d_svhn_loss: 0.0999, d_fake_loss: 0.0357, g_loss: 1.0441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [25000/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0099, d_svhn_loss: 0.0341, d_fake_loss: 0.0487, g_loss: 1.1687\n",
            "saved ./samples_fashion/sample-25000-m-s.png\n",
            "saved ./samples_fashion/sample-25000-s-m.png\n",
            "Step [25010/60000], d_real_loss: 0.0570, d_mnist_loss: 0.0157, d_svhn_loss: 0.0414, d_fake_loss: 0.0934, g_loss: 1.0155\n",
            "Step [25020/60000], d_real_loss: 0.0806, d_mnist_loss: 0.0217, d_svhn_loss: 0.0588, d_fake_loss: 0.1028, g_loss: 1.0910\n",
            "Step [25030/60000], d_real_loss: 0.0536, d_mnist_loss: 0.0109, d_svhn_loss: 0.0427, d_fake_loss: 0.0695, g_loss: 1.0561\n",
            "Step [25040/60000], d_real_loss: 0.1182, d_mnist_loss: 0.0154, d_svhn_loss: 0.1028, d_fake_loss: 0.0367, g_loss: 1.2500\n",
            "Step [25050/60000], d_real_loss: 0.0799, d_mnist_loss: 0.0138, d_svhn_loss: 0.0661, d_fake_loss: 0.0738, g_loss: 1.1722\n",
            "Step [25060/60000], d_real_loss: 0.0648, d_mnist_loss: 0.0249, d_svhn_loss: 0.0399, d_fake_loss: 0.0742, g_loss: 1.2035\n",
            "Step [25070/60000], d_real_loss: 0.0615, d_mnist_loss: 0.0110, d_svhn_loss: 0.0505, d_fake_loss: 0.0564, g_loss: 1.3036\n",
            "Step [25080/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0133, d_svhn_loss: 0.0283, d_fake_loss: 0.0326, g_loss: 1.1140\n",
            "Step [25090/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0103, d_svhn_loss: 0.0269, d_fake_loss: 0.0310, g_loss: 1.2054\n",
            "Step [25100/60000], d_real_loss: 0.0450, d_mnist_loss: 0.0182, d_svhn_loss: 0.0268, d_fake_loss: 0.0342, g_loss: 1.1548\n",
            "Step [25110/60000], d_real_loss: 0.0556, d_mnist_loss: 0.0289, d_svhn_loss: 0.0267, d_fake_loss: 0.0681, g_loss: 1.1298\n",
            "Step [25120/60000], d_real_loss: 0.0585, d_mnist_loss: 0.0280, d_svhn_loss: 0.0305, d_fake_loss: 0.0362, g_loss: 0.9682\n",
            "Step [25130/60000], d_real_loss: 0.0889, d_mnist_loss: 0.0562, d_svhn_loss: 0.0327, d_fake_loss: 0.0515, g_loss: 1.0442\n",
            "Step [25140/60000], d_real_loss: 0.0517, d_mnist_loss: 0.0219, d_svhn_loss: 0.0298, d_fake_loss: 0.0377, g_loss: 1.1941\n",
            "Step [25150/60000], d_real_loss: 0.0578, d_mnist_loss: 0.0232, d_svhn_loss: 0.0346, d_fake_loss: 0.0702, g_loss: 1.2773\n",
            "Step [25160/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0167, d_svhn_loss: 0.0226, d_fake_loss: 0.0334, g_loss: 1.1702\n",
            "Step [25170/60000], d_real_loss: 0.0725, d_mnist_loss: 0.0476, d_svhn_loss: 0.0248, d_fake_loss: 0.1666, g_loss: 1.4277\n",
            "Step [25180/60000], d_real_loss: 0.0411, d_mnist_loss: 0.0229, d_svhn_loss: 0.0182, d_fake_loss: 0.1164, g_loss: 0.9480\n",
            "Step [25190/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0108, d_svhn_loss: 0.0456, d_fake_loss: 0.5814, g_loss: 1.1550\n",
            "Step [25200/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0105, d_svhn_loss: 0.0299, d_fake_loss: 0.0296, g_loss: 1.1667\n",
            "Step [25210/60000], d_real_loss: 0.0749, d_mnist_loss: 0.0282, d_svhn_loss: 0.0468, d_fake_loss: 0.0445, g_loss: 1.1102\n",
            "Step [25220/60000], d_real_loss: 0.0921, d_mnist_loss: 0.0312, d_svhn_loss: 0.0609, d_fake_loss: 0.1882, g_loss: 1.2943\n",
            "Step [25230/60000], d_real_loss: 0.0600, d_mnist_loss: 0.0392, d_svhn_loss: 0.0208, d_fake_loss: 0.0396, g_loss: 1.1205\n",
            "Step [25240/60000], d_real_loss: 0.0579, d_mnist_loss: 0.0161, d_svhn_loss: 0.0418, d_fake_loss: 0.1452, g_loss: 0.8314\n",
            "Step [25250/60000], d_real_loss: 0.0570, d_mnist_loss: 0.0395, d_svhn_loss: 0.0175, d_fake_loss: 0.0305, g_loss: 1.0572\n",
            "Step [25260/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0158, d_svhn_loss: 0.0206, d_fake_loss: 0.0526, g_loss: 1.1073\n",
            "Step [25270/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0216, d_svhn_loss: 0.0211, d_fake_loss: 0.0491, g_loss: 1.2862\n",
            "Step [25280/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0101, d_svhn_loss: 0.0337, d_fake_loss: 0.0266, g_loss: 1.0739\n",
            "Step [25290/60000], d_real_loss: 0.0814, d_mnist_loss: 0.0204, d_svhn_loss: 0.0610, d_fake_loss: 0.0820, g_loss: 1.3394\n",
            "Step [25300/60000], d_real_loss: 0.1233, d_mnist_loss: 0.0444, d_svhn_loss: 0.0789, d_fake_loss: 0.0585, g_loss: 1.2338\n",
            "Step [25310/60000], d_real_loss: 0.0810, d_mnist_loss: 0.0452, d_svhn_loss: 0.0358, d_fake_loss: 0.0711, g_loss: 0.9859\n",
            "Step [25320/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0117, d_svhn_loss: 0.0251, d_fake_loss: 0.0620, g_loss: 1.0564\n",
            "Step [25330/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0112, d_svhn_loss: 0.0262, d_fake_loss: 0.0436, g_loss: 1.0767\n",
            "Step [25340/60000], d_real_loss: 0.0539, d_mnist_loss: 0.0332, d_svhn_loss: 0.0207, d_fake_loss: 0.0324, g_loss: 0.9899\n",
            "Step [25350/60000], d_real_loss: 0.0526, d_mnist_loss: 0.0269, d_svhn_loss: 0.0257, d_fake_loss: 0.2205, g_loss: 1.1730\n",
            "Step [25360/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0183, d_svhn_loss: 0.0193, d_fake_loss: 0.0453, g_loss: 1.0640\n",
            "Step [25370/60000], d_real_loss: 0.0435, d_mnist_loss: 0.0136, d_svhn_loss: 0.0299, d_fake_loss: 0.0955, g_loss: 1.1934\n",
            "Step [25380/60000], d_real_loss: 0.0509, d_mnist_loss: 0.0073, d_svhn_loss: 0.0436, d_fake_loss: 0.0487, g_loss: 1.1473\n",
            "Step [25390/60000], d_real_loss: 0.0429, d_mnist_loss: 0.0261, d_svhn_loss: 0.0168, d_fake_loss: 0.0576, g_loss: 1.1862\n",
            "Step [25400/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0205, d_svhn_loss: 0.0194, d_fake_loss: 0.0606, g_loss: 0.9152\n",
            "Step [25410/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0169, d_svhn_loss: 0.0281, d_fake_loss: 0.1178, g_loss: 1.5205\n",
            "Step [25420/60000], d_real_loss: 0.0678, d_mnist_loss: 0.0121, d_svhn_loss: 0.0557, d_fake_loss: 0.0316, g_loss: 1.1197\n",
            "Step [25430/60000], d_real_loss: 0.1125, d_mnist_loss: 0.0136, d_svhn_loss: 0.0990, d_fake_loss: 0.0565, g_loss: 1.2488\n",
            "Step [25440/60000], d_real_loss: 0.1388, d_mnist_loss: 0.0127, d_svhn_loss: 0.1262, d_fake_loss: 0.2590, g_loss: 1.3274\n",
            "Step [25450/60000], d_real_loss: 0.0794, d_mnist_loss: 0.0132, d_svhn_loss: 0.0662, d_fake_loss: 0.0387, g_loss: 1.1128\n",
            "Step [25460/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0194, d_svhn_loss: 0.0290, d_fake_loss: 0.0749, g_loss: 1.2297\n",
            "Step [25470/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0117, d_svhn_loss: 0.0282, d_fake_loss: 0.0284, g_loss: 1.1618\n",
            "Step [25480/60000], d_real_loss: 0.0817, d_mnist_loss: 0.0450, d_svhn_loss: 0.0367, d_fake_loss: 0.0363, g_loss: 1.1850\n",
            "Step [25490/60000], d_real_loss: 0.1204, d_mnist_loss: 0.0994, d_svhn_loss: 0.0210, d_fake_loss: 0.7712, g_loss: 1.7331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999821186065674, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [25500/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0119, d_svhn_loss: 0.0337, d_fake_loss: 0.0674, g_loss: 1.1867\n",
            "saved ./samples_fashion/sample-25500-m-s.png\n",
            "saved ./samples_fashion/sample-25500-s-m.png\n",
            "Step [25510/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0116, d_svhn_loss: 0.0203, d_fake_loss: 0.1104, g_loss: 1.1946\n",
            "Step [25520/60000], d_real_loss: 0.1374, d_mnist_loss: 0.0314, d_svhn_loss: 0.1060, d_fake_loss: 0.1094, g_loss: 1.0491\n",
            "Step [25530/60000], d_real_loss: 0.0485, d_mnist_loss: 0.0291, d_svhn_loss: 0.0193, d_fake_loss: 0.0370, g_loss: 0.9775\n",
            "Step [25540/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0172, d_svhn_loss: 0.0139, d_fake_loss: 0.0687, g_loss: 0.9148\n",
            "Step [25550/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0069, d_svhn_loss: 0.0309, d_fake_loss: 0.0283, g_loss: 0.9948\n",
            "Step [25560/60000], d_real_loss: 0.0537, d_mnist_loss: 0.0177, d_svhn_loss: 0.0360, d_fake_loss: 0.0280, g_loss: 1.0630\n",
            "Step [25570/60000], d_real_loss: 0.0473, d_mnist_loss: 0.0093, d_svhn_loss: 0.0380, d_fake_loss: 0.0459, g_loss: 1.1171\n",
            "Step [25580/60000], d_real_loss: 0.0594, d_mnist_loss: 0.0298, d_svhn_loss: 0.0296, d_fake_loss: 0.0292, g_loss: 1.1931\n",
            "Step [25590/60000], d_real_loss: 0.0795, d_mnist_loss: 0.0424, d_svhn_loss: 0.0372, d_fake_loss: 0.0639, g_loss: 1.1181\n",
            "Step [25600/60000], d_real_loss: 0.0627, d_mnist_loss: 0.0116, d_svhn_loss: 0.0511, d_fake_loss: 0.2245, g_loss: 1.3912\n",
            "Step [25610/60000], d_real_loss: 0.0408, d_mnist_loss: 0.0154, d_svhn_loss: 0.0253, d_fake_loss: 0.0260, g_loss: 1.2338\n",
            "Step [25620/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0085, d_svhn_loss: 0.0317, d_fake_loss: 0.0979, g_loss: 0.9833\n",
            "Step [25630/60000], d_real_loss: 0.0499, d_mnist_loss: 0.0117, d_svhn_loss: 0.0382, d_fake_loss: 0.0768, g_loss: 1.2199\n",
            "Step [25640/60000], d_real_loss: 0.0743, d_mnist_loss: 0.0343, d_svhn_loss: 0.0400, d_fake_loss: 0.0490, g_loss: 1.0521\n",
            "Step [25650/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0137, d_svhn_loss: 0.0172, d_fake_loss: 0.0416, g_loss: 1.1911\n",
            "Step [25660/60000], d_real_loss: 0.0203, d_mnist_loss: 0.0090, d_svhn_loss: 0.0113, d_fake_loss: 0.0937, g_loss: 1.0679\n",
            "Step [25670/60000], d_real_loss: 0.1057, d_mnist_loss: 0.0204, d_svhn_loss: 0.0853, d_fake_loss: 0.1135, g_loss: 1.0510\n",
            "Step [25680/60000], d_real_loss: 0.0466, d_mnist_loss: 0.0216, d_svhn_loss: 0.0249, d_fake_loss: 0.0698, g_loss: 1.0231\n",
            "Step [25690/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0114, d_svhn_loss: 0.0239, d_fake_loss: 0.0489, g_loss: 1.0113\n",
            "Step [25700/60000], d_real_loss: 0.1115, d_mnist_loss: 0.0189, d_svhn_loss: 0.0926, d_fake_loss: 0.2760, g_loss: 0.8830\n",
            "Step [25710/60000], d_real_loss: 0.1749, d_mnist_loss: 0.0309, d_svhn_loss: 0.1440, d_fake_loss: 0.1251, g_loss: 1.0303\n",
            "Step [25720/60000], d_real_loss: 0.1213, d_mnist_loss: 0.0139, d_svhn_loss: 0.1074, d_fake_loss: 0.0230, g_loss: 1.1416\n",
            "Step [25730/60000], d_real_loss: 0.0537, d_mnist_loss: 0.0282, d_svhn_loss: 0.0255, d_fake_loss: 0.0526, g_loss: 1.0685\n",
            "Step [25740/60000], d_real_loss: 0.0554, d_mnist_loss: 0.0299, d_svhn_loss: 0.0255, d_fake_loss: 0.0632, g_loss: 1.1340\n",
            "Step [25750/60000], d_real_loss: 0.0851, d_mnist_loss: 0.0097, d_svhn_loss: 0.0754, d_fake_loss: 0.0269, g_loss: 1.1010\n",
            "Step [25760/60000], d_real_loss: 0.0841, d_mnist_loss: 0.0132, d_svhn_loss: 0.0709, d_fake_loss: 0.2573, g_loss: 1.4703\n",
            "Step [25770/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0229, d_svhn_loss: 0.0290, d_fake_loss: 0.0495, g_loss: 1.1038\n",
            "Step [25780/60000], d_real_loss: 0.1066, d_mnist_loss: 0.0332, d_svhn_loss: 0.0734, d_fake_loss: 0.0414, g_loss: 1.1887\n",
            "Step [25790/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0243, d_svhn_loss: 0.0297, d_fake_loss: 0.0223, g_loss: 1.0659\n",
            "Step [25800/60000], d_real_loss: 0.0429, d_mnist_loss: 0.0124, d_svhn_loss: 0.0305, d_fake_loss: 0.0522, g_loss: 1.1581\n",
            "Step [25810/60000], d_real_loss: 0.0425, d_mnist_loss: 0.0105, d_svhn_loss: 0.0319, d_fake_loss: 0.0636, g_loss: 1.2626\n",
            "Step [25820/60000], d_real_loss: 0.0655, d_mnist_loss: 0.0125, d_svhn_loss: 0.0530, d_fake_loss: 0.0874, g_loss: 1.1800\n",
            "Step [25830/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0104, d_svhn_loss: 0.0461, d_fake_loss: 0.0668, g_loss: 1.0179\n",
            "Step [25840/60000], d_real_loss: 0.0974, d_mnist_loss: 0.0131, d_svhn_loss: 0.0844, d_fake_loss: 0.0754, g_loss: 1.2492\n",
            "Step [25850/60000], d_real_loss: 0.1398, d_mnist_loss: 0.0133, d_svhn_loss: 0.1265, d_fake_loss: 0.2215, g_loss: 1.0414\n",
            "Step [25860/60000], d_real_loss: 0.0480, d_mnist_loss: 0.0335, d_svhn_loss: 0.0145, d_fake_loss: 0.1403, g_loss: 1.1937\n",
            "Step [25870/60000], d_real_loss: 0.0604, d_mnist_loss: 0.0079, d_svhn_loss: 0.0525, d_fake_loss: 0.0584, g_loss: 1.2287\n",
            "Step [25880/60000], d_real_loss: 0.0328, d_mnist_loss: 0.0120, d_svhn_loss: 0.0209, d_fake_loss: 0.0334, g_loss: 1.0983\n",
            "Step [25890/60000], d_real_loss: 0.0956, d_mnist_loss: 0.0665, d_svhn_loss: 0.0291, d_fake_loss: 0.1160, g_loss: 1.1350\n",
            "Step [25900/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0078, d_svhn_loss: 0.0295, d_fake_loss: 0.0698, g_loss: 1.2273\n",
            "Step [25910/60000], d_real_loss: 0.0546, d_mnist_loss: 0.0120, d_svhn_loss: 0.0427, d_fake_loss: 0.0531, g_loss: 1.0733\n",
            "Step [25920/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0093, d_svhn_loss: 0.0276, d_fake_loss: 0.0426, g_loss: 1.0984\n",
            "Step [25930/60000], d_real_loss: 0.0285, d_mnist_loss: 0.0135, d_svhn_loss: 0.0150, d_fake_loss: 0.0498, g_loss: 1.1329\n",
            "Step [25940/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0102, d_svhn_loss: 0.0255, d_fake_loss: 0.0255, g_loss: 1.0492\n",
            "Step [25950/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0119, d_svhn_loss: 0.0240, d_fake_loss: 0.0538, g_loss: 1.3008\n",
            "Step [25960/60000], d_real_loss: 0.1779, d_mnist_loss: 0.1421, d_svhn_loss: 0.0358, d_fake_loss: 0.0574, g_loss: 1.1060\n",
            "Step [25970/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0150, d_svhn_loss: 0.0282, d_fake_loss: 0.0508, g_loss: 1.0714\n",
            "Step [25980/60000], d_real_loss: 0.2358, d_mnist_loss: 0.0163, d_svhn_loss: 0.2195, d_fake_loss: 0.0390, g_loss: 0.9885\n",
            "Step [25990/60000], d_real_loss: 0.0466, d_mnist_loss: 0.0100, d_svhn_loss: 0.0367, d_fake_loss: 0.0681, g_loss: 1.1328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [26000/60000], d_real_loss: 0.0782, d_mnist_loss: 0.0372, d_svhn_loss: 0.0410, d_fake_loss: 0.0654, g_loss: 1.2237\n",
            "saved ./samples_fashion/sample-26000-m-s.png\n",
            "saved ./samples_fashion/sample-26000-s-m.png\n",
            "Step [26010/60000], d_real_loss: 0.0848, d_mnist_loss: 0.0346, d_svhn_loss: 0.0501, d_fake_loss: 0.0417, g_loss: 1.1148\n",
            "Step [26020/60000], d_real_loss: 0.0450, d_mnist_loss: 0.0079, d_svhn_loss: 0.0371, d_fake_loss: 0.1051, g_loss: 1.1312\n",
            "Step [26030/60000], d_real_loss: 0.2370, d_mnist_loss: 0.1750, d_svhn_loss: 0.0620, d_fake_loss: 0.4714, g_loss: 1.7230\n",
            "Step [26040/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0199, d_svhn_loss: 0.0317, d_fake_loss: 0.0440, g_loss: 1.0428\n",
            "Step [26050/60000], d_real_loss: 0.0466, d_mnist_loss: 0.0088, d_svhn_loss: 0.0378, d_fake_loss: 0.1119, g_loss: 1.2847\n",
            "Step [26060/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0111, d_svhn_loss: 0.0208, d_fake_loss: 0.0389, g_loss: 1.1671\n",
            "Step [26070/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0342, d_svhn_loss: 0.0264, d_fake_loss: 0.0342, g_loss: 1.0044\n",
            "Step [26080/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0149, d_svhn_loss: 0.0293, d_fake_loss: 0.0788, g_loss: 1.1198\n",
            "Step [26090/60000], d_real_loss: 0.0630, d_mnist_loss: 0.0305, d_svhn_loss: 0.0325, d_fake_loss: 0.0427, g_loss: 1.1127\n",
            "Step [26100/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0125, d_svhn_loss: 0.0250, d_fake_loss: 0.0283, g_loss: 1.0852\n",
            "Step [26110/60000], d_real_loss: 0.1207, d_mnist_loss: 0.0166, d_svhn_loss: 0.1041, d_fake_loss: 0.0670, g_loss: 1.1412\n",
            "Step [26120/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0117, d_svhn_loss: 0.0270, d_fake_loss: 0.0293, g_loss: 1.0827\n",
            "Step [26130/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0080, d_svhn_loss: 0.0218, d_fake_loss: 0.0729, g_loss: 1.2310\n",
            "Step [26140/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0090, d_svhn_loss: 0.0238, d_fake_loss: 0.0637, g_loss: 1.3410\n",
            "Step [26150/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0069, d_svhn_loss: 0.0254, d_fake_loss: 0.0541, g_loss: 1.1071\n",
            "Step [26160/60000], d_real_loss: 0.0460, d_mnist_loss: 0.0246, d_svhn_loss: 0.0214, d_fake_loss: 0.0389, g_loss: 1.0559\n",
            "Step [26170/60000], d_real_loss: 0.0354, d_mnist_loss: 0.0093, d_svhn_loss: 0.0261, d_fake_loss: 0.0306, g_loss: 1.2274\n",
            "Step [26180/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0143, d_svhn_loss: 0.0338, d_fake_loss: 0.1100, g_loss: 0.8522\n",
            "Step [26190/60000], d_real_loss: 0.1174, d_mnist_loss: 0.0726, d_svhn_loss: 0.0449, d_fake_loss: 0.0588, g_loss: 1.2546\n",
            "Step [26200/60000], d_real_loss: 0.0329, d_mnist_loss: 0.0061, d_svhn_loss: 0.0269, d_fake_loss: 0.0615, g_loss: 1.0328\n",
            "Step [26210/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0116, d_svhn_loss: 0.0482, d_fake_loss: 0.0493, g_loss: 1.0474\n",
            "Step [26220/60000], d_real_loss: 0.0464, d_mnist_loss: 0.0151, d_svhn_loss: 0.0313, d_fake_loss: 0.0314, g_loss: 1.2087\n",
            "Step [26230/60000], d_real_loss: 0.0361, d_mnist_loss: 0.0153, d_svhn_loss: 0.0208, d_fake_loss: 0.0615, g_loss: 1.2561\n",
            "Step [26240/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0268, d_svhn_loss: 0.0329, d_fake_loss: 0.0342, g_loss: 1.1204\n",
            "Step [26250/60000], d_real_loss: 0.0410, d_mnist_loss: 0.0151, d_svhn_loss: 0.0259, d_fake_loss: 0.0665, g_loss: 0.9561\n",
            "Step [26260/60000], d_real_loss: 0.1668, d_mnist_loss: 0.1182, d_svhn_loss: 0.0486, d_fake_loss: 0.0540, g_loss: 1.4534\n",
            "Step [26270/60000], d_real_loss: 0.1540, d_mnist_loss: 0.0219, d_svhn_loss: 0.1321, d_fake_loss: 0.1602, g_loss: 0.9954\n",
            "Step [26280/60000], d_real_loss: 0.1109, d_mnist_loss: 0.0140, d_svhn_loss: 0.0969, d_fake_loss: 0.1049, g_loss: 1.1569\n",
            "Step [26290/60000], d_real_loss: 0.0608, d_mnist_loss: 0.0311, d_svhn_loss: 0.0297, d_fake_loss: 0.0572, g_loss: 1.2124\n",
            "Step [26300/60000], d_real_loss: 0.0280, d_mnist_loss: 0.0117, d_svhn_loss: 0.0162, d_fake_loss: 0.0320, g_loss: 1.1842\n",
            "Step [26310/60000], d_real_loss: 0.0288, d_mnist_loss: 0.0065, d_svhn_loss: 0.0223, d_fake_loss: 0.0370, g_loss: 1.0782\n",
            "Step [26320/60000], d_real_loss: 0.0880, d_mnist_loss: 0.0099, d_svhn_loss: 0.0781, d_fake_loss: 0.0946, g_loss: 1.0553\n",
            "Step [26330/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0097, d_svhn_loss: 0.0263, d_fake_loss: 0.0278, g_loss: 1.0356\n",
            "Step [26340/60000], d_real_loss: 0.0459, d_mnist_loss: 0.0187, d_svhn_loss: 0.0273, d_fake_loss: 0.0610, g_loss: 1.2823\n",
            "Step [26350/60000], d_real_loss: 0.0804, d_mnist_loss: 0.0122, d_svhn_loss: 0.0683, d_fake_loss: 0.1064, g_loss: 1.0106\n",
            "Step [26360/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0155, d_svhn_loss: 0.0316, d_fake_loss: 0.1228, g_loss: 1.2831\n",
            "Step [26370/60000], d_real_loss: 0.2902, d_mnist_loss: 0.2450, d_svhn_loss: 0.0452, d_fake_loss: 0.1928, g_loss: 1.2659\n",
            "Step [26380/60000], d_real_loss: 0.0613, d_mnist_loss: 0.0138, d_svhn_loss: 0.0475, d_fake_loss: 0.0538, g_loss: 1.3327\n",
            "Step [26390/60000], d_real_loss: 0.0500, d_mnist_loss: 0.0155, d_svhn_loss: 0.0345, d_fake_loss: 0.0382, g_loss: 0.9906\n",
            "Step [26400/60000], d_real_loss: 0.0489, d_mnist_loss: 0.0306, d_svhn_loss: 0.0183, d_fake_loss: 0.0275, g_loss: 1.0641\n",
            "Step [26410/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0116, d_svhn_loss: 0.0203, d_fake_loss: 0.0512, g_loss: 1.1796\n",
            "Step [26420/60000], d_real_loss: 0.0434, d_mnist_loss: 0.0084, d_svhn_loss: 0.0350, d_fake_loss: 0.0549, g_loss: 1.0426\n",
            "Step [26430/60000], d_real_loss: 0.0946, d_mnist_loss: 0.0280, d_svhn_loss: 0.0666, d_fake_loss: 0.0372, g_loss: 0.9839\n",
            "Step [26440/60000], d_real_loss: 0.0563, d_mnist_loss: 0.0275, d_svhn_loss: 0.0288, d_fake_loss: 0.0198, g_loss: 1.1255\n",
            "Step [26450/60000], d_real_loss: 0.1168, d_mnist_loss: 0.0189, d_svhn_loss: 0.0979, d_fake_loss: 0.1142, g_loss: 1.0409\n",
            "Step [26460/60000], d_real_loss: 0.0524, d_mnist_loss: 0.0213, d_svhn_loss: 0.0311, d_fake_loss: 0.0438, g_loss: 1.2268\n",
            "Step [26470/60000], d_real_loss: 0.0740, d_mnist_loss: 0.0083, d_svhn_loss: 0.0656, d_fake_loss: 0.0437, g_loss: 1.1467\n",
            "Step [26480/60000], d_real_loss: 0.1057, d_mnist_loss: 0.0365, d_svhn_loss: 0.0693, d_fake_loss: 0.0714, g_loss: 0.9961\n",
            "Step [26490/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0103, d_svhn_loss: 0.0210, d_fake_loss: 0.0769, g_loss: 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999977946281433, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [26500/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0246, d_svhn_loss: 0.0225, d_fake_loss: 0.0361, g_loss: 1.1186\n",
            "saved ./samples_fashion/sample-26500-m-s.png\n",
            "saved ./samples_fashion/sample-26500-s-m.png\n",
            "Step [26510/60000], d_real_loss: 0.0408, d_mnist_loss: 0.0172, d_svhn_loss: 0.0236, d_fake_loss: 0.0997, g_loss: 1.3622\n",
            "Step [26520/60000], d_real_loss: 0.1085, d_mnist_loss: 0.0485, d_svhn_loss: 0.0601, d_fake_loss: 0.0907, g_loss: 1.1987\n",
            "Step [26530/60000], d_real_loss: 0.0738, d_mnist_loss: 0.0525, d_svhn_loss: 0.0213, d_fake_loss: 0.0402, g_loss: 1.3435\n",
            "Step [26540/60000], d_real_loss: 0.0417, d_mnist_loss: 0.0215, d_svhn_loss: 0.0202, d_fake_loss: 0.1915, g_loss: 1.2473\n",
            "Step [26550/60000], d_real_loss: 0.0343, d_mnist_loss: 0.0101, d_svhn_loss: 0.0242, d_fake_loss: 0.0538, g_loss: 1.1002\n",
            "Step [26560/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0116, d_svhn_loss: 0.0190, d_fake_loss: 0.0414, g_loss: 0.9544\n",
            "Step [26570/60000], d_real_loss: 0.0556, d_mnist_loss: 0.0109, d_svhn_loss: 0.0447, d_fake_loss: 0.0282, g_loss: 1.1298\n",
            "Step [26580/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0108, d_svhn_loss: 0.0227, d_fake_loss: 0.0698, g_loss: 1.2667\n",
            "Step [26590/60000], d_real_loss: 0.0495, d_mnist_loss: 0.0160, d_svhn_loss: 0.0335, d_fake_loss: 0.0272, g_loss: 1.1543\n",
            "Step [26600/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0197, d_svhn_loss: 0.0399, d_fake_loss: 0.0674, g_loss: 1.4418\n",
            "Step [26610/60000], d_real_loss: 0.0643, d_mnist_loss: 0.0240, d_svhn_loss: 0.0403, d_fake_loss: 0.0765, g_loss: 1.0936\n",
            "Step [26620/60000], d_real_loss: 0.1104, d_mnist_loss: 0.0144, d_svhn_loss: 0.0960, d_fake_loss: 0.1327, g_loss: 0.8980\n",
            "Step [26630/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0097, d_svhn_loss: 0.0201, d_fake_loss: 0.0368, g_loss: 1.0857\n",
            "Step [26640/60000], d_real_loss: 0.0491, d_mnist_loss: 0.0219, d_svhn_loss: 0.0272, d_fake_loss: 0.0301, g_loss: 1.1303\n",
            "Step [26650/60000], d_real_loss: 0.0463, d_mnist_loss: 0.0138, d_svhn_loss: 0.0325, d_fake_loss: 0.1058, g_loss: 1.1330\n",
            "Step [26660/60000], d_real_loss: 0.0384, d_mnist_loss: 0.0120, d_svhn_loss: 0.0264, d_fake_loss: 0.0663, g_loss: 1.1620\n",
            "Step [26670/60000], d_real_loss: 0.0496, d_mnist_loss: 0.0199, d_svhn_loss: 0.0296, d_fake_loss: 0.1795, g_loss: 1.0972\n",
            "Step [26680/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0124, d_svhn_loss: 0.0233, d_fake_loss: 0.0725, g_loss: 1.3647\n",
            "Step [26690/60000], d_real_loss: 0.0331, d_mnist_loss: 0.0082, d_svhn_loss: 0.0249, d_fake_loss: 0.0229, g_loss: 1.0761\n",
            "Step [26700/60000], d_real_loss: 0.0815, d_mnist_loss: 0.0195, d_svhn_loss: 0.0620, d_fake_loss: 0.0379, g_loss: 1.2320\n",
            "Step [26710/60000], d_real_loss: 0.1399, d_mnist_loss: 0.0952, d_svhn_loss: 0.0447, d_fake_loss: 0.0390, g_loss: 1.2018\n",
            "Step [26720/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0181, d_svhn_loss: 0.0195, d_fake_loss: 0.0832, g_loss: 1.2608\n",
            "Step [26730/60000], d_real_loss: 0.1812, d_mnist_loss: 0.0261, d_svhn_loss: 0.1551, d_fake_loss: 0.2557, g_loss: 1.1547\n",
            "Step [26740/60000], d_real_loss: 0.1116, d_mnist_loss: 0.0114, d_svhn_loss: 0.1001, d_fake_loss: 0.0569, g_loss: 1.0128\n",
            "Step [26750/60000], d_real_loss: 0.1174, d_mnist_loss: 0.0196, d_svhn_loss: 0.0978, d_fake_loss: 0.0981, g_loss: 1.2366\n",
            "Step [26760/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0203, d_svhn_loss: 0.0304, d_fake_loss: 0.0309, g_loss: 1.1659\n",
            "Step [26770/60000], d_real_loss: 0.0719, d_mnist_loss: 0.0495, d_svhn_loss: 0.0224, d_fake_loss: 0.0469, g_loss: 1.1315\n",
            "Step [26780/60000], d_real_loss: 0.0708, d_mnist_loss: 0.0393, d_svhn_loss: 0.0315, d_fake_loss: 0.0842, g_loss: 1.1977\n",
            "Step [26790/60000], d_real_loss: 0.0366, d_mnist_loss: 0.0140, d_svhn_loss: 0.0226, d_fake_loss: 0.0620, g_loss: 0.9593\n",
            "Step [26800/60000], d_real_loss: 0.0631, d_mnist_loss: 0.0143, d_svhn_loss: 0.0489, d_fake_loss: 0.0607, g_loss: 1.1765\n",
            "Step [26810/60000], d_real_loss: 0.0459, d_mnist_loss: 0.0091, d_svhn_loss: 0.0368, d_fake_loss: 0.0727, g_loss: 1.0163\n",
            "Step [26820/60000], d_real_loss: 0.0354, d_mnist_loss: 0.0093, d_svhn_loss: 0.0261, d_fake_loss: 0.0281, g_loss: 1.1006\n",
            "Step [26830/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0180, d_svhn_loss: 0.0177, d_fake_loss: 0.0435, g_loss: 1.1324\n",
            "Step [26840/60000], d_real_loss: 0.0607, d_mnist_loss: 0.0217, d_svhn_loss: 0.0390, d_fake_loss: 0.0204, g_loss: 1.3419\n",
            "Step [26850/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0152, d_svhn_loss: 0.0237, d_fake_loss: 0.0234, g_loss: 0.9764\n",
            "Step [26860/60000], d_real_loss: 0.0378, d_mnist_loss: 0.0176, d_svhn_loss: 0.0202, d_fake_loss: 0.0481, g_loss: 1.2411\n",
            "Step [26870/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0141, d_svhn_loss: 0.0210, d_fake_loss: 0.0690, g_loss: 0.8920\n",
            "Step [26880/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0260, d_svhn_loss: 0.0160, d_fake_loss: 0.1058, g_loss: 1.2346\n",
            "Step [26890/60000], d_real_loss: 0.1902, d_mnist_loss: 0.0426, d_svhn_loss: 0.1476, d_fake_loss: 0.0644, g_loss: 1.0820\n",
            "Step [26900/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0102, d_svhn_loss: 0.0229, d_fake_loss: 0.0828, g_loss: 1.0787\n",
            "Step [26910/60000], d_real_loss: 0.0712, d_mnist_loss: 0.0269, d_svhn_loss: 0.0443, d_fake_loss: 0.0308, g_loss: 1.2638\n",
            "Step [26920/60000], d_real_loss: 0.0296, d_mnist_loss: 0.0122, d_svhn_loss: 0.0175, d_fake_loss: 0.1469, g_loss: 1.1091\n",
            "Step [26930/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0173, d_svhn_loss: 0.0192, d_fake_loss: 0.0261, g_loss: 1.1488\n",
            "Step [26940/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0115, d_svhn_loss: 0.0241, d_fake_loss: 0.0510, g_loss: 1.2221\n",
            "Step [26950/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0131, d_svhn_loss: 0.0188, d_fake_loss: 0.2112, g_loss: 1.1840\n",
            "Step [26960/60000], d_real_loss: 0.0302, d_mnist_loss: 0.0141, d_svhn_loss: 0.0161, d_fake_loss: 0.0770, g_loss: 0.9891\n",
            "Step [26970/60000], d_real_loss: 0.0980, d_mnist_loss: 0.0092, d_svhn_loss: 0.0889, d_fake_loss: 0.1015, g_loss: 1.1252\n",
            "Step [26980/60000], d_real_loss: 0.0434, d_mnist_loss: 0.0066, d_svhn_loss: 0.0368, d_fake_loss: 0.0773, g_loss: 1.3149\n",
            "Step [26990/60000], d_real_loss: 0.0512, d_mnist_loss: 0.0142, d_svhn_loss: 0.0370, d_fake_loss: 0.0247, g_loss: 1.1183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [27000/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0229, d_svhn_loss: 0.0344, d_fake_loss: 0.0460, g_loss: 1.1430\n",
            "saved ./samples_fashion/sample-27000-m-s.png\n",
            "saved ./samples_fashion/sample-27000-s-m.png\n",
            "Step [27010/60000], d_real_loss: 0.0354, d_mnist_loss: 0.0138, d_svhn_loss: 0.0216, d_fake_loss: 0.0243, g_loss: 1.2022\n",
            "Step [27020/60000], d_real_loss: 0.1323, d_mnist_loss: 0.0397, d_svhn_loss: 0.0926, d_fake_loss: 0.0319, g_loss: 1.1701\n",
            "Step [27030/60000], d_real_loss: 0.0644, d_mnist_loss: 0.0412, d_svhn_loss: 0.0232, d_fake_loss: 0.0371, g_loss: 1.3969\n",
            "Step [27040/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0172, d_svhn_loss: 0.0215, d_fake_loss: 0.0226, g_loss: 1.0863\n",
            "Step [27050/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0077, d_svhn_loss: 0.0406, d_fake_loss: 0.0330, g_loss: 0.9271\n",
            "Step [27060/60000], d_real_loss: 0.0632, d_mnist_loss: 0.0358, d_svhn_loss: 0.0273, d_fake_loss: 0.0571, g_loss: 1.1417\n",
            "Step [27070/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0167, d_svhn_loss: 0.0195, d_fake_loss: 0.0324, g_loss: 0.9406\n",
            "Step [27080/60000], d_real_loss: 0.0670, d_mnist_loss: 0.0473, d_svhn_loss: 0.0196, d_fake_loss: 0.0857, g_loss: 1.1888\n",
            "Step [27090/60000], d_real_loss: 0.0633, d_mnist_loss: 0.0273, d_svhn_loss: 0.0360, d_fake_loss: 0.0382, g_loss: 1.2882\n",
            "Step [27100/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0071, d_svhn_loss: 0.0303, d_fake_loss: 0.0200, g_loss: 1.1743\n",
            "Step [27110/60000], d_real_loss: 0.0617, d_mnist_loss: 0.0121, d_svhn_loss: 0.0496, d_fake_loss: 0.0291, g_loss: 1.0160\n",
            "Step [27120/60000], d_real_loss: 0.0988, d_mnist_loss: 0.0423, d_svhn_loss: 0.0564, d_fake_loss: 0.1753, g_loss: 1.5405\n",
            "Step [27130/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0160, d_svhn_loss: 0.0277, d_fake_loss: 0.0375, g_loss: 1.1528\n",
            "Step [27140/60000], d_real_loss: 0.0553, d_mnist_loss: 0.0229, d_svhn_loss: 0.0324, d_fake_loss: 0.2670, g_loss: 1.1349\n",
            "Step [27150/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0075, d_svhn_loss: 0.0272, d_fake_loss: 0.0298, g_loss: 0.9756\n",
            "Step [27160/60000], d_real_loss: 0.0778, d_mnist_loss: 0.0335, d_svhn_loss: 0.0444, d_fake_loss: 0.0508, g_loss: 1.1940\n",
            "Step [27170/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0122, d_svhn_loss: 0.0311, d_fake_loss: 0.0798, g_loss: 0.9655\n",
            "Step [27180/60000], d_real_loss: 0.0683, d_mnist_loss: 0.0270, d_svhn_loss: 0.0412, d_fake_loss: 0.1031, g_loss: 1.1510\n",
            "Step [27190/60000], d_real_loss: 0.0618, d_mnist_loss: 0.0398, d_svhn_loss: 0.0221, d_fake_loss: 0.0534, g_loss: 1.1167\n",
            "Step [27200/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0074, d_svhn_loss: 0.0347, d_fake_loss: 0.0847, g_loss: 1.1072\n",
            "Step [27210/60000], d_real_loss: 0.0417, d_mnist_loss: 0.0094, d_svhn_loss: 0.0323, d_fake_loss: 0.1752, g_loss: 1.4824\n",
            "Step [27220/60000], d_real_loss: 0.0660, d_mnist_loss: 0.0072, d_svhn_loss: 0.0588, d_fake_loss: 0.0255, g_loss: 1.1419\n",
            "Step [27230/60000], d_real_loss: 0.0944, d_mnist_loss: 0.0117, d_svhn_loss: 0.0827, d_fake_loss: 0.1590, g_loss: 1.0374\n",
            "Step [27240/60000], d_real_loss: 0.0650, d_mnist_loss: 0.0391, d_svhn_loss: 0.0260, d_fake_loss: 0.0266, g_loss: 1.2237\n",
            "Step [27250/60000], d_real_loss: 0.0297, d_mnist_loss: 0.0115, d_svhn_loss: 0.0182, d_fake_loss: 0.0714, g_loss: 1.1012\n",
            "Step [27260/60000], d_real_loss: 0.0526, d_mnist_loss: 0.0311, d_svhn_loss: 0.0215, d_fake_loss: 0.1782, g_loss: 0.5505\n",
            "Step [27270/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0131, d_svhn_loss: 0.0283, d_fake_loss: 0.1169, g_loss: 1.0903\n",
            "Step [27280/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0126, d_svhn_loss: 0.0225, d_fake_loss: 0.0295, g_loss: 1.2485\n",
            "Step [27290/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0194, d_svhn_loss: 0.0399, d_fake_loss: 0.1417, g_loss: 1.1828\n",
            "Step [27300/60000], d_real_loss: 0.1082, d_mnist_loss: 0.0283, d_svhn_loss: 0.0799, d_fake_loss: 0.0872, g_loss: 1.0775\n",
            "Step [27310/60000], d_real_loss: 0.0940, d_mnist_loss: 0.0555, d_svhn_loss: 0.0385, d_fake_loss: 0.1354, g_loss: 0.7782\n",
            "Step [27320/60000], d_real_loss: 0.0796, d_mnist_loss: 0.0119, d_svhn_loss: 0.0677, d_fake_loss: 0.0722, g_loss: 1.1653\n",
            "Step [27330/60000], d_real_loss: 0.0424, d_mnist_loss: 0.0180, d_svhn_loss: 0.0244, d_fake_loss: 0.0638, g_loss: 1.0352\n",
            "Step [27340/60000], d_real_loss: 0.0923, d_mnist_loss: 0.0182, d_svhn_loss: 0.0742, d_fake_loss: 0.0411, g_loss: 1.0694\n",
            "Step [27350/60000], d_real_loss: 0.0462, d_mnist_loss: 0.0211, d_svhn_loss: 0.0250, d_fake_loss: 0.0570, g_loss: 1.3590\n",
            "Step [27360/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0141, d_svhn_loss: 0.0341, d_fake_loss: 0.0664, g_loss: 1.3395\n",
            "Step [27370/60000], d_real_loss: 0.1594, d_mnist_loss: 0.0154, d_svhn_loss: 0.1440, d_fake_loss: 0.0322, g_loss: 1.0922\n",
            "Step [27380/60000], d_real_loss: 0.1181, d_mnist_loss: 0.0144, d_svhn_loss: 0.1037, d_fake_loss: 0.0571, g_loss: 1.0187\n",
            "Step [27390/60000], d_real_loss: 0.0446, d_mnist_loss: 0.0233, d_svhn_loss: 0.0213, d_fake_loss: 0.0391, g_loss: 0.9783\n",
            "Step [27400/60000], d_real_loss: 0.1150, d_mnist_loss: 0.0411, d_svhn_loss: 0.0739, d_fake_loss: 0.0969, g_loss: 1.2989\n",
            "Step [27410/60000], d_real_loss: 0.1640, d_mnist_loss: 0.0144, d_svhn_loss: 0.1496, d_fake_loss: 0.0389, g_loss: 1.1063\n",
            "Step [27420/60000], d_real_loss: 0.0558, d_mnist_loss: 0.0155, d_svhn_loss: 0.0403, d_fake_loss: 0.0608, g_loss: 1.1791\n",
            "Step [27430/60000], d_real_loss: 0.0780, d_mnist_loss: 0.0183, d_svhn_loss: 0.0597, d_fake_loss: 0.1141, g_loss: 1.3017\n",
            "Step [27440/60000], d_real_loss: 0.0328, d_mnist_loss: 0.0174, d_svhn_loss: 0.0154, d_fake_loss: 0.0288, g_loss: 1.2041\n",
            "Step [27450/60000], d_real_loss: 0.1736, d_mnist_loss: 0.1116, d_svhn_loss: 0.0620, d_fake_loss: 0.1658, g_loss: 1.4231\n",
            "Step [27460/60000], d_real_loss: 0.0836, d_mnist_loss: 0.0542, d_svhn_loss: 0.0294, d_fake_loss: 0.1258, g_loss: 1.1185\n",
            "Step [27470/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0059, d_svhn_loss: 0.0457, d_fake_loss: 0.0329, g_loss: 1.0638\n",
            "Step [27480/60000], d_real_loss: 0.0736, d_mnist_loss: 0.0140, d_svhn_loss: 0.0596, d_fake_loss: 0.0603, g_loss: 0.9485\n",
            "Step [27490/60000], d_real_loss: 0.0656, d_mnist_loss: 0.0309, d_svhn_loss: 0.0347, d_fake_loss: 0.0304, g_loss: 0.9453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [27500/60000], d_real_loss: 0.0717, d_mnist_loss: 0.0453, d_svhn_loss: 0.0264, d_fake_loss: 0.0282, g_loss: 1.3271\n",
            "saved ./samples_fashion/sample-27500-m-s.png\n",
            "saved ./samples_fashion/sample-27500-s-m.png\n",
            "Step [27510/60000], d_real_loss: 0.0524, d_mnist_loss: 0.0183, d_svhn_loss: 0.0341, d_fake_loss: 0.1925, g_loss: 1.4850\n",
            "Step [27520/60000], d_real_loss: 0.0350, d_mnist_loss: 0.0085, d_svhn_loss: 0.0265, d_fake_loss: 0.0644, g_loss: 1.2105\n",
            "Step [27530/60000], d_real_loss: 0.1769, d_mnist_loss: 0.0403, d_svhn_loss: 0.1367, d_fake_loss: 0.1373, g_loss: 1.1783\n",
            "Step [27540/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0373, d_svhn_loss: 0.0213, d_fake_loss: 0.0215, g_loss: 1.2178\n",
            "Step [27550/60000], d_real_loss: 0.0622, d_mnist_loss: 0.0299, d_svhn_loss: 0.0323, d_fake_loss: 0.0390, g_loss: 1.0341\n",
            "Step [27560/60000], d_real_loss: 0.0350, d_mnist_loss: 0.0137, d_svhn_loss: 0.0214, d_fake_loss: 0.0428, g_loss: 1.2065\n",
            "Step [27570/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0184, d_svhn_loss: 0.0413, d_fake_loss: 0.0233, g_loss: 1.1309\n",
            "Step [27580/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0301, d_svhn_loss: 0.0174, d_fake_loss: 0.0334, g_loss: 1.2387\n",
            "Step [27590/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0149, d_svhn_loss: 0.0252, d_fake_loss: 0.0377, g_loss: 1.1067\n",
            "Step [27600/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0222, d_svhn_loss: 0.0146, d_fake_loss: 0.1013, g_loss: 1.1886\n",
            "Step [27610/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0158, d_svhn_loss: 0.0323, d_fake_loss: 0.0386, g_loss: 1.2862\n",
            "Step [27620/60000], d_real_loss: 0.0813, d_mnist_loss: 0.0127, d_svhn_loss: 0.0687, d_fake_loss: 0.0583, g_loss: 1.2104\n",
            "Step [27630/60000], d_real_loss: 0.0790, d_mnist_loss: 0.0091, d_svhn_loss: 0.0699, d_fake_loss: 0.1602, g_loss: 1.0224\n",
            "Step [27640/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0100, d_svhn_loss: 0.0370, d_fake_loss: 0.1338, g_loss: 0.9647\n",
            "Step [27650/60000], d_real_loss: 0.0962, d_mnist_loss: 0.0164, d_svhn_loss: 0.0798, d_fake_loss: 0.2092, g_loss: 1.6724\n",
            "Step [27660/60000], d_real_loss: 0.0787, d_mnist_loss: 0.0360, d_svhn_loss: 0.0427, d_fake_loss: 0.0426, g_loss: 1.1157\n",
            "Step [27670/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0256, d_svhn_loss: 0.0183, d_fake_loss: 0.0771, g_loss: 1.1702\n",
            "Step [27680/60000], d_real_loss: 0.0435, d_mnist_loss: 0.0093, d_svhn_loss: 0.0342, d_fake_loss: 0.0456, g_loss: 1.1977\n",
            "Step [27690/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0221, d_svhn_loss: 0.0329, d_fake_loss: 0.0182, g_loss: 1.0867\n",
            "Step [27700/60000], d_real_loss: 0.1554, d_mnist_loss: 0.0098, d_svhn_loss: 0.1456, d_fake_loss: 0.2013, g_loss: 1.4107\n",
            "Step [27710/60000], d_real_loss: 0.0949, d_mnist_loss: 0.0415, d_svhn_loss: 0.0534, d_fake_loss: 0.0572, g_loss: 1.2049\n",
            "Step [27720/60000], d_real_loss: 0.0725, d_mnist_loss: 0.0520, d_svhn_loss: 0.0206, d_fake_loss: 0.0830, g_loss: 0.9243\n",
            "Step [27730/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0162, d_svhn_loss: 0.0421, d_fake_loss: 0.0505, g_loss: 1.1492\n",
            "Step [27740/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0108, d_svhn_loss: 0.0250, d_fake_loss: 0.0931, g_loss: 1.3921\n",
            "Step [27750/60000], d_real_loss: 0.0235, d_mnist_loss: 0.0079, d_svhn_loss: 0.0156, d_fake_loss: 0.0630, g_loss: 1.2803\n",
            "Step [27760/60000], d_real_loss: 0.0886, d_mnist_loss: 0.0120, d_svhn_loss: 0.0766, d_fake_loss: 0.0280, g_loss: 0.9965\n",
            "Step [27770/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0149, d_svhn_loss: 0.0203, d_fake_loss: 0.0248, g_loss: 1.0678\n",
            "Step [27780/60000], d_real_loss: 0.0956, d_mnist_loss: 0.0111, d_svhn_loss: 0.0846, d_fake_loss: 0.0950, g_loss: 1.1329\n",
            "Step [27790/60000], d_real_loss: 0.1321, d_mnist_loss: 0.0162, d_svhn_loss: 0.1159, d_fake_loss: 0.0401, g_loss: 0.9903\n",
            "Step [27800/60000], d_real_loss: 0.1069, d_mnist_loss: 0.0057, d_svhn_loss: 0.1012, d_fake_loss: 0.0853, g_loss: 1.1618\n",
            "Step [27810/60000], d_real_loss: 0.0706, d_mnist_loss: 0.0129, d_svhn_loss: 0.0577, d_fake_loss: 0.0629, g_loss: 1.0698\n",
            "Step [27820/60000], d_real_loss: 0.0591, d_mnist_loss: 0.0223, d_svhn_loss: 0.0367, d_fake_loss: 0.0825, g_loss: 1.2279\n",
            "Step [27830/60000], d_real_loss: 0.0490, d_mnist_loss: 0.0071, d_svhn_loss: 0.0419, d_fake_loss: 0.0318, g_loss: 1.0528\n",
            "Step [27840/60000], d_real_loss: 0.0580, d_mnist_loss: 0.0404, d_svhn_loss: 0.0177, d_fake_loss: 0.0276, g_loss: 1.2962\n",
            "Step [27850/60000], d_real_loss: 0.0720, d_mnist_loss: 0.0118, d_svhn_loss: 0.0602, d_fake_loss: 0.1081, g_loss: 1.1391\n",
            "Step [27860/60000], d_real_loss: 0.1221, d_mnist_loss: 0.1034, d_svhn_loss: 0.0187, d_fake_loss: 0.0359, g_loss: 1.3552\n",
            "Step [27870/60000], d_real_loss: 0.1144, d_mnist_loss: 0.0113, d_svhn_loss: 0.1031, d_fake_loss: 0.0604, g_loss: 1.2113\n",
            "Step [27880/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0264, d_svhn_loss: 0.0169, d_fake_loss: 0.0191, g_loss: 1.1449\n",
            "Step [27890/60000], d_real_loss: 0.0731, d_mnist_loss: 0.0557, d_svhn_loss: 0.0174, d_fake_loss: 0.0633, g_loss: 1.1045\n",
            "Step [27900/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0150, d_svhn_loss: 0.0317, d_fake_loss: 0.0575, g_loss: 1.1771\n",
            "Step [27910/60000], d_real_loss: 0.0570, d_mnist_loss: 0.0181, d_svhn_loss: 0.0390, d_fake_loss: 0.0446, g_loss: 1.2279\n",
            "Step [27920/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0208, d_svhn_loss: 0.0276, d_fake_loss: 0.0504, g_loss: 0.9951\n",
            "Step [27930/60000], d_real_loss: 0.0388, d_mnist_loss: 0.0170, d_svhn_loss: 0.0218, d_fake_loss: 0.0613, g_loss: 0.7756\n",
            "Step [27940/60000], d_real_loss: 0.0497, d_mnist_loss: 0.0190, d_svhn_loss: 0.0307, d_fake_loss: 0.0234, g_loss: 1.0210\n",
            "Step [27950/60000], d_real_loss: 0.0557, d_mnist_loss: 0.0207, d_svhn_loss: 0.0350, d_fake_loss: 0.1021, g_loss: 1.0011\n",
            "Step [27960/60000], d_real_loss: 0.0491, d_mnist_loss: 0.0339, d_svhn_loss: 0.0151, d_fake_loss: 0.0645, g_loss: 1.1910\n",
            "Step [27970/60000], d_real_loss: 0.0497, d_mnist_loss: 0.0120, d_svhn_loss: 0.0377, d_fake_loss: 0.0551, g_loss: 1.1392\n",
            "Step [27980/60000], d_real_loss: 0.0278, d_mnist_loss: 0.0094, d_svhn_loss: 0.0185, d_fake_loss: 0.0481, g_loss: 1.1078\n",
            "Step [27990/60000], d_real_loss: 0.0510, d_mnist_loss: 0.0195, d_svhn_loss: 0.0315, d_fake_loss: 0.1675, g_loss: 1.1924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [28000/60000], d_real_loss: 0.0339, d_mnist_loss: 0.0076, d_svhn_loss: 0.0263, d_fake_loss: 0.0232, g_loss: 1.0996\n",
            "saved ./samples_fashion/sample-28000-m-s.png\n",
            "saved ./samples_fashion/sample-28000-s-m.png\n",
            "Step [28010/60000], d_real_loss: 0.1868, d_mnist_loss: 0.0121, d_svhn_loss: 0.1747, d_fake_loss: 0.0801, g_loss: 1.2400\n",
            "Step [28020/60000], d_real_loss: 0.1566, d_mnist_loss: 0.0912, d_svhn_loss: 0.0654, d_fake_loss: 0.0394, g_loss: 1.0657\n",
            "Step [28030/60000], d_real_loss: 0.0415, d_mnist_loss: 0.0093, d_svhn_loss: 0.0322, d_fake_loss: 0.0504, g_loss: 1.1606\n",
            "Step [28040/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0210, d_svhn_loss: 0.0260, d_fake_loss: 0.0293, g_loss: 1.0468\n",
            "Step [28050/60000], d_real_loss: 0.0933, d_mnist_loss: 0.0205, d_svhn_loss: 0.0728, d_fake_loss: 0.1757, g_loss: 0.9621\n",
            "Step [28060/60000], d_real_loss: 0.0778, d_mnist_loss: 0.0081, d_svhn_loss: 0.0697, d_fake_loss: 0.1420, g_loss: 1.1436\n",
            "Step [28070/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0151, d_svhn_loss: 0.0292, d_fake_loss: 0.1952, g_loss: 0.9985\n",
            "Step [28080/60000], d_real_loss: 0.1098, d_mnist_loss: 0.0101, d_svhn_loss: 0.0997, d_fake_loss: 0.0181, g_loss: 1.1419\n",
            "Step [28090/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0124, d_svhn_loss: 0.0465, d_fake_loss: 0.0617, g_loss: 1.1126\n",
            "Step [28100/60000], d_real_loss: 0.0638, d_mnist_loss: 0.0179, d_svhn_loss: 0.0458, d_fake_loss: 0.0441, g_loss: 1.1891\n",
            "Step [28110/60000], d_real_loss: 0.0860, d_mnist_loss: 0.0155, d_svhn_loss: 0.0705, d_fake_loss: 0.0334, g_loss: 1.0909\n",
            "Step [28120/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0177, d_svhn_loss: 0.0254, d_fake_loss: 0.0248, g_loss: 1.0126\n",
            "Step [28130/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0137, d_svhn_loss: 0.0187, d_fake_loss: 0.1031, g_loss: 1.0932\n",
            "Step [28140/60000], d_real_loss: 0.0960, d_mnist_loss: 0.0108, d_svhn_loss: 0.0852, d_fake_loss: 0.0271, g_loss: 1.1826\n",
            "Step [28150/60000], d_real_loss: 0.0549, d_mnist_loss: 0.0326, d_svhn_loss: 0.0223, d_fake_loss: 0.0237, g_loss: 1.2736\n",
            "Step [28160/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0144, d_svhn_loss: 0.0295, d_fake_loss: 0.0828, g_loss: 1.3018\n",
            "Step [28170/60000], d_real_loss: 0.0838, d_mnist_loss: 0.0456, d_svhn_loss: 0.0382, d_fake_loss: 0.1037, g_loss: 1.1947\n",
            "Step [28180/60000], d_real_loss: 0.0611, d_mnist_loss: 0.0399, d_svhn_loss: 0.0212, d_fake_loss: 0.0391, g_loss: 1.2182\n",
            "Step [28190/60000], d_real_loss: 0.0823, d_mnist_loss: 0.0090, d_svhn_loss: 0.0732, d_fake_loss: 0.0248, g_loss: 1.1154\n",
            "Step [28200/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0166, d_svhn_loss: 0.0206, d_fake_loss: 0.0352, g_loss: 1.0091\n",
            "Step [28210/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0126, d_svhn_loss: 0.0226, d_fake_loss: 0.0306, g_loss: 1.2131\n",
            "Step [28220/60000], d_real_loss: 0.1061, d_mnist_loss: 0.0310, d_svhn_loss: 0.0750, d_fake_loss: 0.1489, g_loss: 1.6796\n",
            "Step [28230/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0214, d_svhn_loss: 0.0202, d_fake_loss: 0.0583, g_loss: 1.1588\n",
            "Step [28240/60000], d_real_loss: 0.0477, d_mnist_loss: 0.0117, d_svhn_loss: 0.0360, d_fake_loss: 0.0452, g_loss: 0.9059\n",
            "Step [28250/60000], d_real_loss: 0.0380, d_mnist_loss: 0.0086, d_svhn_loss: 0.0294, d_fake_loss: 0.0738, g_loss: 1.3360\n",
            "Step [28260/60000], d_real_loss: 0.0793, d_mnist_loss: 0.0140, d_svhn_loss: 0.0653, d_fake_loss: 0.0674, g_loss: 1.1249\n",
            "Step [28270/60000], d_real_loss: 0.4062, d_mnist_loss: 0.3154, d_svhn_loss: 0.0908, d_fake_loss: 0.0843, g_loss: 1.4960\n",
            "Step [28280/60000], d_real_loss: 0.0716, d_mnist_loss: 0.0143, d_svhn_loss: 0.0572, d_fake_loss: 0.1748, g_loss: 1.0590\n",
            "Step [28290/60000], d_real_loss: 0.0832, d_mnist_loss: 0.0085, d_svhn_loss: 0.0747, d_fake_loss: 0.0388, g_loss: 1.2195\n",
            "Step [28300/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0088, d_svhn_loss: 0.0221, d_fake_loss: 0.0314, g_loss: 1.1302\n",
            "Step [28310/60000], d_real_loss: 0.0446, d_mnist_loss: 0.0146, d_svhn_loss: 0.0301, d_fake_loss: 0.0401, g_loss: 1.1607\n",
            "Step [28320/60000], d_real_loss: 0.0997, d_mnist_loss: 0.0158, d_svhn_loss: 0.0839, d_fake_loss: 0.0405, g_loss: 1.3637\n",
            "Step [28330/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0245, d_svhn_loss: 0.0231, d_fake_loss: 0.0379, g_loss: 0.9747\n",
            "Step [28340/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0201, d_svhn_loss: 0.0195, d_fake_loss: 0.0279, g_loss: 1.1193\n",
            "Step [28350/60000], d_real_loss: 0.1674, d_mnist_loss: 0.0213, d_svhn_loss: 0.1461, d_fake_loss: 0.0500, g_loss: 1.1730\n",
            "Step [28360/60000], d_real_loss: 0.0731, d_mnist_loss: 0.0123, d_svhn_loss: 0.0608, d_fake_loss: 0.0652, g_loss: 0.9520\n",
            "Step [28370/60000], d_real_loss: 0.0434, d_mnist_loss: 0.0131, d_svhn_loss: 0.0303, d_fake_loss: 0.0462, g_loss: 1.0230\n",
            "Step [28380/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0195, d_svhn_loss: 0.0181, d_fake_loss: 0.0741, g_loss: 1.2150\n",
            "Step [28390/60000], d_real_loss: 0.0508, d_mnist_loss: 0.0176, d_svhn_loss: 0.0332, d_fake_loss: 0.1605, g_loss: 0.9494\n",
            "Step [28400/60000], d_real_loss: 0.0388, d_mnist_loss: 0.0229, d_svhn_loss: 0.0159, d_fake_loss: 0.0676, g_loss: 1.1566\n",
            "Step [28410/60000], d_real_loss: 0.2149, d_mnist_loss: 0.0115, d_svhn_loss: 0.2033, d_fake_loss: 0.0417, g_loss: 1.0629\n",
            "Step [28420/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0095, d_svhn_loss: 0.0252, d_fake_loss: 0.0232, g_loss: 1.2131\n",
            "Step [28430/60000], d_real_loss: 0.0430, d_mnist_loss: 0.0222, d_svhn_loss: 0.0207, d_fake_loss: 0.0316, g_loss: 1.1042\n",
            "Step [28440/60000], d_real_loss: 0.0579, d_mnist_loss: 0.0216, d_svhn_loss: 0.0363, d_fake_loss: 0.0405, g_loss: 1.1656\n",
            "Step [28450/60000], d_real_loss: 0.0683, d_mnist_loss: 0.0331, d_svhn_loss: 0.0351, d_fake_loss: 0.0519, g_loss: 0.9962\n",
            "Step [28460/60000], d_real_loss: 0.1002, d_mnist_loss: 0.0228, d_svhn_loss: 0.0774, d_fake_loss: 0.0446, g_loss: 1.0565\n",
            "Step [28470/60000], d_real_loss: 0.0502, d_mnist_loss: 0.0279, d_svhn_loss: 0.0222, d_fake_loss: 0.0395, g_loss: 1.1111\n",
            "Step [28480/60000], d_real_loss: 0.1923, d_mnist_loss: 0.0541, d_svhn_loss: 0.1382, d_fake_loss: 0.1148, g_loss: 1.1751\n",
            "Step [28490/60000], d_real_loss: 0.1365, d_mnist_loss: 0.0508, d_svhn_loss: 0.0857, d_fake_loss: 0.2640, g_loss: 1.3394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999990463256836, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [28500/60000], d_real_loss: 0.0546, d_mnist_loss: 0.0200, d_svhn_loss: 0.0346, d_fake_loss: 0.0655, g_loss: 1.1776\n",
            "saved ./samples_fashion/sample-28500-m-s.png\n",
            "saved ./samples_fashion/sample-28500-s-m.png\n",
            "Step [28510/60000], d_real_loss: 0.0281, d_mnist_loss: 0.0061, d_svhn_loss: 0.0220, d_fake_loss: 0.0575, g_loss: 1.3117\n",
            "Step [28520/60000], d_real_loss: 0.0266, d_mnist_loss: 0.0083, d_svhn_loss: 0.0183, d_fake_loss: 0.0557, g_loss: 1.0162\n",
            "Step [28530/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0078, d_svhn_loss: 0.0438, d_fake_loss: 0.2470, g_loss: 1.0378\n",
            "Step [28540/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0300, d_svhn_loss: 0.0118, d_fake_loss: 0.0215, g_loss: 1.0737\n",
            "Step [28550/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0092, d_svhn_loss: 0.0322, d_fake_loss: 0.0272, g_loss: 1.1892\n",
            "Step [28560/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0093, d_svhn_loss: 0.0246, d_fake_loss: 0.1252, g_loss: 1.1549\n",
            "Step [28570/60000], d_real_loss: 0.0502, d_mnist_loss: 0.0249, d_svhn_loss: 0.0254, d_fake_loss: 0.0377, g_loss: 1.1165\n",
            "Step [28580/60000], d_real_loss: 0.1311, d_mnist_loss: 0.1103, d_svhn_loss: 0.0208, d_fake_loss: 0.0695, g_loss: 1.2682\n",
            "Step [28590/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0254, d_svhn_loss: 0.0150, d_fake_loss: 0.0308, g_loss: 1.1656\n",
            "Step [28600/60000], d_real_loss: 0.1057, d_mnist_loss: 0.0412, d_svhn_loss: 0.0645, d_fake_loss: 0.0765, g_loss: 1.1859\n",
            "Step [28610/60000], d_real_loss: 0.1129, d_mnist_loss: 0.0133, d_svhn_loss: 0.0996, d_fake_loss: 0.0450, g_loss: 1.1559\n",
            "Step [28620/60000], d_real_loss: 0.0257, d_mnist_loss: 0.0109, d_svhn_loss: 0.0148, d_fake_loss: 0.0865, g_loss: 1.1192\n",
            "Step [28630/60000], d_real_loss: 0.1081, d_mnist_loss: 0.0228, d_svhn_loss: 0.0853, d_fake_loss: 0.0417, g_loss: 1.1862\n",
            "Step [28640/60000], d_real_loss: 0.0695, d_mnist_loss: 0.0089, d_svhn_loss: 0.0605, d_fake_loss: 0.1804, g_loss: 1.2744\n",
            "Step [28650/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0264, d_svhn_loss: 0.0309, d_fake_loss: 0.0228, g_loss: 1.1080\n",
            "Step [28660/60000], d_real_loss: 0.0356, d_mnist_loss: 0.0133, d_svhn_loss: 0.0224, d_fake_loss: 0.0604, g_loss: 1.1055\n",
            "Step [28670/60000], d_real_loss: 0.0560, d_mnist_loss: 0.0131, d_svhn_loss: 0.0429, d_fake_loss: 0.0501, g_loss: 1.1670\n",
            "Step [28680/60000], d_real_loss: 0.0273, d_mnist_loss: 0.0087, d_svhn_loss: 0.0186, d_fake_loss: 0.0586, g_loss: 1.2055\n",
            "Step [28690/60000], d_real_loss: 0.0500, d_mnist_loss: 0.0319, d_svhn_loss: 0.0182, d_fake_loss: 0.0523, g_loss: 1.3608\n",
            "Step [28700/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0219, d_svhn_loss: 0.0453, d_fake_loss: 0.0791, g_loss: 0.9979\n",
            "Step [28710/60000], d_real_loss: 0.0678, d_mnist_loss: 0.0485, d_svhn_loss: 0.0193, d_fake_loss: 0.0711, g_loss: 1.1645\n",
            "Step [28720/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0124, d_svhn_loss: 0.0211, d_fake_loss: 0.0231, g_loss: 1.0320\n",
            "Step [28730/60000], d_real_loss: 0.0294, d_mnist_loss: 0.0102, d_svhn_loss: 0.0192, d_fake_loss: 0.0229, g_loss: 1.0621\n",
            "Step [28740/60000], d_real_loss: 0.0258, d_mnist_loss: 0.0109, d_svhn_loss: 0.0149, d_fake_loss: 0.0410, g_loss: 1.1856\n",
            "Step [28750/60000], d_real_loss: 0.0462, d_mnist_loss: 0.0160, d_svhn_loss: 0.0302, d_fake_loss: 0.0582, g_loss: 1.2197\n",
            "Step [28760/60000], d_real_loss: 0.0504, d_mnist_loss: 0.0104, d_svhn_loss: 0.0400, d_fake_loss: 0.0340, g_loss: 0.9650\n",
            "Step [28770/60000], d_real_loss: 0.1039, d_mnist_loss: 0.0153, d_svhn_loss: 0.0886, d_fake_loss: 0.0948, g_loss: 1.2231\n",
            "Step [28780/60000], d_real_loss: 0.0602, d_mnist_loss: 0.0234, d_svhn_loss: 0.0368, d_fake_loss: 0.1061, g_loss: 1.2005\n",
            "Step [28790/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0303, d_svhn_loss: 0.0124, d_fake_loss: 0.0370, g_loss: 1.0033\n",
            "Step [28800/60000], d_real_loss: 0.1032, d_mnist_loss: 0.0128, d_svhn_loss: 0.0904, d_fake_loss: 0.0826, g_loss: 1.3490\n",
            "Step [28810/60000], d_real_loss: 0.1102, d_mnist_loss: 0.0378, d_svhn_loss: 0.0724, d_fake_loss: 0.0320, g_loss: 1.2123\n",
            "Step [28820/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0130, d_svhn_loss: 0.0152, d_fake_loss: 0.0597, g_loss: 1.3666\n",
            "Step [28830/60000], d_real_loss: 0.0586, d_mnist_loss: 0.0387, d_svhn_loss: 0.0199, d_fake_loss: 0.0519, g_loss: 1.0792\n",
            "Step [28840/60000], d_real_loss: 0.0690, d_mnist_loss: 0.0139, d_svhn_loss: 0.0551, d_fake_loss: 0.0301, g_loss: 1.3014\n",
            "Step [28850/60000], d_real_loss: 0.0705, d_mnist_loss: 0.0523, d_svhn_loss: 0.0182, d_fake_loss: 0.0734, g_loss: 1.0571\n",
            "Step [28860/60000], d_real_loss: 0.0250, d_mnist_loss: 0.0081, d_svhn_loss: 0.0169, d_fake_loss: 0.0421, g_loss: 1.2132\n",
            "Step [28870/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0159, d_svhn_loss: 0.0277, d_fake_loss: 0.0436, g_loss: 1.2120\n",
            "Step [28880/60000], d_real_loss: 0.0340, d_mnist_loss: 0.0196, d_svhn_loss: 0.0143, d_fake_loss: 0.1967, g_loss: 0.9696\n",
            "Step [28890/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0062, d_svhn_loss: 0.0243, d_fake_loss: 0.0340, g_loss: 1.1260\n",
            "Step [28900/60000], d_real_loss: 0.0536, d_mnist_loss: 0.0283, d_svhn_loss: 0.0253, d_fake_loss: 0.1288, g_loss: 1.0374\n",
            "Step [28910/60000], d_real_loss: 0.1341, d_mnist_loss: 0.0657, d_svhn_loss: 0.0685, d_fake_loss: 0.1408, g_loss: 1.0976\n",
            "Step [28920/60000], d_real_loss: 0.0411, d_mnist_loss: 0.0126, d_svhn_loss: 0.0285, d_fake_loss: 0.0432, g_loss: 1.2067\n",
            "Step [28930/60000], d_real_loss: 0.1359, d_mnist_loss: 0.0273, d_svhn_loss: 0.1086, d_fake_loss: 0.0595, g_loss: 0.9923\n",
            "Step [28940/60000], d_real_loss: 0.0454, d_mnist_loss: 0.0100, d_svhn_loss: 0.0354, d_fake_loss: 0.0616, g_loss: 0.9854\n",
            "Step [28950/60000], d_real_loss: 0.1072, d_mnist_loss: 0.0873, d_svhn_loss: 0.0199, d_fake_loss: 0.0207, g_loss: 1.3437\n",
            "Step [28960/60000], d_real_loss: 0.0512, d_mnist_loss: 0.0110, d_svhn_loss: 0.0403, d_fake_loss: 0.0811, g_loss: 0.9285\n",
            "Step [28970/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0153, d_svhn_loss: 0.0285, d_fake_loss: 0.0294, g_loss: 1.0959\n",
            "Step [28980/60000], d_real_loss: 0.0289, d_mnist_loss: 0.0141, d_svhn_loss: 0.0148, d_fake_loss: 0.0243, g_loss: 1.0531\n",
            "Step [28990/60000], d_real_loss: 0.0370, d_mnist_loss: 0.0078, d_svhn_loss: 0.0292, d_fake_loss: 0.0623, g_loss: 1.1524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [29000/60000], d_real_loss: 0.0541, d_mnist_loss: 0.0097, d_svhn_loss: 0.0445, d_fake_loss: 0.0488, g_loss: 1.2653\n",
            "saved ./samples_fashion/sample-29000-m-s.png\n",
            "saved ./samples_fashion/sample-29000-s-m.png\n",
            "Step [29010/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0218, d_svhn_loss: 0.0202, d_fake_loss: 0.1177, g_loss: 0.9632\n",
            "Step [29020/60000], d_real_loss: 0.0989, d_mnist_loss: 0.0087, d_svhn_loss: 0.0902, d_fake_loss: 0.2353, g_loss: 1.1241\n",
            "Step [29030/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0167, d_svhn_loss: 0.0383, d_fake_loss: 0.0570, g_loss: 0.8674\n",
            "Step [29040/60000], d_real_loss: 0.0458, d_mnist_loss: 0.0170, d_svhn_loss: 0.0288, d_fake_loss: 0.1215, g_loss: 1.0692\n",
            "Step [29050/60000], d_real_loss: 0.0796, d_mnist_loss: 0.0397, d_svhn_loss: 0.0399, d_fake_loss: 0.2824, g_loss: 1.3173\n",
            "Step [29060/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0119, d_svhn_loss: 0.0254, d_fake_loss: 0.0277, g_loss: 1.1059\n",
            "Step [29070/60000], d_real_loss: 0.0519, d_mnist_loss: 0.0145, d_svhn_loss: 0.0374, d_fake_loss: 0.0626, g_loss: 1.2635\n",
            "Step [29080/60000], d_real_loss: 0.1448, d_mnist_loss: 0.1236, d_svhn_loss: 0.0212, d_fake_loss: 0.0755, g_loss: 1.4341\n",
            "Step [29090/60000], d_real_loss: 0.0371, d_mnist_loss: 0.0090, d_svhn_loss: 0.0281, d_fake_loss: 0.1103, g_loss: 1.1821\n",
            "Step [29100/60000], d_real_loss: 0.0609, d_mnist_loss: 0.0169, d_svhn_loss: 0.0440, d_fake_loss: 0.0834, g_loss: 1.0353\n",
            "Step [29110/60000], d_real_loss: 0.0706, d_mnist_loss: 0.0230, d_svhn_loss: 0.0477, d_fake_loss: 0.0725, g_loss: 1.4258\n",
            "Step [29120/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0334, d_svhn_loss: 0.0273, d_fake_loss: 0.0656, g_loss: 1.0603\n",
            "Step [29130/60000], d_real_loss: 0.1051, d_mnist_loss: 0.0097, d_svhn_loss: 0.0954, d_fake_loss: 0.1555, g_loss: 1.2206\n",
            "Step [29140/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0121, d_svhn_loss: 0.0322, d_fake_loss: 0.0244, g_loss: 1.1678\n",
            "Step [29150/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0055, d_svhn_loss: 0.0227, d_fake_loss: 0.0683, g_loss: 0.9586\n",
            "Step [29160/60000], d_real_loss: 0.0466, d_mnist_loss: 0.0242, d_svhn_loss: 0.0224, d_fake_loss: 0.0281, g_loss: 1.3239\n",
            "Step [29170/60000], d_real_loss: 0.0800, d_mnist_loss: 0.0336, d_svhn_loss: 0.0465, d_fake_loss: 0.0585, g_loss: 1.1483\n",
            "Step [29180/60000], d_real_loss: 0.0486, d_mnist_loss: 0.0149, d_svhn_loss: 0.0337, d_fake_loss: 0.0365, g_loss: 1.1570\n",
            "Step [29190/60000], d_real_loss: 0.0222, d_mnist_loss: 0.0076, d_svhn_loss: 0.0146, d_fake_loss: 0.0204, g_loss: 1.1814\n",
            "Step [29200/60000], d_real_loss: 0.2829, d_mnist_loss: 0.0158, d_svhn_loss: 0.2671, d_fake_loss: 0.0456, g_loss: 1.0506\n",
            "Step [29210/60000], d_real_loss: 0.0716, d_mnist_loss: 0.0127, d_svhn_loss: 0.0589, d_fake_loss: 0.0869, g_loss: 1.2810\n",
            "Step [29220/60000], d_real_loss: 0.0730, d_mnist_loss: 0.0405, d_svhn_loss: 0.0324, d_fake_loss: 0.0816, g_loss: 1.1424\n",
            "Step [29230/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0373, d_svhn_loss: 0.0223, d_fake_loss: 0.0388, g_loss: 1.1822\n",
            "Step [29240/60000], d_real_loss: 0.0378, d_mnist_loss: 0.0107, d_svhn_loss: 0.0271, d_fake_loss: 0.0300, g_loss: 1.1268\n",
            "Step [29250/60000], d_real_loss: 0.0383, d_mnist_loss: 0.0127, d_svhn_loss: 0.0256, d_fake_loss: 0.0293, g_loss: 1.2267\n",
            "Step [29260/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0215, d_svhn_loss: 0.0372, d_fake_loss: 0.0263, g_loss: 0.9593\n",
            "Step [29270/60000], d_real_loss: 0.0529, d_mnist_loss: 0.0131, d_svhn_loss: 0.0398, d_fake_loss: 0.0422, g_loss: 1.0409\n",
            "Step [29280/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0149, d_svhn_loss: 0.0210, d_fake_loss: 0.0370, g_loss: 1.0558\n",
            "Step [29290/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0141, d_svhn_loss: 0.0531, d_fake_loss: 0.0773, g_loss: 1.2220\n",
            "Step [29300/60000], d_real_loss: 0.0513, d_mnist_loss: 0.0108, d_svhn_loss: 0.0405, d_fake_loss: 0.0417, g_loss: 1.1067\n",
            "Step [29310/60000], d_real_loss: 0.0985, d_mnist_loss: 0.0226, d_svhn_loss: 0.0759, d_fake_loss: 0.0920, g_loss: 0.9930\n",
            "Step [29320/60000], d_real_loss: 0.0714, d_mnist_loss: 0.0268, d_svhn_loss: 0.0446, d_fake_loss: 0.0604, g_loss: 0.9870\n",
            "Step [29330/60000], d_real_loss: 0.0491, d_mnist_loss: 0.0119, d_svhn_loss: 0.0372, d_fake_loss: 0.0952, g_loss: 0.9835\n",
            "Step [29340/60000], d_real_loss: 0.0660, d_mnist_loss: 0.0416, d_svhn_loss: 0.0244, d_fake_loss: 0.0307, g_loss: 1.1495\n",
            "Step [29350/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0213, d_svhn_loss: 0.0267, d_fake_loss: 0.0583, g_loss: 1.2207\n",
            "Step [29360/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0144, d_svhn_loss: 0.0252, d_fake_loss: 0.0424, g_loss: 1.2249\n",
            "Step [29370/60000], d_real_loss: 0.0854, d_mnist_loss: 0.0357, d_svhn_loss: 0.0497, d_fake_loss: 0.0650, g_loss: 1.1157\n",
            "Step [29380/60000], d_real_loss: 0.0778, d_mnist_loss: 0.0307, d_svhn_loss: 0.0471, d_fake_loss: 0.0743, g_loss: 0.8942\n",
            "Step [29390/60000], d_real_loss: 0.0532, d_mnist_loss: 0.0105, d_svhn_loss: 0.0427, d_fake_loss: 0.0359, g_loss: 1.3074\n",
            "Step [29400/60000], d_real_loss: 0.0315, d_mnist_loss: 0.0074, d_svhn_loss: 0.0241, d_fake_loss: 0.0408, g_loss: 1.1125\n",
            "Step [29410/60000], d_real_loss: 0.0343, d_mnist_loss: 0.0098, d_svhn_loss: 0.0245, d_fake_loss: 0.0625, g_loss: 1.2641\n",
            "Step [29420/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0126, d_svhn_loss: 0.0306, d_fake_loss: 0.0645, g_loss: 1.1688\n",
            "Step [29430/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0078, d_svhn_loss: 0.0162, d_fake_loss: 0.0519, g_loss: 1.0204\n",
            "Step [29440/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0118, d_svhn_loss: 0.0302, d_fake_loss: 0.0263, g_loss: 1.1495\n",
            "Step [29450/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0230, d_svhn_loss: 0.0310, d_fake_loss: 0.0831, g_loss: 1.1601\n",
            "Step [29460/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0201, d_svhn_loss: 0.0465, d_fake_loss: 0.0237, g_loss: 1.1138\n",
            "Step [29470/60000], d_real_loss: 0.1102, d_mnist_loss: 0.0286, d_svhn_loss: 0.0816, d_fake_loss: 0.0603, g_loss: 1.0336\n",
            "Step [29480/60000], d_real_loss: 0.0378, d_mnist_loss: 0.0177, d_svhn_loss: 0.0201, d_fake_loss: 0.0212, g_loss: 1.1003\n",
            "Step [29490/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0104, d_svhn_loss: 0.0242, d_fake_loss: 0.0914, g_loss: 1.2953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [29500/60000], d_real_loss: 0.0966, d_mnist_loss: 0.0377, d_svhn_loss: 0.0589, d_fake_loss: 0.0791, g_loss: 1.0253\n",
            "saved ./samples_fashion/sample-29500-m-s.png\n",
            "saved ./samples_fashion/sample-29500-s-m.png\n",
            "Step [29510/60000], d_real_loss: 0.1235, d_mnist_loss: 0.0302, d_svhn_loss: 0.0933, d_fake_loss: 0.1339, g_loss: 1.1858\n",
            "Step [29520/60000], d_real_loss: 0.0919, d_mnist_loss: 0.0169, d_svhn_loss: 0.0751, d_fake_loss: 0.0366, g_loss: 1.1194\n",
            "Step [29530/60000], d_real_loss: 0.0224, d_mnist_loss: 0.0079, d_svhn_loss: 0.0144, d_fake_loss: 0.0375, g_loss: 0.9781\n",
            "Step [29540/60000], d_real_loss: 0.1078, d_mnist_loss: 0.0064, d_svhn_loss: 0.1014, d_fake_loss: 0.0350, g_loss: 1.0800\n",
            "Step [29550/60000], d_real_loss: 0.1037, d_mnist_loss: 0.0646, d_svhn_loss: 0.0391, d_fake_loss: 0.0714, g_loss: 0.9594\n",
            "Step [29560/60000], d_real_loss: 0.0503, d_mnist_loss: 0.0374, d_svhn_loss: 0.0128, d_fake_loss: 0.0394, g_loss: 0.9719\n",
            "Step [29570/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0110, d_svhn_loss: 0.0193, d_fake_loss: 0.0362, g_loss: 1.0699\n",
            "Step [29580/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0385, d_svhn_loss: 0.0252, d_fake_loss: 0.0735, g_loss: 1.2701\n",
            "Step [29590/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0089, d_svhn_loss: 0.0216, d_fake_loss: 0.0504, g_loss: 1.2071\n",
            "Step [29600/60000], d_real_loss: 0.0234, d_mnist_loss: 0.0062, d_svhn_loss: 0.0171, d_fake_loss: 0.0671, g_loss: 1.3512\n",
            "Step [29610/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0217, d_svhn_loss: 0.0257, d_fake_loss: 0.0622, g_loss: 1.2417\n",
            "Step [29620/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0064, d_svhn_loss: 0.0262, d_fake_loss: 0.0356, g_loss: 1.1323\n",
            "Step [29630/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0130, d_svhn_loss: 0.0262, d_fake_loss: 0.0548, g_loss: 1.1928\n",
            "Step [29640/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0180, d_svhn_loss: 0.0299, d_fake_loss: 0.0916, g_loss: 1.0755\n",
            "Step [29650/60000], d_real_loss: 0.0408, d_mnist_loss: 0.0168, d_svhn_loss: 0.0240, d_fake_loss: 0.0879, g_loss: 1.2652\n",
            "Step [29660/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0441, d_svhn_loss: 0.0196, d_fake_loss: 0.0360, g_loss: 1.1052\n",
            "Step [29670/60000], d_real_loss: 0.0656, d_mnist_loss: 0.0294, d_svhn_loss: 0.0361, d_fake_loss: 0.1009, g_loss: 1.2115\n",
            "Step [29680/60000], d_real_loss: 0.1208, d_mnist_loss: 0.0083, d_svhn_loss: 0.1125, d_fake_loss: 0.0922, g_loss: 1.1697\n",
            "Step [29690/60000], d_real_loss: 0.0588, d_mnist_loss: 0.0113, d_svhn_loss: 0.0475, d_fake_loss: 0.0848, g_loss: 1.0668\n",
            "Step [29700/60000], d_real_loss: 0.1137, d_mnist_loss: 0.0106, d_svhn_loss: 0.1031, d_fake_loss: 0.0182, g_loss: 1.1080\n",
            "Step [29710/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0138, d_svhn_loss: 0.0336, d_fake_loss: 0.0565, g_loss: 1.1750\n",
            "Step [29720/60000], d_real_loss: 0.0288, d_mnist_loss: 0.0079, d_svhn_loss: 0.0209, d_fake_loss: 0.1085, g_loss: 1.1889\n",
            "Step [29730/60000], d_real_loss: 0.0707, d_mnist_loss: 0.0216, d_svhn_loss: 0.0491, d_fake_loss: 0.5229, g_loss: 1.3438\n",
            "Step [29740/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0100, d_svhn_loss: 0.0205, d_fake_loss: 0.0325, g_loss: 1.1983\n",
            "Step [29750/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0085, d_svhn_loss: 0.0372, d_fake_loss: 0.0174, g_loss: 1.2350\n",
            "Step [29760/60000], d_real_loss: 0.0547, d_mnist_loss: 0.0181, d_svhn_loss: 0.0366, d_fake_loss: 0.0460, g_loss: 1.4284\n",
            "Step [29770/60000], d_real_loss: 0.0750, d_mnist_loss: 0.0077, d_svhn_loss: 0.0674, d_fake_loss: 0.0794, g_loss: 0.9691\n",
            "Step [29780/60000], d_real_loss: 0.0777, d_mnist_loss: 0.0069, d_svhn_loss: 0.0708, d_fake_loss: 0.0798, g_loss: 1.1409\n",
            "Step [29790/60000], d_real_loss: 0.0411, d_mnist_loss: 0.0191, d_svhn_loss: 0.0220, d_fake_loss: 0.0396, g_loss: 1.2760\n",
            "Step [29800/60000], d_real_loss: 0.0641, d_mnist_loss: 0.0125, d_svhn_loss: 0.0516, d_fake_loss: 0.0475, g_loss: 0.9951\n",
            "Step [29810/60000], d_real_loss: 0.0415, d_mnist_loss: 0.0164, d_svhn_loss: 0.0251, d_fake_loss: 0.0744, g_loss: 1.1088\n",
            "Step [29820/60000], d_real_loss: 0.0525, d_mnist_loss: 0.0183, d_svhn_loss: 0.0342, d_fake_loss: 0.0692, g_loss: 1.2382\n",
            "Step [29830/60000], d_real_loss: 0.0481, d_mnist_loss: 0.0125, d_svhn_loss: 0.0356, d_fake_loss: 0.3293, g_loss: 1.0546\n",
            "Step [29840/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0119, d_svhn_loss: 0.0360, d_fake_loss: 0.1627, g_loss: 0.9549\n",
            "Step [29850/60000], d_real_loss: 0.0763, d_mnist_loss: 0.0386, d_svhn_loss: 0.0377, d_fake_loss: 0.0475, g_loss: 1.1204\n",
            "Step [29860/60000], d_real_loss: 0.0661, d_mnist_loss: 0.0449, d_svhn_loss: 0.0212, d_fake_loss: 0.0507, g_loss: 1.0891\n",
            "Step [29870/60000], d_real_loss: 0.1284, d_mnist_loss: 0.0129, d_svhn_loss: 0.1156, d_fake_loss: 0.1079, g_loss: 1.2225\n",
            "Step [29880/60000], d_real_loss: 0.0748, d_mnist_loss: 0.0310, d_svhn_loss: 0.0437, d_fake_loss: 0.1526, g_loss: 1.2793\n",
            "Step [29890/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0174, d_svhn_loss: 0.0200, d_fake_loss: 0.0654, g_loss: 1.3791\n",
            "Step [29900/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0095, d_svhn_loss: 0.0287, d_fake_loss: 0.0360, g_loss: 1.1054\n",
            "Step [29910/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0154, d_svhn_loss: 0.0243, d_fake_loss: 0.0337, g_loss: 1.1640\n",
            "Step [29920/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0137, d_svhn_loss: 0.0299, d_fake_loss: 0.0274, g_loss: 1.0291\n",
            "Step [29930/60000], d_real_loss: 0.0817, d_mnist_loss: 0.0303, d_svhn_loss: 0.0515, d_fake_loss: 0.2021, g_loss: 1.2190\n",
            "Step [29940/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0140, d_svhn_loss: 0.0220, d_fake_loss: 0.0987, g_loss: 1.1637\n",
            "Step [29950/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0340, d_svhn_loss: 0.0136, d_fake_loss: 0.0209, g_loss: 1.0971\n",
            "Step [29960/60000], d_real_loss: 0.1909, d_mnist_loss: 0.0196, d_svhn_loss: 0.1713, d_fake_loss: 0.1395, g_loss: 0.9496\n",
            "Step [29970/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0141, d_svhn_loss: 0.0311, d_fake_loss: 0.0386, g_loss: 1.0103\n",
            "Step [29980/60000], d_real_loss: 0.0786, d_mnist_loss: 0.0055, d_svhn_loss: 0.0731, d_fake_loss: 0.0485, g_loss: 1.1113\n",
            "Step [29990/60000], d_real_loss: 0.0598, d_mnist_loss: 0.0300, d_svhn_loss: 0.0298, d_fake_loss: 0.0283, g_loss: 1.2057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [30000/60000], d_real_loss: 0.0274, d_mnist_loss: 0.0134, d_svhn_loss: 0.0140, d_fake_loss: 0.0435, g_loss: 1.2928\n",
            "saved ./samples_fashion/sample-30000-m-s.png\n",
            "saved ./samples_fashion/sample-30000-s-m.png\n",
            "Step [30010/60000], d_real_loss: 0.0558, d_mnist_loss: 0.0263, d_svhn_loss: 0.0295, d_fake_loss: 0.0341, g_loss: 1.2687\n",
            "Step [30020/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0228, d_svhn_loss: 0.0174, d_fake_loss: 0.0446, g_loss: 1.3140\n",
            "Step [30030/60000], d_real_loss: 0.0562, d_mnist_loss: 0.0213, d_svhn_loss: 0.0348, d_fake_loss: 0.0426, g_loss: 1.1247\n",
            "Step [30040/60000], d_real_loss: 0.2189, d_mnist_loss: 0.0412, d_svhn_loss: 0.1777, d_fake_loss: 0.0953, g_loss: 1.0523\n",
            "Step [30050/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0088, d_svhn_loss: 0.0308, d_fake_loss: 0.0330, g_loss: 1.0461\n",
            "Step [30060/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0352, d_svhn_loss: 0.0212, d_fake_loss: 0.0667, g_loss: 1.2076\n",
            "Step [30070/60000], d_real_loss: 0.0683, d_mnist_loss: 0.0247, d_svhn_loss: 0.0436, d_fake_loss: 0.0613, g_loss: 1.1460\n",
            "Step [30080/60000], d_real_loss: 0.0602, d_mnist_loss: 0.0208, d_svhn_loss: 0.0394, d_fake_loss: 0.0508, g_loss: 0.9986\n",
            "Step [30090/60000], d_real_loss: 0.0574, d_mnist_loss: 0.0093, d_svhn_loss: 0.0481, d_fake_loss: 0.0757, g_loss: 1.0724\n",
            "Step [30100/60000], d_real_loss: 0.1169, d_mnist_loss: 0.0126, d_svhn_loss: 0.1043, d_fake_loss: 0.0818, g_loss: 1.0592\n",
            "Step [30110/60000], d_real_loss: 0.0539, d_mnist_loss: 0.0133, d_svhn_loss: 0.0406, d_fake_loss: 0.0647, g_loss: 1.2504\n",
            "Step [30120/60000], d_real_loss: 0.0653, d_mnist_loss: 0.0458, d_svhn_loss: 0.0195, d_fake_loss: 0.0178, g_loss: 1.1347\n",
            "Step [30130/60000], d_real_loss: 0.0642, d_mnist_loss: 0.0133, d_svhn_loss: 0.0509, d_fake_loss: 0.0611, g_loss: 1.2009\n",
            "Step [30140/60000], d_real_loss: 0.0370, d_mnist_loss: 0.0075, d_svhn_loss: 0.0294, d_fake_loss: 0.0740, g_loss: 1.2214\n",
            "Step [30150/60000], d_real_loss: 0.0748, d_mnist_loss: 0.0333, d_svhn_loss: 0.0414, d_fake_loss: 0.0365, g_loss: 1.0910\n",
            "Step [30160/60000], d_real_loss: 0.0906, d_mnist_loss: 0.0282, d_svhn_loss: 0.0624, d_fake_loss: 0.0244, g_loss: 1.1047\n",
            "Step [30170/60000], d_real_loss: 0.0514, d_mnist_loss: 0.0075, d_svhn_loss: 0.0439, d_fake_loss: 0.3474, g_loss: 1.3891\n",
            "Step [30180/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0106, d_svhn_loss: 0.0292, d_fake_loss: 0.0597, g_loss: 1.1855\n",
            "Step [30190/60000], d_real_loss: 0.0275, d_mnist_loss: 0.0093, d_svhn_loss: 0.0183, d_fake_loss: 0.0381, g_loss: 1.1900\n",
            "Step [30200/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0152, d_svhn_loss: 0.0249, d_fake_loss: 0.0196, g_loss: 1.0090\n",
            "Step [30210/60000], d_real_loss: 0.0670, d_mnist_loss: 0.0052, d_svhn_loss: 0.0618, d_fake_loss: 0.0718, g_loss: 1.1821\n",
            "Step [30220/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0136, d_svhn_loss: 0.0233, d_fake_loss: 0.0342, g_loss: 0.9935\n",
            "Step [30230/60000], d_real_loss: 0.0634, d_mnist_loss: 0.0119, d_svhn_loss: 0.0515, d_fake_loss: 0.0259, g_loss: 1.0132\n",
            "Step [30240/60000], d_real_loss: 0.0703, d_mnist_loss: 0.0334, d_svhn_loss: 0.0369, d_fake_loss: 0.1651, g_loss: 1.2327\n",
            "Step [30250/60000], d_real_loss: 0.0683, d_mnist_loss: 0.0105, d_svhn_loss: 0.0578, d_fake_loss: 0.1442, g_loss: 1.2468\n",
            "Step [30260/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0105, d_svhn_loss: 0.0334, d_fake_loss: 0.0776, g_loss: 1.1761\n",
            "Step [30270/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0117, d_svhn_loss: 0.0230, d_fake_loss: 0.0289, g_loss: 1.0756\n",
            "Step [30280/60000], d_real_loss: 0.0496, d_mnist_loss: 0.0192, d_svhn_loss: 0.0304, d_fake_loss: 0.0758, g_loss: 0.5736\n",
            "Step [30290/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0498, d_svhn_loss: 0.0172, d_fake_loss: 0.0293, g_loss: 1.2865\n",
            "Step [30300/60000], d_real_loss: 0.0698, d_mnist_loss: 0.0341, d_svhn_loss: 0.0356, d_fake_loss: 0.0265, g_loss: 1.2969\n",
            "Step [30310/60000], d_real_loss: 0.0829, d_mnist_loss: 0.0204, d_svhn_loss: 0.0625, d_fake_loss: 0.0766, g_loss: 1.2460\n",
            "Step [30320/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0115, d_svhn_loss: 0.0288, d_fake_loss: 0.0727, g_loss: 1.1064\n",
            "Step [30330/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0110, d_svhn_loss: 0.0254, d_fake_loss: 0.0667, g_loss: 1.1376\n",
            "Step [30340/60000], d_real_loss: 0.0480, d_mnist_loss: 0.0097, d_svhn_loss: 0.0383, d_fake_loss: 0.0864, g_loss: 1.0269\n",
            "Step [30350/60000], d_real_loss: 0.1723, d_mnist_loss: 0.1486, d_svhn_loss: 0.0237, d_fake_loss: 0.0558, g_loss: 1.0618\n",
            "Step [30360/60000], d_real_loss: 0.1132, d_mnist_loss: 0.0950, d_svhn_loss: 0.0182, d_fake_loss: 0.0903, g_loss: 1.3157\n",
            "Step [30370/60000], d_real_loss: 0.0815, d_mnist_loss: 0.0130, d_svhn_loss: 0.0686, d_fake_loss: 0.0586, g_loss: 1.1064\n",
            "Step [30380/60000], d_real_loss: 0.0391, d_mnist_loss: 0.0134, d_svhn_loss: 0.0256, d_fake_loss: 0.0624, g_loss: 1.1252\n",
            "Step [30390/60000], d_real_loss: 0.0793, d_mnist_loss: 0.0116, d_svhn_loss: 0.0677, d_fake_loss: 0.1176, g_loss: 1.0890\n",
            "Step [30400/60000], d_real_loss: 0.0955, d_mnist_loss: 0.0061, d_svhn_loss: 0.0894, d_fake_loss: 0.1312, g_loss: 1.2683\n",
            "Step [30410/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0130, d_svhn_loss: 0.0194, d_fake_loss: 0.0375, g_loss: 1.2589\n",
            "Step [30420/60000], d_real_loss: 0.1106, d_mnist_loss: 0.0081, d_svhn_loss: 0.1025, d_fake_loss: 0.1016, g_loss: 1.1143\n",
            "Step [30430/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0088, d_svhn_loss: 0.0204, d_fake_loss: 0.0234, g_loss: 1.1064\n",
            "Step [30440/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0111, d_svhn_loss: 0.0292, d_fake_loss: 0.0411, g_loss: 1.2171\n",
            "Step [30450/60000], d_real_loss: 0.1131, d_mnist_loss: 0.0437, d_svhn_loss: 0.0695, d_fake_loss: 0.0266, g_loss: 1.1692\n",
            "Step [30460/60000], d_real_loss: 0.0406, d_mnist_loss: 0.0186, d_svhn_loss: 0.0220, d_fake_loss: 0.0195, g_loss: 1.0481\n",
            "Step [30470/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0089, d_svhn_loss: 0.0259, d_fake_loss: 0.0832, g_loss: 0.9569\n",
            "Step [30480/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0114, d_svhn_loss: 0.0245, d_fake_loss: 0.1416, g_loss: 1.0289\n",
            "Step [30490/60000], d_real_loss: 0.1329, d_mnist_loss: 0.0233, d_svhn_loss: 0.1096, d_fake_loss: 0.0231, g_loss: 1.1227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [30500/60000], d_real_loss: 0.0497, d_mnist_loss: 0.0239, d_svhn_loss: 0.0258, d_fake_loss: 0.0410, g_loss: 1.3047\n",
            "saved ./samples_fashion/sample-30500-m-s.png\n",
            "saved ./samples_fashion/sample-30500-s-m.png\n",
            "Step [30510/60000], d_real_loss: 0.0871, d_mnist_loss: 0.0101, d_svhn_loss: 0.0770, d_fake_loss: 0.0647, g_loss: 1.1718\n",
            "Step [30520/60000], d_real_loss: 0.0538, d_mnist_loss: 0.0229, d_svhn_loss: 0.0309, d_fake_loss: 0.0443, g_loss: 1.2844\n",
            "Step [30530/60000], d_real_loss: 0.0299, d_mnist_loss: 0.0108, d_svhn_loss: 0.0191, d_fake_loss: 0.0381, g_loss: 1.1845\n",
            "Step [30540/60000], d_real_loss: 0.1565, d_mnist_loss: 0.1377, d_svhn_loss: 0.0188, d_fake_loss: 0.1326, g_loss: 1.6846\n",
            "Step [30550/60000], d_real_loss: 0.0769, d_mnist_loss: 0.0211, d_svhn_loss: 0.0558, d_fake_loss: 0.1100, g_loss: 0.8982\n",
            "Step [30560/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0196, d_svhn_loss: 0.0168, d_fake_loss: 0.0299, g_loss: 1.2674\n",
            "Step [30570/60000], d_real_loss: 0.0563, d_mnist_loss: 0.0123, d_svhn_loss: 0.0440, d_fake_loss: 0.0350, g_loss: 1.2673\n",
            "Step [30580/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0082, d_svhn_loss: 0.0210, d_fake_loss: 0.0414, g_loss: 1.1082\n",
            "Step [30590/60000], d_real_loss: 0.0696, d_mnist_loss: 0.0070, d_svhn_loss: 0.0626, d_fake_loss: 0.1009, g_loss: 1.2826\n",
            "Step [30600/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0074, d_svhn_loss: 0.0174, d_fake_loss: 0.0451, g_loss: 1.2352\n",
            "Step [30610/60000], d_real_loss: 0.0445, d_mnist_loss: 0.0137, d_svhn_loss: 0.0308, d_fake_loss: 0.0376, g_loss: 1.0486\n",
            "Step [30620/60000], d_real_loss: 0.0617, d_mnist_loss: 0.0053, d_svhn_loss: 0.0564, d_fake_loss: 0.0281, g_loss: 1.0438\n",
            "Step [30630/60000], d_real_loss: 0.0551, d_mnist_loss: 0.0084, d_svhn_loss: 0.0467, d_fake_loss: 0.1083, g_loss: 1.3226\n",
            "Step [30640/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0235, d_svhn_loss: 0.0241, d_fake_loss: 0.0719, g_loss: 1.2495\n",
            "Step [30650/60000], d_real_loss: 0.1508, d_mnist_loss: 0.0902, d_svhn_loss: 0.0606, d_fake_loss: 0.1497, g_loss: 1.7797\n",
            "Step [30660/60000], d_real_loss: 0.0539, d_mnist_loss: 0.0146, d_svhn_loss: 0.0392, d_fake_loss: 0.0382, g_loss: 1.1832\n",
            "Step [30670/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0112, d_svhn_loss: 0.0262, d_fake_loss: 0.0363, g_loss: 1.2044\n",
            "Step [30680/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0070, d_svhn_loss: 0.0322, d_fake_loss: 0.0294, g_loss: 1.1726\n",
            "Step [30690/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0118, d_svhn_loss: 0.0366, d_fake_loss: 0.0453, g_loss: 1.3032\n",
            "Step [30700/60000], d_real_loss: 0.0689, d_mnist_loss: 0.0081, d_svhn_loss: 0.0608, d_fake_loss: 0.0854, g_loss: 0.9769\n",
            "Step [30710/60000], d_real_loss: 0.0218, d_mnist_loss: 0.0061, d_svhn_loss: 0.0158, d_fake_loss: 0.0235, g_loss: 1.1746\n",
            "Step [30720/60000], d_real_loss: 0.0926, d_mnist_loss: 0.0362, d_svhn_loss: 0.0565, d_fake_loss: 0.1539, g_loss: 1.4506\n",
            "Step [30730/60000], d_real_loss: 0.0459, d_mnist_loss: 0.0101, d_svhn_loss: 0.0358, d_fake_loss: 0.0338, g_loss: 1.2085\n",
            "Step [30740/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0113, d_svhn_loss: 0.0394, d_fake_loss: 0.0675, g_loss: 1.5133\n",
            "Step [30750/60000], d_real_loss: 0.0354, d_mnist_loss: 0.0110, d_svhn_loss: 0.0243, d_fake_loss: 0.1213, g_loss: 1.5797\n",
            "Step [30760/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0170, d_svhn_loss: 0.0287, d_fake_loss: 0.1422, g_loss: 0.8422\n",
            "Step [30770/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0067, d_svhn_loss: 0.0282, d_fake_loss: 0.0309, g_loss: 1.1001\n",
            "Step [30780/60000], d_real_loss: 0.0910, d_mnist_loss: 0.0076, d_svhn_loss: 0.0834, d_fake_loss: 0.1274, g_loss: 1.1410\n",
            "Step [30790/60000], d_real_loss: 0.1092, d_mnist_loss: 0.0095, d_svhn_loss: 0.0997, d_fake_loss: 0.1172, g_loss: 1.1342\n",
            "Step [30800/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0068, d_svhn_loss: 0.0537, d_fake_loss: 0.1559, g_loss: 1.0187\n",
            "Step [30810/60000], d_real_loss: 0.0591, d_mnist_loss: 0.0076, d_svhn_loss: 0.0515, d_fake_loss: 0.0314, g_loss: 1.0542\n",
            "Step [30820/60000], d_real_loss: 0.1057, d_mnist_loss: 0.0819, d_svhn_loss: 0.0238, d_fake_loss: 0.0993, g_loss: 1.2858\n",
            "Step [30830/60000], d_real_loss: 0.0381, d_mnist_loss: 0.0117, d_svhn_loss: 0.0264, d_fake_loss: 0.1471, g_loss: 1.2733\n",
            "Step [30840/60000], d_real_loss: 0.0608, d_mnist_loss: 0.0215, d_svhn_loss: 0.0394, d_fake_loss: 0.1377, g_loss: 1.1812\n",
            "Step [30850/60000], d_real_loss: 0.0882, d_mnist_loss: 0.0161, d_svhn_loss: 0.0721, d_fake_loss: 0.0242, g_loss: 1.0178\n",
            "Step [30860/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0239, d_svhn_loss: 0.0296, d_fake_loss: 0.0766, g_loss: 1.0639\n",
            "Step [30870/60000], d_real_loss: 0.1024, d_mnist_loss: 0.0515, d_svhn_loss: 0.0510, d_fake_loss: 0.0371, g_loss: 1.0785\n",
            "Step [30880/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0121, d_svhn_loss: 0.0279, d_fake_loss: 0.0337, g_loss: 1.2308\n",
            "Step [30890/60000], d_real_loss: 0.0496, d_mnist_loss: 0.0115, d_svhn_loss: 0.0381, d_fake_loss: 0.0240, g_loss: 1.1026\n",
            "Step [30900/60000], d_real_loss: 0.0266, d_mnist_loss: 0.0072, d_svhn_loss: 0.0194, d_fake_loss: 0.0827, g_loss: 1.1332\n",
            "Step [30910/60000], d_real_loss: 0.0745, d_mnist_loss: 0.0163, d_svhn_loss: 0.0582, d_fake_loss: 0.1386, g_loss: 1.0730\n",
            "Step [30920/60000], d_real_loss: 0.0380, d_mnist_loss: 0.0134, d_svhn_loss: 0.0246, d_fake_loss: 0.0800, g_loss: 1.2038\n",
            "Step [30930/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0099, d_svhn_loss: 0.0231, d_fake_loss: 0.0344, g_loss: 1.1461\n",
            "Step [30940/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0276, d_svhn_loss: 0.0202, d_fake_loss: 0.0630, g_loss: 1.1972\n",
            "Step [30950/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0148, d_svhn_loss: 0.0230, d_fake_loss: 0.0920, g_loss: 1.1436\n",
            "Step [30960/60000], d_real_loss: 0.0899, d_mnist_loss: 0.0132, d_svhn_loss: 0.0767, d_fake_loss: 0.0421, g_loss: 1.1395\n",
            "Step [30970/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0071, d_svhn_loss: 0.0288, d_fake_loss: 0.0239, g_loss: 1.1618\n",
            "Step [30980/60000], d_real_loss: 0.0568, d_mnist_loss: 0.0177, d_svhn_loss: 0.0391, d_fake_loss: 0.1290, g_loss: 1.3348\n",
            "Step [30990/60000], d_real_loss: 0.0529, d_mnist_loss: 0.0266, d_svhn_loss: 0.0263, d_fake_loss: 0.1055, g_loss: 1.1566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [31000/60000], d_real_loss: 0.0579, d_mnist_loss: 0.0189, d_svhn_loss: 0.0391, d_fake_loss: 0.0582, g_loss: 1.2683\n",
            "saved ./samples_fashion/sample-31000-m-s.png\n",
            "saved ./samples_fashion/sample-31000-s-m.png\n",
            "Step [31010/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0125, d_svhn_loss: 0.0252, d_fake_loss: 0.0408, g_loss: 1.0844\n",
            "Step [31020/60000], d_real_loss: 0.0757, d_mnist_loss: 0.0087, d_svhn_loss: 0.0670, d_fake_loss: 0.0505, g_loss: 1.0341\n",
            "Step [31030/60000], d_real_loss: 0.0276, d_mnist_loss: 0.0087, d_svhn_loss: 0.0189, d_fake_loss: 0.0343, g_loss: 1.2182\n",
            "Step [31040/60000], d_real_loss: 0.0774, d_mnist_loss: 0.0192, d_svhn_loss: 0.0581, d_fake_loss: 0.0368, g_loss: 0.9310\n",
            "Step [31050/60000], d_real_loss: 0.0510, d_mnist_loss: 0.0094, d_svhn_loss: 0.0415, d_fake_loss: 0.2365, g_loss: 1.2749\n",
            "Step [31060/60000], d_real_loss: 0.0531, d_mnist_loss: 0.0139, d_svhn_loss: 0.0392, d_fake_loss: 0.0484, g_loss: 1.1063\n",
            "Step [31070/60000], d_real_loss: 0.0907, d_mnist_loss: 0.0143, d_svhn_loss: 0.0764, d_fake_loss: 0.0948, g_loss: 1.0332\n",
            "Step [31080/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0079, d_svhn_loss: 0.0174, d_fake_loss: 0.0469, g_loss: 1.0744\n",
            "Step [31090/60000], d_real_loss: 0.1043, d_mnist_loss: 0.0097, d_svhn_loss: 0.0946, d_fake_loss: 0.1104, g_loss: 1.0937\n",
            "Step [31100/60000], d_real_loss: 0.0695, d_mnist_loss: 0.0148, d_svhn_loss: 0.0547, d_fake_loss: 0.0728, g_loss: 1.0702\n",
            "Step [31110/60000], d_real_loss: 0.1167, d_mnist_loss: 0.0091, d_svhn_loss: 0.1076, d_fake_loss: 0.0234, g_loss: 1.1072\n",
            "Step [31120/60000], d_real_loss: 0.0679, d_mnist_loss: 0.0268, d_svhn_loss: 0.0411, d_fake_loss: 0.0179, g_loss: 1.1943\n",
            "Step [31130/60000], d_real_loss: 0.0739, d_mnist_loss: 0.0148, d_svhn_loss: 0.0591, d_fake_loss: 0.1379, g_loss: 1.1943\n",
            "Step [31140/60000], d_real_loss: 0.0438, d_mnist_loss: 0.0218, d_svhn_loss: 0.0220, d_fake_loss: 0.0358, g_loss: 1.1860\n",
            "Step [31150/60000], d_real_loss: 0.1280, d_mnist_loss: 0.0865, d_svhn_loss: 0.0415, d_fake_loss: 0.0502, g_loss: 1.2031\n",
            "Step [31160/60000], d_real_loss: 0.1273, d_mnist_loss: 0.0109, d_svhn_loss: 0.1163, d_fake_loss: 0.0696, g_loss: 1.0614\n",
            "Step [31170/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0112, d_svhn_loss: 0.0126, d_fake_loss: 0.0737, g_loss: 1.0654\n",
            "Step [31180/60000], d_real_loss: 0.0525, d_mnist_loss: 0.0065, d_svhn_loss: 0.0460, d_fake_loss: 0.0231, g_loss: 1.0140\n",
            "Step [31190/60000], d_real_loss: 0.0558, d_mnist_loss: 0.0244, d_svhn_loss: 0.0313, d_fake_loss: 0.0827, g_loss: 1.2136\n",
            "Step [31200/60000], d_real_loss: 0.1375, d_mnist_loss: 0.1208, d_svhn_loss: 0.0167, d_fake_loss: 0.0760, g_loss: 1.3524\n",
            "Step [31210/60000], d_real_loss: 0.1824, d_mnist_loss: 0.0156, d_svhn_loss: 0.1668, d_fake_loss: 0.0417, g_loss: 1.0247\n",
            "Step [31220/60000], d_real_loss: 0.0273, d_mnist_loss: 0.0090, d_svhn_loss: 0.0183, d_fake_loss: 0.0659, g_loss: 1.1313\n",
            "Step [31230/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0112, d_svhn_loss: 0.0345, d_fake_loss: 0.0401, g_loss: 1.2407\n",
            "Step [31240/60000], d_real_loss: 0.1520, d_mnist_loss: 0.0143, d_svhn_loss: 0.1378, d_fake_loss: 0.1298, g_loss: 1.1295\n",
            "Step [31250/60000], d_real_loss: 0.0486, d_mnist_loss: 0.0085, d_svhn_loss: 0.0401, d_fake_loss: 0.0223, g_loss: 1.1420\n",
            "Step [31260/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0084, d_svhn_loss: 0.0273, d_fake_loss: 0.0668, g_loss: 0.9268\n",
            "Step [31270/60000], d_real_loss: 0.0444, d_mnist_loss: 0.0118, d_svhn_loss: 0.0326, d_fake_loss: 0.0964, g_loss: 1.2064\n",
            "Step [31280/60000], d_real_loss: 0.0340, d_mnist_loss: 0.0068, d_svhn_loss: 0.0272, d_fake_loss: 0.0827, g_loss: 0.9896\n",
            "Step [31290/60000], d_real_loss: 0.1094, d_mnist_loss: 0.0149, d_svhn_loss: 0.0944, d_fake_loss: 0.0371, g_loss: 1.1523\n",
            "Step [31300/60000], d_real_loss: 0.2346, d_mnist_loss: 0.0076, d_svhn_loss: 0.2270, d_fake_loss: 0.1041, g_loss: 1.0667\n",
            "Step [31310/60000], d_real_loss: 0.0472, d_mnist_loss: 0.0270, d_svhn_loss: 0.0202, d_fake_loss: 0.0496, g_loss: 0.9527\n",
            "Step [31320/60000], d_real_loss: 0.0410, d_mnist_loss: 0.0152, d_svhn_loss: 0.0258, d_fake_loss: 0.0388, g_loss: 1.0740\n",
            "Step [31330/60000], d_real_loss: 0.0798, d_mnist_loss: 0.0393, d_svhn_loss: 0.0404, d_fake_loss: 0.0340, g_loss: 1.2343\n",
            "Step [31340/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0140, d_svhn_loss: 0.0212, d_fake_loss: 0.0222, g_loss: 1.0789\n",
            "Step [31350/60000], d_real_loss: 0.0968, d_mnist_loss: 0.0139, d_svhn_loss: 0.0829, d_fake_loss: 0.1125, g_loss: 1.1654\n",
            "Step [31360/60000], d_real_loss: 0.0435, d_mnist_loss: 0.0090, d_svhn_loss: 0.0345, d_fake_loss: 0.1584, g_loss: 1.2558\n",
            "Step [31370/60000], d_real_loss: 0.1438, d_mnist_loss: 0.0238, d_svhn_loss: 0.1200, d_fake_loss: 0.1092, g_loss: 1.1956\n",
            "Step [31380/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0092, d_svhn_loss: 0.0375, d_fake_loss: 0.0592, g_loss: 1.1663\n",
            "Step [31390/60000], d_real_loss: 0.0802, d_mnist_loss: 0.0579, d_svhn_loss: 0.0223, d_fake_loss: 0.1082, g_loss: 1.1033\n",
            "Step [31400/60000], d_real_loss: 0.0853, d_mnist_loss: 0.0529, d_svhn_loss: 0.0324, d_fake_loss: 0.0768, g_loss: 1.2145\n",
            "Step [31410/60000], d_real_loss: 0.0390, d_mnist_loss: 0.0099, d_svhn_loss: 0.0290, d_fake_loss: 0.0219, g_loss: 1.2409\n",
            "Step [31420/60000], d_real_loss: 0.0738, d_mnist_loss: 0.0369, d_svhn_loss: 0.0369, d_fake_loss: 0.0432, g_loss: 1.1423\n",
            "Step [31430/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0106, d_svhn_loss: 0.0245, d_fake_loss: 0.0570, g_loss: 1.2120\n",
            "Step [31440/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0145, d_svhn_loss: 0.0254, d_fake_loss: 0.0574, g_loss: 1.1683\n",
            "Step [31450/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0107, d_svhn_loss: 0.0270, d_fake_loss: 0.0794, g_loss: 1.2819\n",
            "Step [31460/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0107, d_svhn_loss: 0.0245, d_fake_loss: 0.1446, g_loss: 1.0639\n",
            "Step [31470/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0089, d_svhn_loss: 0.0302, d_fake_loss: 0.0884, g_loss: 1.1828\n",
            "Step [31480/60000], d_real_loss: 0.1125, d_mnist_loss: 0.0410, d_svhn_loss: 0.0715, d_fake_loss: 0.0784, g_loss: 1.2266\n",
            "Step [31490/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0179, d_svhn_loss: 0.0222, d_fake_loss: 0.0284, g_loss: 1.1239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [31500/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0221, d_svhn_loss: 0.0176, d_fake_loss: 0.0320, g_loss: 1.0348\n",
            "saved ./samples_fashion/sample-31500-m-s.png\n",
            "saved ./samples_fashion/sample-31500-s-m.png\n",
            "Step [31510/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0074, d_svhn_loss: 0.0248, d_fake_loss: 0.0241, g_loss: 1.1030\n",
            "Step [31520/60000], d_real_loss: 0.0631, d_mnist_loss: 0.0105, d_svhn_loss: 0.0526, d_fake_loss: 0.0548, g_loss: 1.0494\n",
            "Step [31530/60000], d_real_loss: 0.0291, d_mnist_loss: 0.0180, d_svhn_loss: 0.0111, d_fake_loss: 0.0478, g_loss: 0.6235\n",
            "Step [31540/60000], d_real_loss: 0.0854, d_mnist_loss: 0.0569, d_svhn_loss: 0.0284, d_fake_loss: 0.1376, g_loss: 1.1166\n",
            "Step [31550/60000], d_real_loss: 0.0681, d_mnist_loss: 0.0325, d_svhn_loss: 0.0356, d_fake_loss: 0.1556, g_loss: 1.2092\n",
            "Step [31560/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0099, d_svhn_loss: 0.0290, d_fake_loss: 0.0328, g_loss: 1.1470\n",
            "Step [31570/60000], d_real_loss: 0.0668, d_mnist_loss: 0.0160, d_svhn_loss: 0.0509, d_fake_loss: 0.1637, g_loss: 1.1257\n",
            "Step [31580/60000], d_real_loss: 0.1063, d_mnist_loss: 0.0451, d_svhn_loss: 0.0612, d_fake_loss: 0.0205, g_loss: 0.9935\n",
            "Step [31590/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0174, d_svhn_loss: 0.0233, d_fake_loss: 0.0958, g_loss: 1.4196\n",
            "Step [31600/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0367, d_svhn_loss: 0.0285, d_fake_loss: 0.1080, g_loss: 1.0124\n",
            "Step [31610/60000], d_real_loss: 0.0733, d_mnist_loss: 0.0210, d_svhn_loss: 0.0522, d_fake_loss: 0.1128, g_loss: 1.4097\n",
            "Step [31620/60000], d_real_loss: 0.1379, d_mnist_loss: 0.0237, d_svhn_loss: 0.1142, d_fake_loss: 0.0251, g_loss: 0.9158\n",
            "Step [31630/60000], d_real_loss: 0.0555, d_mnist_loss: 0.0094, d_svhn_loss: 0.0461, d_fake_loss: 0.0346, g_loss: 1.0963\n",
            "Step [31640/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0209, d_svhn_loss: 0.0223, d_fake_loss: 0.0762, g_loss: 1.0615\n",
            "Step [31650/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0153, d_svhn_loss: 0.0158, d_fake_loss: 0.0642, g_loss: 1.1151\n",
            "Step [31660/60000], d_real_loss: 0.0527, d_mnist_loss: 0.0117, d_svhn_loss: 0.0410, d_fake_loss: 0.0804, g_loss: 1.1949\n",
            "Step [31670/60000], d_real_loss: 0.0458, d_mnist_loss: 0.0066, d_svhn_loss: 0.0392, d_fake_loss: 0.0359, g_loss: 1.0721\n",
            "Step [31680/60000], d_real_loss: 0.0259, d_mnist_loss: 0.0114, d_svhn_loss: 0.0145, d_fake_loss: 0.0222, g_loss: 1.3292\n",
            "Step [31690/60000], d_real_loss: 0.0302, d_mnist_loss: 0.0105, d_svhn_loss: 0.0197, d_fake_loss: 0.1197, g_loss: 1.1433\n",
            "Step [31700/60000], d_real_loss: 0.1514, d_mnist_loss: 0.0311, d_svhn_loss: 0.1204, d_fake_loss: 0.0626, g_loss: 1.3331\n",
            "Step [31710/60000], d_real_loss: 0.1373, d_mnist_loss: 0.0513, d_svhn_loss: 0.0860, d_fake_loss: 0.0471, g_loss: 0.9681\n",
            "Step [31720/60000], d_real_loss: 0.0670, d_mnist_loss: 0.0455, d_svhn_loss: 0.0215, d_fake_loss: 0.0210, g_loss: 1.2180\n",
            "Step [31730/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0151, d_svhn_loss: 0.0173, d_fake_loss: 0.0234, g_loss: 1.1181\n",
            "Step [31740/60000], d_real_loss: 0.0448, d_mnist_loss: 0.0116, d_svhn_loss: 0.0332, d_fake_loss: 0.0372, g_loss: 1.1914\n",
            "Step [31750/60000], d_real_loss: 0.0914, d_mnist_loss: 0.0097, d_svhn_loss: 0.0818, d_fake_loss: 0.0272, g_loss: 1.2038\n",
            "Step [31760/60000], d_real_loss: 0.1385, d_mnist_loss: 0.0730, d_svhn_loss: 0.0654, d_fake_loss: 0.3132, g_loss: 0.6043\n",
            "Step [31770/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0105, d_svhn_loss: 0.0234, d_fake_loss: 0.0591, g_loss: 1.1042\n",
            "Step [31780/60000], d_real_loss: 0.0782, d_mnist_loss: 0.0101, d_svhn_loss: 0.0681, d_fake_loss: 0.0958, g_loss: 1.2371\n",
            "Step [31790/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0169, d_svhn_loss: 0.0267, d_fake_loss: 0.1447, g_loss: 1.1745\n",
            "Step [31800/60000], d_real_loss: 0.0567, d_mnist_loss: 0.0172, d_svhn_loss: 0.0395, d_fake_loss: 0.1247, g_loss: 1.2155\n",
            "Step [31810/60000], d_real_loss: 0.0943, d_mnist_loss: 0.0190, d_svhn_loss: 0.0753, d_fake_loss: 0.2832, g_loss: 0.8308\n",
            "Step [31820/60000], d_real_loss: 0.0755, d_mnist_loss: 0.0122, d_svhn_loss: 0.0633, d_fake_loss: 0.0535, g_loss: 1.2583\n",
            "Step [31830/60000], d_real_loss: 0.0590, d_mnist_loss: 0.0396, d_svhn_loss: 0.0194, d_fake_loss: 0.0366, g_loss: 1.0380\n",
            "Step [31840/60000], d_real_loss: 0.0505, d_mnist_loss: 0.0176, d_svhn_loss: 0.0329, d_fake_loss: 0.0271, g_loss: 1.1625\n",
            "Step [31850/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0159, d_svhn_loss: 0.0324, d_fake_loss: 0.0221, g_loss: 1.2553\n",
            "Step [31860/60000], d_real_loss: 0.1065, d_mnist_loss: 0.0140, d_svhn_loss: 0.0925, d_fake_loss: 0.0630, g_loss: 1.1833\n",
            "Step [31870/60000], d_real_loss: 0.1091, d_mnist_loss: 0.0129, d_svhn_loss: 0.0961, d_fake_loss: 0.2077, g_loss: 1.0080\n",
            "Step [31880/60000], d_real_loss: 0.0653, d_mnist_loss: 0.0161, d_svhn_loss: 0.0491, d_fake_loss: 0.0411, g_loss: 1.0606\n",
            "Step [31890/60000], d_real_loss: 0.1061, d_mnist_loss: 0.0577, d_svhn_loss: 0.0485, d_fake_loss: 0.0473, g_loss: 1.0954\n",
            "Step [31900/60000], d_real_loss: 0.0511, d_mnist_loss: 0.0142, d_svhn_loss: 0.0368, d_fake_loss: 0.0599, g_loss: 1.1943\n",
            "Step [31910/60000], d_real_loss: 0.0506, d_mnist_loss: 0.0106, d_svhn_loss: 0.0401, d_fake_loss: 0.0424, g_loss: 1.1207\n",
            "Step [31920/60000], d_real_loss: 0.1286, d_mnist_loss: 0.0124, d_svhn_loss: 0.1162, d_fake_loss: 0.0358, g_loss: 1.2321\n",
            "Step [31930/60000], d_real_loss: 0.0438, d_mnist_loss: 0.0082, d_svhn_loss: 0.0356, d_fake_loss: 0.1518, g_loss: 1.1071\n",
            "Step [31940/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0104, d_svhn_loss: 0.0220, d_fake_loss: 0.1033, g_loss: 0.9734\n",
            "Step [31950/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0088, d_svhn_loss: 0.0165, d_fake_loss: 0.0257, g_loss: 1.0224\n",
            "Step [31960/60000], d_real_loss: 0.0237, d_mnist_loss: 0.0068, d_svhn_loss: 0.0170, d_fake_loss: 0.0261, g_loss: 1.1258\n",
            "Step [31970/60000], d_real_loss: 0.0247, d_mnist_loss: 0.0069, d_svhn_loss: 0.0178, d_fake_loss: 0.0274, g_loss: 1.0746\n",
            "Step [31980/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0188, d_svhn_loss: 0.0294, d_fake_loss: 0.0383, g_loss: 1.1147\n",
            "Step [31990/60000], d_real_loss: 0.1170, d_mnist_loss: 0.0088, d_svhn_loss: 0.1082, d_fake_loss: 0.0241, g_loss: 1.0882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [32000/60000], d_real_loss: 0.0272, d_mnist_loss: 0.0075, d_svhn_loss: 0.0197, d_fake_loss: 0.0235, g_loss: 1.0764\n",
            "saved ./samples_fashion/sample-32000-m-s.png\n",
            "saved ./samples_fashion/sample-32000-s-m.png\n",
            "Step [32010/60000], d_real_loss: 0.1061, d_mnist_loss: 0.0577, d_svhn_loss: 0.0484, d_fake_loss: 0.0494, g_loss: 1.5107\n",
            "Step [32020/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0116, d_svhn_loss: 0.0236, d_fake_loss: 0.0217, g_loss: 1.2012\n",
            "Step [32030/60000], d_real_loss: 0.0302, d_mnist_loss: 0.0077, d_svhn_loss: 0.0225, d_fake_loss: 0.0242, g_loss: 1.1323\n",
            "Step [32040/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0244, d_svhn_loss: 0.0176, d_fake_loss: 0.0466, g_loss: 1.2437\n",
            "Step [32050/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0084, d_svhn_loss: 0.0273, d_fake_loss: 0.0315, g_loss: 1.1434\n",
            "Step [32060/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0139, d_svhn_loss: 0.0209, d_fake_loss: 0.0470, g_loss: 1.2233\n",
            "Step [32070/60000], d_real_loss: 0.0545, d_mnist_loss: 0.0273, d_svhn_loss: 0.0272, d_fake_loss: 0.1154, g_loss: 1.1794\n",
            "Step [32080/60000], d_real_loss: 0.0459, d_mnist_loss: 0.0227, d_svhn_loss: 0.0231, d_fake_loss: 0.0271, g_loss: 1.1511\n",
            "Step [32090/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0082, d_svhn_loss: 0.0402, d_fake_loss: 0.0887, g_loss: 1.0927\n",
            "Step [32100/60000], d_real_loss: 0.1718, d_mnist_loss: 0.0152, d_svhn_loss: 0.1566, d_fake_loss: 0.0474, g_loss: 1.2039\n",
            "Step [32110/60000], d_real_loss: 0.1642, d_mnist_loss: 0.0294, d_svhn_loss: 0.1348, d_fake_loss: 0.0406, g_loss: 1.1254\n",
            "Step [32120/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0098, d_svhn_loss: 0.0194, d_fake_loss: 0.0673, g_loss: 1.2051\n",
            "Step [32130/60000], d_real_loss: 0.0449, d_mnist_loss: 0.0270, d_svhn_loss: 0.0180, d_fake_loss: 0.0482, g_loss: 1.2749\n",
            "Step [32140/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0084, d_svhn_loss: 0.0259, d_fake_loss: 0.1559, g_loss: 1.1014\n",
            "Step [32150/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0076, d_svhn_loss: 0.0161, d_fake_loss: 0.0412, g_loss: 1.2182\n",
            "Step [32160/60000], d_real_loss: 0.0260, d_mnist_loss: 0.0092, d_svhn_loss: 0.0169, d_fake_loss: 0.0464, g_loss: 1.3540\n",
            "Step [32170/60000], d_real_loss: 0.1105, d_mnist_loss: 0.0758, d_svhn_loss: 0.0347, d_fake_loss: 0.0346, g_loss: 0.9341\n",
            "Step [32180/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0116, d_svhn_loss: 0.0210, d_fake_loss: 0.1300, g_loss: 0.6714\n",
            "Step [32190/60000], d_real_loss: 0.0495, d_mnist_loss: 0.0222, d_svhn_loss: 0.0273, d_fake_loss: 0.0624, g_loss: 0.9960\n",
            "Step [32200/60000], d_real_loss: 0.0601, d_mnist_loss: 0.0176, d_svhn_loss: 0.0425, d_fake_loss: 0.0255, g_loss: 1.0475\n",
            "Step [32210/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0109, d_svhn_loss: 0.0213, d_fake_loss: 0.0312, g_loss: 1.2206\n",
            "Step [32220/60000], d_real_loss: 0.0532, d_mnist_loss: 0.0110, d_svhn_loss: 0.0422, d_fake_loss: 0.0337, g_loss: 1.1497\n",
            "Step [32230/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0205, d_svhn_loss: 0.0226, d_fake_loss: 0.0976, g_loss: 1.2551\n",
            "Step [32240/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0121, d_svhn_loss: 0.0207, d_fake_loss: 0.0976, g_loss: 1.2475\n",
            "Step [32250/60000], d_real_loss: 0.2188, d_mnist_loss: 0.2054, d_svhn_loss: 0.0134, d_fake_loss: 0.0457, g_loss: 1.5181\n",
            "Step [32260/60000], d_real_loss: 0.1356, d_mnist_loss: 0.1034, d_svhn_loss: 0.0322, d_fake_loss: 0.1153, g_loss: 1.0004\n",
            "Step [32270/60000], d_real_loss: 0.0312, d_mnist_loss: 0.0108, d_svhn_loss: 0.0204, d_fake_loss: 0.0381, g_loss: 1.3317\n",
            "Step [32280/60000], d_real_loss: 0.0934, d_mnist_loss: 0.0631, d_svhn_loss: 0.0303, d_fake_loss: 0.1011, g_loss: 1.0772\n",
            "Step [32290/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0194, d_svhn_loss: 0.0214, d_fake_loss: 0.0300, g_loss: 1.2393\n",
            "Step [32300/60000], d_real_loss: 0.1904, d_mnist_loss: 0.0096, d_svhn_loss: 0.1808, d_fake_loss: 0.0411, g_loss: 1.1157\n",
            "Step [32310/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0109, d_svhn_loss: 0.0189, d_fake_loss: 0.0990, g_loss: 1.2426\n",
            "Step [32320/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0102, d_svhn_loss: 0.0203, d_fake_loss: 0.0153, g_loss: 1.3442\n",
            "Step [32330/60000], d_real_loss: 0.0710, d_mnist_loss: 0.0094, d_svhn_loss: 0.0617, d_fake_loss: 0.1812, g_loss: 1.2199\n",
            "Step [32340/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0077, d_svhn_loss: 0.0232, d_fake_loss: 0.0399, g_loss: 1.1709\n",
            "Step [32350/60000], d_real_loss: 0.0584, d_mnist_loss: 0.0124, d_svhn_loss: 0.0460, d_fake_loss: 0.0893, g_loss: 0.9628\n",
            "Step [32360/60000], d_real_loss: 0.1063, d_mnist_loss: 0.0651, d_svhn_loss: 0.0412, d_fake_loss: 0.0917, g_loss: 1.0384\n",
            "Step [32370/60000], d_real_loss: 0.1400, d_mnist_loss: 0.0108, d_svhn_loss: 0.1292, d_fake_loss: 0.0695, g_loss: 1.1798\n",
            "Step [32380/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0136, d_svhn_loss: 0.0260, d_fake_loss: 0.0241, g_loss: 1.1065\n",
            "Step [32390/60000], d_real_loss: 0.0522, d_mnist_loss: 0.0248, d_svhn_loss: 0.0274, d_fake_loss: 0.0256, g_loss: 1.1115\n",
            "Step [32400/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0138, d_svhn_loss: 0.0168, d_fake_loss: 0.0203, g_loss: 1.0106\n",
            "Step [32410/60000], d_real_loss: 0.0356, d_mnist_loss: 0.0158, d_svhn_loss: 0.0198, d_fake_loss: 0.0405, g_loss: 1.1565\n",
            "Step [32420/60000], d_real_loss: 0.0320, d_mnist_loss: 0.0133, d_svhn_loss: 0.0187, d_fake_loss: 0.0730, g_loss: 1.2571\n",
            "Step [32430/60000], d_real_loss: 0.0996, d_mnist_loss: 0.0179, d_svhn_loss: 0.0816, d_fake_loss: 0.1342, g_loss: 1.3145\n",
            "Step [32440/60000], d_real_loss: 0.0225, d_mnist_loss: 0.0083, d_svhn_loss: 0.0141, d_fake_loss: 0.0244, g_loss: 1.1598\n",
            "Step [32450/60000], d_real_loss: 0.0498, d_mnist_loss: 0.0132, d_svhn_loss: 0.0366, d_fake_loss: 0.0285, g_loss: 1.0926\n",
            "Step [32460/60000], d_real_loss: 0.0579, d_mnist_loss: 0.0276, d_svhn_loss: 0.0304, d_fake_loss: 0.0512, g_loss: 1.2962\n",
            "Step [32470/60000], d_real_loss: 0.1510, d_mnist_loss: 0.0131, d_svhn_loss: 0.1379, d_fake_loss: 0.0394, g_loss: 1.0983\n",
            "Step [32480/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0208, d_svhn_loss: 0.0192, d_fake_loss: 0.0270, g_loss: 1.1581\n",
            "Step [32490/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0083, d_svhn_loss: 0.0170, d_fake_loss: 0.0663, g_loss: 1.3198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999993443489075, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [32500/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0175, d_svhn_loss: 0.0190, d_fake_loss: 0.1136, g_loss: 1.3045\n",
            "saved ./samples_fashion/sample-32500-m-s.png\n",
            "saved ./samples_fashion/sample-32500-s-m.png\n",
            "Step [32510/60000], d_real_loss: 0.0972, d_mnist_loss: 0.0585, d_svhn_loss: 0.0387, d_fake_loss: 0.0405, g_loss: 1.4494\n",
            "Step [32520/60000], d_real_loss: 0.0481, d_mnist_loss: 0.0254, d_svhn_loss: 0.0228, d_fake_loss: 0.0538, g_loss: 1.0294\n",
            "Step [32530/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0140, d_svhn_loss: 0.0292, d_fake_loss: 0.0214, g_loss: 1.0480\n",
            "Step [32540/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0104, d_svhn_loss: 0.0247, d_fake_loss: 0.0313, g_loss: 1.0290\n",
            "Step [32550/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0178, d_svhn_loss: 0.0273, d_fake_loss: 0.0237, g_loss: 1.2560\n",
            "Step [32560/60000], d_real_loss: 0.0680, d_mnist_loss: 0.0101, d_svhn_loss: 0.0578, d_fake_loss: 0.0401, g_loss: 1.0021\n",
            "Step [32570/60000], d_real_loss: 0.0266, d_mnist_loss: 0.0130, d_svhn_loss: 0.0136, d_fake_loss: 0.0489, g_loss: 1.0604\n",
            "Step [32580/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0204, d_svhn_loss: 0.0264, d_fake_loss: 0.0413, g_loss: 1.1336\n",
            "Step [32590/60000], d_real_loss: 0.1668, d_mnist_loss: 0.1318, d_svhn_loss: 0.0350, d_fake_loss: 0.0686, g_loss: 1.5352\n",
            "Step [32600/60000], d_real_loss: 0.0251, d_mnist_loss: 0.0070, d_svhn_loss: 0.0181, d_fake_loss: 0.0781, g_loss: 1.3136\n",
            "Step [32610/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0138, d_svhn_loss: 0.0210, d_fake_loss: 0.0465, g_loss: 1.1024\n",
            "Step [32620/60000], d_real_loss: 0.0422, d_mnist_loss: 0.0234, d_svhn_loss: 0.0188, d_fake_loss: 0.0646, g_loss: 1.1564\n",
            "Step [32630/60000], d_real_loss: 0.1823, d_mnist_loss: 0.0543, d_svhn_loss: 0.1280, d_fake_loss: 0.1377, g_loss: 0.9503\n",
            "Step [32640/60000], d_real_loss: 0.0669, d_mnist_loss: 0.0218, d_svhn_loss: 0.0451, d_fake_loss: 0.1158, g_loss: 1.2671\n",
            "Step [32650/60000], d_real_loss: 0.0846, d_mnist_loss: 0.0126, d_svhn_loss: 0.0720, d_fake_loss: 0.0281, g_loss: 1.1466\n",
            "Step [32660/60000], d_real_loss: 0.0485, d_mnist_loss: 0.0071, d_svhn_loss: 0.0414, d_fake_loss: 0.0225, g_loss: 1.1865\n",
            "Step [32670/60000], d_real_loss: 0.0685, d_mnist_loss: 0.0402, d_svhn_loss: 0.0283, d_fake_loss: 0.0229, g_loss: 1.0297\n",
            "Step [32680/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0094, d_svhn_loss: 0.0342, d_fake_loss: 0.0541, g_loss: 1.0504\n",
            "Step [32690/60000], d_real_loss: 0.0546, d_mnist_loss: 0.0269, d_svhn_loss: 0.0277, d_fake_loss: 0.0174, g_loss: 1.2288\n",
            "Step [32700/60000], d_real_loss: 0.0969, d_mnist_loss: 0.0120, d_svhn_loss: 0.0849, d_fake_loss: 0.0972, g_loss: 1.2207\n",
            "Step [32710/60000], d_real_loss: 0.1547, d_mnist_loss: 0.0076, d_svhn_loss: 0.1471, d_fake_loss: 0.0313, g_loss: 1.0183\n",
            "Step [32720/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0132, d_svhn_loss: 0.0191, d_fake_loss: 0.0374, g_loss: 1.0992\n",
            "Step [32730/60000], d_real_loss: 0.0985, d_mnist_loss: 0.0111, d_svhn_loss: 0.0875, d_fake_loss: 0.0223, g_loss: 1.0861\n",
            "Step [32740/60000], d_real_loss: 0.0784, d_mnist_loss: 0.0086, d_svhn_loss: 0.0698, d_fake_loss: 0.1525, g_loss: 1.0400\n",
            "Step [32750/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0099, d_svhn_loss: 0.0215, d_fake_loss: 0.0265, g_loss: 1.0695\n",
            "Step [32760/60000], d_real_loss: 0.0563, d_mnist_loss: 0.0403, d_svhn_loss: 0.0159, d_fake_loss: 0.0281, g_loss: 1.1014\n",
            "Step [32770/60000], d_real_loss: 0.0764, d_mnist_loss: 0.0244, d_svhn_loss: 0.0520, d_fake_loss: 0.0270, g_loss: 0.9439\n",
            "Step [32780/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0179, d_svhn_loss: 0.0241, d_fake_loss: 0.0722, g_loss: 1.1190\n",
            "Step [32790/60000], d_real_loss: 0.0955, d_mnist_loss: 0.0537, d_svhn_loss: 0.0418, d_fake_loss: 0.0603, g_loss: 1.3007\n",
            "Step [32800/60000], d_real_loss: 0.0943, d_mnist_loss: 0.0099, d_svhn_loss: 0.0844, d_fake_loss: 0.0447, g_loss: 1.0377\n",
            "Step [32810/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0217, d_svhn_loss: 0.0162, d_fake_loss: 0.0475, g_loss: 1.2175\n",
            "Step [32820/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0087, d_svhn_loss: 0.0219, d_fake_loss: 0.0321, g_loss: 1.3712\n",
            "Step [32830/60000], d_real_loss: 0.0526, d_mnist_loss: 0.0080, d_svhn_loss: 0.0446, d_fake_loss: 0.0220, g_loss: 1.1465\n",
            "Step [32840/60000], d_real_loss: 0.0435, d_mnist_loss: 0.0149, d_svhn_loss: 0.0287, d_fake_loss: 0.0632, g_loss: 1.2537\n",
            "Step [32850/60000], d_real_loss: 0.0288, d_mnist_loss: 0.0164, d_svhn_loss: 0.0123, d_fake_loss: 0.1941, g_loss: 1.2914\n",
            "Step [32860/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0118, d_svhn_loss: 0.0120, d_fake_loss: 0.0315, g_loss: 1.1388\n",
            "Step [32870/60000], d_real_loss: 0.0186, d_mnist_loss: 0.0078, d_svhn_loss: 0.0108, d_fake_loss: 0.0205, g_loss: 1.1639\n",
            "Step [32880/60000], d_real_loss: 0.0293, d_mnist_loss: 0.0122, d_svhn_loss: 0.0171, d_fake_loss: 0.0250, g_loss: 0.8940\n",
            "Step [32890/60000], d_real_loss: 0.0333, d_mnist_loss: 0.0085, d_svhn_loss: 0.0248, d_fake_loss: 0.0943, g_loss: 1.3483\n",
            "Step [32900/60000], d_real_loss: 0.1162, d_mnist_loss: 0.0372, d_svhn_loss: 0.0790, d_fake_loss: 0.0542, g_loss: 1.0805\n",
            "Step [32910/60000], d_real_loss: 0.0595, d_mnist_loss: 0.0402, d_svhn_loss: 0.0193, d_fake_loss: 0.0667, g_loss: 0.8777\n",
            "Step [32920/60000], d_real_loss: 0.0763, d_mnist_loss: 0.0145, d_svhn_loss: 0.0617, d_fake_loss: 0.0344, g_loss: 1.0868\n",
            "Step [32930/60000], d_real_loss: 0.0608, d_mnist_loss: 0.0142, d_svhn_loss: 0.0466, d_fake_loss: 0.0712, g_loss: 1.1357\n",
            "Step [32940/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0079, d_svhn_loss: 0.0251, d_fake_loss: 0.0386, g_loss: 0.9807\n",
            "Step [32950/60000], d_real_loss: 0.0312, d_mnist_loss: 0.0067, d_svhn_loss: 0.0244, d_fake_loss: 0.0511, g_loss: 1.1463\n",
            "Step [32960/60000], d_real_loss: 0.0413, d_mnist_loss: 0.0178, d_svhn_loss: 0.0235, d_fake_loss: 0.0390, g_loss: 1.1132\n",
            "Step [32970/60000], d_real_loss: 0.1600, d_mnist_loss: 0.0088, d_svhn_loss: 0.1512, d_fake_loss: 0.1003, g_loss: 1.1128\n",
            "Step [32980/60000], d_real_loss: 0.0674, d_mnist_loss: 0.0102, d_svhn_loss: 0.0572, d_fake_loss: 0.0421, g_loss: 1.3489\n",
            "Step [32990/60000], d_real_loss: 0.0537, d_mnist_loss: 0.0319, d_svhn_loss: 0.0218, d_fake_loss: 0.0369, g_loss: 1.1588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [33000/60000], d_real_loss: 0.0381, d_mnist_loss: 0.0093, d_svhn_loss: 0.0287, d_fake_loss: 0.0524, g_loss: 1.0384\n",
            "saved ./samples_fashion/sample-33000-m-s.png\n",
            "saved ./samples_fashion/sample-33000-s-m.png\n",
            "Step [33010/60000], d_real_loss: 0.1112, d_mnist_loss: 0.0118, d_svhn_loss: 0.0995, d_fake_loss: 0.1749, g_loss: 1.2844\n",
            "Step [33020/60000], d_real_loss: 0.0659, d_mnist_loss: 0.0447, d_svhn_loss: 0.0212, d_fake_loss: 0.0702, g_loss: 1.2204\n",
            "Step [33030/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0281, d_svhn_loss: 0.0201, d_fake_loss: 0.0279, g_loss: 1.1611\n",
            "Step [33040/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0142, d_svhn_loss: 0.0292, d_fake_loss: 0.0375, g_loss: 1.0922\n",
            "Step [33050/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0093, d_svhn_loss: 0.0169, d_fake_loss: 0.0205, g_loss: 1.1659\n",
            "Step [33060/60000], d_real_loss: 0.0753, d_mnist_loss: 0.0200, d_svhn_loss: 0.0553, d_fake_loss: 0.0339, g_loss: 1.0434\n",
            "Step [33070/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0155, d_svhn_loss: 0.0259, d_fake_loss: 0.0210, g_loss: 1.0296\n",
            "Step [33080/60000], d_real_loss: 0.0710, d_mnist_loss: 0.0383, d_svhn_loss: 0.0327, d_fake_loss: 0.0277, g_loss: 1.1907\n",
            "Step [33090/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0064, d_svhn_loss: 0.0258, d_fake_loss: 0.0711, g_loss: 1.2873\n",
            "Step [33100/60000], d_real_loss: 0.0710, d_mnist_loss: 0.0220, d_svhn_loss: 0.0491, d_fake_loss: 0.1739, g_loss: 1.3524\n",
            "Step [33110/60000], d_real_loss: 0.1554, d_mnist_loss: 0.1185, d_svhn_loss: 0.0369, d_fake_loss: 0.0825, g_loss: 1.5498\n",
            "Step [33120/60000], d_real_loss: 0.0963, d_mnist_loss: 0.0732, d_svhn_loss: 0.0231, d_fake_loss: 0.0901, g_loss: 1.4661\n",
            "Step [33130/60000], d_real_loss: 0.0823, d_mnist_loss: 0.0104, d_svhn_loss: 0.0720, d_fake_loss: 0.0359, g_loss: 1.1167\n",
            "Step [33140/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0163, d_svhn_loss: 0.0226, d_fake_loss: 0.0338, g_loss: 0.9981\n",
            "Step [33150/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0345, d_svhn_loss: 0.0227, d_fake_loss: 0.0360, g_loss: 1.1031\n",
            "Step [33160/60000], d_real_loss: 0.0720, d_mnist_loss: 0.0101, d_svhn_loss: 0.0619, d_fake_loss: 0.0437, g_loss: 1.1654\n",
            "Step [33170/60000], d_real_loss: 0.1082, d_mnist_loss: 0.0101, d_svhn_loss: 0.0981, d_fake_loss: 0.1691, g_loss: 1.2285\n",
            "Step [33180/60000], d_real_loss: 0.2223, d_mnist_loss: 0.0203, d_svhn_loss: 0.2020, d_fake_loss: 0.0775, g_loss: 1.0707\n",
            "Step [33190/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0083, d_svhn_loss: 0.0324, d_fake_loss: 0.0258, g_loss: 1.0248\n",
            "Step [33200/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0130, d_svhn_loss: 0.0178, d_fake_loss: 0.0874, g_loss: 1.2551\n",
            "Step [33210/60000], d_real_loss: 0.1250, d_mnist_loss: 0.0092, d_svhn_loss: 0.1158, d_fake_loss: 0.0643, g_loss: 1.0295\n",
            "Step [33220/60000], d_real_loss: 0.0680, d_mnist_loss: 0.0286, d_svhn_loss: 0.0394, d_fake_loss: 0.0434, g_loss: 1.0324\n",
            "Step [33230/60000], d_real_loss: 0.0642, d_mnist_loss: 0.0263, d_svhn_loss: 0.0379, d_fake_loss: 0.0681, g_loss: 1.2179\n",
            "Step [33240/60000], d_real_loss: 0.0459, d_mnist_loss: 0.0084, d_svhn_loss: 0.0375, d_fake_loss: 0.0605, g_loss: 1.4138\n",
            "Step [33250/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0160, d_svhn_loss: 0.0315, d_fake_loss: 0.0520, g_loss: 1.0664\n",
            "Step [33260/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0090, d_svhn_loss: 0.0289, d_fake_loss: 0.0381, g_loss: 1.1337\n",
            "Step [33270/60000], d_real_loss: 0.0768, d_mnist_loss: 0.0536, d_svhn_loss: 0.0232, d_fake_loss: 0.0643, g_loss: 1.0545\n",
            "Step [33280/60000], d_real_loss: 0.0495, d_mnist_loss: 0.0106, d_svhn_loss: 0.0390, d_fake_loss: 0.0321, g_loss: 1.1198\n",
            "Step [33290/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0163, d_svhn_loss: 0.0238, d_fake_loss: 0.0418, g_loss: 1.0038\n",
            "Step [33300/60000], d_real_loss: 0.0513, d_mnist_loss: 0.0153, d_svhn_loss: 0.0359, d_fake_loss: 0.0289, g_loss: 1.0974\n",
            "Step [33310/60000], d_real_loss: 0.0333, d_mnist_loss: 0.0162, d_svhn_loss: 0.0172, d_fake_loss: 0.0416, g_loss: 1.3440\n",
            "Step [33320/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0295, d_svhn_loss: 0.0440, d_fake_loss: 0.0593, g_loss: 1.1499\n",
            "Step [33330/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0309, d_svhn_loss: 0.0165, d_fake_loss: 0.0613, g_loss: 1.1377\n",
            "Step [33340/60000], d_real_loss: 0.0685, d_mnist_loss: 0.0114, d_svhn_loss: 0.0571, d_fake_loss: 0.1038, g_loss: 1.0994\n",
            "Step [33350/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0183, d_svhn_loss: 0.0192, d_fake_loss: 0.0186, g_loss: 1.2143\n",
            "Step [33360/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0095, d_svhn_loss: 0.0267, d_fake_loss: 0.0219, g_loss: 1.1532\n",
            "Step [33370/60000], d_real_loss: 0.0562, d_mnist_loss: 0.0251, d_svhn_loss: 0.0311, d_fake_loss: 0.0478, g_loss: 1.1032\n",
            "Step [33380/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0070, d_svhn_loss: 0.0233, d_fake_loss: 0.1385, g_loss: 1.0878\n",
            "Step [33390/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0153, d_svhn_loss: 0.0298, d_fake_loss: 0.0808, g_loss: 1.2528\n",
            "Step [33400/60000], d_real_loss: 0.0271, d_mnist_loss: 0.0106, d_svhn_loss: 0.0165, d_fake_loss: 0.0792, g_loss: 1.5878\n",
            "Step [33410/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0127, d_svhn_loss: 0.0216, d_fake_loss: 0.0814, g_loss: 1.0924\n",
            "Step [33420/60000], d_real_loss: 0.1113, d_mnist_loss: 0.0562, d_svhn_loss: 0.0551, d_fake_loss: 0.1115, g_loss: 1.1297\n",
            "Step [33430/60000], d_real_loss: 0.0635, d_mnist_loss: 0.0079, d_svhn_loss: 0.0556, d_fake_loss: 0.0548, g_loss: 1.0647\n",
            "Step [33440/60000], d_real_loss: 0.0434, d_mnist_loss: 0.0315, d_svhn_loss: 0.0119, d_fake_loss: 0.0148, g_loss: 1.2724\n",
            "Step [33450/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0126, d_svhn_loss: 0.0136, d_fake_loss: 0.0298, g_loss: 1.2337\n",
            "Step [33460/60000], d_real_loss: 0.0863, d_mnist_loss: 0.0193, d_svhn_loss: 0.0669, d_fake_loss: 0.0314, g_loss: 1.0253\n",
            "Step [33470/60000], d_real_loss: 0.0243, d_mnist_loss: 0.0076, d_svhn_loss: 0.0167, d_fake_loss: 0.0530, g_loss: 1.2795\n",
            "Step [33480/60000], d_real_loss: 0.0871, d_mnist_loss: 0.0212, d_svhn_loss: 0.0659, d_fake_loss: 0.0256, g_loss: 1.1141\n",
            "Step [33490/60000], d_real_loss: 0.0569, d_mnist_loss: 0.0380, d_svhn_loss: 0.0189, d_fake_loss: 0.1629, g_loss: 1.3368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998211860657, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [33500/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0082, d_svhn_loss: 0.0292, d_fake_loss: 0.0235, g_loss: 1.1262\n",
            "saved ./samples_fashion/sample-33500-m-s.png\n",
            "saved ./samples_fashion/sample-33500-s-m.png\n",
            "Step [33510/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0194, d_svhn_loss: 0.0166, d_fake_loss: 0.0188, g_loss: 1.1901\n",
            "Step [33520/60000], d_real_loss: 0.1845, d_mnist_loss: 0.0577, d_svhn_loss: 0.1269, d_fake_loss: 0.0710, g_loss: 0.9936\n",
            "Step [33530/60000], d_real_loss: 0.0611, d_mnist_loss: 0.0396, d_svhn_loss: 0.0215, d_fake_loss: 0.0267, g_loss: 1.0696\n",
            "Step [33540/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0112, d_svhn_loss: 0.0180, d_fake_loss: 0.1327, g_loss: 1.1460\n",
            "Step [33550/60000], d_real_loss: 0.0435, d_mnist_loss: 0.0105, d_svhn_loss: 0.0330, d_fake_loss: 0.0344, g_loss: 1.1334\n",
            "Step [33560/60000], d_real_loss: 0.2113, d_mnist_loss: 0.0472, d_svhn_loss: 0.1641, d_fake_loss: 0.0425, g_loss: 1.0959\n",
            "Step [33570/60000], d_real_loss: 0.0858, d_mnist_loss: 0.0674, d_svhn_loss: 0.0184, d_fake_loss: 0.0848, g_loss: 1.1824\n",
            "Step [33580/60000], d_real_loss: 0.0300, d_mnist_loss: 0.0147, d_svhn_loss: 0.0153, d_fake_loss: 0.0622, g_loss: 1.0372\n",
            "Step [33590/60000], d_real_loss: 0.0520, d_mnist_loss: 0.0164, d_svhn_loss: 0.0356, d_fake_loss: 0.0491, g_loss: 1.0392\n",
            "Step [33600/60000], d_real_loss: 0.0286, d_mnist_loss: 0.0073, d_svhn_loss: 0.0213, d_fake_loss: 0.0296, g_loss: 1.1737\n",
            "Step [33610/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0218, d_svhn_loss: 0.0378, d_fake_loss: 0.0338, g_loss: 0.9939\n",
            "Step [33620/60000], d_real_loss: 0.0214, d_mnist_loss: 0.0065, d_svhn_loss: 0.0149, d_fake_loss: 0.0572, g_loss: 1.0982\n",
            "Step [33630/60000], d_real_loss: 0.0170, d_mnist_loss: 0.0076, d_svhn_loss: 0.0094, d_fake_loss: 0.0412, g_loss: 1.2600\n",
            "Step [33640/60000], d_real_loss: 0.0630, d_mnist_loss: 0.0479, d_svhn_loss: 0.0152, d_fake_loss: 0.0461, g_loss: 1.2207\n",
            "Step [33650/60000], d_real_loss: 0.0328, d_mnist_loss: 0.0079, d_svhn_loss: 0.0249, d_fake_loss: 0.0333, g_loss: 1.1385\n",
            "Step [33660/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0077, d_svhn_loss: 0.0257, d_fake_loss: 0.0139, g_loss: 1.2887\n",
            "Step [33670/60000], d_real_loss: 0.0827, d_mnist_loss: 0.0589, d_svhn_loss: 0.0237, d_fake_loss: 0.0838, g_loss: 0.8555\n",
            "Step [33680/60000], d_real_loss: 0.0629, d_mnist_loss: 0.0088, d_svhn_loss: 0.0541, d_fake_loss: 0.0631, g_loss: 1.2265\n",
            "Step [33690/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0121, d_svhn_loss: 0.0273, d_fake_loss: 0.0878, g_loss: 0.9320\n",
            "Step [33700/60000], d_real_loss: 0.0307, d_mnist_loss: 0.0149, d_svhn_loss: 0.0158, d_fake_loss: 0.0259, g_loss: 1.0917\n",
            "Step [33710/60000], d_real_loss: 0.0715, d_mnist_loss: 0.0521, d_svhn_loss: 0.0194, d_fake_loss: 0.0350, g_loss: 1.0225\n",
            "Step [33720/60000], d_real_loss: 0.0343, d_mnist_loss: 0.0141, d_svhn_loss: 0.0202, d_fake_loss: 0.0646, g_loss: 1.2093\n",
            "Step [33730/60000], d_real_loss: 0.0718, d_mnist_loss: 0.0255, d_svhn_loss: 0.0463, d_fake_loss: 0.0881, g_loss: 0.9562\n",
            "Step [33740/60000], d_real_loss: 0.0668, d_mnist_loss: 0.0115, d_svhn_loss: 0.0553, d_fake_loss: 0.1434, g_loss: 1.0151\n",
            "Step [33750/60000], d_real_loss: 0.0286, d_mnist_loss: 0.0088, d_svhn_loss: 0.0198, d_fake_loss: 0.0172, g_loss: 1.0647\n",
            "Step [33760/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0171, d_svhn_loss: 0.0133, d_fake_loss: 0.0187, g_loss: 1.0761\n",
            "Step [33770/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0165, d_svhn_loss: 0.0148, d_fake_loss: 0.0561, g_loss: 0.9557\n",
            "Step [33780/60000], d_real_loss: 0.0424, d_mnist_loss: 0.0105, d_svhn_loss: 0.0319, d_fake_loss: 0.0251, g_loss: 1.3140\n",
            "Step [33790/60000], d_real_loss: 0.0631, d_mnist_loss: 0.0121, d_svhn_loss: 0.0509, d_fake_loss: 0.1483, g_loss: 1.1260\n",
            "Step [33800/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0196, d_svhn_loss: 0.0240, d_fake_loss: 0.0472, g_loss: 1.1765\n",
            "Step [33810/60000], d_real_loss: 0.0812, d_mnist_loss: 0.0141, d_svhn_loss: 0.0672, d_fake_loss: 0.0672, g_loss: 1.2598\n",
            "Step [33820/60000], d_real_loss: 0.0702, d_mnist_loss: 0.0112, d_svhn_loss: 0.0590, d_fake_loss: 0.0750, g_loss: 1.1780\n",
            "Step [33830/60000], d_real_loss: 0.1258, d_mnist_loss: 0.0126, d_svhn_loss: 0.1132, d_fake_loss: 0.0580, g_loss: 1.1670\n",
            "Step [33840/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0175, d_svhn_loss: 0.0353, d_fake_loss: 0.0931, g_loss: 1.1734\n",
            "Step [33850/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0102, d_svhn_loss: 0.0160, d_fake_loss: 0.0396, g_loss: 1.4609\n",
            "Step [33860/60000], d_real_loss: 0.0588, d_mnist_loss: 0.0148, d_svhn_loss: 0.0440, d_fake_loss: 0.0508, g_loss: 1.1296\n",
            "Step [33870/60000], d_real_loss: 0.0354, d_mnist_loss: 0.0093, d_svhn_loss: 0.0261, d_fake_loss: 0.0213, g_loss: 0.9133\n",
            "Step [33880/60000], d_real_loss: 0.0943, d_mnist_loss: 0.0776, d_svhn_loss: 0.0167, d_fake_loss: 0.2234, g_loss: 1.3692\n",
            "Step [33890/60000], d_real_loss: 0.1609, d_mnist_loss: 0.1427, d_svhn_loss: 0.0182, d_fake_loss: 0.0352, g_loss: 1.3400\n",
            "Step [33900/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0195, d_svhn_loss: 0.0111, d_fake_loss: 0.0311, g_loss: 1.0676\n",
            "Step [33910/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0107, d_svhn_loss: 0.0146, d_fake_loss: 0.0395, g_loss: 1.1776\n",
            "Step [33920/60000], d_real_loss: 0.1111, d_mnist_loss: 0.0267, d_svhn_loss: 0.0844, d_fake_loss: 0.0542, g_loss: 1.1046\n",
            "Step [33930/60000], d_real_loss: 0.0779, d_mnist_loss: 0.0083, d_svhn_loss: 0.0696, d_fake_loss: 0.0291, g_loss: 1.1769\n",
            "Step [33940/60000], d_real_loss: 0.1525, d_mnist_loss: 0.0226, d_svhn_loss: 0.1299, d_fake_loss: 0.1400, g_loss: 1.0180\n",
            "Step [33950/60000], d_real_loss: 0.0214, d_mnist_loss: 0.0065, d_svhn_loss: 0.0149, d_fake_loss: 0.0380, g_loss: 1.0463\n",
            "Step [33960/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0152, d_svhn_loss: 0.0237, d_fake_loss: 0.1162, g_loss: 1.0513\n",
            "Step [33970/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0175, d_svhn_loss: 0.0218, d_fake_loss: 0.0357, g_loss: 1.2635\n",
            "Step [33980/60000], d_real_loss: 0.0289, d_mnist_loss: 0.0113, d_svhn_loss: 0.0176, d_fake_loss: 0.0306, g_loss: 1.2879\n",
            "Step [33990/60000], d_real_loss: 0.1393, d_mnist_loss: 0.0336, d_svhn_loss: 0.1056, d_fake_loss: 0.0311, g_loss: 1.1181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [34000/60000], d_real_loss: 0.0256, d_mnist_loss: 0.0075, d_svhn_loss: 0.0181, d_fake_loss: 0.0258, g_loss: 1.2608\n",
            "saved ./samples_fashion/sample-34000-m-s.png\n",
            "saved ./samples_fashion/sample-34000-s-m.png\n",
            "Step [34010/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0154, d_svhn_loss: 0.0160, d_fake_loss: 0.0461, g_loss: 1.1507\n",
            "Step [34020/60000], d_real_loss: 0.0289, d_mnist_loss: 0.0143, d_svhn_loss: 0.0146, d_fake_loss: 0.0815, g_loss: 1.1323\n",
            "Step [34030/60000], d_real_loss: 0.1343, d_mnist_loss: 0.0175, d_svhn_loss: 0.1168, d_fake_loss: 0.0451, g_loss: 1.1245\n",
            "Step [34040/60000], d_real_loss: 0.0963, d_mnist_loss: 0.0464, d_svhn_loss: 0.0499, d_fake_loss: 0.2908, g_loss: 1.4108\n",
            "Step [34050/60000], d_real_loss: 0.0954, d_mnist_loss: 0.0655, d_svhn_loss: 0.0300, d_fake_loss: 0.0167, g_loss: 0.9451\n",
            "Step [34060/60000], d_real_loss: 0.0410, d_mnist_loss: 0.0097, d_svhn_loss: 0.0313, d_fake_loss: 0.0242, g_loss: 1.1011\n",
            "Step [34070/60000], d_real_loss: 0.0492, d_mnist_loss: 0.0117, d_svhn_loss: 0.0375, d_fake_loss: 0.0848, g_loss: 1.1748\n",
            "Step [34080/60000], d_real_loss: 0.0417, d_mnist_loss: 0.0172, d_svhn_loss: 0.0245, d_fake_loss: 0.0245, g_loss: 1.0565\n",
            "Step [34090/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0291, d_svhn_loss: 0.0143, d_fake_loss: 0.1152, g_loss: 1.2546\n",
            "Step [34100/60000], d_real_loss: 0.1910, d_mnist_loss: 0.1363, d_svhn_loss: 0.0547, d_fake_loss: 0.0386, g_loss: 0.8491\n",
            "Step [34110/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0162, d_svhn_loss: 0.0201, d_fake_loss: 0.0600, g_loss: 1.0488\n",
            "Step [34120/60000], d_real_loss: 0.0702, d_mnist_loss: 0.0115, d_svhn_loss: 0.0588, d_fake_loss: 0.0963, g_loss: 1.0952\n",
            "Step [34130/60000], d_real_loss: 0.0267, d_mnist_loss: 0.0110, d_svhn_loss: 0.0157, d_fake_loss: 0.0263, g_loss: 1.0785\n",
            "Step [34140/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0211, d_svhn_loss: 0.0205, d_fake_loss: 0.0406, g_loss: 1.0956\n",
            "Step [34150/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0304, d_svhn_loss: 0.0170, d_fake_loss: 0.0328, g_loss: 1.0880\n",
            "Step [34160/60000], d_real_loss: 0.1329, d_mnist_loss: 0.0052, d_svhn_loss: 0.1276, d_fake_loss: 0.1041, g_loss: 1.0636\n",
            "Step [34170/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0105, d_svhn_loss: 0.0230, d_fake_loss: 0.0923, g_loss: 1.1464\n",
            "Step [34180/60000], d_real_loss: 0.0879, d_mnist_loss: 0.0069, d_svhn_loss: 0.0810, d_fake_loss: 0.0783, g_loss: 1.2176\n",
            "Step [34190/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0075, d_svhn_loss: 0.0273, d_fake_loss: 0.0290, g_loss: 1.0926\n",
            "Step [34200/60000], d_real_loss: 0.0336, d_mnist_loss: 0.0105, d_svhn_loss: 0.0231, d_fake_loss: 0.0385, g_loss: 1.1452\n",
            "Step [34210/60000], d_real_loss: 0.0599, d_mnist_loss: 0.0092, d_svhn_loss: 0.0507, d_fake_loss: 0.0243, g_loss: 0.9974\n",
            "Step [34220/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0104, d_svhn_loss: 0.0202, d_fake_loss: 0.0379, g_loss: 1.1734\n",
            "Step [34230/60000], d_real_loss: 0.0633, d_mnist_loss: 0.0239, d_svhn_loss: 0.0395, d_fake_loss: 0.0408, g_loss: 0.9137\n",
            "Step [34240/60000], d_real_loss: 0.1994, d_mnist_loss: 0.0618, d_svhn_loss: 0.1376, d_fake_loss: 0.1735, g_loss: 1.1387\n",
            "Step [34250/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0096, d_svhn_loss: 0.0297, d_fake_loss: 0.1429, g_loss: 1.0860\n",
            "Step [34260/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0124, d_svhn_loss: 0.0203, d_fake_loss: 0.0210, g_loss: 1.0578\n",
            "Step [34270/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0110, d_svhn_loss: 0.0321, d_fake_loss: 0.0328, g_loss: 1.1576\n",
            "Step [34280/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0172, d_svhn_loss: 0.0242, d_fake_loss: 0.0195, g_loss: 1.0924\n",
            "Step [34290/60000], d_real_loss: 0.0539, d_mnist_loss: 0.0374, d_svhn_loss: 0.0165, d_fake_loss: 0.0436, g_loss: 0.9368\n",
            "Step [34300/60000], d_real_loss: 0.0566, d_mnist_loss: 0.0121, d_svhn_loss: 0.0444, d_fake_loss: 0.0456, g_loss: 1.2699\n",
            "Step [34310/60000], d_real_loss: 0.0584, d_mnist_loss: 0.0154, d_svhn_loss: 0.0430, d_fake_loss: 0.2860, g_loss: 1.0711\n",
            "Step [34320/60000], d_real_loss: 0.0648, d_mnist_loss: 0.0078, d_svhn_loss: 0.0570, d_fake_loss: 0.0846, g_loss: 1.2415\n",
            "Step [34330/60000], d_real_loss: 0.0226, d_mnist_loss: 0.0046, d_svhn_loss: 0.0180, d_fake_loss: 0.0346, g_loss: 1.1610\n",
            "Step [34340/60000], d_real_loss: 0.1174, d_mnist_loss: 0.0361, d_svhn_loss: 0.0813, d_fake_loss: 0.1323, g_loss: 1.1361\n",
            "Step [34350/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0139, d_svhn_loss: 0.0237, d_fake_loss: 0.0301, g_loss: 1.1152\n",
            "Step [34360/60000], d_real_loss: 0.0462, d_mnist_loss: 0.0103, d_svhn_loss: 0.0358, d_fake_loss: 0.0309, g_loss: 1.0203\n",
            "Step [34370/60000], d_real_loss: 0.0491, d_mnist_loss: 0.0092, d_svhn_loss: 0.0399, d_fake_loss: 0.4436, g_loss: 1.1166\n",
            "Step [34380/60000], d_real_loss: 0.1234, d_mnist_loss: 0.0845, d_svhn_loss: 0.0389, d_fake_loss: 0.0860, g_loss: 1.2091\n",
            "Step [34390/60000], d_real_loss: 0.0616, d_mnist_loss: 0.0202, d_svhn_loss: 0.0414, d_fake_loss: 0.1150, g_loss: 1.0891\n",
            "Step [34400/60000], d_real_loss: 0.0371, d_mnist_loss: 0.0139, d_svhn_loss: 0.0232, d_fake_loss: 0.0335, g_loss: 1.2245\n",
            "Step [34410/60000], d_real_loss: 0.0832, d_mnist_loss: 0.0327, d_svhn_loss: 0.0505, d_fake_loss: 0.0719, g_loss: 1.0702\n",
            "Step [34420/60000], d_real_loss: 0.0215, d_mnist_loss: 0.0073, d_svhn_loss: 0.0142, d_fake_loss: 0.0393, g_loss: 1.0220\n",
            "Step [34430/60000], d_real_loss: 0.1087, d_mnist_loss: 0.0625, d_svhn_loss: 0.0461, d_fake_loss: 0.0522, g_loss: 1.0200\n",
            "Step [34440/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0133, d_svhn_loss: 0.0220, d_fake_loss: 0.0449, g_loss: 1.1791\n",
            "Step [34450/60000], d_real_loss: 0.0488, d_mnist_loss: 0.0187, d_svhn_loss: 0.0301, d_fake_loss: 0.0189, g_loss: 1.0460\n",
            "Step [34460/60000], d_real_loss: 0.0485, d_mnist_loss: 0.0309, d_svhn_loss: 0.0177, d_fake_loss: 0.0505, g_loss: 1.1103\n",
            "Step [34470/60000], d_real_loss: 0.0685, d_mnist_loss: 0.0129, d_svhn_loss: 0.0557, d_fake_loss: 0.0597, g_loss: 1.0543\n",
            "Step [34480/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0219, d_svhn_loss: 0.0139, d_fake_loss: 0.0359, g_loss: 1.2577\n",
            "Step [34490/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0319, d_svhn_loss: 0.0114, d_fake_loss: 0.0914, g_loss: 0.9046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [34500/60000], d_real_loss: 0.0381, d_mnist_loss: 0.0195, d_svhn_loss: 0.0185, d_fake_loss: 0.0306, g_loss: 1.0669\n",
            "saved ./samples_fashion/sample-34500-m-s.png\n",
            "saved ./samples_fashion/sample-34500-s-m.png\n",
            "Step [34510/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0108, d_svhn_loss: 0.0291, d_fake_loss: 0.1154, g_loss: 1.2126\n",
            "Step [34520/60000], d_real_loss: 0.0828, d_mnist_loss: 0.0659, d_svhn_loss: 0.0170, d_fake_loss: 0.1174, g_loss: 1.1741\n",
            "Step [34530/60000], d_real_loss: 0.0329, d_mnist_loss: 0.0068, d_svhn_loss: 0.0261, d_fake_loss: 0.1226, g_loss: 1.2774\n",
            "Step [34540/60000], d_real_loss: 0.1210, d_mnist_loss: 0.0168, d_svhn_loss: 0.1041, d_fake_loss: 0.0350, g_loss: 1.0753\n",
            "Step [34550/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0173, d_svhn_loss: 0.0201, d_fake_loss: 0.0363, g_loss: 1.1526\n",
            "Step [34560/60000], d_real_loss: 0.1543, d_mnist_loss: 0.0306, d_svhn_loss: 0.1237, d_fake_loss: 0.0339, g_loss: 1.1509\n",
            "Step [34570/60000], d_real_loss: 0.0425, d_mnist_loss: 0.0080, d_svhn_loss: 0.0345, d_fake_loss: 0.0882, g_loss: 1.2194\n",
            "Step [34580/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0113, d_svhn_loss: 0.0342, d_fake_loss: 0.0224, g_loss: 1.0951\n",
            "Step [34590/60000], d_real_loss: 0.0549, d_mnist_loss: 0.0373, d_svhn_loss: 0.0176, d_fake_loss: 0.0686, g_loss: 1.1999\n",
            "Step [34600/60000], d_real_loss: 0.0410, d_mnist_loss: 0.0233, d_svhn_loss: 0.0177, d_fake_loss: 0.0944, g_loss: 1.3245\n",
            "Step [34610/60000], d_real_loss: 0.0582, d_mnist_loss: 0.0158, d_svhn_loss: 0.0424, d_fake_loss: 0.0667, g_loss: 0.9694\n",
            "Step [34620/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0139, d_svhn_loss: 0.0199, d_fake_loss: 0.0971, g_loss: 1.1550\n",
            "Step [34630/60000], d_real_loss: 0.0504, d_mnist_loss: 0.0257, d_svhn_loss: 0.0247, d_fake_loss: 0.0975, g_loss: 1.5058\n",
            "Step [34640/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0056, d_svhn_loss: 0.0257, d_fake_loss: 0.0248, g_loss: 1.0911\n",
            "Step [34650/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0086, d_svhn_loss: 0.0354, d_fake_loss: 0.0717, g_loss: 0.9443\n",
            "Step [34660/60000], d_real_loss: 0.0599, d_mnist_loss: 0.0147, d_svhn_loss: 0.0453, d_fake_loss: 0.0420, g_loss: 1.0673\n",
            "Step [34670/60000], d_real_loss: 0.1994, d_mnist_loss: 0.1529, d_svhn_loss: 0.0465, d_fake_loss: 0.1123, g_loss: 1.4590\n",
            "Step [34680/60000], d_real_loss: 0.0624, d_mnist_loss: 0.0103, d_svhn_loss: 0.0521, d_fake_loss: 0.0849, g_loss: 1.0685\n",
            "Step [34690/60000], d_real_loss: 0.1020, d_mnist_loss: 0.0272, d_svhn_loss: 0.0748, d_fake_loss: 0.0566, g_loss: 1.2157\n",
            "Step [34700/60000], d_real_loss: 0.0233, d_mnist_loss: 0.0108, d_svhn_loss: 0.0125, d_fake_loss: 0.0413, g_loss: 1.1497\n",
            "Step [34710/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0155, d_svhn_loss: 0.0183, d_fake_loss: 0.0667, g_loss: 0.9457\n",
            "Step [34720/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0149, d_svhn_loss: 0.0220, d_fake_loss: 0.0475, g_loss: 1.2558\n",
            "Step [34730/60000], d_real_loss: 0.0233, d_mnist_loss: 0.0107, d_svhn_loss: 0.0126, d_fake_loss: 0.0992, g_loss: 1.2300\n",
            "Step [34740/60000], d_real_loss: 0.0747, d_mnist_loss: 0.0101, d_svhn_loss: 0.0646, d_fake_loss: 0.0420, g_loss: 1.0985\n",
            "Step [34750/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0067, d_svhn_loss: 0.0529, d_fake_loss: 0.0535, g_loss: 1.1456\n",
            "Step [34760/60000], d_real_loss: 0.0333, d_mnist_loss: 0.0060, d_svhn_loss: 0.0273, d_fake_loss: 0.0570, g_loss: 1.2339\n",
            "Step [34770/60000], d_real_loss: 0.0299, d_mnist_loss: 0.0079, d_svhn_loss: 0.0220, d_fake_loss: 0.0355, g_loss: 1.1784\n",
            "Step [34780/60000], d_real_loss: 0.0563, d_mnist_loss: 0.0092, d_svhn_loss: 0.0471, d_fake_loss: 0.0750, g_loss: 1.1706\n",
            "Step [34790/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0090, d_svhn_loss: 0.0314, d_fake_loss: 0.0608, g_loss: 1.2452\n",
            "Step [34800/60000], d_real_loss: 0.0650, d_mnist_loss: 0.0416, d_svhn_loss: 0.0234, d_fake_loss: 0.0454, g_loss: 1.1351\n",
            "Step [34810/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0204, d_svhn_loss: 0.0194, d_fake_loss: 0.0510, g_loss: 1.0316\n",
            "Step [34820/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0073, d_svhn_loss: 0.0348, d_fake_loss: 0.0953, g_loss: 0.9367\n",
            "Step [34830/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0172, d_svhn_loss: 0.0197, d_fake_loss: 0.0452, g_loss: 1.1721\n",
            "Step [34840/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0271, d_svhn_loss: 0.0149, d_fake_loss: 0.0525, g_loss: 1.0603\n",
            "Step [34850/60000], d_real_loss: 0.1237, d_mnist_loss: 0.0080, d_svhn_loss: 0.1157, d_fake_loss: 0.2423, g_loss: 1.1709\n",
            "Step [34860/60000], d_real_loss: 0.0835, d_mnist_loss: 0.0184, d_svhn_loss: 0.0651, d_fake_loss: 0.0339, g_loss: 1.2335\n",
            "Step [34870/60000], d_real_loss: 0.0721, d_mnist_loss: 0.0277, d_svhn_loss: 0.0444, d_fake_loss: 0.0487, g_loss: 1.2680\n",
            "Step [34880/60000], d_real_loss: 0.0787, d_mnist_loss: 0.0177, d_svhn_loss: 0.0610, d_fake_loss: 0.1297, g_loss: 1.5912\n",
            "Step [34890/60000], d_real_loss: 0.1711, d_mnist_loss: 0.0162, d_svhn_loss: 0.1549, d_fake_loss: 0.0320, g_loss: 1.0793\n",
            "Step [34900/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0099, d_svhn_loss: 0.0254, d_fake_loss: 0.0491, g_loss: 0.9476\n",
            "Step [34910/60000], d_real_loss: 0.0446, d_mnist_loss: 0.0239, d_svhn_loss: 0.0207, d_fake_loss: 0.0390, g_loss: 1.0333\n",
            "Step [34920/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0265, d_svhn_loss: 0.0265, d_fake_loss: 0.0374, g_loss: 0.9943\n",
            "Step [34930/60000], d_real_loss: 0.1268, d_mnist_loss: 0.0551, d_svhn_loss: 0.0718, d_fake_loss: 0.2076, g_loss: 1.1646\n",
            "Step [34940/60000], d_real_loss: 0.0265, d_mnist_loss: 0.0098, d_svhn_loss: 0.0167, d_fake_loss: 0.0403, g_loss: 1.0264\n",
            "Step [34950/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0076, d_svhn_loss: 0.0284, d_fake_loss: 0.0593, g_loss: 1.3253\n",
            "Step [34960/60000], d_real_loss: 0.1077, d_mnist_loss: 0.0100, d_svhn_loss: 0.0976, d_fake_loss: 0.0255, g_loss: 1.1178\n",
            "Step [34970/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0155, d_svhn_loss: 0.0168, d_fake_loss: 0.0348, g_loss: 1.2528\n",
            "Step [34980/60000], d_real_loss: 0.0325, d_mnist_loss: 0.0069, d_svhn_loss: 0.0256, d_fake_loss: 0.0454, g_loss: 1.2437\n",
            "Step [34990/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0087, d_svhn_loss: 0.0243, d_fake_loss: 0.0528, g_loss: 1.1153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [35000/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0468, d_svhn_loss: 0.0197, d_fake_loss: 0.1387, g_loss: 1.9349\n",
            "saved ./samples_fashion/sample-35000-m-s.png\n",
            "saved ./samples_fashion/sample-35000-s-m.png\n",
            "Step [35010/60000], d_real_loss: 0.0791, d_mnist_loss: 0.0094, d_svhn_loss: 0.0698, d_fake_loss: 0.0293, g_loss: 1.1123\n",
            "Step [35020/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0189, d_svhn_loss: 0.0341, d_fake_loss: 0.1057, g_loss: 1.0393\n",
            "Step [35030/60000], d_real_loss: 0.2874, d_mnist_loss: 0.0331, d_svhn_loss: 0.2543, d_fake_loss: 0.0614, g_loss: 1.1186\n",
            "Step [35040/60000], d_real_loss: 0.0590, d_mnist_loss: 0.0247, d_svhn_loss: 0.0343, d_fake_loss: 0.0586, g_loss: 1.2526\n",
            "Step [35050/60000], d_real_loss: 0.0446, d_mnist_loss: 0.0172, d_svhn_loss: 0.0274, d_fake_loss: 0.0290, g_loss: 1.2523\n",
            "Step [35060/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0076, d_svhn_loss: 0.0291, d_fake_loss: 0.0923, g_loss: 0.9539\n",
            "Step [35070/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0121, d_svhn_loss: 0.0429, d_fake_loss: 0.0408, g_loss: 1.1841\n",
            "Step [35080/60000], d_real_loss: 0.0468, d_mnist_loss: 0.0131, d_svhn_loss: 0.0337, d_fake_loss: 0.0725, g_loss: 1.2257\n",
            "Step [35090/60000], d_real_loss: 0.0385, d_mnist_loss: 0.0102, d_svhn_loss: 0.0283, d_fake_loss: 0.1018, g_loss: 1.4593\n",
            "Step [35100/60000], d_real_loss: 0.1166, d_mnist_loss: 0.0167, d_svhn_loss: 0.1000, d_fake_loss: 0.0545, g_loss: 1.0340\n",
            "Step [35110/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0232, d_svhn_loss: 0.0165, d_fake_loss: 0.1004, g_loss: 1.0209\n",
            "Step [35120/60000], d_real_loss: 0.0584, d_mnist_loss: 0.0194, d_svhn_loss: 0.0390, d_fake_loss: 0.0479, g_loss: 1.1244\n",
            "Step [35130/60000], d_real_loss: 0.0465, d_mnist_loss: 0.0214, d_svhn_loss: 0.0251, d_fake_loss: 0.0215, g_loss: 1.2871\n",
            "Step [35140/60000], d_real_loss: 0.0514, d_mnist_loss: 0.0119, d_svhn_loss: 0.0395, d_fake_loss: 0.0479, g_loss: 1.1495\n",
            "Step [35150/60000], d_real_loss: 0.1042, d_mnist_loss: 0.0096, d_svhn_loss: 0.0945, d_fake_loss: 0.0394, g_loss: 1.2463\n",
            "Step [35160/60000], d_real_loss: 0.0485, d_mnist_loss: 0.0252, d_svhn_loss: 0.0233, d_fake_loss: 0.0317, g_loss: 1.1240\n",
            "Step [35170/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0070, d_svhn_loss: 0.0277, d_fake_loss: 0.0794, g_loss: 1.0956\n",
            "Step [35180/60000], d_real_loss: 0.0361, d_mnist_loss: 0.0119, d_svhn_loss: 0.0243, d_fake_loss: 0.0346, g_loss: 1.0524\n",
            "Step [35190/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0206, d_svhn_loss: 0.0273, d_fake_loss: 0.0614, g_loss: 0.9837\n",
            "Step [35200/60000], d_real_loss: 0.0276, d_mnist_loss: 0.0097, d_svhn_loss: 0.0179, d_fake_loss: 0.0373, g_loss: 1.1906\n",
            "Step [35210/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0367, d_svhn_loss: 0.0197, d_fake_loss: 0.0187, g_loss: 1.0371\n",
            "Step [35220/60000], d_real_loss: 0.0678, d_mnist_loss: 0.0109, d_svhn_loss: 0.0569, d_fake_loss: 0.0352, g_loss: 1.0126\n",
            "Step [35230/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0118, d_svhn_loss: 0.0193, d_fake_loss: 0.0337, g_loss: 0.9821\n",
            "Step [35240/60000], d_real_loss: 0.0454, d_mnist_loss: 0.0226, d_svhn_loss: 0.0228, d_fake_loss: 0.1092, g_loss: 1.0493\n",
            "Step [35250/60000], d_real_loss: 0.0950, d_mnist_loss: 0.0361, d_svhn_loss: 0.0589, d_fake_loss: 0.0516, g_loss: 1.0453\n",
            "Step [35260/60000], d_real_loss: 0.0551, d_mnist_loss: 0.0269, d_svhn_loss: 0.0282, d_fake_loss: 0.0302, g_loss: 1.2886\n",
            "Step [35270/60000], d_real_loss: 0.1373, d_mnist_loss: 0.0391, d_svhn_loss: 0.0982, d_fake_loss: 0.0619, g_loss: 1.2364\n",
            "Step [35280/60000], d_real_loss: 0.0383, d_mnist_loss: 0.0078, d_svhn_loss: 0.0305, d_fake_loss: 0.0337, g_loss: 1.0323\n",
            "Step [35290/60000], d_real_loss: 0.0932, d_mnist_loss: 0.0462, d_svhn_loss: 0.0470, d_fake_loss: 0.0203, g_loss: 1.0056\n",
            "Step [35300/60000], d_real_loss: 0.0493, d_mnist_loss: 0.0254, d_svhn_loss: 0.0239, d_fake_loss: 0.0777, g_loss: 1.2727\n",
            "Step [35310/60000], d_real_loss: 0.0519, d_mnist_loss: 0.0122, d_svhn_loss: 0.0397, d_fake_loss: 0.0733, g_loss: 1.2128\n",
            "Step [35320/60000], d_real_loss: 0.1197, d_mnist_loss: 0.0222, d_svhn_loss: 0.0975, d_fake_loss: 0.0382, g_loss: 1.1983\n",
            "Step [35330/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0098, d_svhn_loss: 0.0205, d_fake_loss: 0.0302, g_loss: 1.1177\n",
            "Step [35340/60000], d_real_loss: 0.0490, d_mnist_loss: 0.0075, d_svhn_loss: 0.0415, d_fake_loss: 0.0425, g_loss: 1.3052\n",
            "Step [35350/60000], d_real_loss: 0.0630, d_mnist_loss: 0.0099, d_svhn_loss: 0.0532, d_fake_loss: 0.0314, g_loss: 1.2604\n",
            "Step [35360/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0229, d_svhn_loss: 0.0246, d_fake_loss: 0.0367, g_loss: 1.1627\n",
            "Step [35370/60000], d_real_loss: 0.3310, d_mnist_loss: 0.2747, d_svhn_loss: 0.0563, d_fake_loss: 0.0637, g_loss: 1.4296\n",
            "Step [35380/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0506, d_svhn_loss: 0.0166, d_fake_loss: 0.0308, g_loss: 1.2558\n",
            "Step [35390/60000], d_real_loss: 0.0340, d_mnist_loss: 0.0184, d_svhn_loss: 0.0156, d_fake_loss: 0.0285, g_loss: 1.2181\n",
            "Step [35400/60000], d_real_loss: 0.0813, d_mnist_loss: 0.0595, d_svhn_loss: 0.0218, d_fake_loss: 0.0777, g_loss: 0.9912\n",
            "Step [35410/60000], d_real_loss: 0.0287, d_mnist_loss: 0.0105, d_svhn_loss: 0.0182, d_fake_loss: 0.0156, g_loss: 1.1668\n",
            "Step [35420/60000], d_real_loss: 0.0328, d_mnist_loss: 0.0129, d_svhn_loss: 0.0199, d_fake_loss: 0.0346, g_loss: 1.1624\n",
            "Step [35430/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0103, d_svhn_loss: 0.0151, d_fake_loss: 0.0987, g_loss: 1.0819\n",
            "Step [35440/60000], d_real_loss: 0.1384, d_mnist_loss: 0.0128, d_svhn_loss: 0.1256, d_fake_loss: 0.0776, g_loss: 1.2586\n",
            "Step [35450/60000], d_real_loss: 0.1668, d_mnist_loss: 0.0103, d_svhn_loss: 0.1565, d_fake_loss: 0.0434, g_loss: 1.2525\n",
            "Step [35460/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0050, d_svhn_loss: 0.0264, d_fake_loss: 0.0777, g_loss: 1.1941\n",
            "Step [35470/60000], d_real_loss: 0.0600, d_mnist_loss: 0.0218, d_svhn_loss: 0.0382, d_fake_loss: 0.1598, g_loss: 1.4165\n",
            "Step [35480/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0074, d_svhn_loss: 0.0245, d_fake_loss: 0.0334, g_loss: 1.2428\n",
            "Step [35490/60000], d_real_loss: 0.1224, d_mnist_loss: 0.0614, d_svhn_loss: 0.0610, d_fake_loss: 0.0753, g_loss: 0.9612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [35500/60000], d_real_loss: 0.0410, d_mnist_loss: 0.0150, d_svhn_loss: 0.0260, d_fake_loss: 0.0605, g_loss: 1.2018\n",
            "saved ./samples_fashion/sample-35500-m-s.png\n",
            "saved ./samples_fashion/sample-35500-s-m.png\n",
            "Step [35510/60000], d_real_loss: 0.0641, d_mnist_loss: 0.0156, d_svhn_loss: 0.0485, d_fake_loss: 0.0675, g_loss: 1.0994\n",
            "Step [35520/60000], d_real_loss: 0.0575, d_mnist_loss: 0.0218, d_svhn_loss: 0.0357, d_fake_loss: 0.0348, g_loss: 1.0513\n",
            "Step [35530/60000], d_real_loss: 0.0473, d_mnist_loss: 0.0228, d_svhn_loss: 0.0246, d_fake_loss: 0.0934, g_loss: 1.0438\n",
            "Step [35540/60000], d_real_loss: 0.0513, d_mnist_loss: 0.0110, d_svhn_loss: 0.0403, d_fake_loss: 0.1559, g_loss: 1.4280\n",
            "Step [35550/60000], d_real_loss: 0.0681, d_mnist_loss: 0.0509, d_svhn_loss: 0.0171, d_fake_loss: 0.0837, g_loss: 1.5533\n",
            "Step [35560/60000], d_real_loss: 0.0473, d_mnist_loss: 0.0151, d_svhn_loss: 0.0321, d_fake_loss: 0.0733, g_loss: 0.9958\n",
            "Step [35570/60000], d_real_loss: 0.0297, d_mnist_loss: 0.0092, d_svhn_loss: 0.0206, d_fake_loss: 0.0498, g_loss: 1.2350\n",
            "Step [35580/60000], d_real_loss: 0.0834, d_mnist_loss: 0.0082, d_svhn_loss: 0.0752, d_fake_loss: 0.1779, g_loss: 1.0307\n",
            "Step [35590/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0059, d_svhn_loss: 0.0471, d_fake_loss: 0.0341, g_loss: 1.0582\n",
            "Step [35600/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0129, d_svhn_loss: 0.0353, d_fake_loss: 0.0460, g_loss: 0.9243\n",
            "Step [35610/60000], d_real_loss: 0.0994, d_mnist_loss: 0.0111, d_svhn_loss: 0.0883, d_fake_loss: 0.0623, g_loss: 1.0476\n",
            "Step [35620/60000], d_real_loss: 0.0643, d_mnist_loss: 0.0341, d_svhn_loss: 0.0301, d_fake_loss: 0.0222, g_loss: 1.2402\n",
            "Step [35630/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0213, d_svhn_loss: 0.0186, d_fake_loss: 0.0275, g_loss: 1.1642\n",
            "Step [35640/60000], d_real_loss: 0.0908, d_mnist_loss: 0.0653, d_svhn_loss: 0.0255, d_fake_loss: 0.0513, g_loss: 1.5124\n",
            "Step [35650/60000], d_real_loss: 0.0825, d_mnist_loss: 0.0103, d_svhn_loss: 0.0721, d_fake_loss: 0.1200, g_loss: 1.3238\n",
            "Step [35660/60000], d_real_loss: 0.3714, d_mnist_loss: 0.3047, d_svhn_loss: 0.0667, d_fake_loss: 0.1932, g_loss: 1.9620\n",
            "Step [35670/60000], d_real_loss: 0.0601, d_mnist_loss: 0.0167, d_svhn_loss: 0.0435, d_fake_loss: 0.0389, g_loss: 1.1018\n",
            "Step [35680/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0134, d_svhn_loss: 0.0287, d_fake_loss: 0.0353, g_loss: 1.0417\n",
            "Step [35690/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0077, d_svhn_loss: 0.0356, d_fake_loss: 0.0655, g_loss: 0.9889\n",
            "Step [35700/60000], d_real_loss: 0.1525, d_mnist_loss: 0.0335, d_svhn_loss: 0.1190, d_fake_loss: 0.0326, g_loss: 1.0557\n",
            "Step [35710/60000], d_real_loss: 0.0555, d_mnist_loss: 0.0175, d_svhn_loss: 0.0380, d_fake_loss: 0.0642, g_loss: 1.2906\n",
            "Step [35720/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0198, d_svhn_loss: 0.0278, d_fake_loss: 0.0222, g_loss: 1.0594\n",
            "Step [35730/60000], d_real_loss: 0.0388, d_mnist_loss: 0.0178, d_svhn_loss: 0.0211, d_fake_loss: 0.0531, g_loss: 1.0887\n",
            "Step [35740/60000], d_real_loss: 0.0466, d_mnist_loss: 0.0236, d_svhn_loss: 0.0230, d_fake_loss: 0.0212, g_loss: 1.0250\n",
            "Step [35750/60000], d_real_loss: 0.0631, d_mnist_loss: 0.0106, d_svhn_loss: 0.0525, d_fake_loss: 0.0725, g_loss: 1.0872\n",
            "Step [35760/60000], d_real_loss: 0.2660, d_mnist_loss: 0.2264, d_svhn_loss: 0.0396, d_fake_loss: 0.0635, g_loss: 1.7648\n",
            "Step [35770/60000], d_real_loss: 0.0786, d_mnist_loss: 0.0341, d_svhn_loss: 0.0445, d_fake_loss: 0.0278, g_loss: 0.9423\n",
            "Step [35780/60000], d_real_loss: 0.1368, d_mnist_loss: 0.0113, d_svhn_loss: 0.1255, d_fake_loss: 0.0695, g_loss: 1.1635\n",
            "Step [35790/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0098, d_svhn_loss: 0.0384, d_fake_loss: 0.0253, g_loss: 1.1491\n",
            "Step [35800/60000], d_real_loss: 0.0720, d_mnist_loss: 0.0170, d_svhn_loss: 0.0549, d_fake_loss: 0.0524, g_loss: 1.1836\n",
            "Step [35810/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0122, d_svhn_loss: 0.0550, d_fake_loss: 0.0724, g_loss: 1.1896\n",
            "Step [35820/60000], d_real_loss: 0.0521, d_mnist_loss: 0.0175, d_svhn_loss: 0.0346, d_fake_loss: 0.0176, g_loss: 1.1508\n",
            "Step [35830/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0206, d_svhn_loss: 0.0230, d_fake_loss: 0.0504, g_loss: 1.0648\n",
            "Step [35840/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0091, d_svhn_loss: 0.0231, d_fake_loss: 0.0564, g_loss: 1.1627\n",
            "Step [35850/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0209, d_svhn_loss: 0.0196, d_fake_loss: 0.0257, g_loss: 0.8730\n",
            "Step [35860/60000], d_real_loss: 0.0549, d_mnist_loss: 0.0224, d_svhn_loss: 0.0325, d_fake_loss: 0.0389, g_loss: 1.1165\n",
            "Step [35870/60000], d_real_loss: 0.0289, d_mnist_loss: 0.0065, d_svhn_loss: 0.0224, d_fake_loss: 0.0754, g_loss: 1.0155\n",
            "Step [35880/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0133, d_svhn_loss: 0.0183, d_fake_loss: 0.0711, g_loss: 0.9451\n",
            "Step [35890/60000], d_real_loss: 0.0739, d_mnist_loss: 0.0573, d_svhn_loss: 0.0165, d_fake_loss: 0.0665, g_loss: 1.1964\n",
            "Step [35900/60000], d_real_loss: 0.0773, d_mnist_loss: 0.0555, d_svhn_loss: 0.0218, d_fake_loss: 0.1102, g_loss: 0.9948\n",
            "Step [35910/60000], d_real_loss: 0.2061, d_mnist_loss: 0.0077, d_svhn_loss: 0.1984, d_fake_loss: 0.1830, g_loss: 1.2095\n",
            "Step [35920/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0085, d_svhn_loss: 0.0197, d_fake_loss: 0.0767, g_loss: 1.1924\n",
            "Step [35930/60000], d_real_loss: 0.0934, d_mnist_loss: 0.0246, d_svhn_loss: 0.0688, d_fake_loss: 0.0232, g_loss: 1.0034\n",
            "Step [35940/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0123, d_svhn_loss: 0.0361, d_fake_loss: 0.0345, g_loss: 1.0989\n",
            "Step [35950/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0151, d_svhn_loss: 0.0319, d_fake_loss: 0.0408, g_loss: 1.2969\n",
            "Step [35960/60000], d_real_loss: 0.0958, d_mnist_loss: 0.0090, d_svhn_loss: 0.0868, d_fake_loss: 0.1292, g_loss: 1.1002\n",
            "Step [35970/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0134, d_svhn_loss: 0.0184, d_fake_loss: 0.0253, g_loss: 1.1927\n",
            "Step [35980/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0087, d_svhn_loss: 0.0648, d_fake_loss: 0.0297, g_loss: 1.1262\n",
            "Step [35990/60000], d_real_loss: 0.0660, d_mnist_loss: 0.0373, d_svhn_loss: 0.0287, d_fake_loss: 0.1457, g_loss: 0.6372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998211860657, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [36000/60000], d_real_loss: 0.0774, d_mnist_loss: 0.0305, d_svhn_loss: 0.0470, d_fake_loss: 0.0386, g_loss: 0.9861\n",
            "saved ./samples_fashion/sample-36000-m-s.png\n",
            "saved ./samples_fashion/sample-36000-s-m.png\n",
            "Step [36010/60000], d_real_loss: 0.0546, d_mnist_loss: 0.0369, d_svhn_loss: 0.0177, d_fake_loss: 0.0429, g_loss: 1.3365\n",
            "Step [36020/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0159, d_svhn_loss: 0.0506, d_fake_loss: 0.0264, g_loss: 1.0516\n",
            "Step [36030/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0243, d_svhn_loss: 0.0263, d_fake_loss: 0.0760, g_loss: 1.4255\n",
            "Step [36040/60000], d_real_loss: 0.0271, d_mnist_loss: 0.0093, d_svhn_loss: 0.0178, d_fake_loss: 0.0261, g_loss: 1.1499\n",
            "Step [36050/60000], d_real_loss: 0.0206, d_mnist_loss: 0.0070, d_svhn_loss: 0.0136, d_fake_loss: 0.0679, g_loss: 1.1927\n",
            "Step [36060/60000], d_real_loss: 0.0277, d_mnist_loss: 0.0094, d_svhn_loss: 0.0183, d_fake_loss: 0.0271, g_loss: 1.2391\n",
            "Step [36070/60000], d_real_loss: 0.0681, d_mnist_loss: 0.0270, d_svhn_loss: 0.0411, d_fake_loss: 0.0318, g_loss: 1.0103\n",
            "Step [36080/60000], d_real_loss: 0.0438, d_mnist_loss: 0.0142, d_svhn_loss: 0.0296, d_fake_loss: 0.0409, g_loss: 1.2021\n",
            "Step [36090/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0158, d_svhn_loss: 0.0205, d_fake_loss: 0.0241, g_loss: 1.1817\n",
            "Step [36100/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0080, d_svhn_loss: 0.0404, d_fake_loss: 0.0285, g_loss: 1.1335\n",
            "Step [36110/60000], d_real_loss: 0.0570, d_mnist_loss: 0.0196, d_svhn_loss: 0.0374, d_fake_loss: 0.0369, g_loss: 1.0816\n",
            "Step [36120/60000], d_real_loss: 0.0868, d_mnist_loss: 0.0104, d_svhn_loss: 0.0764, d_fake_loss: 0.0867, g_loss: 0.9682\n",
            "Step [36130/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0099, d_svhn_loss: 0.0473, d_fake_loss: 0.0266, g_loss: 1.1393\n",
            "Step [36140/60000], d_real_loss: 0.0578, d_mnist_loss: 0.0324, d_svhn_loss: 0.0254, d_fake_loss: 0.0331, g_loss: 1.1650\n",
            "Step [36150/60000], d_real_loss: 0.0506, d_mnist_loss: 0.0266, d_svhn_loss: 0.0240, d_fake_loss: 0.1113, g_loss: 1.1921\n",
            "Step [36160/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0134, d_svhn_loss: 0.0239, d_fake_loss: 0.0618, g_loss: 0.9670\n",
            "Step [36170/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0082, d_svhn_loss: 0.0291, d_fake_loss: 0.0650, g_loss: 1.0828\n",
            "Step [36180/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0244, d_svhn_loss: 0.0291, d_fake_loss: 0.1192, g_loss: 1.0479\n",
            "Step [36190/60000], d_real_loss: 0.0820, d_mnist_loss: 0.0263, d_svhn_loss: 0.0557, d_fake_loss: 0.0878, g_loss: 1.1757\n",
            "Step [36200/60000], d_real_loss: 0.1013, d_mnist_loss: 0.0282, d_svhn_loss: 0.0731, d_fake_loss: 0.0817, g_loss: 1.1659\n",
            "Step [36210/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0291, d_svhn_loss: 0.0298, d_fake_loss: 0.0287, g_loss: 0.9073\n",
            "Step [36220/60000], d_real_loss: 0.0649, d_mnist_loss: 0.0342, d_svhn_loss: 0.0307, d_fake_loss: 0.2313, g_loss: 1.1633\n",
            "Step [36230/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0125, d_svhn_loss: 0.0238, d_fake_loss: 0.0269, g_loss: 1.1305\n",
            "Step [36240/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0104, d_svhn_loss: 0.0242, d_fake_loss: 0.0253, g_loss: 1.0578\n",
            "Step [36250/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0168, d_svhn_loss: 0.0221, d_fake_loss: 0.1229, g_loss: 0.9669\n",
            "Step [36260/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0094, d_svhn_loss: 0.0275, d_fake_loss: 0.0642, g_loss: 1.2309\n",
            "Step [36270/60000], d_real_loss: 0.0818, d_mnist_loss: 0.0163, d_svhn_loss: 0.0656, d_fake_loss: 0.0906, g_loss: 1.2469\n",
            "Step [36280/60000], d_real_loss: 0.0702, d_mnist_loss: 0.0189, d_svhn_loss: 0.0512, d_fake_loss: 0.2034, g_loss: 1.4218\n",
            "Step [36290/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0074, d_svhn_loss: 0.0305, d_fake_loss: 0.0369, g_loss: 1.1684\n",
            "Step [36300/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0091, d_svhn_loss: 0.0309, d_fake_loss: 0.0461, g_loss: 1.1957\n",
            "Step [36310/60000], d_real_loss: 0.0846, d_mnist_loss: 0.0096, d_svhn_loss: 0.0750, d_fake_loss: 0.0286, g_loss: 1.2033\n",
            "Step [36320/60000], d_real_loss: 0.0571, d_mnist_loss: 0.0084, d_svhn_loss: 0.0487, d_fake_loss: 0.0305, g_loss: 1.2758\n",
            "Step [36330/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0214, d_svhn_loss: 0.0261, d_fake_loss: 0.0471, g_loss: 1.1780\n",
            "Step [36340/60000], d_real_loss: 0.1364, d_mnist_loss: 0.0094, d_svhn_loss: 0.1269, d_fake_loss: 0.0497, g_loss: 1.1272\n",
            "Step [36350/60000], d_real_loss: 0.0355, d_mnist_loss: 0.0086, d_svhn_loss: 0.0268, d_fake_loss: 0.0261, g_loss: 1.1642\n",
            "Step [36360/60000], d_real_loss: 0.0224, d_mnist_loss: 0.0081, d_svhn_loss: 0.0144, d_fake_loss: 0.0726, g_loss: 1.2600\n",
            "Step [36370/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0100, d_svhn_loss: 0.0473, d_fake_loss: 0.0800, g_loss: 0.9541\n",
            "Step [36380/60000], d_real_loss: 0.0661, d_mnist_loss: 0.0319, d_svhn_loss: 0.0342, d_fake_loss: 0.0833, g_loss: 1.0627\n",
            "Step [36390/60000], d_real_loss: 0.0422, d_mnist_loss: 0.0218, d_svhn_loss: 0.0204, d_fake_loss: 0.0793, g_loss: 1.3201\n",
            "Step [36400/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0142, d_svhn_loss: 0.0287, d_fake_loss: 0.0274, g_loss: 1.2249\n",
            "Step [36410/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0103, d_svhn_loss: 0.0255, d_fake_loss: 0.0192, g_loss: 1.0968\n",
            "Step [36420/60000], d_real_loss: 0.0481, d_mnist_loss: 0.0176, d_svhn_loss: 0.0305, d_fake_loss: 0.2352, g_loss: 0.3406\n",
            "Step [36430/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0207, d_svhn_loss: 0.0300, d_fake_loss: 0.0288, g_loss: 1.0598\n",
            "Step [36440/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0165, d_svhn_loss: 0.0145, d_fake_loss: 0.0785, g_loss: 1.0838\n",
            "Step [36450/60000], d_real_loss: 0.0285, d_mnist_loss: 0.0133, d_svhn_loss: 0.0152, d_fake_loss: 0.0275, g_loss: 1.2050\n",
            "Step [36460/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0132, d_svhn_loss: 0.0147, d_fake_loss: 0.0889, g_loss: 1.0553\n",
            "Step [36470/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0117, d_svhn_loss: 0.0252, d_fake_loss: 0.0281, g_loss: 1.1313\n",
            "Step [36480/60000], d_real_loss: 0.0916, d_mnist_loss: 0.0105, d_svhn_loss: 0.0811, d_fake_loss: 0.0701, g_loss: 1.2828\n",
            "Step [36490/60000], d_real_loss: 0.0610, d_mnist_loss: 0.0106, d_svhn_loss: 0.0504, d_fake_loss: 0.0468, g_loss: 1.2041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [36500/60000], d_real_loss: 0.0811, d_mnist_loss: 0.0464, d_svhn_loss: 0.0347, d_fake_loss: 0.0413, g_loss: 1.1054\n",
            "saved ./samples_fashion/sample-36500-m-s.png\n",
            "saved ./samples_fashion/sample-36500-s-m.png\n",
            "Step [36510/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0183, d_svhn_loss: 0.0181, d_fake_loss: 0.0508, g_loss: 1.2679\n",
            "Step [36520/60000], d_real_loss: 0.0653, d_mnist_loss: 0.0416, d_svhn_loss: 0.0237, d_fake_loss: 0.0778, g_loss: 0.9774\n",
            "Step [36530/60000], d_real_loss: 0.0331, d_mnist_loss: 0.0078, d_svhn_loss: 0.0253, d_fake_loss: 0.0351, g_loss: 1.1204\n",
            "Step [36540/60000], d_real_loss: 0.0502, d_mnist_loss: 0.0131, d_svhn_loss: 0.0371, d_fake_loss: 0.0463, g_loss: 1.3388\n",
            "Step [36550/60000], d_real_loss: 0.0648, d_mnist_loss: 0.0416, d_svhn_loss: 0.0233, d_fake_loss: 0.1350, g_loss: 1.2164\n",
            "Step [36560/60000], d_real_loss: 0.0682, d_mnist_loss: 0.0088, d_svhn_loss: 0.0594, d_fake_loss: 0.0226, g_loss: 1.0575\n",
            "Step [36570/60000], d_real_loss: 0.0446, d_mnist_loss: 0.0308, d_svhn_loss: 0.0138, d_fake_loss: 0.0825, g_loss: 1.0264\n",
            "Step [36580/60000], d_real_loss: 0.0688, d_mnist_loss: 0.0147, d_svhn_loss: 0.0541, d_fake_loss: 0.0247, g_loss: 1.0353\n",
            "Step [36590/60000], d_real_loss: 0.1608, d_mnist_loss: 0.0132, d_svhn_loss: 0.1476, d_fake_loss: 0.0654, g_loss: 1.2163\n",
            "Step [36600/60000], d_real_loss: 0.0566, d_mnist_loss: 0.0064, d_svhn_loss: 0.0502, d_fake_loss: 0.0494, g_loss: 1.2009\n",
            "Step [36610/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0093, d_svhn_loss: 0.0448, d_fake_loss: 0.0234, g_loss: 1.1336\n",
            "Step [36620/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0107, d_svhn_loss: 0.0207, d_fake_loss: 0.0880, g_loss: 1.3200\n",
            "Step [36630/60000], d_real_loss: 0.0449, d_mnist_loss: 0.0211, d_svhn_loss: 0.0238, d_fake_loss: 0.0315, g_loss: 1.0067\n",
            "Step [36640/60000], d_real_loss: 0.0438, d_mnist_loss: 0.0092, d_svhn_loss: 0.0346, d_fake_loss: 0.2026, g_loss: 1.2523\n",
            "Step [36650/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0133, d_svhn_loss: 0.0229, d_fake_loss: 0.0310, g_loss: 1.0904\n",
            "Step [36660/60000], d_real_loss: 0.1551, d_mnist_loss: 0.0358, d_svhn_loss: 0.1193, d_fake_loss: 0.1010, g_loss: 1.0263\n",
            "Step [36670/60000], d_real_loss: 0.0711, d_mnist_loss: 0.0498, d_svhn_loss: 0.0212, d_fake_loss: 0.0408, g_loss: 1.1170\n",
            "Step [36680/60000], d_real_loss: 0.0454, d_mnist_loss: 0.0161, d_svhn_loss: 0.0293, d_fake_loss: 0.0721, g_loss: 1.0687\n",
            "Step [36690/60000], d_real_loss: 0.0590, d_mnist_loss: 0.0220, d_svhn_loss: 0.0370, d_fake_loss: 0.0639, g_loss: 1.1852\n",
            "Step [36700/60000], d_real_loss: 0.0481, d_mnist_loss: 0.0210, d_svhn_loss: 0.0271, d_fake_loss: 0.1239, g_loss: 1.1889\n",
            "Step [36710/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0099, d_svhn_loss: 0.0217, d_fake_loss: 0.0612, g_loss: 1.1239\n",
            "Step [36720/60000], d_real_loss: 0.0429, d_mnist_loss: 0.0221, d_svhn_loss: 0.0208, d_fake_loss: 0.0324, g_loss: 1.1038\n",
            "Step [36730/60000], d_real_loss: 0.0593, d_mnist_loss: 0.0237, d_svhn_loss: 0.0356, d_fake_loss: 0.0196, g_loss: 1.0404\n",
            "Step [36740/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0141, d_svhn_loss: 0.0164, d_fake_loss: 0.0455, g_loss: 0.9866\n",
            "Step [36750/60000], d_real_loss: 0.0538, d_mnist_loss: 0.0100, d_svhn_loss: 0.0439, d_fake_loss: 0.0587, g_loss: 1.1589\n",
            "Step [36760/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0057, d_svhn_loss: 0.0325, d_fake_loss: 0.0196, g_loss: 1.0434\n",
            "Step [36770/60000], d_real_loss: 0.0891, d_mnist_loss: 0.0400, d_svhn_loss: 0.0491, d_fake_loss: 0.2795, g_loss: 1.1920\n",
            "Step [36780/60000], d_real_loss: 0.0867, d_mnist_loss: 0.0177, d_svhn_loss: 0.0690, d_fake_loss: 0.1287, g_loss: 1.2849\n",
            "Step [36790/60000], d_real_loss: 0.0542, d_mnist_loss: 0.0301, d_svhn_loss: 0.0241, d_fake_loss: 0.0537, g_loss: 1.1768\n",
            "Step [36800/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0097, d_svhn_loss: 0.0174, d_fake_loss: 0.0623, g_loss: 1.1075\n",
            "Step [36810/60000], d_real_loss: 0.0821, d_mnist_loss: 0.0358, d_svhn_loss: 0.0463, d_fake_loss: 0.0639, g_loss: 1.0945\n",
            "Step [36820/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0095, d_svhn_loss: 0.0184, d_fake_loss: 0.0413, g_loss: 1.2564\n",
            "Step [36830/60000], d_real_loss: 0.0497, d_mnist_loss: 0.0169, d_svhn_loss: 0.0328, d_fake_loss: 0.0856, g_loss: 1.3720\n",
            "Step [36840/60000], d_real_loss: 0.0329, d_mnist_loss: 0.0177, d_svhn_loss: 0.0152, d_fake_loss: 0.1362, g_loss: 1.2474\n",
            "Step [36850/60000], d_real_loss: 0.0700, d_mnist_loss: 0.0097, d_svhn_loss: 0.0604, d_fake_loss: 0.0474, g_loss: 1.1953\n",
            "Step [36860/60000], d_real_loss: 0.0972, d_mnist_loss: 0.0658, d_svhn_loss: 0.0314, d_fake_loss: 0.0339, g_loss: 1.2577\n",
            "Step [36870/60000], d_real_loss: 0.0255, d_mnist_loss: 0.0125, d_svhn_loss: 0.0131, d_fake_loss: 0.0417, g_loss: 1.1919\n",
            "Step [36880/60000], d_real_loss: 0.0723, d_mnist_loss: 0.0579, d_svhn_loss: 0.0144, d_fake_loss: 0.0318, g_loss: 1.1069\n",
            "Step [36890/60000], d_real_loss: 0.0567, d_mnist_loss: 0.0249, d_svhn_loss: 0.0317, d_fake_loss: 0.0716, g_loss: 1.1840\n",
            "Step [36900/60000], d_real_loss: 0.0644, d_mnist_loss: 0.0115, d_svhn_loss: 0.0529, d_fake_loss: 0.0929, g_loss: 1.1518\n",
            "Step [36910/60000], d_real_loss: 0.0524, d_mnist_loss: 0.0305, d_svhn_loss: 0.0220, d_fake_loss: 0.0524, g_loss: 1.2826\n",
            "Step [36920/60000], d_real_loss: 0.0496, d_mnist_loss: 0.0320, d_svhn_loss: 0.0176, d_fake_loss: 0.0367, g_loss: 1.2994\n",
            "Step [36930/60000], d_real_loss: 0.0805, d_mnist_loss: 0.0168, d_svhn_loss: 0.0637, d_fake_loss: 0.0478, g_loss: 0.9293\n",
            "Step [36940/60000], d_real_loss: 0.0807, d_mnist_loss: 0.0229, d_svhn_loss: 0.0578, d_fake_loss: 0.1194, g_loss: 1.0551\n",
            "Step [36950/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0092, d_svhn_loss: 0.0268, d_fake_loss: 0.0221, g_loss: 1.0409\n",
            "Step [36960/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0185, d_svhn_loss: 0.0404, d_fake_loss: 0.0293, g_loss: 1.1086\n",
            "Step [36970/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0111, d_svhn_loss: 0.0248, d_fake_loss: 0.0495, g_loss: 1.2836\n",
            "Step [36980/60000], d_real_loss: 0.0820, d_mnist_loss: 0.0128, d_svhn_loss: 0.0692, d_fake_loss: 0.0246, g_loss: 1.1597\n",
            "Step [36990/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0131, d_svhn_loss: 0.0232, d_fake_loss: 0.0280, g_loss: 1.1342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [37000/60000], d_real_loss: 0.0295, d_mnist_loss: 0.0108, d_svhn_loss: 0.0186, d_fake_loss: 0.0371, g_loss: 0.9712\n",
            "saved ./samples_fashion/sample-37000-m-s.png\n",
            "saved ./samples_fashion/sample-37000-s-m.png\n",
            "Step [37010/60000], d_real_loss: 0.0715, d_mnist_loss: 0.0223, d_svhn_loss: 0.0491, d_fake_loss: 0.0357, g_loss: 1.2182\n",
            "Step [37020/60000], d_real_loss: 0.0502, d_mnist_loss: 0.0198, d_svhn_loss: 0.0304, d_fake_loss: 0.0598, g_loss: 1.1226\n",
            "Step [37030/60000], d_real_loss: 0.1008, d_mnist_loss: 0.0682, d_svhn_loss: 0.0326, d_fake_loss: 0.1002, g_loss: 0.9423\n",
            "Step [37040/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0113, d_svhn_loss: 0.0234, d_fake_loss: 0.0203, g_loss: 1.0611\n",
            "Step [37050/60000], d_real_loss: 0.0297, d_mnist_loss: 0.0139, d_svhn_loss: 0.0158, d_fake_loss: 0.0589, g_loss: 1.0591\n",
            "Step [37060/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0164, d_svhn_loss: 0.0232, d_fake_loss: 0.0862, g_loss: 0.9910\n",
            "Step [37070/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0097, d_svhn_loss: 0.0304, d_fake_loss: 0.0223, g_loss: 1.0564\n",
            "Step [37080/60000], d_real_loss: 0.1013, d_mnist_loss: 0.0460, d_svhn_loss: 0.0553, d_fake_loss: 0.0793, g_loss: 1.1632\n",
            "Step [37090/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0145, d_svhn_loss: 0.0160, d_fake_loss: 0.0614, g_loss: 1.2222\n",
            "Step [37100/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0121, d_svhn_loss: 0.0226, d_fake_loss: 0.0329, g_loss: 1.1708\n",
            "Step [37110/60000], d_real_loss: 0.0538, d_mnist_loss: 0.0262, d_svhn_loss: 0.0276, d_fake_loss: 0.0757, g_loss: 1.0816\n",
            "Step [37120/60000], d_real_loss: 0.0522, d_mnist_loss: 0.0253, d_svhn_loss: 0.0268, d_fake_loss: 0.0392, g_loss: 0.9649\n",
            "Step [37130/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0120, d_svhn_loss: 0.0452, d_fake_loss: 0.0481, g_loss: 1.0941\n",
            "Step [37140/60000], d_real_loss: 0.0828, d_mnist_loss: 0.0121, d_svhn_loss: 0.0707, d_fake_loss: 0.1208, g_loss: 1.1751\n",
            "Step [37150/60000], d_real_loss: 0.0987, d_mnist_loss: 0.0095, d_svhn_loss: 0.0892, d_fake_loss: 0.0806, g_loss: 1.0475\n",
            "Step [37160/60000], d_real_loss: 0.1540, d_mnist_loss: 0.0129, d_svhn_loss: 0.1412, d_fake_loss: 0.0728, g_loss: 1.2823\n",
            "Step [37170/60000], d_real_loss: 0.1050, d_mnist_loss: 0.0189, d_svhn_loss: 0.0861, d_fake_loss: 0.0774, g_loss: 1.0518\n",
            "Step [37180/60000], d_real_loss: 0.0288, d_mnist_loss: 0.0089, d_svhn_loss: 0.0199, d_fake_loss: 0.0585, g_loss: 1.1524\n",
            "Step [37190/60000], d_real_loss: 0.0618, d_mnist_loss: 0.0332, d_svhn_loss: 0.0286, d_fake_loss: 0.0378, g_loss: 1.0115\n",
            "Step [37200/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0081, d_svhn_loss: 0.0253, d_fake_loss: 0.0203, g_loss: 1.1145\n",
            "Step [37210/60000], d_real_loss: 0.0578, d_mnist_loss: 0.0359, d_svhn_loss: 0.0220, d_fake_loss: 0.0925, g_loss: 1.4707\n",
            "Step [37220/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0095, d_svhn_loss: 0.0224, d_fake_loss: 0.0376, g_loss: 1.0827\n",
            "Step [37230/60000], d_real_loss: 0.0286, d_mnist_loss: 0.0124, d_svhn_loss: 0.0163, d_fake_loss: 0.0363, g_loss: 1.1501\n",
            "Step [37240/60000], d_real_loss: 0.0486, d_mnist_loss: 0.0083, d_svhn_loss: 0.0403, d_fake_loss: 0.0389, g_loss: 1.2198\n",
            "Step [37250/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0090, d_svhn_loss: 0.0214, d_fake_loss: 0.0921, g_loss: 1.0607\n",
            "Step [37260/60000], d_real_loss: 0.0577, d_mnist_loss: 0.0309, d_svhn_loss: 0.0268, d_fake_loss: 0.0851, g_loss: 1.1632\n",
            "Step [37270/60000], d_real_loss: 0.0736, d_mnist_loss: 0.0248, d_svhn_loss: 0.0488, d_fake_loss: 0.0293, g_loss: 1.3201\n",
            "Step [37280/60000], d_real_loss: 0.0284, d_mnist_loss: 0.0080, d_svhn_loss: 0.0204, d_fake_loss: 0.0249, g_loss: 1.2132\n",
            "Step [37290/60000], d_real_loss: 0.0613, d_mnist_loss: 0.0129, d_svhn_loss: 0.0484, d_fake_loss: 0.1147, g_loss: 1.2265\n",
            "Step [37300/60000], d_real_loss: 0.0523, d_mnist_loss: 0.0120, d_svhn_loss: 0.0403, d_fake_loss: 0.0513, g_loss: 1.5948\n",
            "Step [37310/60000], d_real_loss: 0.0259, d_mnist_loss: 0.0065, d_svhn_loss: 0.0194, d_fake_loss: 0.0292, g_loss: 1.0866\n",
            "Step [37320/60000], d_real_loss: 0.0555, d_mnist_loss: 0.0380, d_svhn_loss: 0.0175, d_fake_loss: 0.0495, g_loss: 1.3876\n",
            "Step [37330/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0188, d_svhn_loss: 0.0278, d_fake_loss: 0.2868, g_loss: 0.6169\n",
            "Step [37340/60000], d_real_loss: 0.1251, d_mnist_loss: 0.0744, d_svhn_loss: 0.0507, d_fake_loss: 0.0901, g_loss: 1.0515\n",
            "Step [37350/60000], d_real_loss: 0.0453, d_mnist_loss: 0.0326, d_svhn_loss: 0.0127, d_fake_loss: 0.0651, g_loss: 1.0741\n",
            "Step [37360/60000], d_real_loss: 0.3263, d_mnist_loss: 0.0315, d_svhn_loss: 0.2949, d_fake_loss: 0.0835, g_loss: 1.1219\n",
            "Step [37370/60000], d_real_loss: 0.0444, d_mnist_loss: 0.0270, d_svhn_loss: 0.0174, d_fake_loss: 0.0417, g_loss: 1.0733\n",
            "Step [37380/60000], d_real_loss: 0.0263, d_mnist_loss: 0.0096, d_svhn_loss: 0.0168, d_fake_loss: 0.0254, g_loss: 1.0809\n",
            "Step [37390/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0090, d_svhn_loss: 0.0269, d_fake_loss: 0.0217, g_loss: 1.1097\n",
            "Step [37400/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0130, d_svhn_loss: 0.0175, d_fake_loss: 0.0613, g_loss: 1.1719\n",
            "Step [37410/60000], d_real_loss: 0.0488, d_mnist_loss: 0.0234, d_svhn_loss: 0.0253, d_fake_loss: 0.0417, g_loss: 0.9926\n",
            "Step [37420/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0096, d_svhn_loss: 0.0325, d_fake_loss: 0.0178, g_loss: 1.1191\n",
            "Step [37430/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0102, d_svhn_loss: 0.0245, d_fake_loss: 0.0876, g_loss: 1.0493\n",
            "Step [37440/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0223, d_svhn_loss: 0.0164, d_fake_loss: 0.0720, g_loss: 1.1208\n",
            "Step [37450/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0097, d_svhn_loss: 0.0262, d_fake_loss: 0.0319, g_loss: 1.1151\n",
            "Step [37460/60000], d_real_loss: 0.0480, d_mnist_loss: 0.0281, d_svhn_loss: 0.0199, d_fake_loss: 0.1012, g_loss: 1.1769\n",
            "Step [37470/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0320, d_svhn_loss: 0.0220, d_fake_loss: 0.0361, g_loss: 0.9922\n",
            "Step [37480/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0221, d_svhn_loss: 0.0156, d_fake_loss: 0.0237, g_loss: 1.0123\n",
            "Step [37490/60000], d_real_loss: 0.0486, d_mnist_loss: 0.0308, d_svhn_loss: 0.0179, d_fake_loss: 0.0203, g_loss: 0.9964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [37500/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0137, d_svhn_loss: 0.0207, d_fake_loss: 0.0514, g_loss: 1.1773\n",
            "saved ./samples_fashion/sample-37500-m-s.png\n",
            "saved ./samples_fashion/sample-37500-s-m.png\n",
            "Step [37510/60000], d_real_loss: 0.0287, d_mnist_loss: 0.0103, d_svhn_loss: 0.0184, d_fake_loss: 0.0627, g_loss: 1.0975\n",
            "Step [37520/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0437, d_svhn_loss: 0.0169, d_fake_loss: 0.0655, g_loss: 1.0892\n",
            "Step [37530/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0149, d_svhn_loss: 0.0293, d_fake_loss: 0.0544, g_loss: 1.0489\n",
            "Step [37540/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0206, d_svhn_loss: 0.0139, d_fake_loss: 0.0314, g_loss: 1.2692\n",
            "Step [37550/60000], d_real_loss: 0.0619, d_mnist_loss: 0.0405, d_svhn_loss: 0.0214, d_fake_loss: 0.0547, g_loss: 1.2662\n",
            "Step [37560/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0244, d_svhn_loss: 0.0188, d_fake_loss: 0.0307, g_loss: 0.9516\n",
            "Step [37570/60000], d_real_loss: 0.0430, d_mnist_loss: 0.0141, d_svhn_loss: 0.0289, d_fake_loss: 0.0184, g_loss: 1.0796\n",
            "Step [37580/60000], d_real_loss: 0.0277, d_mnist_loss: 0.0144, d_svhn_loss: 0.0133, d_fake_loss: 0.0397, g_loss: 1.0798\n",
            "Step [37590/60000], d_real_loss: 0.1330, d_mnist_loss: 0.0094, d_svhn_loss: 0.1236, d_fake_loss: 0.1536, g_loss: 1.2267\n",
            "Step [37600/60000], d_real_loss: 0.1037, d_mnist_loss: 0.0688, d_svhn_loss: 0.0349, d_fake_loss: 0.0593, g_loss: 1.1593\n",
            "Step [37610/60000], d_real_loss: 0.0676, d_mnist_loss: 0.0080, d_svhn_loss: 0.0596, d_fake_loss: 0.0355, g_loss: 1.1249\n",
            "Step [37620/60000], d_real_loss: 0.0515, d_mnist_loss: 0.0225, d_svhn_loss: 0.0290, d_fake_loss: 0.0295, g_loss: 1.1479\n",
            "Step [37630/60000], d_real_loss: 0.0257, d_mnist_loss: 0.0102, d_svhn_loss: 0.0155, d_fake_loss: 0.0586, g_loss: 1.1798\n",
            "Step [37640/60000], d_real_loss: 0.0591, d_mnist_loss: 0.0104, d_svhn_loss: 0.0487, d_fake_loss: 0.0454, g_loss: 1.0412\n",
            "Step [37650/60000], d_real_loss: 0.1095, d_mnist_loss: 0.0831, d_svhn_loss: 0.0263, d_fake_loss: 0.0669, g_loss: 1.2819\n",
            "Step [37660/60000], d_real_loss: 0.0430, d_mnist_loss: 0.0141, d_svhn_loss: 0.0289, d_fake_loss: 0.0711, g_loss: 1.0887\n",
            "Step [37670/60000], d_real_loss: 0.1679, d_mnist_loss: 0.0122, d_svhn_loss: 0.1557, d_fake_loss: 0.0387, g_loss: 1.0398\n",
            "Step [37680/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0174, d_svhn_loss: 0.0233, d_fake_loss: 0.0308, g_loss: 1.0914\n",
            "Step [37690/60000], d_real_loss: 0.0532, d_mnist_loss: 0.0155, d_svhn_loss: 0.0377, d_fake_loss: 0.0432, g_loss: 1.0591\n",
            "Step [37700/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0149, d_svhn_loss: 0.0367, d_fake_loss: 0.0601, g_loss: 1.1168\n",
            "Step [37710/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0103, d_svhn_loss: 0.0207, d_fake_loss: 0.0956, g_loss: 1.0749\n",
            "Step [37720/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0083, d_svhn_loss: 0.0164, d_fake_loss: 0.0415, g_loss: 1.2143\n",
            "Step [37730/60000], d_real_loss: 0.0825, d_mnist_loss: 0.0185, d_svhn_loss: 0.0639, d_fake_loss: 0.0486, g_loss: 0.8919\n",
            "Step [37740/60000], d_real_loss: 0.1077, d_mnist_loss: 0.0138, d_svhn_loss: 0.0939, d_fake_loss: 0.0505, g_loss: 0.9630\n",
            "Step [37750/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0111, d_svhn_loss: 0.0291, d_fake_loss: 0.0303, g_loss: 1.1902\n",
            "Step [37760/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0115, d_svhn_loss: 0.0272, d_fake_loss: 0.0268, g_loss: 1.1995\n",
            "Step [37770/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0094, d_svhn_loss: 0.0281, d_fake_loss: 0.0251, g_loss: 1.1619\n",
            "Step [37780/60000], d_real_loss: 0.1070, d_mnist_loss: 0.0170, d_svhn_loss: 0.0901, d_fake_loss: 0.0243, g_loss: 1.0421\n",
            "Step [37790/60000], d_real_loss: 0.0299, d_mnist_loss: 0.0105, d_svhn_loss: 0.0195, d_fake_loss: 0.1426, g_loss: 1.1069\n",
            "Step [37800/60000], d_real_loss: 0.1218, d_mnist_loss: 0.0941, d_svhn_loss: 0.0277, d_fake_loss: 0.4001, g_loss: 1.8075\n",
            "Step [37810/60000], d_real_loss: 0.0731, d_mnist_loss: 0.0524, d_svhn_loss: 0.0206, d_fake_loss: 0.0455, g_loss: 1.1811\n",
            "Step [37820/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0218, d_svhn_loss: 0.0434, d_fake_loss: 0.0311, g_loss: 1.0398\n",
            "Step [37830/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0089, d_svhn_loss: 0.0499, d_fake_loss: 0.0290, g_loss: 1.1380\n",
            "Step [37840/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0183, d_svhn_loss: 0.0221, d_fake_loss: 0.0462, g_loss: 1.1849\n",
            "Step [37850/60000], d_real_loss: 0.0350, d_mnist_loss: 0.0111, d_svhn_loss: 0.0239, d_fake_loss: 0.0419, g_loss: 1.0040\n",
            "Step [37860/60000], d_real_loss: 0.0386, d_mnist_loss: 0.0125, d_svhn_loss: 0.0262, d_fake_loss: 0.2161, g_loss: 0.9971\n",
            "Step [37870/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0199, d_svhn_loss: 0.0272, d_fake_loss: 0.0283, g_loss: 1.0662\n",
            "Step [37880/60000], d_real_loss: 0.0331, d_mnist_loss: 0.0111, d_svhn_loss: 0.0220, d_fake_loss: 0.1151, g_loss: 1.1911\n",
            "Step [37890/60000], d_real_loss: 0.0919, d_mnist_loss: 0.0612, d_svhn_loss: 0.0307, d_fake_loss: 0.0155, g_loss: 1.3437\n",
            "Step [37900/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0091, d_svhn_loss: 0.0212, d_fake_loss: 0.0721, g_loss: 0.9418\n",
            "Step [37910/60000], d_real_loss: 0.0408, d_mnist_loss: 0.0089, d_svhn_loss: 0.0319, d_fake_loss: 0.0400, g_loss: 1.3463\n",
            "Step [37920/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0081, d_svhn_loss: 0.0437, d_fake_loss: 0.0565, g_loss: 1.1318\n",
            "Step [37930/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0070, d_svhn_loss: 0.0170, d_fake_loss: 0.0156, g_loss: 1.1714\n",
            "Step [37940/60000], d_real_loss: 0.0523, d_mnist_loss: 0.0135, d_svhn_loss: 0.0389, d_fake_loss: 0.1716, g_loss: 1.5030\n",
            "Step [37950/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0094, d_svhn_loss: 0.0470, d_fake_loss: 0.0715, g_loss: 1.0449\n",
            "Step [37960/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0084, d_svhn_loss: 0.0275, d_fake_loss: 0.1104, g_loss: 1.2596\n",
            "Step [37970/60000], d_real_loss: 0.0908, d_mnist_loss: 0.0663, d_svhn_loss: 0.0246, d_fake_loss: 0.0564, g_loss: 0.9291\n",
            "Step [37980/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0140, d_svhn_loss: 0.0448, d_fake_loss: 0.0526, g_loss: 1.1205\n",
            "Step [37990/60000], d_real_loss: 0.0590, d_mnist_loss: 0.0149, d_svhn_loss: 0.0441, d_fake_loss: 0.0666, g_loss: 1.0751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [38000/60000], d_real_loss: 0.0285, d_mnist_loss: 0.0137, d_svhn_loss: 0.0148, d_fake_loss: 0.0474, g_loss: 1.2400\n",
            "saved ./samples_fashion/sample-38000-m-s.png\n",
            "saved ./samples_fashion/sample-38000-s-m.png\n",
            "Step [38010/60000], d_real_loss: 0.0272, d_mnist_loss: 0.0117, d_svhn_loss: 0.0154, d_fake_loss: 0.0319, g_loss: 1.1696\n",
            "Step [38020/60000], d_real_loss: 0.0510, d_mnist_loss: 0.0194, d_svhn_loss: 0.0315, d_fake_loss: 0.0475, g_loss: 1.2157\n",
            "Step [38030/60000], d_real_loss: 0.0858, d_mnist_loss: 0.0177, d_svhn_loss: 0.0681, d_fake_loss: 0.0628, g_loss: 1.1082\n",
            "Step [38040/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0100, d_svhn_loss: 0.0298, d_fake_loss: 0.0389, g_loss: 1.0208\n",
            "Step [38050/60000], d_real_loss: 0.1177, d_mnist_loss: 0.0118, d_svhn_loss: 0.1058, d_fake_loss: 0.0967, g_loss: 1.1467\n",
            "Step [38060/60000], d_real_loss: 0.0728, d_mnist_loss: 0.0112, d_svhn_loss: 0.0617, d_fake_loss: 0.1178, g_loss: 1.1851\n",
            "Step [38070/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0287, d_svhn_loss: 0.0197, d_fake_loss: 0.0596, g_loss: 1.1675\n",
            "Step [38080/60000], d_real_loss: 0.0851, d_mnist_loss: 0.0095, d_svhn_loss: 0.0757, d_fake_loss: 0.0501, g_loss: 1.2606\n",
            "Step [38090/60000], d_real_loss: 0.0243, d_mnist_loss: 0.0066, d_svhn_loss: 0.0177, d_fake_loss: 0.0357, g_loss: 1.0377\n",
            "Step [38100/60000], d_real_loss: 0.0333, d_mnist_loss: 0.0061, d_svhn_loss: 0.0271, d_fake_loss: 0.0199, g_loss: 1.2355\n",
            "Step [38110/60000], d_real_loss: 0.0281, d_mnist_loss: 0.0083, d_svhn_loss: 0.0198, d_fake_loss: 0.0584, g_loss: 1.1543\n",
            "Step [38120/60000], d_real_loss: 0.1031, d_mnist_loss: 0.0229, d_svhn_loss: 0.0802, d_fake_loss: 0.1226, g_loss: 1.2509\n",
            "Step [38130/60000], d_real_loss: 0.0244, d_mnist_loss: 0.0087, d_svhn_loss: 0.0157, d_fake_loss: 0.0516, g_loss: 1.0552\n",
            "Step [38140/60000], d_real_loss: 0.0222, d_mnist_loss: 0.0065, d_svhn_loss: 0.0157, d_fake_loss: 0.0257, g_loss: 1.2256\n",
            "Step [38150/60000], d_real_loss: 0.0586, d_mnist_loss: 0.0110, d_svhn_loss: 0.0476, d_fake_loss: 0.0152, g_loss: 1.1569\n",
            "Step [38160/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0087, d_svhn_loss: 0.0340, d_fake_loss: 0.0428, g_loss: 0.9964\n",
            "Step [38170/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0127, d_svhn_loss: 0.0326, d_fake_loss: 0.0863, g_loss: 1.0643\n",
            "Step [38180/60000], d_real_loss: 0.0190, d_mnist_loss: 0.0083, d_svhn_loss: 0.0107, d_fake_loss: 0.0724, g_loss: 1.2775\n",
            "Step [38190/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0180, d_svhn_loss: 0.0185, d_fake_loss: 0.0244, g_loss: 1.1743\n",
            "Step [38200/60000], d_real_loss: 0.0226, d_mnist_loss: 0.0067, d_svhn_loss: 0.0159, d_fake_loss: 0.0428, g_loss: 0.9746\n",
            "Step [38210/60000], d_real_loss: 0.0411, d_mnist_loss: 0.0083, d_svhn_loss: 0.0328, d_fake_loss: 0.0139, g_loss: 1.0793\n",
            "Step [38220/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0149, d_svhn_loss: 0.0130, d_fake_loss: 0.0182, g_loss: 1.1811\n",
            "Step [38230/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0223, d_svhn_loss: 0.0229, d_fake_loss: 0.0361, g_loss: 1.2186\n",
            "Step [38240/60000], d_real_loss: 0.0449, d_mnist_loss: 0.0189, d_svhn_loss: 0.0260, d_fake_loss: 0.0241, g_loss: 1.0854\n",
            "Step [38250/60000], d_real_loss: 0.1431, d_mnist_loss: 0.0876, d_svhn_loss: 0.0555, d_fake_loss: 0.0802, g_loss: 1.5438\n",
            "Step [38260/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0489, d_svhn_loss: 0.0182, d_fake_loss: 0.1205, g_loss: 0.7847\n",
            "Step [38270/60000], d_real_loss: 0.0272, d_mnist_loss: 0.0075, d_svhn_loss: 0.0198, d_fake_loss: 0.0910, g_loss: 1.2133\n",
            "Step [38280/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0074, d_svhn_loss: 0.0205, d_fake_loss: 0.0273, g_loss: 1.0516\n",
            "Step [38290/60000], d_real_loss: 0.0752, d_mnist_loss: 0.0117, d_svhn_loss: 0.0635, d_fake_loss: 0.1068, g_loss: 1.0297\n",
            "Step [38300/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0114, d_svhn_loss: 0.0279, d_fake_loss: 0.0646, g_loss: 1.2436\n",
            "Step [38310/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0163, d_svhn_loss: 0.0270, d_fake_loss: 0.0456, g_loss: 1.1171\n",
            "Step [38320/60000], d_real_loss: 0.0811, d_mnist_loss: 0.0081, d_svhn_loss: 0.0730, d_fake_loss: 0.1378, g_loss: 1.0017\n",
            "Step [38330/60000], d_real_loss: 0.0670, d_mnist_loss: 0.0165, d_svhn_loss: 0.0505, d_fake_loss: 0.0384, g_loss: 0.9813\n",
            "Step [38340/60000], d_real_loss: 0.0853, d_mnist_loss: 0.0611, d_svhn_loss: 0.0243, d_fake_loss: 0.1668, g_loss: 1.4217\n",
            "Step [38350/60000], d_real_loss: 0.1359, d_mnist_loss: 0.1088, d_svhn_loss: 0.0271, d_fake_loss: 0.1718, g_loss: 1.4412\n",
            "Step [38360/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0116, d_svhn_loss: 0.0204, d_fake_loss: 0.0485, g_loss: 1.0672\n",
            "Step [38370/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0115, d_svhn_loss: 0.0208, d_fake_loss: 0.0155, g_loss: 1.1009\n",
            "Step [38380/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0115, d_svhn_loss: 0.0285, d_fake_loss: 0.0372, g_loss: 1.0679\n",
            "Step [38390/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0109, d_svhn_loss: 0.0173, d_fake_loss: 0.0198, g_loss: 0.9995\n",
            "Step [38400/60000], d_real_loss: 0.0533, d_mnist_loss: 0.0092, d_svhn_loss: 0.0441, d_fake_loss: 0.0200, g_loss: 1.1168\n",
            "Step [38410/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0138, d_svhn_loss: 0.0527, d_fake_loss: 0.0219, g_loss: 1.1786\n",
            "Step [38420/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0086, d_svhn_loss: 0.0167, d_fake_loss: 0.0313, g_loss: 1.1656\n",
            "Step [38430/60000], d_real_loss: 0.0666, d_mnist_loss: 0.0073, d_svhn_loss: 0.0594, d_fake_loss: 0.1009, g_loss: 1.1299\n",
            "Step [38440/60000], d_real_loss: 0.0752, d_mnist_loss: 0.0176, d_svhn_loss: 0.0577, d_fake_loss: 0.0382, g_loss: 1.1308\n",
            "Step [38450/60000], d_real_loss: 0.1133, d_mnist_loss: 0.0348, d_svhn_loss: 0.0785, d_fake_loss: 0.0946, g_loss: 1.1253\n",
            "Step [38460/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0063, d_svhn_loss: 0.0248, d_fake_loss: 0.0347, g_loss: 1.1860\n",
            "Step [38470/60000], d_real_loss: 0.0570, d_mnist_loss: 0.0483, d_svhn_loss: 0.0087, d_fake_loss: 0.0343, g_loss: 1.1513\n",
            "Step [38480/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0424, d_svhn_loss: 0.0173, d_fake_loss: 0.0760, g_loss: 1.1007\n",
            "Step [38490/60000], d_real_loss: 0.1547, d_mnist_loss: 0.0089, d_svhn_loss: 0.1458, d_fake_loss: 0.0384, g_loss: 1.0636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [38500/60000], d_real_loss: 0.0575, d_mnist_loss: 0.0450, d_svhn_loss: 0.0125, d_fake_loss: 0.0833, g_loss: 0.8861\n",
            "saved ./samples_fashion/sample-38500-m-s.png\n",
            "saved ./samples_fashion/sample-38500-s-m.png\n",
            "Step [38510/60000], d_real_loss: 0.0658, d_mnist_loss: 0.0101, d_svhn_loss: 0.0557, d_fake_loss: 0.0864, g_loss: 1.2377\n",
            "Step [38520/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0164, d_svhn_loss: 0.0255, d_fake_loss: 0.0408, g_loss: 1.1644\n",
            "Step [38530/60000], d_real_loss: 0.0666, d_mnist_loss: 0.0305, d_svhn_loss: 0.0362, d_fake_loss: 0.1708, g_loss: 1.2465\n",
            "Step [38540/60000], d_real_loss: 0.0264, d_mnist_loss: 0.0112, d_svhn_loss: 0.0152, d_fake_loss: 0.0348, g_loss: 1.2332\n",
            "Step [38550/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0163, d_svhn_loss: 0.0233, d_fake_loss: 0.0255, g_loss: 0.9930\n",
            "Step [38560/60000], d_real_loss: 0.0541, d_mnist_loss: 0.0148, d_svhn_loss: 0.0393, d_fake_loss: 0.1600, g_loss: 1.0276\n",
            "Step [38570/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0139, d_svhn_loss: 0.0411, d_fake_loss: 0.0221, g_loss: 1.1788\n",
            "Step [38580/60000], d_real_loss: 0.0239, d_mnist_loss: 0.0060, d_svhn_loss: 0.0180, d_fake_loss: 0.0162, g_loss: 1.0270\n",
            "Step [38590/60000], d_real_loss: 0.0834, d_mnist_loss: 0.0521, d_svhn_loss: 0.0313, d_fake_loss: 0.0376, g_loss: 0.9843\n",
            "Step [38600/60000], d_real_loss: 0.0289, d_mnist_loss: 0.0129, d_svhn_loss: 0.0160, d_fake_loss: 0.0139, g_loss: 1.0434\n",
            "Step [38610/60000], d_real_loss: 0.0294, d_mnist_loss: 0.0091, d_svhn_loss: 0.0203, d_fake_loss: 0.0520, g_loss: 1.1436\n",
            "Step [38620/60000], d_real_loss: 0.0789, d_mnist_loss: 0.0089, d_svhn_loss: 0.0700, d_fake_loss: 0.0277, g_loss: 1.0388\n",
            "Step [38630/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0063, d_svhn_loss: 0.0329, d_fake_loss: 0.0326, g_loss: 1.1431\n",
            "Step [38640/60000], d_real_loss: 0.0462, d_mnist_loss: 0.0154, d_svhn_loss: 0.0308, d_fake_loss: 0.0297, g_loss: 1.1003\n",
            "Step [38650/60000], d_real_loss: 0.0541, d_mnist_loss: 0.0181, d_svhn_loss: 0.0360, d_fake_loss: 0.0652, g_loss: 1.0719\n",
            "Step [38660/60000], d_real_loss: 0.0423, d_mnist_loss: 0.0149, d_svhn_loss: 0.0274, d_fake_loss: 0.0388, g_loss: 1.2050\n",
            "Step [38670/60000], d_real_loss: 0.0260, d_mnist_loss: 0.0112, d_svhn_loss: 0.0148, d_fake_loss: 0.0184, g_loss: 1.0375\n",
            "Step [38680/60000], d_real_loss: 0.0654, d_mnist_loss: 0.0068, d_svhn_loss: 0.0586, d_fake_loss: 0.0396, g_loss: 1.0892\n",
            "Step [38690/60000], d_real_loss: 0.0532, d_mnist_loss: 0.0337, d_svhn_loss: 0.0195, d_fake_loss: 0.1619, g_loss: 1.1479\n",
            "Step [38700/60000], d_real_loss: 0.0797, d_mnist_loss: 0.0261, d_svhn_loss: 0.0536, d_fake_loss: 0.0267, g_loss: 1.3501\n",
            "Step [38710/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0197, d_svhn_loss: 0.0367, d_fake_loss: 0.0297, g_loss: 1.1318\n",
            "Step [38720/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0189, d_svhn_loss: 0.0159, d_fake_loss: 0.0345, g_loss: 1.0650\n",
            "Step [38730/60000], d_real_loss: 0.1129, d_mnist_loss: 0.0483, d_svhn_loss: 0.0645, d_fake_loss: 0.0357, g_loss: 1.2091\n",
            "Step [38740/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0081, d_svhn_loss: 0.0345, d_fake_loss: 0.0280, g_loss: 1.1080\n",
            "Step [38750/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0222, d_svhn_loss: 0.0296, d_fake_loss: 0.0688, g_loss: 1.1043\n",
            "Step [38760/60000], d_real_loss: 0.0643, d_mnist_loss: 0.0094, d_svhn_loss: 0.0549, d_fake_loss: 0.0237, g_loss: 1.2451\n",
            "Step [38770/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0204, d_svhn_loss: 0.0171, d_fake_loss: 0.1646, g_loss: 1.0213\n",
            "Step [38780/60000], d_real_loss: 0.0295, d_mnist_loss: 0.0132, d_svhn_loss: 0.0163, d_fake_loss: 0.0418, g_loss: 1.0610\n",
            "Step [38790/60000], d_real_loss: 0.0394, d_mnist_loss: 0.0154, d_svhn_loss: 0.0239, d_fake_loss: 0.0224, g_loss: 1.1656\n",
            "Step [38800/60000], d_real_loss: 0.1534, d_mnist_loss: 0.0467, d_svhn_loss: 0.1067, d_fake_loss: 0.0719, g_loss: 0.9856\n",
            "Step [38810/60000], d_real_loss: 0.1141, d_mnist_loss: 0.0242, d_svhn_loss: 0.0899, d_fake_loss: 0.0348, g_loss: 1.0499\n",
            "Step [38820/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0132, d_svhn_loss: 0.0220, d_fake_loss: 0.0211, g_loss: 1.1100\n",
            "Step [38830/60000], d_real_loss: 0.0762, d_mnist_loss: 0.0101, d_svhn_loss: 0.0661, d_fake_loss: 0.0592, g_loss: 1.1478\n",
            "Step [38840/60000], d_real_loss: 0.0302, d_mnist_loss: 0.0085, d_svhn_loss: 0.0217, d_fake_loss: 0.0501, g_loss: 1.2376\n",
            "Step [38850/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0115, d_svhn_loss: 0.0261, d_fake_loss: 0.1135, g_loss: 1.2335\n",
            "Step [38860/60000], d_real_loss: 0.0762, d_mnist_loss: 0.0504, d_svhn_loss: 0.0258, d_fake_loss: 0.0960, g_loss: 1.3235\n",
            "Step [38870/60000], d_real_loss: 0.0888, d_mnist_loss: 0.0466, d_svhn_loss: 0.0422, d_fake_loss: 0.0327, g_loss: 1.2995\n",
            "Step [38880/60000], d_real_loss: 0.0650, d_mnist_loss: 0.0381, d_svhn_loss: 0.0269, d_fake_loss: 0.0205, g_loss: 0.9772\n",
            "Step [38890/60000], d_real_loss: 0.0920, d_mnist_loss: 0.0447, d_svhn_loss: 0.0473, d_fake_loss: 0.0284, g_loss: 0.9760\n",
            "Step [38900/60000], d_real_loss: 0.0508, d_mnist_loss: 0.0166, d_svhn_loss: 0.0341, d_fake_loss: 0.0232, g_loss: 1.0599\n",
            "Step [38910/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0113, d_svhn_loss: 0.0190, d_fake_loss: 0.0565, g_loss: 1.1665\n",
            "Step [38920/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0138, d_svhn_loss: 0.0458, d_fake_loss: 0.0209, g_loss: 1.2800\n",
            "Step [38930/60000], d_real_loss: 0.0286, d_mnist_loss: 0.0053, d_svhn_loss: 0.0232, d_fake_loss: 0.0575, g_loss: 1.3810\n",
            "Step [38940/60000], d_real_loss: 0.0920, d_mnist_loss: 0.0468, d_svhn_loss: 0.0452, d_fake_loss: 0.1813, g_loss: 0.8051\n",
            "Step [38950/60000], d_real_loss: 0.0676, d_mnist_loss: 0.0129, d_svhn_loss: 0.0546, d_fake_loss: 0.0682, g_loss: 1.0481\n",
            "Step [38960/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0200, d_svhn_loss: 0.0200, d_fake_loss: 0.0269, g_loss: 1.1468\n",
            "Step [38970/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0077, d_svhn_loss: 0.0343, d_fake_loss: 0.0520, g_loss: 1.1890\n",
            "Step [38980/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0141, d_svhn_loss: 0.0201, d_fake_loss: 0.1298, g_loss: 1.1070\n",
            "Step [38990/60000], d_real_loss: 0.0469, d_mnist_loss: 0.0123, d_svhn_loss: 0.0347, d_fake_loss: 0.1127, g_loss: 1.0587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999995827674866, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [39000/60000], d_real_loss: 0.1264, d_mnist_loss: 0.0162, d_svhn_loss: 0.1102, d_fake_loss: 0.0544, g_loss: 1.2048\n",
            "saved ./samples_fashion/sample-39000-m-s.png\n",
            "saved ./samples_fashion/sample-39000-s-m.png\n",
            "Step [39010/60000], d_real_loss: 0.0548, d_mnist_loss: 0.0143, d_svhn_loss: 0.0406, d_fake_loss: 0.0985, g_loss: 1.1931\n",
            "Step [39020/60000], d_real_loss: 0.0730, d_mnist_loss: 0.0315, d_svhn_loss: 0.0414, d_fake_loss: 0.0533, g_loss: 0.9510\n",
            "Step [39030/60000], d_real_loss: 0.0246, d_mnist_loss: 0.0093, d_svhn_loss: 0.0152, d_fake_loss: 0.0343, g_loss: 1.0607\n",
            "Step [39040/60000], d_real_loss: 0.0657, d_mnist_loss: 0.0410, d_svhn_loss: 0.0248, d_fake_loss: 0.0419, g_loss: 1.2975\n",
            "Step [39050/60000], d_real_loss: 0.0563, d_mnist_loss: 0.0276, d_svhn_loss: 0.0287, d_fake_loss: 0.0309, g_loss: 1.2447\n",
            "Step [39060/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0083, d_svhn_loss: 0.0293, d_fake_loss: 0.0198, g_loss: 1.0428\n",
            "Step [39070/60000], d_real_loss: 0.0227, d_mnist_loss: 0.0078, d_svhn_loss: 0.0148, d_fake_loss: 0.0403, g_loss: 1.2342\n",
            "Step [39080/60000], d_real_loss: 0.0559, d_mnist_loss: 0.0104, d_svhn_loss: 0.0455, d_fake_loss: 0.0225, g_loss: 1.2402\n",
            "Step [39090/60000], d_real_loss: 0.0209, d_mnist_loss: 0.0097, d_svhn_loss: 0.0112, d_fake_loss: 0.0221, g_loss: 1.0985\n",
            "Step [39100/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0084, d_svhn_loss: 0.0319, d_fake_loss: 0.0469, g_loss: 1.0815\n",
            "Step [39110/60000], d_real_loss: 0.0866, d_mnist_loss: 0.0089, d_svhn_loss: 0.0777, d_fake_loss: 0.0289, g_loss: 1.1206\n",
            "Step [39120/60000], d_real_loss: 0.0739, d_mnist_loss: 0.0161, d_svhn_loss: 0.0577, d_fake_loss: 0.0979, g_loss: 1.2392\n",
            "Step [39130/60000], d_real_loss: 0.0332, d_mnist_loss: 0.0234, d_svhn_loss: 0.0098, d_fake_loss: 0.0384, g_loss: 0.9368\n",
            "Step [39140/60000], d_real_loss: 0.0690, d_mnist_loss: 0.0209, d_svhn_loss: 0.0481, d_fake_loss: 0.0272, g_loss: 1.0470\n",
            "Step [39150/60000], d_real_loss: 0.0263, d_mnist_loss: 0.0078, d_svhn_loss: 0.0184, d_fake_loss: 0.0617, g_loss: 1.1313\n",
            "Step [39160/60000], d_real_loss: 0.0865, d_mnist_loss: 0.0181, d_svhn_loss: 0.0684, d_fake_loss: 0.1127, g_loss: 1.3362\n",
            "Step [39170/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0099, d_svhn_loss: 0.0301, d_fake_loss: 0.0398, g_loss: 1.2623\n",
            "Step [39180/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0109, d_svhn_loss: 0.0312, d_fake_loss: 0.0498, g_loss: 0.9620\n",
            "Step [39190/60000], d_real_loss: 0.1176, d_mnist_loss: 0.0535, d_svhn_loss: 0.0641, d_fake_loss: 0.1579, g_loss: 1.3238\n",
            "Step [39200/60000], d_real_loss: 0.1237, d_mnist_loss: 0.0136, d_svhn_loss: 0.1101, d_fake_loss: 0.0393, g_loss: 1.1755\n",
            "Step [39210/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0069, d_svhn_loss: 0.0324, d_fake_loss: 0.2349, g_loss: 1.0988\n",
            "Step [39220/60000], d_real_loss: 0.0602, d_mnist_loss: 0.0104, d_svhn_loss: 0.0497, d_fake_loss: 0.0323, g_loss: 1.0584\n",
            "Step [39230/60000], d_real_loss: 0.0926, d_mnist_loss: 0.0403, d_svhn_loss: 0.0523, d_fake_loss: 0.2695, g_loss: 1.7614\n",
            "Step [39240/60000], d_real_loss: 0.1277, d_mnist_loss: 0.0108, d_svhn_loss: 0.1169, d_fake_loss: 0.1111, g_loss: 0.9639\n",
            "Step [39250/60000], d_real_loss: 0.0533, d_mnist_loss: 0.0073, d_svhn_loss: 0.0461, d_fake_loss: 0.0433, g_loss: 1.1511\n",
            "Step [39260/60000], d_real_loss: 0.0523, d_mnist_loss: 0.0096, d_svhn_loss: 0.0428, d_fake_loss: 0.0238, g_loss: 1.2084\n",
            "Step [39270/60000], d_real_loss: 0.0520, d_mnist_loss: 0.0121, d_svhn_loss: 0.0400, d_fake_loss: 0.0499, g_loss: 1.0085\n",
            "Step [39280/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0067, d_svhn_loss: 0.0570, d_fake_loss: 0.0649, g_loss: 1.2881\n",
            "Step [39290/60000], d_real_loss: 0.0386, d_mnist_loss: 0.0182, d_svhn_loss: 0.0204, d_fake_loss: 0.0571, g_loss: 1.2286\n",
            "Step [39300/60000], d_real_loss: 0.0946, d_mnist_loss: 0.0089, d_svhn_loss: 0.0857, d_fake_loss: 0.0559, g_loss: 1.3160\n",
            "Step [39310/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0094, d_svhn_loss: 0.0359, d_fake_loss: 0.0342, g_loss: 0.9588\n",
            "Step [39320/60000], d_real_loss: 0.0697, d_mnist_loss: 0.0076, d_svhn_loss: 0.0621, d_fake_loss: 0.0475, g_loss: 1.1877\n",
            "Step [39330/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0205, d_svhn_loss: 0.0176, d_fake_loss: 0.0436, g_loss: 1.0668\n",
            "Step [39340/60000], d_real_loss: 0.1339, d_mnist_loss: 0.0552, d_svhn_loss: 0.0786, d_fake_loss: 0.1334, g_loss: 1.0990\n",
            "Step [39350/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0097, d_svhn_loss: 0.0295, d_fake_loss: 0.0329, g_loss: 1.1606\n",
            "Step [39360/60000], d_real_loss: 0.0468, d_mnist_loss: 0.0150, d_svhn_loss: 0.0318, d_fake_loss: 0.0327, g_loss: 1.2742\n",
            "Step [39370/60000], d_real_loss: 0.1017, d_mnist_loss: 0.0709, d_svhn_loss: 0.0308, d_fake_loss: 0.0316, g_loss: 0.9786\n",
            "Step [39380/60000], d_real_loss: 0.0247, d_mnist_loss: 0.0120, d_svhn_loss: 0.0127, d_fake_loss: 0.0336, g_loss: 1.1894\n",
            "Step [39390/60000], d_real_loss: 0.0272, d_mnist_loss: 0.0101, d_svhn_loss: 0.0172, d_fake_loss: 0.0341, g_loss: 1.1353\n",
            "Step [39400/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0099, d_svhn_loss: 0.0205, d_fake_loss: 0.0204, g_loss: 1.0488\n",
            "Step [39410/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0109, d_svhn_loss: 0.0218, d_fake_loss: 0.0415, g_loss: 1.0455\n",
            "Step [39420/60000], d_real_loss: 0.0922, d_mnist_loss: 0.0100, d_svhn_loss: 0.0822, d_fake_loss: 0.0404, g_loss: 1.0664\n",
            "Step [39430/60000], d_real_loss: 0.0472, d_mnist_loss: 0.0194, d_svhn_loss: 0.0278, d_fake_loss: 0.0389, g_loss: 1.2365\n",
            "Step [39440/60000], d_real_loss: 0.0274, d_mnist_loss: 0.0142, d_svhn_loss: 0.0132, d_fake_loss: 0.0254, g_loss: 1.0011\n",
            "Step [39450/60000], d_real_loss: 0.0844, d_mnist_loss: 0.0107, d_svhn_loss: 0.0737, d_fake_loss: 0.0489, g_loss: 1.1348\n",
            "Step [39460/60000], d_real_loss: 0.0354, d_mnist_loss: 0.0107, d_svhn_loss: 0.0247, d_fake_loss: 0.0210, g_loss: 1.0651\n",
            "Step [39470/60000], d_real_loss: 0.1183, d_mnist_loss: 0.0333, d_svhn_loss: 0.0850, d_fake_loss: 0.0215, g_loss: 1.1345\n",
            "Step [39480/60000], d_real_loss: 0.0692, d_mnist_loss: 0.0236, d_svhn_loss: 0.0456, d_fake_loss: 0.0299, g_loss: 1.0453\n",
            "Step [39490/60000], d_real_loss: 0.0798, d_mnist_loss: 0.0100, d_svhn_loss: 0.0698, d_fake_loss: 0.0584, g_loss: 1.0151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [39500/60000], d_real_loss: 0.0340, d_mnist_loss: 0.0116, d_svhn_loss: 0.0224, d_fake_loss: 0.0379, g_loss: 1.2684\n",
            "saved ./samples_fashion/sample-39500-m-s.png\n",
            "saved ./samples_fashion/sample-39500-s-m.png\n",
            "Step [39510/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0149, d_svhn_loss: 0.0255, d_fake_loss: 0.0595, g_loss: 1.2149\n",
            "Step [39520/60000], d_real_loss: 0.0339, d_mnist_loss: 0.0183, d_svhn_loss: 0.0156, d_fake_loss: 0.0566, g_loss: 1.1347\n",
            "Step [39530/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0163, d_svhn_loss: 0.0312, d_fake_loss: 0.0210, g_loss: 1.1595\n",
            "Step [39540/60000], d_real_loss: 0.0477, d_mnist_loss: 0.0232, d_svhn_loss: 0.0245, d_fake_loss: 0.0460, g_loss: 1.2194\n",
            "Step [39550/60000], d_real_loss: 0.0827, d_mnist_loss: 0.0212, d_svhn_loss: 0.0615, d_fake_loss: 0.0694, g_loss: 1.2909\n",
            "Step [39560/60000], d_real_loss: 0.1312, d_mnist_loss: 0.0105, d_svhn_loss: 0.1207, d_fake_loss: 0.0239, g_loss: 1.2411\n",
            "Step [39570/60000], d_real_loss: 0.0522, d_mnist_loss: 0.0114, d_svhn_loss: 0.0408, d_fake_loss: 0.0615, g_loss: 1.2362\n",
            "Step [39580/60000], d_real_loss: 0.0662, d_mnist_loss: 0.0118, d_svhn_loss: 0.0544, d_fake_loss: 0.1372, g_loss: 1.1603\n",
            "Step [39590/60000], d_real_loss: 0.0250, d_mnist_loss: 0.0100, d_svhn_loss: 0.0149, d_fake_loss: 0.0235, g_loss: 0.9317\n",
            "Step [39600/60000], d_real_loss: 0.0449, d_mnist_loss: 0.0180, d_svhn_loss: 0.0269, d_fake_loss: 0.0712, g_loss: 1.2280\n",
            "Step [39610/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0079, d_svhn_loss: 0.0293, d_fake_loss: 0.0195, g_loss: 1.1627\n",
            "Step [39620/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0106, d_svhn_loss: 0.0213, d_fake_loss: 0.0626, g_loss: 1.0917\n",
            "Step [39630/60000], d_real_loss: 0.0275, d_mnist_loss: 0.0082, d_svhn_loss: 0.0193, d_fake_loss: 0.0350, g_loss: 1.0851\n",
            "Step [39640/60000], d_real_loss: 0.1874, d_mnist_loss: 0.1037, d_svhn_loss: 0.0838, d_fake_loss: 0.0516, g_loss: 0.9209\n",
            "Step [39650/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0154, d_svhn_loss: 0.0186, d_fake_loss: 0.0569, g_loss: 1.0052\n",
            "Step [39660/60000], d_real_loss: 0.0478, d_mnist_loss: 0.0071, d_svhn_loss: 0.0407, d_fake_loss: 0.1109, g_loss: 1.1513\n",
            "Step [39670/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0084, d_svhn_loss: 0.0373, d_fake_loss: 0.0885, g_loss: 1.3088\n",
            "Step [39680/60000], d_real_loss: 0.0290, d_mnist_loss: 0.0063, d_svhn_loss: 0.0227, d_fake_loss: 0.0590, g_loss: 1.2253\n",
            "Step [39690/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0133, d_svhn_loss: 0.0268, d_fake_loss: 0.1042, g_loss: 0.9806\n",
            "Step [39700/60000], d_real_loss: 0.0688, d_mnist_loss: 0.0109, d_svhn_loss: 0.0578, d_fake_loss: 0.0423, g_loss: 1.2179\n",
            "Step [39710/60000], d_real_loss: 0.0275, d_mnist_loss: 0.0149, d_svhn_loss: 0.0126, d_fake_loss: 0.1008, g_loss: 1.3410\n",
            "Step [39720/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0087, d_svhn_loss: 0.0315, d_fake_loss: 0.0317, g_loss: 0.9573\n",
            "Step [39730/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0087, d_svhn_loss: 0.0441, d_fake_loss: 0.0276, g_loss: 1.0903\n",
            "Step [39740/60000], d_real_loss: 0.0325, d_mnist_loss: 0.0065, d_svhn_loss: 0.0259, d_fake_loss: 0.0271, g_loss: 1.0474\n",
            "Step [39750/60000], d_real_loss: 0.0607, d_mnist_loss: 0.0165, d_svhn_loss: 0.0442, d_fake_loss: 0.0464, g_loss: 0.9228\n",
            "Step [39760/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0216, d_svhn_loss: 0.0203, d_fake_loss: 0.0548, g_loss: 1.2130\n",
            "Step [39770/60000], d_real_loss: 0.0650, d_mnist_loss: 0.0440, d_svhn_loss: 0.0210, d_fake_loss: 0.0273, g_loss: 1.0211\n",
            "Step [39780/60000], d_real_loss: 0.0745, d_mnist_loss: 0.0095, d_svhn_loss: 0.0650, d_fake_loss: 0.0643, g_loss: 1.0184\n",
            "Step [39790/60000], d_real_loss: 0.1386, d_mnist_loss: 0.0554, d_svhn_loss: 0.0832, d_fake_loss: 0.0752, g_loss: 1.0740\n",
            "Step [39800/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0157, d_svhn_loss: 0.0322, d_fake_loss: 0.0341, g_loss: 0.9582\n",
            "Step [39810/60000], d_real_loss: 0.0514, d_mnist_loss: 0.0116, d_svhn_loss: 0.0398, d_fake_loss: 0.0392, g_loss: 1.0078\n",
            "Step [39820/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0298, d_svhn_loss: 0.0156, d_fake_loss: 0.0585, g_loss: 1.2080\n",
            "Step [39830/60000], d_real_loss: 0.0424, d_mnist_loss: 0.0167, d_svhn_loss: 0.0257, d_fake_loss: 0.0249, g_loss: 1.0312\n",
            "Step [39840/60000], d_real_loss: 0.0670, d_mnist_loss: 0.0100, d_svhn_loss: 0.0571, d_fake_loss: 0.0552, g_loss: 1.1376\n",
            "Step [39850/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0145, d_svhn_loss: 0.0171, d_fake_loss: 0.0452, g_loss: 1.0522\n",
            "Step [39860/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0197, d_svhn_loss: 0.0127, d_fake_loss: 0.0231, g_loss: 1.0032\n",
            "Step [39870/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0193, d_svhn_loss: 0.0239, d_fake_loss: 0.0224, g_loss: 1.1316\n",
            "Step [39880/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0125, d_svhn_loss: 0.0264, d_fake_loss: 0.0474, g_loss: 1.2910\n",
            "Step [39890/60000], d_real_loss: 0.1152, d_mnist_loss: 0.0292, d_svhn_loss: 0.0860, d_fake_loss: 0.4129, g_loss: 1.1145\n",
            "Step [39900/60000], d_real_loss: 0.0487, d_mnist_loss: 0.0078, d_svhn_loss: 0.0409, d_fake_loss: 0.0317, g_loss: 1.0751\n",
            "Step [39910/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0162, d_svhn_loss: 0.0157, d_fake_loss: 0.0296, g_loss: 1.0603\n",
            "Step [39920/60000], d_real_loss: 0.0921, d_mnist_loss: 0.0076, d_svhn_loss: 0.0845, d_fake_loss: 0.0646, g_loss: 1.1036\n",
            "Step [39930/60000], d_real_loss: 0.0278, d_mnist_loss: 0.0066, d_svhn_loss: 0.0212, d_fake_loss: 0.0653, g_loss: 1.2088\n",
            "Step [39940/60000], d_real_loss: 0.0508, d_mnist_loss: 0.0250, d_svhn_loss: 0.0258, d_fake_loss: 0.0658, g_loss: 1.0229\n",
            "Step [39950/60000], d_real_loss: 0.0317, d_mnist_loss: 0.0078, d_svhn_loss: 0.0239, d_fake_loss: 0.0281, g_loss: 1.1814\n",
            "Step [39960/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0109, d_svhn_loss: 0.0239, d_fake_loss: 0.0678, g_loss: 1.3964\n",
            "Step [39970/60000], d_real_loss: 0.0682, d_mnist_loss: 0.0077, d_svhn_loss: 0.0605, d_fake_loss: 0.0471, g_loss: 1.0910\n",
            "Step [39980/60000], d_real_loss: 0.0739, d_mnist_loss: 0.0345, d_svhn_loss: 0.0394, d_fake_loss: 0.0256, g_loss: 1.1783\n",
            "Step [39990/60000], d_real_loss: 0.0660, d_mnist_loss: 0.0182, d_svhn_loss: 0.0477, d_fake_loss: 0.0208, g_loss: 1.2370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [40000/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0088, d_svhn_loss: 0.0364, d_fake_loss: 0.0577, g_loss: 1.0612\n",
            "saved ./samples_fashion/sample-40000-m-s.png\n",
            "saved ./samples_fashion/sample-40000-s-m.png\n",
            "Step [40010/60000], d_real_loss: 0.1590, d_mnist_loss: 0.0997, d_svhn_loss: 0.0594, d_fake_loss: 0.0291, g_loss: 1.3280\n",
            "Step [40020/60000], d_real_loss: 0.0549, d_mnist_loss: 0.0185, d_svhn_loss: 0.0363, d_fake_loss: 0.0394, g_loss: 1.0490\n",
            "Step [40030/60000], d_real_loss: 0.0621, d_mnist_loss: 0.0200, d_svhn_loss: 0.0420, d_fake_loss: 0.0525, g_loss: 1.2070\n",
            "Step [40040/60000], d_real_loss: 0.1728, d_mnist_loss: 0.1444, d_svhn_loss: 0.0284, d_fake_loss: 0.0265, g_loss: 1.2260\n",
            "Step [40050/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0141, d_svhn_loss: 0.0183, d_fake_loss: 0.0272, g_loss: 1.1042\n",
            "Step [40060/60000], d_real_loss: 0.0791, d_mnist_loss: 0.0123, d_svhn_loss: 0.0668, d_fake_loss: 0.0265, g_loss: 1.3394\n",
            "Step [40070/60000], d_real_loss: 0.1608, d_mnist_loss: 0.0114, d_svhn_loss: 0.1494, d_fake_loss: 0.0932, g_loss: 1.3099\n",
            "Step [40080/60000], d_real_loss: 0.0547, d_mnist_loss: 0.0106, d_svhn_loss: 0.0441, d_fake_loss: 0.0287, g_loss: 0.9974\n",
            "Step [40090/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0139, d_svhn_loss: 0.0153, d_fake_loss: 0.0271, g_loss: 1.2857\n",
            "Step [40100/60000], d_real_loss: 0.0700, d_mnist_loss: 0.0525, d_svhn_loss: 0.0175, d_fake_loss: 0.0255, g_loss: 1.1855\n",
            "Step [40110/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0149, d_svhn_loss: 0.0159, d_fake_loss: 0.2011, g_loss: 0.8277\n",
            "Step [40120/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0107, d_svhn_loss: 0.0476, d_fake_loss: 0.0256, g_loss: 1.0330\n",
            "Step [40130/60000], d_real_loss: 0.2016, d_mnist_loss: 0.0239, d_svhn_loss: 0.1777, d_fake_loss: 0.0902, g_loss: 1.2140\n",
            "Step [40140/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0138, d_svhn_loss: 0.0239, d_fake_loss: 0.0406, g_loss: 1.2253\n",
            "Step [40150/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0131, d_svhn_loss: 0.0283, d_fake_loss: 0.0194, g_loss: 1.0610\n",
            "Step [40160/60000], d_real_loss: 0.0504, d_mnist_loss: 0.0088, d_svhn_loss: 0.0416, d_fake_loss: 0.0276, g_loss: 1.0550\n",
            "Step [40170/60000], d_real_loss: 0.0517, d_mnist_loss: 0.0082, d_svhn_loss: 0.0435, d_fake_loss: 0.0479, g_loss: 1.0259\n",
            "Step [40180/60000], d_real_loss: 0.0267, d_mnist_loss: 0.0091, d_svhn_loss: 0.0176, d_fake_loss: 0.0444, g_loss: 1.0103\n",
            "Step [40190/60000], d_real_loss: 0.0449, d_mnist_loss: 0.0091, d_svhn_loss: 0.0358, d_fake_loss: 0.0337, g_loss: 1.0818\n",
            "Step [40200/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0081, d_svhn_loss: 0.0232, d_fake_loss: 0.0350, g_loss: 1.1780\n",
            "Step [40210/60000], d_real_loss: 0.0450, d_mnist_loss: 0.0251, d_svhn_loss: 0.0198, d_fake_loss: 0.0652, g_loss: 1.1220\n",
            "Step [40220/60000], d_real_loss: 0.0749, d_mnist_loss: 0.0439, d_svhn_loss: 0.0310, d_fake_loss: 0.0290, g_loss: 1.0531\n",
            "Step [40230/60000], d_real_loss: 0.1581, d_mnist_loss: 0.0104, d_svhn_loss: 0.1477, d_fake_loss: 0.0545, g_loss: 1.2170\n",
            "Step [40240/60000], d_real_loss: 0.0657, d_mnist_loss: 0.0303, d_svhn_loss: 0.0355, d_fake_loss: 0.0707, g_loss: 1.0936\n",
            "Step [40250/60000], d_real_loss: 0.0796, d_mnist_loss: 0.0360, d_svhn_loss: 0.0437, d_fake_loss: 0.1352, g_loss: 1.2876\n",
            "Step [40260/60000], d_real_loss: 0.0694, d_mnist_loss: 0.0397, d_svhn_loss: 0.0297, d_fake_loss: 0.0807, g_loss: 1.4415\n",
            "Step [40270/60000], d_real_loss: 0.0790, d_mnist_loss: 0.0352, d_svhn_loss: 0.0438, d_fake_loss: 0.1904, g_loss: 1.3365\n",
            "Step [40280/60000], d_real_loss: 0.0702, d_mnist_loss: 0.0088, d_svhn_loss: 0.0615, d_fake_loss: 0.0931, g_loss: 1.3233\n",
            "Step [40290/60000], d_real_loss: 0.0876, d_mnist_loss: 0.0703, d_svhn_loss: 0.0173, d_fake_loss: 0.0393, g_loss: 1.0583\n",
            "Step [40300/60000], d_real_loss: 0.0754, d_mnist_loss: 0.0223, d_svhn_loss: 0.0532, d_fake_loss: 0.0764, g_loss: 1.0513\n",
            "Step [40310/60000], d_real_loss: 0.0355, d_mnist_loss: 0.0125, d_svhn_loss: 0.0229, d_fake_loss: 0.1235, g_loss: 1.2694\n",
            "Step [40320/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0142, d_svhn_loss: 0.0449, d_fake_loss: 0.0311, g_loss: 1.1825\n",
            "Step [40330/60000], d_real_loss: 0.0317, d_mnist_loss: 0.0145, d_svhn_loss: 0.0172, d_fake_loss: 0.0179, g_loss: 1.0759\n",
            "Step [40340/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0266, d_svhn_loss: 0.0204, d_fake_loss: 0.1070, g_loss: 1.1512\n",
            "Step [40350/60000], d_real_loss: 0.0453, d_mnist_loss: 0.0141, d_svhn_loss: 0.0312, d_fake_loss: 0.1204, g_loss: 1.3065\n",
            "Step [40360/60000], d_real_loss: 0.0902, d_mnist_loss: 0.0067, d_svhn_loss: 0.0835, d_fake_loss: 0.0540, g_loss: 1.1303\n",
            "Step [40370/60000], d_real_loss: 0.0967, d_mnist_loss: 0.0543, d_svhn_loss: 0.0424, d_fake_loss: 0.0465, g_loss: 1.2999\n",
            "Step [40380/60000], d_real_loss: 0.0381, d_mnist_loss: 0.0113, d_svhn_loss: 0.0268, d_fake_loss: 0.0354, g_loss: 1.0995\n",
            "Step [40390/60000], d_real_loss: 0.0356, d_mnist_loss: 0.0091, d_svhn_loss: 0.0266, d_fake_loss: 0.0216, g_loss: 1.2123\n",
            "Step [40400/60000], d_real_loss: 0.0682, d_mnist_loss: 0.0134, d_svhn_loss: 0.0548, d_fake_loss: 0.1148, g_loss: 1.0894\n",
            "Step [40410/60000], d_real_loss: 0.0536, d_mnist_loss: 0.0339, d_svhn_loss: 0.0197, d_fake_loss: 0.0371, g_loss: 1.0382\n",
            "Step [40420/60000], d_real_loss: 0.0328, d_mnist_loss: 0.0117, d_svhn_loss: 0.0211, d_fake_loss: 0.0205, g_loss: 1.0671\n",
            "Step [40430/60000], d_real_loss: 0.0552, d_mnist_loss: 0.0096, d_svhn_loss: 0.0457, d_fake_loss: 0.0684, g_loss: 1.3841\n",
            "Step [40440/60000], d_real_loss: 0.0259, d_mnist_loss: 0.0107, d_svhn_loss: 0.0152, d_fake_loss: 0.0530, g_loss: 1.3120\n",
            "Step [40450/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0123, d_svhn_loss: 0.0269, d_fake_loss: 0.1469, g_loss: 1.3705\n",
            "Step [40460/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0156, d_svhn_loss: 0.0227, d_fake_loss: 0.0966, g_loss: 1.1002\n",
            "Step [40470/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0098, d_svhn_loss: 0.0419, d_fake_loss: 0.0331, g_loss: 1.2783\n",
            "Step [40480/60000], d_real_loss: 0.0559, d_mnist_loss: 0.0105, d_svhn_loss: 0.0454, d_fake_loss: 0.1141, g_loss: 1.1940\n",
            "Step [40490/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0088, d_svhn_loss: 0.0228, d_fake_loss: 0.0512, g_loss: 1.0497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [40500/60000], d_real_loss: 0.0892, d_mnist_loss: 0.0084, d_svhn_loss: 0.0808, d_fake_loss: 0.1475, g_loss: 1.2451\n",
            "saved ./samples_fashion/sample-40500-m-s.png\n",
            "saved ./samples_fashion/sample-40500-s-m.png\n",
            "Step [40510/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0086, d_svhn_loss: 0.0396, d_fake_loss: 0.0357, g_loss: 1.2623\n",
            "Step [40520/60000], d_real_loss: 0.1210, d_mnist_loss: 0.0272, d_svhn_loss: 0.0937, d_fake_loss: 0.1165, g_loss: 1.1393\n",
            "Step [40530/60000], d_real_loss: 0.0642, d_mnist_loss: 0.0092, d_svhn_loss: 0.0550, d_fake_loss: 0.0187, g_loss: 1.1947\n",
            "Step [40540/60000], d_real_loss: 0.0320, d_mnist_loss: 0.0107, d_svhn_loss: 0.0213, d_fake_loss: 0.0591, g_loss: 1.0690\n",
            "Step [40550/60000], d_real_loss: 0.0264, d_mnist_loss: 0.0096, d_svhn_loss: 0.0168, d_fake_loss: 0.0865, g_loss: 1.4214\n",
            "Step [40560/60000], d_real_loss: 0.0247, d_mnist_loss: 0.0081, d_svhn_loss: 0.0166, d_fake_loss: 0.0212, g_loss: 1.1800\n",
            "Step [40570/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0068, d_svhn_loss: 0.0279, d_fake_loss: 0.0427, g_loss: 1.1356\n",
            "Step [40580/60000], d_real_loss: 0.0210, d_mnist_loss: 0.0079, d_svhn_loss: 0.0131, d_fake_loss: 0.0324, g_loss: 1.2700\n",
            "Step [40590/60000], d_real_loss: 0.0514, d_mnist_loss: 0.0280, d_svhn_loss: 0.0234, d_fake_loss: 0.0424, g_loss: 1.2522\n",
            "Step [40600/60000], d_real_loss: 0.0726, d_mnist_loss: 0.0105, d_svhn_loss: 0.0621, d_fake_loss: 0.0177, g_loss: 1.1575\n",
            "Step [40610/60000], d_real_loss: 0.0655, d_mnist_loss: 0.0405, d_svhn_loss: 0.0250, d_fake_loss: 0.0205, g_loss: 1.2351\n",
            "Step [40620/60000], d_real_loss: 0.0504, d_mnist_loss: 0.0078, d_svhn_loss: 0.0426, d_fake_loss: 0.0366, g_loss: 0.9718\n",
            "Step [40630/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0144, d_svhn_loss: 0.0166, d_fake_loss: 0.0271, g_loss: 0.9403\n",
            "Step [40640/60000], d_real_loss: 0.1034, d_mnist_loss: 0.0522, d_svhn_loss: 0.0511, d_fake_loss: 0.0236, g_loss: 1.0493\n",
            "Step [40650/60000], d_real_loss: 0.0752, d_mnist_loss: 0.0275, d_svhn_loss: 0.0478, d_fake_loss: 0.1192, g_loss: 1.0226\n",
            "Step [40660/60000], d_real_loss: 0.0563, d_mnist_loss: 0.0168, d_svhn_loss: 0.0396, d_fake_loss: 0.0212, g_loss: 1.1121\n",
            "Step [40670/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0104, d_svhn_loss: 0.0149, d_fake_loss: 0.0479, g_loss: 1.2037\n",
            "Step [40680/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0128, d_svhn_loss: 0.0260, d_fake_loss: 0.0852, g_loss: 1.1507\n",
            "Step [40690/60000], d_real_loss: 0.0838, d_mnist_loss: 0.0268, d_svhn_loss: 0.0570, d_fake_loss: 0.1020, g_loss: 1.1224\n",
            "Step [40700/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0172, d_svhn_loss: 0.0307, d_fake_loss: 0.0409, g_loss: 1.1493\n",
            "Step [40710/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0107, d_svhn_loss: 0.0198, d_fake_loss: 0.0720, g_loss: 0.9109\n",
            "Step [40720/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0089, d_svhn_loss: 0.0181, d_fake_loss: 0.0106, g_loss: 1.0378\n",
            "Step [40730/60000], d_real_loss: 0.0515, d_mnist_loss: 0.0128, d_svhn_loss: 0.0387, d_fake_loss: 0.0722, g_loss: 1.2551\n",
            "Step [40740/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0105, d_svhn_loss: 0.0203, d_fake_loss: 0.0240, g_loss: 1.1244\n",
            "Step [40750/60000], d_real_loss: 0.0807, d_mnist_loss: 0.0227, d_svhn_loss: 0.0580, d_fake_loss: 0.0794, g_loss: 1.0516\n",
            "Step [40760/60000], d_real_loss: 0.0596, d_mnist_loss: 0.0294, d_svhn_loss: 0.0301, d_fake_loss: 0.0646, g_loss: 1.2420\n",
            "Step [40770/60000], d_real_loss: 0.0632, d_mnist_loss: 0.0277, d_svhn_loss: 0.0356, d_fake_loss: 0.0349, g_loss: 1.1279\n",
            "Step [40780/60000], d_real_loss: 0.0567, d_mnist_loss: 0.0158, d_svhn_loss: 0.0409, d_fake_loss: 0.0650, g_loss: 1.0324\n",
            "Step [40790/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0091, d_svhn_loss: 0.0188, d_fake_loss: 0.1469, g_loss: 1.3857\n",
            "Step [40800/60000], d_real_loss: 0.0384, d_mnist_loss: 0.0121, d_svhn_loss: 0.0263, d_fake_loss: 0.0713, g_loss: 1.1894\n",
            "Step [40810/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0321, d_svhn_loss: 0.0244, d_fake_loss: 0.0258, g_loss: 1.0145\n",
            "Step [40820/60000], d_real_loss: 0.0526, d_mnist_loss: 0.0093, d_svhn_loss: 0.0433, d_fake_loss: 0.0985, g_loss: 1.5616\n",
            "Step [40830/60000], d_real_loss: 0.0749, d_mnist_loss: 0.0356, d_svhn_loss: 0.0393, d_fake_loss: 0.0898, g_loss: 1.3379\n",
            "Step [40840/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0103, d_svhn_loss: 0.0244, d_fake_loss: 0.0586, g_loss: 1.1889\n",
            "Step [40850/60000], d_real_loss: 0.0771, d_mnist_loss: 0.0102, d_svhn_loss: 0.0669, d_fake_loss: 0.0328, g_loss: 1.0057\n",
            "Step [40860/60000], d_real_loss: 0.0384, d_mnist_loss: 0.0160, d_svhn_loss: 0.0224, d_fake_loss: 0.0406, g_loss: 1.0103\n",
            "Step [40870/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0126, d_svhn_loss: 0.0122, d_fake_loss: 0.0176, g_loss: 1.0671\n",
            "Step [40880/60000], d_real_loss: 0.1779, d_mnist_loss: 0.1415, d_svhn_loss: 0.0364, d_fake_loss: 0.1967, g_loss: 1.5117\n",
            "Step [40890/60000], d_real_loss: 0.0295, d_mnist_loss: 0.0135, d_svhn_loss: 0.0161, d_fake_loss: 0.0471, g_loss: 1.0644\n",
            "Step [40900/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0117, d_svhn_loss: 0.0153, d_fake_loss: 0.0195, g_loss: 1.1105\n",
            "Step [40910/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0120, d_svhn_loss: 0.0128, d_fake_loss: 0.0209, g_loss: 1.1276\n",
            "Step [40920/60000], d_real_loss: 0.0726, d_mnist_loss: 0.0547, d_svhn_loss: 0.0178, d_fake_loss: 0.0456, g_loss: 1.3316\n",
            "Step [40930/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0126, d_svhn_loss: 0.0538, d_fake_loss: 0.0755, g_loss: 1.0924\n",
            "Step [40940/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0093, d_svhn_loss: 0.0223, d_fake_loss: 0.0275, g_loss: 1.0988\n",
            "Step [40950/60000], d_real_loss: 0.0269, d_mnist_loss: 0.0072, d_svhn_loss: 0.0197, d_fake_loss: 0.1015, g_loss: 1.1697\n",
            "Step [40960/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0115, d_svhn_loss: 0.0246, d_fake_loss: 0.0714, g_loss: 1.2487\n",
            "Step [40970/60000], d_real_loss: 0.0463, d_mnist_loss: 0.0085, d_svhn_loss: 0.0379, d_fake_loss: 0.0295, g_loss: 1.0037\n",
            "Step [40980/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0064, d_svhn_loss: 0.0271, d_fake_loss: 0.0766, g_loss: 1.5185\n",
            "Step [40990/60000], d_real_loss: 0.0280, d_mnist_loss: 0.0114, d_svhn_loss: 0.0166, d_fake_loss: 0.0365, g_loss: 1.0972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [41000/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0071, d_svhn_loss: 0.0316, d_fake_loss: 0.0438, g_loss: 1.2192\n",
            "saved ./samples_fashion/sample-41000-m-s.png\n",
            "saved ./samples_fashion/sample-41000-s-m.png\n",
            "Step [41010/60000], d_real_loss: 0.0717, d_mnist_loss: 0.0266, d_svhn_loss: 0.0451, d_fake_loss: 0.0710, g_loss: 1.0798\n",
            "Step [41020/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0228, d_svhn_loss: 0.0159, d_fake_loss: 0.0854, g_loss: 0.9471\n",
            "Step [41030/60000], d_real_loss: 0.0508, d_mnist_loss: 0.0095, d_svhn_loss: 0.0414, d_fake_loss: 0.0137, g_loss: 1.1200\n",
            "Step [41040/60000], d_real_loss: 0.0820, d_mnist_loss: 0.0219, d_svhn_loss: 0.0602, d_fake_loss: 0.0664, g_loss: 1.2464\n",
            "Step [41050/60000], d_real_loss: 0.1701, d_mnist_loss: 0.1471, d_svhn_loss: 0.0230, d_fake_loss: 0.0333, g_loss: 1.2598\n",
            "Step [41060/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0160, d_svhn_loss: 0.0144, d_fake_loss: 0.0211, g_loss: 1.1367\n",
            "Step [41070/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0130, d_svhn_loss: 0.0209, d_fake_loss: 0.0224, g_loss: 1.0325\n",
            "Step [41080/60000], d_real_loss: 0.0627, d_mnist_loss: 0.0216, d_svhn_loss: 0.0410, d_fake_loss: 0.0567, g_loss: 1.1522\n",
            "Step [41090/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0185, d_svhn_loss: 0.0217, d_fake_loss: 0.0194, g_loss: 1.0716\n",
            "Step [41100/60000], d_real_loss: 0.0278, d_mnist_loss: 0.0137, d_svhn_loss: 0.0141, d_fake_loss: 0.0210, g_loss: 1.0737\n",
            "Step [41110/60000], d_real_loss: 0.0250, d_mnist_loss: 0.0084, d_svhn_loss: 0.0166, d_fake_loss: 0.0256, g_loss: 1.1416\n",
            "Step [41120/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0108, d_svhn_loss: 0.0367, d_fake_loss: 0.0850, g_loss: 1.0367\n",
            "Step [41130/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0087, d_svhn_loss: 0.0257, d_fake_loss: 0.0268, g_loss: 1.2603\n",
            "Step [41140/60000], d_real_loss: 0.0614, d_mnist_loss: 0.0318, d_svhn_loss: 0.0296, d_fake_loss: 0.0212, g_loss: 1.2466\n",
            "Step [41150/60000], d_real_loss: 0.0231, d_mnist_loss: 0.0111, d_svhn_loss: 0.0119, d_fake_loss: 0.0638, g_loss: 0.9334\n",
            "Step [41160/60000], d_real_loss: 0.3270, d_mnist_loss: 0.2883, d_svhn_loss: 0.0387, d_fake_loss: 0.1839, g_loss: 1.7569\n",
            "Step [41170/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0120, d_svhn_loss: 0.0296, d_fake_loss: 0.1482, g_loss: 1.0630\n",
            "Step [41180/60000], d_real_loss: 0.0757, d_mnist_loss: 0.0371, d_svhn_loss: 0.0387, d_fake_loss: 0.0457, g_loss: 1.0671\n",
            "Step [41190/60000], d_real_loss: 0.0264, d_mnist_loss: 0.0084, d_svhn_loss: 0.0180, d_fake_loss: 0.0258, g_loss: 1.0704\n",
            "Step [41200/60000], d_real_loss: 0.0539, d_mnist_loss: 0.0123, d_svhn_loss: 0.0416, d_fake_loss: 0.0556, g_loss: 1.1946\n",
            "Step [41210/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0117, d_svhn_loss: 0.0221, d_fake_loss: 0.0304, g_loss: 1.0705\n",
            "Step [41220/60000], d_real_loss: 0.0537, d_mnist_loss: 0.0148, d_svhn_loss: 0.0389, d_fake_loss: 0.0502, g_loss: 1.0078\n",
            "Step [41230/60000], d_real_loss: 0.0557, d_mnist_loss: 0.0128, d_svhn_loss: 0.0429, d_fake_loss: 0.0436, g_loss: 1.0293\n",
            "Step [41240/60000], d_real_loss: 0.0501, d_mnist_loss: 0.0110, d_svhn_loss: 0.0390, d_fake_loss: 0.0475, g_loss: 1.0003\n",
            "Step [41250/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0091, d_svhn_loss: 0.0253, d_fake_loss: 0.0931, g_loss: 1.1772\n",
            "Step [41260/60000], d_real_loss: 0.0312, d_mnist_loss: 0.0110, d_svhn_loss: 0.0202, d_fake_loss: 0.0554, g_loss: 1.0871\n",
            "Step [41270/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0101, d_svhn_loss: 0.0205, d_fake_loss: 0.0418, g_loss: 0.9740\n",
            "Step [41280/60000], d_real_loss: 0.0625, d_mnist_loss: 0.0425, d_svhn_loss: 0.0200, d_fake_loss: 0.0450, g_loss: 1.2078\n",
            "Step [41290/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0140, d_svhn_loss: 0.0258, d_fake_loss: 0.0390, g_loss: 1.2722\n",
            "Step [41300/60000], d_real_loss: 0.0953, d_mnist_loss: 0.0136, d_svhn_loss: 0.0818, d_fake_loss: 0.0311, g_loss: 1.1117\n",
            "Step [41310/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0112, d_svhn_loss: 0.0193, d_fake_loss: 0.0450, g_loss: 1.0258\n",
            "Step [41320/60000], d_real_loss: 0.0569, d_mnist_loss: 0.0324, d_svhn_loss: 0.0246, d_fake_loss: 0.0228, g_loss: 1.2644\n",
            "Step [41330/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0106, d_svhn_loss: 0.0243, d_fake_loss: 0.0385, g_loss: 1.0598\n",
            "Step [41340/60000], d_real_loss: 0.0212, d_mnist_loss: 0.0081, d_svhn_loss: 0.0131, d_fake_loss: 0.0495, g_loss: 1.1730\n",
            "Step [41350/60000], d_real_loss: 0.1048, d_mnist_loss: 0.0097, d_svhn_loss: 0.0951, d_fake_loss: 0.0692, g_loss: 0.9974\n",
            "Step [41360/60000], d_real_loss: 0.0299, d_mnist_loss: 0.0083, d_svhn_loss: 0.0216, d_fake_loss: 0.0394, g_loss: 1.0258\n",
            "Step [41370/60000], d_real_loss: 0.0417, d_mnist_loss: 0.0257, d_svhn_loss: 0.0160, d_fake_loss: 0.0334, g_loss: 0.8561\n",
            "Step [41380/60000], d_real_loss: 0.0598, d_mnist_loss: 0.0153, d_svhn_loss: 0.0445, d_fake_loss: 0.0186, g_loss: 1.1192\n",
            "Step [41390/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0046, d_svhn_loss: 0.0260, d_fake_loss: 0.0240, g_loss: 1.1672\n",
            "Step [41400/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0192, d_svhn_loss: 0.0165, d_fake_loss: 0.0245, g_loss: 1.1426\n",
            "Step [41410/60000], d_real_loss: 0.0422, d_mnist_loss: 0.0139, d_svhn_loss: 0.0283, d_fake_loss: 0.0224, g_loss: 1.3421\n",
            "Step [41420/60000], d_real_loss: 0.0468, d_mnist_loss: 0.0094, d_svhn_loss: 0.0373, d_fake_loss: 0.0268, g_loss: 1.1611\n",
            "Step [41430/60000], d_real_loss: 0.0465, d_mnist_loss: 0.0275, d_svhn_loss: 0.0189, d_fake_loss: 0.0231, g_loss: 1.0593\n",
            "Step [41440/60000], d_real_loss: 0.0501, d_mnist_loss: 0.0073, d_svhn_loss: 0.0428, d_fake_loss: 0.0478, g_loss: 1.1409\n",
            "Step [41450/60000], d_real_loss: 0.0333, d_mnist_loss: 0.0172, d_svhn_loss: 0.0161, d_fake_loss: 0.0221, g_loss: 1.1038\n",
            "Step [41460/60000], d_real_loss: 0.0542, d_mnist_loss: 0.0080, d_svhn_loss: 0.0462, d_fake_loss: 0.0208, g_loss: 1.2159\n",
            "Step [41470/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0096, d_svhn_loss: 0.0286, d_fake_loss: 0.0147, g_loss: 1.0630\n",
            "Step [41480/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0124, d_svhn_loss: 0.0195, d_fake_loss: 0.1081, g_loss: 1.2824\n",
            "Step [41490/60000], d_real_loss: 0.0979, d_mnist_loss: 0.0352, d_svhn_loss: 0.0627, d_fake_loss: 0.0480, g_loss: 1.3696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [41500/60000], d_real_loss: 0.0707, d_mnist_loss: 0.0144, d_svhn_loss: 0.0564, d_fake_loss: 0.0672, g_loss: 1.1894\n",
            "saved ./samples_fashion/sample-41500-m-s.png\n",
            "saved ./samples_fashion/sample-41500-s-m.png\n",
            "Step [41510/60000], d_real_loss: 0.1823, d_mnist_loss: 0.1681, d_svhn_loss: 0.0143, d_fake_loss: 0.1575, g_loss: 1.1600\n",
            "Step [41520/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0226, d_svhn_loss: 0.0361, d_fake_loss: 0.0954, g_loss: 1.0107\n",
            "Step [41530/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0182, d_svhn_loss: 0.0164, d_fake_loss: 0.0378, g_loss: 1.2605\n",
            "Step [41540/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0147, d_svhn_loss: 0.0247, d_fake_loss: 0.1862, g_loss: 1.0710\n",
            "Step [41550/60000], d_real_loss: 0.0860, d_mnist_loss: 0.0099, d_svhn_loss: 0.0761, d_fake_loss: 0.0326, g_loss: 1.0608\n",
            "Step [41560/60000], d_real_loss: 0.0824, d_mnist_loss: 0.0094, d_svhn_loss: 0.0730, d_fake_loss: 0.0860, g_loss: 1.0833\n",
            "Step [41570/60000], d_real_loss: 0.0527, d_mnist_loss: 0.0319, d_svhn_loss: 0.0208, d_fake_loss: 0.0214, g_loss: 1.1313\n",
            "Step [41580/60000], d_real_loss: 0.0567, d_mnist_loss: 0.0074, d_svhn_loss: 0.0493, d_fake_loss: 0.0931, g_loss: 1.2717\n",
            "Step [41590/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0202, d_svhn_loss: 0.0198, d_fake_loss: 0.0530, g_loss: 1.1491\n",
            "Step [41600/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0191, d_svhn_loss: 0.0171, d_fake_loss: 0.0301, g_loss: 0.9634\n",
            "Step [41610/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0089, d_svhn_loss: 0.0263, d_fake_loss: 0.0414, g_loss: 1.3448\n",
            "Step [41620/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0198, d_svhn_loss: 0.0176, d_fake_loss: 0.0271, g_loss: 0.9942\n",
            "Step [41630/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0121, d_svhn_loss: 0.0191, d_fake_loss: 0.0423, g_loss: 1.0729\n",
            "Step [41640/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0253, d_svhn_loss: 0.0223, d_fake_loss: 0.0458, g_loss: 1.0803\n",
            "Step [41650/60000], d_real_loss: 0.0386, d_mnist_loss: 0.0195, d_svhn_loss: 0.0191, d_fake_loss: 0.0310, g_loss: 1.1740\n",
            "Step [41660/60000], d_real_loss: 0.0877, d_mnist_loss: 0.0087, d_svhn_loss: 0.0790, d_fake_loss: 0.0597, g_loss: 0.9952\n",
            "Step [41670/60000], d_real_loss: 0.0412, d_mnist_loss: 0.0102, d_svhn_loss: 0.0310, d_fake_loss: 0.0323, g_loss: 1.2515\n",
            "Step [41680/60000], d_real_loss: 0.0251, d_mnist_loss: 0.0066, d_svhn_loss: 0.0185, d_fake_loss: 0.0235, g_loss: 1.0958\n",
            "Step [41690/60000], d_real_loss: 0.0615, d_mnist_loss: 0.0175, d_svhn_loss: 0.0440, d_fake_loss: 0.0322, g_loss: 0.9993\n",
            "Step [41700/60000], d_real_loss: 0.0895, d_mnist_loss: 0.0215, d_svhn_loss: 0.0681, d_fake_loss: 0.0402, g_loss: 0.9559\n",
            "Step [41710/60000], d_real_loss: 0.0458, d_mnist_loss: 0.0099, d_svhn_loss: 0.0359, d_fake_loss: 0.0242, g_loss: 1.0330\n",
            "Step [41720/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0093, d_svhn_loss: 0.0145, d_fake_loss: 0.0294, g_loss: 1.0679\n",
            "Step [41730/60000], d_real_loss: 0.1114, d_mnist_loss: 0.0114, d_svhn_loss: 0.0999, d_fake_loss: 0.0237, g_loss: 1.0794\n",
            "Step [41740/60000], d_real_loss: 0.0687, d_mnist_loss: 0.0131, d_svhn_loss: 0.0556, d_fake_loss: 0.0301, g_loss: 1.0189\n",
            "Step [41750/60000], d_real_loss: 0.0473, d_mnist_loss: 0.0260, d_svhn_loss: 0.0213, d_fake_loss: 0.0121, g_loss: 1.0808\n",
            "Step [41760/60000], d_real_loss: 0.0456, d_mnist_loss: 0.0195, d_svhn_loss: 0.0261, d_fake_loss: 0.0573, g_loss: 0.8306\n",
            "Step [41770/60000], d_real_loss: 0.0627, d_mnist_loss: 0.0219, d_svhn_loss: 0.0407, d_fake_loss: 0.0328, g_loss: 1.1050\n",
            "Step [41780/60000], d_real_loss: 0.0207, d_mnist_loss: 0.0059, d_svhn_loss: 0.0149, d_fake_loss: 0.0273, g_loss: 1.0146\n",
            "Step [41790/60000], d_real_loss: 0.0628, d_mnist_loss: 0.0094, d_svhn_loss: 0.0534, d_fake_loss: 0.0877, g_loss: 1.0991\n",
            "Step [41800/60000], d_real_loss: 0.0354, d_mnist_loss: 0.0139, d_svhn_loss: 0.0215, d_fake_loss: 0.0184, g_loss: 1.1100\n",
            "Step [41810/60000], d_real_loss: 0.0502, d_mnist_loss: 0.0148, d_svhn_loss: 0.0354, d_fake_loss: 0.0186, g_loss: 1.1181\n",
            "Step [41820/60000], d_real_loss: 0.0778, d_mnist_loss: 0.0308, d_svhn_loss: 0.0470, d_fake_loss: 0.0441, g_loss: 1.1536\n",
            "Step [41830/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0263, d_svhn_loss: 0.0211, d_fake_loss: 0.0293, g_loss: 1.4150\n",
            "Step [41840/60000], d_real_loss: 0.0576, d_mnist_loss: 0.0104, d_svhn_loss: 0.0472, d_fake_loss: 0.0315, g_loss: 1.0427\n",
            "Step [41850/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0200, d_svhn_loss: 0.0141, d_fake_loss: 0.0296, g_loss: 1.2472\n",
            "Step [41860/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0156, d_svhn_loss: 0.0220, d_fake_loss: 0.0304, g_loss: 0.9594\n",
            "Step [41870/60000], d_real_loss: 0.0766, d_mnist_loss: 0.0096, d_svhn_loss: 0.0670, d_fake_loss: 0.0243, g_loss: 1.1497\n",
            "Step [41880/60000], d_real_loss: 0.0307, d_mnist_loss: 0.0119, d_svhn_loss: 0.0188, d_fake_loss: 0.1182, g_loss: 1.2214\n",
            "Step [41890/60000], d_real_loss: 0.0406, d_mnist_loss: 0.0120, d_svhn_loss: 0.0286, d_fake_loss: 0.0170, g_loss: 1.0355\n",
            "Step [41900/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0158, d_svhn_loss: 0.0241, d_fake_loss: 0.0351, g_loss: 1.0876\n",
            "Step [41910/60000], d_real_loss: 0.0275, d_mnist_loss: 0.0083, d_svhn_loss: 0.0192, d_fake_loss: 0.0504, g_loss: 1.0814\n",
            "Step [41920/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0236, d_svhn_loss: 0.0240, d_fake_loss: 0.0331, g_loss: 1.2070\n",
            "Step [41930/60000], d_real_loss: 0.0273, d_mnist_loss: 0.0065, d_svhn_loss: 0.0208, d_fake_loss: 0.0194, g_loss: 1.0514\n",
            "Step [41940/60000], d_real_loss: 0.0836, d_mnist_loss: 0.0101, d_svhn_loss: 0.0735, d_fake_loss: 0.1289, g_loss: 1.1001\n",
            "Step [41950/60000], d_real_loss: 0.0409, d_mnist_loss: 0.0075, d_svhn_loss: 0.0334, d_fake_loss: 0.0445, g_loss: 1.2399\n",
            "Step [41960/60000], d_real_loss: 0.0574, d_mnist_loss: 0.0108, d_svhn_loss: 0.0466, d_fake_loss: 0.0410, g_loss: 1.1619\n",
            "Step [41970/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0096, d_svhn_loss: 0.0183, d_fake_loss: 0.0338, g_loss: 0.9706\n",
            "Step [41980/60000], d_real_loss: 0.0897, d_mnist_loss: 0.0368, d_svhn_loss: 0.0529, d_fake_loss: 0.1980, g_loss: 0.9177\n",
            "Step [41990/60000], d_real_loss: 0.1507, d_mnist_loss: 0.0521, d_svhn_loss: 0.0986, d_fake_loss: 0.0399, g_loss: 1.2006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [42000/60000], d_real_loss: 0.0903, d_mnist_loss: 0.0305, d_svhn_loss: 0.0599, d_fake_loss: 0.0585, g_loss: 1.3784\n",
            "saved ./samples_fashion/sample-42000-m-s.png\n",
            "saved ./samples_fashion/sample-42000-s-m.png\n",
            "Step [42010/60000], d_real_loss: 0.0909, d_mnist_loss: 0.0345, d_svhn_loss: 0.0564, d_fake_loss: 0.1846, g_loss: 1.5292\n",
            "Step [42020/60000], d_real_loss: 0.0524, d_mnist_loss: 0.0385, d_svhn_loss: 0.0138, d_fake_loss: 0.1099, g_loss: 1.3311\n",
            "Step [42030/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0078, d_svhn_loss: 0.0257, d_fake_loss: 0.0279, g_loss: 1.1632\n",
            "Step [42040/60000], d_real_loss: 0.1114, d_mnist_loss: 0.0294, d_svhn_loss: 0.0820, d_fake_loss: 0.0402, g_loss: 1.2026\n",
            "Step [42050/60000], d_real_loss: 0.0566, d_mnist_loss: 0.0140, d_svhn_loss: 0.0426, d_fake_loss: 0.0291, g_loss: 1.1429\n",
            "Step [42060/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0106, d_svhn_loss: 0.0242, d_fake_loss: 0.0315, g_loss: 1.0434\n",
            "Step [42070/60000], d_real_loss: 0.0537, d_mnist_loss: 0.0107, d_svhn_loss: 0.0430, d_fake_loss: 0.0650, g_loss: 1.1348\n",
            "Step [42080/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0123, d_svhn_loss: 0.0309, d_fake_loss: 0.0442, g_loss: 1.3515\n",
            "Step [42090/60000], d_real_loss: 0.0634, d_mnist_loss: 0.0245, d_svhn_loss: 0.0389, d_fake_loss: 0.0304, g_loss: 1.1065\n",
            "Step [42100/60000], d_real_loss: 0.1019, d_mnist_loss: 0.0177, d_svhn_loss: 0.0842, d_fake_loss: 0.0248, g_loss: 1.0740\n",
            "Step [42110/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0140, d_svhn_loss: 0.0258, d_fake_loss: 0.0156, g_loss: 1.1324\n",
            "Step [42120/60000], d_real_loss: 0.0750, d_mnist_loss: 0.0499, d_svhn_loss: 0.0251, d_fake_loss: 0.0583, g_loss: 0.9792\n",
            "Step [42130/60000], d_real_loss: 0.1156, d_mnist_loss: 0.0095, d_svhn_loss: 0.1062, d_fake_loss: 0.0278, g_loss: 1.0435\n",
            "Step [42140/60000], d_real_loss: 0.0775, d_mnist_loss: 0.0071, d_svhn_loss: 0.0704, d_fake_loss: 0.0417, g_loss: 1.0973\n",
            "Step [42150/60000], d_real_loss: 0.1951, d_mnist_loss: 0.1821, d_svhn_loss: 0.0130, d_fake_loss: 0.0392, g_loss: 1.0933\n",
            "Step [42160/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0154, d_svhn_loss: 0.0192, d_fake_loss: 0.0318, g_loss: 1.0826\n",
            "Step [42170/60000], d_real_loss: 0.0537, d_mnist_loss: 0.0325, d_svhn_loss: 0.0212, d_fake_loss: 0.0863, g_loss: 1.0481\n",
            "Step [42180/60000], d_real_loss: 0.0632, d_mnist_loss: 0.0078, d_svhn_loss: 0.0554, d_fake_loss: 0.0446, g_loss: 1.0421\n",
            "Step [42190/60000], d_real_loss: 0.0469, d_mnist_loss: 0.0089, d_svhn_loss: 0.0380, d_fake_loss: 0.1163, g_loss: 1.2485\n",
            "Step [42200/60000], d_real_loss: 0.0659, d_mnist_loss: 0.0490, d_svhn_loss: 0.0168, d_fake_loss: 0.0759, g_loss: 1.1121\n",
            "Step [42210/60000], d_real_loss: 0.0725, d_mnist_loss: 0.0302, d_svhn_loss: 0.0423, d_fake_loss: 0.0505, g_loss: 1.2245\n",
            "Step [42220/60000], d_real_loss: 0.0206, d_mnist_loss: 0.0063, d_svhn_loss: 0.0143, d_fake_loss: 0.0192, g_loss: 1.0877\n",
            "Step [42230/60000], d_real_loss: 0.0480, d_mnist_loss: 0.0096, d_svhn_loss: 0.0384, d_fake_loss: 0.0509, g_loss: 1.0236\n",
            "Step [42240/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0104, d_svhn_loss: 0.0379, d_fake_loss: 0.0850, g_loss: 0.9789\n",
            "Step [42250/60000], d_real_loss: 0.0575, d_mnist_loss: 0.0169, d_svhn_loss: 0.0406, d_fake_loss: 0.0911, g_loss: 1.2745\n",
            "Step [42260/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0407, d_svhn_loss: 0.0245, d_fake_loss: 0.0679, g_loss: 1.2559\n",
            "Step [42270/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0102, d_svhn_loss: 0.0244, d_fake_loss: 0.0537, g_loss: 1.0013\n",
            "Step [42280/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0124, d_svhn_loss: 0.0169, d_fake_loss: 0.0182, g_loss: 1.0625\n",
            "Step [42290/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0121, d_svhn_loss: 0.0195, d_fake_loss: 0.0741, g_loss: 1.2087\n",
            "Step [42300/60000], d_real_loss: 0.0719, d_mnist_loss: 0.0251, d_svhn_loss: 0.0468, d_fake_loss: 0.0525, g_loss: 1.2717\n",
            "Step [42310/60000], d_real_loss: 0.0394, d_mnist_loss: 0.0115, d_svhn_loss: 0.0279, d_fake_loss: 0.0654, g_loss: 1.3399\n",
            "Step [42320/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0071, d_svhn_loss: 0.0347, d_fake_loss: 0.0243, g_loss: 1.0259\n",
            "Step [42330/60000], d_real_loss: 0.0757, d_mnist_loss: 0.0113, d_svhn_loss: 0.0645, d_fake_loss: 0.0172, g_loss: 1.1009\n",
            "Step [42340/60000], d_real_loss: 0.1124, d_mnist_loss: 0.0250, d_svhn_loss: 0.0875, d_fake_loss: 0.0220, g_loss: 1.1314\n",
            "Step [42350/60000], d_real_loss: 0.0664, d_mnist_loss: 0.0323, d_svhn_loss: 0.0341, d_fake_loss: 0.0217, g_loss: 1.1177\n",
            "Step [42360/60000], d_real_loss: 0.0259, d_mnist_loss: 0.0069, d_svhn_loss: 0.0191, d_fake_loss: 0.0333, g_loss: 1.0810\n",
            "Step [42370/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0080, d_svhn_loss: 0.0190, d_fake_loss: 0.0403, g_loss: 1.1774\n",
            "Step [42380/60000], d_real_loss: 0.0571, d_mnist_loss: 0.0246, d_svhn_loss: 0.0326, d_fake_loss: 0.0465, g_loss: 1.4893\n",
            "Step [42390/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0127, d_svhn_loss: 0.0277, d_fake_loss: 0.0418, g_loss: 1.1218\n",
            "Step [42400/60000], d_real_loss: 0.0557, d_mnist_loss: 0.0365, d_svhn_loss: 0.0192, d_fake_loss: 0.0279, g_loss: 1.1121\n",
            "Step [42410/60000], d_real_loss: 0.0250, d_mnist_loss: 0.0085, d_svhn_loss: 0.0166, d_fake_loss: 0.0165, g_loss: 1.0866\n",
            "Step [42420/60000], d_real_loss: 0.0343, d_mnist_loss: 0.0083, d_svhn_loss: 0.0260, d_fake_loss: 0.0653, g_loss: 0.9288\n",
            "Step [42430/60000], d_real_loss: 0.0980, d_mnist_loss: 0.0058, d_svhn_loss: 0.0922, d_fake_loss: 0.0246, g_loss: 1.1274\n",
            "Step [42440/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0173, d_svhn_loss: 0.0189, d_fake_loss: 0.0342, g_loss: 1.2633\n",
            "Step [42450/60000], d_real_loss: 0.0980, d_mnist_loss: 0.0454, d_svhn_loss: 0.0526, d_fake_loss: 0.0563, g_loss: 1.2221\n",
            "Step [42460/60000], d_real_loss: 0.0534, d_mnist_loss: 0.0107, d_svhn_loss: 0.0427, d_fake_loss: 0.0639, g_loss: 1.2321\n",
            "Step [42470/60000], d_real_loss: 0.0642, d_mnist_loss: 0.0160, d_svhn_loss: 0.0482, d_fake_loss: 0.0464, g_loss: 1.1846\n",
            "Step [42480/60000], d_real_loss: 0.1143, d_mnist_loss: 0.0206, d_svhn_loss: 0.0937, d_fake_loss: 0.0663, g_loss: 1.2850\n",
            "Step [42490/60000], d_real_loss: 0.0549, d_mnist_loss: 0.0153, d_svhn_loss: 0.0396, d_fake_loss: 0.0284, g_loss: 1.0746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999966621398926, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [42500/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0145, d_svhn_loss: 0.0330, d_fake_loss: 0.0329, g_loss: 1.1641\n",
            "saved ./samples_fashion/sample-42500-m-s.png\n",
            "saved ./samples_fashion/sample-42500-s-m.png\n",
            "Step [42510/60000], d_real_loss: 0.0515, d_mnist_loss: 0.0318, d_svhn_loss: 0.0197, d_fake_loss: 0.0535, g_loss: 1.1211\n",
            "Step [42520/60000], d_real_loss: 0.0288, d_mnist_loss: 0.0164, d_svhn_loss: 0.0125, d_fake_loss: 0.0180, g_loss: 1.1448\n",
            "Step [42530/60000], d_real_loss: 0.0269, d_mnist_loss: 0.0105, d_svhn_loss: 0.0163, d_fake_loss: 0.0422, g_loss: 1.3952\n",
            "Step [42540/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0178, d_svhn_loss: 0.0221, d_fake_loss: 0.0563, g_loss: 0.7960\n",
            "Step [42550/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0159, d_svhn_loss: 0.0217, d_fake_loss: 0.0629, g_loss: 1.1138\n",
            "Step [42560/60000], d_real_loss: 0.1649, d_mnist_loss: 0.0135, d_svhn_loss: 0.1515, d_fake_loss: 0.0520, g_loss: 1.1590\n",
            "Step [42570/60000], d_real_loss: 0.0267, d_mnist_loss: 0.0107, d_svhn_loss: 0.0160, d_fake_loss: 0.0555, g_loss: 1.1105\n",
            "Step [42580/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0150, d_svhn_loss: 0.0202, d_fake_loss: 0.0323, g_loss: 1.1316\n",
            "Step [42590/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0140, d_svhn_loss: 0.0389, d_fake_loss: 0.0350, g_loss: 1.1224\n",
            "Step [42600/60000], d_real_loss: 0.0261, d_mnist_loss: 0.0057, d_svhn_loss: 0.0204, d_fake_loss: 0.0372, g_loss: 1.1827\n",
            "Step [42610/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0192, d_svhn_loss: 0.0262, d_fake_loss: 0.0530, g_loss: 1.2346\n",
            "Step [42620/60000], d_real_loss: 0.0287, d_mnist_loss: 0.0108, d_svhn_loss: 0.0179, d_fake_loss: 0.1608, g_loss: 0.9645\n",
            "Step [42630/60000], d_real_loss: 0.0296, d_mnist_loss: 0.0070, d_svhn_loss: 0.0226, d_fake_loss: 0.0381, g_loss: 1.2868\n",
            "Step [42640/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0088, d_svhn_loss: 0.0352, d_fake_loss: 0.1149, g_loss: 1.4444\n",
            "Step [42650/60000], d_real_loss: 0.0260, d_mnist_loss: 0.0088, d_svhn_loss: 0.0172, d_fake_loss: 0.0195, g_loss: 1.1744\n",
            "Step [42660/60000], d_real_loss: 0.0275, d_mnist_loss: 0.0072, d_svhn_loss: 0.0203, d_fake_loss: 0.0298, g_loss: 1.1032\n",
            "Step [42670/60000], d_real_loss: 0.0225, d_mnist_loss: 0.0073, d_svhn_loss: 0.0152, d_fake_loss: 0.0230, g_loss: 1.2506\n",
            "Step [42680/60000], d_real_loss: 0.2167, d_mnist_loss: 0.0087, d_svhn_loss: 0.2080, d_fake_loss: 0.1615, g_loss: 1.1056\n",
            "Step [42690/60000], d_real_loss: 0.0274, d_mnist_loss: 0.0068, d_svhn_loss: 0.0206, d_fake_loss: 0.0249, g_loss: 1.1233\n",
            "Step [42700/60000], d_real_loss: 0.0667, d_mnist_loss: 0.0324, d_svhn_loss: 0.0343, d_fake_loss: 0.0813, g_loss: 1.2734\n",
            "Step [42710/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0208, d_svhn_loss: 0.0160, d_fake_loss: 0.0280, g_loss: 1.1449\n",
            "Step [42720/60000], d_real_loss: 0.0561, d_mnist_loss: 0.0107, d_svhn_loss: 0.0454, d_fake_loss: 0.1051, g_loss: 0.9084\n",
            "Step [42730/60000], d_real_loss: 0.0390, d_mnist_loss: 0.0072, d_svhn_loss: 0.0319, d_fake_loss: 0.0380, g_loss: 1.2254\n",
            "Step [42740/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0129, d_svhn_loss: 0.0266, d_fake_loss: 0.0509, g_loss: 1.0220\n",
            "Step [42750/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0091, d_svhn_loss: 0.0324, d_fake_loss: 0.0973, g_loss: 0.9958\n",
            "Step [42760/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0070, d_svhn_loss: 0.0310, d_fake_loss: 0.0426, g_loss: 1.1703\n",
            "Step [42770/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0120, d_svhn_loss: 0.0128, d_fake_loss: 0.0389, g_loss: 1.1070\n",
            "Step [42780/60000], d_real_loss: 0.0656, d_mnist_loss: 0.0066, d_svhn_loss: 0.0590, d_fake_loss: 0.0768, g_loss: 1.1137\n",
            "Step [42790/60000], d_real_loss: 0.0732, d_mnist_loss: 0.0092, d_svhn_loss: 0.0640, d_fake_loss: 0.0277, g_loss: 1.0949\n",
            "Step [42800/60000], d_real_loss: 0.1029, d_mnist_loss: 0.0330, d_svhn_loss: 0.0699, d_fake_loss: 0.0360, g_loss: 1.0892\n",
            "Step [42810/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0080, d_svhn_loss: 0.0231, d_fake_loss: 0.0571, g_loss: 1.0440\n",
            "Step [42820/60000], d_real_loss: 0.1310, d_mnist_loss: 0.0695, d_svhn_loss: 0.0615, d_fake_loss: 0.0250, g_loss: 1.2508\n",
            "Step [42830/60000], d_real_loss: 0.0571, d_mnist_loss: 0.0103, d_svhn_loss: 0.0468, d_fake_loss: 0.0409, g_loss: 1.1978\n",
            "Step [42840/60000], d_real_loss: 0.0760, d_mnist_loss: 0.0304, d_svhn_loss: 0.0456, d_fake_loss: 0.0770, g_loss: 1.5960\n",
            "Step [42850/60000], d_real_loss: 0.1311, d_mnist_loss: 0.1024, d_svhn_loss: 0.0287, d_fake_loss: 0.0691, g_loss: 1.1447\n",
            "Step [42860/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0210, d_svhn_loss: 0.0163, d_fake_loss: 0.0309, g_loss: 1.1464\n",
            "Step [42870/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0075, d_svhn_loss: 0.0165, d_fake_loss: 0.1483, g_loss: 1.1826\n",
            "Step [42880/60000], d_real_loss: 0.0228, d_mnist_loss: 0.0085, d_svhn_loss: 0.0143, d_fake_loss: 0.0580, g_loss: 1.1712\n",
            "Step [42890/60000], d_real_loss: 0.0228, d_mnist_loss: 0.0066, d_svhn_loss: 0.0162, d_fake_loss: 0.0186, g_loss: 1.0483\n",
            "Step [42900/60000], d_real_loss: 0.0558, d_mnist_loss: 0.0365, d_svhn_loss: 0.0193, d_fake_loss: 0.0295, g_loss: 1.1937\n",
            "Step [42910/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0149, d_svhn_loss: 0.0246, d_fake_loss: 0.0386, g_loss: 1.2505\n",
            "Step [42920/60000], d_real_loss: 0.0720, d_mnist_loss: 0.0083, d_svhn_loss: 0.0636, d_fake_loss: 0.0316, g_loss: 1.0798\n",
            "Step [42930/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0086, d_svhn_loss: 0.0283, d_fake_loss: 0.0213, g_loss: 1.1037\n",
            "Step [42940/60000], d_real_loss: 0.0627, d_mnist_loss: 0.0134, d_svhn_loss: 0.0493, d_fake_loss: 0.0683, g_loss: 1.1295\n",
            "Step [42950/60000], d_real_loss: 0.0876, d_mnist_loss: 0.0611, d_svhn_loss: 0.0265, d_fake_loss: 0.0490, g_loss: 1.2803\n",
            "Step [42960/60000], d_real_loss: 0.0219, d_mnist_loss: 0.0103, d_svhn_loss: 0.0116, d_fake_loss: 0.0599, g_loss: 1.2828\n",
            "Step [42970/60000], d_real_loss: 0.0283, d_mnist_loss: 0.0097, d_svhn_loss: 0.0186, d_fake_loss: 0.0302, g_loss: 1.0524\n",
            "Step [42980/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0066, d_svhn_loss: 0.0237, d_fake_loss: 0.0207, g_loss: 1.0935\n",
            "Step [42990/60000], d_real_loss: 0.0366, d_mnist_loss: 0.0155, d_svhn_loss: 0.0212, d_fake_loss: 0.1058, g_loss: 1.2493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [43000/60000], d_real_loss: 0.0871, d_mnist_loss: 0.0110, d_svhn_loss: 0.0761, d_fake_loss: 0.0481, g_loss: 1.2773\n",
            "saved ./samples_fashion/sample-43000-m-s.png\n",
            "saved ./samples_fashion/sample-43000-s-m.png\n",
            "Step [43010/60000], d_real_loss: 0.0731, d_mnist_loss: 0.0376, d_svhn_loss: 0.0356, d_fake_loss: 0.0247, g_loss: 1.0660\n",
            "Step [43020/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0189, d_svhn_loss: 0.0156, d_fake_loss: 0.0485, g_loss: 0.9969\n",
            "Step [43030/60000], d_real_loss: 0.0300, d_mnist_loss: 0.0047, d_svhn_loss: 0.0253, d_fake_loss: 0.0433, g_loss: 1.0024\n",
            "Step [43040/60000], d_real_loss: 0.0214, d_mnist_loss: 0.0084, d_svhn_loss: 0.0130, d_fake_loss: 0.0669, g_loss: 1.2132\n",
            "Step [43050/60000], d_real_loss: 0.0409, d_mnist_loss: 0.0212, d_svhn_loss: 0.0197, d_fake_loss: 0.0668, g_loss: 1.0096\n",
            "Step [43060/60000], d_real_loss: 0.0560, d_mnist_loss: 0.0081, d_svhn_loss: 0.0479, d_fake_loss: 0.0617, g_loss: 1.1579\n",
            "Step [43070/60000], d_real_loss: 0.0269, d_mnist_loss: 0.0102, d_svhn_loss: 0.0167, d_fake_loss: 0.0382, g_loss: 1.1136\n",
            "Step [43080/60000], d_real_loss: 0.0380, d_mnist_loss: 0.0084, d_svhn_loss: 0.0296, d_fake_loss: 0.0412, g_loss: 1.1820\n",
            "Step [43090/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0105, d_svhn_loss: 0.0196, d_fake_loss: 0.0404, g_loss: 1.1133\n",
            "Step [43100/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0125, d_svhn_loss: 0.0183, d_fake_loss: 0.0234, g_loss: 1.3008\n",
            "Step [43110/60000], d_real_loss: 0.0320, d_mnist_loss: 0.0112, d_svhn_loss: 0.0208, d_fake_loss: 0.0836, g_loss: 1.2713\n",
            "Step [43120/60000], d_real_loss: 0.0740, d_mnist_loss: 0.0093, d_svhn_loss: 0.0647, d_fake_loss: 0.0515, g_loss: 1.1362\n",
            "Step [43130/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0192, d_svhn_loss: 0.0165, d_fake_loss: 0.0212, g_loss: 1.1392\n",
            "Step [43140/60000], d_real_loss: 0.0246, d_mnist_loss: 0.0092, d_svhn_loss: 0.0153, d_fake_loss: 0.0688, g_loss: 1.3166\n",
            "Step [43150/60000], d_real_loss: 0.0529, d_mnist_loss: 0.0251, d_svhn_loss: 0.0278, d_fake_loss: 0.0232, g_loss: 1.1496\n",
            "Step [43160/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0153, d_svhn_loss: 0.0148, d_fake_loss: 0.0808, g_loss: 1.4435\n",
            "Step [43170/60000], d_real_loss: 0.0749, d_mnist_loss: 0.0127, d_svhn_loss: 0.0622, d_fake_loss: 0.0379, g_loss: 1.0897\n",
            "Step [43180/60000], d_real_loss: 0.0325, d_mnist_loss: 0.0184, d_svhn_loss: 0.0141, d_fake_loss: 0.0194, g_loss: 1.1271\n",
            "Step [43190/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0092, d_svhn_loss: 0.0383, d_fake_loss: 0.0198, g_loss: 1.0916\n",
            "Step [43200/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0104, d_svhn_loss: 0.0561, d_fake_loss: 0.1205, g_loss: 0.8805\n",
            "Step [43210/60000], d_real_loss: 0.0693, d_mnist_loss: 0.0519, d_svhn_loss: 0.0174, d_fake_loss: 0.0189, g_loss: 1.2068\n",
            "Step [43220/60000], d_real_loss: 0.0604, d_mnist_loss: 0.0138, d_svhn_loss: 0.0466, d_fake_loss: 0.1034, g_loss: 1.1079\n",
            "Step [43230/60000], d_real_loss: 0.0497, d_mnist_loss: 0.0274, d_svhn_loss: 0.0223, d_fake_loss: 0.0319, g_loss: 1.1026\n",
            "Step [43240/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0145, d_svhn_loss: 0.0247, d_fake_loss: 0.0259, g_loss: 1.0266\n",
            "Step [43250/60000], d_real_loss: 0.0765, d_mnist_loss: 0.0452, d_svhn_loss: 0.0313, d_fake_loss: 0.0440, g_loss: 1.1605\n",
            "Step [43260/60000], d_real_loss: 0.0615, d_mnist_loss: 0.0284, d_svhn_loss: 0.0331, d_fake_loss: 0.0997, g_loss: 1.0722\n",
            "Step [43270/60000], d_real_loss: 0.0225, d_mnist_loss: 0.0077, d_svhn_loss: 0.0149, d_fake_loss: 0.0418, g_loss: 0.9811\n",
            "Step [43280/60000], d_real_loss: 0.0600, d_mnist_loss: 0.0093, d_svhn_loss: 0.0507, d_fake_loss: 0.0222, g_loss: 1.0216\n",
            "Step [43290/60000], d_real_loss: 0.0278, d_mnist_loss: 0.0107, d_svhn_loss: 0.0172, d_fake_loss: 0.3439, g_loss: 1.5406\n",
            "Step [43300/60000], d_real_loss: 0.0286, d_mnist_loss: 0.0127, d_svhn_loss: 0.0158, d_fake_loss: 0.0239, g_loss: 0.9987\n",
            "Step [43310/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0077, d_svhn_loss: 0.0561, d_fake_loss: 0.1330, g_loss: 1.0525\n",
            "Step [43320/60000], d_real_loss: 0.0631, d_mnist_loss: 0.0434, d_svhn_loss: 0.0197, d_fake_loss: 0.0499, g_loss: 1.2860\n",
            "Step [43330/60000], d_real_loss: 0.0926, d_mnist_loss: 0.0185, d_svhn_loss: 0.0741, d_fake_loss: 0.0358, g_loss: 1.2830\n",
            "Step [43340/60000], d_real_loss: 0.0920, d_mnist_loss: 0.0281, d_svhn_loss: 0.0639, d_fake_loss: 0.0352, g_loss: 0.9230\n",
            "Step [43350/60000], d_real_loss: 0.0254, d_mnist_loss: 0.0083, d_svhn_loss: 0.0171, d_fake_loss: 0.0235, g_loss: 1.0816\n",
            "Step [43360/60000], d_real_loss: 0.0646, d_mnist_loss: 0.0071, d_svhn_loss: 0.0575, d_fake_loss: 0.0600, g_loss: 1.0718\n",
            "Step [43370/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0086, d_svhn_loss: 0.0176, d_fake_loss: 0.1207, g_loss: 1.2706\n",
            "Step [43380/60000], d_real_loss: 0.0897, d_mnist_loss: 0.0554, d_svhn_loss: 0.0344, d_fake_loss: 0.0230, g_loss: 1.2586\n",
            "Step [43390/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0109, d_svhn_loss: 0.0255, d_fake_loss: 0.0262, g_loss: 1.0127\n",
            "Step [43400/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0152, d_svhn_loss: 0.0249, d_fake_loss: 0.0386, g_loss: 1.1082\n",
            "Step [43410/60000], d_real_loss: 0.0302, d_mnist_loss: 0.0090, d_svhn_loss: 0.0212, d_fake_loss: 0.0444, g_loss: 1.1227\n",
            "Step [43420/60000], d_real_loss: 0.0426, d_mnist_loss: 0.0248, d_svhn_loss: 0.0178, d_fake_loss: 0.1054, g_loss: 1.1222\n",
            "Step [43430/60000], d_real_loss: 0.0370, d_mnist_loss: 0.0113, d_svhn_loss: 0.0257, d_fake_loss: 0.0799, g_loss: 1.1154\n",
            "Step [43440/60000], d_real_loss: 0.0247, d_mnist_loss: 0.0059, d_svhn_loss: 0.0188, d_fake_loss: 0.0231, g_loss: 1.1288\n",
            "Step [43450/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0199, d_svhn_loss: 0.0148, d_fake_loss: 0.1320, g_loss: 1.0670\n",
            "Step [43460/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0186, d_svhn_loss: 0.0133, d_fake_loss: 0.0236, g_loss: 1.0860\n",
            "Step [43470/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0120, d_svhn_loss: 0.0226, d_fake_loss: 0.0347, g_loss: 1.0405\n",
            "Step [43480/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0105, d_svhn_loss: 0.0218, d_fake_loss: 0.0330, g_loss: 1.2319\n",
            "Step [43490/60000], d_real_loss: 0.0337, d_mnist_loss: 0.0159, d_svhn_loss: 0.0178, d_fake_loss: 0.2502, g_loss: 1.1452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [43500/60000], d_real_loss: 0.0754, d_mnist_loss: 0.0159, d_svhn_loss: 0.0594, d_fake_loss: 0.0302, g_loss: 1.2611\n",
            "saved ./samples_fashion/sample-43500-m-s.png\n",
            "saved ./samples_fashion/sample-43500-s-m.png\n",
            "Step [43510/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0097, d_svhn_loss: 0.0243, d_fake_loss: 0.0364, g_loss: 1.0684\n",
            "Step [43520/60000], d_real_loss: 0.0967, d_mnist_loss: 0.0102, d_svhn_loss: 0.0865, d_fake_loss: 0.0326, g_loss: 1.1016\n",
            "Step [43530/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0075, d_svhn_loss: 0.0400, d_fake_loss: 0.0326, g_loss: 1.1488\n",
            "Step [43540/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0113, d_svhn_loss: 0.0342, d_fake_loss: 0.0519, g_loss: 0.9933\n",
            "Step [43550/60000], d_real_loss: 0.0394, d_mnist_loss: 0.0296, d_svhn_loss: 0.0098, d_fake_loss: 0.0407, g_loss: 1.0733\n",
            "Step [43560/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0081, d_svhn_loss: 0.0227, d_fake_loss: 0.0489, g_loss: 1.3141\n",
            "Step [43570/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0200, d_svhn_loss: 0.0218, d_fake_loss: 0.0331, g_loss: 1.1909\n",
            "Step [43580/60000], d_real_loss: 0.0521, d_mnist_loss: 0.0247, d_svhn_loss: 0.0274, d_fake_loss: 0.0280, g_loss: 1.0782\n",
            "Step [43590/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0129, d_svhn_loss: 0.0247, d_fake_loss: 0.0919, g_loss: 1.1836\n",
            "Step [43600/60000], d_real_loss: 0.1034, d_mnist_loss: 0.0254, d_svhn_loss: 0.0780, d_fake_loss: 0.1111, g_loss: 1.2288\n",
            "Step [43610/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0086, d_svhn_loss: 0.0279, d_fake_loss: 0.0541, g_loss: 1.1715\n",
            "Step [43620/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0191, d_svhn_loss: 0.0182, d_fake_loss: 0.0573, g_loss: 1.1565\n",
            "Step [43630/60000], d_real_loss: 0.0888, d_mnist_loss: 0.0099, d_svhn_loss: 0.0789, d_fake_loss: 0.0408, g_loss: 1.0803\n",
            "Step [43640/60000], d_real_loss: 0.0977, d_mnist_loss: 0.0063, d_svhn_loss: 0.0914, d_fake_loss: 0.0377, g_loss: 1.2112\n",
            "Step [43650/60000], d_real_loss: 0.0555, d_mnist_loss: 0.0430, d_svhn_loss: 0.0126, d_fake_loss: 0.0692, g_loss: 1.1992\n",
            "Step [43660/60000], d_real_loss: 0.0718, d_mnist_loss: 0.0514, d_svhn_loss: 0.0204, d_fake_loss: 0.0892, g_loss: 1.1366\n",
            "Step [43670/60000], d_real_loss: 0.0604, d_mnist_loss: 0.0118, d_svhn_loss: 0.0487, d_fake_loss: 0.0503, g_loss: 1.2061\n",
            "Step [43680/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0080, d_svhn_loss: 0.0212, d_fake_loss: 0.0406, g_loss: 1.0851\n",
            "Step [43690/60000], d_real_loss: 0.0454, d_mnist_loss: 0.0215, d_svhn_loss: 0.0239, d_fake_loss: 0.0340, g_loss: 1.2413\n",
            "Step [43700/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0074, d_svhn_loss: 0.0518, d_fake_loss: 0.0477, g_loss: 1.1824\n",
            "Step [43710/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0121, d_svhn_loss: 0.0177, d_fake_loss: 0.0331, g_loss: 1.1040\n",
            "Step [43720/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0182, d_svhn_loss: 0.0353, d_fake_loss: 0.1019, g_loss: 1.1525\n",
            "Step [43730/60000], d_real_loss: 0.0293, d_mnist_loss: 0.0054, d_svhn_loss: 0.0239, d_fake_loss: 0.0289, g_loss: 1.0958\n",
            "Step [43740/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0132, d_svhn_loss: 0.0257, d_fake_loss: 0.0160, g_loss: 1.1904\n",
            "Step [43750/60000], d_real_loss: 0.0721, d_mnist_loss: 0.0393, d_svhn_loss: 0.0328, d_fake_loss: 0.0184, g_loss: 0.9492\n",
            "Step [43760/60000], d_real_loss: 0.0456, d_mnist_loss: 0.0108, d_svhn_loss: 0.0348, d_fake_loss: 0.0302, g_loss: 1.2541\n",
            "Step [43770/60000], d_real_loss: 0.0700, d_mnist_loss: 0.0159, d_svhn_loss: 0.0541, d_fake_loss: 0.1008, g_loss: 1.0605\n",
            "Step [43780/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0081, d_svhn_loss: 0.0222, d_fake_loss: 0.0403, g_loss: 1.2087\n",
            "Step [43790/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0158, d_svhn_loss: 0.0192, d_fake_loss: 0.0438, g_loss: 1.1809\n",
            "Step [43800/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0051, d_svhn_loss: 0.0313, d_fake_loss: 0.0529, g_loss: 0.9471\n",
            "Step [43810/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0139, d_svhn_loss: 0.0226, d_fake_loss: 0.1856, g_loss: 1.1384\n",
            "Step [43820/60000], d_real_loss: 0.0410, d_mnist_loss: 0.0147, d_svhn_loss: 0.0264, d_fake_loss: 0.0243, g_loss: 1.0531\n",
            "Step [43830/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0120, d_svhn_loss: 0.0215, d_fake_loss: 0.0388, g_loss: 1.1260\n",
            "Step [43840/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0187, d_svhn_loss: 0.0253, d_fake_loss: 0.0856, g_loss: 1.1554\n",
            "Step [43850/60000], d_real_loss: 0.0320, d_mnist_loss: 0.0130, d_svhn_loss: 0.0190, d_fake_loss: 0.0299, g_loss: 1.2567\n",
            "Step [43860/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0088, d_svhn_loss: 0.0216, d_fake_loss: 0.0444, g_loss: 1.1102\n",
            "Step [43870/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0136, d_svhn_loss: 0.0334, d_fake_loss: 0.0519, g_loss: 0.9759\n",
            "Step [43880/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0130, d_svhn_loss: 0.0232, d_fake_loss: 0.0321, g_loss: 1.0004\n",
            "Step [43890/60000], d_real_loss: 0.0423, d_mnist_loss: 0.0191, d_svhn_loss: 0.0232, d_fake_loss: 0.0553, g_loss: 1.1869\n",
            "Step [43900/60000], d_real_loss: 0.0371, d_mnist_loss: 0.0125, d_svhn_loss: 0.0246, d_fake_loss: 0.0940, g_loss: 1.0579\n",
            "Step [43910/60000], d_real_loss: 0.1169, d_mnist_loss: 0.0417, d_svhn_loss: 0.0752, d_fake_loss: 0.0497, g_loss: 1.0101\n",
            "Step [43920/60000], d_real_loss: 0.0715, d_mnist_loss: 0.0113, d_svhn_loss: 0.0602, d_fake_loss: 0.0661, g_loss: 1.0059\n",
            "Step [43930/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0117, d_svhn_loss: 0.0258, d_fake_loss: 0.0831, g_loss: 0.9372\n",
            "Step [43940/60000], d_real_loss: 0.0315, d_mnist_loss: 0.0121, d_svhn_loss: 0.0194, d_fake_loss: 0.0814, g_loss: 1.2936\n",
            "Step [43950/60000], d_real_loss: 0.0413, d_mnist_loss: 0.0091, d_svhn_loss: 0.0322, d_fake_loss: 0.0288, g_loss: 1.0388\n",
            "Step [43960/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0150, d_svhn_loss: 0.0157, d_fake_loss: 0.1097, g_loss: 1.0316\n",
            "Step [43970/60000], d_real_loss: 0.0824, d_mnist_loss: 0.0106, d_svhn_loss: 0.0717, d_fake_loss: 0.0284, g_loss: 1.1217\n",
            "Step [43980/60000], d_real_loss: 0.0762, d_mnist_loss: 0.0115, d_svhn_loss: 0.0647, d_fake_loss: 0.0438, g_loss: 1.1819\n",
            "Step [43990/60000], d_real_loss: 0.0515, d_mnist_loss: 0.0067, d_svhn_loss: 0.0448, d_fake_loss: 0.0838, g_loss: 1.0577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999961853027344, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [44000/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0084, d_svhn_loss: 0.0219, d_fake_loss: 0.0489, g_loss: 1.1318\n",
            "saved ./samples_fashion/sample-44000-m-s.png\n",
            "saved ./samples_fashion/sample-44000-s-m.png\n",
            "Step [44010/60000], d_real_loss: 0.0667, d_mnist_loss: 0.0082, d_svhn_loss: 0.0585, d_fake_loss: 0.0863, g_loss: 1.1794\n",
            "Step [44020/60000], d_real_loss: 0.0296, d_mnist_loss: 0.0098, d_svhn_loss: 0.0198, d_fake_loss: 0.0604, g_loss: 1.0772\n",
            "Step [44030/60000], d_real_loss: 0.0491, d_mnist_loss: 0.0249, d_svhn_loss: 0.0242, d_fake_loss: 0.0260, g_loss: 1.2777\n",
            "Step [44040/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0167, d_svhn_loss: 0.0368, d_fake_loss: 0.0839, g_loss: 1.2419\n",
            "Step [44050/60000], d_real_loss: 0.0568, d_mnist_loss: 0.0194, d_svhn_loss: 0.0374, d_fake_loss: 0.0361, g_loss: 1.1180\n",
            "Step [44060/60000], d_real_loss: 0.1060, d_mnist_loss: 0.0110, d_svhn_loss: 0.0950, d_fake_loss: 0.0310, g_loss: 1.2067\n",
            "Step [44070/60000], d_real_loss: 0.0268, d_mnist_loss: 0.0091, d_svhn_loss: 0.0178, d_fake_loss: 0.0199, g_loss: 1.1103\n",
            "Step [44080/60000], d_real_loss: 0.0566, d_mnist_loss: 0.0221, d_svhn_loss: 0.0345, d_fake_loss: 0.1369, g_loss: 1.1170\n",
            "Step [44090/60000], d_real_loss: 0.0260, d_mnist_loss: 0.0068, d_svhn_loss: 0.0192, d_fake_loss: 0.0228, g_loss: 1.0844\n",
            "Step [44100/60000], d_real_loss: 0.0350, d_mnist_loss: 0.0124, d_svhn_loss: 0.0226, d_fake_loss: 0.0215, g_loss: 1.0499\n",
            "Step [44110/60000], d_real_loss: 0.0842, d_mnist_loss: 0.0082, d_svhn_loss: 0.0760, d_fake_loss: 0.1511, g_loss: 1.2772\n",
            "Step [44120/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0307, d_svhn_loss: 0.0222, d_fake_loss: 0.0186, g_loss: 1.1807\n",
            "Step [44130/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0068, d_svhn_loss: 0.0538, d_fake_loss: 0.0302, g_loss: 1.1042\n",
            "Step [44140/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0110, d_svhn_loss: 0.0455, d_fake_loss: 0.0351, g_loss: 1.1306\n",
            "Step [44150/60000], d_real_loss: 0.0708, d_mnist_loss: 0.0083, d_svhn_loss: 0.0624, d_fake_loss: 0.0458, g_loss: 1.1276\n",
            "Step [44160/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0093, d_svhn_loss: 0.0274, d_fake_loss: 0.0329, g_loss: 1.1334\n",
            "Step [44170/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0056, d_svhn_loss: 0.0257, d_fake_loss: 0.0368, g_loss: 1.2973\n",
            "Step [44180/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0141, d_svhn_loss: 0.0256, d_fake_loss: 0.0584, g_loss: 0.9343\n",
            "Step [44190/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0116, d_svhn_loss: 0.0336, d_fake_loss: 0.0622, g_loss: 1.1894\n",
            "Step [44200/60000], d_real_loss: 0.1245, d_mnist_loss: 0.0231, d_svhn_loss: 0.1015, d_fake_loss: 0.1089, g_loss: 0.7992\n",
            "Step [44210/60000], d_real_loss: 0.0559, d_mnist_loss: 0.0055, d_svhn_loss: 0.0504, d_fake_loss: 0.0661, g_loss: 1.1116\n",
            "Step [44220/60000], d_real_loss: 0.0979, d_mnist_loss: 0.0075, d_svhn_loss: 0.0904, d_fake_loss: 0.0571, g_loss: 0.9990\n",
            "Step [44230/60000], d_real_loss: 0.0464, d_mnist_loss: 0.0109, d_svhn_loss: 0.0355, d_fake_loss: 0.0641, g_loss: 1.3780\n",
            "Step [44240/60000], d_real_loss: 0.0551, d_mnist_loss: 0.0120, d_svhn_loss: 0.0431, d_fake_loss: 0.0350, g_loss: 1.1477\n",
            "Step [44250/60000], d_real_loss: 0.0260, d_mnist_loss: 0.0082, d_svhn_loss: 0.0178, d_fake_loss: 0.0492, g_loss: 1.1688\n",
            "Step [44260/60000], d_real_loss: 0.0899, d_mnist_loss: 0.0152, d_svhn_loss: 0.0747, d_fake_loss: 0.0309, g_loss: 1.0103\n",
            "Step [44270/60000], d_real_loss: 0.0285, d_mnist_loss: 0.0074, d_svhn_loss: 0.0211, d_fake_loss: 0.1222, g_loss: 1.0417\n",
            "Step [44280/60000], d_real_loss: 0.1028, d_mnist_loss: 0.0181, d_svhn_loss: 0.0847, d_fake_loss: 0.0342, g_loss: 1.1338\n",
            "Step [44290/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0159, d_svhn_loss: 0.0208, d_fake_loss: 0.0415, g_loss: 1.0957\n",
            "Step [44300/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0126, d_svhn_loss: 0.0232, d_fake_loss: 0.0436, g_loss: 1.2944\n",
            "Step [44310/60000], d_real_loss: 0.0636, d_mnist_loss: 0.0161, d_svhn_loss: 0.0475, d_fake_loss: 0.0311, g_loss: 1.1817\n",
            "Step [44320/60000], d_real_loss: 0.0979, d_mnist_loss: 0.0154, d_svhn_loss: 0.0825, d_fake_loss: 0.0743, g_loss: 1.2208\n",
            "Step [44330/60000], d_real_loss: 0.0630, d_mnist_loss: 0.0107, d_svhn_loss: 0.0524, d_fake_loss: 0.0819, g_loss: 1.0455\n",
            "Step [44340/60000], d_real_loss: 0.1773, d_mnist_loss: 0.1606, d_svhn_loss: 0.0167, d_fake_loss: 0.0390, g_loss: 1.1976\n",
            "Step [44350/60000], d_real_loss: 0.0642, d_mnist_loss: 0.0187, d_svhn_loss: 0.0455, d_fake_loss: 0.1106, g_loss: 1.2758\n",
            "Step [44360/60000], d_real_loss: 0.1458, d_mnist_loss: 0.0087, d_svhn_loss: 0.1371, d_fake_loss: 0.4470, g_loss: 1.1355\n",
            "Step [44370/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0105, d_svhn_loss: 0.0282, d_fake_loss: 0.0702, g_loss: 1.0918\n",
            "Step [44380/60000], d_real_loss: 0.0889, d_mnist_loss: 0.0095, d_svhn_loss: 0.0794, d_fake_loss: 0.1717, g_loss: 1.1525\n",
            "Step [44390/60000], d_real_loss: 0.0529, d_mnist_loss: 0.0210, d_svhn_loss: 0.0319, d_fake_loss: 0.0586, g_loss: 1.2273\n",
            "Step [44400/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0116, d_svhn_loss: 0.0355, d_fake_loss: 0.1411, g_loss: 1.3263\n",
            "Step [44410/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0193, d_svhn_loss: 0.0459, d_fake_loss: 0.0267, g_loss: 1.1178\n",
            "Step [44420/60000], d_real_loss: 0.0678, d_mnist_loss: 0.0428, d_svhn_loss: 0.0249, d_fake_loss: 0.0185, g_loss: 1.2187\n",
            "Step [44430/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0103, d_svhn_loss: 0.0223, d_fake_loss: 0.0629, g_loss: 1.0766\n",
            "Step [44440/60000], d_real_loss: 0.0453, d_mnist_loss: 0.0071, d_svhn_loss: 0.0381, d_fake_loss: 0.0438, g_loss: 1.0862\n",
            "Step [44450/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0081, d_svhn_loss: 0.0269, d_fake_loss: 0.0439, g_loss: 1.0254\n",
            "Step [44460/60000], d_real_loss: 0.2062, d_mnist_loss: 0.0078, d_svhn_loss: 0.1984, d_fake_loss: 0.0551, g_loss: 1.0567\n",
            "Step [44470/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0083, d_svhn_loss: 0.0218, d_fake_loss: 0.0637, g_loss: 0.9484\n",
            "Step [44480/60000], d_real_loss: 0.0381, d_mnist_loss: 0.0145, d_svhn_loss: 0.0236, d_fake_loss: 0.0255, g_loss: 1.2603\n",
            "Step [44490/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0083, d_svhn_loss: 0.0227, d_fake_loss: 0.0298, g_loss: 0.9347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [44500/60000], d_real_loss: 0.0896, d_mnist_loss: 0.0253, d_svhn_loss: 0.0643, d_fake_loss: 0.1147, g_loss: 1.2824\n",
            "saved ./samples_fashion/sample-44500-m-s.png\n",
            "saved ./samples_fashion/sample-44500-s-m.png\n",
            "Step [44510/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0070, d_svhn_loss: 0.0171, d_fake_loss: 0.0362, g_loss: 1.3200\n",
            "Step [44520/60000], d_real_loss: 0.1471, d_mnist_loss: 0.0097, d_svhn_loss: 0.1374, d_fake_loss: 0.1279, g_loss: 1.1169\n",
            "Step [44530/60000], d_real_loss: 0.0321, d_mnist_loss: 0.0101, d_svhn_loss: 0.0221, d_fake_loss: 0.0158, g_loss: 1.1290\n",
            "Step [44540/60000], d_real_loss: 0.0354, d_mnist_loss: 0.0082, d_svhn_loss: 0.0272, d_fake_loss: 0.1018, g_loss: 1.1246\n",
            "Step [44550/60000], d_real_loss: 0.1052, d_mnist_loss: 0.0543, d_svhn_loss: 0.0510, d_fake_loss: 0.0281, g_loss: 0.9177\n",
            "Step [44560/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0174, d_svhn_loss: 0.0228, d_fake_loss: 0.0365, g_loss: 1.1103\n",
            "Step [44570/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0115, d_svhn_loss: 0.0155, d_fake_loss: 0.0183, g_loss: 1.0683\n",
            "Step [44580/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0195, d_svhn_loss: 0.0203, d_fake_loss: 0.0277, g_loss: 1.0706\n",
            "Step [44590/60000], d_real_loss: 0.0215, d_mnist_loss: 0.0066, d_svhn_loss: 0.0149, d_fake_loss: 0.0210, g_loss: 0.9778\n",
            "Step [44600/60000], d_real_loss: 0.0417, d_mnist_loss: 0.0148, d_svhn_loss: 0.0270, d_fake_loss: 0.0440, g_loss: 1.1871\n",
            "Step [44610/60000], d_real_loss: 0.0957, d_mnist_loss: 0.0381, d_svhn_loss: 0.0575, d_fake_loss: 0.0784, g_loss: 1.2999\n",
            "Step [44620/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0107, d_svhn_loss: 0.0250, d_fake_loss: 0.0725, g_loss: 1.1208\n",
            "Step [44630/60000], d_real_loss: 0.1120, d_mnist_loss: 0.0098, d_svhn_loss: 0.1022, d_fake_loss: 0.1740, g_loss: 1.1566\n",
            "Step [44640/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0294, d_svhn_loss: 0.0148, d_fake_loss: 0.0624, g_loss: 1.1666\n",
            "Step [44650/60000], d_real_loss: 0.0449, d_mnist_loss: 0.0203, d_svhn_loss: 0.0246, d_fake_loss: 0.0266, g_loss: 1.1422\n",
            "Step [44660/60000], d_real_loss: 0.0501, d_mnist_loss: 0.0171, d_svhn_loss: 0.0330, d_fake_loss: 0.0277, g_loss: 1.1363\n",
            "Step [44670/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0092, d_svhn_loss: 0.0224, d_fake_loss: 0.0205, g_loss: 1.1488\n",
            "Step [44680/60000], d_real_loss: 0.0243, d_mnist_loss: 0.0064, d_svhn_loss: 0.0178, d_fake_loss: 0.0208, g_loss: 1.0240\n",
            "Step [44690/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0094, d_svhn_loss: 0.0154, d_fake_loss: 0.0276, g_loss: 1.0369\n",
            "Step [44700/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0137, d_svhn_loss: 0.0236, d_fake_loss: 0.0715, g_loss: 1.0488\n",
            "Step [44710/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0107, d_svhn_loss: 0.0184, d_fake_loss: 0.0693, g_loss: 1.0672\n",
            "Step [44720/60000], d_real_loss: 0.0763, d_mnist_loss: 0.0088, d_svhn_loss: 0.0675, d_fake_loss: 0.0189, g_loss: 1.1231\n",
            "Step [44730/60000], d_real_loss: 0.0551, d_mnist_loss: 0.0077, d_svhn_loss: 0.0474, d_fake_loss: 0.0314, g_loss: 1.2260\n",
            "Step [44740/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0060, d_svhn_loss: 0.0470, d_fake_loss: 0.2321, g_loss: 1.2703\n",
            "Step [44750/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0122, d_svhn_loss: 0.0235, d_fake_loss: 0.0336, g_loss: 1.0861\n",
            "Step [44760/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0111, d_svhn_loss: 0.0207, d_fake_loss: 0.0833, g_loss: 1.1579\n",
            "Step [44770/60000], d_real_loss: 0.0185, d_mnist_loss: 0.0067, d_svhn_loss: 0.0117, d_fake_loss: 0.0646, g_loss: 1.0820\n",
            "Step [44780/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0082, d_svhn_loss: 0.0289, d_fake_loss: 0.0535, g_loss: 1.1696\n",
            "Step [44790/60000], d_real_loss: 0.0240, d_mnist_loss: 0.0082, d_svhn_loss: 0.0158, d_fake_loss: 0.0353, g_loss: 1.1446\n",
            "Step [44800/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0117, d_svhn_loss: 0.0121, d_fake_loss: 0.0200, g_loss: 1.0520\n",
            "Step [44810/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0133, d_svhn_loss: 0.0232, d_fake_loss: 0.0862, g_loss: 1.2846\n",
            "Step [44820/60000], d_real_loss: 0.0261, d_mnist_loss: 0.0140, d_svhn_loss: 0.0121, d_fake_loss: 0.0359, g_loss: 0.9769\n",
            "Step [44830/60000], d_real_loss: 0.0996, d_mnist_loss: 0.0694, d_svhn_loss: 0.0303, d_fake_loss: 0.0655, g_loss: 1.1487\n",
            "Step [44840/60000], d_real_loss: 0.0300, d_mnist_loss: 0.0075, d_svhn_loss: 0.0225, d_fake_loss: 0.0991, g_loss: 1.0941\n",
            "Step [44850/60000], d_real_loss: 0.0515, d_mnist_loss: 0.0086, d_svhn_loss: 0.0430, d_fake_loss: 0.0469, g_loss: 1.0286\n",
            "Step [44860/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0261, d_svhn_loss: 0.0223, d_fake_loss: 0.0705, g_loss: 1.2445\n",
            "Step [44870/60000], d_real_loss: 0.0466, d_mnist_loss: 0.0196, d_svhn_loss: 0.0269, d_fake_loss: 0.0606, g_loss: 1.4041\n",
            "Step [44880/60000], d_real_loss: 0.0450, d_mnist_loss: 0.0234, d_svhn_loss: 0.0216, d_fake_loss: 0.0602, g_loss: 1.2984\n",
            "Step [44890/60000], d_real_loss: 0.0328, d_mnist_loss: 0.0123, d_svhn_loss: 0.0206, d_fake_loss: 0.0253, g_loss: 1.1459\n",
            "Step [44900/60000], d_real_loss: 0.0336, d_mnist_loss: 0.0153, d_svhn_loss: 0.0184, d_fake_loss: 0.0270, g_loss: 1.2798\n",
            "Step [44910/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0185, d_svhn_loss: 0.0174, d_fake_loss: 0.0330, g_loss: 1.0382\n",
            "Step [44920/60000], d_real_loss: 0.0538, d_mnist_loss: 0.0293, d_svhn_loss: 0.0245, d_fake_loss: 0.0430, g_loss: 1.0949\n",
            "Step [44930/60000], d_real_loss: 0.0669, d_mnist_loss: 0.0408, d_svhn_loss: 0.0262, d_fake_loss: 0.0414, g_loss: 1.2301\n",
            "Step [44940/60000], d_real_loss: 0.0950, d_mnist_loss: 0.0149, d_svhn_loss: 0.0801, d_fake_loss: 0.0419, g_loss: 1.0667\n",
            "Step [44950/60000], d_real_loss: 0.1058, d_mnist_loss: 0.0086, d_svhn_loss: 0.0972, d_fake_loss: 0.1506, g_loss: 1.0823\n",
            "Step [44960/60000], d_real_loss: 0.2058, d_mnist_loss: 0.0069, d_svhn_loss: 0.1989, d_fake_loss: 0.1221, g_loss: 1.1949\n",
            "Step [44970/60000], d_real_loss: 0.0629, d_mnist_loss: 0.0192, d_svhn_loss: 0.0437, d_fake_loss: 0.0471, g_loss: 1.2296\n",
            "Step [44980/60000], d_real_loss: 0.0560, d_mnist_loss: 0.0123, d_svhn_loss: 0.0436, d_fake_loss: 0.0700, g_loss: 1.1462\n",
            "Step [44990/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0140, d_svhn_loss: 0.0139, d_fake_loss: 0.0186, g_loss: 1.0793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [45000/60000], d_real_loss: 0.0677, d_mnist_loss: 0.0060, d_svhn_loss: 0.0617, d_fake_loss: 0.0310, g_loss: 1.1538\n",
            "saved ./samples_fashion/sample-45000-m-s.png\n",
            "saved ./samples_fashion/sample-45000-s-m.png\n",
            "Step [45010/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0234, d_svhn_loss: 0.0284, d_fake_loss: 0.2115, g_loss: 1.0411\n",
            "Step [45020/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0095, d_svhn_loss: 0.0227, d_fake_loss: 0.0290, g_loss: 1.0931\n",
            "Step [45030/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0260, d_svhn_loss: 0.0214, d_fake_loss: 0.0320, g_loss: 1.2877\n",
            "Step [45040/60000], d_real_loss: 0.1180, d_mnist_loss: 0.0066, d_svhn_loss: 0.1114, d_fake_loss: 0.0721, g_loss: 1.0906\n",
            "Step [45050/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0115, d_svhn_loss: 0.0221, d_fake_loss: 0.0446, g_loss: 1.1358\n",
            "Step [45060/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0120, d_svhn_loss: 0.0363, d_fake_loss: 0.0671, g_loss: 1.3723\n",
            "Step [45070/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0089, d_svhn_loss: 0.0203, d_fake_loss: 0.0284, g_loss: 1.1784\n",
            "Step [45080/60000], d_real_loss: 0.0612, d_mnist_loss: 0.0109, d_svhn_loss: 0.0503, d_fake_loss: 0.0871, g_loss: 0.9868\n",
            "Step [45090/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0129, d_svhn_loss: 0.0249, d_fake_loss: 0.0482, g_loss: 1.2441\n",
            "Step [45100/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0139, d_svhn_loss: 0.0175, d_fake_loss: 0.0508, g_loss: 1.4817\n",
            "Step [45110/60000], d_real_loss: 0.0649, d_mnist_loss: 0.0307, d_svhn_loss: 0.0343, d_fake_loss: 0.0619, g_loss: 1.0302\n",
            "Step [45120/60000], d_real_loss: 0.0296, d_mnist_loss: 0.0073, d_svhn_loss: 0.0222, d_fake_loss: 0.1126, g_loss: 1.1188\n",
            "Step [45130/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0279, d_svhn_loss: 0.0139, d_fake_loss: 0.1233, g_loss: 1.2067\n",
            "Step [45140/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0115, d_svhn_loss: 0.0207, d_fake_loss: 0.0344, g_loss: 1.1136\n",
            "Step [45150/60000], d_real_loss: 0.0380, d_mnist_loss: 0.0101, d_svhn_loss: 0.0278, d_fake_loss: 0.0196, g_loss: 1.0907\n",
            "Step [45160/60000], d_real_loss: 0.0251, d_mnist_loss: 0.0108, d_svhn_loss: 0.0143, d_fake_loss: 0.0188, g_loss: 1.1264\n",
            "Step [45170/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0135, d_svhn_loss: 0.0231, d_fake_loss: 0.0609, g_loss: 1.3093\n",
            "Step [45180/60000], d_real_loss: 0.0985, d_mnist_loss: 0.0228, d_svhn_loss: 0.0757, d_fake_loss: 0.0368, g_loss: 1.1306\n",
            "Step [45190/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0201, d_svhn_loss: 0.0239, d_fake_loss: 0.0668, g_loss: 1.2397\n",
            "Step [45200/60000], d_real_loss: 0.0230, d_mnist_loss: 0.0070, d_svhn_loss: 0.0160, d_fake_loss: 0.0246, g_loss: 1.0521\n",
            "Step [45210/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0082, d_svhn_loss: 0.0234, d_fake_loss: 0.1021, g_loss: 1.4387\n",
            "Step [45220/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0113, d_svhn_loss: 0.0279, d_fake_loss: 0.0364, g_loss: 1.1843\n",
            "Step [45230/60000], d_real_loss: 0.0899, d_mnist_loss: 0.0568, d_svhn_loss: 0.0332, d_fake_loss: 0.0425, g_loss: 1.0956\n",
            "Step [45240/60000], d_real_loss: 0.0749, d_mnist_loss: 0.0536, d_svhn_loss: 0.0213, d_fake_loss: 0.0386, g_loss: 1.1696\n",
            "Step [45250/60000], d_real_loss: 0.0410, d_mnist_loss: 0.0100, d_svhn_loss: 0.0310, d_fake_loss: 0.0272, g_loss: 1.1377\n",
            "Step [45260/60000], d_real_loss: 0.0777, d_mnist_loss: 0.0488, d_svhn_loss: 0.0289, d_fake_loss: 0.0468, g_loss: 1.2077\n",
            "Step [45270/60000], d_real_loss: 0.0271, d_mnist_loss: 0.0075, d_svhn_loss: 0.0195, d_fake_loss: 0.0607, g_loss: 1.2333\n",
            "Step [45280/60000], d_real_loss: 0.0586, d_mnist_loss: 0.0383, d_svhn_loss: 0.0203, d_fake_loss: 0.0395, g_loss: 1.1682\n",
            "Step [45290/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0103, d_svhn_loss: 0.0248, d_fake_loss: 0.1337, g_loss: 1.1613\n",
            "Step [45300/60000], d_real_loss: 0.0541, d_mnist_loss: 0.0166, d_svhn_loss: 0.0375, d_fake_loss: 0.0316, g_loss: 1.2976\n",
            "Step [45310/60000], d_real_loss: 0.0795, d_mnist_loss: 0.0179, d_svhn_loss: 0.0616, d_fake_loss: 0.0823, g_loss: 1.1107\n",
            "Step [45320/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0202, d_svhn_loss: 0.0194, d_fake_loss: 0.0224, g_loss: 1.2976\n",
            "Step [45330/60000], d_real_loss: 0.0345, d_mnist_loss: 0.0139, d_svhn_loss: 0.0206, d_fake_loss: 0.0518, g_loss: 1.0991\n",
            "Step [45340/60000], d_real_loss: 0.0642, d_mnist_loss: 0.0116, d_svhn_loss: 0.0526, d_fake_loss: 0.0458, g_loss: 1.1798\n",
            "Step [45350/60000], d_real_loss: 0.0216, d_mnist_loss: 0.0073, d_svhn_loss: 0.0143, d_fake_loss: 0.0187, g_loss: 1.1935\n",
            "Step [45360/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0091, d_svhn_loss: 0.0314, d_fake_loss: 0.0181, g_loss: 1.1969\n",
            "Step [45370/60000], d_real_loss: 0.0584, d_mnist_loss: 0.0269, d_svhn_loss: 0.0315, d_fake_loss: 0.0606, g_loss: 1.2071\n",
            "Step [45380/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0188, d_svhn_loss: 0.0286, d_fake_loss: 0.0974, g_loss: 1.1019\n",
            "Step [45390/60000], d_real_loss: 0.0343, d_mnist_loss: 0.0100, d_svhn_loss: 0.0243, d_fake_loss: 0.0767, g_loss: 1.2154\n",
            "Step [45400/60000], d_real_loss: 0.0255, d_mnist_loss: 0.0131, d_svhn_loss: 0.0124, d_fake_loss: 0.0468, g_loss: 1.1771\n",
            "Step [45410/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0135, d_svhn_loss: 0.0281, d_fake_loss: 0.0615, g_loss: 1.1869\n",
            "Step [45420/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0085, d_svhn_loss: 0.0154, d_fake_loss: 0.1710, g_loss: 1.1450\n",
            "Step [45430/60000], d_real_loss: 0.0861, d_mnist_loss: 0.0129, d_svhn_loss: 0.0731, d_fake_loss: 0.0266, g_loss: 1.1017\n",
            "Step [45440/60000], d_real_loss: 0.0447, d_mnist_loss: 0.0075, d_svhn_loss: 0.0372, d_fake_loss: 0.0754, g_loss: 1.3972\n",
            "Step [45450/60000], d_real_loss: 0.0586, d_mnist_loss: 0.0250, d_svhn_loss: 0.0337, d_fake_loss: 0.0379, g_loss: 1.1621\n",
            "Step [45460/60000], d_real_loss: 0.1047, d_mnist_loss: 0.0802, d_svhn_loss: 0.0244, d_fake_loss: 0.2030, g_loss: 1.3667\n",
            "Step [45470/60000], d_real_loss: 0.0705, d_mnist_loss: 0.0241, d_svhn_loss: 0.0465, d_fake_loss: 0.0884, g_loss: 1.0933\n",
            "Step [45480/60000], d_real_loss: 0.0244, d_mnist_loss: 0.0057, d_svhn_loss: 0.0188, d_fake_loss: 0.0306, g_loss: 1.1614\n",
            "Step [45490/60000], d_real_loss: 0.0331, d_mnist_loss: 0.0062, d_svhn_loss: 0.0269, d_fake_loss: 0.0666, g_loss: 1.0870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [45500/60000], d_real_loss: 0.0429, d_mnist_loss: 0.0138, d_svhn_loss: 0.0290, d_fake_loss: 0.2520, g_loss: 1.2131\n",
            "saved ./samples_fashion/sample-45500-m-s.png\n",
            "saved ./samples_fashion/sample-45500-s-m.png\n",
            "Step [45510/60000], d_real_loss: 0.0460, d_mnist_loss: 0.0069, d_svhn_loss: 0.0391, d_fake_loss: 0.0423, g_loss: 1.1592\n",
            "Step [45520/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0089, d_svhn_loss: 0.0189, d_fake_loss: 0.0255, g_loss: 0.9925\n",
            "Step [45530/60000], d_real_loss: 0.0490, d_mnist_loss: 0.0323, d_svhn_loss: 0.0167, d_fake_loss: 0.0421, g_loss: 0.9872\n",
            "Step [45540/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0113, d_svhn_loss: 0.0169, d_fake_loss: 0.0416, g_loss: 1.1102\n",
            "Step [45550/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0098, d_svhn_loss: 0.0260, d_fake_loss: 0.0264, g_loss: 1.0920\n",
            "Step [45560/60000], d_real_loss: 0.0768, d_mnist_loss: 0.0177, d_svhn_loss: 0.0591, d_fake_loss: 0.0421, g_loss: 1.0305\n",
            "Step [45570/60000], d_real_loss: 0.0386, d_mnist_loss: 0.0108, d_svhn_loss: 0.0278, d_fake_loss: 0.0310, g_loss: 1.0497\n",
            "Step [45580/60000], d_real_loss: 0.0293, d_mnist_loss: 0.0119, d_svhn_loss: 0.0173, d_fake_loss: 0.0604, g_loss: 0.9779\n",
            "Step [45590/60000], d_real_loss: 0.0317, d_mnist_loss: 0.0183, d_svhn_loss: 0.0133, d_fake_loss: 0.1276, g_loss: 0.9282\n",
            "Step [45600/60000], d_real_loss: 0.0917, d_mnist_loss: 0.0643, d_svhn_loss: 0.0274, d_fake_loss: 0.0695, g_loss: 1.0309\n",
            "Step [45610/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0100, d_svhn_loss: 0.0211, d_fake_loss: 0.0146, g_loss: 1.1562\n",
            "Step [45620/60000], d_real_loss: 0.1205, d_mnist_loss: 0.0188, d_svhn_loss: 0.1017, d_fake_loss: 0.1201, g_loss: 1.0661\n",
            "Step [45630/60000], d_real_loss: 0.0333, d_mnist_loss: 0.0075, d_svhn_loss: 0.0258, d_fake_loss: 0.0253, g_loss: 1.1375\n",
            "Step [45640/60000], d_real_loss: 0.0225, d_mnist_loss: 0.0103, d_svhn_loss: 0.0122, d_fake_loss: 0.0348, g_loss: 1.1717\n",
            "Step [45650/60000], d_real_loss: 0.0770, d_mnist_loss: 0.0063, d_svhn_loss: 0.0708, d_fake_loss: 0.0775, g_loss: 1.2183\n",
            "Step [45660/60000], d_real_loss: 0.0603, d_mnist_loss: 0.0399, d_svhn_loss: 0.0204, d_fake_loss: 0.1215, g_loss: 1.2916\n",
            "Step [45670/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0148, d_svhn_loss: 0.0250, d_fake_loss: 0.0415, g_loss: 1.1113\n",
            "Step [45680/60000], d_real_loss: 0.1036, d_mnist_loss: 0.0547, d_svhn_loss: 0.0489, d_fake_loss: 0.0524, g_loss: 1.0473\n",
            "Step [45690/60000], d_real_loss: 0.1291, d_mnist_loss: 0.0314, d_svhn_loss: 0.0977, d_fake_loss: 0.1065, g_loss: 1.3221\n",
            "Step [45700/60000], d_real_loss: 0.0537, d_mnist_loss: 0.0324, d_svhn_loss: 0.0213, d_fake_loss: 0.0297, g_loss: 1.1539\n",
            "Step [45710/60000], d_real_loss: 0.1132, d_mnist_loss: 0.0756, d_svhn_loss: 0.0376, d_fake_loss: 0.0236, g_loss: 1.0135\n",
            "Step [45720/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0102, d_svhn_loss: 0.0203, d_fake_loss: 0.0248, g_loss: 1.2702\n",
            "Step [45730/60000], d_real_loss: 0.0587, d_mnist_loss: 0.0131, d_svhn_loss: 0.0456, d_fake_loss: 0.0489, g_loss: 1.2657\n",
            "Step [45740/60000], d_real_loss: 0.0614, d_mnist_loss: 0.0102, d_svhn_loss: 0.0512, d_fake_loss: 0.0231, g_loss: 1.1205\n",
            "Step [45750/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0147, d_svhn_loss: 0.0176, d_fake_loss: 0.0356, g_loss: 1.1997\n",
            "Step [45760/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0280, d_svhn_loss: 0.0284, d_fake_loss: 0.0706, g_loss: 1.2474\n",
            "Step [45770/60000], d_real_loss: 0.0957, d_mnist_loss: 0.0537, d_svhn_loss: 0.0420, d_fake_loss: 0.0583, g_loss: 1.0573\n",
            "Step [45780/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0359, d_svhn_loss: 0.0293, d_fake_loss: 0.0722, g_loss: 1.1061\n",
            "Step [45790/60000], d_real_loss: 0.0256, d_mnist_loss: 0.0083, d_svhn_loss: 0.0172, d_fake_loss: 0.0217, g_loss: 1.0945\n",
            "Step [45800/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0107, d_svhn_loss: 0.0255, d_fake_loss: 0.0506, g_loss: 1.2459\n",
            "Step [45810/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0069, d_svhn_loss: 0.0350, d_fake_loss: 0.0553, g_loss: 1.2043\n",
            "Step [45820/60000], d_real_loss: 0.0223, d_mnist_loss: 0.0092, d_svhn_loss: 0.0131, d_fake_loss: 0.0199, g_loss: 1.0477\n",
            "Step [45830/60000], d_real_loss: 0.0637, d_mnist_loss: 0.0107, d_svhn_loss: 0.0530, d_fake_loss: 0.0386, g_loss: 1.2036\n",
            "Step [45840/60000], d_real_loss: 0.0619, d_mnist_loss: 0.0140, d_svhn_loss: 0.0480, d_fake_loss: 0.0471, g_loss: 1.0839\n",
            "Step [45850/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0069, d_svhn_loss: 0.0528, d_fake_loss: 0.0504, g_loss: 1.1780\n",
            "Step [45860/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0110, d_svhn_loss: 0.0332, d_fake_loss: 0.1933, g_loss: 1.2968\n",
            "Step [45870/60000], d_real_loss: 0.0339, d_mnist_loss: 0.0095, d_svhn_loss: 0.0244, d_fake_loss: 0.0244, g_loss: 1.1787\n",
            "Step [45880/60000], d_real_loss: 0.0909, d_mnist_loss: 0.0074, d_svhn_loss: 0.0834, d_fake_loss: 0.0354, g_loss: 1.0293\n",
            "Step [45890/60000], d_real_loss: 0.1633, d_mnist_loss: 0.0123, d_svhn_loss: 0.1510, d_fake_loss: 0.0781, g_loss: 1.2238\n",
            "Step [45900/60000], d_real_loss: 0.0458, d_mnist_loss: 0.0084, d_svhn_loss: 0.0374, d_fake_loss: 0.0696, g_loss: 1.3127\n",
            "Step [45910/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0100, d_svhn_loss: 0.0318, d_fake_loss: 0.0198, g_loss: 1.0196\n",
            "Step [45920/60000], d_real_loss: 0.0272, d_mnist_loss: 0.0096, d_svhn_loss: 0.0177, d_fake_loss: 0.0330, g_loss: 1.0163\n",
            "Step [45930/60000], d_real_loss: 0.0237, d_mnist_loss: 0.0085, d_svhn_loss: 0.0152, d_fake_loss: 0.0468, g_loss: 1.1118\n",
            "Step [45940/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0208, d_svhn_loss: 0.0259, d_fake_loss: 0.0242, g_loss: 1.0530\n",
            "Step [45950/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0121, d_svhn_loss: 0.0322, d_fake_loss: 0.0190, g_loss: 1.1418\n",
            "Step [45960/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0115, d_svhn_loss: 0.0277, d_fake_loss: 0.0638, g_loss: 1.1389\n",
            "Step [45970/60000], d_real_loss: 0.0283, d_mnist_loss: 0.0098, d_svhn_loss: 0.0185, d_fake_loss: 0.0632, g_loss: 1.2273\n",
            "Step [45980/60000], d_real_loss: 0.0430, d_mnist_loss: 0.0084, d_svhn_loss: 0.0346, d_fake_loss: 0.0230, g_loss: 1.2239\n",
            "Step [45990/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0074, d_svhn_loss: 0.0397, d_fake_loss: 0.1124, g_loss: 1.2338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [46000/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0192, d_svhn_loss: 0.0236, d_fake_loss: 0.0529, g_loss: 1.1024\n",
            "saved ./samples_fashion/sample-46000-m-s.png\n",
            "saved ./samples_fashion/sample-46000-s-m.png\n",
            "Step [46010/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0119, d_svhn_loss: 0.0411, d_fake_loss: 0.0271, g_loss: 1.2516\n",
            "Step [46020/60000], d_real_loss: 0.0448, d_mnist_loss: 0.0119, d_svhn_loss: 0.0329, d_fake_loss: 0.0586, g_loss: 1.0806\n",
            "Step [46030/60000], d_real_loss: 0.0807, d_mnist_loss: 0.0427, d_svhn_loss: 0.0380, d_fake_loss: 0.2027, g_loss: 0.9842\n",
            "Step [46040/60000], d_real_loss: 0.0877, d_mnist_loss: 0.0107, d_svhn_loss: 0.0770, d_fake_loss: 0.1465, g_loss: 1.0238\n",
            "Step [46050/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0078, d_svhn_loss: 0.0175, d_fake_loss: 0.0273, g_loss: 1.1655\n",
            "Step [46060/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0139, d_svhn_loss: 0.0250, d_fake_loss: 0.0525, g_loss: 1.0773\n",
            "Step [46070/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0176, d_svhn_loss: 0.0397, d_fake_loss: 0.0240, g_loss: 1.1731\n",
            "Step [46080/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0107, d_svhn_loss: 0.0268, d_fake_loss: 0.0235, g_loss: 1.0351\n",
            "Step [46090/60000], d_real_loss: 0.0424, d_mnist_loss: 0.0087, d_svhn_loss: 0.0337, d_fake_loss: 0.0992, g_loss: 1.3447\n",
            "Step [46100/60000], d_real_loss: 0.0215, d_mnist_loss: 0.0074, d_svhn_loss: 0.0142, d_fake_loss: 0.0876, g_loss: 1.1135\n",
            "Step [46110/60000], d_real_loss: 0.0480, d_mnist_loss: 0.0123, d_svhn_loss: 0.0357, d_fake_loss: 0.0193, g_loss: 1.1723\n",
            "Step [46120/60000], d_real_loss: 0.0434, d_mnist_loss: 0.0185, d_svhn_loss: 0.0249, d_fake_loss: 0.0182, g_loss: 1.0786\n",
            "Step [46130/60000], d_real_loss: 0.1014, d_mnist_loss: 0.0099, d_svhn_loss: 0.0915, d_fake_loss: 0.0213, g_loss: 1.1517\n",
            "Step [46140/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0059, d_svhn_loss: 0.0224, d_fake_loss: 0.0320, g_loss: 1.2149\n",
            "Step [46150/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0147, d_svhn_loss: 0.0274, d_fake_loss: 0.0615, g_loss: 1.1738\n",
            "Step [46160/60000], d_real_loss: 0.1330, d_mnist_loss: 0.1032, d_svhn_loss: 0.0298, d_fake_loss: 0.0376, g_loss: 1.5249\n",
            "Step [46170/60000], d_real_loss: 0.0531, d_mnist_loss: 0.0176, d_svhn_loss: 0.0354, d_fake_loss: 0.1136, g_loss: 1.2281\n",
            "Step [46180/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0166, d_svhn_loss: 0.0239, d_fake_loss: 0.0376, g_loss: 0.9807\n",
            "Step [46190/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0210, d_svhn_loss: 0.0206, d_fake_loss: 0.0241, g_loss: 1.2235\n",
            "Step [46200/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0261, d_svhn_loss: 0.0168, d_fake_loss: 0.0404, g_loss: 1.1176\n",
            "Step [46210/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0095, d_svhn_loss: 0.0146, d_fake_loss: 0.0366, g_loss: 1.2569\n",
            "Step [46220/60000], d_real_loss: 0.0524, d_mnist_loss: 0.0104, d_svhn_loss: 0.0420, d_fake_loss: 0.1238, g_loss: 1.1061\n",
            "Step [46230/60000], d_real_loss: 0.0438, d_mnist_loss: 0.0221, d_svhn_loss: 0.0217, d_fake_loss: 0.0310, g_loss: 1.3064\n",
            "Step [46240/60000], d_real_loss: 0.0463, d_mnist_loss: 0.0079, d_svhn_loss: 0.0384, d_fake_loss: 0.1816, g_loss: 1.0307\n",
            "Step [46250/60000], d_real_loss: 0.0595, d_mnist_loss: 0.0344, d_svhn_loss: 0.0251, d_fake_loss: 0.0659, g_loss: 1.0919\n",
            "Step [46260/60000], d_real_loss: 0.1178, d_mnist_loss: 0.0221, d_svhn_loss: 0.0957, d_fake_loss: 0.0519, g_loss: 1.0793\n",
            "Step [46270/60000], d_real_loss: 0.1128, d_mnist_loss: 0.0161, d_svhn_loss: 0.0966, d_fake_loss: 0.0469, g_loss: 1.1241\n",
            "Step [46280/60000], d_real_loss: 0.0579, d_mnist_loss: 0.0064, d_svhn_loss: 0.0515, d_fake_loss: 0.0776, g_loss: 1.0801\n",
            "Step [46290/60000], d_real_loss: 0.0232, d_mnist_loss: 0.0106, d_svhn_loss: 0.0126, d_fake_loss: 0.0775, g_loss: 1.3029\n",
            "Step [46300/60000], d_real_loss: 0.0629, d_mnist_loss: 0.0185, d_svhn_loss: 0.0444, d_fake_loss: 0.0827, g_loss: 1.1419\n",
            "Step [46310/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0120, d_svhn_loss: 0.0463, d_fake_loss: 0.0501, g_loss: 0.9844\n",
            "Step [46320/60000], d_real_loss: 0.0332, d_mnist_loss: 0.0108, d_svhn_loss: 0.0224, d_fake_loss: 0.0196, g_loss: 1.0856\n",
            "Step [46330/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0221, d_svhn_loss: 0.0195, d_fake_loss: 0.0843, g_loss: 1.1589\n",
            "Step [46340/60000], d_real_loss: 0.0556, d_mnist_loss: 0.0112, d_svhn_loss: 0.0444, d_fake_loss: 0.0649, g_loss: 1.1025\n",
            "Step [46350/60000], d_real_loss: 0.0287, d_mnist_loss: 0.0111, d_svhn_loss: 0.0175, d_fake_loss: 0.0172, g_loss: 1.1484\n",
            "Step [46360/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0073, d_svhn_loss: 0.0236, d_fake_loss: 0.0865, g_loss: 0.9487\n",
            "Step [46370/60000], d_real_loss: 0.0573, d_mnist_loss: 0.0170, d_svhn_loss: 0.0403, d_fake_loss: 0.0648, g_loss: 1.1852\n",
            "Step [46380/60000], d_real_loss: 0.0763, d_mnist_loss: 0.0607, d_svhn_loss: 0.0156, d_fake_loss: 0.0868, g_loss: 1.0730\n",
            "Step [46390/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0226, d_svhn_loss: 0.0339, d_fake_loss: 0.0244, g_loss: 1.2579\n",
            "Step [46400/60000], d_real_loss: 0.0418, d_mnist_loss: 0.0093, d_svhn_loss: 0.0325, d_fake_loss: 0.0543, g_loss: 1.1381\n",
            "Step [46410/60000], d_real_loss: 0.0406, d_mnist_loss: 0.0090, d_svhn_loss: 0.0316, d_fake_loss: 0.0159, g_loss: 1.1256\n",
            "Step [46420/60000], d_real_loss: 0.0755, d_mnist_loss: 0.0127, d_svhn_loss: 0.0628, d_fake_loss: 0.0409, g_loss: 1.1347\n",
            "Step [46430/60000], d_real_loss: 0.0194, d_mnist_loss: 0.0068, d_svhn_loss: 0.0126, d_fake_loss: 0.0668, g_loss: 0.9698\n",
            "Step [46440/60000], d_real_loss: 0.1819, d_mnist_loss: 0.0121, d_svhn_loss: 0.1697, d_fake_loss: 0.1241, g_loss: 1.0438\n",
            "Step [46450/60000], d_real_loss: 0.0291, d_mnist_loss: 0.0083, d_svhn_loss: 0.0208, d_fake_loss: 0.0514, g_loss: 1.0693\n",
            "Step [46460/60000], d_real_loss: 0.0378, d_mnist_loss: 0.0111, d_svhn_loss: 0.0268, d_fake_loss: 0.0714, g_loss: 1.2643\n",
            "Step [46470/60000], d_real_loss: 0.0247, d_mnist_loss: 0.0077, d_svhn_loss: 0.0170, d_fake_loss: 0.0428, g_loss: 1.1106\n",
            "Step [46480/60000], d_real_loss: 0.0242, d_mnist_loss: 0.0125, d_svhn_loss: 0.0117, d_fake_loss: 0.0497, g_loss: 1.3072\n",
            "Step [46490/60000], d_real_loss: 0.0370, d_mnist_loss: 0.0152, d_svhn_loss: 0.0219, d_fake_loss: 0.0859, g_loss: 1.0341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [46500/60000], d_real_loss: 0.0255, d_mnist_loss: 0.0106, d_svhn_loss: 0.0148, d_fake_loss: 0.0237, g_loss: 1.2218\n",
            "saved ./samples_fashion/sample-46500-m-s.png\n",
            "saved ./samples_fashion/sample-46500-s-m.png\n",
            "Step [46510/60000], d_real_loss: 0.0645, d_mnist_loss: 0.0076, d_svhn_loss: 0.0569, d_fake_loss: 0.0874, g_loss: 1.3120\n",
            "Step [46520/60000], d_real_loss: 0.0605, d_mnist_loss: 0.0274, d_svhn_loss: 0.0331, d_fake_loss: 0.0402, g_loss: 1.1528\n",
            "Step [46530/60000], d_real_loss: 0.0888, d_mnist_loss: 0.0652, d_svhn_loss: 0.0236, d_fake_loss: 0.0452, g_loss: 0.8903\n",
            "Step [46540/60000], d_real_loss: 0.0232, d_mnist_loss: 0.0090, d_svhn_loss: 0.0142, d_fake_loss: 0.0267, g_loss: 0.9890\n",
            "Step [46550/60000], d_real_loss: 0.0413, d_mnist_loss: 0.0172, d_svhn_loss: 0.0241, d_fake_loss: 0.0341, g_loss: 1.2335\n",
            "Step [46560/60000], d_real_loss: 0.0246, d_mnist_loss: 0.0096, d_svhn_loss: 0.0151, d_fake_loss: 0.0666, g_loss: 1.2425\n",
            "Step [46570/60000], d_real_loss: 0.0194, d_mnist_loss: 0.0080, d_svhn_loss: 0.0114, d_fake_loss: 0.0200, g_loss: 1.0783\n",
            "Step [46580/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0058, d_svhn_loss: 0.0381, d_fake_loss: 0.0215, g_loss: 1.1311\n",
            "Step [46590/60000], d_real_loss: 0.0722, d_mnist_loss: 0.0101, d_svhn_loss: 0.0621, d_fake_loss: 0.1099, g_loss: 1.1450\n",
            "Step [46600/60000], d_real_loss: 0.0941, d_mnist_loss: 0.0772, d_svhn_loss: 0.0169, d_fake_loss: 0.2333, g_loss: 1.5773\n",
            "Step [46610/60000], d_real_loss: 0.0332, d_mnist_loss: 0.0139, d_svhn_loss: 0.0193, d_fake_loss: 0.0686, g_loss: 1.1530\n",
            "Step [46620/60000], d_real_loss: 0.1311, d_mnist_loss: 0.0103, d_svhn_loss: 0.1208, d_fake_loss: 0.0238, g_loss: 1.1941\n",
            "Step [46630/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0089, d_svhn_loss: 0.0279, d_fake_loss: 0.0227, g_loss: 1.1143\n",
            "Step [46640/60000], d_real_loss: 0.0258, d_mnist_loss: 0.0054, d_svhn_loss: 0.0204, d_fake_loss: 0.0658, g_loss: 1.1389\n",
            "Step [46650/60000], d_real_loss: 0.0383, d_mnist_loss: 0.0145, d_svhn_loss: 0.0238, d_fake_loss: 0.0564, g_loss: 1.2088\n",
            "Step [46660/60000], d_real_loss: 0.0625, d_mnist_loss: 0.0099, d_svhn_loss: 0.0526, d_fake_loss: 0.0419, g_loss: 1.0846\n",
            "Step [46670/60000], d_real_loss: 0.0780, d_mnist_loss: 0.0046, d_svhn_loss: 0.0734, d_fake_loss: 0.0754, g_loss: 1.1684\n",
            "Step [46680/60000], d_real_loss: 0.1517, d_mnist_loss: 0.0077, d_svhn_loss: 0.1440, d_fake_loss: 0.0575, g_loss: 1.2583\n",
            "Step [46690/60000], d_real_loss: 0.0302, d_mnist_loss: 0.0148, d_svhn_loss: 0.0154, d_fake_loss: 0.0537, g_loss: 1.3803\n",
            "Step [46700/60000], d_real_loss: 0.0544, d_mnist_loss: 0.0147, d_svhn_loss: 0.0397, d_fake_loss: 0.0486, g_loss: 1.4100\n",
            "Step [46710/60000], d_real_loss: 0.2223, d_mnist_loss: 0.1509, d_svhn_loss: 0.0714, d_fake_loss: 0.0858, g_loss: 1.4460\n",
            "Step [46720/60000], d_real_loss: 0.0294, d_mnist_loss: 0.0078, d_svhn_loss: 0.0215, d_fake_loss: 0.0265, g_loss: 1.0694\n",
            "Step [46730/60000], d_real_loss: 0.0285, d_mnist_loss: 0.0076, d_svhn_loss: 0.0209, d_fake_loss: 0.0408, g_loss: 1.1068\n",
            "Step [46740/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0204, d_svhn_loss: 0.0278, d_fake_loss: 0.0202, g_loss: 1.1553\n",
            "Step [46750/60000], d_real_loss: 0.0786, d_mnist_loss: 0.0585, d_svhn_loss: 0.0202, d_fake_loss: 0.1473, g_loss: 1.2431\n",
            "Step [46760/60000], d_real_loss: 0.1070, d_mnist_loss: 0.0856, d_svhn_loss: 0.0214, d_fake_loss: 0.0211, g_loss: 1.1085\n",
            "Step [46770/60000], d_real_loss: 0.0817, d_mnist_loss: 0.0376, d_svhn_loss: 0.0442, d_fake_loss: 0.0165, g_loss: 1.0391\n",
            "Step [46780/60000], d_real_loss: 0.1251, d_mnist_loss: 0.0262, d_svhn_loss: 0.0989, d_fake_loss: 0.0480, g_loss: 1.0819\n",
            "Step [46790/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0151, d_svhn_loss: 0.0208, d_fake_loss: 0.0434, g_loss: 0.9658\n",
            "Step [46800/60000], d_real_loss: 0.0582, d_mnist_loss: 0.0214, d_svhn_loss: 0.0368, d_fake_loss: 0.0710, g_loss: 1.1419\n",
            "Step [46810/60000], d_real_loss: 0.0261, d_mnist_loss: 0.0065, d_svhn_loss: 0.0196, d_fake_loss: 0.0676, g_loss: 0.8950\n",
            "Step [46820/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0259, d_svhn_loss: 0.0172, d_fake_loss: 0.0492, g_loss: 1.0647\n",
            "Step [46830/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0060, d_svhn_loss: 0.0203, d_fake_loss: 0.0179, g_loss: 1.1772\n",
            "Step [46840/60000], d_real_loss: 0.0799, d_mnist_loss: 0.0138, d_svhn_loss: 0.0660, d_fake_loss: 0.1421, g_loss: 1.2273\n",
            "Step [46850/60000], d_real_loss: 0.0480, d_mnist_loss: 0.0198, d_svhn_loss: 0.0282, d_fake_loss: 0.0480, g_loss: 1.1031\n",
            "Step [46860/60000], d_real_loss: 0.0302, d_mnist_loss: 0.0084, d_svhn_loss: 0.0218, d_fake_loss: 0.0922, g_loss: 1.1832\n",
            "Step [46870/60000], d_real_loss: 0.0294, d_mnist_loss: 0.0089, d_svhn_loss: 0.0206, d_fake_loss: 0.0603, g_loss: 1.2213\n",
            "Step [46880/60000], d_real_loss: 0.0307, d_mnist_loss: 0.0088, d_svhn_loss: 0.0219, d_fake_loss: 0.0981, g_loss: 1.1633\n",
            "Step [46890/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0349, d_svhn_loss: 0.0248, d_fake_loss: 0.0420, g_loss: 0.9807\n",
            "Step [46900/60000], d_real_loss: 0.0321, d_mnist_loss: 0.0120, d_svhn_loss: 0.0201, d_fake_loss: 0.0227, g_loss: 1.1399\n",
            "Step [46910/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0106, d_svhn_loss: 0.0135, d_fake_loss: 0.0641, g_loss: 1.1704\n",
            "Step [46920/60000], d_real_loss: 0.0819, d_mnist_loss: 0.0074, d_svhn_loss: 0.0745, d_fake_loss: 0.1234, g_loss: 1.0087\n",
            "Step [46930/60000], d_real_loss: 0.0289, d_mnist_loss: 0.0081, d_svhn_loss: 0.0208, d_fake_loss: 0.0708, g_loss: 1.1865\n",
            "Step [46940/60000], d_real_loss: 0.0754, d_mnist_loss: 0.0135, d_svhn_loss: 0.0619, d_fake_loss: 0.0140, g_loss: 1.1492\n",
            "Step [46950/60000], d_real_loss: 0.0531, d_mnist_loss: 0.0126, d_svhn_loss: 0.0405, d_fake_loss: 0.0386, g_loss: 1.3479\n",
            "Step [46960/60000], d_real_loss: 0.1210, d_mnist_loss: 0.1063, d_svhn_loss: 0.0146, d_fake_loss: 0.0380, g_loss: 1.2643\n",
            "Step [46970/60000], d_real_loss: 0.1139, d_mnist_loss: 0.0120, d_svhn_loss: 0.1019, d_fake_loss: 0.0558, g_loss: 1.1264\n",
            "Step [46980/60000], d_real_loss: 0.0264, d_mnist_loss: 0.0069, d_svhn_loss: 0.0195, d_fake_loss: 0.0731, g_loss: 1.2369\n",
            "Step [46990/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0101, d_svhn_loss: 0.0272, d_fake_loss: 0.0394, g_loss: 1.2579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [47000/60000], d_real_loss: 0.0792, d_mnist_loss: 0.0166, d_svhn_loss: 0.0627, d_fake_loss: 0.0505, g_loss: 1.1033\n",
            "saved ./samples_fashion/sample-47000-m-s.png\n",
            "saved ./samples_fashion/sample-47000-s-m.png\n",
            "Step [47010/60000], d_real_loss: 0.0307, d_mnist_loss: 0.0089, d_svhn_loss: 0.0217, d_fake_loss: 0.1609, g_loss: 1.0988\n",
            "Step [47020/60000], d_real_loss: 0.0567, d_mnist_loss: 0.0403, d_svhn_loss: 0.0164, d_fake_loss: 0.0385, g_loss: 0.9369\n",
            "Step [47030/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0272, d_svhn_loss: 0.0211, d_fake_loss: 0.0222, g_loss: 1.3566\n",
            "Step [47040/60000], d_real_loss: 0.0741, d_mnist_loss: 0.0163, d_svhn_loss: 0.0578, d_fake_loss: 0.1114, g_loss: 1.1257\n",
            "Step [47050/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0127, d_svhn_loss: 0.0241, d_fake_loss: 0.2618, g_loss: 1.5814\n",
            "Step [47060/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0174, d_svhn_loss: 0.0414, d_fake_loss: 0.0602, g_loss: 1.1934\n",
            "Step [47070/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0271, d_svhn_loss: 0.0128, d_fake_loss: 0.0133, g_loss: 1.0139\n",
            "Step [47080/60000], d_real_loss: 0.0586, d_mnist_loss: 0.0087, d_svhn_loss: 0.0500, d_fake_loss: 0.0291, g_loss: 1.1747\n",
            "Step [47090/60000], d_real_loss: 0.0925, d_mnist_loss: 0.0090, d_svhn_loss: 0.0835, d_fake_loss: 0.0415, g_loss: 1.2299\n",
            "Step [47100/60000], d_real_loss: 0.0508, d_mnist_loss: 0.0220, d_svhn_loss: 0.0288, d_fake_loss: 0.0216, g_loss: 1.0873\n",
            "Step [47110/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0240, d_svhn_loss: 0.0235, d_fake_loss: 0.0317, g_loss: 1.0546\n",
            "Step [47120/60000], d_real_loss: 0.0604, d_mnist_loss: 0.0133, d_svhn_loss: 0.0471, d_fake_loss: 0.0377, g_loss: 1.2682\n",
            "Step [47130/60000], d_real_loss: 0.0584, d_mnist_loss: 0.0105, d_svhn_loss: 0.0479, d_fake_loss: 0.0352, g_loss: 0.9706\n",
            "Step [47140/60000], d_real_loss: 0.0410, d_mnist_loss: 0.0129, d_svhn_loss: 0.0281, d_fake_loss: 0.0421, g_loss: 1.3358\n",
            "Step [47150/60000], d_real_loss: 0.0612, d_mnist_loss: 0.0175, d_svhn_loss: 0.0437, d_fake_loss: 0.0175, g_loss: 1.3006\n",
            "Step [47160/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0168, d_svhn_loss: 0.0196, d_fake_loss: 0.0463, g_loss: 1.1123\n",
            "Step [47170/60000], d_real_loss: 0.0257, d_mnist_loss: 0.0100, d_svhn_loss: 0.0157, d_fake_loss: 0.0300, g_loss: 1.0078\n",
            "Step [47180/60000], d_real_loss: 0.0635, d_mnist_loss: 0.0092, d_svhn_loss: 0.0543, d_fake_loss: 0.0285, g_loss: 1.1426\n",
            "Step [47190/60000], d_real_loss: 0.0411, d_mnist_loss: 0.0217, d_svhn_loss: 0.0194, d_fake_loss: 0.0347, g_loss: 1.1630\n",
            "Step [47200/60000], d_real_loss: 0.0275, d_mnist_loss: 0.0078, d_svhn_loss: 0.0197, d_fake_loss: 0.0574, g_loss: 1.0268\n",
            "Step [47210/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0215, d_svhn_loss: 0.0179, d_fake_loss: 0.0191, g_loss: 1.2407\n",
            "Step [47220/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0274, d_svhn_loss: 0.0168, d_fake_loss: 0.0343, g_loss: 1.0603\n",
            "Step [47230/60000], d_real_loss: 0.1212, d_mnist_loss: 0.0969, d_svhn_loss: 0.0243, d_fake_loss: 0.0566, g_loss: 1.2496\n",
            "Step [47240/60000], d_real_loss: 0.0844, d_mnist_loss: 0.0146, d_svhn_loss: 0.0698, d_fake_loss: 0.0317, g_loss: 1.0140\n",
            "Step [47250/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0107, d_svhn_loss: 0.0196, d_fake_loss: 0.0303, g_loss: 1.2377\n",
            "Step [47260/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0122, d_svhn_loss: 0.0181, d_fake_loss: 0.0163, g_loss: 1.0552\n",
            "Step [47270/60000], d_real_loss: 0.0696, d_mnist_loss: 0.0416, d_svhn_loss: 0.0280, d_fake_loss: 0.0502, g_loss: 1.2301\n",
            "Step [47280/60000], d_real_loss: 0.0369, d_mnist_loss: 0.0095, d_svhn_loss: 0.0274, d_fake_loss: 0.0411, g_loss: 1.1240\n",
            "Step [47290/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0079, d_svhn_loss: 0.0225, d_fake_loss: 0.0157, g_loss: 1.1047\n",
            "Step [47300/60000], d_real_loss: 0.0801, d_mnist_loss: 0.0076, d_svhn_loss: 0.0725, d_fake_loss: 0.0424, g_loss: 1.1044\n",
            "Step [47310/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0088, d_svhn_loss: 0.0264, d_fake_loss: 0.1690, g_loss: 1.4055\n",
            "Step [47320/60000], d_real_loss: 0.2365, d_mnist_loss: 0.1167, d_svhn_loss: 0.1198, d_fake_loss: 0.3273, g_loss: 1.0408\n",
            "Step [47330/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0118, d_svhn_loss: 0.0195, d_fake_loss: 0.0474, g_loss: 1.1238\n",
            "Step [47340/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0107, d_svhn_loss: 0.0205, d_fake_loss: 0.0529, g_loss: 1.1154\n",
            "Step [47350/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0138, d_svhn_loss: 0.0258, d_fake_loss: 0.0777, g_loss: 1.1668\n",
            "Step [47360/60000], d_real_loss: 0.0794, d_mnist_loss: 0.0158, d_svhn_loss: 0.0636, d_fake_loss: 0.0537, g_loss: 1.1190\n",
            "Step [47370/60000], d_real_loss: 0.0661, d_mnist_loss: 0.0208, d_svhn_loss: 0.0453, d_fake_loss: 0.0740, g_loss: 1.0671\n",
            "Step [47380/60000], d_real_loss: 0.0391, d_mnist_loss: 0.0059, d_svhn_loss: 0.0332, d_fake_loss: 0.0304, g_loss: 1.1517\n",
            "Step [47390/60000], d_real_loss: 0.0325, d_mnist_loss: 0.0070, d_svhn_loss: 0.0255, d_fake_loss: 0.2568, g_loss: 1.1136\n",
            "Step [47400/60000], d_real_loss: 0.0237, d_mnist_loss: 0.0105, d_svhn_loss: 0.0132, d_fake_loss: 0.0648, g_loss: 1.2399\n",
            "Step [47410/60000], d_real_loss: 0.0615, d_mnist_loss: 0.0087, d_svhn_loss: 0.0529, d_fake_loss: 0.0271, g_loss: 1.1021\n",
            "Step [47420/60000], d_real_loss: 0.1233, d_mnist_loss: 0.0792, d_svhn_loss: 0.0440, d_fake_loss: 0.0547, g_loss: 1.5748\n",
            "Step [47430/60000], d_real_loss: 0.0616, d_mnist_loss: 0.0218, d_svhn_loss: 0.0398, d_fake_loss: 0.0625, g_loss: 1.1676\n",
            "Step [47440/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0121, d_svhn_loss: 0.0187, d_fake_loss: 0.0686, g_loss: 1.2407\n",
            "Step [47450/60000], d_real_loss: 0.0379, d_mnist_loss: 0.0195, d_svhn_loss: 0.0184, d_fake_loss: 0.0475, g_loss: 1.2048\n",
            "Step [47460/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0229, d_svhn_loss: 0.0227, d_fake_loss: 0.0852, g_loss: 1.2236\n",
            "Step [47470/60000], d_real_loss: 0.0815, d_mnist_loss: 0.0099, d_svhn_loss: 0.0716, d_fake_loss: 0.0874, g_loss: 1.2430\n",
            "Step [47480/60000], d_real_loss: 0.0371, d_mnist_loss: 0.0164, d_svhn_loss: 0.0206, d_fake_loss: 0.0432, g_loss: 1.2364\n",
            "Step [47490/60000], d_real_loss: 0.0265, d_mnist_loss: 0.0103, d_svhn_loss: 0.0163, d_fake_loss: 0.0238, g_loss: 1.1364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [47500/60000], d_real_loss: 0.0477, d_mnist_loss: 0.0252, d_svhn_loss: 0.0225, d_fake_loss: 0.0680, g_loss: 1.1455\n",
            "saved ./samples_fashion/sample-47500-m-s.png\n",
            "saved ./samples_fashion/sample-47500-s-m.png\n",
            "Step [47510/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0143, d_svhn_loss: 0.0288, d_fake_loss: 0.0190, g_loss: 1.2002\n",
            "Step [47520/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0087, d_svhn_loss: 0.0396, d_fake_loss: 0.0677, g_loss: 1.1101\n",
            "Step [47530/60000], d_real_loss: 0.0783, d_mnist_loss: 0.0112, d_svhn_loss: 0.0670, d_fake_loss: 0.0191, g_loss: 1.2174\n",
            "Step [47540/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0139, d_svhn_loss: 0.0198, d_fake_loss: 0.0161, g_loss: 1.1696\n",
            "Step [47550/60000], d_real_loss: 0.0381, d_mnist_loss: 0.0162, d_svhn_loss: 0.0219, d_fake_loss: 0.0792, g_loss: 1.1339\n",
            "Step [47560/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0084, d_svhn_loss: 0.0323, d_fake_loss: 0.0164, g_loss: 1.1493\n",
            "Step [47570/60000], d_real_loss: 0.1195, d_mnist_loss: 0.0403, d_svhn_loss: 0.0792, d_fake_loss: 0.0529, g_loss: 1.0376\n",
            "Step [47580/60000], d_real_loss: 0.1042, d_mnist_loss: 0.0090, d_svhn_loss: 0.0952, d_fake_loss: 0.0305, g_loss: 1.1483\n",
            "Step [47590/60000], d_real_loss: 0.0575, d_mnist_loss: 0.0189, d_svhn_loss: 0.0386, d_fake_loss: 0.0306, g_loss: 1.1449\n",
            "Step [47600/60000], d_real_loss: 0.0466, d_mnist_loss: 0.0101, d_svhn_loss: 0.0366, d_fake_loss: 0.0297, g_loss: 1.0614\n",
            "Step [47610/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0083, d_svhn_loss: 0.0316, d_fake_loss: 0.0260, g_loss: 1.2032\n",
            "Step [47620/60000], d_real_loss: 0.1152, d_mnist_loss: 0.0207, d_svhn_loss: 0.0945, d_fake_loss: 0.0804, g_loss: 1.1932\n",
            "Step [47630/60000], d_real_loss: 0.0317, d_mnist_loss: 0.0085, d_svhn_loss: 0.0232, d_fake_loss: 0.0356, g_loss: 1.2890\n",
            "Step [47640/60000], d_real_loss: 0.0512, d_mnist_loss: 0.0354, d_svhn_loss: 0.0158, d_fake_loss: 0.0263, g_loss: 1.2725\n",
            "Step [47650/60000], d_real_loss: 0.0173, d_mnist_loss: 0.0049, d_svhn_loss: 0.0125, d_fake_loss: 0.0622, g_loss: 1.0651\n",
            "Step [47660/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0133, d_svhn_loss: 0.0227, d_fake_loss: 0.0822, g_loss: 1.0697\n",
            "Step [47670/60000], d_real_loss: 0.0295, d_mnist_loss: 0.0095, d_svhn_loss: 0.0200, d_fake_loss: 0.0321, g_loss: 1.2018\n",
            "Step [47680/60000], d_real_loss: 0.0964, d_mnist_loss: 0.0441, d_svhn_loss: 0.0523, d_fake_loss: 0.1125, g_loss: 1.4871\n",
            "Step [47690/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0102, d_svhn_loss: 0.0146, d_fake_loss: 0.0330, g_loss: 0.9901\n",
            "Step [47700/60000], d_real_loss: 0.0469, d_mnist_loss: 0.0086, d_svhn_loss: 0.0384, d_fake_loss: 0.0341, g_loss: 1.2154\n",
            "Step [47710/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0133, d_svhn_loss: 0.0287, d_fake_loss: 0.0138, g_loss: 1.0167\n",
            "Step [47720/60000], d_real_loss: 0.0544, d_mnist_loss: 0.0082, d_svhn_loss: 0.0462, d_fake_loss: 0.0210, g_loss: 1.0996\n",
            "Step [47730/60000], d_real_loss: 0.0226, d_mnist_loss: 0.0076, d_svhn_loss: 0.0150, d_fake_loss: 0.0211, g_loss: 1.1417\n",
            "Step [47740/60000], d_real_loss: 0.0484, d_mnist_loss: 0.0077, d_svhn_loss: 0.0407, d_fake_loss: 0.0250, g_loss: 1.1404\n",
            "Step [47750/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0093, d_svhn_loss: 0.0177, d_fake_loss: 0.0509, g_loss: 1.1284\n",
            "Step [47760/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0148, d_svhn_loss: 0.0334, d_fake_loss: 0.0433, g_loss: 1.1018\n",
            "Step [47770/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0266, d_svhn_loss: 0.0128, d_fake_loss: 0.0487, g_loss: 1.0264\n",
            "Step [47780/60000], d_real_loss: 0.1511, d_mnist_loss: 0.0114, d_svhn_loss: 0.1397, d_fake_loss: 0.0831, g_loss: 1.1932\n",
            "Step [47790/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0376, d_svhn_loss: 0.0159, d_fake_loss: 0.0579, g_loss: 1.1452\n",
            "Step [47800/60000], d_real_loss: 0.0867, d_mnist_loss: 0.0293, d_svhn_loss: 0.0574, d_fake_loss: 0.0729, g_loss: 1.0848\n",
            "Step [47810/60000], d_real_loss: 0.0197, d_mnist_loss: 0.0070, d_svhn_loss: 0.0127, d_fake_loss: 0.0206, g_loss: 1.1997\n",
            "Step [47820/60000], d_real_loss: 0.0254, d_mnist_loss: 0.0074, d_svhn_loss: 0.0180, d_fake_loss: 0.0556, g_loss: 1.3744\n",
            "Step [47830/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0127, d_svhn_loss: 0.0178, d_fake_loss: 0.0745, g_loss: 1.3010\n",
            "Step [47840/60000], d_real_loss: 0.0448, d_mnist_loss: 0.0279, d_svhn_loss: 0.0169, d_fake_loss: 0.0185, g_loss: 1.2770\n",
            "Step [47850/60000], d_real_loss: 0.0510, d_mnist_loss: 0.0300, d_svhn_loss: 0.0210, d_fake_loss: 0.0901, g_loss: 1.3210\n",
            "Step [47860/60000], d_real_loss: 0.0317, d_mnist_loss: 0.0130, d_svhn_loss: 0.0187, d_fake_loss: 0.0198, g_loss: 1.1452\n",
            "Step [47870/60000], d_real_loss: 0.0286, d_mnist_loss: 0.0088, d_svhn_loss: 0.0198, d_fake_loss: 0.0278, g_loss: 1.0226\n",
            "Step [47880/60000], d_real_loss: 0.0297, d_mnist_loss: 0.0092, d_svhn_loss: 0.0205, d_fake_loss: 0.0250, g_loss: 1.1853\n",
            "Step [47890/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0075, d_svhn_loss: 0.0252, d_fake_loss: 0.0148, g_loss: 1.1061\n",
            "Step [47900/60000], d_real_loss: 0.0409, d_mnist_loss: 0.0109, d_svhn_loss: 0.0300, d_fake_loss: 0.0317, g_loss: 1.0533\n",
            "Step [47910/60000], d_real_loss: 0.0250, d_mnist_loss: 0.0054, d_svhn_loss: 0.0196, d_fake_loss: 0.0254, g_loss: 1.1995\n",
            "Step [47920/60000], d_real_loss: 0.0233, d_mnist_loss: 0.0089, d_svhn_loss: 0.0145, d_fake_loss: 0.0267, g_loss: 1.2698\n",
            "Step [47930/60000], d_real_loss: 0.0394, d_mnist_loss: 0.0103, d_svhn_loss: 0.0291, d_fake_loss: 0.0209, g_loss: 1.1336\n",
            "Step [47940/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0114, d_svhn_loss: 0.0245, d_fake_loss: 0.0670, g_loss: 1.2427\n",
            "Step [47950/60000], d_real_loss: 0.0628, d_mnist_loss: 0.0114, d_svhn_loss: 0.0514, d_fake_loss: 0.0235, g_loss: 1.1861\n",
            "Step [47960/60000], d_real_loss: 0.0933, d_mnist_loss: 0.0762, d_svhn_loss: 0.0171, d_fake_loss: 0.0865, g_loss: 1.4205\n",
            "Step [47970/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0106, d_svhn_loss: 0.0237, d_fake_loss: 0.0274, g_loss: 1.1425\n",
            "Step [47980/60000], d_real_loss: 0.0600, d_mnist_loss: 0.0057, d_svhn_loss: 0.0543, d_fake_loss: 0.0215, g_loss: 1.0069\n",
            "Step [47990/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0109, d_svhn_loss: 0.0291, d_fake_loss: 0.1027, g_loss: 0.8163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999998807907104, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [48000/60000], d_real_loss: 0.0296, d_mnist_loss: 0.0173, d_svhn_loss: 0.0123, d_fake_loss: 0.0365, g_loss: 1.1388\n",
            "saved ./samples_fashion/sample-48000-m-s.png\n",
            "saved ./samples_fashion/sample-48000-s-m.png\n",
            "Step [48010/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0142, d_svhn_loss: 0.0240, d_fake_loss: 0.0255, g_loss: 1.1107\n",
            "Step [48020/60000], d_real_loss: 0.0526, d_mnist_loss: 0.0116, d_svhn_loss: 0.0410, d_fake_loss: 0.0184, g_loss: 1.1263\n",
            "Step [48030/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0234, d_svhn_loss: 0.0431, d_fake_loss: 0.0305, g_loss: 1.0197\n",
            "Step [48040/60000], d_real_loss: 0.1725, d_mnist_loss: 0.0290, d_svhn_loss: 0.1435, d_fake_loss: 0.0411, g_loss: 1.1240\n",
            "Step [48050/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0124, d_svhn_loss: 0.0280, d_fake_loss: 0.0655, g_loss: 1.1962\n",
            "Step [48060/60000], d_real_loss: 0.0463, d_mnist_loss: 0.0268, d_svhn_loss: 0.0194, d_fake_loss: 0.1616, g_loss: 1.1911\n",
            "Step [48070/60000], d_real_loss: 0.1046, d_mnist_loss: 0.0084, d_svhn_loss: 0.0961, d_fake_loss: 0.0410, g_loss: 1.0627\n",
            "Step [48080/60000], d_real_loss: 0.1015, d_mnist_loss: 0.0085, d_svhn_loss: 0.0930, d_fake_loss: 0.0202, g_loss: 1.1786\n",
            "Step [48090/60000], d_real_loss: 0.0729, d_mnist_loss: 0.0185, d_svhn_loss: 0.0544, d_fake_loss: 0.0475, g_loss: 1.1016\n",
            "Step [48100/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0106, d_svhn_loss: 0.0308, d_fake_loss: 0.0345, g_loss: 1.0877\n",
            "Step [48110/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0071, d_svhn_loss: 0.0208, d_fake_loss: 0.0185, g_loss: 1.1198\n",
            "Step [48120/60000], d_real_loss: 0.0547, d_mnist_loss: 0.0368, d_svhn_loss: 0.0180, d_fake_loss: 0.0253, g_loss: 1.0631\n",
            "Step [48130/60000], d_real_loss: 0.0307, d_mnist_loss: 0.0077, d_svhn_loss: 0.0231, d_fake_loss: 0.1159, g_loss: 1.0174\n",
            "Step [48140/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0136, d_svhn_loss: 0.0182, d_fake_loss: 0.0508, g_loss: 0.8611\n",
            "Step [48150/60000], d_real_loss: 0.0492, d_mnist_loss: 0.0224, d_svhn_loss: 0.0268, d_fake_loss: 0.0783, g_loss: 0.8902\n",
            "Step [48160/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0099, d_svhn_loss: 0.0214, d_fake_loss: 0.0334, g_loss: 1.2135\n",
            "Step [48170/60000], d_real_loss: 0.0334, d_mnist_loss: 0.0082, d_svhn_loss: 0.0253, d_fake_loss: 0.0812, g_loss: 1.0498\n",
            "Step [48180/60000], d_real_loss: 0.0610, d_mnist_loss: 0.0250, d_svhn_loss: 0.0360, d_fake_loss: 0.0194, g_loss: 1.2553\n",
            "Step [48190/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0239, d_svhn_loss: 0.0163, d_fake_loss: 0.0587, g_loss: 1.2435\n",
            "Step [48200/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0079, d_svhn_loss: 0.0397, d_fake_loss: 0.0561, g_loss: 0.9992\n",
            "Step [48210/60000], d_real_loss: 0.0351, d_mnist_loss: 0.0075, d_svhn_loss: 0.0276, d_fake_loss: 0.1797, g_loss: 1.0432\n",
            "Step [48220/60000], d_real_loss: 0.0509, d_mnist_loss: 0.0068, d_svhn_loss: 0.0442, d_fake_loss: 0.1389, g_loss: 1.2167\n",
            "Step [48230/60000], d_real_loss: 0.1532, d_mnist_loss: 0.0621, d_svhn_loss: 0.0912, d_fake_loss: 0.0510, g_loss: 1.0431\n",
            "Step [48240/60000], d_real_loss: 0.1583, d_mnist_loss: 0.0104, d_svhn_loss: 0.1479, d_fake_loss: 0.0685, g_loss: 0.9999\n",
            "Step [48250/60000], d_real_loss: 0.1610, d_mnist_loss: 0.1100, d_svhn_loss: 0.0510, d_fake_loss: 0.0647, g_loss: 1.3023\n",
            "Step [48260/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0183, d_svhn_loss: 0.0184, d_fake_loss: 0.0334, g_loss: 1.0773\n",
            "Step [48270/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0109, d_svhn_loss: 0.0280, d_fake_loss: 0.0355, g_loss: 1.1658\n",
            "Step [48280/60000], d_real_loss: 0.0429, d_mnist_loss: 0.0206, d_svhn_loss: 0.0223, d_fake_loss: 0.0725, g_loss: 1.1776\n",
            "Step [48290/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0137, d_svhn_loss: 0.0329, d_fake_loss: 0.0566, g_loss: 1.2176\n",
            "Step [48300/60000], d_real_loss: 0.0876, d_mnist_loss: 0.0082, d_svhn_loss: 0.0794, d_fake_loss: 0.0299, g_loss: 1.1377\n",
            "Step [48310/60000], d_real_loss: 0.0281, d_mnist_loss: 0.0071, d_svhn_loss: 0.0210, d_fake_loss: 0.0171, g_loss: 1.0933\n",
            "Step [48320/60000], d_real_loss: 0.0392, d_mnist_loss: 0.0042, d_svhn_loss: 0.0350, d_fake_loss: 0.0403, g_loss: 1.2125\n",
            "Step [48330/60000], d_real_loss: 0.1794, d_mnist_loss: 0.0459, d_svhn_loss: 0.1335, d_fake_loss: 0.0918, g_loss: 1.2999\n",
            "Step [48340/60000], d_real_loss: 0.0281, d_mnist_loss: 0.0088, d_svhn_loss: 0.0193, d_fake_loss: 0.0167, g_loss: 1.1617\n",
            "Step [48350/60000], d_real_loss: 0.0594, d_mnist_loss: 0.0191, d_svhn_loss: 0.0403, d_fake_loss: 0.0405, g_loss: 1.2788\n",
            "Step [48360/60000], d_real_loss: 0.0488, d_mnist_loss: 0.0290, d_svhn_loss: 0.0198, d_fake_loss: 0.0197, g_loss: 0.9693\n",
            "Step [48370/60000], d_real_loss: 0.0235, d_mnist_loss: 0.0041, d_svhn_loss: 0.0194, d_fake_loss: 0.0240, g_loss: 1.1384\n",
            "Step [48380/60000], d_real_loss: 0.0891, d_mnist_loss: 0.0626, d_svhn_loss: 0.0266, d_fake_loss: 0.0516, g_loss: 1.0512\n",
            "Step [48390/60000], d_real_loss: 0.0621, d_mnist_loss: 0.0079, d_svhn_loss: 0.0542, d_fake_loss: 0.0593, g_loss: 1.0697\n",
            "Step [48400/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0095, d_svhn_loss: 0.0267, d_fake_loss: 0.0721, g_loss: 1.0742\n",
            "Step [48410/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0060, d_svhn_loss: 0.0512, d_fake_loss: 0.0510, g_loss: 1.2659\n",
            "Step [48420/60000], d_real_loss: 0.0312, d_mnist_loss: 0.0065, d_svhn_loss: 0.0247, d_fake_loss: 0.0211, g_loss: 1.1609\n",
            "Step [48430/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0163, d_svhn_loss: 0.0183, d_fake_loss: 0.0449, g_loss: 1.0475\n",
            "Step [48440/60000], d_real_loss: 0.0423, d_mnist_loss: 0.0108, d_svhn_loss: 0.0315, d_fake_loss: 0.0960, g_loss: 1.2381\n",
            "Step [48450/60000], d_real_loss: 0.0552, d_mnist_loss: 0.0132, d_svhn_loss: 0.0420, d_fake_loss: 0.0607, g_loss: 1.0441\n",
            "Step [48460/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0304, d_svhn_loss: 0.0171, d_fake_loss: 0.0525, g_loss: 0.9238\n",
            "Step [48470/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0092, d_svhn_loss: 0.0306, d_fake_loss: 0.1225, g_loss: 1.0098\n",
            "Step [48480/60000], d_real_loss: 0.0343, d_mnist_loss: 0.0077, d_svhn_loss: 0.0265, d_fake_loss: 0.0440, g_loss: 1.1791\n",
            "Step [48490/60000], d_real_loss: 0.1508, d_mnist_loss: 0.0664, d_svhn_loss: 0.0844, d_fake_loss: 0.0770, g_loss: 1.1525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [48500/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0057, d_svhn_loss: 0.0515, d_fake_loss: 0.0664, g_loss: 1.1869\n",
            "saved ./samples_fashion/sample-48500-m-s.png\n",
            "saved ./samples_fashion/sample-48500-s-m.png\n",
            "Step [48510/60000], d_real_loss: 0.0487, d_mnist_loss: 0.0181, d_svhn_loss: 0.0306, d_fake_loss: 0.0552, g_loss: 1.1278\n",
            "Step [48520/60000], d_real_loss: 0.0913, d_mnist_loss: 0.0101, d_svhn_loss: 0.0812, d_fake_loss: 0.1145, g_loss: 1.1195\n",
            "Step [48530/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0130, d_svhn_loss: 0.0232, d_fake_loss: 0.0306, g_loss: 1.0101\n",
            "Step [48540/60000], d_real_loss: 0.0705, d_mnist_loss: 0.0160, d_svhn_loss: 0.0544, d_fake_loss: 0.0205, g_loss: 1.1659\n",
            "Step [48550/60000], d_real_loss: 0.0755, d_mnist_loss: 0.0423, d_svhn_loss: 0.0332, d_fake_loss: 0.0179, g_loss: 0.9718\n",
            "Step [48560/60000], d_real_loss: 0.0555, d_mnist_loss: 0.0134, d_svhn_loss: 0.0421, d_fake_loss: 0.0873, g_loss: 1.2558\n",
            "Step [48570/60000], d_real_loss: 0.0296, d_mnist_loss: 0.0170, d_svhn_loss: 0.0126, d_fake_loss: 0.0366, g_loss: 1.1178\n",
            "Step [48580/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0146, d_svhn_loss: 0.0384, d_fake_loss: 0.0237, g_loss: 1.3470\n",
            "Step [48590/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0114, d_svhn_loss: 0.0288, d_fake_loss: 0.0636, g_loss: 1.0323\n",
            "Step [48600/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0077, d_svhn_loss: 0.0269, d_fake_loss: 0.0502, g_loss: 1.3255\n",
            "Step [48610/60000], d_real_loss: 0.0518, d_mnist_loss: 0.0137, d_svhn_loss: 0.0381, d_fake_loss: 0.1048, g_loss: 1.1416\n",
            "Step [48620/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0230, d_svhn_loss: 0.0131, d_fake_loss: 0.0334, g_loss: 1.0848\n",
            "Step [48630/60000], d_real_loss: 0.0902, d_mnist_loss: 0.0067, d_svhn_loss: 0.0835, d_fake_loss: 0.0230, g_loss: 1.0881\n",
            "Step [48640/60000], d_real_loss: 0.0258, d_mnist_loss: 0.0126, d_svhn_loss: 0.0132, d_fake_loss: 0.0565, g_loss: 1.0902\n",
            "Step [48650/60000], d_real_loss: 0.0370, d_mnist_loss: 0.0186, d_svhn_loss: 0.0184, d_fake_loss: 0.0328, g_loss: 1.0841\n",
            "Step [48660/60000], d_real_loss: 0.0753, d_mnist_loss: 0.0244, d_svhn_loss: 0.0509, d_fake_loss: 0.0757, g_loss: 0.9893\n",
            "Step [48670/60000], d_real_loss: 0.0490, d_mnist_loss: 0.0150, d_svhn_loss: 0.0340, d_fake_loss: 0.0287, g_loss: 1.0634\n",
            "Step [48680/60000], d_real_loss: 0.1065, d_mnist_loss: 0.0370, d_svhn_loss: 0.0695, d_fake_loss: 0.0207, g_loss: 1.0280\n",
            "Step [48690/60000], d_real_loss: 0.1200, d_mnist_loss: 0.0753, d_svhn_loss: 0.0447, d_fake_loss: 0.0276, g_loss: 1.0352\n",
            "Step [48700/60000], d_real_loss: 0.0251, d_mnist_loss: 0.0076, d_svhn_loss: 0.0175, d_fake_loss: 0.0784, g_loss: 0.9841\n",
            "Step [48710/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0158, d_svhn_loss: 0.0196, d_fake_loss: 0.0382, g_loss: 0.9632\n",
            "Step [48720/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0102, d_svhn_loss: 0.0239, d_fake_loss: 0.0886, g_loss: 1.1000\n",
            "Step [48730/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0192, d_svhn_loss: 0.0161, d_fake_loss: 0.1079, g_loss: 1.0165\n",
            "Step [48740/60000], d_real_loss: 0.1647, d_mnist_loss: 0.0574, d_svhn_loss: 0.1073, d_fake_loss: 0.0435, g_loss: 1.1070\n",
            "Step [48750/60000], d_real_loss: 0.0830, d_mnist_loss: 0.0680, d_svhn_loss: 0.0150, d_fake_loss: 0.1991, g_loss: 1.0513\n",
            "Step [48760/60000], d_real_loss: 0.0650, d_mnist_loss: 0.0256, d_svhn_loss: 0.0394, d_fake_loss: 0.1381, g_loss: 1.2637\n",
            "Step [48770/60000], d_real_loss: 0.0714, d_mnist_loss: 0.0084, d_svhn_loss: 0.0630, d_fake_loss: 0.0736, g_loss: 1.0906\n",
            "Step [48780/60000], d_real_loss: 0.0821, d_mnist_loss: 0.0605, d_svhn_loss: 0.0215, d_fake_loss: 0.0233, g_loss: 1.1269\n",
            "Step [48790/60000], d_real_loss: 0.0353, d_mnist_loss: 0.0085, d_svhn_loss: 0.0268, d_fake_loss: 0.0656, g_loss: 1.0142\n",
            "Step [48800/60000], d_real_loss: 0.0245, d_mnist_loss: 0.0085, d_svhn_loss: 0.0161, d_fake_loss: 0.0539, g_loss: 1.1394\n",
            "Step [48810/60000], d_real_loss: 0.0413, d_mnist_loss: 0.0237, d_svhn_loss: 0.0176, d_fake_loss: 0.0966, g_loss: 1.0196\n",
            "Step [48820/60000], d_real_loss: 0.0291, d_mnist_loss: 0.0096, d_svhn_loss: 0.0195, d_fake_loss: 0.0244, g_loss: 1.2707\n",
            "Step [48830/60000], d_real_loss: 0.0527, d_mnist_loss: 0.0393, d_svhn_loss: 0.0134, d_fake_loss: 0.0632, g_loss: 1.3241\n",
            "Step [48840/60000], d_real_loss: 0.0242, d_mnist_loss: 0.0070, d_svhn_loss: 0.0172, d_fake_loss: 0.0534, g_loss: 1.1765\n",
            "Step [48850/60000], d_real_loss: 0.0340, d_mnist_loss: 0.0090, d_svhn_loss: 0.0250, d_fake_loss: 0.0556, g_loss: 1.3519\n",
            "Step [48860/60000], d_real_loss: 0.0386, d_mnist_loss: 0.0093, d_svhn_loss: 0.0293, d_fake_loss: 0.0188, g_loss: 1.0902\n",
            "Step [48870/60000], d_real_loss: 0.0254, d_mnist_loss: 0.0091, d_svhn_loss: 0.0164, d_fake_loss: 0.0366, g_loss: 0.9867\n",
            "Step [48880/60000], d_real_loss: 0.0552, d_mnist_loss: 0.0423, d_svhn_loss: 0.0129, d_fake_loss: 0.0451, g_loss: 1.1960\n",
            "Step [48890/60000], d_real_loss: 0.0871, d_mnist_loss: 0.0270, d_svhn_loss: 0.0601, d_fake_loss: 0.1093, g_loss: 1.2417\n",
            "Step [48900/60000], d_real_loss: 0.0458, d_mnist_loss: 0.0066, d_svhn_loss: 0.0392, d_fake_loss: 0.0604, g_loss: 1.0811\n",
            "Step [48910/60000], d_real_loss: 0.0634, d_mnist_loss: 0.0082, d_svhn_loss: 0.0551, d_fake_loss: 0.0560, g_loss: 1.1797\n",
            "Step [48920/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0216, d_svhn_loss: 0.0242, d_fake_loss: 0.0582, g_loss: 1.1141\n",
            "Step [48930/60000], d_real_loss: 0.0742, d_mnist_loss: 0.0236, d_svhn_loss: 0.0506, d_fake_loss: 0.0365, g_loss: 1.1809\n",
            "Step [48940/60000], d_real_loss: 0.0624, d_mnist_loss: 0.0218, d_svhn_loss: 0.0406, d_fake_loss: 0.0979, g_loss: 0.8271\n",
            "Step [48950/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0143, d_svhn_loss: 0.0297, d_fake_loss: 0.0420, g_loss: 1.1214\n",
            "Step [48960/60000], d_real_loss: 0.0269, d_mnist_loss: 0.0071, d_svhn_loss: 0.0198, d_fake_loss: 0.0475, g_loss: 1.2393\n",
            "Step [48970/60000], d_real_loss: 0.0361, d_mnist_loss: 0.0135, d_svhn_loss: 0.0226, d_fake_loss: 0.0368, g_loss: 1.1128\n",
            "Step [48980/60000], d_real_loss: 0.1080, d_mnist_loss: 0.0238, d_svhn_loss: 0.0842, d_fake_loss: 0.1162, g_loss: 1.2917\n",
            "Step [48990/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0140, d_svhn_loss: 0.0170, d_fake_loss: 0.0631, g_loss: 1.1338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [49000/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0204, d_svhn_loss: 0.0272, d_fake_loss: 0.0788, g_loss: 1.1949\n",
            "saved ./samples_fashion/sample-49000-m-s.png\n",
            "saved ./samples_fashion/sample-49000-s-m.png\n",
            "Step [49010/60000], d_real_loss: 0.0466, d_mnist_loss: 0.0236, d_svhn_loss: 0.0229, d_fake_loss: 0.0693, g_loss: 1.2469\n",
            "Step [49020/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0139, d_svhn_loss: 0.0175, d_fake_loss: 0.0317, g_loss: 1.2780\n",
            "Step [49030/60000], d_real_loss: 0.0519, d_mnist_loss: 0.0083, d_svhn_loss: 0.0436, d_fake_loss: 0.1649, g_loss: 1.1031\n",
            "Step [49040/60000], d_real_loss: 0.0570, d_mnist_loss: 0.0195, d_svhn_loss: 0.0375, d_fake_loss: 0.0336, g_loss: 1.1244\n",
            "Step [49050/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0162, d_svhn_loss: 0.0197, d_fake_loss: 0.0285, g_loss: 0.9797\n",
            "Step [49060/60000], d_real_loss: 0.0343, d_mnist_loss: 0.0126, d_svhn_loss: 0.0218, d_fake_loss: 0.0969, g_loss: 1.1834\n",
            "Step [49070/60000], d_real_loss: 0.0848, d_mnist_loss: 0.0163, d_svhn_loss: 0.0685, d_fake_loss: 0.0227, g_loss: 1.1816\n",
            "Step [49080/60000], d_real_loss: 0.0794, d_mnist_loss: 0.0334, d_svhn_loss: 0.0460, d_fake_loss: 0.0197, g_loss: 1.1928\n",
            "Step [49090/60000], d_real_loss: 0.0621, d_mnist_loss: 0.0193, d_svhn_loss: 0.0427, d_fake_loss: 0.0332, g_loss: 1.1444\n",
            "Step [49100/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0099, d_svhn_loss: 0.0273, d_fake_loss: 0.0439, g_loss: 1.2270\n",
            "Step [49110/60000], d_real_loss: 0.1621, d_mnist_loss: 0.0403, d_svhn_loss: 0.1218, d_fake_loss: 0.0377, g_loss: 1.4190\n",
            "Step [49120/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0231, d_svhn_loss: 0.0220, d_fake_loss: 0.0209, g_loss: 1.1616\n",
            "Step [49130/60000], d_real_loss: 0.0520, d_mnist_loss: 0.0201, d_svhn_loss: 0.0319, d_fake_loss: 0.0305, g_loss: 1.1523\n",
            "Step [49140/60000], d_real_loss: 0.0438, d_mnist_loss: 0.0168, d_svhn_loss: 0.0270, d_fake_loss: 0.0179, g_loss: 1.1696\n",
            "Step [49150/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0102, d_svhn_loss: 0.0273, d_fake_loss: 0.0909, g_loss: 1.2045\n",
            "Step [49160/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0067, d_svhn_loss: 0.0370, d_fake_loss: 0.0240, g_loss: 1.1527\n",
            "Step [49170/60000], d_real_loss: 0.0261, d_mnist_loss: 0.0061, d_svhn_loss: 0.0200, d_fake_loss: 0.0517, g_loss: 1.1086\n",
            "Step [49180/60000], d_real_loss: 0.0256, d_mnist_loss: 0.0080, d_svhn_loss: 0.0176, d_fake_loss: 0.0395, g_loss: 1.0518\n",
            "Step [49190/60000], d_real_loss: 0.0446, d_mnist_loss: 0.0098, d_svhn_loss: 0.0348, d_fake_loss: 0.0400, g_loss: 0.9448\n",
            "Step [49200/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0227, d_svhn_loss: 0.0133, d_fake_loss: 0.0281, g_loss: 1.1141\n",
            "Step [49210/60000], d_real_loss: 0.0273, d_mnist_loss: 0.0067, d_svhn_loss: 0.0206, d_fake_loss: 0.0946, g_loss: 1.2031\n",
            "Step [49220/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0095, d_svhn_loss: 0.0321, d_fake_loss: 0.0437, g_loss: 1.1799\n",
            "Step [49230/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0078, d_svhn_loss: 0.0318, d_fake_loss: 0.0438, g_loss: 1.1808\n",
            "Step [49240/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0102, d_svhn_loss: 0.0258, d_fake_loss: 0.0270, g_loss: 1.1554\n",
            "Step [49250/60000], d_real_loss: 0.1013, d_mnist_loss: 0.0109, d_svhn_loss: 0.0905, d_fake_loss: 0.0664, g_loss: 1.0245\n",
            "Step [49260/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0116, d_svhn_loss: 0.0231, d_fake_loss: 0.0858, g_loss: 1.0777\n",
            "Step [49270/60000], d_real_loss: 0.0831, d_mnist_loss: 0.0405, d_svhn_loss: 0.0426, d_fake_loss: 0.3168, g_loss: 0.6256\n",
            "Step [49280/60000], d_real_loss: 0.0297, d_mnist_loss: 0.0119, d_svhn_loss: 0.0178, d_fake_loss: 0.1445, g_loss: 1.1847\n",
            "Step [49290/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0117, d_svhn_loss: 0.0290, d_fake_loss: 0.0304, g_loss: 1.0308\n",
            "Step [49300/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0188, d_svhn_loss: 0.0211, d_fake_loss: 0.0581, g_loss: 1.0886\n",
            "Step [49310/60000], d_real_loss: 0.0854, d_mnist_loss: 0.0207, d_svhn_loss: 0.0646, d_fake_loss: 0.0319, g_loss: 1.0655\n",
            "Step [49320/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0425, d_svhn_loss: 0.0167, d_fake_loss: 0.2213, g_loss: 1.0708\n",
            "Step [49330/60000], d_real_loss: 0.0949, d_mnist_loss: 0.0067, d_svhn_loss: 0.0882, d_fake_loss: 0.1051, g_loss: 1.1674\n",
            "Step [49340/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0168, d_svhn_loss: 0.0158, d_fake_loss: 0.0567, g_loss: 0.9100\n",
            "Step [49350/60000], d_real_loss: 0.0603, d_mnist_loss: 0.0400, d_svhn_loss: 0.0202, d_fake_loss: 0.0855, g_loss: 1.1838\n",
            "Step [49360/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0133, d_svhn_loss: 0.0274, d_fake_loss: 0.0185, g_loss: 1.1450\n",
            "Step [49370/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0080, d_svhn_loss: 0.0229, d_fake_loss: 0.0205, g_loss: 1.1766\n",
            "Step [49380/60000], d_real_loss: 0.0735, d_mnist_loss: 0.0234, d_svhn_loss: 0.0501, d_fake_loss: 0.0271, g_loss: 1.1270\n",
            "Step [49390/60000], d_real_loss: 0.0272, d_mnist_loss: 0.0087, d_svhn_loss: 0.0185, d_fake_loss: 0.0355, g_loss: 1.0976\n",
            "Step [49400/60000], d_real_loss: 0.0312, d_mnist_loss: 0.0135, d_svhn_loss: 0.0177, d_fake_loss: 0.0513, g_loss: 1.1322\n",
            "Step [49410/60000], d_real_loss: 0.0465, d_mnist_loss: 0.0119, d_svhn_loss: 0.0345, d_fake_loss: 0.0259, g_loss: 1.0784\n",
            "Step [49420/60000], d_real_loss: 0.0921, d_mnist_loss: 0.0075, d_svhn_loss: 0.0845, d_fake_loss: 0.0406, g_loss: 1.0710\n",
            "Step [49430/60000], d_real_loss: 0.0297, d_mnist_loss: 0.0091, d_svhn_loss: 0.0206, d_fake_loss: 0.1478, g_loss: 1.3426\n",
            "Step [49440/60000], d_real_loss: 0.1324, d_mnist_loss: 0.0122, d_svhn_loss: 0.1202, d_fake_loss: 0.0465, g_loss: 1.1793\n",
            "Step [49450/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0125, d_svhn_loss: 0.0206, d_fake_loss: 0.0345, g_loss: 1.1590\n",
            "Step [49460/60000], d_real_loss: 0.0214, d_mnist_loss: 0.0076, d_svhn_loss: 0.0138, d_fake_loss: 0.0226, g_loss: 1.1821\n",
            "Step [49470/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0103, d_svhn_loss: 0.0175, d_fake_loss: 0.0170, g_loss: 1.1339\n",
            "Step [49480/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0091, d_svhn_loss: 0.0210, d_fake_loss: 0.0142, g_loss: 1.1533\n",
            "Step [49490/60000], d_real_loss: 0.1166, d_mnist_loss: 0.0094, d_svhn_loss: 0.1073, d_fake_loss: 0.0365, g_loss: 1.1550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [49500/60000], d_real_loss: 0.0453, d_mnist_loss: 0.0242, d_svhn_loss: 0.0211, d_fake_loss: 0.0249, g_loss: 1.0687\n",
            "saved ./samples_fashion/sample-49500-m-s.png\n",
            "saved ./samples_fashion/sample-49500-s-m.png\n",
            "Step [49510/60000], d_real_loss: 0.0717, d_mnist_loss: 0.0483, d_svhn_loss: 0.0234, d_fake_loss: 0.0200, g_loss: 1.1299\n",
            "Step [49520/60000], d_real_loss: 0.0760, d_mnist_loss: 0.0093, d_svhn_loss: 0.0666, d_fake_loss: 0.1544, g_loss: 1.1586\n",
            "Step [49530/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0227, d_svhn_loss: 0.0323, d_fake_loss: 0.0695, g_loss: 1.4115\n",
            "Step [49540/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0116, d_svhn_loss: 0.0419, d_fake_loss: 0.0386, g_loss: 1.1520\n",
            "Step [49550/60000], d_real_loss: 0.0538, d_mnist_loss: 0.0222, d_svhn_loss: 0.0316, d_fake_loss: 0.0518, g_loss: 1.1623\n",
            "Step [49560/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0108, d_svhn_loss: 0.0233, d_fake_loss: 0.0182, g_loss: 1.1776\n",
            "Step [49570/60000], d_real_loss: 0.0329, d_mnist_loss: 0.0129, d_svhn_loss: 0.0200, d_fake_loss: 0.0769, g_loss: 1.1782\n",
            "Step [49580/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0093, d_svhn_loss: 0.0423, d_fake_loss: 0.0378, g_loss: 1.3274\n",
            "Step [49590/60000], d_real_loss: 0.0286, d_mnist_loss: 0.0072, d_svhn_loss: 0.0215, d_fake_loss: 0.0260, g_loss: 1.1099\n",
            "Step [49600/60000], d_real_loss: 0.0892, d_mnist_loss: 0.0245, d_svhn_loss: 0.0646, d_fake_loss: 0.0208, g_loss: 1.1709\n",
            "Step [49610/60000], d_real_loss: 0.0886, d_mnist_loss: 0.0610, d_svhn_loss: 0.0276, d_fake_loss: 0.1613, g_loss: 1.1874\n",
            "Step [49620/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0099, d_svhn_loss: 0.0194, d_fake_loss: 0.0620, g_loss: 1.1671\n",
            "Step [49630/60000], d_real_loss: 0.1179, d_mnist_loss: 0.0122, d_svhn_loss: 0.1057, d_fake_loss: 0.2291, g_loss: 1.1146\n",
            "Step [49640/60000], d_real_loss: 0.0522, d_mnist_loss: 0.0078, d_svhn_loss: 0.0443, d_fake_loss: 0.0614, g_loss: 1.0240\n",
            "Step [49650/60000], d_real_loss: 0.0339, d_mnist_loss: 0.0097, d_svhn_loss: 0.0242, d_fake_loss: 0.2158, g_loss: 1.6090\n",
            "Step [49660/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0146, d_svhn_loss: 0.0419, d_fake_loss: 0.0200, g_loss: 1.0627\n",
            "Step [49670/60000], d_real_loss: 0.0454, d_mnist_loss: 0.0153, d_svhn_loss: 0.0301, d_fake_loss: 0.0445, g_loss: 1.0241\n",
            "Step [49680/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0092, d_svhn_loss: 0.0312, d_fake_loss: 0.0479, g_loss: 1.3051\n",
            "Step [49690/60000], d_real_loss: 0.0201, d_mnist_loss: 0.0078, d_svhn_loss: 0.0124, d_fake_loss: 0.0280, g_loss: 1.1969\n",
            "Step [49700/60000], d_real_loss: 0.0228, d_mnist_loss: 0.0107, d_svhn_loss: 0.0122, d_fake_loss: 0.1262, g_loss: 0.8873\n",
            "Step [49710/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0413, d_svhn_loss: 0.0252, d_fake_loss: 0.0732, g_loss: 1.6181\n",
            "Step [49720/60000], d_real_loss: 0.0244, d_mnist_loss: 0.0108, d_svhn_loss: 0.0137, d_fake_loss: 0.0249, g_loss: 1.1736\n",
            "Step [49730/60000], d_real_loss: 0.0244, d_mnist_loss: 0.0096, d_svhn_loss: 0.0148, d_fake_loss: 0.0617, g_loss: 1.2222\n",
            "Step [49740/60000], d_real_loss: 0.0231, d_mnist_loss: 0.0114, d_svhn_loss: 0.0118, d_fake_loss: 0.0243, g_loss: 1.1344\n",
            "Step [49750/60000], d_real_loss: 0.0704, d_mnist_loss: 0.0294, d_svhn_loss: 0.0410, d_fake_loss: 0.0640, g_loss: 1.0872\n",
            "Step [49760/60000], d_real_loss: 0.0703, d_mnist_loss: 0.0416, d_svhn_loss: 0.0287, d_fake_loss: 0.0525, g_loss: 0.9916\n",
            "Step [49770/60000], d_real_loss: 0.0492, d_mnist_loss: 0.0260, d_svhn_loss: 0.0232, d_fake_loss: 0.0395, g_loss: 1.1109\n",
            "Step [49780/60000], d_real_loss: 0.0283, d_mnist_loss: 0.0114, d_svhn_loss: 0.0169, d_fake_loss: 0.0178, g_loss: 1.2000\n",
            "Step [49790/60000], d_real_loss: 0.0211, d_mnist_loss: 0.0085, d_svhn_loss: 0.0126, d_fake_loss: 0.0406, g_loss: 1.1145\n",
            "Step [49800/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0210, d_svhn_loss: 0.0188, d_fake_loss: 0.0162, g_loss: 1.0475\n",
            "Step [49810/60000], d_real_loss: 0.0647, d_mnist_loss: 0.0074, d_svhn_loss: 0.0573, d_fake_loss: 0.2251, g_loss: 1.2190\n",
            "Step [49820/60000], d_real_loss: 0.1174, d_mnist_loss: 0.0065, d_svhn_loss: 0.1109, d_fake_loss: 0.0297, g_loss: 1.0841\n",
            "Step [49830/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0127, d_svhn_loss: 0.0266, d_fake_loss: 0.0364, g_loss: 1.1293\n",
            "Step [49840/60000], d_real_loss: 0.0508, d_mnist_loss: 0.0087, d_svhn_loss: 0.0421, d_fake_loss: 0.0422, g_loss: 1.2102\n",
            "Step [49850/60000], d_real_loss: 0.0485, d_mnist_loss: 0.0181, d_svhn_loss: 0.0304, d_fake_loss: 0.0230, g_loss: 0.8098\n",
            "Step [49860/60000], d_real_loss: 0.0520, d_mnist_loss: 0.0179, d_svhn_loss: 0.0341, d_fake_loss: 0.0488, g_loss: 1.2019\n",
            "Step [49870/60000], d_real_loss: 0.0571, d_mnist_loss: 0.0315, d_svhn_loss: 0.0256, d_fake_loss: 0.0266, g_loss: 0.9948\n",
            "Step [49880/60000], d_real_loss: 0.0551, d_mnist_loss: 0.0196, d_svhn_loss: 0.0355, d_fake_loss: 0.0195, g_loss: 1.0537\n",
            "Step [49890/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0106, d_svhn_loss: 0.0370, d_fake_loss: 0.0388, g_loss: 0.9801\n",
            "Step [49900/60000], d_real_loss: 0.0355, d_mnist_loss: 0.0116, d_svhn_loss: 0.0239, d_fake_loss: 0.0294, g_loss: 1.0583\n",
            "Step [49910/60000], d_real_loss: 0.0520, d_mnist_loss: 0.0148, d_svhn_loss: 0.0371, d_fake_loss: 0.0970, g_loss: 1.3416\n",
            "Step [49920/60000], d_real_loss: 0.0260, d_mnist_loss: 0.0110, d_svhn_loss: 0.0149, d_fake_loss: 0.1160, g_loss: 0.9517\n",
            "Step [49930/60000], d_real_loss: 0.0730, d_mnist_loss: 0.0085, d_svhn_loss: 0.0645, d_fake_loss: 0.1061, g_loss: 1.0459\n",
            "Step [49940/60000], d_real_loss: 0.1150, d_mnist_loss: 0.0094, d_svhn_loss: 0.1057, d_fake_loss: 0.0422, g_loss: 1.1541\n",
            "Step [49950/60000], d_real_loss: 0.0424, d_mnist_loss: 0.0173, d_svhn_loss: 0.0251, d_fake_loss: 0.0431, g_loss: 1.1385\n",
            "Step [49960/60000], d_real_loss: 0.2004, d_mnist_loss: 0.0071, d_svhn_loss: 0.1933, d_fake_loss: 0.0751, g_loss: 1.1840\n",
            "Step [49970/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0247, d_svhn_loss: 0.0153, d_fake_loss: 0.0572, g_loss: 1.0532\n",
            "Step [49980/60000], d_real_loss: 0.0420, d_mnist_loss: 0.0244, d_svhn_loss: 0.0175, d_fake_loss: 0.0216, g_loss: 1.1772\n",
            "Step [49990/60000], d_real_loss: 0.0291, d_mnist_loss: 0.0125, d_svhn_loss: 0.0166, d_fake_loss: 0.0507, g_loss: 1.0996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [50000/60000], d_real_loss: 0.0290, d_mnist_loss: 0.0088, d_svhn_loss: 0.0203, d_fake_loss: 0.0577, g_loss: 1.1664\n",
            "saved ./samples_fashion/sample-50000-m-s.png\n",
            "saved ./samples_fashion/sample-50000-s-m.png\n",
            "Step [50010/60000], d_real_loss: 0.0542, d_mnist_loss: 0.0252, d_svhn_loss: 0.0291, d_fake_loss: 0.0653, g_loss: 0.9566\n",
            "Step [50020/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0094, d_svhn_loss: 0.0168, d_fake_loss: 0.0564, g_loss: 1.0432\n",
            "Step [50030/60000], d_real_loss: 0.0960, d_mnist_loss: 0.0106, d_svhn_loss: 0.0854, d_fake_loss: 0.0757, g_loss: 1.1077\n",
            "Step [50040/60000], d_real_loss: 0.0546, d_mnist_loss: 0.0134, d_svhn_loss: 0.0412, d_fake_loss: 0.1484, g_loss: 1.1735\n",
            "Step [50050/60000], d_real_loss: 0.0751, d_mnist_loss: 0.0062, d_svhn_loss: 0.0689, d_fake_loss: 0.0844, g_loss: 1.1360\n",
            "Step [50060/60000], d_real_loss: 0.0211, d_mnist_loss: 0.0052, d_svhn_loss: 0.0159, d_fake_loss: 0.0888, g_loss: 1.4535\n",
            "Step [50070/60000], d_real_loss: 0.0425, d_mnist_loss: 0.0278, d_svhn_loss: 0.0147, d_fake_loss: 0.0238, g_loss: 1.2341\n",
            "Step [50080/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0092, d_svhn_loss: 0.0259, d_fake_loss: 0.0276, g_loss: 1.0186\n",
            "Step [50090/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0120, d_svhn_loss: 0.0128, d_fake_loss: 0.0135, g_loss: 1.1285\n",
            "Step [50100/60000], d_real_loss: 0.0473, d_mnist_loss: 0.0160, d_svhn_loss: 0.0314, d_fake_loss: 0.0597, g_loss: 1.1249\n",
            "Step [50110/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0085, d_svhn_loss: 0.0155, d_fake_loss: 0.0391, g_loss: 1.1802\n",
            "Step [50120/60000], d_real_loss: 0.0317, d_mnist_loss: 0.0081, d_svhn_loss: 0.0236, d_fake_loss: 0.0247, g_loss: 1.2507\n",
            "Step [50130/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0225, d_svhn_loss: 0.0138, d_fake_loss: 0.0308, g_loss: 0.9810\n",
            "Step [50140/60000], d_real_loss: 0.0641, d_mnist_loss: 0.0096, d_svhn_loss: 0.0545, d_fake_loss: 0.0621, g_loss: 1.0463\n",
            "Step [50150/60000], d_real_loss: 0.0715, d_mnist_loss: 0.0147, d_svhn_loss: 0.0568, d_fake_loss: 0.0189, g_loss: 1.0477\n",
            "Step [50160/60000], d_real_loss: 0.1094, d_mnist_loss: 0.0536, d_svhn_loss: 0.0558, d_fake_loss: 0.0315, g_loss: 1.3678\n",
            "Step [50170/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0139, d_svhn_loss: 0.0180, d_fake_loss: 0.0156, g_loss: 1.2700\n",
            "Step [50180/60000], d_real_loss: 0.0522, d_mnist_loss: 0.0141, d_svhn_loss: 0.0381, d_fake_loss: 0.0829, g_loss: 1.0080\n",
            "Step [50190/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0113, d_svhn_loss: 0.0262, d_fake_loss: 0.0581, g_loss: 1.0880\n",
            "Step [50200/60000], d_real_loss: 0.0483, d_mnist_loss: 0.0074, d_svhn_loss: 0.0409, d_fake_loss: 0.0645, g_loss: 1.3490\n",
            "Step [50210/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0211, d_svhn_loss: 0.0352, d_fake_loss: 0.0325, g_loss: 1.0788\n",
            "Step [50220/60000], d_real_loss: 0.0574, d_mnist_loss: 0.0370, d_svhn_loss: 0.0204, d_fake_loss: 0.1602, g_loss: 0.9816\n",
            "Step [50230/60000], d_real_loss: 0.0271, d_mnist_loss: 0.0125, d_svhn_loss: 0.0145, d_fake_loss: 0.0252, g_loss: 1.1718\n",
            "Step [50240/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0141, d_svhn_loss: 0.0248, d_fake_loss: 0.0247, g_loss: 1.2191\n",
            "Step [50250/60000], d_real_loss: 0.0331, d_mnist_loss: 0.0097, d_svhn_loss: 0.0234, d_fake_loss: 0.0280, g_loss: 1.0906\n",
            "Step [50260/60000], d_real_loss: 0.0940, d_mnist_loss: 0.0217, d_svhn_loss: 0.0723, d_fake_loss: 0.0250, g_loss: 0.9461\n",
            "Step [50270/60000], d_real_loss: 0.0278, d_mnist_loss: 0.0164, d_svhn_loss: 0.0114, d_fake_loss: 0.0154, g_loss: 1.2175\n",
            "Step [50280/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0090, d_svhn_loss: 0.0262, d_fake_loss: 0.0163, g_loss: 1.1194\n",
            "Step [50290/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0091, d_svhn_loss: 0.0328, d_fake_loss: 0.0318, g_loss: 1.1578\n",
            "Step [50300/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0072, d_svhn_loss: 0.0229, d_fake_loss: 0.0193, g_loss: 1.2128\n",
            "Step [50310/60000], d_real_loss: 0.0704, d_mnist_loss: 0.0434, d_svhn_loss: 0.0269, d_fake_loss: 0.0333, g_loss: 1.2199\n",
            "Step [50320/60000], d_real_loss: 0.0922, d_mnist_loss: 0.0121, d_svhn_loss: 0.0801, d_fake_loss: 0.0561, g_loss: 1.2158\n",
            "Step [50330/60000], d_real_loss: 0.0626, d_mnist_loss: 0.0429, d_svhn_loss: 0.0197, d_fake_loss: 0.0552, g_loss: 1.1880\n",
            "Step [50340/60000], d_real_loss: 0.0552, d_mnist_loss: 0.0295, d_svhn_loss: 0.0257, d_fake_loss: 0.0278, g_loss: 1.1365\n",
            "Step [50350/60000], d_real_loss: 0.0464, d_mnist_loss: 0.0267, d_svhn_loss: 0.0197, d_fake_loss: 0.0176, g_loss: 1.1280\n",
            "Step [50360/60000], d_real_loss: 0.0220, d_mnist_loss: 0.0082, d_svhn_loss: 0.0139, d_fake_loss: 0.0905, g_loss: 1.1820\n",
            "Step [50370/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0171, d_svhn_loss: 0.0189, d_fake_loss: 0.0974, g_loss: 0.8757\n",
            "Step [50380/60000], d_real_loss: 0.0669, d_mnist_loss: 0.0156, d_svhn_loss: 0.0512, d_fake_loss: 0.2069, g_loss: 1.2034\n",
            "Step [50390/60000], d_real_loss: 0.0732, d_mnist_loss: 0.0148, d_svhn_loss: 0.0583, d_fake_loss: 0.0517, g_loss: 1.2073\n",
            "Step [50400/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0138, d_svhn_loss: 0.0318, d_fake_loss: 0.0750, g_loss: 0.9930\n",
            "Step [50410/60000], d_real_loss: 0.0519, d_mnist_loss: 0.0056, d_svhn_loss: 0.0463, d_fake_loss: 0.0414, g_loss: 1.0098\n",
            "Step [50420/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0093, d_svhn_loss: 0.0211, d_fake_loss: 0.0305, g_loss: 1.0872\n",
            "Step [50430/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0128, d_svhn_loss: 0.0229, d_fake_loss: 0.0271, g_loss: 1.3471\n",
            "Step [50440/60000], d_real_loss: 0.1605, d_mnist_loss: 0.0066, d_svhn_loss: 0.1540, d_fake_loss: 0.0563, g_loss: 1.1729\n",
            "Step [50450/60000], d_real_loss: 0.0263, d_mnist_loss: 0.0075, d_svhn_loss: 0.0189, d_fake_loss: 0.0460, g_loss: 1.2711\n",
            "Step [50460/60000], d_real_loss: 0.0388, d_mnist_loss: 0.0106, d_svhn_loss: 0.0282, d_fake_loss: 0.0619, g_loss: 1.2417\n",
            "Step [50470/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0102, d_svhn_loss: 0.0299, d_fake_loss: 0.0299, g_loss: 1.2670\n",
            "Step [50480/60000], d_real_loss: 0.0505, d_mnist_loss: 0.0130, d_svhn_loss: 0.0375, d_fake_loss: 0.0869, g_loss: 1.1755\n",
            "Step [50490/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0134, d_svhn_loss: 0.0175, d_fake_loss: 0.0444, g_loss: 0.9914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [50500/60000], d_real_loss: 0.0945, d_mnist_loss: 0.0219, d_svhn_loss: 0.0726, d_fake_loss: 0.0504, g_loss: 1.3385\n",
            "saved ./samples_fashion/sample-50500-m-s.png\n",
            "saved ./samples_fashion/sample-50500-s-m.png\n",
            "Step [50510/60000], d_real_loss: 0.0258, d_mnist_loss: 0.0058, d_svhn_loss: 0.0200, d_fake_loss: 0.0517, g_loss: 1.2795\n",
            "Step [50520/60000], d_real_loss: 0.0274, d_mnist_loss: 0.0066, d_svhn_loss: 0.0208, d_fake_loss: 0.0400, g_loss: 1.1504\n",
            "Step [50530/60000], d_real_loss: 0.0447, d_mnist_loss: 0.0147, d_svhn_loss: 0.0300, d_fake_loss: 0.0572, g_loss: 1.1665\n",
            "Step [50540/60000], d_real_loss: 0.0444, d_mnist_loss: 0.0235, d_svhn_loss: 0.0210, d_fake_loss: 0.0549, g_loss: 1.5338\n",
            "Step [50550/60000], d_real_loss: 0.0916, d_mnist_loss: 0.0106, d_svhn_loss: 0.0810, d_fake_loss: 0.0707, g_loss: 1.1518\n",
            "Step [50560/60000], d_real_loss: 0.0559, d_mnist_loss: 0.0149, d_svhn_loss: 0.0410, d_fake_loss: 0.0802, g_loss: 1.3637\n",
            "Step [50570/60000], d_real_loss: 0.0336, d_mnist_loss: 0.0056, d_svhn_loss: 0.0280, d_fake_loss: 0.0394, g_loss: 1.2046\n",
            "Step [50580/60000], d_real_loss: 0.1227, d_mnist_loss: 0.0224, d_svhn_loss: 0.1002, d_fake_loss: 0.0359, g_loss: 1.0373\n",
            "Step [50590/60000], d_real_loss: 0.0242, d_mnist_loss: 0.0082, d_svhn_loss: 0.0160, d_fake_loss: 0.0307, g_loss: 1.2203\n",
            "Step [50600/60000], d_real_loss: 0.0949, d_mnist_loss: 0.0602, d_svhn_loss: 0.0347, d_fake_loss: 0.0350, g_loss: 1.2774\n",
            "Step [50610/60000], d_real_loss: 0.0833, d_mnist_loss: 0.0147, d_svhn_loss: 0.0686, d_fake_loss: 0.0151, g_loss: 1.1518\n",
            "Step [50620/60000], d_real_loss: 0.0488, d_mnist_loss: 0.0151, d_svhn_loss: 0.0337, d_fake_loss: 0.1490, g_loss: 0.6733\n",
            "Step [50630/60000], d_real_loss: 0.0949, d_mnist_loss: 0.0105, d_svhn_loss: 0.0844, d_fake_loss: 0.0828, g_loss: 0.9652\n",
            "Step [50640/60000], d_real_loss: 0.0489, d_mnist_loss: 0.0117, d_svhn_loss: 0.0372, d_fake_loss: 0.0435, g_loss: 1.2300\n",
            "Step [50650/60000], d_real_loss: 0.1026, d_mnist_loss: 0.0229, d_svhn_loss: 0.0796, d_fake_loss: 0.0341, g_loss: 1.0514\n",
            "Step [50660/60000], d_real_loss: 0.0366, d_mnist_loss: 0.0118, d_svhn_loss: 0.0248, d_fake_loss: 0.0514, g_loss: 1.1236\n",
            "Step [50670/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0060, d_svhn_loss: 0.0281, d_fake_loss: 0.0346, g_loss: 1.1458\n",
            "Step [50680/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0119, d_svhn_loss: 0.0256, d_fake_loss: 0.0950, g_loss: 1.3299\n",
            "Step [50690/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0314, d_svhn_loss: 0.0105, d_fake_loss: 0.0220, g_loss: 1.0908\n",
            "Step [50700/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0084, d_svhn_loss: 0.0231, d_fake_loss: 0.0143, g_loss: 1.1047\n",
            "Step [50710/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0093, d_svhn_loss: 0.0339, d_fake_loss: 0.0224, g_loss: 1.2439\n",
            "Step [50720/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0099, d_svhn_loss: 0.0242, d_fake_loss: 0.1301, g_loss: 1.2985\n",
            "Step [50730/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0056, d_svhn_loss: 0.0528, d_fake_loss: 0.0252, g_loss: 1.1152\n",
            "Step [50740/60000], d_real_loss: 0.0545, d_mnist_loss: 0.0150, d_svhn_loss: 0.0395, d_fake_loss: 0.0193, g_loss: 1.0824\n",
            "Step [50750/60000], d_real_loss: 0.0299, d_mnist_loss: 0.0148, d_svhn_loss: 0.0151, d_fake_loss: 0.0493, g_loss: 1.1934\n",
            "Step [50760/60000], d_real_loss: 0.0476, d_mnist_loss: 0.0064, d_svhn_loss: 0.0412, d_fake_loss: 0.0234, g_loss: 1.1370\n",
            "Step [50770/60000], d_real_loss: 0.0325, d_mnist_loss: 0.0127, d_svhn_loss: 0.0198, d_fake_loss: 0.0276, g_loss: 1.0167\n",
            "Step [50780/60000], d_real_loss: 0.0390, d_mnist_loss: 0.0139, d_svhn_loss: 0.0251, d_fake_loss: 0.0264, g_loss: 1.0877\n",
            "Step [50790/60000], d_real_loss: 0.0284, d_mnist_loss: 0.0096, d_svhn_loss: 0.0188, d_fake_loss: 0.0329, g_loss: 1.1640\n",
            "Step [50800/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0100, d_svhn_loss: 0.0258, d_fake_loss: 0.1080, g_loss: 0.9680\n",
            "Step [50810/60000], d_real_loss: 0.0461, d_mnist_loss: 0.0306, d_svhn_loss: 0.0156, d_fake_loss: 0.0579, g_loss: 1.3361\n",
            "Step [50820/60000], d_real_loss: 0.0627, d_mnist_loss: 0.0270, d_svhn_loss: 0.0356, d_fake_loss: 0.0912, g_loss: 1.0756\n",
            "Step [50830/60000], d_real_loss: 0.0755, d_mnist_loss: 0.0223, d_svhn_loss: 0.0532, d_fake_loss: 0.0596, g_loss: 1.2994\n",
            "Step [50840/60000], d_real_loss: 0.0239, d_mnist_loss: 0.0085, d_svhn_loss: 0.0155, d_fake_loss: 0.0301, g_loss: 1.1009\n",
            "Step [50850/60000], d_real_loss: 0.0240, d_mnist_loss: 0.0098, d_svhn_loss: 0.0142, d_fake_loss: 0.0152, g_loss: 1.2287\n",
            "Step [50860/60000], d_real_loss: 0.0244, d_mnist_loss: 0.0079, d_svhn_loss: 0.0165, d_fake_loss: 0.0236, g_loss: 1.1754\n",
            "Step [50870/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0062, d_svhn_loss: 0.0265, d_fake_loss: 0.0249, g_loss: 1.1622\n",
            "Step [50880/60000], d_real_loss: 0.0634, d_mnist_loss: 0.0135, d_svhn_loss: 0.0499, d_fake_loss: 0.2475, g_loss: 0.4097\n",
            "Step [50890/60000], d_real_loss: 0.0263, d_mnist_loss: 0.0111, d_svhn_loss: 0.0153, d_fake_loss: 0.0209, g_loss: 1.1980\n",
            "Step [50900/60000], d_real_loss: 0.0444, d_mnist_loss: 0.0089, d_svhn_loss: 0.0355, d_fake_loss: 0.0353, g_loss: 1.1151\n",
            "Step [50910/60000], d_real_loss: 0.0413, d_mnist_loss: 0.0222, d_svhn_loss: 0.0191, d_fake_loss: 0.1125, g_loss: 1.2088\n",
            "Step [50920/60000], d_real_loss: 0.0444, d_mnist_loss: 0.0125, d_svhn_loss: 0.0319, d_fake_loss: 0.0945, g_loss: 0.9944\n",
            "Step [50930/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0063, d_svhn_loss: 0.0356, d_fake_loss: 0.0250, g_loss: 1.2504\n",
            "Step [50940/60000], d_real_loss: 0.0406, d_mnist_loss: 0.0064, d_svhn_loss: 0.0341, d_fake_loss: 0.0361, g_loss: 1.2214\n",
            "Step [50950/60000], d_real_loss: 0.0722, d_mnist_loss: 0.0381, d_svhn_loss: 0.0341, d_fake_loss: 0.0403, g_loss: 1.1231\n",
            "Step [50960/60000], d_real_loss: 0.0855, d_mnist_loss: 0.0058, d_svhn_loss: 0.0797, d_fake_loss: 0.0411, g_loss: 1.0977\n",
            "Step [50970/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0145, d_svhn_loss: 0.0286, d_fake_loss: 0.0401, g_loss: 1.2636\n",
            "Step [50980/60000], d_real_loss: 0.0992, d_mnist_loss: 0.0143, d_svhn_loss: 0.0849, d_fake_loss: 0.0237, g_loss: 1.1364\n",
            "Step [50990/60000], d_real_loss: 0.0263, d_mnist_loss: 0.0117, d_svhn_loss: 0.0146, d_fake_loss: 0.0198, g_loss: 1.1592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [51000/60000], d_real_loss: 0.0786, d_mnist_loss: 0.0557, d_svhn_loss: 0.0229, d_fake_loss: 0.0942, g_loss: 1.5339\n",
            "saved ./samples_fashion/sample-51000-m-s.png\n",
            "saved ./samples_fashion/sample-51000-s-m.png\n",
            "Step [51010/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0138, d_svhn_loss: 0.0244, d_fake_loss: 0.0435, g_loss: 1.0726\n",
            "Step [51020/60000], d_real_loss: 0.0381, d_mnist_loss: 0.0094, d_svhn_loss: 0.0287, d_fake_loss: 0.0590, g_loss: 1.2726\n",
            "Step [51030/60000], d_real_loss: 0.0942, d_mnist_loss: 0.0123, d_svhn_loss: 0.0819, d_fake_loss: 0.1238, g_loss: 1.0391\n",
            "Step [51040/60000], d_real_loss: 0.0276, d_mnist_loss: 0.0082, d_svhn_loss: 0.0195, d_fake_loss: 0.0351, g_loss: 1.1964\n",
            "Step [51050/60000], d_real_loss: 0.0260, d_mnist_loss: 0.0079, d_svhn_loss: 0.0181, d_fake_loss: 0.0484, g_loss: 1.0758\n",
            "Step [51060/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0080, d_svhn_loss: 0.0250, d_fake_loss: 0.0438, g_loss: 1.1672\n",
            "Step [51070/60000], d_real_loss: 0.0256, d_mnist_loss: 0.0089, d_svhn_loss: 0.0168, d_fake_loss: 0.0250, g_loss: 1.0915\n",
            "Step [51080/60000], d_real_loss: 0.1113, d_mnist_loss: 0.0169, d_svhn_loss: 0.0944, d_fake_loss: 0.0306, g_loss: 1.0171\n",
            "Step [51090/60000], d_real_loss: 0.0235, d_mnist_loss: 0.0067, d_svhn_loss: 0.0168, d_fake_loss: 0.0944, g_loss: 1.3266\n",
            "Step [51100/60000], d_real_loss: 0.0558, d_mnist_loss: 0.0330, d_svhn_loss: 0.0227, d_fake_loss: 0.0251, g_loss: 1.0335\n",
            "Step [51110/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0058, d_svhn_loss: 0.0243, d_fake_loss: 0.0605, g_loss: 1.0756\n",
            "Step [51120/60000], d_real_loss: 0.1597, d_mnist_loss: 0.0150, d_svhn_loss: 0.1447, d_fake_loss: 0.1470, g_loss: 1.0160\n",
            "Step [51130/60000], d_real_loss: 0.0533, d_mnist_loss: 0.0153, d_svhn_loss: 0.0380, d_fake_loss: 0.0322, g_loss: 1.1233\n",
            "Step [51140/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0072, d_svhn_loss: 0.0295, d_fake_loss: 0.0317, g_loss: 0.9994\n",
            "Step [51150/60000], d_real_loss: 0.1565, d_mnist_loss: 0.0189, d_svhn_loss: 0.1376, d_fake_loss: 0.0235, g_loss: 1.2734\n",
            "Step [51160/60000], d_real_loss: 0.0356, d_mnist_loss: 0.0078, d_svhn_loss: 0.0278, d_fake_loss: 0.0537, g_loss: 1.1221\n",
            "Step [51170/60000], d_real_loss: 0.1454, d_mnist_loss: 0.0810, d_svhn_loss: 0.0644, d_fake_loss: 0.1083, g_loss: 1.1237\n",
            "Step [51180/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0082, d_svhn_loss: 0.0582, d_fake_loss: 0.0345, g_loss: 1.0932\n",
            "Step [51190/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0165, d_svhn_loss: 0.0267, d_fake_loss: 0.0533, g_loss: 1.3549\n",
            "Step [51200/60000], d_real_loss: 0.0233, d_mnist_loss: 0.0082, d_svhn_loss: 0.0151, d_fake_loss: 0.0194, g_loss: 1.0921\n",
            "Step [51210/60000], d_real_loss: 0.0458, d_mnist_loss: 0.0078, d_svhn_loss: 0.0380, d_fake_loss: 0.0332, g_loss: 1.1005\n",
            "Step [51220/60000], d_real_loss: 0.0223, d_mnist_loss: 0.0080, d_svhn_loss: 0.0143, d_fake_loss: 0.0385, g_loss: 1.3172\n",
            "Step [51230/60000], d_real_loss: 0.0763, d_mnist_loss: 0.0424, d_svhn_loss: 0.0339, d_fake_loss: 0.0809, g_loss: 1.2378\n",
            "Step [51240/60000], d_real_loss: 0.0525, d_mnist_loss: 0.0285, d_svhn_loss: 0.0240, d_fake_loss: 0.0285, g_loss: 1.2090\n",
            "Step [51250/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0126, d_svhn_loss: 0.0272, d_fake_loss: 0.0965, g_loss: 1.3114\n",
            "Step [51260/60000], d_real_loss: 0.0275, d_mnist_loss: 0.0093, d_svhn_loss: 0.0182, d_fake_loss: 0.0886, g_loss: 1.2598\n",
            "Step [51270/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0073, d_svhn_loss: 0.0226, d_fake_loss: 0.0244, g_loss: 1.0551\n",
            "Step [51280/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0070, d_svhn_loss: 0.0469, d_fake_loss: 0.1714, g_loss: 1.1286\n",
            "Step [51290/60000], d_real_loss: 0.0578, d_mnist_loss: 0.0121, d_svhn_loss: 0.0456, d_fake_loss: 0.0766, g_loss: 1.0444\n",
            "Step [51300/60000], d_real_loss: 0.0840, d_mnist_loss: 0.0244, d_svhn_loss: 0.0597, d_fake_loss: 0.0482, g_loss: 1.1855\n",
            "Step [51310/60000], d_real_loss: 0.0409, d_mnist_loss: 0.0191, d_svhn_loss: 0.0218, d_fake_loss: 0.0326, g_loss: 1.0475\n",
            "Step [51320/60000], d_real_loss: 0.0599, d_mnist_loss: 0.0409, d_svhn_loss: 0.0189, d_fake_loss: 0.0416, g_loss: 1.1494\n",
            "Step [51330/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0094, d_svhn_loss: 0.0272, d_fake_loss: 0.0450, g_loss: 1.1703\n",
            "Step [51340/60000], d_real_loss: 0.0854, d_mnist_loss: 0.0452, d_svhn_loss: 0.0402, d_fake_loss: 0.0248, g_loss: 1.0544\n",
            "Step [51350/60000], d_real_loss: 0.0501, d_mnist_loss: 0.0315, d_svhn_loss: 0.0186, d_fake_loss: 0.0343, g_loss: 1.2749\n",
            "Step [51360/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0152, d_svhn_loss: 0.0186, d_fake_loss: 0.0215, g_loss: 1.1554\n",
            "Step [51370/60000], d_real_loss: 0.0590, d_mnist_loss: 0.0216, d_svhn_loss: 0.0373, d_fake_loss: 0.0561, g_loss: 1.0886\n",
            "Step [51380/60000], d_real_loss: 0.0761, d_mnist_loss: 0.0065, d_svhn_loss: 0.0695, d_fake_loss: 0.0428, g_loss: 1.1788\n",
            "Step [51390/60000], d_real_loss: 0.0663, d_mnist_loss: 0.0260, d_svhn_loss: 0.0403, d_fake_loss: 0.0935, g_loss: 1.3674\n",
            "Step [51400/60000], d_real_loss: 0.1625, d_mnist_loss: 0.0073, d_svhn_loss: 0.1552, d_fake_loss: 0.1020, g_loss: 1.1322\n",
            "Step [51410/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0057, d_svhn_loss: 0.0181, d_fake_loss: 0.0446, g_loss: 1.0707\n",
            "Step [51420/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0169, d_svhn_loss: 0.0188, d_fake_loss: 0.1226, g_loss: 1.1409\n",
            "Step [51430/60000], d_real_loss: 0.0430, d_mnist_loss: 0.0079, d_svhn_loss: 0.0351, d_fake_loss: 0.0319, g_loss: 1.1209\n",
            "Step [51440/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0148, d_svhn_loss: 0.0161, d_fake_loss: 0.0264, g_loss: 1.1275\n",
            "Step [51450/60000], d_real_loss: 0.0632, d_mnist_loss: 0.0182, d_svhn_loss: 0.0450, d_fake_loss: 0.0813, g_loss: 1.1813\n",
            "Step [51460/60000], d_real_loss: 0.0953, d_mnist_loss: 0.0748, d_svhn_loss: 0.0205, d_fake_loss: 0.0362, g_loss: 1.2934\n",
            "Step [51470/60000], d_real_loss: 0.0249, d_mnist_loss: 0.0091, d_svhn_loss: 0.0157, d_fake_loss: 0.0151, g_loss: 1.1362\n",
            "Step [51480/60000], d_real_loss: 0.0625, d_mnist_loss: 0.0149, d_svhn_loss: 0.0476, d_fake_loss: 0.0557, g_loss: 1.0864\n",
            "Step [51490/60000], d_real_loss: 0.0500, d_mnist_loss: 0.0098, d_svhn_loss: 0.0402, d_fake_loss: 0.0268, g_loss: 1.1641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [51500/60000], d_real_loss: 0.0456, d_mnist_loss: 0.0079, d_svhn_loss: 0.0377, d_fake_loss: 0.0389, g_loss: 1.2334\n",
            "saved ./samples_fashion/sample-51500-m-s.png\n",
            "saved ./samples_fashion/sample-51500-s-m.png\n",
            "Step [51510/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0102, d_svhn_loss: 0.0233, d_fake_loss: 0.0266, g_loss: 1.1441\n",
            "Step [51520/60000], d_real_loss: 0.0811, d_mnist_loss: 0.0082, d_svhn_loss: 0.0729, d_fake_loss: 0.0672, g_loss: 1.1601\n",
            "Step [51530/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0147, d_svhn_loss: 0.0304, d_fake_loss: 0.0543, g_loss: 1.0344\n",
            "Step [51540/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0246, d_svhn_loss: 0.0197, d_fake_loss: 0.1702, g_loss: 0.9705\n",
            "Step [51550/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0057, d_svhn_loss: 0.0307, d_fake_loss: 0.0518, g_loss: 1.1678\n",
            "Step [51560/60000], d_real_loss: 0.1128, d_mnist_loss: 0.0069, d_svhn_loss: 0.1058, d_fake_loss: 0.0522, g_loss: 1.0498\n",
            "Step [51570/60000], d_real_loss: 0.0291, d_mnist_loss: 0.0079, d_svhn_loss: 0.0212, d_fake_loss: 0.0520, g_loss: 1.0950\n",
            "Step [51580/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0065, d_svhn_loss: 0.0205, d_fake_loss: 0.0251, g_loss: 1.1625\n",
            "Step [51590/60000], d_real_loss: 0.0168, d_mnist_loss: 0.0073, d_svhn_loss: 0.0095, d_fake_loss: 0.0716, g_loss: 1.0611\n",
            "Step [51600/60000], d_real_loss: 0.0808, d_mnist_loss: 0.0383, d_svhn_loss: 0.0424, d_fake_loss: 0.0350, g_loss: 1.3064\n",
            "Step [51610/60000], d_real_loss: 0.0209, d_mnist_loss: 0.0087, d_svhn_loss: 0.0121, d_fake_loss: 0.0771, g_loss: 1.0695\n",
            "Step [51620/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0065, d_svhn_loss: 0.0263, d_fake_loss: 0.0389, g_loss: 1.0043\n",
            "Step [51630/60000], d_real_loss: 0.0959, d_mnist_loss: 0.0156, d_svhn_loss: 0.0803, d_fake_loss: 0.1294, g_loss: 1.1432\n",
            "Step [51640/60000], d_real_loss: 0.0600, d_mnist_loss: 0.0061, d_svhn_loss: 0.0539, d_fake_loss: 0.0284, g_loss: 1.1967\n",
            "Step [51650/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0068, d_svhn_loss: 0.0304, d_fake_loss: 0.0287, g_loss: 1.1394\n",
            "Step [51660/60000], d_real_loss: 0.0294, d_mnist_loss: 0.0161, d_svhn_loss: 0.0132, d_fake_loss: 0.0734, g_loss: 1.1284\n",
            "Step [51670/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0090, d_svhn_loss: 0.0362, d_fake_loss: 0.0274, g_loss: 1.1634\n",
            "Step [51680/60000], d_real_loss: 0.0514, d_mnist_loss: 0.0145, d_svhn_loss: 0.0369, d_fake_loss: 0.0474, g_loss: 1.3449\n",
            "Step [51690/60000], d_real_loss: 0.1912, d_mnist_loss: 0.0230, d_svhn_loss: 0.1682, d_fake_loss: 0.1736, g_loss: 1.1253\n",
            "Step [51700/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0065, d_svhn_loss: 0.0307, d_fake_loss: 0.0284, g_loss: 1.2003\n",
            "Step [51710/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0058, d_svhn_loss: 0.0256, d_fake_loss: 0.0468, g_loss: 1.4832\n",
            "Step [51720/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0087, d_svhn_loss: 0.0236, d_fake_loss: 0.0861, g_loss: 1.1140\n",
            "Step [51730/60000], d_real_loss: 0.0709, d_mnist_loss: 0.0118, d_svhn_loss: 0.0591, d_fake_loss: 0.0548, g_loss: 1.1917\n",
            "Step [51740/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0094, d_svhn_loss: 0.0225, d_fake_loss: 0.1210, g_loss: 1.2179\n",
            "Step [51750/60000], d_real_loss: 0.0898, d_mnist_loss: 0.0413, d_svhn_loss: 0.0485, d_fake_loss: 0.0455, g_loss: 1.3234\n",
            "Step [51760/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0105, d_svhn_loss: 0.0225, d_fake_loss: 0.0421, g_loss: 1.0087\n",
            "Step [51770/60000], d_real_loss: 0.0490, d_mnist_loss: 0.0150, d_svhn_loss: 0.0341, d_fake_loss: 0.0374, g_loss: 1.1372\n",
            "Step [51780/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0085, d_svhn_loss: 0.0185, d_fake_loss: 0.0516, g_loss: 1.1410\n",
            "Step [51790/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0142, d_svhn_loss: 0.0150, d_fake_loss: 0.0219, g_loss: 1.0710\n",
            "Step [51800/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0092, d_svhn_loss: 0.0178, d_fake_loss: 0.0416, g_loss: 1.1631\n",
            "Step [51810/60000], d_real_loss: 0.1216, d_mnist_loss: 0.0630, d_svhn_loss: 0.0586, d_fake_loss: 0.4659, g_loss: 1.0763\n",
            "Step [51820/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0057, d_svhn_loss: 0.0244, d_fake_loss: 0.1600, g_loss: 1.1634\n",
            "Step [51830/60000], d_real_loss: 0.0291, d_mnist_loss: 0.0112, d_svhn_loss: 0.0179, d_fake_loss: 0.0242, g_loss: 1.1339\n",
            "Step [51840/60000], d_real_loss: 0.0263, d_mnist_loss: 0.0079, d_svhn_loss: 0.0185, d_fake_loss: 0.0332, g_loss: 1.0818\n",
            "Step [51850/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0071, d_svhn_loss: 0.0170, d_fake_loss: 0.0446, g_loss: 1.1983\n",
            "Step [51860/60000], d_real_loss: 0.0488, d_mnist_loss: 0.0111, d_svhn_loss: 0.0377, d_fake_loss: 0.0349, g_loss: 1.1739\n",
            "Step [51870/60000], d_real_loss: 0.0246, d_mnist_loss: 0.0088, d_svhn_loss: 0.0159, d_fake_loss: 0.0572, g_loss: 1.1043\n",
            "Step [51880/60000], d_real_loss: 0.0540, d_mnist_loss: 0.0109, d_svhn_loss: 0.0431, d_fake_loss: 0.0200, g_loss: 1.1272\n",
            "Step [51890/60000], d_real_loss: 0.0332, d_mnist_loss: 0.0075, d_svhn_loss: 0.0257, d_fake_loss: 0.0144, g_loss: 1.0605\n",
            "Step [51900/60000], d_real_loss: 0.0678, d_mnist_loss: 0.0142, d_svhn_loss: 0.0536, d_fake_loss: 0.1446, g_loss: 1.0968\n",
            "Step [51910/60000], d_real_loss: 0.0839, d_mnist_loss: 0.0160, d_svhn_loss: 0.0678, d_fake_loss: 0.0298, g_loss: 1.0805\n",
            "Step [51920/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0125, d_svhn_loss: 0.0279, d_fake_loss: 0.0923, g_loss: 0.9809\n",
            "Step [51930/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0133, d_svhn_loss: 0.0538, d_fake_loss: 0.0639, g_loss: 1.1980\n",
            "Step [51940/60000], d_real_loss: 0.1063, d_mnist_loss: 0.0163, d_svhn_loss: 0.0900, d_fake_loss: 0.0382, g_loss: 1.1956\n",
            "Step [51950/60000], d_real_loss: 0.0662, d_mnist_loss: 0.0093, d_svhn_loss: 0.0569, d_fake_loss: 0.0386, g_loss: 1.1304\n",
            "Step [51960/60000], d_real_loss: 0.1272, d_mnist_loss: 0.0108, d_svhn_loss: 0.1164, d_fake_loss: 0.0237, g_loss: 1.0452\n",
            "Step [51970/60000], d_real_loss: 0.0436, d_mnist_loss: 0.0236, d_svhn_loss: 0.0200, d_fake_loss: 0.0555, g_loss: 1.1622\n",
            "Step [51980/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0224, d_svhn_loss: 0.0180, d_fake_loss: 0.0308, g_loss: 1.1861\n",
            "Step [51990/60000], d_real_loss: 0.0814, d_mnist_loss: 0.0145, d_svhn_loss: 0.0669, d_fake_loss: 0.0308, g_loss: 1.2348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [52000/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0150, d_svhn_loss: 0.0289, d_fake_loss: 0.0394, g_loss: 1.1083\n",
            "saved ./samples_fashion/sample-52000-m-s.png\n",
            "saved ./samples_fashion/sample-52000-s-m.png\n",
            "Step [52010/60000], d_real_loss: 0.0651, d_mnist_loss: 0.0295, d_svhn_loss: 0.0356, d_fake_loss: 0.0177, g_loss: 1.2148\n",
            "Step [52020/60000], d_real_loss: 0.1233, d_mnist_loss: 0.0068, d_svhn_loss: 0.1165, d_fake_loss: 0.0365, g_loss: 1.2156\n",
            "Step [52030/60000], d_real_loss: 0.0950, d_mnist_loss: 0.0395, d_svhn_loss: 0.0555, d_fake_loss: 0.0719, g_loss: 1.2212\n",
            "Step [52040/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0251, d_svhn_loss: 0.0192, d_fake_loss: 0.0529, g_loss: 1.2480\n",
            "Step [52050/60000], d_real_loss: 0.0663, d_mnist_loss: 0.0131, d_svhn_loss: 0.0532, d_fake_loss: 0.0419, g_loss: 1.1117\n",
            "Step [52060/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0065, d_svhn_loss: 0.0331, d_fake_loss: 0.0328, g_loss: 1.1296\n",
            "Step [52070/60000], d_real_loss: 0.1106, d_mnist_loss: 0.0112, d_svhn_loss: 0.0994, d_fake_loss: 0.0263, g_loss: 1.1270\n",
            "Step [52080/60000], d_real_loss: 0.0329, d_mnist_loss: 0.0134, d_svhn_loss: 0.0196, d_fake_loss: 0.0469, g_loss: 1.1570\n",
            "Step [52090/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0147, d_svhn_loss: 0.0228, d_fake_loss: 0.0244, g_loss: 1.0647\n",
            "Step [52100/60000], d_real_loss: 0.0565, d_mnist_loss: 0.0155, d_svhn_loss: 0.0410, d_fake_loss: 0.0470, g_loss: 1.0956\n",
            "Step [52110/60000], d_real_loss: 0.0549, d_mnist_loss: 0.0186, d_svhn_loss: 0.0363, d_fake_loss: 0.0308, g_loss: 1.2707\n",
            "Step [52120/60000], d_real_loss: 0.1856, d_mnist_loss: 0.0238, d_svhn_loss: 0.1618, d_fake_loss: 0.0766, g_loss: 1.0943\n",
            "Step [52130/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0117, d_svhn_loss: 0.0209, d_fake_loss: 0.0352, g_loss: 1.0185\n",
            "Step [52140/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0053, d_svhn_loss: 0.0229, d_fake_loss: 0.0535, g_loss: 1.0495\n",
            "Step [52150/60000], d_real_loss: 0.0294, d_mnist_loss: 0.0107, d_svhn_loss: 0.0187, d_fake_loss: 0.0182, g_loss: 1.1739\n",
            "Step [52160/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0067, d_svhn_loss: 0.0296, d_fake_loss: 0.0157, g_loss: 1.1068\n",
            "Step [52170/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0118, d_svhn_loss: 0.0283, d_fake_loss: 0.1577, g_loss: 1.3105\n",
            "Step [52180/60000], d_real_loss: 0.0923, d_mnist_loss: 0.0650, d_svhn_loss: 0.0274, d_fake_loss: 0.0710, g_loss: 1.3996\n",
            "Step [52190/60000], d_real_loss: 0.0295, d_mnist_loss: 0.0063, d_svhn_loss: 0.0233, d_fake_loss: 0.0882, g_loss: 0.9982\n",
            "Step [52200/60000], d_real_loss: 0.0574, d_mnist_loss: 0.0215, d_svhn_loss: 0.0359, d_fake_loss: 0.0327, g_loss: 1.0364\n",
            "Step [52210/60000], d_real_loss: 0.0666, d_mnist_loss: 0.0193, d_svhn_loss: 0.0473, d_fake_loss: 0.0579, g_loss: 1.3974\n",
            "Step [52220/60000], d_real_loss: 0.0366, d_mnist_loss: 0.0115, d_svhn_loss: 0.0251, d_fake_loss: 0.0299, g_loss: 1.1446\n",
            "Step [52230/60000], d_real_loss: 0.0625, d_mnist_loss: 0.0187, d_svhn_loss: 0.0438, d_fake_loss: 0.1014, g_loss: 1.0488\n",
            "Step [52240/60000], d_real_loss: 0.0350, d_mnist_loss: 0.0117, d_svhn_loss: 0.0233, d_fake_loss: 0.0816, g_loss: 1.0397\n",
            "Step [52250/60000], d_real_loss: 0.0222, d_mnist_loss: 0.0084, d_svhn_loss: 0.0139, d_fake_loss: 0.0298, g_loss: 1.3040\n",
            "Step [52260/60000], d_real_loss: 0.0667, d_mnist_loss: 0.0068, d_svhn_loss: 0.0599, d_fake_loss: 0.0289, g_loss: 1.1446\n",
            "Step [52270/60000], d_real_loss: 0.3232, d_mnist_loss: 0.0580, d_svhn_loss: 0.2652, d_fake_loss: 0.1679, g_loss: 1.2045\n",
            "Step [52280/60000], d_real_loss: 0.0721, d_mnist_loss: 0.0289, d_svhn_loss: 0.0432, d_fake_loss: 0.0151, g_loss: 1.1208\n",
            "Step [52290/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0269, d_svhn_loss: 0.0128, d_fake_loss: 0.0212, g_loss: 1.2082\n",
            "Step [52300/60000], d_real_loss: 0.0875, d_mnist_loss: 0.0105, d_svhn_loss: 0.0770, d_fake_loss: 0.1079, g_loss: 1.1309\n",
            "Step [52310/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0107, d_svhn_loss: 0.0296, d_fake_loss: 0.0540, g_loss: 0.9422\n",
            "Step [52320/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0116, d_svhn_loss: 0.0193, d_fake_loss: 0.0304, g_loss: 1.1218\n",
            "Step [52330/60000], d_real_loss: 0.0775, d_mnist_loss: 0.0373, d_svhn_loss: 0.0402, d_fake_loss: 0.0643, g_loss: 1.0894\n",
            "Step [52340/60000], d_real_loss: 0.0320, d_mnist_loss: 0.0073, d_svhn_loss: 0.0246, d_fake_loss: 0.0759, g_loss: 0.9996\n",
            "Step [52350/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0069, d_svhn_loss: 0.0184, d_fake_loss: 0.0854, g_loss: 0.9640\n",
            "Step [52360/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0078, d_svhn_loss: 0.0349, d_fake_loss: 0.0178, g_loss: 1.1032\n",
            "Step [52370/60000], d_real_loss: 0.0503, d_mnist_loss: 0.0157, d_svhn_loss: 0.0347, d_fake_loss: 0.0516, g_loss: 1.1745\n",
            "Step [52380/60000], d_real_loss: 0.0385, d_mnist_loss: 0.0044, d_svhn_loss: 0.0341, d_fake_loss: 0.0232, g_loss: 1.0411\n",
            "Step [52390/60000], d_real_loss: 0.0423, d_mnist_loss: 0.0268, d_svhn_loss: 0.0156, d_fake_loss: 0.1434, g_loss: 1.2717\n",
            "Step [52400/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0112, d_svhn_loss: 0.0212, d_fake_loss: 0.0318, g_loss: 1.4345\n",
            "Step [52410/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0152, d_svhn_loss: 0.0249, d_fake_loss: 0.0411, g_loss: 1.0494\n",
            "Step [52420/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0069, d_svhn_loss: 0.0229, d_fake_loss: 0.0567, g_loss: 1.3935\n",
            "Step [52430/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0103, d_svhn_loss: 0.0254, d_fake_loss: 0.0414, g_loss: 1.0485\n",
            "Step [52440/60000], d_real_loss: 0.0352, d_mnist_loss: 0.0055, d_svhn_loss: 0.0296, d_fake_loss: 0.0425, g_loss: 1.1833\n",
            "Step [52450/60000], d_real_loss: 0.0480, d_mnist_loss: 0.0206, d_svhn_loss: 0.0274, d_fake_loss: 0.0152, g_loss: 1.2643\n",
            "Step [52460/60000], d_real_loss: 0.0380, d_mnist_loss: 0.0071, d_svhn_loss: 0.0309, d_fake_loss: 0.0288, g_loss: 1.0757\n",
            "Step [52470/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0127, d_svhn_loss: 0.0292, d_fake_loss: 0.0448, g_loss: 1.0840\n",
            "Step [52480/60000], d_real_loss: 0.0585, d_mnist_loss: 0.0349, d_svhn_loss: 0.0236, d_fake_loss: 0.0519, g_loss: 0.9430\n",
            "Step [52490/60000], d_real_loss: 0.0435, d_mnist_loss: 0.0085, d_svhn_loss: 0.0350, d_fake_loss: 0.0243, g_loss: 1.2380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [52500/60000], d_real_loss: 0.0251, d_mnist_loss: 0.0058, d_svhn_loss: 0.0193, d_fake_loss: 0.0967, g_loss: 1.2402\n",
            "saved ./samples_fashion/sample-52500-m-s.png\n",
            "saved ./samples_fashion/sample-52500-s-m.png\n",
            "Step [52510/60000], d_real_loss: 0.0263, d_mnist_loss: 0.0105, d_svhn_loss: 0.0158, d_fake_loss: 0.0700, g_loss: 1.0742\n",
            "Step [52520/60000], d_real_loss: 0.0281, d_mnist_loss: 0.0078, d_svhn_loss: 0.0203, d_fake_loss: 0.0502, g_loss: 1.1370\n",
            "Step [52530/60000], d_real_loss: 0.1108, d_mnist_loss: 0.0615, d_svhn_loss: 0.0493, d_fake_loss: 0.0503, g_loss: 1.3535\n",
            "Step [52540/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0079, d_svhn_loss: 0.0335, d_fake_loss: 0.0427, g_loss: 1.2826\n",
            "Step [52550/60000], d_real_loss: 0.1634, d_mnist_loss: 0.0929, d_svhn_loss: 0.0705, d_fake_loss: 0.0561, g_loss: 1.3585\n",
            "Step [52560/60000], d_real_loss: 0.0366, d_mnist_loss: 0.0191, d_svhn_loss: 0.0175, d_fake_loss: 0.0536, g_loss: 1.1887\n",
            "Step [52570/60000], d_real_loss: 0.0593, d_mnist_loss: 0.0425, d_svhn_loss: 0.0168, d_fake_loss: 0.0223, g_loss: 1.0401\n",
            "Step [52580/60000], d_real_loss: 0.0336, d_mnist_loss: 0.0156, d_svhn_loss: 0.0179, d_fake_loss: 0.0255, g_loss: 1.0084\n",
            "Step [52590/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0080, d_svhn_loss: 0.0351, d_fake_loss: 0.0465, g_loss: 1.1371\n",
            "Step [52600/60000], d_real_loss: 0.0422, d_mnist_loss: 0.0125, d_svhn_loss: 0.0297, d_fake_loss: 0.0911, g_loss: 1.1733\n",
            "Step [52610/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0081, d_svhn_loss: 0.0230, d_fake_loss: 0.0241, g_loss: 1.2026\n",
            "Step [52620/60000], d_real_loss: 0.0701, d_mnist_loss: 0.0417, d_svhn_loss: 0.0283, d_fake_loss: 0.0729, g_loss: 1.1520\n",
            "Step [52630/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0065, d_svhn_loss: 0.0303, d_fake_loss: 0.0291, g_loss: 1.0848\n",
            "Step [52640/60000], d_real_loss: 0.0240, d_mnist_loss: 0.0069, d_svhn_loss: 0.0171, d_fake_loss: 0.0250, g_loss: 1.1840\n",
            "Step [52650/60000], d_real_loss: 0.0269, d_mnist_loss: 0.0096, d_svhn_loss: 0.0173, d_fake_loss: 0.0395, g_loss: 1.0702\n",
            "Step [52660/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0079, d_svhn_loss: 0.0505, d_fake_loss: 0.0377, g_loss: 0.9687\n",
            "Step [52670/60000], d_real_loss: 0.0907, d_mnist_loss: 0.0690, d_svhn_loss: 0.0217, d_fake_loss: 0.0369, g_loss: 1.2334\n",
            "Step [52680/60000], d_real_loss: 0.0909, d_mnist_loss: 0.0548, d_svhn_loss: 0.0361, d_fake_loss: 0.0567, g_loss: 1.1742\n",
            "Step [52690/60000], d_real_loss: 0.0437, d_mnist_loss: 0.0207, d_svhn_loss: 0.0230, d_fake_loss: 0.0251, g_loss: 1.0501\n",
            "Step [52700/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0273, d_svhn_loss: 0.0234, d_fake_loss: 0.0240, g_loss: 1.0382\n",
            "Step [52710/60000], d_real_loss: 0.0383, d_mnist_loss: 0.0113, d_svhn_loss: 0.0270, d_fake_loss: 0.0158, g_loss: 1.1282\n",
            "Step [52720/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0093, d_svhn_loss: 0.0232, d_fake_loss: 0.0633, g_loss: 1.0441\n",
            "Step [52730/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0109, d_svhn_loss: 0.0173, d_fake_loss: 0.0194, g_loss: 1.0410\n",
            "Step [52740/60000], d_real_loss: 0.0315, d_mnist_loss: 0.0062, d_svhn_loss: 0.0252, d_fake_loss: 0.0492, g_loss: 1.0591\n",
            "Step [52750/60000], d_real_loss: 0.0315, d_mnist_loss: 0.0124, d_svhn_loss: 0.0191, d_fake_loss: 0.0333, g_loss: 0.9880\n",
            "Step [52760/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0078, d_svhn_loss: 0.0324, d_fake_loss: 0.0334, g_loss: 1.0556\n",
            "Step [52770/60000], d_real_loss: 0.0321, d_mnist_loss: 0.0105, d_svhn_loss: 0.0215, d_fake_loss: 0.0305, g_loss: 1.0914\n",
            "Step [52780/60000], d_real_loss: 0.0255, d_mnist_loss: 0.0089, d_svhn_loss: 0.0166, d_fake_loss: 0.0472, g_loss: 1.1160\n",
            "Step [52790/60000], d_real_loss: 0.0599, d_mnist_loss: 0.0085, d_svhn_loss: 0.0515, d_fake_loss: 0.0638, g_loss: 1.2186\n",
            "Step [52800/60000], d_real_loss: 0.1036, d_mnist_loss: 0.0166, d_svhn_loss: 0.0870, d_fake_loss: 0.0233, g_loss: 1.0022\n",
            "Step [52810/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0156, d_svhn_loss: 0.0183, d_fake_loss: 0.0219, g_loss: 1.1546\n",
            "Step [52820/60000], d_real_loss: 0.0547, d_mnist_loss: 0.0096, d_svhn_loss: 0.0451, d_fake_loss: 0.0265, g_loss: 1.1448\n",
            "Step [52830/60000], d_real_loss: 0.0285, d_mnist_loss: 0.0121, d_svhn_loss: 0.0164, d_fake_loss: 0.0311, g_loss: 1.1019\n",
            "Step [52840/60000], d_real_loss: 0.0182, d_mnist_loss: 0.0087, d_svhn_loss: 0.0095, d_fake_loss: 0.0359, g_loss: 1.0869\n",
            "Step [52850/60000], d_real_loss: 0.0493, d_mnist_loss: 0.0084, d_svhn_loss: 0.0409, d_fake_loss: 0.1084, g_loss: 0.9327\n",
            "Step [52860/60000], d_real_loss: 0.0958, d_mnist_loss: 0.0416, d_svhn_loss: 0.0542, d_fake_loss: 0.0861, g_loss: 1.3241\n",
            "Step [52870/60000], d_real_loss: 0.0643, d_mnist_loss: 0.0478, d_svhn_loss: 0.0165, d_fake_loss: 0.0292, g_loss: 1.2530\n",
            "Step [52880/60000], d_real_loss: 0.2034, d_mnist_loss: 0.0131, d_svhn_loss: 0.1902, d_fake_loss: 0.0792, g_loss: 1.0109\n",
            "Step [52890/60000], d_real_loss: 0.0390, d_mnist_loss: 0.0083, d_svhn_loss: 0.0308, d_fake_loss: 0.0195, g_loss: 1.1414\n",
            "Step [52900/60000], d_real_loss: 0.0477, d_mnist_loss: 0.0106, d_svhn_loss: 0.0371, d_fake_loss: 0.0330, g_loss: 0.9688\n",
            "Step [52910/60000], d_real_loss: 0.0202, d_mnist_loss: 0.0089, d_svhn_loss: 0.0113, d_fake_loss: 0.0209, g_loss: 1.0810\n",
            "Step [52920/60000], d_real_loss: 0.0479, d_mnist_loss: 0.0088, d_svhn_loss: 0.0390, d_fake_loss: 0.1258, g_loss: 1.1583\n",
            "Step [52930/60000], d_real_loss: 0.0350, d_mnist_loss: 0.0140, d_svhn_loss: 0.0210, d_fake_loss: 0.0233, g_loss: 1.2492\n",
            "Step [52940/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0089, d_svhn_loss: 0.0339, d_fake_loss: 0.1240, g_loss: 1.2190\n",
            "Step [52950/60000], d_real_loss: 0.1144, d_mnist_loss: 0.0165, d_svhn_loss: 0.0979, d_fake_loss: 0.0792, g_loss: 1.0622\n",
            "Step [52960/60000], d_real_loss: 0.0807, d_mnist_loss: 0.0275, d_svhn_loss: 0.0532, d_fake_loss: 0.0744, g_loss: 1.0737\n",
            "Step [52970/60000], d_real_loss: 0.0419, d_mnist_loss: 0.0097, d_svhn_loss: 0.0322, d_fake_loss: 0.0771, g_loss: 1.1262\n",
            "Step [52980/60000], d_real_loss: 0.0926, d_mnist_loss: 0.0128, d_svhn_loss: 0.0798, d_fake_loss: 0.0387, g_loss: 0.9948\n",
            "Step [52990/60000], d_real_loss: 0.0443, d_mnist_loss: 0.0215, d_svhn_loss: 0.0228, d_fake_loss: 0.1806, g_loss: 1.0266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999985098838806, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [53000/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0091, d_svhn_loss: 0.0238, d_fake_loss: 0.0279, g_loss: 1.1874\n",
            "saved ./samples_fashion/sample-53000-m-s.png\n",
            "saved ./samples_fashion/sample-53000-s-m.png\n",
            "Step [53010/60000], d_real_loss: 0.0285, d_mnist_loss: 0.0078, d_svhn_loss: 0.0207, d_fake_loss: 0.0221, g_loss: 1.0897\n",
            "Step [53020/60000], d_real_loss: 0.0746, d_mnist_loss: 0.0280, d_svhn_loss: 0.0465, d_fake_loss: 0.0241, g_loss: 1.0792\n",
            "Step [53030/60000], d_real_loss: 0.0236, d_mnist_loss: 0.0083, d_svhn_loss: 0.0153, d_fake_loss: 0.0380, g_loss: 1.1866\n",
            "Step [53040/60000], d_real_loss: 0.0337, d_mnist_loss: 0.0126, d_svhn_loss: 0.0211, d_fake_loss: 0.0413, g_loss: 1.2805\n",
            "Step [53050/60000], d_real_loss: 0.0696, d_mnist_loss: 0.0092, d_svhn_loss: 0.0604, d_fake_loss: 0.0389, g_loss: 1.0313\n",
            "Step [53060/60000], d_real_loss: 0.0225, d_mnist_loss: 0.0095, d_svhn_loss: 0.0130, d_fake_loss: 0.0285, g_loss: 1.0953\n",
            "Step [53070/60000], d_real_loss: 0.0463, d_mnist_loss: 0.0212, d_svhn_loss: 0.0250, d_fake_loss: 0.0181, g_loss: 1.2280\n",
            "Step [53080/60000], d_real_loss: 0.0315, d_mnist_loss: 0.0106, d_svhn_loss: 0.0209, d_fake_loss: 0.0687, g_loss: 1.1875\n",
            "Step [53090/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0327, d_svhn_loss: 0.0101, d_fake_loss: 0.0832, g_loss: 1.1198\n",
            "Step [53100/60000], d_real_loss: 0.1363, d_mnist_loss: 0.1165, d_svhn_loss: 0.0198, d_fake_loss: 0.0257, g_loss: 1.3724\n",
            "Step [53110/60000], d_real_loss: 0.1057, d_mnist_loss: 0.0173, d_svhn_loss: 0.0884, d_fake_loss: 0.0386, g_loss: 0.9743\n",
            "Step [53120/60000], d_real_loss: 0.0914, d_mnist_loss: 0.0037, d_svhn_loss: 0.0878, d_fake_loss: 0.1953, g_loss: 1.0923\n",
            "Step [53130/60000], d_real_loss: 0.0264, d_mnist_loss: 0.0057, d_svhn_loss: 0.0208, d_fake_loss: 0.0659, g_loss: 1.0342\n",
            "Step [53140/60000], d_real_loss: 0.0409, d_mnist_loss: 0.0223, d_svhn_loss: 0.0186, d_fake_loss: 0.0473, g_loss: 1.2141\n",
            "Step [53150/60000], d_real_loss: 0.0269, d_mnist_loss: 0.0067, d_svhn_loss: 0.0202, d_fake_loss: 0.1875, g_loss: 1.2330\n",
            "Step [53160/60000], d_real_loss: 0.0315, d_mnist_loss: 0.0094, d_svhn_loss: 0.0221, d_fake_loss: 0.0535, g_loss: 1.0153\n",
            "Step [53170/60000], d_real_loss: 0.0503, d_mnist_loss: 0.0220, d_svhn_loss: 0.0283, d_fake_loss: 0.0722, g_loss: 1.0917\n",
            "Step [53180/60000], d_real_loss: 0.1125, d_mnist_loss: 0.0469, d_svhn_loss: 0.0656, d_fake_loss: 0.0637, g_loss: 1.3037\n",
            "Step [53190/60000], d_real_loss: 0.0281, d_mnist_loss: 0.0103, d_svhn_loss: 0.0179, d_fake_loss: 0.0385, g_loss: 1.1781\n",
            "Step [53200/60000], d_real_loss: 0.0994, d_mnist_loss: 0.0163, d_svhn_loss: 0.0831, d_fake_loss: 0.0495, g_loss: 0.9945\n",
            "Step [53210/60000], d_real_loss: 0.0459, d_mnist_loss: 0.0095, d_svhn_loss: 0.0364, d_fake_loss: 0.0422, g_loss: 0.9913\n",
            "Step [53220/60000], d_real_loss: 0.0575, d_mnist_loss: 0.0290, d_svhn_loss: 0.0286, d_fake_loss: 0.0241, g_loss: 1.3454\n",
            "Step [53230/60000], d_real_loss: 0.1823, d_mnist_loss: 0.0212, d_svhn_loss: 0.1611, d_fake_loss: 0.2603, g_loss: 0.9450\n",
            "Step [53240/60000], d_real_loss: 0.0528, d_mnist_loss: 0.0330, d_svhn_loss: 0.0199, d_fake_loss: 0.0233, g_loss: 1.0615\n",
            "Step [53250/60000], d_real_loss: 0.1081, d_mnist_loss: 0.0114, d_svhn_loss: 0.0967, d_fake_loss: 0.0142, g_loss: 1.1258\n",
            "Step [53260/60000], d_real_loss: 0.0593, d_mnist_loss: 0.0099, d_svhn_loss: 0.0494, d_fake_loss: 0.0529, g_loss: 1.2901\n",
            "Step [53270/60000], d_real_loss: 0.0551, d_mnist_loss: 0.0222, d_svhn_loss: 0.0329, d_fake_loss: 0.0194, g_loss: 1.0507\n",
            "Step [53280/60000], d_real_loss: 0.0567, d_mnist_loss: 0.0389, d_svhn_loss: 0.0177, d_fake_loss: 0.0717, g_loss: 1.0197\n",
            "Step [53290/60000], d_real_loss: 0.0522, d_mnist_loss: 0.0164, d_svhn_loss: 0.0358, d_fake_loss: 0.1290, g_loss: 1.1694\n",
            "Step [53300/60000], d_real_loss: 0.0740, d_mnist_loss: 0.0116, d_svhn_loss: 0.0625, d_fake_loss: 0.0551, g_loss: 1.0523\n",
            "Step [53310/60000], d_real_loss: 0.0363, d_mnist_loss: 0.0218, d_svhn_loss: 0.0145, d_fake_loss: 0.0185, g_loss: 1.2576\n",
            "Step [53320/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0092, d_svhn_loss: 0.0207, d_fake_loss: 0.0379, g_loss: 1.2034\n",
            "Step [53330/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0115, d_svhn_loss: 0.0195, d_fake_loss: 0.0522, g_loss: 1.0284\n",
            "Step [53340/60000], d_real_loss: 0.0698, d_mnist_loss: 0.0175, d_svhn_loss: 0.0523, d_fake_loss: 0.0823, g_loss: 0.9721\n",
            "Step [53350/60000], d_real_loss: 0.0633, d_mnist_loss: 0.0211, d_svhn_loss: 0.0422, d_fake_loss: 0.0919, g_loss: 1.0474\n",
            "Step [53360/60000], d_real_loss: 0.0394, d_mnist_loss: 0.0083, d_svhn_loss: 0.0311, d_fake_loss: 0.1037, g_loss: 1.2955\n",
            "Step [53370/60000], d_real_loss: 0.0566, d_mnist_loss: 0.0053, d_svhn_loss: 0.0513, d_fake_loss: 0.0556, g_loss: 1.1581\n",
            "Step [53380/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0103, d_svhn_loss: 0.0271, d_fake_loss: 0.0829, g_loss: 1.2601\n",
            "Step [53390/60000], d_real_loss: 0.1287, d_mnist_loss: 0.0454, d_svhn_loss: 0.0832, d_fake_loss: 0.0901, g_loss: 1.0430\n",
            "Step [53400/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0092, d_svhn_loss: 0.0231, d_fake_loss: 0.0133, g_loss: 1.0915\n",
            "Step [53410/60000], d_real_loss: 0.0543, d_mnist_loss: 0.0194, d_svhn_loss: 0.0349, d_fake_loss: 0.0345, g_loss: 1.0017\n",
            "Step [53420/60000], d_real_loss: 0.0562, d_mnist_loss: 0.0116, d_svhn_loss: 0.0446, d_fake_loss: 0.0983, g_loss: 1.2228\n",
            "Step [53430/60000], d_real_loss: 0.0345, d_mnist_loss: 0.0159, d_svhn_loss: 0.0185, d_fake_loss: 0.0266, g_loss: 1.1923\n",
            "Step [53440/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0118, d_svhn_loss: 0.0163, d_fake_loss: 0.0277, g_loss: 1.0817\n",
            "Step [53450/60000], d_real_loss: 0.0913, d_mnist_loss: 0.0135, d_svhn_loss: 0.0778, d_fake_loss: 0.1030, g_loss: 0.8294\n",
            "Step [53460/60000], d_real_loss: 0.0394, d_mnist_loss: 0.0257, d_svhn_loss: 0.0137, d_fake_loss: 0.0423, g_loss: 1.0169\n",
            "Step [53470/60000], d_real_loss: 0.0284, d_mnist_loss: 0.0076, d_svhn_loss: 0.0208, d_fake_loss: 0.0339, g_loss: 1.1676\n",
            "Step [53480/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0076, d_svhn_loss: 0.0162, d_fake_loss: 0.0337, g_loss: 1.1216\n",
            "Step [53490/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0083, d_svhn_loss: 0.0239, d_fake_loss: 0.0623, g_loss: 1.1375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [53500/60000], d_real_loss: 0.0200, d_mnist_loss: 0.0064, d_svhn_loss: 0.0136, d_fake_loss: 0.0300, g_loss: 1.2313\n",
            "saved ./samples_fashion/sample-53500-m-s.png\n",
            "saved ./samples_fashion/sample-53500-s-m.png\n",
            "Step [53510/60000], d_real_loss: 0.0284, d_mnist_loss: 0.0131, d_svhn_loss: 0.0152, d_fake_loss: 0.0250, g_loss: 1.1453\n",
            "Step [53520/60000], d_real_loss: 0.0535, d_mnist_loss: 0.0247, d_svhn_loss: 0.0288, d_fake_loss: 0.1694, g_loss: 1.3335\n",
            "Step [53530/60000], d_real_loss: 0.0546, d_mnist_loss: 0.0170, d_svhn_loss: 0.0377, d_fake_loss: 0.0344, g_loss: 1.1550\n",
            "Step [53540/60000], d_real_loss: 0.0550, d_mnist_loss: 0.0094, d_svhn_loss: 0.0456, d_fake_loss: 0.0286, g_loss: 1.1184\n",
            "Step [53550/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0117, d_svhn_loss: 0.0209, d_fake_loss: 0.0195, g_loss: 1.0331\n",
            "Step [53560/60000], d_real_loss: 0.0975, d_mnist_loss: 0.0178, d_svhn_loss: 0.0797, d_fake_loss: 0.0146, g_loss: 1.0760\n",
            "Step [53570/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0361, d_svhn_loss: 0.0168, d_fake_loss: 0.0166, g_loss: 1.1761\n",
            "Step [53580/60000], d_real_loss: 0.0889, d_mnist_loss: 0.0197, d_svhn_loss: 0.0692, d_fake_loss: 0.1427, g_loss: 1.0324\n",
            "Step [53590/60000], d_real_loss: 0.0237, d_mnist_loss: 0.0086, d_svhn_loss: 0.0150, d_fake_loss: 0.0586, g_loss: 0.9989\n",
            "Step [53600/60000], d_real_loss: 0.0500, d_mnist_loss: 0.0231, d_svhn_loss: 0.0269, d_fake_loss: 0.1238, g_loss: 1.1011\n",
            "Step [53610/60000], d_real_loss: 0.0786, d_mnist_loss: 0.0312, d_svhn_loss: 0.0474, d_fake_loss: 0.0301, g_loss: 1.2149\n",
            "Step [53620/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0098, d_svhn_loss: 0.0432, d_fake_loss: 0.0690, g_loss: 1.1112\n",
            "Step [53630/60000], d_real_loss: 0.0250, d_mnist_loss: 0.0093, d_svhn_loss: 0.0157, d_fake_loss: 0.0262, g_loss: 1.0466\n",
            "Step [53640/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0100, d_svhn_loss: 0.0258, d_fake_loss: 0.1376, g_loss: 0.9661\n",
            "Step [53650/60000], d_real_loss: 0.0577, d_mnist_loss: 0.0170, d_svhn_loss: 0.0407, d_fake_loss: 0.2236, g_loss: 1.1105\n",
            "Step [53660/60000], d_real_loss: 0.0355, d_mnist_loss: 0.0178, d_svhn_loss: 0.0177, d_fake_loss: 0.0295, g_loss: 1.1138\n",
            "Step [53670/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0083, d_svhn_loss: 0.0227, d_fake_loss: 0.0337, g_loss: 1.2592\n",
            "Step [53680/60000], d_real_loss: 0.0331, d_mnist_loss: 0.0065, d_svhn_loss: 0.0265, d_fake_loss: 0.0466, g_loss: 1.1818\n",
            "Step [53690/60000], d_real_loss: 0.0505, d_mnist_loss: 0.0159, d_svhn_loss: 0.0346, d_fake_loss: 0.0217, g_loss: 1.0443\n",
            "Step [53700/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0150, d_svhn_loss: 0.0191, d_fake_loss: 0.0189, g_loss: 0.9742\n",
            "Step [53710/60000], d_real_loss: 0.0811, d_mnist_loss: 0.0076, d_svhn_loss: 0.0735, d_fake_loss: 0.0836, g_loss: 0.9929\n",
            "Step [53720/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0165, d_svhn_loss: 0.0146, d_fake_loss: 0.0350, g_loss: 1.0473\n",
            "Step [53730/60000], d_real_loss: 0.0294, d_mnist_loss: 0.0134, d_svhn_loss: 0.0160, d_fake_loss: 0.0705, g_loss: 1.0048\n",
            "Step [53740/60000], d_real_loss: 0.0953, d_mnist_loss: 0.0636, d_svhn_loss: 0.0317, d_fake_loss: 0.0419, g_loss: 1.0577\n",
            "Step [53750/60000], d_real_loss: 0.1223, d_mnist_loss: 0.0420, d_svhn_loss: 0.0803, d_fake_loss: 0.0641, g_loss: 1.3056\n",
            "Step [53760/60000], d_real_loss: 0.0239, d_mnist_loss: 0.0095, d_svhn_loss: 0.0144, d_fake_loss: 0.0391, g_loss: 1.1488\n",
            "Step [53770/60000], d_real_loss: 0.0582, d_mnist_loss: 0.0433, d_svhn_loss: 0.0149, d_fake_loss: 0.0679, g_loss: 1.4095\n",
            "Step [53780/60000], d_real_loss: 0.0447, d_mnist_loss: 0.0291, d_svhn_loss: 0.0156, d_fake_loss: 0.0278, g_loss: 1.0295\n",
            "Step [53790/60000], d_real_loss: 0.0724, d_mnist_loss: 0.0245, d_svhn_loss: 0.0479, d_fake_loss: 0.1110, g_loss: 1.0425\n",
            "Step [53800/60000], d_real_loss: 0.1021, d_mnist_loss: 0.0063, d_svhn_loss: 0.0958, d_fake_loss: 0.0867, g_loss: 1.1099\n",
            "Step [53810/60000], d_real_loss: 0.0426, d_mnist_loss: 0.0192, d_svhn_loss: 0.0234, d_fake_loss: 0.0521, g_loss: 1.0798\n",
            "Step [53820/60000], d_real_loss: 0.0222, d_mnist_loss: 0.0069, d_svhn_loss: 0.0153, d_fake_loss: 0.0240, g_loss: 1.0821\n",
            "Step [53830/60000], d_real_loss: 0.0520, d_mnist_loss: 0.0109, d_svhn_loss: 0.0410, d_fake_loss: 0.0287, g_loss: 1.1426\n",
            "Step [53840/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0058, d_svhn_loss: 0.0240, d_fake_loss: 0.0241, g_loss: 1.2106\n",
            "Step [53850/60000], d_real_loss: 0.0320, d_mnist_loss: 0.0139, d_svhn_loss: 0.0181, d_fake_loss: 0.0164, g_loss: 1.1461\n",
            "Step [53860/60000], d_real_loss: 0.0478, d_mnist_loss: 0.0064, d_svhn_loss: 0.0414, d_fake_loss: 0.0617, g_loss: 0.9924\n",
            "Step [53870/60000], d_real_loss: 0.0178, d_mnist_loss: 0.0066, d_svhn_loss: 0.0112, d_fake_loss: 0.1148, g_loss: 1.0887\n",
            "Step [53880/60000], d_real_loss: 0.0409, d_mnist_loss: 0.0080, d_svhn_loss: 0.0328, d_fake_loss: 0.0353, g_loss: 1.1843\n",
            "Step [53890/60000], d_real_loss: 0.0187, d_mnist_loss: 0.0050, d_svhn_loss: 0.0137, d_fake_loss: 0.0256, g_loss: 1.1892\n",
            "Step [53900/60000], d_real_loss: 0.0545, d_mnist_loss: 0.0063, d_svhn_loss: 0.0482, d_fake_loss: 0.0452, g_loss: 1.1867\n",
            "Step [53910/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0126, d_svhn_loss: 0.0314, d_fake_loss: 0.1274, g_loss: 1.0781\n",
            "Step [53920/60000], d_real_loss: 0.1352, d_mnist_loss: 0.0134, d_svhn_loss: 0.1218, d_fake_loss: 0.0844, g_loss: 1.1351\n",
            "Step [53930/60000], d_real_loss: 0.0219, d_mnist_loss: 0.0083, d_svhn_loss: 0.0136, d_fake_loss: 0.0244, g_loss: 1.0855\n",
            "Step [53940/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0080, d_svhn_loss: 0.0351, d_fake_loss: 0.0858, g_loss: 1.0098\n",
            "Step [53950/60000], d_real_loss: 0.0477, d_mnist_loss: 0.0111, d_svhn_loss: 0.0366, d_fake_loss: 0.0749, g_loss: 1.2323\n",
            "Step [53960/60000], d_real_loss: 0.0475, d_mnist_loss: 0.0183, d_svhn_loss: 0.0292, d_fake_loss: 0.0475, g_loss: 1.0173\n",
            "Step [53970/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0057, d_svhn_loss: 0.0330, d_fake_loss: 0.0173, g_loss: 1.1168\n",
            "Step [53980/60000], d_real_loss: 0.0591, d_mnist_loss: 0.0351, d_svhn_loss: 0.0240, d_fake_loss: 0.0285, g_loss: 1.5101\n",
            "Step [53990/60000], d_real_loss: 0.0293, d_mnist_loss: 0.0077, d_svhn_loss: 0.0215, d_fake_loss: 0.0349, g_loss: 1.1780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [54000/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0073, d_svhn_loss: 0.0269, d_fake_loss: 0.0307, g_loss: 1.1945\n",
            "saved ./samples_fashion/sample-54000-m-s.png\n",
            "saved ./samples_fashion/sample-54000-s-m.png\n",
            "Step [54010/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0088, d_svhn_loss: 0.0333, d_fake_loss: 0.0283, g_loss: 1.2327\n",
            "Step [54020/60000], d_real_loss: 0.3480, d_mnist_loss: 0.3149, d_svhn_loss: 0.0331, d_fake_loss: 0.0345, g_loss: 1.3171\n",
            "Step [54030/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0088, d_svhn_loss: 0.0563, d_fake_loss: 0.1301, g_loss: 1.1903\n",
            "Step [54040/60000], d_real_loss: 0.0312, d_mnist_loss: 0.0110, d_svhn_loss: 0.0203, d_fake_loss: 0.0211, g_loss: 1.0756\n",
            "Step [54050/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0193, d_svhn_loss: 0.0220, d_fake_loss: 0.0210, g_loss: 1.0579\n",
            "Step [54060/60000], d_real_loss: 0.0183, d_mnist_loss: 0.0078, d_svhn_loss: 0.0104, d_fake_loss: 0.0391, g_loss: 1.1315\n",
            "Step [54070/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0172, d_svhn_loss: 0.0226, d_fake_loss: 0.0529, g_loss: 1.0963\n",
            "Step [54080/60000], d_real_loss: 0.0268, d_mnist_loss: 0.0106, d_svhn_loss: 0.0162, d_fake_loss: 0.0208, g_loss: 1.1527\n",
            "Step [54090/60000], d_real_loss: 0.0612, d_mnist_loss: 0.0051, d_svhn_loss: 0.0561, d_fake_loss: 0.0245, g_loss: 1.1414\n",
            "Step [54100/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0122, d_svhn_loss: 0.0224, d_fake_loss: 0.0220, g_loss: 1.0660\n",
            "Step [54110/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0068, d_svhn_loss: 0.0173, d_fake_loss: 0.0468, g_loss: 0.9912\n",
            "Step [54120/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0145, d_svhn_loss: 0.0242, d_fake_loss: 0.0261, g_loss: 1.2001\n",
            "Step [54130/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0082, d_svhn_loss: 0.0181, d_fake_loss: 0.0223, g_loss: 1.2686\n",
            "Step [54140/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0050, d_svhn_loss: 0.0188, d_fake_loss: 0.0594, g_loss: 1.3320\n",
            "Step [54150/60000], d_real_loss: 0.0254, d_mnist_loss: 0.0068, d_svhn_loss: 0.0186, d_fake_loss: 0.0438, g_loss: 1.1787\n",
            "Step [54160/60000], d_real_loss: 0.0286, d_mnist_loss: 0.0090, d_svhn_loss: 0.0195, d_fake_loss: 0.0483, g_loss: 1.0867\n",
            "Step [54170/60000], d_real_loss: 0.0209, d_mnist_loss: 0.0068, d_svhn_loss: 0.0141, d_fake_loss: 0.0383, g_loss: 1.0285\n",
            "Step [54180/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0076, d_svhn_loss: 0.0381, d_fake_loss: 0.0415, g_loss: 0.9818\n",
            "Step [54190/60000], d_real_loss: 0.0240, d_mnist_loss: 0.0080, d_svhn_loss: 0.0160, d_fake_loss: 0.0471, g_loss: 1.3417\n",
            "Step [54200/60000], d_real_loss: 0.0338, d_mnist_loss: 0.0253, d_svhn_loss: 0.0086, d_fake_loss: 0.0826, g_loss: 0.9022\n",
            "Step [54210/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0150, d_svhn_loss: 0.0283, d_fake_loss: 0.0829, g_loss: 1.0073\n",
            "Step [54220/60000], d_real_loss: 0.0427, d_mnist_loss: 0.0079, d_svhn_loss: 0.0349, d_fake_loss: 0.0205, g_loss: 1.0648\n",
            "Step [54230/60000], d_real_loss: 0.0506, d_mnist_loss: 0.0112, d_svhn_loss: 0.0394, d_fake_loss: 0.0297, g_loss: 1.1604\n",
            "Step [54240/60000], d_real_loss: 0.0927, d_mnist_loss: 0.0209, d_svhn_loss: 0.0718, d_fake_loss: 0.1006, g_loss: 1.0122\n",
            "Step [54250/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0205, d_svhn_loss: 0.0156, d_fake_loss: 0.0952, g_loss: 0.9654\n",
            "Step [54260/60000], d_real_loss: 0.0568, d_mnist_loss: 0.0105, d_svhn_loss: 0.0463, d_fake_loss: 0.0534, g_loss: 0.9799\n",
            "Step [54270/60000], d_real_loss: 0.0782, d_mnist_loss: 0.0112, d_svhn_loss: 0.0670, d_fake_loss: 0.0218, g_loss: 1.1588\n",
            "Step [54280/60000], d_real_loss: 0.0677, d_mnist_loss: 0.0079, d_svhn_loss: 0.0597, d_fake_loss: 0.0273, g_loss: 1.1744\n",
            "Step [54290/60000], d_real_loss: 0.0220, d_mnist_loss: 0.0072, d_svhn_loss: 0.0148, d_fake_loss: 0.0216, g_loss: 1.2094\n",
            "Step [54300/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0134, d_svhn_loss: 0.0128, d_fake_loss: 0.0140, g_loss: 1.0131\n",
            "Step [54310/60000], d_real_loss: 0.0557, d_mnist_loss: 0.0300, d_svhn_loss: 0.0257, d_fake_loss: 0.1005, g_loss: 1.0089\n",
            "Step [54320/60000], d_real_loss: 0.1172, d_mnist_loss: 0.0646, d_svhn_loss: 0.0526, d_fake_loss: 0.0930, g_loss: 1.3555\n",
            "Step [54330/60000], d_real_loss: 0.0412, d_mnist_loss: 0.0199, d_svhn_loss: 0.0213, d_fake_loss: 0.0548, g_loss: 1.0099\n",
            "Step [54340/60000], d_real_loss: 0.0655, d_mnist_loss: 0.0352, d_svhn_loss: 0.0303, d_fake_loss: 0.0318, g_loss: 1.1032\n",
            "Step [54350/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0090, d_svhn_loss: 0.0189, d_fake_loss: 0.0446, g_loss: 1.0992\n",
            "Step [54360/60000], d_real_loss: 0.0835, d_mnist_loss: 0.0065, d_svhn_loss: 0.0770, d_fake_loss: 0.0529, g_loss: 1.0777\n",
            "Step [54370/60000], d_real_loss: 0.0278, d_mnist_loss: 0.0065, d_svhn_loss: 0.0213, d_fake_loss: 0.0227, g_loss: 1.1423\n",
            "Step [54380/60000], d_real_loss: 0.0234, d_mnist_loss: 0.0089, d_svhn_loss: 0.0146, d_fake_loss: 0.0180, g_loss: 1.1400\n",
            "Step [54390/60000], d_real_loss: 0.0940, d_mnist_loss: 0.0606, d_svhn_loss: 0.0334, d_fake_loss: 0.0416, g_loss: 1.4349\n",
            "Step [54400/60000], d_real_loss: 0.0194, d_mnist_loss: 0.0065, d_svhn_loss: 0.0129, d_fake_loss: 0.0260, g_loss: 1.0512\n",
            "Step [54410/60000], d_real_loss: 0.1539, d_mnist_loss: 0.0095, d_svhn_loss: 0.1444, d_fake_loss: 0.0307, g_loss: 1.1643\n",
            "Step [54420/60000], d_real_loss: 0.0499, d_mnist_loss: 0.0049, d_svhn_loss: 0.0450, d_fake_loss: 0.0274, g_loss: 1.0196\n",
            "Step [54430/60000], d_real_loss: 0.0845, d_mnist_loss: 0.0427, d_svhn_loss: 0.0419, d_fake_loss: 0.0302, g_loss: 0.9202\n",
            "Step [54440/60000], d_real_loss: 0.1101, d_mnist_loss: 0.0408, d_svhn_loss: 0.0693, d_fake_loss: 0.0537, g_loss: 0.9907\n",
            "Step [54450/60000], d_real_loss: 0.0199, d_mnist_loss: 0.0066, d_svhn_loss: 0.0133, d_fake_loss: 0.0224, g_loss: 0.9958\n",
            "Step [54460/60000], d_real_loss: 0.0258, d_mnist_loss: 0.0100, d_svhn_loss: 0.0157, d_fake_loss: 0.0986, g_loss: 1.1872\n",
            "Step [54470/60000], d_real_loss: 0.0472, d_mnist_loss: 0.0073, d_svhn_loss: 0.0399, d_fake_loss: 0.0497, g_loss: 1.0780\n",
            "Step [54480/60000], d_real_loss: 0.0376, d_mnist_loss: 0.0215, d_svhn_loss: 0.0160, d_fake_loss: 0.0617, g_loss: 1.0755\n",
            "Step [54490/60000], d_real_loss: 0.0689, d_mnist_loss: 0.0074, d_svhn_loss: 0.0615, d_fake_loss: 0.0639, g_loss: 1.0926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [54500/60000], d_real_loss: 0.0688, d_mnist_loss: 0.0127, d_svhn_loss: 0.0561, d_fake_loss: 0.0607, g_loss: 1.0572\n",
            "saved ./samples_fashion/sample-54500-m-s.png\n",
            "saved ./samples_fashion/sample-54500-s-m.png\n",
            "Step [54510/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0096, d_svhn_loss: 0.0245, d_fake_loss: 0.0186, g_loss: 1.1608\n",
            "Step [54520/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0183, d_svhn_loss: 0.0193, d_fake_loss: 0.0342, g_loss: 1.1089\n",
            "Step [54530/60000], d_real_loss: 0.0334, d_mnist_loss: 0.0187, d_svhn_loss: 0.0147, d_fake_loss: 0.0311, g_loss: 1.0260\n",
            "Step [54540/60000], d_real_loss: 0.1217, d_mnist_loss: 0.0098, d_svhn_loss: 0.1119, d_fake_loss: 0.0565, g_loss: 1.0471\n",
            "Step [54550/60000], d_real_loss: 0.0424, d_mnist_loss: 0.0145, d_svhn_loss: 0.0278, d_fake_loss: 0.0346, g_loss: 1.0836\n",
            "Step [54560/60000], d_real_loss: 0.0446, d_mnist_loss: 0.0074, d_svhn_loss: 0.0372, d_fake_loss: 0.0422, g_loss: 1.1491\n",
            "Step [54570/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0257, d_svhn_loss: 0.0142, d_fake_loss: 0.0541, g_loss: 1.0213\n",
            "Step [54580/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0079, d_svhn_loss: 0.0281, d_fake_loss: 0.0270, g_loss: 1.1405\n",
            "Step [54590/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0131, d_svhn_loss: 0.0302, d_fake_loss: 0.0511, g_loss: 1.2129\n",
            "Step [54600/60000], d_real_loss: 0.0585, d_mnist_loss: 0.0461, d_svhn_loss: 0.0124, d_fake_loss: 0.0955, g_loss: 1.1294\n",
            "Step [54610/60000], d_real_loss: 0.0751, d_mnist_loss: 0.0206, d_svhn_loss: 0.0545, d_fake_loss: 0.0342, g_loss: 1.0129\n",
            "Step [54620/60000], d_real_loss: 0.0873, d_mnist_loss: 0.0542, d_svhn_loss: 0.0331, d_fake_loss: 0.0249, g_loss: 1.1772\n",
            "Step [54630/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0103, d_svhn_loss: 0.0232, d_fake_loss: 0.0409, g_loss: 1.1462\n",
            "Step [54640/60000], d_real_loss: 0.0336, d_mnist_loss: 0.0122, d_svhn_loss: 0.0214, d_fake_loss: 0.1101, g_loss: 1.3778\n",
            "Step [54650/60000], d_real_loss: 0.0446, d_mnist_loss: 0.0090, d_svhn_loss: 0.0355, d_fake_loss: 0.0962, g_loss: 1.2815\n",
            "Step [54660/60000], d_real_loss: 0.1714, d_mnist_loss: 0.0105, d_svhn_loss: 0.1608, d_fake_loss: 0.0342, g_loss: 1.0747\n",
            "Step [54670/60000], d_real_loss: 0.0389, d_mnist_loss: 0.0221, d_svhn_loss: 0.0167, d_fake_loss: 0.0898, g_loss: 1.0646\n",
            "Step [54680/60000], d_real_loss: 0.0487, d_mnist_loss: 0.0107, d_svhn_loss: 0.0380, d_fake_loss: 0.0213, g_loss: 1.0423\n",
            "Step [54690/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0102, d_svhn_loss: 0.0222, d_fake_loss: 0.0422, g_loss: 1.2191\n",
            "Step [54700/60000], d_real_loss: 0.0548, d_mnist_loss: 0.0182, d_svhn_loss: 0.0367, d_fake_loss: 0.1538, g_loss: 1.3317\n",
            "Step [54710/60000], d_real_loss: 0.0423, d_mnist_loss: 0.0231, d_svhn_loss: 0.0192, d_fake_loss: 0.0303, g_loss: 1.1492\n",
            "Step [54720/60000], d_real_loss: 0.0206, d_mnist_loss: 0.0061, d_svhn_loss: 0.0145, d_fake_loss: 0.0225, g_loss: 1.1000\n",
            "Step [54730/60000], d_real_loss: 0.0421, d_mnist_loss: 0.0230, d_svhn_loss: 0.0191, d_fake_loss: 0.0632, g_loss: 1.0976\n",
            "Step [54740/60000], d_real_loss: 0.0381, d_mnist_loss: 0.0098, d_svhn_loss: 0.0284, d_fake_loss: 0.0834, g_loss: 1.1875\n",
            "Step [54750/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0089, d_svhn_loss: 0.0256, d_fake_loss: 0.0125, g_loss: 1.1316\n",
            "Step [54760/60000], d_real_loss: 0.0967, d_mnist_loss: 0.0111, d_svhn_loss: 0.0856, d_fake_loss: 0.0585, g_loss: 1.0707\n",
            "Step [54770/60000], d_real_loss: 0.0568, d_mnist_loss: 0.0094, d_svhn_loss: 0.0474, d_fake_loss: 0.0218, g_loss: 1.1260\n",
            "Step [54780/60000], d_real_loss: 0.0267, d_mnist_loss: 0.0076, d_svhn_loss: 0.0191, d_fake_loss: 0.0170, g_loss: 1.1280\n",
            "Step [54790/60000], d_real_loss: 0.0388, d_mnist_loss: 0.0134, d_svhn_loss: 0.0254, d_fake_loss: 0.0701, g_loss: 1.0102\n",
            "Step [54800/60000], d_real_loss: 0.0468, d_mnist_loss: 0.0239, d_svhn_loss: 0.0229, d_fake_loss: 0.0510, g_loss: 1.2624\n",
            "Step [54810/60000], d_real_loss: 0.1403, d_mnist_loss: 0.0652, d_svhn_loss: 0.0751, d_fake_loss: 0.0879, g_loss: 1.3182\n",
            "Step [54820/60000], d_real_loss: 0.0417, d_mnist_loss: 0.0127, d_svhn_loss: 0.0290, d_fake_loss: 0.0335, g_loss: 1.1010\n",
            "Step [54830/60000], d_real_loss: 0.0403, d_mnist_loss: 0.0205, d_svhn_loss: 0.0198, d_fake_loss: 0.0210, g_loss: 1.1822\n",
            "Step [54840/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0102, d_svhn_loss: 0.0222, d_fake_loss: 0.0236, g_loss: 1.1066\n",
            "Step [54850/60000], d_real_loss: 0.1117, d_mnist_loss: 0.0112, d_svhn_loss: 0.1005, d_fake_loss: 0.0208, g_loss: 1.3461\n",
            "Step [54860/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0118, d_svhn_loss: 0.0278, d_fake_loss: 0.0887, g_loss: 1.2100\n",
            "Step [54870/60000], d_real_loss: 0.0564, d_mnist_loss: 0.0148, d_svhn_loss: 0.0416, d_fake_loss: 0.0743, g_loss: 1.1996\n",
            "Step [54880/60000], d_real_loss: 0.0869, d_mnist_loss: 0.0053, d_svhn_loss: 0.0817, d_fake_loss: 0.0420, g_loss: 1.1197\n",
            "Step [54890/60000], d_real_loss: 0.0532, d_mnist_loss: 0.0394, d_svhn_loss: 0.0138, d_fake_loss: 0.0296, g_loss: 1.1162\n",
            "Step [54900/60000], d_real_loss: 0.0610, d_mnist_loss: 0.0254, d_svhn_loss: 0.0356, d_fake_loss: 0.1018, g_loss: 1.1284\n",
            "Step [54910/60000], d_real_loss: 0.0220, d_mnist_loss: 0.0057, d_svhn_loss: 0.0163, d_fake_loss: 0.0256, g_loss: 1.2337\n",
            "Step [54920/60000], d_real_loss: 0.0247, d_mnist_loss: 0.0116, d_svhn_loss: 0.0131, d_fake_loss: 0.0341, g_loss: 1.0356\n",
            "Step [54930/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0090, d_svhn_loss: 0.0213, d_fake_loss: 0.0210, g_loss: 1.0732\n",
            "Step [54940/60000], d_real_loss: 0.0340, d_mnist_loss: 0.0112, d_svhn_loss: 0.0228, d_fake_loss: 0.0271, g_loss: 1.0112\n",
            "Step [54950/60000], d_real_loss: 0.0635, d_mnist_loss: 0.0399, d_svhn_loss: 0.0236, d_fake_loss: 0.0859, g_loss: 1.2892\n",
            "Step [54960/60000], d_real_loss: 0.0251, d_mnist_loss: 0.0085, d_svhn_loss: 0.0166, d_fake_loss: 0.0295, g_loss: 1.0115\n",
            "Step [54970/60000], d_real_loss: 0.0451, d_mnist_loss: 0.0123, d_svhn_loss: 0.0327, d_fake_loss: 0.0175, g_loss: 1.0966\n",
            "Step [54980/60000], d_real_loss: 0.0370, d_mnist_loss: 0.0166, d_svhn_loss: 0.0204, d_fake_loss: 0.0187, g_loss: 1.0929\n",
            "Step [54990/60000], d_real_loss: 0.0222, d_mnist_loss: 0.0088, d_svhn_loss: 0.0134, d_fake_loss: 0.0788, g_loss: 1.0108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [55000/60000], d_real_loss: 0.0297, d_mnist_loss: 0.0055, d_svhn_loss: 0.0242, d_fake_loss: 0.0233, g_loss: 1.2509\n",
            "saved ./samples_fashion/sample-55000-m-s.png\n",
            "saved ./samples_fashion/sample-55000-s-m.png\n",
            "Step [55010/60000], d_real_loss: 0.0720, d_mnist_loss: 0.0081, d_svhn_loss: 0.0639, d_fake_loss: 0.1525, g_loss: 1.0575\n",
            "Step [55020/60000], d_real_loss: 0.0251, d_mnist_loss: 0.0078, d_svhn_loss: 0.0173, d_fake_loss: 0.0182, g_loss: 1.0438\n",
            "Step [55030/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0074, d_svhn_loss: 0.0275, d_fake_loss: 0.0728, g_loss: 1.5011\n",
            "Step [55040/60000], d_real_loss: 0.0601, d_mnist_loss: 0.0304, d_svhn_loss: 0.0297, d_fake_loss: 0.0454, g_loss: 1.0945\n",
            "Step [55050/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0203, d_svhn_loss: 0.0140, d_fake_loss: 0.0222, g_loss: 1.0341\n",
            "Step [55060/60000], d_real_loss: 0.1035, d_mnist_loss: 0.0231, d_svhn_loss: 0.0804, d_fake_loss: 0.0440, g_loss: 1.0873\n",
            "Step [55070/60000], d_real_loss: 0.0764, d_mnist_loss: 0.0241, d_svhn_loss: 0.0523, d_fake_loss: 0.0418, g_loss: 1.1522\n",
            "Step [55080/60000], d_real_loss: 0.0615, d_mnist_loss: 0.0387, d_svhn_loss: 0.0228, d_fake_loss: 0.0180, g_loss: 0.9919\n",
            "Step [55090/60000], d_real_loss: 0.0715, d_mnist_loss: 0.0554, d_svhn_loss: 0.0162, d_fake_loss: 0.0400, g_loss: 1.0609\n",
            "Step [55100/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0083, d_svhn_loss: 0.0283, d_fake_loss: 0.0736, g_loss: 1.0458\n",
            "Step [55110/60000], d_real_loss: 0.0442, d_mnist_loss: 0.0076, d_svhn_loss: 0.0365, d_fake_loss: 0.0221, g_loss: 1.1042\n",
            "Step [55120/60000], d_real_loss: 0.0360, d_mnist_loss: 0.0041, d_svhn_loss: 0.0319, d_fake_loss: 0.0371, g_loss: 1.1546\n",
            "Step [55130/60000], d_real_loss: 0.1215, d_mnist_loss: 0.0067, d_svhn_loss: 0.1148, d_fake_loss: 0.0952, g_loss: 1.2035\n",
            "Step [55140/60000], d_real_loss: 0.0584, d_mnist_loss: 0.0048, d_svhn_loss: 0.0536, d_fake_loss: 0.0199, g_loss: 1.2440\n",
            "Step [55150/60000], d_real_loss: 0.0202, d_mnist_loss: 0.0076, d_svhn_loss: 0.0126, d_fake_loss: 0.0207, g_loss: 1.1658\n",
            "Step [55160/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0088, d_svhn_loss: 0.0223, d_fake_loss: 0.0294, g_loss: 1.1222\n",
            "Step [55170/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0071, d_svhn_loss: 0.0286, d_fake_loss: 0.1474, g_loss: 0.9324\n",
            "Step [55180/60000], d_real_loss: 0.0342, d_mnist_loss: 0.0101, d_svhn_loss: 0.0241, d_fake_loss: 0.1638, g_loss: 1.3792\n",
            "Step [55190/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0129, d_svhn_loss: 0.0220, d_fake_loss: 0.0234, g_loss: 1.1022\n",
            "Step [55200/60000], d_real_loss: 0.0272, d_mnist_loss: 0.0107, d_svhn_loss: 0.0165, d_fake_loss: 0.0343, g_loss: 1.2743\n",
            "Step [55210/60000], d_real_loss: 0.0531, d_mnist_loss: 0.0115, d_svhn_loss: 0.0416, d_fake_loss: 0.0561, g_loss: 1.2394\n",
            "Step [55220/60000], d_real_loss: 0.0315, d_mnist_loss: 0.0074, d_svhn_loss: 0.0240, d_fake_loss: 0.0347, g_loss: 1.2249\n",
            "Step [55230/60000], d_real_loss: 0.0336, d_mnist_loss: 0.0202, d_svhn_loss: 0.0135, d_fake_loss: 0.0175, g_loss: 1.2049\n",
            "Step [55240/60000], d_real_loss: 0.0313, d_mnist_loss: 0.0149, d_svhn_loss: 0.0164, d_fake_loss: 0.0619, g_loss: 1.1348\n",
            "Step [55250/60000], d_real_loss: 0.0344, d_mnist_loss: 0.0144, d_svhn_loss: 0.0200, d_fake_loss: 0.0643, g_loss: 1.3394\n",
            "Step [55260/60000], d_real_loss: 0.0435, d_mnist_loss: 0.0174, d_svhn_loss: 0.0261, d_fake_loss: 0.0456, g_loss: 0.9876\n",
            "Step [55270/60000], d_real_loss: 0.0314, d_mnist_loss: 0.0085, d_svhn_loss: 0.0229, d_fake_loss: 0.0259, g_loss: 1.2097\n",
            "Step [55280/60000], d_real_loss: 0.0460, d_mnist_loss: 0.0159, d_svhn_loss: 0.0302, d_fake_loss: 0.0288, g_loss: 1.1351\n",
            "Step [55290/60000], d_real_loss: 0.0673, d_mnist_loss: 0.0091, d_svhn_loss: 0.0583, d_fake_loss: 0.0300, g_loss: 1.2630\n",
            "Step [55300/60000], d_real_loss: 0.0251, d_mnist_loss: 0.0092, d_svhn_loss: 0.0158, d_fake_loss: 0.0352, g_loss: 1.0071\n",
            "Step [55310/60000], d_real_loss: 0.0242, d_mnist_loss: 0.0055, d_svhn_loss: 0.0187, d_fake_loss: 0.0811, g_loss: 1.1335\n",
            "Step [55320/60000], d_real_loss: 0.0513, d_mnist_loss: 0.0162, d_svhn_loss: 0.0351, d_fake_loss: 0.0412, g_loss: 1.3370\n",
            "Step [55330/60000], d_real_loss: 0.0805, d_mnist_loss: 0.0326, d_svhn_loss: 0.0479, d_fake_loss: 0.0519, g_loss: 1.0184\n",
            "Step [55340/60000], d_real_loss: 0.0610, d_mnist_loss: 0.0283, d_svhn_loss: 0.0327, d_fake_loss: 0.0447, g_loss: 1.2347\n",
            "Step [55350/60000], d_real_loss: 0.0773, d_mnist_loss: 0.0282, d_svhn_loss: 0.0492, d_fake_loss: 0.0602, g_loss: 1.0829\n",
            "Step [55360/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0194, d_svhn_loss: 0.0209, d_fake_loss: 0.0243, g_loss: 1.2725\n",
            "Step [55370/60000], d_real_loss: 0.0289, d_mnist_loss: 0.0115, d_svhn_loss: 0.0174, d_fake_loss: 0.0259, g_loss: 1.1988\n",
            "Step [55380/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0061, d_svhn_loss: 0.0266, d_fake_loss: 0.0162, g_loss: 1.1284\n",
            "Step [55390/60000], d_real_loss: 0.0411, d_mnist_loss: 0.0114, d_svhn_loss: 0.0297, d_fake_loss: 0.0217, g_loss: 1.0816\n",
            "Step [55400/60000], d_real_loss: 0.0883, d_mnist_loss: 0.0321, d_svhn_loss: 0.0562, d_fake_loss: 0.0409, g_loss: 1.0331\n",
            "Step [55410/60000], d_real_loss: 0.0733, d_mnist_loss: 0.0110, d_svhn_loss: 0.0624, d_fake_loss: 0.0259, g_loss: 1.0298\n",
            "Step [55420/60000], d_real_loss: 0.0521, d_mnist_loss: 0.0319, d_svhn_loss: 0.0202, d_fake_loss: 0.0210, g_loss: 1.2714\n",
            "Step [55430/60000], d_real_loss: 0.0251, d_mnist_loss: 0.0121, d_svhn_loss: 0.0130, d_fake_loss: 0.0435, g_loss: 1.0442\n",
            "Step [55440/60000], d_real_loss: 0.0424, d_mnist_loss: 0.0226, d_svhn_loss: 0.0198, d_fake_loss: 0.0931, g_loss: 1.1684\n",
            "Step [55450/60000], d_real_loss: 0.0191, d_mnist_loss: 0.0074, d_svhn_loss: 0.0117, d_fake_loss: 0.0449, g_loss: 1.2018\n",
            "Step [55460/60000], d_real_loss: 0.0198, d_mnist_loss: 0.0076, d_svhn_loss: 0.0122, d_fake_loss: 0.0266, g_loss: 1.0949\n",
            "Step [55470/60000], d_real_loss: 0.0232, d_mnist_loss: 0.0084, d_svhn_loss: 0.0148, d_fake_loss: 0.0265, g_loss: 1.0472\n",
            "Step [55480/60000], d_real_loss: 0.0494, d_mnist_loss: 0.0162, d_svhn_loss: 0.0332, d_fake_loss: 0.0307, g_loss: 1.1425\n",
            "Step [55490/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0222, d_svhn_loss: 0.0230, d_fake_loss: 0.0280, g_loss: 1.1113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [55500/60000], d_real_loss: 0.0629, d_mnist_loss: 0.0425, d_svhn_loss: 0.0204, d_fake_loss: 0.0556, g_loss: 0.8931\n",
            "saved ./samples_fashion/sample-55500-m-s.png\n",
            "saved ./samples_fashion/sample-55500-s-m.png\n",
            "Step [55510/60000], d_real_loss: 0.0545, d_mnist_loss: 0.0157, d_svhn_loss: 0.0388, d_fake_loss: 0.0856, g_loss: 0.9682\n",
            "Step [55520/60000], d_real_loss: 0.0255, d_mnist_loss: 0.0073, d_svhn_loss: 0.0182, d_fake_loss: 0.0253, g_loss: 1.0596\n",
            "Step [55530/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0116, d_svhn_loss: 0.0212, d_fake_loss: 0.0273, g_loss: 1.0001\n",
            "Step [55540/60000], d_real_loss: 0.0202, d_mnist_loss: 0.0080, d_svhn_loss: 0.0122, d_fake_loss: 0.0377, g_loss: 1.2873\n",
            "Step [55550/60000], d_real_loss: 0.0563, d_mnist_loss: 0.0180, d_svhn_loss: 0.0384, d_fake_loss: 0.0518, g_loss: 1.1127\n",
            "Step [55560/60000], d_real_loss: 0.0431, d_mnist_loss: 0.0278, d_svhn_loss: 0.0153, d_fake_loss: 0.1380, g_loss: 1.0473\n",
            "Step [55570/60000], d_real_loss: 0.0371, d_mnist_loss: 0.0199, d_svhn_loss: 0.0172, d_fake_loss: 0.0477, g_loss: 1.1591\n",
            "Step [55580/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0095, d_svhn_loss: 0.0495, d_fake_loss: 0.0816, g_loss: 1.0598\n",
            "Step [55590/60000], d_real_loss: 0.0639, d_mnist_loss: 0.0109, d_svhn_loss: 0.0530, d_fake_loss: 0.0387, g_loss: 0.9923\n",
            "Step [55600/60000], d_real_loss: 0.0822, d_mnist_loss: 0.0229, d_svhn_loss: 0.0593, d_fake_loss: 0.0394, g_loss: 1.1005\n",
            "Step [55610/60000], d_real_loss: 0.0862, d_mnist_loss: 0.0116, d_svhn_loss: 0.0746, d_fake_loss: 0.0833, g_loss: 1.0764\n",
            "Step [55620/60000], d_real_loss: 0.0574, d_mnist_loss: 0.0377, d_svhn_loss: 0.0198, d_fake_loss: 0.0229, g_loss: 1.2465\n",
            "Step [55630/60000], d_real_loss: 0.0198, d_mnist_loss: 0.0076, d_svhn_loss: 0.0122, d_fake_loss: 0.0160, g_loss: 1.1430\n",
            "Step [55640/60000], d_real_loss: 0.0784, d_mnist_loss: 0.0591, d_svhn_loss: 0.0193, d_fake_loss: 0.0229, g_loss: 1.0336\n",
            "Step [55650/60000], d_real_loss: 0.0879, d_mnist_loss: 0.0438, d_svhn_loss: 0.0441, d_fake_loss: 0.0945, g_loss: 1.5080\n",
            "Step [55660/60000], d_real_loss: 0.0732, d_mnist_loss: 0.0417, d_svhn_loss: 0.0315, d_fake_loss: 0.0267, g_loss: 1.2964\n",
            "Step [55670/60000], d_real_loss: 0.0325, d_mnist_loss: 0.0122, d_svhn_loss: 0.0203, d_fake_loss: 0.0273, g_loss: 1.0898\n",
            "Step [55680/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0101, d_svhn_loss: 0.0263, d_fake_loss: 0.0234, g_loss: 1.1283\n",
            "Step [55690/60000], d_real_loss: 0.0269, d_mnist_loss: 0.0078, d_svhn_loss: 0.0192, d_fake_loss: 0.0207, g_loss: 1.1694\n",
            "Step [55700/60000], d_real_loss: 0.0684, d_mnist_loss: 0.0519, d_svhn_loss: 0.0165, d_fake_loss: 0.0480, g_loss: 1.0523\n",
            "Step [55710/60000], d_real_loss: 0.0347, d_mnist_loss: 0.0069, d_svhn_loss: 0.0277, d_fake_loss: 0.0259, g_loss: 1.0822\n",
            "Step [55720/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0115, d_svhn_loss: 0.0342, d_fake_loss: 0.0837, g_loss: 1.1278\n",
            "Step [55730/60000], d_real_loss: 0.0385, d_mnist_loss: 0.0179, d_svhn_loss: 0.0207, d_fake_loss: 0.0245, g_loss: 1.0263\n",
            "Step [55740/60000], d_real_loss: 0.0529, d_mnist_loss: 0.0132, d_svhn_loss: 0.0397, d_fake_loss: 0.0221, g_loss: 1.2789\n",
            "Step [55750/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0102, d_svhn_loss: 0.0405, d_fake_loss: 0.0342, g_loss: 1.1648\n",
            "Step [55760/60000], d_real_loss: 0.0523, d_mnist_loss: 0.0082, d_svhn_loss: 0.0441, d_fake_loss: 0.0341, g_loss: 1.1639\n",
            "Step [55770/60000], d_real_loss: 0.0456, d_mnist_loss: 0.0089, d_svhn_loss: 0.0367, d_fake_loss: 0.0202, g_loss: 1.1571\n",
            "Step [55780/60000], d_real_loss: 0.1618, d_mnist_loss: 0.0134, d_svhn_loss: 0.1484, d_fake_loss: 0.0398, g_loss: 1.0536\n",
            "Step [55790/60000], d_real_loss: 0.1694, d_mnist_loss: 0.1523, d_svhn_loss: 0.0171, d_fake_loss: 0.0201, g_loss: 1.3092\n",
            "Step [55800/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0198, d_svhn_loss: 0.0151, d_fake_loss: 0.0520, g_loss: 1.0287\n",
            "Step [55810/60000], d_real_loss: 0.0423, d_mnist_loss: 0.0112, d_svhn_loss: 0.0311, d_fake_loss: 0.0223, g_loss: 1.2090\n",
            "Step [55820/60000], d_real_loss: 0.0795, d_mnist_loss: 0.0155, d_svhn_loss: 0.0641, d_fake_loss: 0.0297, g_loss: 1.1039\n",
            "Step [55830/60000], d_real_loss: 0.0315, d_mnist_loss: 0.0071, d_svhn_loss: 0.0244, d_fake_loss: 0.1512, g_loss: 1.2330\n",
            "Step [55840/60000], d_real_loss: 0.0698, d_mnist_loss: 0.0426, d_svhn_loss: 0.0272, d_fake_loss: 0.0300, g_loss: 1.1540\n",
            "Step [55850/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0116, d_svhn_loss: 0.0175, d_fake_loss: 0.0439, g_loss: 1.0652\n",
            "Step [55860/60000], d_real_loss: 0.0478, d_mnist_loss: 0.0357, d_svhn_loss: 0.0121, d_fake_loss: 0.0249, g_loss: 1.1281\n",
            "Step [55870/60000], d_real_loss: 0.0199, d_mnist_loss: 0.0082, d_svhn_loss: 0.0118, d_fake_loss: 0.0151, g_loss: 1.0920\n",
            "Step [55880/60000], d_real_loss: 0.0785, d_mnist_loss: 0.0404, d_svhn_loss: 0.0382, d_fake_loss: 0.0689, g_loss: 1.3723\n",
            "Step [55890/60000], d_real_loss: 0.0258, d_mnist_loss: 0.0083, d_svhn_loss: 0.0176, d_fake_loss: 0.0199, g_loss: 1.0790\n",
            "Step [55900/60000], d_real_loss: 0.0546, d_mnist_loss: 0.0312, d_svhn_loss: 0.0233, d_fake_loss: 0.0302, g_loss: 1.0137\n",
            "Step [55910/60000], d_real_loss: 0.0662, d_mnist_loss: 0.0117, d_svhn_loss: 0.0544, d_fake_loss: 0.0563, g_loss: 0.8928\n",
            "Step [55920/60000], d_real_loss: 0.0464, d_mnist_loss: 0.0292, d_svhn_loss: 0.0173, d_fake_loss: 0.0414, g_loss: 1.1219\n",
            "Step [55930/60000], d_real_loss: 0.0801, d_mnist_loss: 0.0081, d_svhn_loss: 0.0720, d_fake_loss: 0.0736, g_loss: 1.1914\n",
            "Step [55940/60000], d_real_loss: 0.0411, d_mnist_loss: 0.0187, d_svhn_loss: 0.0224, d_fake_loss: 0.0153, g_loss: 1.0670\n",
            "Step [55950/60000], d_real_loss: 0.0209, d_mnist_loss: 0.0104, d_svhn_loss: 0.0105, d_fake_loss: 0.0926, g_loss: 1.0350\n",
            "Step [55960/60000], d_real_loss: 0.0986, d_mnist_loss: 0.0051, d_svhn_loss: 0.0935, d_fake_loss: 0.0484, g_loss: 1.1362\n",
            "Step [55970/60000], d_real_loss: 0.0332, d_mnist_loss: 0.0063, d_svhn_loss: 0.0270, d_fake_loss: 0.0277, g_loss: 1.1835\n",
            "Step [55980/60000], d_real_loss: 0.0888, d_mnist_loss: 0.0074, d_svhn_loss: 0.0814, d_fake_loss: 0.1478, g_loss: 1.0189\n",
            "Step [55990/60000], d_real_loss: 0.0595, d_mnist_loss: 0.0110, d_svhn_loss: 0.0485, d_fake_loss: 0.0483, g_loss: 1.1164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999999403953552, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [56000/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0108, d_svhn_loss: 0.0259, d_fake_loss: 0.0628, g_loss: 1.1210\n",
            "saved ./samples_fashion/sample-56000-m-s.png\n",
            "saved ./samples_fashion/sample-56000-s-m.png\n",
            "Step [56010/60000], d_real_loss: 0.0589, d_mnist_loss: 0.0421, d_svhn_loss: 0.0167, d_fake_loss: 0.0192, g_loss: 1.0010\n",
            "Step [56020/60000], d_real_loss: 0.0549, d_mnist_loss: 0.0128, d_svhn_loss: 0.0422, d_fake_loss: 0.0320, g_loss: 0.9491\n",
            "Step [56030/60000], d_real_loss: 0.0268, d_mnist_loss: 0.0095, d_svhn_loss: 0.0173, d_fake_loss: 0.0590, g_loss: 1.0281\n",
            "Step [56040/60000], d_real_loss: 0.0271, d_mnist_loss: 0.0058, d_svhn_loss: 0.0213, d_fake_loss: 0.0174, g_loss: 1.2080\n",
            "Step [56050/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0122, d_svhn_loss: 0.0157, d_fake_loss: 0.0379, g_loss: 1.0668\n",
            "Step [56060/60000], d_real_loss: 0.0238, d_mnist_loss: 0.0062, d_svhn_loss: 0.0176, d_fake_loss: 0.0291, g_loss: 1.2997\n",
            "Step [56070/60000], d_real_loss: 0.0505, d_mnist_loss: 0.0117, d_svhn_loss: 0.0388, d_fake_loss: 0.0461, g_loss: 0.9949\n",
            "Step [56080/60000], d_real_loss: 0.0281, d_mnist_loss: 0.0068, d_svhn_loss: 0.0213, d_fake_loss: 0.0748, g_loss: 1.3043\n",
            "Step [56090/60000], d_real_loss: 0.0463, d_mnist_loss: 0.0077, d_svhn_loss: 0.0385, d_fake_loss: 0.0259, g_loss: 1.0762\n",
            "Step [56100/60000], d_real_loss: 0.0618, d_mnist_loss: 0.0406, d_svhn_loss: 0.0211, d_fake_loss: 0.0126, g_loss: 1.0201\n",
            "Step [56110/60000], d_real_loss: 0.0273, d_mnist_loss: 0.0079, d_svhn_loss: 0.0194, d_fake_loss: 0.0283, g_loss: 1.1283\n",
            "Step [56120/60000], d_real_loss: 0.0635, d_mnist_loss: 0.0126, d_svhn_loss: 0.0509, d_fake_loss: 0.0668, g_loss: 1.1176\n",
            "Step [56130/60000], d_real_loss: 0.0364, d_mnist_loss: 0.0087, d_svhn_loss: 0.0277, d_fake_loss: 0.1327, g_loss: 1.0238\n",
            "Step [56140/60000], d_real_loss: 0.0754, d_mnist_loss: 0.0070, d_svhn_loss: 0.0683, d_fake_loss: 0.2363, g_loss: 1.0786\n",
            "Step [56150/60000], d_real_loss: 0.0628, d_mnist_loss: 0.0459, d_svhn_loss: 0.0170, d_fake_loss: 0.0303, g_loss: 1.1775\n",
            "Step [56160/60000], d_real_loss: 0.0365, d_mnist_loss: 0.0096, d_svhn_loss: 0.0269, d_fake_loss: 0.0300, g_loss: 1.1554\n",
            "Step [56170/60000], d_real_loss: 0.0455, d_mnist_loss: 0.0147, d_svhn_loss: 0.0308, d_fake_loss: 0.0620, g_loss: 0.9821\n",
            "Step [56180/60000], d_real_loss: 0.0349, d_mnist_loss: 0.0183, d_svhn_loss: 0.0166, d_fake_loss: 0.0215, g_loss: 1.0605\n",
            "Step [56190/60000], d_real_loss: 0.0321, d_mnist_loss: 0.0089, d_svhn_loss: 0.0232, d_fake_loss: 0.0254, g_loss: 1.0782\n",
            "Step [56200/60000], d_real_loss: 0.0908, d_mnist_loss: 0.0724, d_svhn_loss: 0.0183, d_fake_loss: 0.0390, g_loss: 1.2332\n",
            "Step [56210/60000], d_real_loss: 0.0295, d_mnist_loss: 0.0068, d_svhn_loss: 0.0227, d_fake_loss: 0.0275, g_loss: 1.0617\n",
            "Step [56220/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0064, d_svhn_loss: 0.0303, d_fake_loss: 0.0170, g_loss: 1.1665\n",
            "Step [56230/60000], d_real_loss: 0.0187, d_mnist_loss: 0.0058, d_svhn_loss: 0.0129, d_fake_loss: 0.0133, g_loss: 1.2858\n",
            "Step [56240/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0135, d_svhn_loss: 0.0447, d_fake_loss: 0.0358, g_loss: 1.1504\n",
            "Step [56250/60000], d_real_loss: 0.0391, d_mnist_loss: 0.0180, d_svhn_loss: 0.0211, d_fake_loss: 0.0658, g_loss: 1.1342\n",
            "Step [56260/60000], d_real_loss: 0.0198, d_mnist_loss: 0.0064, d_svhn_loss: 0.0134, d_fake_loss: 0.1433, g_loss: 1.1981\n",
            "Step [56270/60000], d_real_loss: 0.1604, d_mnist_loss: 0.0106, d_svhn_loss: 0.1497, d_fake_loss: 0.0590, g_loss: 1.0413\n",
            "Step [56280/60000], d_real_loss: 0.3008, d_mnist_loss: 0.1824, d_svhn_loss: 0.1183, d_fake_loss: 0.0407, g_loss: 1.5497\n",
            "Step [56290/60000], d_real_loss: 0.0378, d_mnist_loss: 0.0160, d_svhn_loss: 0.0218, d_fake_loss: 0.0224, g_loss: 1.0755\n",
            "Step [56300/60000], d_real_loss: 0.0370, d_mnist_loss: 0.0079, d_svhn_loss: 0.0291, d_fake_loss: 0.0492, g_loss: 1.2164\n",
            "Step [56310/60000], d_real_loss: 0.0423, d_mnist_loss: 0.0153, d_svhn_loss: 0.0269, d_fake_loss: 0.0361, g_loss: 1.0142\n",
            "Step [56320/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0140, d_svhn_loss: 0.0452, d_fake_loss: 0.0661, g_loss: 1.1938\n",
            "Step [56330/60000], d_real_loss: 0.0543, d_mnist_loss: 0.0078, d_svhn_loss: 0.0465, d_fake_loss: 0.0148, g_loss: 1.1131\n",
            "Step [56340/60000], d_real_loss: 0.1001, d_mnist_loss: 0.0057, d_svhn_loss: 0.0945, d_fake_loss: 0.0773, g_loss: 1.1142\n",
            "Step [56350/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0134, d_svhn_loss: 0.0128, d_fake_loss: 0.0943, g_loss: 1.2473\n",
            "Step [56360/60000], d_real_loss: 0.0218, d_mnist_loss: 0.0068, d_svhn_loss: 0.0150, d_fake_loss: 0.0187, g_loss: 1.1618\n",
            "Step [56370/60000], d_real_loss: 0.0214, d_mnist_loss: 0.0078, d_svhn_loss: 0.0136, d_fake_loss: 0.0432, g_loss: 1.0985\n",
            "Step [56380/60000], d_real_loss: 0.0333, d_mnist_loss: 0.0094, d_svhn_loss: 0.0240, d_fake_loss: 0.0568, g_loss: 1.0510\n",
            "Step [56390/60000], d_real_loss: 0.0378, d_mnist_loss: 0.0249, d_svhn_loss: 0.0130, d_fake_loss: 0.0214, g_loss: 1.1067\n",
            "Step [56400/60000], d_real_loss: 0.0230, d_mnist_loss: 0.0047, d_svhn_loss: 0.0183, d_fake_loss: 0.0335, g_loss: 1.0555\n",
            "Step [56410/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0119, d_svhn_loss: 0.0248, d_fake_loss: 0.0152, g_loss: 1.0231\n",
            "Step [56420/60000], d_real_loss: 0.0582, d_mnist_loss: 0.0073, d_svhn_loss: 0.0510, d_fake_loss: 0.1345, g_loss: 1.1339\n",
            "Step [56430/60000], d_real_loss: 0.0679, d_mnist_loss: 0.0148, d_svhn_loss: 0.0531, d_fake_loss: 0.0983, g_loss: 1.2403\n",
            "Step [56440/60000], d_real_loss: 0.0751, d_mnist_loss: 0.0092, d_svhn_loss: 0.0659, d_fake_loss: 0.0234, g_loss: 1.0972\n",
            "Step [56450/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0122, d_svhn_loss: 0.0360, d_fake_loss: 0.0213, g_loss: 1.0721\n",
            "Step [56460/60000], d_real_loss: 0.1776, d_mnist_loss: 0.1166, d_svhn_loss: 0.0611, d_fake_loss: 0.0875, g_loss: 1.7513\n",
            "Step [56470/60000], d_real_loss: 0.0309, d_mnist_loss: 0.0086, d_svhn_loss: 0.0223, d_fake_loss: 0.0285, g_loss: 1.1543\n",
            "Step [56480/60000], d_real_loss: 0.0260, d_mnist_loss: 0.0086, d_svhn_loss: 0.0174, d_fake_loss: 0.0819, g_loss: 1.1422\n",
            "Step [56490/60000], d_real_loss: 0.0469, d_mnist_loss: 0.0293, d_svhn_loss: 0.0176, d_fake_loss: 0.0350, g_loss: 0.9695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-0.9999992251396179, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [56500/60000], d_real_loss: 0.1226, d_mnist_loss: 0.0817, d_svhn_loss: 0.0409, d_fake_loss: 0.1097, g_loss: 0.9943\n",
            "saved ./samples_fashion/sample-56500-m-s.png\n",
            "saved ./samples_fashion/sample-56500-s-m.png\n",
            "Step [56510/60000], d_real_loss: 0.0450, d_mnist_loss: 0.0199, d_svhn_loss: 0.0251, d_fake_loss: 0.0416, g_loss: 1.1358\n",
            "Step [56520/60000], d_real_loss: 0.0300, d_mnist_loss: 0.0093, d_svhn_loss: 0.0207, d_fake_loss: 0.0360, g_loss: 1.1684\n",
            "Step [56530/60000], d_real_loss: 0.0487, d_mnist_loss: 0.0139, d_svhn_loss: 0.0348, d_fake_loss: 0.0469, g_loss: 1.1888\n",
            "Step [56540/60000], d_real_loss: 0.0491, d_mnist_loss: 0.0268, d_svhn_loss: 0.0224, d_fake_loss: 0.0376, g_loss: 1.0693\n",
            "Step [56550/60000], d_real_loss: 0.0216, d_mnist_loss: 0.0065, d_svhn_loss: 0.0151, d_fake_loss: 0.0288, g_loss: 1.2531\n",
            "Step [56560/60000], d_real_loss: 0.1751, d_mnist_loss: 0.0260, d_svhn_loss: 0.1491, d_fake_loss: 0.0386, g_loss: 1.1741\n",
            "Step [56570/60000], d_real_loss: 0.0287, d_mnist_loss: 0.0073, d_svhn_loss: 0.0214, d_fake_loss: 0.0186, g_loss: 1.1095\n",
            "Step [56580/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0177, d_svhn_loss: 0.0263, d_fake_loss: 0.0349, g_loss: 1.1538\n",
            "Step [56590/60000], d_real_loss: 0.0331, d_mnist_loss: 0.0114, d_svhn_loss: 0.0217, d_fake_loss: 0.0158, g_loss: 1.1760\n",
            "Step [56600/60000], d_real_loss: 0.0447, d_mnist_loss: 0.0072, d_svhn_loss: 0.0375, d_fake_loss: 0.0940, g_loss: 1.3454\n",
            "Step [56610/60000], d_real_loss: 0.0387, d_mnist_loss: 0.0082, d_svhn_loss: 0.0305, d_fake_loss: 0.0305, g_loss: 1.2321\n",
            "Step [56620/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0184, d_svhn_loss: 0.0140, d_fake_loss: 0.0426, g_loss: 1.0631\n",
            "Step [56630/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0074, d_svhn_loss: 0.0188, d_fake_loss: 0.0693, g_loss: 1.1134\n",
            "Step [56640/60000], d_real_loss: 0.0661, d_mnist_loss: 0.0082, d_svhn_loss: 0.0579, d_fake_loss: 0.0822, g_loss: 1.1758\n",
            "Step [56650/60000], d_real_loss: 0.0439, d_mnist_loss: 0.0078, d_svhn_loss: 0.0361, d_fake_loss: 0.0496, g_loss: 1.3086\n",
            "Step [56660/60000], d_real_loss: 0.0333, d_mnist_loss: 0.0099, d_svhn_loss: 0.0234, d_fake_loss: 0.1023, g_loss: 0.8841\n",
            "Step [56670/60000], d_real_loss: 0.0606, d_mnist_loss: 0.0133, d_svhn_loss: 0.0473, d_fake_loss: 0.0357, g_loss: 1.1149\n",
            "Step [56680/60000], d_real_loss: 0.0812, d_mnist_loss: 0.0146, d_svhn_loss: 0.0666, d_fake_loss: 0.0144, g_loss: 1.0520\n",
            "Step [56690/60000], d_real_loss: 0.1093, d_mnist_loss: 0.0076, d_svhn_loss: 0.1018, d_fake_loss: 0.0869, g_loss: 1.2237\n",
            "Step [56700/60000], d_real_loss: 0.1806, d_mnist_loss: 0.1547, d_svhn_loss: 0.0259, d_fake_loss: 0.0430, g_loss: 1.2055\n",
            "Step [56710/60000], d_real_loss: 0.0256, d_mnist_loss: 0.0076, d_svhn_loss: 0.0180, d_fake_loss: 0.0320, g_loss: 1.1219\n",
            "Step [56720/60000], d_real_loss: 0.0617, d_mnist_loss: 0.0111, d_svhn_loss: 0.0506, d_fake_loss: 0.0361, g_loss: 1.0795\n",
            "Step [56730/60000], d_real_loss: 0.0462, d_mnist_loss: 0.0091, d_svhn_loss: 0.0370, d_fake_loss: 0.0167, g_loss: 1.1489\n",
            "Step [56740/60000], d_real_loss: 0.0285, d_mnist_loss: 0.0106, d_svhn_loss: 0.0180, d_fake_loss: 0.0608, g_loss: 1.1556\n",
            "Step [56750/60000], d_real_loss: 0.0604, d_mnist_loss: 0.0389, d_svhn_loss: 0.0215, d_fake_loss: 0.0187, g_loss: 1.2393\n",
            "Step [56760/60000], d_real_loss: 0.0507, d_mnist_loss: 0.0248, d_svhn_loss: 0.0259, d_fake_loss: 0.0241, g_loss: 0.9558\n",
            "Step [56770/60000], d_real_loss: 0.0400, d_mnist_loss: 0.0055, d_svhn_loss: 0.0345, d_fake_loss: 0.0470, g_loss: 1.1737\n",
            "Step [56780/60000], d_real_loss: 0.0705, d_mnist_loss: 0.0158, d_svhn_loss: 0.0547, d_fake_loss: 0.0458, g_loss: 0.9724\n",
            "Step [56790/60000], d_real_loss: 0.0393, d_mnist_loss: 0.0243, d_svhn_loss: 0.0149, d_fake_loss: 0.0307, g_loss: 0.9960\n",
            "Step [56800/60000], d_real_loss: 0.0636, d_mnist_loss: 0.0235, d_svhn_loss: 0.0401, d_fake_loss: 0.0395, g_loss: 1.1427\n",
            "Step [56810/60000], d_real_loss: 0.0339, d_mnist_loss: 0.0068, d_svhn_loss: 0.0271, d_fake_loss: 0.0289, g_loss: 1.0017\n",
            "Step [56820/60000], d_real_loss: 0.0583, d_mnist_loss: 0.0360, d_svhn_loss: 0.0223, d_fake_loss: 0.1497, g_loss: 1.3109\n",
            "Step [56830/60000], d_real_loss: 0.0242, d_mnist_loss: 0.0093, d_svhn_loss: 0.0149, d_fake_loss: 0.0302, g_loss: 1.0436\n",
            "Step [56840/60000], d_real_loss: 0.0330, d_mnist_loss: 0.0098, d_svhn_loss: 0.0232, d_fake_loss: 0.0299, g_loss: 1.1825\n",
            "Step [56850/60000], d_real_loss: 0.0974, d_mnist_loss: 0.0141, d_svhn_loss: 0.0833, d_fake_loss: 0.1095, g_loss: 0.9667\n",
            "Step [56860/60000], d_real_loss: 0.0470, d_mnist_loss: 0.0080, d_svhn_loss: 0.0390, d_fake_loss: 0.0498, g_loss: 1.2349\n",
            "Step [56870/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0065, d_svhn_loss: 0.0188, d_fake_loss: 0.0782, g_loss: 1.1493\n",
            "Step [56880/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0190, d_svhn_loss: 0.0182, d_fake_loss: 0.0425, g_loss: 1.0791\n",
            "Step [56890/60000], d_real_loss: 0.1030, d_mnist_loss: 0.0065, d_svhn_loss: 0.0965, d_fake_loss: 0.0417, g_loss: 1.2126\n",
            "Step [56900/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0099, d_svhn_loss: 0.0368, d_fake_loss: 0.0224, g_loss: 0.8851\n",
            "Step [56910/60000], d_real_loss: 0.0802, d_mnist_loss: 0.0461, d_svhn_loss: 0.0341, d_fake_loss: 0.0704, g_loss: 1.1453\n",
            "Step [56920/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0082, d_svhn_loss: 0.0375, d_fake_loss: 0.0474, g_loss: 1.0891\n",
            "Step [56930/60000], d_real_loss: 0.0187, d_mnist_loss: 0.0088, d_svhn_loss: 0.0099, d_fake_loss: 0.0225, g_loss: 1.1484\n",
            "Step [56940/60000], d_real_loss: 0.0672, d_mnist_loss: 0.0251, d_svhn_loss: 0.0421, d_fake_loss: 0.0536, g_loss: 0.9576\n",
            "Step [56950/60000], d_real_loss: 0.0683, d_mnist_loss: 0.0256, d_svhn_loss: 0.0427, d_fake_loss: 0.0690, g_loss: 1.0413\n",
            "Step [56960/60000], d_real_loss: 0.0731, d_mnist_loss: 0.0081, d_svhn_loss: 0.0650, d_fake_loss: 0.0590, g_loss: 1.3035\n",
            "Step [56970/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0077, d_svhn_loss: 0.0249, d_fake_loss: 0.0365, g_loss: 1.1499\n",
            "Step [56980/60000], d_real_loss: 0.0644, d_mnist_loss: 0.0103, d_svhn_loss: 0.0542, d_fake_loss: 0.0415, g_loss: 1.2248\n",
            "Step [56990/60000], d_real_loss: 0.0322, d_mnist_loss: 0.0081, d_svhn_loss: 0.0241, d_fake_loss: 0.0336, g_loss: 1.2788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [57000/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0146, d_svhn_loss: 0.0155, d_fake_loss: 0.0209, g_loss: 1.0292\n",
            "saved ./samples_fashion/sample-57000-m-s.png\n",
            "saved ./samples_fashion/sample-57000-s-m.png\n",
            "Step [57010/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0146, d_svhn_loss: 0.0286, d_fake_loss: 0.0552, g_loss: 0.9981\n",
            "Step [57020/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0092, d_svhn_loss: 0.0231, d_fake_loss: 0.0739, g_loss: 1.2221\n",
            "Step [57030/60000], d_real_loss: 0.0296, d_mnist_loss: 0.0147, d_svhn_loss: 0.0149, d_fake_loss: 0.1422, g_loss: 0.9333\n",
            "Step [57040/60000], d_real_loss: 0.0197, d_mnist_loss: 0.0102, d_svhn_loss: 0.0095, d_fake_loss: 0.0774, g_loss: 1.2602\n",
            "Step [57050/60000], d_real_loss: 0.0512, d_mnist_loss: 0.0239, d_svhn_loss: 0.0273, d_fake_loss: 0.0282, g_loss: 1.1787\n",
            "Step [57060/60000], d_real_loss: 0.0560, d_mnist_loss: 0.0066, d_svhn_loss: 0.0494, d_fake_loss: 0.0137, g_loss: 1.1031\n",
            "Step [57070/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0216, d_svhn_loss: 0.0191, d_fake_loss: 0.0336, g_loss: 1.1661\n",
            "Step [57080/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0106, d_svhn_loss: 0.0141, d_fake_loss: 0.0608, g_loss: 0.9911\n",
            "Step [57090/60000], d_real_loss: 0.0597, d_mnist_loss: 0.0246, d_svhn_loss: 0.0351, d_fake_loss: 0.0156, g_loss: 1.1905\n",
            "Step [57100/60000], d_real_loss: 0.0584, d_mnist_loss: 0.0076, d_svhn_loss: 0.0508, d_fake_loss: 0.0375, g_loss: 1.2312\n",
            "Step [57110/60000], d_real_loss: 0.0510, d_mnist_loss: 0.0079, d_svhn_loss: 0.0431, d_fake_loss: 0.1096, g_loss: 1.0185\n",
            "Step [57120/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0212, d_svhn_loss: 0.0156, d_fake_loss: 0.0185, g_loss: 1.0076\n",
            "Step [57130/60000], d_real_loss: 0.0310, d_mnist_loss: 0.0142, d_svhn_loss: 0.0168, d_fake_loss: 0.0559, g_loss: 1.0455\n",
            "Step [57140/60000], d_real_loss: 0.0399, d_mnist_loss: 0.0136, d_svhn_loss: 0.0263, d_fake_loss: 0.0447, g_loss: 1.1621\n",
            "Step [57150/60000], d_real_loss: 0.0320, d_mnist_loss: 0.0064, d_svhn_loss: 0.0257, d_fake_loss: 0.0329, g_loss: 1.0601\n",
            "Step [57160/60000], d_real_loss: 0.0415, d_mnist_loss: 0.0062, d_svhn_loss: 0.0353, d_fake_loss: 0.0231, g_loss: 1.0703\n",
            "Step [57170/60000], d_real_loss: 0.0849, d_mnist_loss: 0.0092, d_svhn_loss: 0.0757, d_fake_loss: 0.0600, g_loss: 1.1291\n",
            "Step [57180/60000], d_real_loss: 0.0846, d_mnist_loss: 0.0295, d_svhn_loss: 0.0551, d_fake_loss: 0.0467, g_loss: 1.1158\n",
            "Step [57190/60000], d_real_loss: 0.1005, d_mnist_loss: 0.0160, d_svhn_loss: 0.0846, d_fake_loss: 0.0331, g_loss: 1.1420\n",
            "Step [57200/60000], d_real_loss: 0.0377, d_mnist_loss: 0.0093, d_svhn_loss: 0.0284, d_fake_loss: 0.1369, g_loss: 1.1634\n",
            "Step [57210/60000], d_real_loss: 0.0248, d_mnist_loss: 0.0069, d_svhn_loss: 0.0179, d_fake_loss: 0.0300, g_loss: 1.1749\n",
            "Step [57220/60000], d_real_loss: 0.1206, d_mnist_loss: 0.0239, d_svhn_loss: 0.0966, d_fake_loss: 0.0420, g_loss: 1.1010\n",
            "Step [57230/60000], d_real_loss: 0.0346, d_mnist_loss: 0.0130, d_svhn_loss: 0.0217, d_fake_loss: 0.0281, g_loss: 1.1650\n",
            "Step [57240/60000], d_real_loss: 0.0623, d_mnist_loss: 0.0129, d_svhn_loss: 0.0494, d_fake_loss: 0.0282, g_loss: 1.0592\n",
            "Step [57250/60000], d_real_loss: 0.0266, d_mnist_loss: 0.0127, d_svhn_loss: 0.0139, d_fake_loss: 0.0913, g_loss: 1.2317\n",
            "Step [57260/60000], d_real_loss: 0.0469, d_mnist_loss: 0.0047, d_svhn_loss: 0.0422, d_fake_loss: 0.0255, g_loss: 1.1828\n",
            "Step [57270/60000], d_real_loss: 0.0319, d_mnist_loss: 0.0051, d_svhn_loss: 0.0268, d_fake_loss: 0.0732, g_loss: 1.2451\n",
            "Step [57280/60000], d_real_loss: 0.0905, d_mnist_loss: 0.0072, d_svhn_loss: 0.0832, d_fake_loss: 0.0289, g_loss: 1.0550\n",
            "Step [57290/60000], d_real_loss: 0.0234, d_mnist_loss: 0.0102, d_svhn_loss: 0.0132, d_fake_loss: 0.0500, g_loss: 0.9493\n",
            "Step [57300/60000], d_real_loss: 0.0433, d_mnist_loss: 0.0097, d_svhn_loss: 0.0336, d_fake_loss: 0.0388, g_loss: 1.1698\n",
            "Step [57310/60000], d_real_loss: 0.0588, d_mnist_loss: 0.0076, d_svhn_loss: 0.0512, d_fake_loss: 0.0255, g_loss: 1.0630\n",
            "Step [57320/60000], d_real_loss: 0.0412, d_mnist_loss: 0.0062, d_svhn_loss: 0.0349, d_fake_loss: 0.0587, g_loss: 1.1395\n",
            "Step [57330/60000], d_real_loss: 0.0457, d_mnist_loss: 0.0234, d_svhn_loss: 0.0223, d_fake_loss: 0.0915, g_loss: 1.1613\n",
            "Step [57340/60000], d_real_loss: 0.0261, d_mnist_loss: 0.0051, d_svhn_loss: 0.0211, d_fake_loss: 0.0299, g_loss: 1.1322\n",
            "Step [57350/60000], d_real_loss: 0.0283, d_mnist_loss: 0.0058, d_svhn_loss: 0.0225, d_fake_loss: 0.0252, g_loss: 1.1780\n",
            "Step [57360/60000], d_real_loss: 0.0280, d_mnist_loss: 0.0081, d_svhn_loss: 0.0199, d_fake_loss: 0.0561, g_loss: 1.0319\n",
            "Step [57370/60000], d_real_loss: 0.0343, d_mnist_loss: 0.0058, d_svhn_loss: 0.0285, d_fake_loss: 0.0211, g_loss: 1.1555\n",
            "Step [57380/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0283, d_svhn_loss: 0.0370, d_fake_loss: 0.0394, g_loss: 1.1941\n",
            "Step [57390/60000], d_real_loss: 0.1310, d_mnist_loss: 0.0525, d_svhn_loss: 0.0785, d_fake_loss: 0.0622, g_loss: 1.1178\n",
            "Step [57400/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0071, d_svhn_loss: 0.0182, d_fake_loss: 0.0175, g_loss: 1.0351\n",
            "Step [57410/60000], d_real_loss: 0.0390, d_mnist_loss: 0.0199, d_svhn_loss: 0.0190, d_fake_loss: 0.0291, g_loss: 1.3355\n",
            "Step [57420/60000], d_real_loss: 0.0503, d_mnist_loss: 0.0213, d_svhn_loss: 0.0290, d_fake_loss: 0.0300, g_loss: 1.1179\n",
            "Step [57430/60000], d_real_loss: 0.0930, d_mnist_loss: 0.0112, d_svhn_loss: 0.0818, d_fake_loss: 0.0241, g_loss: 1.1052\n",
            "Step [57440/60000], d_real_loss: 0.0481, d_mnist_loss: 0.0169, d_svhn_loss: 0.0312, d_fake_loss: 0.0457, g_loss: 1.1160\n",
            "Step [57450/60000], d_real_loss: 0.0171, d_mnist_loss: 0.0061, d_svhn_loss: 0.0110, d_fake_loss: 0.0373, g_loss: 1.2597\n",
            "Step [57460/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0088, d_svhn_loss: 0.0344, d_fake_loss: 0.0457, g_loss: 1.2148\n",
            "Step [57470/60000], d_real_loss: 0.0682, d_mnist_loss: 0.0133, d_svhn_loss: 0.0549, d_fake_loss: 0.1670, g_loss: 1.1200\n",
            "Step [57480/60000], d_real_loss: 0.0247, d_mnist_loss: 0.0050, d_svhn_loss: 0.0197, d_fake_loss: 0.0286, g_loss: 1.1990\n",
            "Step [57490/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0119, d_svhn_loss: 0.0160, d_fake_loss: 0.0539, g_loss: 0.8222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [57500/60000], d_real_loss: 0.0265, d_mnist_loss: 0.0092, d_svhn_loss: 0.0173, d_fake_loss: 0.0818, g_loss: 1.2858\n",
            "saved ./samples_fashion/sample-57500-m-s.png\n",
            "saved ./samples_fashion/sample-57500-s-m.png\n",
            "Step [57510/60000], d_real_loss: 0.0665, d_mnist_loss: 0.0152, d_svhn_loss: 0.0513, d_fake_loss: 0.1209, g_loss: 1.1111\n",
            "Step [57520/60000], d_real_loss: 0.0230, d_mnist_loss: 0.0087, d_svhn_loss: 0.0143, d_fake_loss: 0.0185, g_loss: 1.1986\n",
            "Step [57530/60000], d_real_loss: 0.0264, d_mnist_loss: 0.0063, d_svhn_loss: 0.0201, d_fake_loss: 0.0801, g_loss: 1.1226\n",
            "Step [57540/60000], d_real_loss: 0.0678, d_mnist_loss: 0.0172, d_svhn_loss: 0.0506, d_fake_loss: 0.0999, g_loss: 1.2651\n",
            "Step [57550/60000], d_real_loss: 0.0548, d_mnist_loss: 0.0338, d_svhn_loss: 0.0210, d_fake_loss: 0.0719, g_loss: 1.2867\n",
            "Step [57560/60000], d_real_loss: 0.0579, d_mnist_loss: 0.0185, d_svhn_loss: 0.0394, d_fake_loss: 0.0461, g_loss: 1.1470\n",
            "Step [57570/60000], d_real_loss: 0.0329, d_mnist_loss: 0.0118, d_svhn_loss: 0.0211, d_fake_loss: 0.0229, g_loss: 1.0899\n",
            "Step [57580/60000], d_real_loss: 0.0378, d_mnist_loss: 0.0110, d_svhn_loss: 0.0269, d_fake_loss: 0.0548, g_loss: 1.0569\n",
            "Step [57590/60000], d_real_loss: 0.0770, d_mnist_loss: 0.0423, d_svhn_loss: 0.0347, d_fake_loss: 0.0208, g_loss: 1.1443\n",
            "Step [57600/60000], d_real_loss: 0.0964, d_mnist_loss: 0.0178, d_svhn_loss: 0.0786, d_fake_loss: 0.2351, g_loss: 1.0995\n",
            "Step [57610/60000], d_real_loss: 0.1023, d_mnist_loss: 0.0091, d_svhn_loss: 0.0932, d_fake_loss: 0.0441, g_loss: 1.0757\n",
            "Step [57620/60000], d_real_loss: 0.0252, d_mnist_loss: 0.0070, d_svhn_loss: 0.0182, d_fake_loss: 0.0294, g_loss: 1.0497\n",
            "Step [57630/60000], d_real_loss: 0.0397, d_mnist_loss: 0.0128, d_svhn_loss: 0.0269, d_fake_loss: 0.0303, g_loss: 1.1063\n",
            "Step [57640/60000], d_real_loss: 0.0548, d_mnist_loss: 0.0083, d_svhn_loss: 0.0465, d_fake_loss: 0.0444, g_loss: 1.0525\n",
            "Step [57650/60000], d_real_loss: 0.0328, d_mnist_loss: 0.0073, d_svhn_loss: 0.0255, d_fake_loss: 0.0454, g_loss: 1.2742\n",
            "Step [57660/60000], d_real_loss: 0.0465, d_mnist_loss: 0.0162, d_svhn_loss: 0.0302, d_fake_loss: 0.0678, g_loss: 1.1897\n",
            "Step [57670/60000], d_real_loss: 0.0867, d_mnist_loss: 0.0102, d_svhn_loss: 0.0765, d_fake_loss: 0.0283, g_loss: 1.1481\n",
            "Step [57680/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0080, d_svhn_loss: 0.0218, d_fake_loss: 0.0320, g_loss: 1.1268\n",
            "Step [57690/60000], d_real_loss: 0.0253, d_mnist_loss: 0.0123, d_svhn_loss: 0.0130, d_fake_loss: 0.0677, g_loss: 1.1816\n",
            "Step [57700/60000], d_real_loss: 0.0264, d_mnist_loss: 0.0101, d_svhn_loss: 0.0163, d_fake_loss: 0.0187, g_loss: 1.1188\n",
            "Step [57710/60000], d_real_loss: 0.0464, d_mnist_loss: 0.0119, d_svhn_loss: 0.0346, d_fake_loss: 0.0776, g_loss: 0.9944\n",
            "Step [57720/60000], d_real_loss: 0.0496, d_mnist_loss: 0.0120, d_svhn_loss: 0.0376, d_fake_loss: 0.0236, g_loss: 1.1674\n",
            "Step [57730/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0153, d_svhn_loss: 0.0174, d_fake_loss: 0.0131, g_loss: 1.0241\n",
            "Step [57740/60000], d_real_loss: 0.0643, d_mnist_loss: 0.0174, d_svhn_loss: 0.0469, d_fake_loss: 0.0631, g_loss: 1.0669\n",
            "Step [57750/60000], d_real_loss: 0.0407, d_mnist_loss: 0.0069, d_svhn_loss: 0.0339, d_fake_loss: 0.0476, g_loss: 1.2166\n",
            "Step [57760/60000], d_real_loss: 0.0445, d_mnist_loss: 0.0073, d_svhn_loss: 0.0372, d_fake_loss: 0.0167, g_loss: 1.0797\n",
            "Step [57770/60000], d_real_loss: 0.0218, d_mnist_loss: 0.0094, d_svhn_loss: 0.0124, d_fake_loss: 0.0939, g_loss: 1.0264\n",
            "Step [57780/60000], d_real_loss: 0.0355, d_mnist_loss: 0.0144, d_svhn_loss: 0.0211, d_fake_loss: 0.2217, g_loss: 1.2263\n",
            "Step [57790/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0143, d_svhn_loss: 0.0289, d_fake_loss: 0.0255, g_loss: 1.1125\n",
            "Step [57800/60000], d_real_loss: 0.0371, d_mnist_loss: 0.0116, d_svhn_loss: 0.0255, d_fake_loss: 0.1285, g_loss: 1.3213\n",
            "Step [57810/60000], d_real_loss: 0.1059, d_mnist_loss: 0.0076, d_svhn_loss: 0.0983, d_fake_loss: 0.0264, g_loss: 1.0401\n",
            "Step [57820/60000], d_real_loss: 0.0630, d_mnist_loss: 0.0437, d_svhn_loss: 0.0192, d_fake_loss: 0.0629, g_loss: 1.0952\n",
            "Step [57830/60000], d_real_loss: 0.0302, d_mnist_loss: 0.0053, d_svhn_loss: 0.0249, d_fake_loss: 0.0502, g_loss: 1.2548\n",
            "Step [57840/60000], d_real_loss: 0.0321, d_mnist_loss: 0.0179, d_svhn_loss: 0.0142, d_fake_loss: 0.0235, g_loss: 1.2665\n",
            "Step [57850/60000], d_real_loss: 0.0440, d_mnist_loss: 0.0223, d_svhn_loss: 0.0217, d_fake_loss: 0.0964, g_loss: 1.1817\n",
            "Step [57860/60000], d_real_loss: 0.0512, d_mnist_loss: 0.0276, d_svhn_loss: 0.0236, d_fake_loss: 0.0138, g_loss: 1.0639\n",
            "Step [57870/60000], d_real_loss: 0.1661, d_mnist_loss: 0.0083, d_svhn_loss: 0.1578, d_fake_loss: 0.0542, g_loss: 1.2310\n",
            "Step [57880/60000], d_real_loss: 0.0900, d_mnist_loss: 0.0233, d_svhn_loss: 0.0667, d_fake_loss: 0.0373, g_loss: 1.2921\n",
            "Step [57890/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0067, d_svhn_loss: 0.0238, d_fake_loss: 0.0279, g_loss: 1.1006\n",
            "Step [57900/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0106, d_svhn_loss: 0.0176, d_fake_loss: 0.0535, g_loss: 1.2614\n",
            "Step [57910/60000], d_real_loss: 0.0324, d_mnist_loss: 0.0056, d_svhn_loss: 0.0267, d_fake_loss: 0.0285, g_loss: 0.9661\n",
            "Step [57920/60000], d_real_loss: 0.0687, d_mnist_loss: 0.0267, d_svhn_loss: 0.0420, d_fake_loss: 0.0630, g_loss: 1.0187\n",
            "Step [57930/60000], d_real_loss: 0.0845, d_mnist_loss: 0.0219, d_svhn_loss: 0.0626, d_fake_loss: 0.1152, g_loss: 1.1583\n",
            "Step [57940/60000], d_real_loss: 0.1768, d_mnist_loss: 0.0071, d_svhn_loss: 0.1696, d_fake_loss: 0.1830, g_loss: 1.1208\n",
            "Step [57950/60000], d_real_loss: 0.0493, d_mnist_loss: 0.0168, d_svhn_loss: 0.0325, d_fake_loss: 0.0380, g_loss: 1.1155\n",
            "Step [57960/60000], d_real_loss: 0.0301, d_mnist_loss: 0.0056, d_svhn_loss: 0.0245, d_fake_loss: 0.0563, g_loss: 1.6558\n",
            "Step [57970/60000], d_real_loss: 0.0497, d_mnist_loss: 0.0149, d_svhn_loss: 0.0348, d_fake_loss: 0.0352, g_loss: 1.0867\n",
            "Step [57980/60000], d_real_loss: 0.0273, d_mnist_loss: 0.0090, d_svhn_loss: 0.0182, d_fake_loss: 0.0461, g_loss: 1.2013\n",
            "Step [57990/60000], d_real_loss: 0.0246, d_mnist_loss: 0.0055, d_svhn_loss: 0.0191, d_fake_loss: 0.0348, g_loss: 1.1726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [58000/60000], d_real_loss: 0.0268, d_mnist_loss: 0.0121, d_svhn_loss: 0.0147, d_fake_loss: 0.0368, g_loss: 0.8946\n",
            "saved ./samples_fashion/sample-58000-m-s.png\n",
            "saved ./samples_fashion/sample-58000-s-m.png\n",
            "Step [58010/60000], d_real_loss: 0.0402, d_mnist_loss: 0.0158, d_svhn_loss: 0.0244, d_fake_loss: 0.0327, g_loss: 1.1243\n",
            "Step [58020/60000], d_real_loss: 0.0614, d_mnist_loss: 0.0090, d_svhn_loss: 0.0525, d_fake_loss: 0.0208, g_loss: 1.1071\n",
            "Step [58030/60000], d_real_loss: 0.0434, d_mnist_loss: 0.0237, d_svhn_loss: 0.0197, d_fake_loss: 0.0378, g_loss: 1.0980\n",
            "Step [58040/60000], d_real_loss: 0.0612, d_mnist_loss: 0.0061, d_svhn_loss: 0.0551, d_fake_loss: 0.2038, g_loss: 1.0634\n",
            "Step [58050/60000], d_real_loss: 0.0265, d_mnist_loss: 0.0118, d_svhn_loss: 0.0148, d_fake_loss: 0.0191, g_loss: 1.1734\n",
            "Step [58060/60000], d_real_loss: 0.1042, d_mnist_loss: 0.0096, d_svhn_loss: 0.0946, d_fake_loss: 0.0497, g_loss: 1.1261\n",
            "Step [58070/60000], d_real_loss: 0.0355, d_mnist_loss: 0.0162, d_svhn_loss: 0.0193, d_fake_loss: 0.0413, g_loss: 1.1540\n",
            "Step [58080/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0184, d_svhn_loss: 0.0298, d_fake_loss: 0.0274, g_loss: 1.0536\n",
            "Step [58090/60000], d_real_loss: 0.1038, d_mnist_loss: 0.0642, d_svhn_loss: 0.0396, d_fake_loss: 0.1903, g_loss: 0.9348\n",
            "Step [58100/60000], d_real_loss: 0.1774, d_mnist_loss: 0.0351, d_svhn_loss: 0.1423, d_fake_loss: 0.0625, g_loss: 1.0265\n",
            "Step [58110/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0083, d_svhn_loss: 0.0223, d_fake_loss: 0.0197, g_loss: 1.0863\n",
            "Step [58120/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0083, d_svhn_loss: 0.0158, d_fake_loss: 0.0194, g_loss: 1.1194\n",
            "Step [58130/60000], d_real_loss: 0.0268, d_mnist_loss: 0.0054, d_svhn_loss: 0.0214, d_fake_loss: 0.0613, g_loss: 1.1846\n",
            "Step [58140/60000], d_real_loss: 0.0209, d_mnist_loss: 0.0048, d_svhn_loss: 0.0161, d_fake_loss: 0.0808, g_loss: 1.3453\n",
            "Step [58150/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0222, d_svhn_loss: 0.0160, d_fake_loss: 0.0150, g_loss: 1.1111\n",
            "Step [58160/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0108, d_svhn_loss: 0.0191, d_fake_loss: 0.0550, g_loss: 0.8492\n",
            "Step [58170/60000], d_real_loss: 0.0428, d_mnist_loss: 0.0074, d_svhn_loss: 0.0354, d_fake_loss: 0.0462, g_loss: 1.0900\n",
            "Step [58180/60000], d_real_loss: 0.0274, d_mnist_loss: 0.0083, d_svhn_loss: 0.0191, d_fake_loss: 0.0343, g_loss: 1.0717\n",
            "Step [58190/60000], d_real_loss: 0.0673, d_mnist_loss: 0.0085, d_svhn_loss: 0.0588, d_fake_loss: 0.0257, g_loss: 1.1826\n",
            "Step [58200/60000], d_real_loss: 0.0486, d_mnist_loss: 0.0275, d_svhn_loss: 0.0212, d_fake_loss: 0.0316, g_loss: 1.2501\n",
            "Step [58210/60000], d_real_loss: 0.0304, d_mnist_loss: 0.0115, d_svhn_loss: 0.0189, d_fake_loss: 0.0146, g_loss: 1.1665\n",
            "Step [58220/60000], d_real_loss: 0.0852, d_mnist_loss: 0.0744, d_svhn_loss: 0.0109, d_fake_loss: 0.0375, g_loss: 1.0332\n",
            "Step [58230/60000], d_real_loss: 0.0990, d_mnist_loss: 0.0135, d_svhn_loss: 0.0856, d_fake_loss: 0.0691, g_loss: 1.1179\n",
            "Step [58240/60000], d_real_loss: 0.0472, d_mnist_loss: 0.0308, d_svhn_loss: 0.0163, d_fake_loss: 0.1354, g_loss: 1.0956\n",
            "Step [58250/60000], d_real_loss: 0.1401, d_mnist_loss: 0.0562, d_svhn_loss: 0.0839, d_fake_loss: 0.0379, g_loss: 1.0522\n",
            "Step [58260/60000], d_real_loss: 0.1748, d_mnist_loss: 0.0371, d_svhn_loss: 0.1377, d_fake_loss: 0.0320, g_loss: 1.0117\n",
            "Step [58270/60000], d_real_loss: 0.0289, d_mnist_loss: 0.0132, d_svhn_loss: 0.0157, d_fake_loss: 0.0178, g_loss: 0.9779\n",
            "Step [58280/60000], d_real_loss: 0.1099, d_mnist_loss: 0.0350, d_svhn_loss: 0.0749, d_fake_loss: 0.0293, g_loss: 1.0445\n",
            "Step [58290/60000], d_real_loss: 0.0233, d_mnist_loss: 0.0087, d_svhn_loss: 0.0146, d_fake_loss: 0.0297, g_loss: 1.0567\n",
            "Step [58300/60000], d_real_loss: 0.0489, d_mnist_loss: 0.0082, d_svhn_loss: 0.0407, d_fake_loss: 0.0313, g_loss: 1.0735\n",
            "Step [58310/60000], d_real_loss: 0.0259, d_mnist_loss: 0.0074, d_svhn_loss: 0.0185, d_fake_loss: 0.0577, g_loss: 1.1045\n",
            "Step [58320/60000], d_real_loss: 0.0255, d_mnist_loss: 0.0107, d_svhn_loss: 0.0148, d_fake_loss: 0.0811, g_loss: 1.2874\n",
            "Step [58330/60000], d_real_loss: 0.0228, d_mnist_loss: 0.0071, d_svhn_loss: 0.0156, d_fake_loss: 0.1276, g_loss: 1.0257\n",
            "Step [58340/60000], d_real_loss: 0.0255, d_mnist_loss: 0.0073, d_svhn_loss: 0.0182, d_fake_loss: 0.0291, g_loss: 0.9388\n",
            "Step [58350/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0183, d_svhn_loss: 0.0140, d_fake_loss: 0.0197, g_loss: 1.1182\n",
            "Step [58360/60000], d_real_loss: 0.0359, d_mnist_loss: 0.0081, d_svhn_loss: 0.0277, d_fake_loss: 0.0160, g_loss: 1.0879\n",
            "Step [58370/60000], d_real_loss: 0.0250, d_mnist_loss: 0.0060, d_svhn_loss: 0.0190, d_fake_loss: 0.0317, g_loss: 1.1608\n",
            "Step [58380/60000], d_real_loss: 0.0266, d_mnist_loss: 0.0161, d_svhn_loss: 0.0106, d_fake_loss: 0.0465, g_loss: 1.1417\n",
            "Step [58390/60000], d_real_loss: 0.0671, d_mnist_loss: 0.0058, d_svhn_loss: 0.0613, d_fake_loss: 0.0477, g_loss: 1.1417\n",
            "Step [58400/60000], d_real_loss: 0.0368, d_mnist_loss: 0.0197, d_svhn_loss: 0.0171, d_fake_loss: 0.0574, g_loss: 1.1197\n",
            "Step [58410/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0141, d_svhn_loss: 0.0201, d_fake_loss: 0.0607, g_loss: 1.0888\n",
            "Step [58420/60000], d_real_loss: 0.0374, d_mnist_loss: 0.0047, d_svhn_loss: 0.0327, d_fake_loss: 0.0182, g_loss: 1.1017\n",
            "Step [58430/60000], d_real_loss: 0.0482, d_mnist_loss: 0.0116, d_svhn_loss: 0.0366, d_fake_loss: 0.0436, g_loss: 1.2370\n",
            "Step [58440/60000], d_real_loss: 0.0180, d_mnist_loss: 0.0077, d_svhn_loss: 0.0103, d_fake_loss: 0.0369, g_loss: 1.0740\n",
            "Step [58450/60000], d_real_loss: 0.0282, d_mnist_loss: 0.0135, d_svhn_loss: 0.0147, d_fake_loss: 0.0140, g_loss: 1.0462\n",
            "Step [58460/60000], d_real_loss: 0.0305, d_mnist_loss: 0.0043, d_svhn_loss: 0.0261, d_fake_loss: 0.0256, g_loss: 1.1765\n",
            "Step [58470/60000], d_real_loss: 0.0367, d_mnist_loss: 0.0075, d_svhn_loss: 0.0292, d_fake_loss: 0.0449, g_loss: 1.1366\n",
            "Step [58480/60000], d_real_loss: 0.0373, d_mnist_loss: 0.0068, d_svhn_loss: 0.0305, d_fake_loss: 0.0245, g_loss: 1.1776\n",
            "Step [58490/60000], d_real_loss: 0.0745, d_mnist_loss: 0.0323, d_svhn_loss: 0.0422, d_fake_loss: 0.0322, g_loss: 1.2072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [58500/60000], d_real_loss: 0.0276, d_mnist_loss: 0.0085, d_svhn_loss: 0.0191, d_fake_loss: 0.0317, g_loss: 1.1029\n",
            "saved ./samples_fashion/sample-58500-m-s.png\n",
            "saved ./samples_fashion/sample-58500-s-m.png\n",
            "Step [58510/60000], d_real_loss: 0.0285, d_mnist_loss: 0.0099, d_svhn_loss: 0.0187, d_fake_loss: 0.0236, g_loss: 1.0668\n",
            "Step [58520/60000], d_real_loss: 0.0659, d_mnist_loss: 0.0426, d_svhn_loss: 0.0233, d_fake_loss: 0.0217, g_loss: 1.0775\n",
            "Step [58530/60000], d_real_loss: 0.0690, d_mnist_loss: 0.0161, d_svhn_loss: 0.0529, d_fake_loss: 0.0313, g_loss: 1.1627\n",
            "Step [58540/60000], d_real_loss: 0.0257, d_mnist_loss: 0.0115, d_svhn_loss: 0.0142, d_fake_loss: 0.0420, g_loss: 1.1036\n",
            "Step [58550/60000], d_real_loss: 0.0268, d_mnist_loss: 0.0076, d_svhn_loss: 0.0192, d_fake_loss: 0.0482, g_loss: 1.0770\n",
            "Step [58560/60000], d_real_loss: 0.0306, d_mnist_loss: 0.0093, d_svhn_loss: 0.0214, d_fake_loss: 0.0189, g_loss: 1.0935\n",
            "Step [58570/60000], d_real_loss: 0.0323, d_mnist_loss: 0.0125, d_svhn_loss: 0.0198, d_fake_loss: 0.0272, g_loss: 1.3133\n",
            "Step [58580/60000], d_real_loss: 0.0358, d_mnist_loss: 0.0107, d_svhn_loss: 0.0251, d_fake_loss: 0.0789, g_loss: 1.2173\n",
            "Step [58590/60000], d_real_loss: 0.0375, d_mnist_loss: 0.0094, d_svhn_loss: 0.0280, d_fake_loss: 0.0273, g_loss: 1.1490\n",
            "Step [58600/60000], d_real_loss: 0.0361, d_mnist_loss: 0.0184, d_svhn_loss: 0.0177, d_fake_loss: 0.0413, g_loss: 1.0703\n",
            "Step [58610/60000], d_real_loss: 0.0572, d_mnist_loss: 0.0067, d_svhn_loss: 0.0505, d_fake_loss: 0.0368, g_loss: 1.1732\n",
            "Step [58620/60000], d_real_loss: 0.0180, d_mnist_loss: 0.0058, d_svhn_loss: 0.0123, d_fake_loss: 0.0488, g_loss: 1.2112\n",
            "Step [58630/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0088, d_svhn_loss: 0.0228, d_fake_loss: 0.0266, g_loss: 1.1864\n",
            "Step [58640/60000], d_real_loss: 0.0526, d_mnist_loss: 0.0078, d_svhn_loss: 0.0447, d_fake_loss: 0.0649, g_loss: 1.1336\n",
            "Step [58650/60000], d_real_loss: 0.1030, d_mnist_loss: 0.0393, d_svhn_loss: 0.0637, d_fake_loss: 0.0480, g_loss: 1.2095\n",
            "Step [58660/60000], d_real_loss: 0.0326, d_mnist_loss: 0.0121, d_svhn_loss: 0.0206, d_fake_loss: 0.0387, g_loss: 1.0009\n",
            "Step [58670/60000], d_real_loss: 0.0622, d_mnist_loss: 0.0209, d_svhn_loss: 0.0413, d_fake_loss: 0.0344, g_loss: 1.0403\n",
            "Step [58680/60000], d_real_loss: 0.0328, d_mnist_loss: 0.0082, d_svhn_loss: 0.0246, d_fake_loss: 0.0213, g_loss: 1.1894\n",
            "Step [58690/60000], d_real_loss: 0.0255, d_mnist_loss: 0.0125, d_svhn_loss: 0.0130, d_fake_loss: 0.1152, g_loss: 1.3187\n",
            "Step [58700/60000], d_real_loss: 0.0241, d_mnist_loss: 0.0089, d_svhn_loss: 0.0152, d_fake_loss: 0.0167, g_loss: 1.1226\n",
            "Step [58710/60000], d_real_loss: 0.2605, d_mnist_loss: 0.2265, d_svhn_loss: 0.0339, d_fake_loss: 0.0665, g_loss: 0.9012\n",
            "Step [58720/60000], d_real_loss: 0.0445, d_mnist_loss: 0.0092, d_svhn_loss: 0.0353, d_fake_loss: 0.0531, g_loss: 0.9522\n",
            "Step [58730/60000], d_real_loss: 0.0553, d_mnist_loss: 0.0336, d_svhn_loss: 0.0217, d_fake_loss: 0.0309, g_loss: 1.0652\n",
            "Step [58740/60000], d_real_loss: 0.0332, d_mnist_loss: 0.0070, d_svhn_loss: 0.0262, d_fake_loss: 0.0735, g_loss: 1.0374\n",
            "Step [58750/60000], d_real_loss: 0.0311, d_mnist_loss: 0.0074, d_svhn_loss: 0.0237, d_fake_loss: 0.0294, g_loss: 1.1881\n",
            "Step [58760/60000], d_real_loss: 0.0388, d_mnist_loss: 0.0110, d_svhn_loss: 0.0278, d_fake_loss: 0.1182, g_loss: 0.9520\n",
            "Step [58770/60000], d_real_loss: 0.0590, d_mnist_loss: 0.0184, d_svhn_loss: 0.0405, d_fake_loss: 0.0208, g_loss: 1.0978\n",
            "Step [58780/60000], d_real_loss: 0.0361, d_mnist_loss: 0.0092, d_svhn_loss: 0.0269, d_fake_loss: 0.0337, g_loss: 0.9986\n",
            "Step [58790/60000], d_real_loss: 0.0492, d_mnist_loss: 0.0281, d_svhn_loss: 0.0211, d_fake_loss: 0.0272, g_loss: 1.0634\n",
            "Step [58800/60000], d_real_loss: 0.0279, d_mnist_loss: 0.0120, d_svhn_loss: 0.0159, d_fake_loss: 0.0453, g_loss: 0.9757\n",
            "Step [58810/60000], d_real_loss: 0.0362, d_mnist_loss: 0.0073, d_svhn_loss: 0.0289, d_fake_loss: 0.0660, g_loss: 1.0860\n",
            "Step [58820/60000], d_real_loss: 0.0553, d_mnist_loss: 0.0297, d_svhn_loss: 0.0256, d_fake_loss: 0.0206, g_loss: 1.0079\n",
            "Step [58830/60000], d_real_loss: 0.0936, d_mnist_loss: 0.0074, d_svhn_loss: 0.0862, d_fake_loss: 0.0272, g_loss: 1.0071\n",
            "Step [58840/60000], d_real_loss: 0.0472, d_mnist_loss: 0.0111, d_svhn_loss: 0.0361, d_fake_loss: 0.0345, g_loss: 1.1690\n",
            "Step [58850/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0251, d_svhn_loss: 0.0154, d_fake_loss: 0.0538, g_loss: 1.1901\n",
            "Step [58860/60000], d_real_loss: 0.0289, d_mnist_loss: 0.0083, d_svhn_loss: 0.0207, d_fake_loss: 0.0546, g_loss: 1.2271\n",
            "Step [58870/60000], d_real_loss: 0.0720, d_mnist_loss: 0.0373, d_svhn_loss: 0.0348, d_fake_loss: 0.0175, g_loss: 1.0144\n",
            "Step [58880/60000], d_real_loss: 0.0318, d_mnist_loss: 0.0115, d_svhn_loss: 0.0203, d_fake_loss: 0.0286, g_loss: 1.0121\n",
            "Step [58890/60000], d_real_loss: 0.0303, d_mnist_loss: 0.0053, d_svhn_loss: 0.0250, d_fake_loss: 0.0247, g_loss: 1.0932\n",
            "Step [58900/60000], d_real_loss: 0.0416, d_mnist_loss: 0.0257, d_svhn_loss: 0.0159, d_fake_loss: 0.0242, g_loss: 1.2216\n",
            "Step [58910/60000], d_real_loss: 0.0260, d_mnist_loss: 0.0077, d_svhn_loss: 0.0183, d_fake_loss: 0.1098, g_loss: 1.3007\n",
            "Step [58920/60000], d_real_loss: 0.0467, d_mnist_loss: 0.0196, d_svhn_loss: 0.0271, d_fake_loss: 0.2937, g_loss: 1.0670\n",
            "Step [58930/60000], d_real_loss: 0.0733, d_mnist_loss: 0.0137, d_svhn_loss: 0.0595, d_fake_loss: 0.0246, g_loss: 1.1777\n",
            "Step [58940/60000], d_real_loss: 0.0257, d_mnist_loss: 0.0070, d_svhn_loss: 0.0187, d_fake_loss: 0.0242, g_loss: 1.1446\n",
            "Step [58950/60000], d_real_loss: 0.0634, d_mnist_loss: 0.0087, d_svhn_loss: 0.0546, d_fake_loss: 0.0204, g_loss: 1.1167\n",
            "Step [58960/60000], d_real_loss: 0.0265, d_mnist_loss: 0.0065, d_svhn_loss: 0.0200, d_fake_loss: 0.0194, g_loss: 1.1027\n",
            "Step [58970/60000], d_real_loss: 0.0415, d_mnist_loss: 0.0096, d_svhn_loss: 0.0319, d_fake_loss: 0.1116, g_loss: 1.2268\n",
            "Step [58980/60000], d_real_loss: 0.1421, d_mnist_loss: 0.0088, d_svhn_loss: 0.1332, d_fake_loss: 0.0332, g_loss: 1.1712\n",
            "Step [58990/60000], d_real_loss: 0.0741, d_mnist_loss: 0.0199, d_svhn_loss: 0.0541, d_fake_loss: 0.0802, g_loss: 1.0488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [59000/60000], d_real_loss: 0.0280, d_mnist_loss: 0.0102, d_svhn_loss: 0.0178, d_fake_loss: 0.0315, g_loss: 1.1428\n",
            "saved ./samples_fashion/sample-59000-m-s.png\n",
            "saved ./samples_fashion/sample-59000-s-m.png\n",
            "Step [59010/60000], d_real_loss: 0.0266, d_mnist_loss: 0.0073, d_svhn_loss: 0.0193, d_fake_loss: 0.0185, g_loss: 1.1599\n",
            "Step [59020/60000], d_real_loss: 0.0205, d_mnist_loss: 0.0096, d_svhn_loss: 0.0109, d_fake_loss: 0.0450, g_loss: 1.2102\n",
            "Step [59030/60000], d_real_loss: 0.0788, d_mnist_loss: 0.0264, d_svhn_loss: 0.0524, d_fake_loss: 0.1859, g_loss: 1.0864\n",
            "Step [59040/60000], d_real_loss: 0.0414, d_mnist_loss: 0.0120, d_svhn_loss: 0.0294, d_fake_loss: 0.0247, g_loss: 1.0952\n",
            "Step [59050/60000], d_real_loss: 0.0404, d_mnist_loss: 0.0139, d_svhn_loss: 0.0265, d_fake_loss: 0.0203, g_loss: 1.0883\n",
            "Step [59060/60000], d_real_loss: 0.0170, d_mnist_loss: 0.0073, d_svhn_loss: 0.0097, d_fake_loss: 0.0502, g_loss: 1.1590\n",
            "Step [59070/60000], d_real_loss: 0.0308, d_mnist_loss: 0.0143, d_svhn_loss: 0.0165, d_fake_loss: 0.0382, g_loss: 1.0937\n",
            "Step [59080/60000], d_real_loss: 0.0271, d_mnist_loss: 0.0130, d_svhn_loss: 0.0141, d_fake_loss: 0.0599, g_loss: 1.0945\n",
            "Step [59090/60000], d_real_loss: 0.0177, d_mnist_loss: 0.0047, d_svhn_loss: 0.0131, d_fake_loss: 0.0326, g_loss: 1.0876\n",
            "Step [59100/60000], d_real_loss: 0.0354, d_mnist_loss: 0.0131, d_svhn_loss: 0.0224, d_fake_loss: 0.1164, g_loss: 0.9637\n",
            "Step [59110/60000], d_real_loss: 0.0332, d_mnist_loss: 0.0152, d_svhn_loss: 0.0179, d_fake_loss: 0.0213, g_loss: 1.1361\n",
            "Step [59120/60000], d_real_loss: 0.0417, d_mnist_loss: 0.0228, d_svhn_loss: 0.0189, d_fake_loss: 0.0258, g_loss: 1.2402\n",
            "Step [59130/60000], d_real_loss: 0.0256, d_mnist_loss: 0.0072, d_svhn_loss: 0.0184, d_fake_loss: 0.0162, g_loss: 1.0844\n",
            "Step [59140/60000], d_real_loss: 0.0464, d_mnist_loss: 0.0095, d_svhn_loss: 0.0369, d_fake_loss: 0.0134, g_loss: 1.1537\n",
            "Step [59150/60000], d_real_loss: 0.0409, d_mnist_loss: 0.0166, d_svhn_loss: 0.0243, d_fake_loss: 0.0331, g_loss: 1.1138\n",
            "Step [59160/60000], d_real_loss: 0.0794, d_mnist_loss: 0.0092, d_svhn_loss: 0.0702, d_fake_loss: 0.0470, g_loss: 1.1699\n",
            "Step [59170/60000], d_real_loss: 0.0547, d_mnist_loss: 0.0053, d_svhn_loss: 0.0494, d_fake_loss: 0.0195, g_loss: 1.0904\n",
            "Step [59180/60000], d_real_loss: 0.0405, d_mnist_loss: 0.0145, d_svhn_loss: 0.0261, d_fake_loss: 0.0749, g_loss: 1.3323\n",
            "Step [59190/60000], d_real_loss: 0.0768, d_mnist_loss: 0.0657, d_svhn_loss: 0.0111, d_fake_loss: 0.0359, g_loss: 1.4296\n",
            "Step [59200/60000], d_real_loss: 0.1193, d_mnist_loss: 0.0263, d_svhn_loss: 0.0930, d_fake_loss: 0.0815, g_loss: 1.0788\n",
            "Step [59210/60000], d_real_loss: 0.0201, d_mnist_loss: 0.0108, d_svhn_loss: 0.0093, d_fake_loss: 0.0378, g_loss: 1.0815\n",
            "Step [59220/60000], d_real_loss: 0.0371, d_mnist_loss: 0.0093, d_svhn_loss: 0.0278, d_fake_loss: 0.0186, g_loss: 1.3312\n",
            "Step [59230/60000], d_real_loss: 0.0275, d_mnist_loss: 0.0091, d_svhn_loss: 0.0184, d_fake_loss: 0.0226, g_loss: 1.0584\n",
            "Step [59240/60000], d_real_loss: 0.0298, d_mnist_loss: 0.0067, d_svhn_loss: 0.0231, d_fake_loss: 0.0279, g_loss: 1.1406\n",
            "Step [59250/60000], d_real_loss: 0.0426, d_mnist_loss: 0.0297, d_svhn_loss: 0.0129, d_fake_loss: 0.0338, g_loss: 1.3088\n",
            "Step [59260/60000], d_real_loss: 0.0382, d_mnist_loss: 0.0258, d_svhn_loss: 0.0124, d_fake_loss: 0.0262, g_loss: 0.9421\n",
            "Step [59270/60000], d_real_loss: 0.0435, d_mnist_loss: 0.0179, d_svhn_loss: 0.0256, d_fake_loss: 0.0436, g_loss: 1.2112\n",
            "Step [59280/60000], d_real_loss: 0.0557, d_mnist_loss: 0.0072, d_svhn_loss: 0.0485, d_fake_loss: 0.0150, g_loss: 1.1607\n",
            "Step [59290/60000], d_real_loss: 0.0401, d_mnist_loss: 0.0123, d_svhn_loss: 0.0278, d_fake_loss: 0.0388, g_loss: 1.3309\n",
            "Step [59300/60000], d_real_loss: 0.0341, d_mnist_loss: 0.0067, d_svhn_loss: 0.0273, d_fake_loss: 0.0402, g_loss: 1.3459\n",
            "Step [59310/60000], d_real_loss: 0.0395, d_mnist_loss: 0.0139, d_svhn_loss: 0.0256, d_fake_loss: 0.0951, g_loss: 0.9489\n",
            "Step [59320/60000], d_real_loss: 0.0883, d_mnist_loss: 0.0520, d_svhn_loss: 0.0363, d_fake_loss: 0.0756, g_loss: 1.1056\n",
            "Step [59330/60000], d_real_loss: 0.0246, d_mnist_loss: 0.0092, d_svhn_loss: 0.0155, d_fake_loss: 0.0526, g_loss: 1.1472\n",
            "Step [59340/60000], d_real_loss: 0.0307, d_mnist_loss: 0.0134, d_svhn_loss: 0.0173, d_fake_loss: 0.0155, g_loss: 1.0562\n",
            "Step [59350/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0172, d_svhn_loss: 0.0163, d_fake_loss: 0.0516, g_loss: 1.1690\n",
            "Step [59360/60000], d_real_loss: 0.0348, d_mnist_loss: 0.0128, d_svhn_loss: 0.0221, d_fake_loss: 0.0321, g_loss: 1.0751\n",
            "Step [59370/60000], d_real_loss: 0.0383, d_mnist_loss: 0.0147, d_svhn_loss: 0.0237, d_fake_loss: 0.0428, g_loss: 1.2264\n",
            "Step [59380/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0180, d_svhn_loss: 0.0192, d_fake_loss: 0.0712, g_loss: 1.2012\n",
            "Step [59390/60000], d_real_loss: 0.0532, d_mnist_loss: 0.0114, d_svhn_loss: 0.0419, d_fake_loss: 0.1178, g_loss: 1.0243\n",
            "Step [59400/60000], d_real_loss: 0.0268, d_mnist_loss: 0.0096, d_svhn_loss: 0.0171, d_fake_loss: 0.0460, g_loss: 1.0263\n",
            "Step [59410/60000], d_real_loss: 0.0357, d_mnist_loss: 0.0071, d_svhn_loss: 0.0286, d_fake_loss: 0.0166, g_loss: 1.1500\n",
            "Step [59420/60000], d_real_loss: 0.0234, d_mnist_loss: 0.0071, d_svhn_loss: 0.0163, d_fake_loss: 0.0161, g_loss: 1.0565\n",
            "Step [59430/60000], d_real_loss: 0.0432, d_mnist_loss: 0.0095, d_svhn_loss: 0.0337, d_fake_loss: 0.0294, g_loss: 1.2894\n",
            "Step [59440/60000], d_real_loss: 0.0471, d_mnist_loss: 0.0346, d_svhn_loss: 0.0126, d_fake_loss: 0.0308, g_loss: 1.2777\n",
            "Step [59450/60000], d_real_loss: 0.0335, d_mnist_loss: 0.0189, d_svhn_loss: 0.0146, d_fake_loss: 0.0466, g_loss: 1.1831\n",
            "Step [59460/60000], d_real_loss: 0.0516, d_mnist_loss: 0.0130, d_svhn_loss: 0.0386, d_fake_loss: 0.0424, g_loss: 1.1668\n",
            "Step [59470/60000], d_real_loss: 0.0530, d_mnist_loss: 0.0068, d_svhn_loss: 0.0461, d_fake_loss: 0.0311, g_loss: 1.2486\n",
            "Step [59480/60000], d_real_loss: 0.0509, d_mnist_loss: 0.0071, d_svhn_loss: 0.0438, d_fake_loss: 0.0541, g_loss: 1.0926\n",
            "Step [59490/60000], d_real_loss: 0.0286, d_mnist_loss: 0.0060, d_svhn_loss: 0.0226, d_fake_loss: 0.0289, g_loss: 1.0928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [59500/60000], d_real_loss: 0.0911, d_mnist_loss: 0.0105, d_svhn_loss: 0.0806, d_fake_loss: 0.1072, g_loss: 1.0727\n",
            "saved ./samples_fashion/sample-59500-m-s.png\n",
            "saved ./samples_fashion/sample-59500-s-m.png\n",
            "Step [59510/60000], d_real_loss: 0.0469, d_mnist_loss: 0.0081, d_svhn_loss: 0.0388, d_fake_loss: 0.0520, g_loss: 1.1340\n",
            "Step [59520/60000], d_real_loss: 0.0452, d_mnist_loss: 0.0159, d_svhn_loss: 0.0293, d_fake_loss: 0.0590, g_loss: 1.1781\n",
            "Step [59530/60000], d_real_loss: 0.0592, d_mnist_loss: 0.0090, d_svhn_loss: 0.0502, d_fake_loss: 0.0340, g_loss: 1.1510\n",
            "Step [59540/60000], d_real_loss: 0.0474, d_mnist_loss: 0.0148, d_svhn_loss: 0.0326, d_fake_loss: 0.0235, g_loss: 1.1481\n",
            "Step [59550/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0220, d_svhn_loss: 0.0153, d_fake_loss: 0.0185, g_loss: 1.1173\n",
            "Step [59560/60000], d_real_loss: 0.0290, d_mnist_loss: 0.0052, d_svhn_loss: 0.0238, d_fake_loss: 0.0636, g_loss: 1.0485\n",
            "Step [59570/60000], d_real_loss: 0.1031, d_mnist_loss: 0.0085, d_svhn_loss: 0.0946, d_fake_loss: 0.0528, g_loss: 1.2640\n",
            "Step [59580/60000], d_real_loss: 0.0408, d_mnist_loss: 0.0226, d_svhn_loss: 0.0182, d_fake_loss: 0.0357, g_loss: 0.8720\n",
            "Step [59590/60000], d_real_loss: 0.3993, d_mnist_loss: 0.3637, d_svhn_loss: 0.0356, d_fake_loss: 0.1427, g_loss: 1.1307\n",
            "Step [59600/60000], d_real_loss: 0.1019, d_mnist_loss: 0.0316, d_svhn_loss: 0.0703, d_fake_loss: 0.1133, g_loss: 1.0412\n",
            "Step [59610/60000], d_real_loss: 0.0384, d_mnist_loss: 0.0072, d_svhn_loss: 0.0312, d_fake_loss: 0.0408, g_loss: 1.2200\n",
            "Step [59620/60000], d_real_loss: 0.0340, d_mnist_loss: 0.0083, d_svhn_loss: 0.0258, d_fake_loss: 0.0696, g_loss: 1.1571\n",
            "Step [59630/60000], d_real_loss: 0.0275, d_mnist_loss: 0.0080, d_svhn_loss: 0.0194, d_fake_loss: 0.0714, g_loss: 1.1673\n",
            "Step [59640/60000], d_real_loss: 0.0959, d_mnist_loss: 0.0092, d_svhn_loss: 0.0867, d_fake_loss: 0.0702, g_loss: 1.2331\n",
            "Step [59650/60000], d_real_loss: 0.0206, d_mnist_loss: 0.0067, d_svhn_loss: 0.0139, d_fake_loss: 0.0433, g_loss: 1.1424\n",
            "Step [59660/60000], d_real_loss: 0.0762, d_mnist_loss: 0.0099, d_svhn_loss: 0.0663, d_fake_loss: 0.0292, g_loss: 1.0453\n",
            "Step [59670/60000], d_real_loss: 0.0396, d_mnist_loss: 0.0133, d_svhn_loss: 0.0263, d_fake_loss: 0.0471, g_loss: 1.0812\n",
            "Step [59680/60000], d_real_loss: 0.0222, d_mnist_loss: 0.0050, d_svhn_loss: 0.0171, d_fake_loss: 0.0269, g_loss: 1.1472\n",
            "Step [59690/60000], d_real_loss: 0.0641, d_mnist_loss: 0.0283, d_svhn_loss: 0.0357, d_fake_loss: 0.0492, g_loss: 0.9726\n",
            "Step [59700/60000], d_real_loss: 0.0858, d_mnist_loss: 0.0206, d_svhn_loss: 0.0651, d_fake_loss: 0.0826, g_loss: 1.2623\n",
            "Step [59710/60000], d_real_loss: 0.0262, d_mnist_loss: 0.0069, d_svhn_loss: 0.0193, d_fake_loss: 0.0393, g_loss: 1.1831\n",
            "Step [59720/60000], d_real_loss: 0.0327, d_mnist_loss: 0.0164, d_svhn_loss: 0.0162, d_fake_loss: 0.0807, g_loss: 0.9405\n",
            "Step [59730/60000], d_real_loss: 0.0823, d_mnist_loss: 0.0075, d_svhn_loss: 0.0748, d_fake_loss: 0.0505, g_loss: 1.1289\n",
            "Step [59740/60000], d_real_loss: 0.0995, d_mnist_loss: 0.0775, d_svhn_loss: 0.0220, d_fake_loss: 0.0532, g_loss: 1.1652\n",
            "Step [59750/60000], d_real_loss: 0.1829, d_mnist_loss: 0.0707, d_svhn_loss: 0.1122, d_fake_loss: 0.0597, g_loss: 1.1005\n",
            "Step [59760/60000], d_real_loss: 0.0619, d_mnist_loss: 0.0063, d_svhn_loss: 0.0556, d_fake_loss: 0.0396, g_loss: 1.1757\n",
            "Step [59770/60000], d_real_loss: 0.0750, d_mnist_loss: 0.0063, d_svhn_loss: 0.0687, d_fake_loss: 0.0794, g_loss: 1.1960\n",
            "Step [59780/60000], d_real_loss: 0.0227, d_mnist_loss: 0.0097, d_svhn_loss: 0.0131, d_fake_loss: 0.0275, g_loss: 1.1139\n",
            "Step [59790/60000], d_real_loss: 0.0372, d_mnist_loss: 0.0139, d_svhn_loss: 0.0232, d_fake_loss: 0.0125, g_loss: 1.1667\n",
            "Step [59800/60000], d_real_loss: 0.0652, d_mnist_loss: 0.0156, d_svhn_loss: 0.0496, d_fake_loss: 0.0189, g_loss: 1.0808\n",
            "Step [59810/60000], d_real_loss: 0.0644, d_mnist_loss: 0.0115, d_svhn_loss: 0.0529, d_fake_loss: 0.0426, g_loss: 1.0859\n",
            "Step [59820/60000], d_real_loss: 0.0292, d_mnist_loss: 0.0102, d_svhn_loss: 0.0190, d_fake_loss: 0.0206, g_loss: 1.2186\n",
            "Step [59830/60000], d_real_loss: 0.0281, d_mnist_loss: 0.0064, d_svhn_loss: 0.0217, d_fake_loss: 0.0317, g_loss: 1.1434\n",
            "Step [59840/60000], d_real_loss: 0.0252, d_mnist_loss: 0.0048, d_svhn_loss: 0.0204, d_fake_loss: 0.0514, g_loss: 1.1415\n",
            "Step [59850/60000], d_real_loss: 0.1516, d_mnist_loss: 0.0859, d_svhn_loss: 0.0657, d_fake_loss: 0.0734, g_loss: 1.4455\n",
            "Step [59860/60000], d_real_loss: 0.0712, d_mnist_loss: 0.0096, d_svhn_loss: 0.0616, d_fake_loss: 0.0181, g_loss: 1.1024\n",
            "Step [59870/60000], d_real_loss: 0.0339, d_mnist_loss: 0.0046, d_svhn_loss: 0.0293, d_fake_loss: 0.0168, g_loss: 1.1448\n",
            "Step [59880/60000], d_real_loss: 0.0511, d_mnist_loss: 0.0356, d_svhn_loss: 0.0155, d_fake_loss: 0.0135, g_loss: 1.0527\n",
            "Step [59890/60000], d_real_loss: 0.0487, d_mnist_loss: 0.0121, d_svhn_loss: 0.0366, d_fake_loss: 0.0190, g_loss: 1.0220\n",
            "Step [59900/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0160, d_svhn_loss: 0.0111, d_fake_loss: 0.0269, g_loss: 1.1443\n",
            "Step [59910/60000], d_real_loss: 0.1249, d_mnist_loss: 0.0200, d_svhn_loss: 0.1049, d_fake_loss: 0.0577, g_loss: 1.0293\n",
            "Step [59920/60000], d_real_loss: 0.0316, d_mnist_loss: 0.0168, d_svhn_loss: 0.0148, d_fake_loss: 0.1198, g_loss: 1.6341\n",
            "Step [59930/60000], d_real_loss: 0.0218, d_mnist_loss: 0.0104, d_svhn_loss: 0.0114, d_fake_loss: 0.0275, g_loss: 1.1343\n",
            "Step [59940/60000], d_real_loss: 0.0895, d_mnist_loss: 0.0152, d_svhn_loss: 0.0743, d_fake_loss: 0.0976, g_loss: 1.0926\n",
            "Step [59950/60000], d_real_loss: 0.0270, d_mnist_loss: 0.0083, d_svhn_loss: 0.0187, d_fake_loss: 0.0245, g_loss: 1.0735\n",
            "Step [59960/60000], d_real_loss: 0.0398, d_mnist_loss: 0.0093, d_svhn_loss: 0.0305, d_fake_loss: 0.0257, g_loss: 1.2451\n",
            "Step [59970/60000], d_real_loss: 0.0890, d_mnist_loss: 0.0210, d_svhn_loss: 0.0680, d_fake_loss: 0.0221, g_loss: 1.2021\n",
            "Step [59980/60000], d_real_loss: 0.0307, d_mnist_loss: 0.0170, d_svhn_loss: 0.0138, d_fake_loss: 0.0247, g_loss: 1.0703\n",
            "Step [59990/60000], d_real_loss: 0.0276, d_mnist_loss: 0.0082, d_svhn_loss: 0.0195, d_fake_loss: 0.0565, g_loss: 1.2476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [60000/60000], d_real_loss: 0.0329, d_mnist_loss: 0.0172, d_svhn_loss: 0.0157, d_fake_loss: 0.0286, g_loss: 1.2147\n",
            "saved ./samples_fashion/sample-60000-m-s.png\n",
            "saved ./samples_fashion/sample-60000-s-m.png\n"
          ]
        }
      ],
      "source": [
        "d_real_loss_list1, d_mnist_loss_list1, d_svhn_loss_list1, d_fake_loss_list1, g_loss_list1 = train(fashion_loader, Fashionmnist_loader, sample_path=sample_path2, model_path=model_path2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "classes = [d_real_loss_list1,d_mnist_loss_list1,d_svhn_loss_list1,d_fake_loss_list1,g_loss_list1]\n",
        "labels = ['d_real_loss','d_mnist_loss','d_svhn_loss','d_fake_loss','g_loss']\n",
        "# 第一幅图的下标从1开始，设置6张子图\n",
        "for plt_index in range(1,6):\n",
        "    # 往画布上添加子图：按三行二列，添加到下标为plt_index的位置\n",
        "    ax = fig.add_subplot(3,2,plt_index)\n",
        "    # 绘制对应的子图\n",
        "    plt.plot(range(train_iters+1), classes[plt_index-1], label = labels[plt_index-1])\n",
        "    plt.xlabel(\"iters\")\n",
        "    plt.ylabel(\"loss values\")\n",
        "    pass\n",
        "\n",
        "# 显示画布\n",
        "plt.title(\"The figure of loss in transformation betweem fashionmnist and small fashion product images\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "vpCo2tdasSAL",
        "outputId": "7fb3ca7b-8825-48fb-a6e5-c990d21795ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, tarfile\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def make_targz_one_by_one(output_filename, source_dir):\n",
        "  tar = tarfile.open(output_filename,\"w\")\n",
        "  for root,dir_name,files_list in os.walk(source_dir):\n",
        "    for file in files_list:\n",
        "      pathfile = os.path.join(root, file)\n",
        "      tar.add(pathfile)\n",
        "  tar.close()\n",
        "  files.download(output_filename)\n",
        "\n",
        "make_targz_one_by_one('models_mnist_svhn.zip', '/content/models_mnist_svhn')\n",
        "make_targz_one_by_one('samples_mnist_svhn.zip', '/content/samples_mnist_svhn')\n",
        "make_targz_one_by_one('models_fashion.zip', '/content/models_fashion')\n",
        "make_targz_one_by_one('samples_fashion.zip', '/content/samples_fashion')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6-1HE7fy-4tb",
        "outputId": "652128ac-7e75-4ec0-bb9e-f967cd5af481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ad087ed5-cb72-4a6e-aac6-3255de0869b9\", \"models_mnist_svhn.zip\", 10240)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0198d9e-2ad2-4efb-8001-c9bb75fc3096\", \"models_mnist_svhn.zip\", 10240)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0f9cb2e8-7e0c-4031-888b-513a573ae6e4\", \"models_fashion.zip\", 10240)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ff657b48-638d-429e-9e59-59369731f1cf\", \"samples_fashion.zip\", 10240)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "503f5874e8434572a40ced3070e25145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ffc1762f31e40b596ef4d6722c019cc",
              "IPY_MODEL_6d7757fff1834a71afcd9e74954951af",
              "IPY_MODEL_34e40568f0074269985944e865755ab7"
            ],
            "layout": "IPY_MODEL_f266338a6e0d453699f61c2e205f76a0"
          }
        },
        "8ffc1762f31e40b596ef4d6722c019cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06cf417f63f1436d8845caa45395d475",
            "placeholder": "​",
            "style": "IPY_MODEL_04aa2d4602b64480a1229d7cf55cccb7",
            "value": "100%"
          }
        },
        "6d7757fff1834a71afcd9e74954951af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6759c2072257440f8c8570960f93214a",
            "max": 182040794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c369026a3754724a72927fc3b2f0f8a",
            "value": 182040794
          }
        },
        "34e40568f0074269985944e865755ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8c83db90c2d4a2b8a4e68cd8873e552",
            "placeholder": "​",
            "style": "IPY_MODEL_753249d9f0884877880a104a2a2207ae",
            "value": " 182040794/182040794 [00:08&lt;00:00, 42641850.15it/s]"
          }
        },
        "f266338a6e0d453699f61c2e205f76a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06cf417f63f1436d8845caa45395d475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04aa2d4602b64480a1229d7cf55cccb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6759c2072257440f8c8570960f93214a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c369026a3754724a72927fc3b2f0f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8c83db90c2d4a2b8a4e68cd8873e552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753249d9f0884877880a104a2a2207ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91ed187dd38848e8a1720432f67125d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c6670c27405441d8829b9b2dbd60fc2",
              "IPY_MODEL_2800b89f320a41179bc1c43173649be2",
              "IPY_MODEL_0aedfa8a9c734b8d83c497aae478ba51"
            ],
            "layout": "IPY_MODEL_1b85359e5c6642548ee72f7d4c4f7e6e"
          }
        },
        "4c6670c27405441d8829b9b2dbd60fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f45653fedc634c3884ed394d8535608b",
            "placeholder": "​",
            "style": "IPY_MODEL_2c7639bcfc204511bec0171d96358855",
            "value": "100%"
          }
        },
        "2800b89f320a41179bc1c43173649be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aadd4926464f49d6ab080b0204e7ddbe",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f105bb0ae2843d89c8e00ce9fbdb647",
            "value": 9912422
          }
        },
        "0aedfa8a9c734b8d83c497aae478ba51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dcc3493b5c74bf8876060ad3fe22361",
            "placeholder": "​",
            "style": "IPY_MODEL_f860476ed0e5444ebb83d69ec6f5541d",
            "value": " 9912422/9912422 [00:00&lt;00:00, 7526741.46it/s]"
          }
        },
        "1b85359e5c6642548ee72f7d4c4f7e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f45653fedc634c3884ed394d8535608b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c7639bcfc204511bec0171d96358855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aadd4926464f49d6ab080b0204e7ddbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f105bb0ae2843d89c8e00ce9fbdb647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dcc3493b5c74bf8876060ad3fe22361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f860476ed0e5444ebb83d69ec6f5541d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bf417e12e5d441c84d5a156dff8ed0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de0dae07b3ce42948d1a230a13b9676d",
              "IPY_MODEL_ca44342d362f4dcfab532e2eb3d9f1b9",
              "IPY_MODEL_8551971bca634910967753615a8856af"
            ],
            "layout": "IPY_MODEL_8ee5e6bbe0834f7e9cf079c72d191ee5"
          }
        },
        "de0dae07b3ce42948d1a230a13b9676d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf1502f2e714ccf8317f519f795d149",
            "placeholder": "​",
            "style": "IPY_MODEL_75b42e95955a4982bd8a1440e6723d94",
            "value": "100%"
          }
        },
        "ca44342d362f4dcfab532e2eb3d9f1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed2b067a90c04d05968dc5227a648657",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afd73a36ae224d1ba692713ecca9c6bb",
            "value": 28881
          }
        },
        "8551971bca634910967753615a8856af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7182f771e8f048ba94a39a6681c9d6b5",
            "placeholder": "​",
            "style": "IPY_MODEL_534e8036bfb2416c8daac51e45833ade",
            "value": " 28881/28881 [00:00&lt;00:00, 710185.87it/s]"
          }
        },
        "8ee5e6bbe0834f7e9cf079c72d191ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf1502f2e714ccf8317f519f795d149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b42e95955a4982bd8a1440e6723d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed2b067a90c04d05968dc5227a648657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd73a36ae224d1ba692713ecca9c6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7182f771e8f048ba94a39a6681c9d6b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534e8036bfb2416c8daac51e45833ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "909862a11f974f3d9b758b41409532e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c90c1bed97954ba9bcea6b537409fc1e",
              "IPY_MODEL_73fe63ce4bff4b9c9faedee2a283d898",
              "IPY_MODEL_9f9dcf06f66e4767b49a4e8de26f2b4d"
            ],
            "layout": "IPY_MODEL_08dd5301db3f4edc99ebf94bdc1e937e"
          }
        },
        "c90c1bed97954ba9bcea6b537409fc1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf0115fe86534c37b9c7a8a19b5f3ef0",
            "placeholder": "​",
            "style": "IPY_MODEL_4a50700cf6f84976bfb81057de789cc5",
            "value": "100%"
          }
        },
        "73fe63ce4bff4b9c9faedee2a283d898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd1b77bd7ccd49c695dc494e306b3dd5",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea4d7c16e75b4ac4bc0dc79f910013a6",
            "value": 1648877
          }
        },
        "9f9dcf06f66e4767b49a4e8de26f2b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94200059f7d94112948c4a61d3cf19d5",
            "placeholder": "​",
            "style": "IPY_MODEL_72258eb849784eeeb154e8450ebbe83d",
            "value": " 1648877/1648877 [00:00&lt;00:00, 17213301.43it/s]"
          }
        },
        "08dd5301db3f4edc99ebf94bdc1e937e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf0115fe86534c37b9c7a8a19b5f3ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a50700cf6f84976bfb81057de789cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd1b77bd7ccd49c695dc494e306b3dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea4d7c16e75b4ac4bc0dc79f910013a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94200059f7d94112948c4a61d3cf19d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72258eb849784eeeb154e8450ebbe83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d69fe6625a74ab198029fd865edfb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fef566748bfe4d61acda556a43925e69",
              "IPY_MODEL_5738b24fdc6b44cba2416e50a0968093",
              "IPY_MODEL_db64d227eb1f4351a9defa6a29599eaa"
            ],
            "layout": "IPY_MODEL_d7127bb454ae40779394bd81808d2dac"
          }
        },
        "fef566748bfe4d61acda556a43925e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ff662113304860817d441516252c36",
            "placeholder": "​",
            "style": "IPY_MODEL_0dc46ad7cf5c4ec5b4c800c69e5e2c86",
            "value": "100%"
          }
        },
        "5738b24fdc6b44cba2416e50a0968093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f5a136733924c2a957d653e2d32ac68",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d8ea2a251334676a84cd2c56ec5f09f",
            "value": 4542
          }
        },
        "db64d227eb1f4351a9defa6a29599eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ca1ce4a92a48bb84e3501a388f86c2",
            "placeholder": "​",
            "style": "IPY_MODEL_d22d5e477f504c4ead0896c1d4ab961f",
            "value": " 4542/4542 [00:00&lt;00:00, 125203.93it/s]"
          }
        },
        "d7127bb454ae40779394bd81808d2dac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ff662113304860817d441516252c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dc46ad7cf5c4ec5b4c800c69e5e2c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f5a136733924c2a957d653e2d32ac68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d8ea2a251334676a84cd2c56ec5f09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1ca1ce4a92a48bb84e3501a388f86c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22d5e477f504c4ead0896c1d4ab961f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}